nohup: ignoring input
4
/home/wxt/.conda/envs/halos3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Making experiment directory /home/wxt/.cache/huggingface/hub/llama2_7b_dpo_halos
WARNING: eval_every must be divisible by batch_size
Setting eval_every to 992
no FSDP port specified; using open port for FSDP: 55167
seed: 1
exp_name: llama2_7b_dpo_halos
datasets:
- hh
mode: train
debug: false
use_fsdp: true
fsdp_port: 55167
wandb:
  enabled: true
  entity: null
  project: archangel
cache_dir: /home/wxt/.cache/huggingface/hub
local_run_dir: /home/wxt/.cache/huggingface/hub/llama2_7b_dpo_halos
do_first_eval: true
minimum_log_interval_secs: 1.0
intermediate_checkpoints: false
trainer: SFTTrainer
lr: 1.0e-06
n_epochs: 1
n_examples: null
optimizer: RMSprop
warmup_steps: 150
eval_every: 992
n_samples: 128
samples_dir: samples/
n_eval_examples: 512
saved_policy: /home/wxt/.cache/huggingface/hub/llama2_7b_dpo_halos/LATEST/policy.pt
top_p: 0.95
human_prefix: '

  <|user|>

  '
assistant_prefix: '

  <|assistant|>

  '
human_suffix: ''
assistant_suffix: ''
frac_unique_desirable: 1.0
frac_unique_undesirable: 1.0
model:
  name_or_path: daryl149/llama-2-7b-hf
  tokenizer_name_or_path: null
  load_from: /home/wxt/.cache/huggingface/hub/llama2_7b_sft_halos/LATEST/policy.pt
  block_name: LlamaDecoderLayer
  policy_dtype: bfloat16
  fsdp_policy_mp: null
  reference_dtype: bfloat16
  max_grad_norm: 10.0
  v_head_max_grad_norm: 0.1
  max_length: 1024
  max_prompt_length: 512
  activation_checkpointing: true
  batch_size: 16
  gradient_accumulation_steps: 4
  eval_batch_size: 16
  use_flash_attention: false
loss:
  name: dpo
  beta: 0.1
  trainer: DPOTrainer
  dataloader: PairedPreferenceDataLoader
  use_reference_model: true

================================================================================
Writing to design-agent-09:/home/wxt/.cache/huggingface/hub/llama2_7b_dpo_halos
================================================================================
building policy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
building reference model
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]
loading pre-trained weights at step 159872 from /home/wxt/.cache/huggingface/hub/llama2_7b_sft_halos/LATEST/policy.pt with metrics {}
loaded pre-trained weights
Loading tokenizer daryl149/llama-2-7b-hf
0 special tokens added
Loading HH dataset (train split) from Huggingface...
Processing HH:   0%|          | 0/160800 [00:00<?, ?it/s]Processing HH:   1%|          | 1458/160800 [00:00<00:10, 14575.53it/s]Processing HH:   2%|▏         | 2956/160800 [00:00<00:10, 14799.53it/s]Processing HH:   3%|▎         | 4474/160800 [00:00<00:10, 14971.24it/s]Processing HH:   4%|▎         | 5972/160800 [00:00<00:10, 14897.03it/s]Processing HH:   5%|▍         | 7462/160800 [00:00<00:10, 14821.53it/s]Processing HH:   6%|▌         | 8945/160800 [00:00<00:10, 14765.57it/s]Processing HH:   6%|▋         | 10422/160800 [00:00<00:10, 14671.65it/s]Processing HH:   7%|▋         | 11890/160800 [00:00<00:10, 14665.64it/s]Processing HH:   8%|▊         | 13357/160800 [00:00<00:10, 14588.24it/s]Processing HH:   9%|▉         | 14816/160800 [00:01<00:13, 10482.49it/s]Processing HH:  10%|█         | 16302/160800 [00:01<00:12, 11528.16it/s]Processing HH:  11%|█         | 17792/160800 [00:01<00:11, 12385.87it/s]Processing HH:  12%|█▏        | 19197/160800 [00:01<00:11, 12828.28it/s]Processing HH:  13%|█▎        | 20662/160800 [00:01<00:10, 13330.36it/s]Processing HH:  14%|█▎        | 22086/160800 [00:01<00:10, 13584.88it/s]Processing HH:  15%|█▍        | 23560/160800 [00:01<00:09, 13916.65it/s]Processing HH:  16%|█▌        | 25001/160800 [00:01<00:09, 14059.79it/s]Processing HH:  16%|█▋        | 26432/160800 [00:01<00:09, 13937.59it/s]Processing HH:  17%|█▋        | 27886/160800 [00:02<00:09, 14112.15it/s]Processing HH:  18%|█▊        | 29310/160800 [00:02<00:09, 14074.61it/s]Processing HH:  19%|█▉        | 30736/160800 [00:02<00:09, 14126.49it/s]Processing HH:  20%|██        | 32167/160800 [00:02<00:09, 14177.09it/s]Processing HH:  21%|██        | 33621/160800 [00:02<00:12, 10446.45it/s]Processing HH:  22%|██▏       | 35049/160800 [00:02<00:11, 11354.23it/s]Processing HH:  23%|██▎       | 36366/160800 [00:02<00:10, 11812.78it/s]Processing HH:  23%|██▎       | 37779/160800 [00:02<00:09, 12427.41it/s]Processing HH:  24%|██▍       | 39103/160800 [00:02<00:09, 12650.62it/s]Processing HH:  25%|██▌       | 40522/160800 [00:03<00:09, 13081.96it/s]Processing HH:  26%|██▌       | 41935/160800 [00:03<00:08, 13379.90it/s]Processing HH:  27%|██▋       | 43324/160800 [00:03<00:08, 13527.37it/s]Processing HH:  28%|██▊       | 44699/160800 [00:03<00:08, 13433.48it/s]Processing HH:  29%|██▊       | 46058/160800 [00:03<00:08, 13452.85it/s]Processing HH:  29%|██▉       | 47414/160800 [00:03<00:08, 13452.75it/s]Processing HH:  30%|███       | 48806/160800 [00:03<00:08, 13590.22it/s]Processing HH:  31%|███       | 50173/160800 [00:03<00:08, 13610.11it/s]Processing HH:  32%|███▏      | 51538/160800 [00:03<00:08, 13494.72it/s]Processing HH:  33%|███▎      | 52891/160800 [00:03<00:08, 13471.85it/s]Processing HH:  34%|███▎      | 54246/160800 [00:04<00:07, 13494.56it/s]Processing HH:  35%|███▍      | 55646/160800 [00:04<00:07, 13644.24it/s]Processing HH:  35%|███▌      | 57014/160800 [00:04<00:07, 13653.73it/s]Processing HH:  36%|███▋      | 58381/160800 [00:04<00:10, 9648.21it/s] Processing HH:  37%|███▋      | 59787/160800 [00:04<00:09, 10667.64it/s]Processing HH:  38%|███▊      | 61135/160800 [00:04<00:08, 11366.49it/s]Processing HH:  39%|███▉      | 62566/160800 [00:04<00:08, 12137.93it/s]Processing HH:  40%|███▉      | 63881/160800 [00:04<00:07, 12412.83it/s]Processing HH:  41%|████      | 65269/160800 [00:05<00:07, 12822.03it/s]Processing HH:  41%|████▏     | 66691/160800 [00:05<00:07, 13219.90it/s]Processing HH:  42%|████▏     | 68069/160800 [00:05<00:06, 13381.57it/s]Processing HH:  43%|████▎     | 69460/160800 [00:05<00:06, 13534.15it/s]Processing HH:  44%|████▍     | 70833/160800 [00:05<00:06, 13536.90it/s]Processing HH:  45%|████▍     | 72237/160800 [00:05<00:06, 13683.37it/s]Processing HH:  46%|████▌     | 73652/160800 [00:05<00:06, 13817.57it/s]Processing HH:  47%|████▋     | 75075/160800 [00:05<00:06, 13938.52it/s]Processing HH:  48%|████▊     | 76474/160800 [00:05<00:06, 13888.12it/s]Processing HH:  48%|████▊     | 77867/160800 [00:05<00:06, 13709.82it/s]Processing HH:  49%|████▉     | 79241/160800 [00:06<00:05, 13611.88it/s]Processing HH:  50%|█████     | 80624/160800 [00:06<00:05, 13675.82it/s]Processing HH:  51%|█████     | 81994/160800 [00:06<00:05, 13674.30it/s]Processing HH:  52%|█████▏    | 83363/160800 [00:06<00:05, 13667.71it/s]Processing HH:  53%|█████▎    | 84756/160800 [00:06<00:05, 13745.78it/s]Processing HH:  54%|█████▎    | 86146/160800 [00:06<00:05, 13790.19it/s]Processing HH:  54%|█████▍    | 87526/160800 [00:06<00:08, 8341.24it/s] Processing HH:  55%|█████▌    | 88622/160800 [00:06<00:08, 8213.45it/s]Processing HH:  56%|█████▌    | 89625/160800 [00:07<00:08, 8255.31it/s]Processing HH:  56%|█████▋    | 90579/160800 [00:07<00:08, 8278.56it/s]Processing HH:  57%|█████▋    | 91497/160800 [00:07<00:08, 8255.45it/s]Processing HH:  57%|█████▋    | 92386/160800 [00:07<00:08, 8326.49it/s]Processing HH:  58%|█████▊    | 93264/160800 [00:07<00:08, 8255.80it/s]Processing HH:  59%|█████▊    | 94121/160800 [00:07<00:08, 8294.71it/s]Processing HH:  59%|█████▉    | 94973/160800 [00:07<00:07, 8301.77it/s]Processing HH:  60%|█████▉    | 95819/160800 [00:07<00:07, 8264.61it/s]Processing HH:  60%|██████    | 96657/160800 [00:07<00:07, 8232.00it/s]Processing HH:  61%|██████    | 97488/160800 [00:08<00:07, 8240.50it/s]Processing HH:  61%|██████    | 98318/160800 [00:08<00:07, 8190.88it/s]Processing HH:  62%|██████▏   | 99144/160800 [00:08<00:07, 8209.30it/s]Processing HH:  62%|██████▏   | 99968/160800 [00:08<00:07, 8212.91it/s]Processing HH:  63%|██████▎   | 100792/160800 [00:08<00:07, 8173.67it/s]Processing HH:  63%|██████▎   | 101628/160800 [00:08<00:07, 8226.23it/s]Processing HH:  64%|██████▎   | 102495/160800 [00:08<00:06, 8357.70it/s]Processing HH:  64%|██████▍   | 103353/160800 [00:08<00:06, 8423.09it/s]Processing HH:  65%|██████▍   | 104196/160800 [00:08<00:06, 8367.69it/s]Processing HH:  65%|██████▌   | 105034/160800 [00:08<00:06, 8173.04it/s]Processing HH:  66%|██████▌   | 105887/160800 [00:09<00:06, 8277.63it/s]Processing HH:  66%|██████▋   | 106716/160800 [00:09<00:06, 8123.88it/s]Processing HH:  67%|██████▋   | 107534/160800 [00:09<00:06, 8134.88it/s]Processing HH:  67%|██████▋   | 108352/160800 [00:09<00:06, 8147.29it/s]Processing HH:  68%|██████▊   | 109551/160800 [00:09<00:05, 9281.75it/s]Processing HH:  69%|██████▉   | 110781/160800 [00:09<00:04, 10176.90it/s]Processing HH:  70%|██████▉   | 111982/160800 [00:09<00:04, 10723.05it/s]Processing HH:  70%|███████   | 113173/160800 [00:09<00:04, 11075.73it/s]Processing HH:  71%|███████   | 114347/160800 [00:09<00:04, 11270.10it/s]Processing HH:  72%|███████▏  | 115563/160800 [00:09<00:03, 11534.34it/s]Processing HH:  73%|███████▎  | 116773/160800 [00:10<00:03, 11701.12it/s]Processing HH:  73%|███████▎  | 117989/160800 [00:10<00:03, 11837.39it/s]Processing HH:  74%|███████▍  | 119180/160800 [00:10<00:03, 11857.64it/s]Processing HH:  75%|███████▍  | 120397/160800 [00:10<00:03, 11948.46it/s]Processing HH:  76%|███████▌  | 121614/160800 [00:10<00:03, 12014.79it/s]Processing HH:  76%|███████▋  | 122816/160800 [00:10<00:05, 7437.49it/s] Processing HH:  77%|███████▋  | 123966/160800 [00:10<00:04, 8287.91it/s]Processing HH:  78%|███████▊  | 125161/160800 [00:10<00:03, 9131.37it/s]Processing HH:  79%|███████▊  | 126371/160800 [00:11<00:03, 9866.06it/s]Processing HH:  79%|███████▉  | 127581/160800 [00:11<00:03, 10448.84it/s]Processing HH:  80%|████████  | 128803/160800 [00:11<00:02, 10927.58it/s]Processing HH:  81%|████████  | 130007/160800 [00:11<00:02, 11238.36it/s]Processing HH:  82%|████████▏ | 131235/160800 [00:11<00:02, 11533.08it/s]Processing HH:  82%|████████▏ | 132449/160800 [00:11<00:02, 11704.23it/s]Processing HH:  83%|████████▎ | 133700/160800 [00:11<00:02, 11939.62it/s]Processing HH:  84%|████████▍ | 134919/160800 [00:11<00:02, 12011.56it/s]Processing HH:  85%|████████▍ | 136135/160800 [00:11<00:02, 11985.95it/s]Processing HH:  85%|████████▌ | 137344/160800 [00:11<00:01, 11980.73it/s]Processing HH:  86%|████████▌ | 138564/160800 [00:12<00:01, 12044.90it/s]Processing HH:  87%|████████▋ | 139774/160800 [00:12<00:01, 12028.18it/s]Processing HH:  88%|████████▊ | 140981/160800 [00:12<00:01, 12004.73it/s]Processing HH:  88%|████████▊ | 142184/160800 [00:12<00:01, 11997.93it/s]Processing HH:  89%|████████▉ | 143417/160800 [00:12<00:01, 12096.49it/s]Processing HH:  90%|████████▉ | 144648/160800 [00:12<00:01, 12159.79it/s]Processing HH:  91%|█████████ | 145872/160800 [00:12<00:01, 12182.48it/s]Processing HH:  91%|█████████▏| 147091/160800 [00:12<00:01, 12159.34it/s]Processing HH:  92%|█████████▏| 148308/160800 [00:12<00:01, 12145.97it/s]Processing HH:  93%|█████████▎| 149523/160800 [00:12<00:00, 12069.02it/s]Processing HH:  94%|█████████▎| 150731/160800 [00:13<00:00, 11977.83it/s]Processing HH:  95%|█████████▍| 151965/160800 [00:13<00:00, 12084.64it/s]Processing HH:  95%|█████████▌| 153174/160800 [00:13<00:00, 12067.33it/s]Processing HH:  96%|█████████▌| 154393/160800 [00:13<00:00, 12101.95it/s]Processing HH:  97%|█████████▋| 155613/160800 [00:13<00:00, 12127.60it/s]Processing HH:  98%|█████████▊| 156834/160800 [00:13<00:00, 12151.55it/s]Processing HH:  98%|█████████▊| 158050/160800 [00:13<00:00, 12147.25it/s]Processing HH:  99%|█████████▉| 159277/160800 [00:13<00:00, 12181.71it/s]Processing HH: 100%|█████████▉| 160496/160800 [00:13<00:00, 12025.44it/s]Processing HH: 100%|██████████| 160800/160800 [00:13<00:00, 11544.00it/s]
Loading HH dataset (test split) from Huggingface...
Processing HH:   0%|          | 0/8552 [00:00<?, ?it/s]Processing HH:  17%|█▋        | 1444/8552 [00:00<00:00, 14431.38it/s]Processing HH:  34%|███▍      | 2888/8552 [00:00<00:00, 14286.86it/s]Processing HH:  50%|█████     | 4317/8552 [00:00<00:00, 14235.17it/s]Processing HH:  67%|██████▋   | 5741/8552 [00:00<00:00, 11837.33it/s]Processing HH:  82%|████████▏ | 6974/8552 [00:00<00:00, 11813.97it/s]Processing HH:  96%|█████████▌| 8187/8552 [00:01<00:00, 5401.70it/s] Processing HH: 100%|██████████| 8552/8552 [00:01<00:00, 7924.63it/s]
starting 4 processes for FSDP training
setting RLIMIT_NOFILE soft limit to 1048576 from 1024
4
0 initializing distributed
Creating trainer on process 0 with world size 4
Finished 512 examples on test split
Loaded 32 eval batches of size 16
Sharding models...
Attempting to enable activation checkpointing...
Applying activation checkpointing wrapper to policy...
FSDP activation checkpointing enabled!
Loaded model on rank 0
Using RMSprop optimizer with learning rate 1e-06
Running evaluation after 0 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]/home/wxt/.conda/envs/halos3/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/wxt/.conda/envs/halos3/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/wxt/.conda/envs/halos3/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/wxt/.conda/envs/halos3/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Computing eval metrics:   3%|▎         | 1/32 [00:02<01:11,  2.31s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:03,  2.12s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.87s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:41,  1.60s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:35,  1.44s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.51s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:34,  1.51s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:31,  1.44s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:31,  1.50s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:28,  1.45s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:26,  1.40s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:24,  1.39s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.25s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.20s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.28s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.29s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.24s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.19s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:29<00:13,  1.22s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.11s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.17s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:09,  1.25s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.22s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:07,  1.26s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:37<00:07,  1.43s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:38<00:05,  1.37s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.56s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:41<00:02,  1.38s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.37s/it]Computing eval metrics: 100%|██████████| 32/32 [00:44<00:00,  1.36s/it]Computing eval metrics: 100%|██████████| 32/32 [00:44<00:00,  1.39s/it]
eval after 0: {'rewards_eval/chosen': '0', 'rewards_eval/rejected': '0', 'rewards_eval/accuracies': '0', 'rewards_eval/margins': '0', 'logps_eval/rejected': '-122.16', 'logps_eval/chosen': '-118.49', 'loss/eval': '0.69141'}
skipping logging after 16 examples to avoid logging too frequently
skipping logging after 32 examples to avoid logging too frequently
skipping logging after 48 examples to avoid logging too frequently
train stats after 64 examples: {'rewards_train/chosen': '0', 'rewards_train/rejected': '0', 'rewards_train/accuracies': '0', 'rewards_train/margins': '0', 'logps_train/rejected': '-113.92', 'logps_train/chosen': '-118.07', 'loss/train': '0.69141', 'examples_per_second': '6.337', 'grad_norm': '17.75', 'counters/examples': 64, 'counters/updates': 4}
skipping logging after 80 examples to avoid logging too frequently
skipping logging after 96 examples to avoid logging too frequently
skipping logging after 112 examples to avoid logging too frequently
train stats after 128 examples: {'rewards_train/chosen': '0.0030303', 'rewards_train/rejected': '0.0063052', 'rewards_train/accuracies': '0.25', 'rewards_train/margins': '-0.0032802', 'logps_train/rejected': '-105.23', 'logps_train/chosen': '-137.44', 'loss/train': '0.6925', 'examples_per_second': '4.789', 'grad_norm': '18.5', 'counters/examples': 128, 'counters/updates': 8}
skipping logging after 144 examples to avoid logging too frequently
skipping logging after 160 examples to avoid logging too frequently
skipping logging after 176 examples to avoid logging too frequently
train stats after 192 examples: {'rewards_train/chosen': '-0.0037146', 'rewards_train/rejected': '-0.0030552', 'rewards_train/accuracies': '0.375', 'rewards_train/margins': '-0.00065982', 'logps_train/rejected': '-127.69', 'logps_train/chosen': '-124.94', 'loss/train': '0.69336', 'examples_per_second': '3.7236', 'grad_norm': '15.188', 'counters/examples': 192, 'counters/updates': 12}
skipping logging after 208 examples to avoid logging too frequently
skipping logging after 224 examples to avoid logging too frequently
skipping logging after 240 examples to avoid logging too frequently
train stats after 256 examples: {'rewards_train/chosen': '0.0029325', 'rewards_train/rejected': '0.010434', 'rewards_train/accuracies': '0.21875', 'rewards_train/margins': '-0.0075083', 'logps_train/rejected': '-107.49', 'logps_train/chosen': '-114.18', 'loss/train': '0.69373', 'examples_per_second': '6.0308', 'grad_norm': '16.75', 'counters/examples': 256, 'counters/updates': 16}
skipping logging after 272 examples to avoid logging too frequently
skipping logging after 288 examples to avoid logging too frequently
skipping logging after 304 examples to avoid logging too frequently
train stats after 320 examples: {'rewards_train/chosen': '0.001173', 'rewards_train/rejected': '0.0071828', 'rewards_train/accuracies': '0.25', 'rewards_train/margins': '-0.0060103', 'logps_train/rejected': '-126.62', 'logps_train/chosen': '-105.07', 'loss/train': '0.69476', 'examples_per_second': '5.2978', 'grad_norm': '15', 'counters/examples': 320, 'counters/updates': 20}
skipping logging after 336 examples to avoid logging too frequently
skipping logging after 352 examples to avoid logging too frequently
skipping logging after 368 examples to avoid logging too frequently
train stats after 384 examples: {'rewards_train/chosen': '0.0011241', 'rewards_train/rejected': '0.01212', 'rewards_train/accuracies': '0.3125', 'rewards_train/margins': '-0.010999', 'logps_train/rejected': '-120.21', 'logps_train/chosen': '-108.42', 'loss/train': '0.6969', 'examples_per_second': '6.3324', 'grad_norm': '14.812', 'counters/examples': 384, 'counters/updates': 24}
skipping logging after 400 examples to avoid logging too frequently
skipping logging after 416 examples to avoid logging too frequently
skipping logging after 432 examples to avoid logging too frequently
train stats after 448 examples: {'rewards_train/chosen': '0.00068426', 'rewards_train/rejected': '0.011264', 'rewards_train/accuracies': '0.28125', 'rewards_train/margins': '-0.010575', 'logps_train/rejected': '-93.964', 'logps_train/chosen': '-83.201', 'loss/train': '0.6972', 'examples_per_second': '5.4319', 'grad_norm': '13.812', 'counters/examples': 448, 'counters/updates': 28}
skipping logging after 464 examples to avoid logging too frequently
skipping logging after 480 examples to avoid logging too frequently
skipping logging after 496 examples to avoid logging too frequently
train stats after 512 examples: {'rewards_train/chosen': '-0.0066001', 'rewards_train/rejected': '0.0031047', 'rewards_train/accuracies': '0.34375', 'rewards_train/margins': '-0.0096979', 'logps_train/rejected': '-93.092', 'logps_train/chosen': '-96.663', 'loss/train': '0.69885', 'examples_per_second': '5.8347', 'grad_norm': '13.938', 'counters/examples': 512, 'counters/updates': 32}
skipping logging after 528 examples to avoid logging too frequently
skipping logging after 544 examples to avoid logging too frequently
skipping logging after 560 examples to avoid logging too frequently
train stats after 576 examples: {'rewards_train/chosen': '0.0026383', 'rewards_train/rejected': '-0.0030792', 'rewards_train/accuracies': '0.32812', 'rewards_train/margins': '0.0057118', 'logps_train/rejected': '-100.79', 'logps_train/chosen': '-121.45', 'loss/train': '0.69116', 'examples_per_second': '4.9519', 'grad_norm': '14.5', 'counters/examples': 576, 'counters/updates': 36}
skipping logging after 592 examples to avoid logging too frequently
skipping logging after 608 examples to avoid logging too frequently
skipping logging after 624 examples to avoid logging too frequently
train stats after 640 examples: {'rewards_train/chosen': '0.00041735', 'rewards_train/rejected': '-0.0045699', 'rewards_train/accuracies': '0.39062', 'rewards_train/margins': '0.0049863', 'logps_train/rejected': '-115.56', 'logps_train/chosen': '-107.12', 'loss/train': '0.69049', 'examples_per_second': '4.7393', 'grad_norm': '20.5', 'counters/examples': 640, 'counters/updates': 40}
skipping logging after 656 examples to avoid logging too frequently
skipping logging after 672 examples to avoid logging too frequently
skipping logging after 688 examples to avoid logging too frequently
train stats after 704 examples: {'rewards_train/chosen': '-0.0048895', 'rewards_train/rejected': '-0.0016618', 'rewards_train/accuracies': '0.26562', 'rewards_train/margins': '-0.0032258', 'logps_train/rejected': '-120.23', 'logps_train/chosen': '-137.77', 'loss/train': '0.69257', 'examples_per_second': '4.9682', 'grad_norm': '17.375', 'counters/examples': 704, 'counters/updates': 44}
skipping logging after 720 examples to avoid logging too frequently
skipping logging after 736 examples to avoid logging too frequently
skipping logging after 752 examples to avoid logging too frequently
train stats after 768 examples: {'rewards_train/chosen': '-0.0080764', 'rewards_train/rejected': '-0.0059018', 'rewards_train/accuracies': '0.375', 'rewards_train/margins': '-0.0021708', 'logps_train/rejected': '-98.589', 'logps_train/chosen': '-125.69', 'loss/train': '0.69556', 'examples_per_second': '5.3978', 'grad_norm': '14.188', 'counters/examples': 768, 'counters/updates': 48}
skipping logging after 784 examples to avoid logging too frequently
skipping logging after 800 examples to avoid logging too frequently
skipping logging after 816 examples to avoid logging too frequently
train stats after 832 examples: {'rewards_train/chosen': '-0.0017729', 'rewards_train/rejected': '-0.010618', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.0088382', 'logps_train/rejected': '-93.917', 'logps_train/chosen': '-118.35', 'loss/train': '0.68982', 'examples_per_second': '6.4917', 'grad_norm': '20.625', 'counters/examples': 832, 'counters/updates': 52}
skipping logging after 848 examples to avoid logging too frequently
skipping logging after 864 examples to avoid logging too frequently
skipping logging after 880 examples to avoid logging too frequently
train stats after 896 examples: {'rewards_train/chosen': '0.0049851', 'rewards_train/rejected': '0.0085537', 'rewards_train/accuracies': '0.375', 'rewards_train/margins': '-0.0035765', 'logps_train/rejected': '-109.94', 'logps_train/chosen': '-104.41', 'loss/train': '0.69476', 'examples_per_second': '3.704', 'grad_norm': '14.875', 'counters/examples': 896, 'counters/updates': 56}
skipping logging after 912 examples to avoid logging too frequently
skipping logging after 928 examples to avoid logging too frequently
skipping logging after 944 examples to avoid logging too frequently
train stats after 960 examples: {'rewards_train/chosen': '0.0062068', 'rewards_train/rejected': '0.0031271', 'rewards_train/accuracies': '0.34375', 'rewards_train/margins': '0.0030847', 'logps_train/rejected': '-124.66', 'logps_train/chosen': '-114.88', 'loss/train': '0.69159', 'examples_per_second': '5.8515', 'grad_norm': '16', 'counters/examples': 960, 'counters/updates': 60}
skipping logging after 976 examples to avoid logging too frequently
skipping logging after 992 examples to avoid logging too frequently
Running evaluation after 992 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:11,  2.29s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:04,  2.15s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:55,  1.90s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.89s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.54s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.25s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.29s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 992: {'rewards_eval/chosen': '0.0029569', 'rewards_eval/rejected': '0.00064582', 'rewards_eval/accuracies': '0.31641', 'rewards_eval/margins': '0.0023133', 'logps_eval/rejected': '-122.15', 'logps_eval/chosen': '-118.47', 'loss/eval': '0.69234'}
skipping logging after 1008 examples to avoid logging too frequently
train stats after 1024 examples: {'rewards_train/chosen': '0.0083337', 'rewards_train/rejected': '-0.0067697', 'rewards_train/accuracies': '0.35938', 'rewards_train/margins': '0.01512', 'logps_train/rejected': '-98.946', 'logps_train/chosen': '-119.14', 'loss/train': '0.68762', 'examples_per_second': '4.9399', 'grad_norm': '14.938', 'counters/examples': 1024, 'counters/updates': 64}
skipping logging after 1040 examples to avoid logging too frequently
skipping logging after 1056 examples to avoid logging too frequently
skipping logging after 1072 examples to avoid logging too frequently
train stats after 1088 examples: {'rewards_train/chosen': '-0.0073791', 'rewards_train/rejected': '-0.0089447', 'rewards_train/accuracies': '0.375', 'rewards_train/margins': '0.0015659', 'logps_train/rejected': '-94.035', 'logps_train/chosen': '-105.47', 'loss/train': '0.69336', 'examples_per_second': '5.9497', 'grad_norm': '12.875', 'counters/examples': 1088, 'counters/updates': 68}
skipping logging after 1104 examples to avoid logging too frequently
skipping logging after 1120 examples to avoid logging too frequently
skipping logging after 1136 examples to avoid logging too frequently
train stats after 1152 examples: {'rewards_train/chosen': '-0.01393', 'rewards_train/rejected': '-0.0066349', 'rewards_train/accuracies': '0.34375', 'rewards_train/margins': '-0.0072954', 'logps_train/rejected': '-99.616', 'logps_train/chosen': '-111.97', 'loss/train': '0.69629', 'examples_per_second': '5.935', 'grad_norm': '15.375', 'counters/examples': 1152, 'counters/updates': 72}
skipping logging after 1168 examples to avoid logging too frequently
skipping logging after 1184 examples to avoid logging too frequently
skipping logging after 1200 examples to avoid logging too frequently
train stats after 1216 examples: {'rewards_train/chosen': '0.0032248', 'rewards_train/rejected': '-0.0003171', 'rewards_train/accuracies': '0.34375', 'rewards_train/margins': '0.0035439', 'logps_train/rejected': '-116.17', 'logps_train/chosen': '-115.53', 'loss/train': '0.69299', 'examples_per_second': '4.5077', 'grad_norm': '14.312', 'counters/examples': 1216, 'counters/updates': 76}
skipping logging after 1232 examples to avoid logging too frequently
skipping logging after 1248 examples to avoid logging too frequently
skipping logging after 1264 examples to avoid logging too frequently
train stats after 1280 examples: {'rewards_train/chosen': '0.002346', 'rewards_train/rejected': '9.7752e-05', 'rewards_train/accuracies': '0.40625', 'rewards_train/margins': '0.0022507', 'logps_train/rejected': '-124.08', 'logps_train/chosen': '-125.76', 'loss/train': '0.69257', 'examples_per_second': '4.4662', 'grad_norm': '16.75', 'counters/examples': 1280, 'counters/updates': 80}
skipping logging after 1296 examples to avoid logging too frequently
skipping logging after 1312 examples to avoid logging too frequently
skipping logging after 1328 examples to avoid logging too frequently
train stats after 1344 examples: {'rewards_train/chosen': '0.0045948', 'rewards_train/rejected': '-0.0050097', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '0.009613', 'logps_train/rejected': '-116.64', 'logps_train/chosen': '-113.66', 'loss/train': '0.68695', 'examples_per_second': '6.0719', 'grad_norm': '14.188', 'counters/examples': 1344, 'counters/updates': 84}
skipping logging after 1360 examples to avoid logging too frequently
skipping logging after 1376 examples to avoid logging too frequently
skipping logging after 1392 examples to avoid logging too frequently
train stats after 1408 examples: {'rewards_train/chosen': '0.0013695', 'rewards_train/rejected': '-0.0010021', 'rewards_train/accuracies': '0.39062', 'rewards_train/margins': '0.0023646', 'logps_train/rejected': '-133.06', 'logps_train/chosen': '-108.07', 'loss/train': '0.6922', 'examples_per_second': '4.6135', 'grad_norm': '16.375', 'counters/examples': 1408, 'counters/updates': 88}
skipping logging after 1424 examples to avoid logging too frequently
skipping logging after 1440 examples to avoid logging too frequently
skipping logging after 1456 examples to avoid logging too frequently
train stats after 1472 examples: {'rewards_train/chosen': '-0.0056217', 'rewards_train/rejected': '-0.007329', 'rewards_train/accuracies': '0.32812', 'rewards_train/margins': '0.0017142', 'logps_train/rejected': '-112.06', 'logps_train/chosen': '-104.27', 'loss/train': '0.69373', 'examples_per_second': '3.9274', 'grad_norm': '16.375', 'counters/examples': 1472, 'counters/updates': 92}
skipping logging after 1488 examples to avoid logging too frequently
skipping logging after 1504 examples to avoid logging too frequently
skipping logging after 1520 examples to avoid logging too frequently
train stats after 1536 examples: {'rewards_train/chosen': '0.0010539', 'rewards_train/rejected': '0.0075772', 'rewards_train/accuracies': '0.39062', 'rewards_train/margins': '-0.0065178', 'logps_train/rejected': '-124.57', 'logps_train/chosen': '-108.41', 'loss/train': '0.69769', 'examples_per_second': '4.9181', 'grad_norm': '16.875', 'counters/examples': 1536, 'counters/updates': 96}
skipping logging after 1552 examples to avoid logging too frequently
skipping logging after 1568 examples to avoid logging too frequently
skipping logging after 1584 examples to avoid logging too frequently
train stats after 1600 examples: {'rewards_train/chosen': '0.0010508', 'rewards_train/rejected': '0.00014615', 'rewards_train/accuracies': '0.35938', 'rewards_train/margins': '0.00089955', 'logps_train/rejected': '-111.48', 'logps_train/chosen': '-113.44', 'loss/train': '0.69275', 'examples_per_second': '5.433', 'grad_norm': '14.562', 'counters/examples': 1600, 'counters/updates': 100}
skipping logging after 1616 examples to avoid logging too frequently
skipping logging after 1632 examples to avoid logging too frequently
skipping logging after 1648 examples to avoid logging too frequently
train stats after 1664 examples: {'rewards_train/chosen': '-0.0025911', 'rewards_train/rejected': '-0.0020533', 'rewards_train/accuracies': '0.34375', 'rewards_train/margins': '-0.00052524', 'logps_train/rejected': '-131.69', 'logps_train/chosen': '-133.85', 'loss/train': '0.69373', 'examples_per_second': '5.7409', 'grad_norm': '17.5', 'counters/examples': 1664, 'counters/updates': 104}
skipping logging after 1680 examples to avoid logging too frequently
skipping logging after 1696 examples to avoid logging too frequently
skipping logging after 1712 examples to avoid logging too frequently
train stats after 1728 examples: {'rewards_train/chosen': '0.0036168', 'rewards_train/rejected': '-0.0072825', 'rewards_train/accuracies': '0.40625', 'rewards_train/margins': '0.010898', 'logps_train/rejected': '-137.72', 'logps_train/chosen': '-125.1', 'loss/train': '0.68481', 'examples_per_second': '6.6066', 'grad_norm': '16.625', 'counters/examples': 1728, 'counters/updates': 108}
skipping logging after 1744 examples to avoid logging too frequently
skipping logging after 1760 examples to avoid logging too frequently
skipping logging after 1776 examples to avoid logging too frequently
train stats after 1792 examples: {'rewards_train/chosen': '-0.0031648', 'rewards_train/rejected': '-0.0048263', 'rewards_train/accuracies': '0.42188', 'rewards_train/margins': '0.0016589', 'logps_train/rejected': '-110.3', 'logps_train/chosen': '-100.09', 'loss/train': '0.69196', 'examples_per_second': '4.3772', 'grad_norm': '15.562', 'counters/examples': 1792, 'counters/updates': 112}
skipping logging after 1808 examples to avoid logging too frequently
skipping logging after 1824 examples to avoid logging too frequently
skipping logging after 1840 examples to avoid logging too frequently
train stats after 1856 examples: {'rewards_train/chosen': '0.0093846', 'rewards_train/rejected': '-0.0068917', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.016281', 'logps_train/rejected': '-87.361', 'logps_train/chosen': '-118.94', 'loss/train': '0.68359', 'examples_per_second': '4.9683', 'grad_norm': '13.688', 'counters/examples': 1856, 'counters/updates': 116}
skipping logging after 1872 examples to avoid logging too frequently
skipping logging after 1888 examples to avoid logging too frequently
skipping logging after 1904 examples to avoid logging too frequently
train stats after 1920 examples: {'rewards_train/chosen': '-0.0046935', 'rewards_train/rejected': '-0.00066304', 'rewards_train/accuracies': '0.35938', 'rewards_train/margins': '-0.0040152', 'logps_train/rejected': '-89.592', 'logps_train/chosen': '-97.276', 'loss/train': '0.69574', 'examples_per_second': '5.0101', 'grad_norm': '13.812', 'counters/examples': 1920, 'counters/updates': 120}
skipping logging after 1936 examples to avoid logging too frequently
skipping logging after 1952 examples to avoid logging too frequently
skipping logging after 1968 examples to avoid logging too frequently
train stats after 1984 examples: {'rewards_train/chosen': '-0.0022244', 'rewards_train/rejected': '-0.01393', 'rewards_train/accuracies': '0.375', 'rewards_train/margins': '0.01171', 'logps_train/rejected': '-131.32', 'logps_train/chosen': '-122.31', 'loss/train': '0.68744', 'examples_per_second': '5.056', 'grad_norm': '16.25', 'counters/examples': 1984, 'counters/updates': 124}
Running evaluation after 1984 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.53s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.42s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 1984: {'rewards_eval/chosen': '0.0002001', 'rewards_eval/rejected': '0.0034221', 'rewards_eval/accuracies': '0.36523', 'rewards_eval/margins': '-0.0032223', 'logps_eval/rejected': '-122.12', 'logps_eval/chosen': '-118.49', 'loss/eval': '0.69446'}
skipping logging after 2000 examples to avoid logging too frequently
skipping logging after 2016 examples to avoid logging too frequently
skipping logging after 2032 examples to avoid logging too frequently
train stats after 2048 examples: {'rewards_train/chosen': '0.0066981', 'rewards_train/rejected': '0.0058904', 'rewards_train/accuracies': '0.32812', 'rewards_train/margins': '0.00079656', 'logps_train/rejected': '-107.15', 'logps_train/chosen': '-115.8', 'loss/train': '0.69128', 'examples_per_second': '5.0762', 'grad_norm': '14.438', 'counters/examples': 2048, 'counters/updates': 128}
skipping logging after 2064 examples to avoid logging too frequently
skipping logging after 2080 examples to avoid logging too frequently
skipping logging after 2096 examples to avoid logging too frequently
train stats after 2112 examples: {'rewards_train/chosen': '0.0047894', 'rewards_train/rejected': '-0.003422', 'rewards_train/accuracies': '0.42188', 'rewards_train/margins': '0.0082121', 'logps_train/rejected': '-107.35', 'logps_train/chosen': '-133.59', 'loss/train': '0.68878', 'examples_per_second': '5.1373', 'grad_norm': '15.812', 'counters/examples': 2112, 'counters/updates': 132}
skipping logging after 2128 examples to avoid logging too frequently
skipping logging after 2144 examples to avoid logging too frequently
skipping logging after 2160 examples to avoid logging too frequently
train stats after 2176 examples: {'rewards_train/chosen': '0.0032029', 'rewards_train/rejected': '-0.0016861', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '0.0048881', 'logps_train/rejected': '-96.46', 'logps_train/chosen': '-92.964', 'loss/train': '0.69171', 'examples_per_second': '5.9144', 'grad_norm': '14.438', 'counters/examples': 2176, 'counters/updates': 136}
skipping logging after 2192 examples to avoid logging too frequently
skipping logging after 2208 examples to avoid logging too frequently
skipping logging after 2224 examples to avoid logging too frequently
train stats after 2240 examples: {'rewards_train/chosen': '-0.0058651', 'rewards_train/rejected': '-0.0011249', 'rewards_train/accuracies': '0.34375', 'rewards_train/margins': '-0.004735', 'logps_train/rejected': '-106.27', 'logps_train/chosen': '-121.11', 'loss/train': '0.69684', 'examples_per_second': '6.0271', 'grad_norm': '16.25', 'counters/examples': 2240, 'counters/updates': 140}
skipping logging after 2256 examples to avoid logging too frequently
skipping logging after 2272 examples to avoid logging too frequently
skipping logging after 2288 examples to avoid logging too frequently
train stats after 2304 examples: {'rewards_train/chosen': '0.0089436', 'rewards_train/rejected': '-0.001272', 'rewards_train/accuracies': '0.40625', 'rewards_train/margins': '0.010231', 'logps_train/rejected': '-127.67', 'logps_train/chosen': '-121.59', 'loss/train': '0.68787', 'examples_per_second': '4.4365', 'grad_norm': '15.5', 'counters/examples': 2304, 'counters/updates': 144}
skipping logging after 2320 examples to avoid logging too frequently
skipping logging after 2336 examples to avoid logging too frequently
skipping logging after 2352 examples to avoid logging too frequently
train stats after 2368 examples: {'rewards_train/chosen': '-0.001761', 'rewards_train/rejected': '-0.00083089', 'rewards_train/accuracies': '0.35938', 'rewards_train/margins': '-0.00092888', 'logps_train/rejected': '-94.589', 'logps_train/chosen': '-106.87', 'loss/train': '0.69495', 'examples_per_second': '5.7071', 'grad_norm': '13.25', 'counters/examples': 2368, 'counters/updates': 148}
skipping logging after 2384 examples to avoid logging too frequently
skipping logging after 2400 examples to avoid logging too frequently
skipping logging after 2416 examples to avoid logging too frequently
train stats after 2432 examples: {'rewards_train/chosen': '-0.0061591', 'rewards_train/rejected': '0.0025897', 'rewards_train/accuracies': '0.375', 'rewards_train/margins': '-0.008745', 'logps_train/rejected': '-106.92', 'logps_train/chosen': '-116.18', 'loss/train': '0.69824', 'examples_per_second': '5.4375', 'grad_norm': '16', 'counters/examples': 2432, 'counters/updates': 152}
skipping logging after 2448 examples to avoid logging too frequently
skipping logging after 2464 examples to avoid logging too frequently
skipping logging after 2480 examples to avoid logging too frequently
train stats after 2496 examples: {'rewards_train/chosen': '0.0094352', 'rewards_train/rejected': '-0.00352', 'rewards_train/accuracies': '0.42188', 'rewards_train/margins': '0.012968', 'logps_train/rejected': '-117.84', 'logps_train/chosen': '-114.77', 'loss/train': '0.68665', 'examples_per_second': '6.8997', 'grad_norm': '15.938', 'counters/examples': 2496, 'counters/updates': 156}
skipping logging after 2512 examples to avoid logging too frequently
skipping logging after 2528 examples to avoid logging too frequently
skipping logging after 2544 examples to avoid logging too frequently
train stats after 2560 examples: {'rewards_train/chosen': '0.0010976', 'rewards_train/rejected': '0.0059104', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '-0.0048248', 'logps_train/rejected': '-126.78', 'logps_train/chosen': '-114.43', 'loss/train': '0.69849', 'examples_per_second': '4.8915', 'grad_norm': '16.625', 'counters/examples': 2560, 'counters/updates': 160}
skipping logging after 2576 examples to avoid logging too frequently
skipping logging after 2592 examples to avoid logging too frequently
skipping logging after 2608 examples to avoid logging too frequently
train stats after 2624 examples: {'rewards_train/chosen': '-0.001076', 'rewards_train/rejected': '-0.011143', 'rewards_train/accuracies': '0.42188', 'rewards_train/margins': '0.010069', 'logps_train/rejected': '-118.69', 'logps_train/chosen': '-122.9', 'loss/train': '0.68866', 'examples_per_second': '4.5477', 'grad_norm': '15.375', 'counters/examples': 2624, 'counters/updates': 164}
skipping logging after 2640 examples to avoid logging too frequently
skipping logging after 2656 examples to avoid logging too frequently
skipping logging after 2672 examples to avoid logging too frequently
train stats after 2688 examples: {'rewards_train/chosen': '0.0021274', 'rewards_train/rejected': '-0.0025637', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '0.0047054', 'logps_train/rejected': '-95.954', 'logps_train/chosen': '-110.8', 'loss/train': '0.69025', 'examples_per_second': '5.6757', 'grad_norm': '14.375', 'counters/examples': 2688, 'counters/updates': 168}
skipping logging after 2704 examples to avoid logging too frequently
skipping logging after 2720 examples to avoid logging too frequently
skipping logging after 2736 examples to avoid logging too frequently
train stats after 2752 examples: {'rewards_train/chosen': '0.0017842', 'rewards_train/rejected': '-0.0046178', 'rewards_train/accuracies': '0.39062', 'rewards_train/margins': '0.0064192', 'logps_train/rejected': '-86.451', 'logps_train/chosen': '-80.856', 'loss/train': '0.69214', 'examples_per_second': '5.6018', 'grad_norm': '14.375', 'counters/examples': 2752, 'counters/updates': 172}
skipping logging after 2768 examples to avoid logging too frequently
skipping logging after 2784 examples to avoid logging too frequently
skipping logging after 2800 examples to avoid logging too frequently
train stats after 2816 examples: {'rewards_train/chosen': '-0.0075753', 'rewards_train/rejected': '0.0040894', 'rewards_train/accuracies': '0.35938', 'rewards_train/margins': '-0.011665', 'logps_train/rejected': '-104.47', 'logps_train/chosen': '-94.637', 'loss/train': '0.70062', 'examples_per_second': '5.6167', 'grad_norm': '13.312', 'counters/examples': 2816, 'counters/updates': 176}
skipping logging after 2832 examples to avoid logging too frequently
skipping logging after 2848 examples to avoid logging too frequently
skipping logging after 2864 examples to avoid logging too frequently
train stats after 2880 examples: {'rewards_train/chosen': '-0.0071363', 'rewards_train/rejected': '-0.0002954', 'rewards_train/accuracies': '0.3125', 'rewards_train/margins': '-0.006845', 'logps_train/rejected': '-100.66', 'logps_train/chosen': '-115.78', 'loss/train': '0.69702', 'examples_per_second': '5.0353', 'grad_norm': '15.625', 'counters/examples': 2880, 'counters/updates': 180}
skipping logging after 2896 examples to avoid logging too frequently
skipping logging after 2912 examples to avoid logging too frequently
skipping logging after 2928 examples to avoid logging too frequently
train stats after 2944 examples: {'rewards_train/chosen': '-0.012806', 'rewards_train/rejected': '-0.012316', 'rewards_train/accuracies': '0.35938', 'rewards_train/margins': '-0.0004878', 'logps_train/rejected': '-107.04', 'logps_train/chosen': '-99.789', 'loss/train': '0.69287', 'examples_per_second': '5.8726', 'grad_norm': '15', 'counters/examples': 2944, 'counters/updates': 184}
skipping logging after 2960 examples to avoid logging too frequently
skipping logging after 2976 examples to avoid logging too frequently
Running evaluation after 2976 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:16,  2.47s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:06,  2.21s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:56,  1.94s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.90s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.55s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.65s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 2976: {'rewards_eval/chosen': '-0.0012404', 'rewards_eval/rejected': '-0.0012867', 'rewards_eval/accuracies': '0.41016', 'rewards_eval/margins': '3.8132e-05', 'logps_eval/rejected': '-122.17', 'logps_eval/chosen': '-118.51', 'loss/eval': '0.69395'}
skipping logging after 2992 examples to avoid logging too frequently
train stats after 3008 examples: {'rewards_train/chosen': '-0.0065494', 'rewards_train/rejected': '0.00097394', 'rewards_train/accuracies': '0.34375', 'rewards_train/margins': '-0.0075254', 'logps_train/rejected': '-89.838', 'logps_train/chosen': '-93.257', 'loss/train': '0.69653', 'examples_per_second': '4.9384', 'grad_norm': '12.375', 'counters/examples': 3008, 'counters/updates': 188}
skipping logging after 3024 examples to avoid logging too frequently
skipping logging after 3040 examples to avoid logging too frequently
skipping logging after 3056 examples to avoid logging too frequently
train stats after 3072 examples: {'rewards_train/chosen': '-0.0015621', 'rewards_train/rejected': '-0.013539', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.011994', 'logps_train/rejected': '-141.56', 'logps_train/chosen': '-135.72', 'loss/train': '0.68518', 'examples_per_second': '5.2035', 'grad_norm': '18.5', 'counters/examples': 3072, 'counters/updates': 192}
skipping logging after 3088 examples to avoid logging too frequently
skipping logging after 3104 examples to avoid logging too frequently
skipping logging after 3120 examples to avoid logging too frequently
train stats after 3136 examples: {'rewards_train/chosen': '0.0022696', 'rewards_train/rejected': '-0.0069795', 'rewards_train/accuracies': '0.35938', 'rewards_train/margins': '0.0092638', 'logps_train/rejected': '-128.17', 'logps_train/chosen': '-135.87', 'loss/train': '0.69159', 'examples_per_second': '5.2063', 'grad_norm': '18', 'counters/examples': 3136, 'counters/updates': 196}
skipping logging after 3152 examples to avoid logging too frequently
skipping logging after 3168 examples to avoid logging too frequently
skipping logging after 3184 examples to avoid logging too frequently
train stats after 3200 examples: {'rewards_train/chosen': '-0.0085044', 'rewards_train/rejected': '-0.0004158', 'rewards_train/accuracies': '0.34375', 'rewards_train/margins': '-0.00809', 'logps_train/rejected': '-150.88', 'logps_train/chosen': '-126.32', 'loss/train': '0.6955', 'examples_per_second': '4.7164', 'grad_norm': '17.625', 'counters/examples': 3200, 'counters/updates': 200}
skipping logging after 3216 examples to avoid logging too frequently
skipping logging after 3232 examples to avoid logging too frequently
skipping logging after 3248 examples to avoid logging too frequently
train stats after 3264 examples: {'rewards_train/chosen': '-0.0061816', 'rewards_train/rejected': '-0.0097256', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.0035439', 'logps_train/rejected': '-105.82', 'logps_train/chosen': '-127.18', 'loss/train': '0.68994', 'examples_per_second': '5.6647', 'grad_norm': '15.25', 'counters/examples': 3264, 'counters/updates': 204}
skipping logging after 3280 examples to avoid logging too frequently
skipping logging after 3296 examples to avoid logging too frequently
skipping logging after 3312 examples to avoid logging too frequently
train stats after 3328 examples: {'rewards_train/chosen': '-0.0014906', 'rewards_train/rejected': '-0.010753', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '0.0092602', 'logps_train/rejected': '-144.99', 'logps_train/chosen': '-105.28', 'loss/train': '0.68787', 'examples_per_second': '5.2568', 'grad_norm': '14.5', 'counters/examples': 3328, 'counters/updates': 208}
skipping logging after 3344 examples to avoid logging too frequently
skipping logging after 3360 examples to avoid logging too frequently
skipping logging after 3376 examples to avoid logging too frequently
train stats after 3392 examples: {'rewards_train/chosen': '-0.0034952', 'rewards_train/rejected': '-0.01149', 'rewards_train/accuracies': '0.42188', 'rewards_train/margins': '0.0080013', 'logps_train/rejected': '-114.42', 'logps_train/chosen': '-132.38', 'loss/train': '0.68964', 'examples_per_second': '4.9734', 'grad_norm': '14.125', 'counters/examples': 3392, 'counters/updates': 212}
skipping logging after 3408 examples to avoid logging too frequently
skipping logging after 3424 examples to avoid logging too frequently
skipping logging after 3440 examples to avoid logging too frequently
train stats after 3456 examples: {'rewards_train/chosen': '-0.0074277', 'rewards_train/rejected': '-0.0074787', 'rewards_train/accuracies': '0.34375', 'rewards_train/margins': '4.4346e-05', 'logps_train/rejected': '-103.53', 'logps_train/chosen': '-96.13', 'loss/train': '0.69159', 'examples_per_second': '4.8268', 'grad_norm': '16.75', 'counters/examples': 3456, 'counters/updates': 216}
skipping logging after 3472 examples to avoid logging too frequently
skipping logging after 3488 examples to avoid logging too frequently
skipping logging after 3504 examples to avoid logging too frequently
train stats after 3520 examples: {'rewards_train/chosen': '-0.014275', 'rewards_train/rejected': '-0.010166', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '-0.0041018', 'logps_train/rejected': '-120.53', 'logps_train/chosen': '-112.41', 'loss/train': '0.69672', 'examples_per_second': '5.4351', 'grad_norm': '15.312', 'counters/examples': 3520, 'counters/updates': 220}
skipping logging after 3536 examples to avoid logging too frequently
skipping logging after 3552 examples to avoid logging too frequently
skipping logging after 3568 examples to avoid logging too frequently
train stats after 3584 examples: {'rewards_train/chosen': '-0.0041504', 'rewards_train/rejected': '-0.014024', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '0.0098906', 'logps_train/rejected': '-133.76', 'logps_train/chosen': '-118.18', 'loss/train': '0.6864', 'examples_per_second': '4.6803', 'grad_norm': '17.625', 'counters/examples': 3584, 'counters/updates': 224}
skipping logging after 3600 examples to avoid logging too frequently
skipping logging after 3616 examples to avoid logging too frequently
skipping logging after 3632 examples to avoid logging too frequently
train stats after 3648 examples: {'rewards_train/chosen': '-0.013294', 'rewards_train/rejected': '-0.0096238', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '-0.0036762', 'logps_train/rejected': '-100.86', 'logps_train/chosen': '-135.71', 'loss/train': '0.69275', 'examples_per_second': '6.3633', 'grad_norm': '16.75', 'counters/examples': 3648, 'counters/updates': 228}
skipping logging after 3664 examples to avoid logging too frequently
skipping logging after 3680 examples to avoid logging too frequently
skipping logging after 3696 examples to avoid logging too frequently
train stats after 3712 examples: {'rewards_train/chosen': '0.0026379', 'rewards_train/rejected': '-0.0010767', 'rewards_train/accuracies': '0.375', 'rewards_train/margins': '0.003706', 'logps_train/rejected': '-104.15', 'logps_train/chosen': '-119.25', 'loss/train': '0.69104', 'examples_per_second': '5.2735', 'grad_norm': '14.5', 'counters/examples': 3712, 'counters/updates': 232}
skipping logging after 3728 examples to avoid logging too frequently
skipping logging after 3744 examples to avoid logging too frequently
skipping logging after 3760 examples to avoid logging too frequently
train stats after 3776 examples: {'rewards_train/chosen': '-0.004982', 'rewards_train/rejected': '-0.0062323', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.0012417', 'logps_train/rejected': '-117.54', 'logps_train/chosen': '-114.97', 'loss/train': '0.69025', 'examples_per_second': '4.9107', 'grad_norm': '14.875', 'counters/examples': 3776, 'counters/updates': 236}
skipping logging after 3792 examples to avoid logging too frequently
skipping logging after 3808 examples to avoid logging too frequently
skipping logging after 3824 examples to avoid logging too frequently
train stats after 3840 examples: {'rewards_train/chosen': '-0.012325', 'rewards_train/rejected': '-0.0056186', 'rewards_train/accuracies': '0.35938', 'rewards_train/margins': '-0.0067253', 'logps_train/rejected': '-102.94', 'logps_train/chosen': '-117.72', 'loss/train': '0.69788', 'examples_per_second': '5.5757', 'grad_norm': '15.312', 'counters/examples': 3840, 'counters/updates': 240}
skipping logging after 3856 examples to avoid logging too frequently
skipping logging after 3872 examples to avoid logging too frequently
skipping logging after 3888 examples to avoid logging too frequently
train stats after 3904 examples: {'rewards_train/chosen': '0.012684', 'rewards_train/rejected': '-0.015133', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.027836', 'logps_train/rejected': '-109.18', 'logps_train/chosen': '-128.7', 'loss/train': '0.68073', 'examples_per_second': '5.8488', 'grad_norm': '17.875', 'counters/examples': 3904, 'counters/updates': 244}
skipping logging after 3920 examples to avoid logging too frequently
skipping logging after 3936 examples to avoid logging too frequently
skipping logging after 3952 examples to avoid logging too frequently
train stats after 3968 examples: {'rewards_train/chosen': '-0.0077991', 'rewards_train/rejected': '0.0017773', 'rewards_train/accuracies': '0.35938', 'rewards_train/margins': '-0.0095794', 'logps_train/rejected': '-108', 'logps_train/chosen': '-108.98', 'loss/train': '0.69897', 'examples_per_second': '4.6404', 'grad_norm': '15.438', 'counters/examples': 3968, 'counters/updates': 248}
Running evaluation after 3968 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.81s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.53s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.46s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.53s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.42s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 3968: {'rewards_eval/chosen': '-0.0053606', 'rewards_eval/rejected': '-0.0064028', 'rewards_eval/accuracies': '0.41406', 'rewards_eval/margins': '0.0010417', 'logps_eval/rejected': '-122.22', 'logps_eval/chosen': '-118.55', 'loss/eval': '0.69308'}
skipping logging after 3984 examples to avoid logging too frequently
skipping logging after 4000 examples to avoid logging too frequently
skipping logging after 4016 examples to avoid logging too frequently
train stats after 4032 examples: {'rewards_train/chosen': '-0.00063086', 'rewards_train/rejected': '-0.0010767', 'rewards_train/accuracies': '0.35938', 'rewards_train/margins': '0.00044918', 'logps_train/rejected': '-114.9', 'logps_train/chosen': '-128.45', 'loss/train': '0.69128', 'examples_per_second': '4.5969', 'grad_norm': '14.688', 'counters/examples': 4032, 'counters/updates': 252}
skipping logging after 4048 examples to avoid logging too frequently
skipping logging after 4064 examples to avoid logging too frequently
skipping logging after 4080 examples to avoid logging too frequently
train stats after 4096 examples: {'rewards_train/chosen': '0.006373', 'rewards_train/rejected': '-0.00026786', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.0066481', 'logps_train/rejected': '-113.25', 'logps_train/chosen': '-98.5', 'loss/train': '0.68896', 'examples_per_second': '4.5611', 'grad_norm': '15.562', 'counters/examples': 4096, 'counters/updates': 256}
skipping logging after 4112 examples to avoid logging too frequently
skipping logging after 4128 examples to avoid logging too frequently
skipping logging after 4144 examples to avoid logging too frequently
train stats after 4160 examples: {'rewards_train/chosen': '-0.0031371', 'rewards_train/rejected': '-0.0036451', 'rewards_train/accuracies': '0.42188', 'rewards_train/margins': '0.00051117', 'logps_train/rejected': '-110.32', 'logps_train/chosen': '-116.44', 'loss/train': '0.6944', 'examples_per_second': '5.1141', 'grad_norm': '14.375', 'counters/examples': 4160, 'counters/updates': 260}
skipping logging after 4176 examples to avoid logging too frequently
skipping logging after 4192 examples to avoid logging too frequently
skipping logging after 4208 examples to avoid logging too frequently
train stats after 4224 examples: {'rewards_train/chosen': '-0.0089173', 'rewards_train/rejected': '-0.024035', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.015122', 'logps_train/rejected': '-106.03', 'logps_train/chosen': '-112.66', 'loss/train': '0.68439', 'examples_per_second': '4.9452', 'grad_norm': '15', 'counters/examples': 4224, 'counters/updates': 264}
skipping logging after 4240 examples to avoid logging too frequently
skipping logging after 4256 examples to avoid logging too frequently
skipping logging after 4272 examples to avoid logging too frequently
train stats after 4288 examples: {'rewards_train/chosen': '0.0097167', 'rewards_train/rejected': '-0.018626', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.028351', 'logps_train/rejected': '-130.15', 'logps_train/chosen': '-150.1', 'loss/train': '0.67963', 'examples_per_second': '5.7027', 'grad_norm': '17.5', 'counters/examples': 4288, 'counters/updates': 268}
skipping logging after 4304 examples to avoid logging too frequently
skipping logging after 4320 examples to avoid logging too frequently
skipping logging after 4336 examples to avoid logging too frequently
train stats after 4352 examples: {'rewards_train/chosen': '0.0069335', 'rewards_train/rejected': '-0.018254', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.025208', 'logps_train/rejected': '-97.326', 'logps_train/chosen': '-101.83', 'loss/train': '0.68329', 'examples_per_second': '5.6554', 'grad_norm': '15.062', 'counters/examples': 4352, 'counters/updates': 272}
skipping logging after 4368 examples to avoid logging too frequently
skipping logging after 4384 examples to avoid logging too frequently
skipping logging after 4400 examples to avoid logging too frequently
train stats after 4416 examples: {'rewards_train/chosen': '-0.010943', 'rewards_train/rejected': '-0.025166', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '0.014232', 'logps_train/rejected': '-117.16', 'logps_train/chosen': '-130.58', 'loss/train': '0.68829', 'examples_per_second': '4.8714', 'grad_norm': '15.562', 'counters/examples': 4416, 'counters/updates': 276}
skipping logging after 4432 examples to avoid logging too frequently
skipping logging after 4448 examples to avoid logging too frequently
skipping logging after 4464 examples to avoid logging too frequently
train stats after 4480 examples: {'rewards_train/chosen': '-0.0082169', 'rewards_train/rejected': '-0.028147', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.019948', 'logps_train/rejected': '-109.92', 'logps_train/chosen': '-127.78', 'loss/train': '0.6814', 'examples_per_second': '5.5843', 'grad_norm': '15.688', 'counters/examples': 4480, 'counters/updates': 280}
skipping logging after 4496 examples to avoid logging too frequently
skipping logging after 4512 examples to avoid logging too frequently
skipping logging after 4528 examples to avoid logging too frequently
train stats after 4544 examples: {'rewards_train/chosen': '-0.013131', 'rewards_train/rejected': '-0.015972', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.0028181', 'logps_train/rejected': '-104.92', 'logps_train/chosen': '-113.6', 'loss/train': '0.69293', 'examples_per_second': '5.5277', 'grad_norm': '15.625', 'counters/examples': 4544, 'counters/updates': 284}
skipping logging after 4560 examples to avoid logging too frequently
skipping logging after 4576 examples to avoid logging too frequently
skipping logging after 4592 examples to avoid logging too frequently
train stats after 4608 examples: {'rewards_train/chosen': '-0.013029', 'rewards_train/rejected': '-0.018852', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.0058403', 'logps_train/rejected': '-104.77', 'logps_train/chosen': '-109.45', 'loss/train': '0.68933', 'examples_per_second': '5.8227', 'grad_norm': '13.438', 'counters/examples': 4608, 'counters/updates': 288}
skipping logging after 4624 examples to avoid logging too frequently
skipping logging after 4640 examples to avoid logging too frequently
skipping logging after 4656 examples to avoid logging too frequently
train stats after 4672 examples: {'rewards_train/chosen': '-0.0050125', 'rewards_train/rejected': '-0.016116', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '0.011105', 'logps_train/rejected': '-110.59', 'logps_train/chosen': '-148.24', 'loss/train': '0.68689', 'examples_per_second': '3.7823', 'grad_norm': '16.625', 'counters/examples': 4672, 'counters/updates': 292}
skipping logging after 4688 examples to avoid logging too frequently
skipping logging after 4704 examples to avoid logging too frequently
skipping logging after 4720 examples to avoid logging too frequently
train stats after 4736 examples: {'rewards_train/chosen': '-0.016034', 'rewards_train/rejected': '-0.0050764', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '-0.010962', 'logps_train/rejected': '-131.57', 'logps_train/chosen': '-128.3', 'loss/train': '0.69684', 'examples_per_second': '4.8878', 'grad_norm': '15.938', 'counters/examples': 4736, 'counters/updates': 296}
skipping logging after 4752 examples to avoid logging too frequently
skipping logging after 4768 examples to avoid logging too frequently
skipping logging after 4784 examples to avoid logging too frequently
train stats after 4800 examples: {'rewards_train/chosen': '-0.017643', 'rewards_train/rejected': '-0.01812', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.00048161', 'logps_train/rejected': '-105.13', 'logps_train/chosen': '-127.39', 'loss/train': '0.69464', 'examples_per_second': '4.7016', 'grad_norm': '15.5', 'counters/examples': 4800, 'counters/updates': 300}
skipping logging after 4816 examples to avoid logging too frequently
skipping logging after 4832 examples to avoid logging too frequently
skipping logging after 4848 examples to avoid logging too frequently
train stats after 4864 examples: {'rewards_train/chosen': '-0.016144', 'rewards_train/rejected': '-0.0053029', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '-0.010853', 'logps_train/rejected': '-125.83', 'logps_train/chosen': '-134.61', 'loss/train': '0.69617', 'examples_per_second': '5.3997', 'grad_norm': '16.25', 'counters/examples': 4864, 'counters/updates': 304}
skipping logging after 4880 examples to avoid logging too frequently
skipping logging after 4896 examples to avoid logging too frequently
skipping logging after 4912 examples to avoid logging too frequently
train stats after 4928 examples: {'rewards_train/chosen': '-0.013823', 'rewards_train/rejected': '-0.023661', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.0098224', 'logps_train/rejected': '-111.95', 'logps_train/chosen': '-129.29', 'loss/train': '0.68829', 'examples_per_second': '5.2993', 'grad_norm': '15', 'counters/examples': 4928, 'counters/updates': 308}
skipping logging after 4944 examples to avoid logging too frequently
skipping logging after 4960 examples to avoid logging too frequently
Running evaluation after 4960 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:11,  2.29s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:04,  2.14s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:55,  1.90s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.89s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.54s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 4960: {'rewards_eval/chosen': '-0.014265', 'rewards_eval/rejected': '-0.018013', 'rewards_eval/accuracies': '0.44922', 'rewards_eval/margins': '0.0037498', 'logps_eval/rejected': '-122.34', 'logps_eval/chosen': '-118.64', 'loss/eval': '0.69148'}
skipping logging after 4976 examples to avoid logging too frequently
train stats after 4992 examples: {'rewards_train/chosen': '-0.0040706', 'rewards_train/rejected': '-0.0020459', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '-0.0019987', 'logps_train/rejected': '-107.95', 'logps_train/chosen': '-121.29', 'loss/train': '0.69409', 'examples_per_second': '5.024', 'grad_norm': '14.625', 'counters/examples': 4992, 'counters/updates': 312}
skipping logging after 5008 examples to avoid logging too frequently
skipping logging after 5024 examples to avoid logging too frequently
skipping logging after 5040 examples to avoid logging too frequently
train stats after 5056 examples: {'rewards_train/chosen': '-0.028728', 'rewards_train/rejected': '-0.022386', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '-0.0063543', 'logps_train/rejected': '-110.09', 'logps_train/chosen': '-110.71', 'loss/train': '0.70239', 'examples_per_second': '4.8856', 'grad_norm': '14.438', 'counters/examples': 5056, 'counters/updates': 316}
skipping logging after 5072 examples to avoid logging too frequently
skipping logging after 5088 examples to avoid logging too frequently
skipping logging after 5104 examples to avoid logging too frequently
train stats after 5120 examples: {'rewards_train/chosen': '0.012345', 'rewards_train/rejected': '-0.010747', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.023094', 'logps_train/rejected': '-120.02', 'logps_train/chosen': '-133.28', 'loss/train': '0.68353', 'examples_per_second': '5.1535', 'grad_norm': '16.25', 'counters/examples': 5120, 'counters/updates': 320}
skipping logging after 5136 examples to avoid logging too frequently
skipping logging after 5152 examples to avoid logging too frequently
skipping logging after 5168 examples to avoid logging too frequently
train stats after 5184 examples: {'rewards_train/chosen': '-0.011201', 'rewards_train/rejected': '-0.018864', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '0.007694', 'logps_train/rejected': '-112.25', 'logps_train/chosen': '-111.72', 'loss/train': '0.69019', 'examples_per_second': '5.3276', 'grad_norm': '13.812', 'counters/examples': 5184, 'counters/updates': 324}
skipping logging after 5200 examples to avoid logging too frequently
skipping logging after 5216 examples to avoid logging too frequently
skipping logging after 5232 examples to avoid logging too frequently
train stats after 5248 examples: {'rewards_train/chosen': '-0.00065136', 'rewards_train/rejected': '-0.0088274', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.0082188', 'logps_train/rejected': '-87.609', 'logps_train/chosen': '-115.86', 'loss/train': '0.68658', 'examples_per_second': '7.0078', 'grad_norm': '13.75', 'counters/examples': 5248, 'counters/updates': 328}
skipping logging after 5264 examples to avoid logging too frequently
skipping logging after 5280 examples to avoid logging too frequently
skipping logging after 5296 examples to avoid logging too frequently
train stats after 5312 examples: {'rewards_train/chosen': '-0.01891', 'rewards_train/rejected': '-0.018228', 'rewards_train/accuracies': '0.39062', 'rewards_train/margins': '-0.00067806', 'logps_train/rejected': '-91.129', 'logps_train/chosen': '-121.69', 'loss/train': '0.69159', 'examples_per_second': '5.6654', 'grad_norm': '15.25', 'counters/examples': 5312, 'counters/updates': 332}
skipping logging after 5328 examples to avoid logging too frequently
skipping logging after 5344 examples to avoid logging too frequently
skipping logging after 5360 examples to avoid logging too frequently
train stats after 5376 examples: {'rewards_train/chosen': '-0.013341', 'rewards_train/rejected': '-0.012882', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '-0.0004549', 'logps_train/rejected': '-125.14', 'logps_train/chosen': '-129.33', 'loss/train': '0.69366', 'examples_per_second': '5.5012', 'grad_norm': '16.125', 'counters/examples': 5376, 'counters/updates': 336}
skipping logging after 5392 examples to avoid logging too frequently
skipping logging after 5408 examples to avoid logging too frequently
skipping logging after 5424 examples to avoid logging too frequently
train stats after 5440 examples: {'rewards_train/chosen': '0.012325', 'rewards_train/rejected': '-0.023589', 'rewards_train/accuracies': '0.40625', 'rewards_train/margins': '0.035916', 'logps_train/rejected': '-106.66', 'logps_train/chosen': '-118.11', 'loss/train': '0.68579', 'examples_per_second': '4.25', 'grad_norm': '15.125', 'counters/examples': 5440, 'counters/updates': 340}
skipping logging after 5456 examples to avoid logging too frequently
skipping logging after 5472 examples to avoid logging too frequently
skipping logging after 5488 examples to avoid logging too frequently
train stats after 5504 examples: {'rewards_train/chosen': '-0.0022635', 'rewards_train/rejected': '-0.024373', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.022098', 'logps_train/rejected': '-95.319', 'logps_train/chosen': '-111.57', 'loss/train': '0.68335', 'examples_per_second': '5.3106', 'grad_norm': '15', 'counters/examples': 5504, 'counters/updates': 344}
skipping logging after 5520 examples to avoid logging too frequently
skipping logging after 5536 examples to avoid logging too frequently
skipping logging after 5552 examples to avoid logging too frequently
train stats after 5568 examples: {'rewards_train/chosen': '0.0013157', 'rewards_train/rejected': '-0.019306', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.020672', 'logps_train/rejected': '-91.896', 'logps_train/chosen': '-128.81', 'loss/train': '0.68396', 'examples_per_second': '4.7892', 'grad_norm': '17.25', 'counters/examples': 5568, 'counters/updates': 348}
skipping logging after 5584 examples to avoid logging too frequently
skipping logging after 5600 examples to avoid logging too frequently
skipping logging after 5616 examples to avoid logging too frequently
train stats after 5632 examples: {'rewards_train/chosen': '-0.0014524', 'rewards_train/rejected': '-0.029148', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.027706', 'logps_train/rejected': '-115.97', 'logps_train/chosen': '-111.58', 'loss/train': '0.68127', 'examples_per_second': '5.6914', 'grad_norm': '14.375', 'counters/examples': 5632, 'counters/updates': 352}
skipping logging after 5648 examples to avoid logging too frequently
skipping logging after 5664 examples to avoid logging too frequently
skipping logging after 5680 examples to avoid logging too frequently
train stats after 5696 examples: {'rewards_train/chosen': '-0.017185', 'rewards_train/rejected': '-0.037778', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.020601', 'logps_train/rejected': '-117.21', 'logps_train/chosen': '-138.36', 'loss/train': '0.68384', 'examples_per_second': '5.3876', 'grad_norm': '17.5', 'counters/examples': 5696, 'counters/updates': 356}
skipping logging after 5712 examples to avoid logging too frequently
skipping logging after 5728 examples to avoid logging too frequently
skipping logging after 5744 examples to avoid logging too frequently
train stats after 5760 examples: {'rewards_train/chosen': '0.010633', 'rewards_train/rejected': '-0.051707', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.062356', 'logps_train/rejected': '-138.63', 'logps_train/chosen': '-125.99', 'loss/train': '0.66434', 'examples_per_second': '5.1634', 'grad_norm': '23.375', 'counters/examples': 5760, 'counters/updates': 360}
skipping logging after 5776 examples to avoid logging too frequently
skipping logging after 5792 examples to avoid logging too frequently
skipping logging after 5808 examples to avoid logging too frequently
train stats after 5824 examples: {'rewards_train/chosen': '-0.023757', 'rewards_train/rejected': '-0.047956', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.024182', 'logps_train/rejected': '-108.94', 'logps_train/chosen': '-100.46', 'loss/train': '0.6842', 'examples_per_second': '5.2218', 'grad_norm': '15.25', 'counters/examples': 5824, 'counters/updates': 364}
skipping logging after 5840 examples to avoid logging too frequently
skipping logging after 5856 examples to avoid logging too frequently
skipping logging after 5872 examples to avoid logging too frequently
train stats after 5888 examples: {'rewards_train/chosen': '-0.010453', 'rewards_train/rejected': '-0.0039349', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '-0.0065427', 'logps_train/rejected': '-113.48', 'logps_train/chosen': '-100.41', 'loss/train': '0.698', 'examples_per_second': '5.8075', 'grad_norm': '14.438', 'counters/examples': 5888, 'counters/updates': 368}
skipping logging after 5904 examples to avoid logging too frequently
skipping logging after 5920 examples to avoid logging too frequently
skipping logging after 5936 examples to avoid logging too frequently
train stats after 5952 examples: {'rewards_train/chosen': '-0.0080369', 'rewards_train/rejected': '-0.027653', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.019589', 'logps_train/rejected': '-124.32', 'logps_train/chosen': '-145.3', 'loss/train': '0.68445', 'examples_per_second': '4.9678', 'grad_norm': '16.5', 'counters/examples': 5952, 'counters/updates': 372}
Running evaluation after 5952 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 5952: {'rewards_eval/chosen': '-0.028431', 'rewards_eval/rejected': '-0.036364', 'rewards_eval/accuracies': '0.50391', 'rewards_eval/margins': '0.0079296', 'logps_eval/rejected': '-122.52', 'logps_eval/chosen': '-118.78', 'loss/eval': '0.69032'}
skipping logging after 5968 examples to avoid logging too frequently
skipping logging after 5984 examples to avoid logging too frequently
skipping logging after 6000 examples to avoid logging too frequently
train stats after 6016 examples: {'rewards_train/chosen': '-0.03189', 'rewards_train/rejected': '-0.053068', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.021189', 'logps_train/rejected': '-132.01', 'logps_train/chosen': '-118.55', 'loss/train': '0.68347', 'examples_per_second': '4.9935', 'grad_norm': '19.875', 'counters/examples': 6016, 'counters/updates': 376}
skipping logging after 6032 examples to avoid logging too frequently
skipping logging after 6048 examples to avoid logging too frequently
skipping logging after 6064 examples to avoid logging too frequently
train stats after 6080 examples: {'rewards_train/chosen': '-0.054076', 'rewards_train/rejected': '-0.051224', 'rewards_train/accuracies': '0.42188', 'rewards_train/margins': '-0.0028057', 'logps_train/rejected': '-88.132', 'logps_train/chosen': '-90.103', 'loss/train': '0.6936', 'examples_per_second': '6.9704', 'grad_norm': '14', 'counters/examples': 6080, 'counters/updates': 380}
skipping logging after 6096 examples to avoid logging too frequently
skipping logging after 6112 examples to avoid logging too frequently
skipping logging after 6128 examples to avoid logging too frequently
train stats after 6144 examples: {'rewards_train/chosen': '-0.020119', 'rewards_train/rejected': '-0.056118', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.035982', 'logps_train/rejected': '-123.53', 'logps_train/chosen': '-119.56', 'loss/train': '0.67578', 'examples_per_second': '4.5844', 'grad_norm': '17.875', 'counters/examples': 6144, 'counters/updates': 384}
skipping logging after 6160 examples to avoid logging too frequently
skipping logging after 6176 examples to avoid logging too frequently
skipping logging after 6192 examples to avoid logging too frequently
train stats after 6208 examples: {'rewards_train/chosen': '-0.04762', 'rewards_train/rejected': '-0.062863', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.015257', 'logps_train/rejected': '-116.43', 'logps_train/chosen': '-138.48', 'loss/train': '0.68912', 'examples_per_second': '5.4141', 'grad_norm': '16.25', 'counters/examples': 6208, 'counters/updates': 388}
skipping logging after 6224 examples to avoid logging too frequently
skipping logging after 6240 examples to avoid logging too frequently
skipping logging after 6256 examples to avoid logging too frequently
train stats after 6272 examples: {'rewards_train/chosen': '-0.016203', 'rewards_train/rejected': '-0.065146', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.048992', 'logps_train/rejected': '-89.813', 'logps_train/chosen': '-137.65', 'loss/train': '0.67014', 'examples_per_second': '5.3676', 'grad_norm': '21', 'counters/examples': 6272, 'counters/updates': 392}
skipping logging after 6288 examples to avoid logging too frequently
skipping logging after 6304 examples to avoid logging too frequently
skipping logging after 6320 examples to avoid logging too frequently
train stats after 6336 examples: {'rewards_train/chosen': '-0.037452', 'rewards_train/rejected': '-0.039987', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.0025277', 'logps_train/rejected': '-116.46', 'logps_train/chosen': '-106.22', 'loss/train': '0.69427', 'examples_per_second': '4.8276', 'grad_norm': '12.75', 'counters/examples': 6336, 'counters/updates': 396}
skipping logging after 6352 examples to avoid logging too frequently
skipping logging after 6368 examples to avoid logging too frequently
skipping logging after 6384 examples to avoid logging too frequently
train stats after 6400 examples: {'rewards_train/chosen': '-0.092815', 'rewards_train/rejected': '-0.091879', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '-0.00091648', 'logps_train/rejected': '-106.08', 'logps_train/chosen': '-104.8', 'loss/train': '0.69476', 'examples_per_second': '5.3063', 'grad_norm': '14.25', 'counters/examples': 6400, 'counters/updates': 400}
skipping logging after 6416 examples to avoid logging too frequently
skipping logging after 6432 examples to avoid logging too frequently
skipping logging after 6448 examples to avoid logging too frequently
train stats after 6464 examples: {'rewards_train/chosen': '-0.054248', 'rewards_train/rejected': '-0.083779', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.029556', 'logps_train/rejected': '-90.712', 'logps_train/chosen': '-91.946', 'loss/train': '0.68271', 'examples_per_second': '5.3998', 'grad_norm': '15.188', 'counters/examples': 6464, 'counters/updates': 404}
skipping logging after 6480 examples to avoid logging too frequently
skipping logging after 6496 examples to avoid logging too frequently
skipping logging after 6512 examples to avoid logging too frequently
train stats after 6528 examples: {'rewards_train/chosen': '-0.097785', 'rewards_train/rejected': '-0.12483', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.027027', 'logps_train/rejected': '-126.86', 'logps_train/chosen': '-127.37', 'loss/train': '0.68216', 'examples_per_second': '4.9818', 'grad_norm': '17.5', 'counters/examples': 6528, 'counters/updates': 408}
skipping logging after 6544 examples to avoid logging too frequently
skipping logging after 6560 examples to avoid logging too frequently
skipping logging after 6576 examples to avoid logging too frequently
train stats after 6592 examples: {'rewards_train/chosen': '-0.1002', 'rewards_train/rejected': '-0.12931', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.029173', 'logps_train/rejected': '-106.58', 'logps_train/chosen': '-104.87', 'loss/train': '0.68484', 'examples_per_second': '5.1298', 'grad_norm': '14.688', 'counters/examples': 6592, 'counters/updates': 412}
skipping logging after 6608 examples to avoid logging too frequently
skipping logging after 6624 examples to avoid logging too frequently
skipping logging after 6640 examples to avoid logging too frequently
train stats after 6656 examples: {'rewards_train/chosen': '-0.082742', 'rewards_train/rejected': '-0.089154', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.0064411', 'logps_train/rejected': '-121.51', 'logps_train/chosen': '-155.18', 'loss/train': '0.69604', 'examples_per_second': '5.4264', 'grad_norm': '19.375', 'counters/examples': 6656, 'counters/updates': 416}
skipping logging after 6672 examples to avoid logging too frequently
skipping logging after 6688 examples to avoid logging too frequently
skipping logging after 6704 examples to avoid logging too frequently
train stats after 6720 examples: {'rewards_train/chosen': '-0.097877', 'rewards_train/rejected': '-0.13561', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.037731', 'logps_train/rejected': '-109.84', 'logps_train/chosen': '-137.97', 'loss/train': '0.67917', 'examples_per_second': '5.544', 'grad_norm': '15.75', 'counters/examples': 6720, 'counters/updates': 420}
skipping logging after 6736 examples to avoid logging too frequently
skipping logging after 6752 examples to avoid logging too frequently
skipping logging after 6768 examples to avoid logging too frequently
train stats after 6784 examples: {'rewards_train/chosen': '-0.17336', 'rewards_train/rejected': '-0.1622', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '-0.011186', 'logps_train/rejected': '-147.52', 'logps_train/chosen': '-156.74', 'loss/train': '0.7066', 'examples_per_second': '3.5418', 'grad_norm': '20.5', 'counters/examples': 6784, 'counters/updates': 424}
skipping logging after 6800 examples to avoid logging too frequently
skipping logging after 6816 examples to avoid logging too frequently
skipping logging after 6832 examples to avoid logging too frequently
train stats after 6848 examples: {'rewards_train/chosen': '-0.1004', 'rewards_train/rejected': '-0.11581', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.015406', 'logps_train/rejected': '-123.15', 'logps_train/chosen': '-126.56', 'loss/train': '0.68719', 'examples_per_second': '5.7857', 'grad_norm': '19.25', 'counters/examples': 6848, 'counters/updates': 428}
skipping logging after 6864 examples to avoid logging too frequently
skipping logging after 6880 examples to avoid logging too frequently
skipping logging after 6896 examples to avoid logging too frequently
train stats after 6912 examples: {'rewards_train/chosen': '-0.17918', 'rewards_train/rejected': '-0.21149', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.032373', 'logps_train/rejected': '-122.93', 'logps_train/chosen': '-113.27', 'loss/train': '0.67551', 'examples_per_second': '4.5551', 'grad_norm': '14.062', 'counters/examples': 6912, 'counters/updates': 432}
skipping logging after 6928 examples to avoid logging too frequently
skipping logging after 6944 examples to avoid logging too frequently
Running evaluation after 6944 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:08,  2.22s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:03,  2.11s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.88s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.87s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 6944: {'rewards_eval/chosen': '-0.14827', 'rewards_eval/rejected': '-0.1611', 'rewards_eval/accuracies': '0.52344', 'rewards_eval/margins': '0.012821', 'logps_eval/rejected': '-123.77', 'logps_eval/chosen': '-119.98', 'loss/eval': '0.69032'}
skipping logging after 6960 examples to avoid logging too frequently
train stats after 6976 examples: {'rewards_train/chosen': '-0.12497', 'rewards_train/rejected': '-0.17631', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.051369', 'logps_train/rejected': '-116.84', 'logps_train/chosen': '-107.61', 'loss/train': '0.6774', 'examples_per_second': '5.669', 'grad_norm': '15.438', 'counters/examples': 6976, 'counters/updates': 436}
skipping logging after 6992 examples to avoid logging too frequently
skipping logging after 7008 examples to avoid logging too frequently
skipping logging after 7024 examples to avoid logging too frequently
train stats after 7040 examples: {'rewards_train/chosen': '-0.14649', 'rewards_train/rejected': '-0.15218', 'rewards_train/accuracies': '0.42188', 'rewards_train/margins': '0.0056639', 'logps_train/rejected': '-86.931', 'logps_train/chosen': '-103.43', 'loss/train': '0.69455', 'examples_per_second': '4.6084', 'grad_norm': '14.562', 'counters/examples': 7040, 'counters/updates': 440}
skipping logging after 7056 examples to avoid logging too frequently
skipping logging after 7072 examples to avoid logging too frequently
skipping logging after 7088 examples to avoid logging too frequently
train stats after 7104 examples: {'rewards_train/chosen': '-0.1513', 'rewards_train/rejected': '-0.1665', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.015205', 'logps_train/rejected': '-100.68', 'logps_train/chosen': '-86.382', 'loss/train': '0.69214', 'examples_per_second': '5.5974', 'grad_norm': '16.375', 'counters/examples': 7104, 'counters/updates': 444}
skipping logging after 7120 examples to avoid logging too frequently
skipping logging after 7136 examples to avoid logging too frequently
skipping logging after 7152 examples to avoid logging too frequently
train stats after 7168 examples: {'rewards_train/chosen': '-0.12216', 'rewards_train/rejected': '-0.1362', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.014054', 'logps_train/rejected': '-97.753', 'logps_train/chosen': '-105.61', 'loss/train': '0.68872', 'examples_per_second': '5.4418', 'grad_norm': '15.438', 'counters/examples': 7168, 'counters/updates': 448}
skipping logging after 7184 examples to avoid logging too frequently
skipping logging after 7200 examples to avoid logging too frequently
skipping logging after 7216 examples to avoid logging too frequently
train stats after 7232 examples: {'rewards_train/chosen': '-0.12329', 'rewards_train/rejected': '-0.11234', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '-0.010927', 'logps_train/rejected': '-121.63', 'logps_train/chosen': '-126.32', 'loss/train': '0.70255', 'examples_per_second': '5.4336', 'grad_norm': '15.625', 'counters/examples': 7232, 'counters/updates': 452}
skipping logging after 7248 examples to avoid logging too frequently
skipping logging after 7264 examples to avoid logging too frequently
skipping logging after 7280 examples to avoid logging too frequently
train stats after 7296 examples: {'rewards_train/chosen': '-0.074145', 'rewards_train/rejected': '-0.095742', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.021613', 'logps_train/rejected': '-150.9', 'logps_train/chosen': '-145.46', 'loss/train': '0.68823', 'examples_per_second': '4.7161', 'grad_norm': '16.875', 'counters/examples': 7296, 'counters/updates': 456}
skipping logging after 7312 examples to avoid logging too frequently
skipping logging after 7328 examples to avoid logging too frequently
skipping logging after 7344 examples to avoid logging too frequently
train stats after 7360 examples: {'rewards_train/chosen': '-0.080851', 'rewards_train/rejected': '-0.10356', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.022718', 'logps_train/rejected': '-114.38', 'logps_train/chosen': '-119.06', 'loss/train': '0.68445', 'examples_per_second': '5.4713', 'grad_norm': '14.75', 'counters/examples': 7360, 'counters/updates': 460}
skipping logging after 7376 examples to avoid logging too frequently
skipping logging after 7392 examples to avoid logging too frequently
skipping logging after 7408 examples to avoid logging too frequently
train stats after 7424 examples: {'rewards_train/chosen': '-0.076343', 'rewards_train/rejected': '-0.13328', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.056945', 'logps_train/rejected': '-109.78', 'logps_train/chosen': '-108.6', 'loss/train': '0.67429', 'examples_per_second': '5.213', 'grad_norm': '16.625', 'counters/examples': 7424, 'counters/updates': 464}
skipping logging after 7440 examples to avoid logging too frequently
skipping logging after 7456 examples to avoid logging too frequently
skipping logging after 7472 examples to avoid logging too frequently
train stats after 7488 examples: {'rewards_train/chosen': '-0.1191', 'rewards_train/rejected': '-0.13933', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.020218', 'logps_train/rejected': '-109.43', 'logps_train/chosen': '-122.64', 'loss/train': '0.68741', 'examples_per_second': '4.7416', 'grad_norm': '16.5', 'counters/examples': 7488, 'counters/updates': 468}
skipping logging after 7504 examples to avoid logging too frequently
skipping logging after 7520 examples to avoid logging too frequently
skipping logging after 7536 examples to avoid logging too frequently
train stats after 7552 examples: {'rewards_train/chosen': '-0.13484', 'rewards_train/rejected': '-0.17133', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.036448', 'logps_train/rejected': '-100.47', 'logps_train/chosen': '-102.42', 'loss/train': '0.67688', 'examples_per_second': '6.0287', 'grad_norm': '13.75', 'counters/examples': 7552, 'counters/updates': 472}
skipping logging after 7568 examples to avoid logging too frequently
skipping logging after 7584 examples to avoid logging too frequently
skipping logging after 7600 examples to avoid logging too frequently
train stats after 7616 examples: {'rewards_train/chosen': '-0.10517', 'rewards_train/rejected': '-0.11888', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.013733', 'logps_train/rejected': '-117.41', 'logps_train/chosen': '-121.41', 'loss/train': '0.6897', 'examples_per_second': '4.5351', 'grad_norm': '17.75', 'counters/examples': 7616, 'counters/updates': 476}
skipping logging after 7632 examples to avoid logging too frequently
skipping logging after 7648 examples to avoid logging too frequently
skipping logging after 7664 examples to avoid logging too frequently
train stats after 7680 examples: {'rewards_train/chosen': '-0.11487', 'rewards_train/rejected': '-0.12466', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.0097618', 'logps_train/rejected': '-131.45', 'logps_train/chosen': '-117.76', 'loss/train': '0.69165', 'examples_per_second': '4.2379', 'grad_norm': '17.25', 'counters/examples': 7680, 'counters/updates': 480}
skipping logging after 7696 examples to avoid logging too frequently
skipping logging after 7712 examples to avoid logging too frequently
skipping logging after 7728 examples to avoid logging too frequently
train stats after 7744 examples: {'rewards_train/chosen': '-0.10849', 'rewards_train/rejected': '-0.18306', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.074634', 'logps_train/rejected': '-117.17', 'logps_train/chosen': '-98.944', 'loss/train': '0.66309', 'examples_per_second': '4.8769', 'grad_norm': '20', 'counters/examples': 7744, 'counters/updates': 484}
skipping logging after 7760 examples to avoid logging too frequently
skipping logging after 7776 examples to avoid logging too frequently
skipping logging after 7792 examples to avoid logging too frequently
train stats after 7808 examples: {'rewards_train/chosen': '-0.11281', 'rewards_train/rejected': '-0.18433', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.071546', 'logps_train/rejected': '-112.58', 'logps_train/chosen': '-109.08', 'loss/train': '0.66324', 'examples_per_second': '4.9735', 'grad_norm': '17.25', 'counters/examples': 7808, 'counters/updates': 488}
skipping logging after 7824 examples to avoid logging too frequently
skipping logging after 7840 examples to avoid logging too frequently
skipping logging after 7856 examples to avoid logging too frequently
train stats after 7872 examples: {'rewards_train/chosen': '-0.15655', 'rewards_train/rejected': '-0.18947', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.032904', 'logps_train/rejected': '-124.89', 'logps_train/chosen': '-133.02', 'loss/train': '0.68555', 'examples_per_second': '5.4572', 'grad_norm': '22', 'counters/examples': 7872, 'counters/updates': 492}
skipping logging after 7888 examples to avoid logging too frequently
skipping logging after 7904 examples to avoid logging too frequently
skipping logging after 7920 examples to avoid logging too frequently
train stats after 7936 examples: {'rewards_train/chosen': '-0.18396', 'rewards_train/rejected': '-0.20086', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.01689', 'logps_train/rejected': '-98.522', 'logps_train/chosen': '-95.104', 'loss/train': '0.68884', 'examples_per_second': '5.2276', 'grad_norm': '14.75', 'counters/examples': 7936, 'counters/updates': 496}
Running evaluation after 7936 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:41,  1.61s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.45s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:12<00:36,  1.53s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.46s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.53s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 7936: {'rewards_eval/chosen': '-0.22635', 'rewards_eval/rejected': '-0.25104', 'rewards_eval/accuracies': '0.50977', 'rewards_eval/margins': '0.024702', 'logps_eval/rejected': '-124.67', 'logps_eval/chosen': '-120.76', 'loss/eval': '0.68771'}
skipping logging after 7952 examples to avoid logging too frequently
skipping logging after 7968 examples to avoid logging too frequently
skipping logging after 7984 examples to avoid logging too frequently
train stats after 8000 examples: {'rewards_train/chosen': '-0.25157', 'rewards_train/rejected': '-0.30874', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.05712', 'logps_train/rejected': '-114.2', 'logps_train/chosen': '-127.23', 'loss/train': '0.67447', 'examples_per_second': '4.5213', 'grad_norm': '16.75', 'counters/examples': 8000, 'counters/updates': 500}
skipping logging after 8016 examples to avoid logging too frequently
skipping logging after 8032 examples to avoid logging too frequently
skipping logging after 8048 examples to avoid logging too frequently
train stats after 8064 examples: {'rewards_train/chosen': '-0.20636', 'rewards_train/rejected': '-0.25298', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.046556', 'logps_train/rejected': '-122.91', 'logps_train/chosen': '-120.52', 'loss/train': '0.67825', 'examples_per_second': '5.0177', 'grad_norm': '16.75', 'counters/examples': 8064, 'counters/updates': 504}
skipping logging after 8080 examples to avoid logging too frequently
skipping logging after 8096 examples to avoid logging too frequently
skipping logging after 8112 examples to avoid logging too frequently
train stats after 8128 examples: {'rewards_train/chosen': '-0.15148', 'rewards_train/rejected': '-0.16451', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.013031', 'logps_train/rejected': '-101.54', 'logps_train/chosen': '-126.3', 'loss/train': '0.69437', 'examples_per_second': '5.5239', 'grad_norm': '18.5', 'counters/examples': 8128, 'counters/updates': 508}
skipping logging after 8144 examples to avoid logging too frequently
skipping logging after 8160 examples to avoid logging too frequently
skipping logging after 8176 examples to avoid logging too frequently
train stats after 8192 examples: {'rewards_train/chosen': '-0.19738', 'rewards_train/rejected': '-0.19354', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '-0.0038719', 'logps_train/rejected': '-134.3', 'logps_train/chosen': '-104.2', 'loss/train': '0.70105', 'examples_per_second': '5.2454', 'grad_norm': '17.125', 'counters/examples': 8192, 'counters/updates': 512}
skipping logging after 8208 examples to avoid logging too frequently
skipping logging after 8224 examples to avoid logging too frequently
skipping logging after 8240 examples to avoid logging too frequently
train stats after 8256 examples: {'rewards_train/chosen': '-0.17189', 'rewards_train/rejected': '-0.21015', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.038197', 'logps_train/rejected': '-107.17', 'logps_train/chosen': '-118.52', 'loss/train': '0.68002', 'examples_per_second': '5.8361', 'grad_norm': '16', 'counters/examples': 8256, 'counters/updates': 516}
skipping logging after 8272 examples to avoid logging too frequently
skipping logging after 8288 examples to avoid logging too frequently
skipping logging after 8304 examples to avoid logging too frequently
train stats after 8320 examples: {'rewards_train/chosen': '-0.16016', 'rewards_train/rejected': '-0.18067', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.020523', 'logps_train/rejected': '-132.58', 'logps_train/chosen': '-140.51', 'loss/train': '0.68948', 'examples_per_second': '4.5162', 'grad_norm': '16.625', 'counters/examples': 8320, 'counters/updates': 520}
skipping logging after 8336 examples to avoid logging too frequently
skipping logging after 8352 examples to avoid logging too frequently
skipping logging after 8368 examples to avoid logging too frequently
train stats after 8384 examples: {'rewards_train/chosen': '-0.15269', 'rewards_train/rejected': '-0.1937', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.041015', 'logps_train/rejected': '-117', 'logps_train/chosen': '-106.47', 'loss/train': '0.67911', 'examples_per_second': '5.9839', 'grad_norm': '15.438', 'counters/examples': 8384, 'counters/updates': 524}
skipping logging after 8400 examples to avoid logging too frequently
skipping logging after 8416 examples to avoid logging too frequently
skipping logging after 8432 examples to avoid logging too frequently
train stats after 8448 examples: {'rewards_train/chosen': '-0.12211', 'rewards_train/rejected': '-0.14056', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.018472', 'logps_train/rejected': '-117.23', 'logps_train/chosen': '-124.29', 'loss/train': '0.69131', 'examples_per_second': '4.3879', 'grad_norm': '16.875', 'counters/examples': 8448, 'counters/updates': 528}
skipping logging after 8464 examples to avoid logging too frequently
skipping logging after 8480 examples to avoid logging too frequently
skipping logging after 8496 examples to avoid logging too frequently
train stats after 8512 examples: {'rewards_train/chosen': '-0.15624', 'rewards_train/rejected': '-0.16159', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.0053005', 'logps_train/rejected': '-116.92', 'logps_train/chosen': '-123.25', 'loss/train': '0.69424', 'examples_per_second': '5.0599', 'grad_norm': '15.5', 'counters/examples': 8512, 'counters/updates': 532}
skipping logging after 8528 examples to avoid logging too frequently
skipping logging after 8544 examples to avoid logging too frequently
skipping logging after 8560 examples to avoid logging too frequently
train stats after 8576 examples: {'rewards_train/chosen': '-0.16042', 'rewards_train/rejected': '-0.1677', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.0072842', 'logps_train/rejected': '-128.67', 'logps_train/chosen': '-118.42', 'loss/train': '0.6973', 'examples_per_second': '5.2562', 'grad_norm': '16.375', 'counters/examples': 8576, 'counters/updates': 536}
skipping logging after 8592 examples to avoid logging too frequently
skipping logging after 8608 examples to avoid logging too frequently
skipping logging after 8624 examples to avoid logging too frequently
train stats after 8640 examples: {'rewards_train/chosen': '-0.10053', 'rewards_train/rejected': '-0.15029', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.04977', 'logps_train/rejected': '-87.867', 'logps_train/chosen': '-122.16', 'loss/train': '0.67435', 'examples_per_second': '4.8294', 'grad_norm': '17.75', 'counters/examples': 8640, 'counters/updates': 540}
skipping logging after 8656 examples to avoid logging too frequently
skipping logging after 8672 examples to avoid logging too frequently
skipping logging after 8688 examples to avoid logging too frequently
train stats after 8704 examples: {'rewards_train/chosen': '-0.18645', 'rewards_train/rejected': '-0.24546', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.059029', 'logps_train/rejected': '-123.44', 'logps_train/chosen': '-114.77', 'loss/train': '0.67166', 'examples_per_second': '5.83', 'grad_norm': '14.812', 'counters/examples': 8704, 'counters/updates': 544}
skipping logging after 8720 examples to avoid logging too frequently
skipping logging after 8736 examples to avoid logging too frequently
skipping logging after 8752 examples to avoid logging too frequently
train stats after 8768 examples: {'rewards_train/chosen': '-0.11641', 'rewards_train/rejected': '-0.16552', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.049055', 'logps_train/rejected': '-158.76', 'logps_train/chosen': '-136.96', 'loss/train': '0.67624', 'examples_per_second': '4.3719', 'grad_norm': '20.125', 'counters/examples': 8768, 'counters/updates': 548}
skipping logging after 8784 examples to avoid logging too frequently
skipping logging after 8800 examples to avoid logging too frequently
skipping logging after 8816 examples to avoid logging too frequently
train stats after 8832 examples: {'rewards_train/chosen': '-0.14492', 'rewards_train/rejected': '-0.25009', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.10519', 'logps_train/rejected': '-114.17', 'logps_train/chosen': '-122.55', 'loss/train': '0.65048', 'examples_per_second': '5.0035', 'grad_norm': '14.938', 'counters/examples': 8832, 'counters/updates': 552}
skipping logging after 8848 examples to avoid logging too frequently
skipping logging after 8864 examples to avoid logging too frequently
skipping logging after 8880 examples to avoid logging too frequently
train stats after 8896 examples: {'rewards_train/chosen': '-0.16576', 'rewards_train/rejected': '-0.17788', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.012186', 'logps_train/rejected': '-100.51', 'logps_train/chosen': '-97.731', 'loss/train': '0.69635', 'examples_per_second': '4.508', 'grad_norm': '13.625', 'counters/examples': 8896, 'counters/updates': 556}
skipping logging after 8912 examples to avoid logging too frequently
skipping logging after 8928 examples to avoid logging too frequently
Running evaluation after 8928 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:14,  2.39s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:05,  2.18s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:55,  1.92s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.89s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.54s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.65s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 8928: {'rewards_eval/chosen': '-0.14402', 'rewards_eval/rejected': '-0.17648', 'rewards_eval/accuracies': '0.54102', 'rewards_eval/margins': '0.032462', 'logps_eval/rejected': '-123.92', 'logps_eval/chosen': '-119.93', 'loss/eval': '0.68393'}
skipping logging after 8944 examples to avoid logging too frequently
train stats after 8960 examples: {'rewards_train/chosen': '-0.17247', 'rewards_train/rejected': '-0.17929', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.0068893', 'logps_train/rejected': '-123.26', 'logps_train/chosen': '-117.4', 'loss/train': '0.69531', 'examples_per_second': '5.3115', 'grad_norm': '15.625', 'counters/examples': 8960, 'counters/updates': 560}
skipping logging after 8976 examples to avoid logging too frequently
skipping logging after 8992 examples to avoid logging too frequently
skipping logging after 9008 examples to avoid logging too frequently
train stats after 9024 examples: {'rewards_train/chosen': '-0.15763', 'rewards_train/rejected': '-0.20626', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.048685', 'logps_train/rejected': '-111', 'logps_train/chosen': '-139.94', 'loss/train': '0.67599', 'examples_per_second': '5.8512', 'grad_norm': '16.5', 'counters/examples': 9024, 'counters/updates': 564}
skipping logging after 9040 examples to avoid logging too frequently
skipping logging after 9056 examples to avoid logging too frequently
skipping logging after 9072 examples to avoid logging too frequently
train stats after 9088 examples: {'rewards_train/chosen': '-0.13746', 'rewards_train/rejected': '-0.19762', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.060106', 'logps_train/rejected': '-98.114', 'logps_train/chosen': '-87.504', 'loss/train': '0.67041', 'examples_per_second': '4.9302', 'grad_norm': '14.125', 'counters/examples': 9088, 'counters/updates': 568}
skipping logging after 9104 examples to avoid logging too frequently
skipping logging after 9120 examples to avoid logging too frequently
skipping logging after 9136 examples to avoid logging too frequently
train stats after 9152 examples: {'rewards_train/chosen': '-0.20542', 'rewards_train/rejected': '-0.25577', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.050411', 'logps_train/rejected': '-131.45', 'logps_train/chosen': '-140.27', 'loss/train': '0.67789', 'examples_per_second': '5.3998', 'grad_norm': '19.5', 'counters/examples': 9152, 'counters/updates': 572}
skipping logging after 9168 examples to avoid logging too frequently
skipping logging after 9184 examples to avoid logging too frequently
skipping logging after 9200 examples to avoid logging too frequently
train stats after 9216 examples: {'rewards_train/chosen': '-0.20989', 'rewards_train/rejected': '-0.25484', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.044991', 'logps_train/rejected': '-120.72', 'logps_train/chosen': '-118.02', 'loss/train': '0.67776', 'examples_per_second': '5.0572', 'grad_norm': '15.25', 'counters/examples': 9216, 'counters/updates': 576}
skipping logging after 9232 examples to avoid logging too frequently
skipping logging after 9248 examples to avoid logging too frequently
skipping logging after 9264 examples to avoid logging too frequently
train stats after 9280 examples: {'rewards_train/chosen': '-0.15587', 'rewards_train/rejected': '-0.18311', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.027318', 'logps_train/rejected': '-105.86', 'logps_train/chosen': '-129.94', 'loss/train': '0.68533', 'examples_per_second': '6.5375', 'grad_norm': '15', 'counters/examples': 9280, 'counters/updates': 580}
skipping logging after 9296 examples to avoid logging too frequently
skipping logging after 9312 examples to avoid logging too frequently
skipping logging after 9328 examples to avoid logging too frequently
train stats after 9344 examples: {'rewards_train/chosen': '-0.1285', 'rewards_train/rejected': '-0.20233', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.073759', 'logps_train/rejected': '-125.48', 'logps_train/chosen': '-107.63', 'loss/train': '0.66602', 'examples_per_second': '4.1633', 'grad_norm': '16.625', 'counters/examples': 9344, 'counters/updates': 584}
skipping logging after 9360 examples to avoid logging too frequently
skipping logging after 9376 examples to avoid logging too frequently
skipping logging after 9392 examples to avoid logging too frequently
train stats after 9408 examples: {'rewards_train/chosen': '-0.17112', 'rewards_train/rejected': '-0.27001', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.098895', 'logps_train/rejected': '-86.111', 'logps_train/chosen': '-93.913', 'loss/train': '0.65768', 'examples_per_second': '5.9622', 'grad_norm': '18.875', 'counters/examples': 9408, 'counters/updates': 588}
skipping logging after 9424 examples to avoid logging too frequently
skipping logging after 9440 examples to avoid logging too frequently
skipping logging after 9456 examples to avoid logging too frequently
train stats after 9472 examples: {'rewards_train/chosen': '-0.25945', 'rewards_train/rejected': '-0.28856', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.029081', 'logps_train/rejected': '-126.05', 'logps_train/chosen': '-112.09', 'loss/train': '0.68973', 'examples_per_second': '4.479', 'grad_norm': '19.625', 'counters/examples': 9472, 'counters/updates': 592}
skipping logging after 9488 examples to avoid logging too frequently
skipping logging after 9504 examples to avoid logging too frequently
skipping logging after 9520 examples to avoid logging too frequently
train stats after 9536 examples: {'rewards_train/chosen': '-0.21412', 'rewards_train/rejected': '-0.23819', 'rewards_train/accuracies': '0.42188', 'rewards_train/margins': '0.024117', 'logps_train/rejected': '-128.05', 'logps_train/chosen': '-137.51', 'loss/train': '0.69049', 'examples_per_second': '4.7825', 'grad_norm': '17.375', 'counters/examples': 9536, 'counters/updates': 596}
skipping logging after 9552 examples to avoid logging too frequently
skipping logging after 9568 examples to avoid logging too frequently
skipping logging after 9584 examples to avoid logging too frequently
train stats after 9600 examples: {'rewards_train/chosen': '-0.24364', 'rewards_train/rejected': '-0.278', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.034424', 'logps_train/rejected': '-112.47', 'logps_train/chosen': '-119.59', 'loss/train': '0.68549', 'examples_per_second': '5.0536', 'grad_norm': '19.375', 'counters/examples': 9600, 'counters/updates': 600}
skipping logging after 9616 examples to avoid logging too frequently
skipping logging after 9632 examples to avoid logging too frequently
skipping logging after 9648 examples to avoid logging too frequently
train stats after 9664 examples: {'rewards_train/chosen': '-0.21275', 'rewards_train/rejected': '-0.24776', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.034962', 'logps_train/rejected': '-116.46', 'logps_train/chosen': '-117.86', 'loss/train': '0.68869', 'examples_per_second': '6.0531', 'grad_norm': '18.25', 'counters/examples': 9664, 'counters/updates': 604}
skipping logging after 9680 examples to avoid logging too frequently
skipping logging after 9696 examples to avoid logging too frequently
skipping logging after 9712 examples to avoid logging too frequently
train stats after 9728 examples: {'rewards_train/chosen': '-0.16055', 'rewards_train/rejected': '-0.24108', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.080605', 'logps_train/rejected': '-132.25', 'logps_train/chosen': '-137.13', 'loss/train': '0.66226', 'examples_per_second': '4.8643', 'grad_norm': '17.25', 'counters/examples': 9728, 'counters/updates': 608}
skipping logging after 9744 examples to avoid logging too frequently
skipping logging after 9760 examples to avoid logging too frequently
skipping logging after 9776 examples to avoid logging too frequently
train stats after 9792 examples: {'rewards_train/chosen': '-0.19305', 'rewards_train/rejected': '-0.2844', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.091419', 'logps_train/rejected': '-118.47', 'logps_train/chosen': '-150.61', 'loss/train': '0.65567', 'examples_per_second': '5.2769', 'grad_norm': '15.188', 'counters/examples': 9792, 'counters/updates': 612}
skipping logging after 9808 examples to avoid logging too frequently
skipping logging after 9824 examples to avoid logging too frequently
skipping logging after 9840 examples to avoid logging too frequently
train stats after 9856 examples: {'rewards_train/chosen': '-0.254', 'rewards_train/rejected': '-0.28851', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.03455', 'logps_train/rejected': '-104.47', 'logps_train/chosen': '-117.8', 'loss/train': '0.68524', 'examples_per_second': '4.5497', 'grad_norm': '16.875', 'counters/examples': 9856, 'counters/updates': 616}
skipping logging after 9872 examples to avoid logging too frequently
skipping logging after 9888 examples to avoid logging too frequently
skipping logging after 9904 examples to avoid logging too frequently
train stats after 9920 examples: {'rewards_train/chosen': '-0.20014', 'rewards_train/rejected': '-0.2877', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.087532', 'logps_train/rejected': '-108.09', 'logps_train/chosen': '-135.25', 'loss/train': '0.65884', 'examples_per_second': '5.5969', 'grad_norm': '16.875', 'counters/examples': 9920, 'counters/updates': 620}
Running evaluation after 9920 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 9920: {'rewards_eval/chosen': '-0.24739', 'rewards_eval/rejected': '-0.29085', 'rewards_eval/accuracies': '0.51562', 'rewards_eval/margins': '0.043415', 'logps_eval/rejected': '-125.06', 'logps_eval/chosen': '-120.97', 'loss/eval': '0.68242'}
skipping logging after 9936 examples to avoid logging too frequently
skipping logging after 9952 examples to avoid logging too frequently
skipping logging after 9968 examples to avoid logging too frequently
train stats after 9984 examples: {'rewards_train/chosen': '-0.27003', 'rewards_train/rejected': '-0.29549', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.025447', 'logps_train/rejected': '-116.49', 'logps_train/chosen': '-94.118', 'loss/train': '0.69312', 'examples_per_second': '6.3092', 'grad_norm': '16.625', 'counters/examples': 9984, 'counters/updates': 624}
skipping logging after 10000 examples to avoid logging too frequently
skipping logging after 10016 examples to avoid logging too frequently
skipping logging after 10032 examples to avoid logging too frequently
train stats after 10048 examples: {'rewards_train/chosen': '-0.19303', 'rewards_train/rejected': '-0.34325', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.15032', 'logps_train/rejected': '-105.11', 'logps_train/chosen': '-107.71', 'loss/train': '0.6315', 'examples_per_second': '5.2173', 'grad_norm': '16.625', 'counters/examples': 10048, 'counters/updates': 628}
skipping logging after 10064 examples to avoid logging too frequently
skipping logging after 10080 examples to avoid logging too frequently
skipping logging after 10096 examples to avoid logging too frequently
train stats after 10112 examples: {'rewards_train/chosen': '-0.28798', 'rewards_train/rejected': '-0.29434', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.006279', 'logps_train/rejected': '-117.99', 'logps_train/chosen': '-120.8', 'loss/train': '0.70749', 'examples_per_second': '5.2325', 'grad_norm': '18.25', 'counters/examples': 10112, 'counters/updates': 632}
skipping logging after 10128 examples to avoid logging too frequently
skipping logging after 10144 examples to avoid logging too frequently
skipping logging after 10160 examples to avoid logging too frequently
train stats after 10176 examples: {'rewards_train/chosen': '-0.25249', 'rewards_train/rejected': '-0.39936', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.14687', 'logps_train/rejected': '-114.94', 'logps_train/chosen': '-130.78', 'loss/train': '0.63705', 'examples_per_second': '5.26', 'grad_norm': '16.75', 'counters/examples': 10176, 'counters/updates': 636}
skipping logging after 10192 examples to avoid logging too frequently
skipping logging after 10208 examples to avoid logging too frequently
skipping logging after 10224 examples to avoid logging too frequently
train stats after 10240 examples: {'rewards_train/chosen': '-0.35651', 'rewards_train/rejected': '-0.36162', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.005043', 'logps_train/rejected': '-124.09', 'logps_train/chosen': '-148.2', 'loss/train': '0.70474', 'examples_per_second': '5.9359', 'grad_norm': '22', 'counters/examples': 10240, 'counters/updates': 640}
skipping logging after 10256 examples to avoid logging too frequently
skipping logging after 10272 examples to avoid logging too frequently
skipping logging after 10288 examples to avoid logging too frequently
train stats after 10304 examples: {'rewards_train/chosen': '-0.31089', 'rewards_train/rejected': '-0.3535', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.042625', 'logps_train/rejected': '-113.39', 'logps_train/chosen': '-119.49', 'loss/train': '0.68118', 'examples_per_second': '4.9449', 'grad_norm': '18.375', 'counters/examples': 10304, 'counters/updates': 644}
skipping logging after 10320 examples to avoid logging too frequently
skipping logging after 10336 examples to avoid logging too frequently
skipping logging after 10352 examples to avoid logging too frequently
train stats after 10368 examples: {'rewards_train/chosen': '-0.3665', 'rewards_train/rejected': '-0.46458', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.09814', 'logps_train/rejected': '-111.54', 'logps_train/chosen': '-107.33', 'loss/train': '0.65466', 'examples_per_second': '5.3582', 'grad_norm': '16.625', 'counters/examples': 10368, 'counters/updates': 648}
skipping logging after 10384 examples to avoid logging too frequently
skipping logging after 10400 examples to avoid logging too frequently
skipping logging after 10416 examples to avoid logging too frequently
train stats after 10432 examples: {'rewards_train/chosen': '-0.30977', 'rewards_train/rejected': '-0.35244', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.042591', 'logps_train/rejected': '-116.64', 'logps_train/chosen': '-120.32', 'loss/train': '0.6825', 'examples_per_second': '5.0948', 'grad_norm': '14.688', 'counters/examples': 10432, 'counters/updates': 652}
skipping logging after 10448 examples to avoid logging too frequently
skipping logging after 10464 examples to avoid logging too frequently
skipping logging after 10480 examples to avoid logging too frequently
train stats after 10496 examples: {'rewards_train/chosen': '-0.28179', 'rewards_train/rejected': '-0.35038', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.068571', 'logps_train/rejected': '-124.21', 'logps_train/chosen': '-133.03', 'loss/train': '0.66797', 'examples_per_second': '4.5598', 'grad_norm': '16.25', 'counters/examples': 10496, 'counters/updates': 656}
skipping logging after 10512 examples to avoid logging too frequently
skipping logging after 10528 examples to avoid logging too frequently
skipping logging after 10544 examples to avoid logging too frequently
train stats after 10560 examples: {'rewards_train/chosen': '-0.37142', 'rewards_train/rejected': '-0.46526', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.093767', 'logps_train/rejected': '-110.87', 'logps_train/chosen': '-114.98', 'loss/train': '0.65741', 'examples_per_second': '5.5913', 'grad_norm': '17.875', 'counters/examples': 10560, 'counters/updates': 660}
skipping logging after 10576 examples to avoid logging too frequently
skipping logging after 10592 examples to avoid logging too frequently
skipping logging after 10608 examples to avoid logging too frequently
train stats after 10624 examples: {'rewards_train/chosen': '-0.32195', 'rewards_train/rejected': '-0.33156', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.0096083', 'logps_train/rejected': '-103.89', 'logps_train/chosen': '-120.79', 'loss/train': '0.69724', 'examples_per_second': '4.8259', 'grad_norm': '16.5', 'counters/examples': 10624, 'counters/updates': 664}
skipping logging after 10640 examples to avoid logging too frequently
skipping logging after 10656 examples to avoid logging too frequently
skipping logging after 10672 examples to avoid logging too frequently
train stats after 10688 examples: {'rewards_train/chosen': '-0.32188', 'rewards_train/rejected': '-0.41254', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.09058', 'logps_train/rejected': '-129.3', 'logps_train/chosen': '-123.82', 'loss/train': '0.66037', 'examples_per_second': '5.2302', 'grad_norm': '15.812', 'counters/examples': 10688, 'counters/updates': 668}
skipping logging after 10704 examples to avoid logging too frequently
skipping logging after 10720 examples to avoid logging too frequently
skipping logging after 10736 examples to avoid logging too frequently
train stats after 10752 examples: {'rewards_train/chosen': '-0.36223', 'rewards_train/rejected': '-0.32884', 'rewards_train/accuracies': '0.375', 'rewards_train/margins': '-0.033394', 'logps_train/rejected': '-119.82', 'logps_train/chosen': '-124.39', 'loss/train': '0.71838', 'examples_per_second': '4.528', 'grad_norm': '16.75', 'counters/examples': 10752, 'counters/updates': 672}
skipping logging after 10768 examples to avoid logging too frequently
skipping logging after 10784 examples to avoid logging too frequently
skipping logging after 10800 examples to avoid logging too frequently
train stats after 10816 examples: {'rewards_train/chosen': '-0.22145', 'rewards_train/rejected': '-0.36209', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.1407', 'logps_train/rejected': '-115.23', 'logps_train/chosen': '-114.19', 'loss/train': '0.63753', 'examples_per_second': '4.8733', 'grad_norm': '16.25', 'counters/examples': 10816, 'counters/updates': 676}
skipping logging after 10832 examples to avoid logging too frequently
skipping logging after 10848 examples to avoid logging too frequently
skipping logging after 10864 examples to avoid logging too frequently
train stats after 10880 examples: {'rewards_train/chosen': '-0.23066', 'rewards_train/rejected': '-0.30176', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.071178', 'logps_train/rejected': '-121.12', 'logps_train/chosen': '-125.44', 'loss/train': '0.66794', 'examples_per_second': '4.3524', 'grad_norm': '16', 'counters/examples': 10880, 'counters/updates': 680}
skipping logging after 10896 examples to avoid logging too frequently
skipping logging after 10912 examples to avoid logging too frequently
Running evaluation after 10912 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:09,  2.24s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:03,  2.13s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.89s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.88s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.54s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 10912: {'rewards_eval/chosen': '-0.25205', 'rewards_eval/rejected': '-0.30124', 'rewards_eval/accuracies': '0.52539', 'rewards_eval/margins': '0.049197', 'logps_eval/rejected': '-125.17', 'logps_eval/chosen': '-121.01', 'loss/eval': '0.6807'}
skipping logging after 10928 examples to avoid logging too frequently
train stats after 10944 examples: {'rewards_train/chosen': '-0.28703', 'rewards_train/rejected': '-0.36213', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.075127', 'logps_train/rejected': '-103.55', 'logps_train/chosen': '-110.5', 'loss/train': '0.6716', 'examples_per_second': '4.356', 'grad_norm': '14.5', 'counters/examples': 10944, 'counters/updates': 684}
skipping logging after 10960 examples to avoid logging too frequently
skipping logging after 10976 examples to avoid logging too frequently
skipping logging after 10992 examples to avoid logging too frequently
train stats after 11008 examples: {'rewards_train/chosen': '-0.21326', 'rewards_train/rejected': '-0.27422', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.060959', 'logps_train/rejected': '-168.47', 'logps_train/chosen': '-140.39', 'loss/train': '0.67572', 'examples_per_second': '4.7016', 'grad_norm': '19.75', 'counters/examples': 11008, 'counters/updates': 688}
skipping logging after 11024 examples to avoid logging too frequently
skipping logging after 11040 examples to avoid logging too frequently
skipping logging after 11056 examples to avoid logging too frequently
train stats after 11072 examples: {'rewards_train/chosen': '-0.23948', 'rewards_train/rejected': '-0.3298', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.090328', 'logps_train/rejected': '-131.29', 'logps_train/chosen': '-122.85', 'loss/train': '0.66324', 'examples_per_second': '4.6627', 'grad_norm': '16.375', 'counters/examples': 11072, 'counters/updates': 692}
skipping logging after 11088 examples to avoid logging too frequently
skipping logging after 11104 examples to avoid logging too frequently
skipping logging after 11120 examples to avoid logging too frequently
train stats after 11136 examples: {'rewards_train/chosen': '-0.24513', 'rewards_train/rejected': '-0.29993', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.054852', 'logps_train/rejected': '-113.84', 'logps_train/chosen': '-124.43', 'loss/train': '0.68304', 'examples_per_second': '4.7013', 'grad_norm': '16.5', 'counters/examples': 11136, 'counters/updates': 696}
skipping logging after 11152 examples to avoid logging too frequently
skipping logging after 11168 examples to avoid logging too frequently
skipping logging after 11184 examples to avoid logging too frequently
train stats after 11200 examples: {'rewards_train/chosen': '-0.30404', 'rewards_train/rejected': '-0.32761', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.023563', 'logps_train/rejected': '-94.042', 'logps_train/chosen': '-81.232', 'loss/train': '0.68982', 'examples_per_second': '5.9716', 'grad_norm': '14', 'counters/examples': 11200, 'counters/updates': 700}
skipping logging after 11216 examples to avoid logging too frequently
skipping logging after 11232 examples to avoid logging too frequently
skipping logging after 11248 examples to avoid logging too frequently
train stats after 11264 examples: {'rewards_train/chosen': '-0.31249', 'rewards_train/rejected': '-0.34093', 'rewards_train/accuracies': '0.42188', 'rewards_train/margins': '0.02849', 'logps_train/rejected': '-110.18', 'logps_train/chosen': '-106.1', 'loss/train': '0.68884', 'examples_per_second': '5.2308', 'grad_norm': '17.375', 'counters/examples': 11264, 'counters/updates': 704}
skipping logging after 11280 examples to avoid logging too frequently
skipping logging after 11296 examples to avoid logging too frequently
skipping logging after 11312 examples to avoid logging too frequently
train stats after 11328 examples: {'rewards_train/chosen': '-0.22085', 'rewards_train/rejected': '-0.22956', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.008688', 'logps_train/rejected': '-150.6', 'logps_train/chosen': '-149.14', 'loss/train': '0.69879', 'examples_per_second': '4.6551', 'grad_norm': '21.5', 'counters/examples': 11328, 'counters/updates': 708}
skipping logging after 11344 examples to avoid logging too frequently
skipping logging after 11360 examples to avoid logging too frequently
skipping logging after 11376 examples to avoid logging too frequently
train stats after 11392 examples: {'rewards_train/chosen': '-0.18369', 'rewards_train/rejected': '-0.23596', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.052227', 'logps_train/rejected': '-114.27', 'logps_train/chosen': '-122.66', 'loss/train': '0.67603', 'examples_per_second': '6.1087', 'grad_norm': '15.875', 'counters/examples': 11392, 'counters/updates': 712}
skipping logging after 11408 examples to avoid logging too frequently
skipping logging after 11424 examples to avoid logging too frequently
skipping logging after 11440 examples to avoid logging too frequently
train stats after 11456 examples: {'rewards_train/chosen': '-0.178', 'rewards_train/rejected': '-0.26399', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.086013', 'logps_train/rejected': '-125.15', 'logps_train/chosen': '-126.59', 'loss/train': '0.66629', 'examples_per_second': '4.431', 'grad_norm': '18.125', 'counters/examples': 11456, 'counters/updates': 716}
skipping logging after 11472 examples to avoid logging too frequently
skipping logging after 11488 examples to avoid logging too frequently
skipping logging after 11504 examples to avoid logging too frequently
train stats after 11520 examples: {'rewards_train/chosen': '-0.29615', 'rewards_train/rejected': '-0.31016', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.014057', 'logps_train/rejected': '-105.87', 'logps_train/chosen': '-105.63', 'loss/train': '0.69287', 'examples_per_second': '6.4006', 'grad_norm': '14.938', 'counters/examples': 11520, 'counters/updates': 720}
skipping logging after 11536 examples to avoid logging too frequently
skipping logging after 11552 examples to avoid logging too frequently
skipping logging after 11568 examples to avoid logging too frequently
train stats after 11584 examples: {'rewards_train/chosen': '-0.18079', 'rewards_train/rejected': '-0.21474', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.033895', 'logps_train/rejected': '-117.81', 'logps_train/chosen': '-115.95', 'loss/train': '0.6955', 'examples_per_second': '4.6643', 'grad_norm': '18.625', 'counters/examples': 11584, 'counters/updates': 724}
skipping logging after 11600 examples to avoid logging too frequently
skipping logging after 11616 examples to avoid logging too frequently
skipping logging after 11632 examples to avoid logging too frequently
train stats after 11648 examples: {'rewards_train/chosen': '-0.24716', 'rewards_train/rejected': '-0.24651', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '-0.00070381', 'logps_train/rejected': '-117.04', 'logps_train/chosen': '-110.73', 'loss/train': '0.69992', 'examples_per_second': '4.6565', 'grad_norm': '15.562', 'counters/examples': 11648, 'counters/updates': 728}
skipping logging after 11664 examples to avoid logging too frequently
skipping logging after 11680 examples to avoid logging too frequently
skipping logging after 11696 examples to avoid logging too frequently
train stats after 11712 examples: {'rewards_train/chosen': '-0.15626', 'rewards_train/rejected': '-0.15212', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '-0.0040779', 'logps_train/rejected': '-137.39', 'logps_train/chosen': '-118.99', 'loss/train': '0.7019', 'examples_per_second': '5.414', 'grad_norm': '16.625', 'counters/examples': 11712, 'counters/updates': 732}
skipping logging after 11728 examples to avoid logging too frequently
skipping logging after 11744 examples to avoid logging too frequently
skipping logging after 11760 examples to avoid logging too frequently
train stats after 11776 examples: {'rewards_train/chosen': '-0.16714', 'rewards_train/rejected': '-0.20865', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.041535', 'logps_train/rejected': '-103.46', 'logps_train/chosen': '-106.45', 'loss/train': '0.68137', 'examples_per_second': '5.644', 'grad_norm': '16.625', 'counters/examples': 11776, 'counters/updates': 736}
skipping logging after 11792 examples to avoid logging too frequently
skipping logging after 11808 examples to avoid logging too frequently
skipping logging after 11824 examples to avoid logging too frequently
train stats after 11840 examples: {'rewards_train/chosen': '-0.15561', 'rewards_train/rejected': '-0.26286', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.10716', 'logps_train/rejected': '-138.35', 'logps_train/chosen': '-144.13', 'loss/train': '0.65479', 'examples_per_second': '4.828', 'grad_norm': '19.125', 'counters/examples': 11840, 'counters/updates': 740}
skipping logging after 11856 examples to avoid logging too frequently
skipping logging after 11872 examples to avoid logging too frequently
skipping logging after 11888 examples to avoid logging too frequently
train stats after 11904 examples: {'rewards_train/chosen': '-0.20377', 'rewards_train/rejected': '-0.25401', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.050268', 'logps_train/rejected': '-137.37', 'logps_train/chosen': '-133.59', 'loss/train': '0.67624', 'examples_per_second': '4.8317', 'grad_norm': '15.375', 'counters/examples': 11904, 'counters/updates': 744}
Running evaluation after 11904 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 11904: {'rewards_eval/chosen': '-0.19728', 'rewards_eval/rejected': '-0.24642', 'rewards_eval/accuracies': '0.50977', 'rewards_eval/margins': '0.049152', 'logps_eval/rejected': '-124.62', 'logps_eval/chosen': '-120.47', 'loss/eval': '0.67894'}
skipping logging after 11920 examples to avoid logging too frequently
skipping logging after 11936 examples to avoid logging too frequently
skipping logging after 11952 examples to avoid logging too frequently
train stats after 11968 examples: {'rewards_train/chosen': '-0.21084', 'rewards_train/rejected': '-0.28271', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.071833', 'logps_train/rejected': '-114.39', 'logps_train/chosen': '-138.24', 'loss/train': '0.66736', 'examples_per_second': '4.9919', 'grad_norm': '17.375', 'counters/examples': 11968, 'counters/updates': 748}
skipping logging after 11984 examples to avoid logging too frequently
skipping logging after 12000 examples to avoid logging too frequently
skipping logging after 12016 examples to avoid logging too frequently
train stats after 12032 examples: {'rewards_train/chosen': '-0.25706', 'rewards_train/rejected': '-0.29506', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '0.037939', 'logps_train/rejected': '-134.83', 'logps_train/chosen': '-140.26', 'loss/train': '0.68707', 'examples_per_second': '5.1182', 'grad_norm': '16.5', 'counters/examples': 12032, 'counters/updates': 752}
skipping logging after 12048 examples to avoid logging too frequently
skipping logging after 12064 examples to avoid logging too frequently
skipping logging after 12080 examples to avoid logging too frequently
train stats after 12096 examples: {'rewards_train/chosen': '-0.2749', 'rewards_train/rejected': '-0.35492', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.080006', 'logps_train/rejected': '-117.5', 'logps_train/chosen': '-115.78', 'loss/train': '0.66542', 'examples_per_second': '5.5743', 'grad_norm': '15.125', 'counters/examples': 12096, 'counters/updates': 756}
skipping logging after 12112 examples to avoid logging too frequently
skipping logging after 12128 examples to avoid logging too frequently
skipping logging after 12144 examples to avoid logging too frequently
train stats after 12160 examples: {'rewards_train/chosen': '-0.23838', 'rewards_train/rejected': '-0.30231', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.063911', 'logps_train/rejected': '-132.17', 'logps_train/chosen': '-130.94', 'loss/train': '0.67026', 'examples_per_second': '4.9768', 'grad_norm': '16.375', 'counters/examples': 12160, 'counters/updates': 760}
skipping logging after 12176 examples to avoid logging too frequently
skipping logging after 12192 examples to avoid logging too frequently
skipping logging after 12208 examples to avoid logging too frequently
train stats after 12224 examples: {'rewards_train/chosen': '-0.25773', 'rewards_train/rejected': '-0.31763', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.059871', 'logps_train/rejected': '-122.13', 'logps_train/chosen': '-104.04', 'loss/train': '0.67181', 'examples_per_second': '5.6218', 'grad_norm': '17.625', 'counters/examples': 12224, 'counters/updates': 764}
skipping logging after 12240 examples to avoid logging too frequently
skipping logging after 12256 examples to avoid logging too frequently
skipping logging after 12272 examples to avoid logging too frequently
train stats after 12288 examples: {'rewards_train/chosen': '-0.22088', 'rewards_train/rejected': '-0.21917', 'rewards_train/accuracies': '0.40625', 'rewards_train/margins': '-0.0017414', 'logps_train/rejected': '-115.57', 'logps_train/chosen': '-117.68', 'loss/train': '0.7052', 'examples_per_second': '5.1719', 'grad_norm': '14.688', 'counters/examples': 12288, 'counters/updates': 768}
skipping logging after 12304 examples to avoid logging too frequently
skipping logging after 12320 examples to avoid logging too frequently
skipping logging after 12336 examples to avoid logging too frequently
train stats after 12352 examples: {'rewards_train/chosen': '-0.16109', 'rewards_train/rejected': '-0.27689', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.11572', 'logps_train/rejected': '-178.7', 'logps_train/chosen': '-160.37', 'loss/train': '0.64603', 'examples_per_second': '4.4603', 'grad_norm': '21.625', 'counters/examples': 12352, 'counters/updates': 772}
skipping logging after 12368 examples to avoid logging too frequently
skipping logging after 12384 examples to avoid logging too frequently
skipping logging after 12400 examples to avoid logging too frequently
train stats after 12416 examples: {'rewards_train/chosen': '-0.26089', 'rewards_train/rejected': '-0.33099', 'rewards_train/accuracies': '0.42188', 'rewards_train/margins': '0.07008', 'logps_train/rejected': '-119.94', 'logps_train/chosen': '-130.77', 'loss/train': '0.67398', 'examples_per_second': '4.2227', 'grad_norm': '15.875', 'counters/examples': 12416, 'counters/updates': 776}
skipping logging after 12432 examples to avoid logging too frequently
skipping logging after 12448 examples to avoid logging too frequently
skipping logging after 12464 examples to avoid logging too frequently
train stats after 12480 examples: {'rewards_train/chosen': '-0.25235', 'rewards_train/rejected': '-0.33608', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.083772', 'logps_train/rejected': '-123.56', 'logps_train/chosen': '-128.37', 'loss/train': '0.67204', 'examples_per_second': '4.1135', 'grad_norm': '21.375', 'counters/examples': 12480, 'counters/updates': 780}
skipping logging after 12496 examples to avoid logging too frequently
skipping logging after 12512 examples to avoid logging too frequently
skipping logging after 12528 examples to avoid logging too frequently
train stats after 12544 examples: {'rewards_train/chosen': '-0.17215', 'rewards_train/rejected': '-0.25583', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.083759', 'logps_train/rejected': '-139.95', 'logps_train/chosen': '-107.19', 'loss/train': '0.66205', 'examples_per_second': '4.6703', 'grad_norm': '21.75', 'counters/examples': 12544, 'counters/updates': 784}
skipping logging after 12560 examples to avoid logging too frequently
skipping logging after 12576 examples to avoid logging too frequently
skipping logging after 12592 examples to avoid logging too frequently
train stats after 12608 examples: {'rewards_train/chosen': '-0.21992', 'rewards_train/rejected': '-0.2497', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.029793', 'logps_train/rejected': '-131.98', 'logps_train/chosen': '-106.35', 'loss/train': '0.69016', 'examples_per_second': '4.7812', 'grad_norm': '17', 'counters/examples': 12608, 'counters/updates': 788}
skipping logging after 12624 examples to avoid logging too frequently
skipping logging after 12640 examples to avoid logging too frequently
skipping logging after 12656 examples to avoid logging too frequently
train stats after 12672 examples: {'rewards_train/chosen': '-0.16843', 'rewards_train/rejected': '-0.22932', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.060884', 'logps_train/rejected': '-131.75', 'logps_train/chosen': '-119.45', 'loss/train': '0.67581', 'examples_per_second': '4.5097', 'grad_norm': '16', 'counters/examples': 12672, 'counters/updates': 792}
skipping logging after 12688 examples to avoid logging too frequently
skipping logging after 12704 examples to avoid logging too frequently
skipping logging after 12720 examples to avoid logging too frequently
train stats after 12736 examples: {'rewards_train/chosen': '-0.19635', 'rewards_train/rejected': '-0.26288', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.066648', 'logps_train/rejected': '-110.41', 'logps_train/chosen': '-125.73', 'loss/train': '0.67752', 'examples_per_second': '4.6074', 'grad_norm': '19.125', 'counters/examples': 12736, 'counters/updates': 796}
skipping logging after 12752 examples to avoid logging too frequently
skipping logging after 12768 examples to avoid logging too frequently
skipping logging after 12784 examples to avoid logging too frequently
train stats after 12800 examples: {'rewards_train/chosen': '-0.17197', 'rewards_train/rejected': '-0.27732', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.10543', 'logps_train/rejected': '-120.79', 'logps_train/chosen': '-131.59', 'loss/train': '0.65704', 'examples_per_second': '5.4289', 'grad_norm': '15.75', 'counters/examples': 12800, 'counters/updates': 800}
skipping logging after 12816 examples to avoid logging too frequently
skipping logging after 12832 examples to avoid logging too frequently
skipping logging after 12848 examples to avoid logging too frequently
train stats after 12864 examples: {'rewards_train/chosen': '-0.22357', 'rewards_train/rejected': '-0.32913', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.10558', 'logps_train/rejected': '-114.69', 'logps_train/chosen': '-139.52', 'loss/train': '0.65173', 'examples_per_second': '4.4892', 'grad_norm': '17.625', 'counters/examples': 12864, 'counters/updates': 804}
skipping logging after 12880 examples to avoid logging too frequently
skipping logging after 12896 examples to avoid logging too frequently
Running evaluation after 12896 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:18,  2.52s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:07,  2.24s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:56,  1.95s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:08<00:53,  1.91s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.55s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.65s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 12896: {'rewards_eval/chosen': '-0.23999', 'rewards_eval/rejected': '-0.29953', 'rewards_eval/accuracies': '0.5332', 'rewards_eval/margins': '0.059582', 'logps_eval/rejected': '-125.15', 'logps_eval/chosen': '-120.89', 'loss/eval': '0.67711'}
skipping logging after 12912 examples to avoid logging too frequently
train stats after 12928 examples: {'rewards_train/chosen': '-0.15041', 'rewards_train/rejected': '-0.26706', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.11661', 'logps_train/rejected': '-113.61', 'logps_train/chosen': '-122.21', 'loss/train': '0.64914', 'examples_per_second': '5.4887', 'grad_norm': '17', 'counters/examples': 12928, 'counters/updates': 808}
skipping logging after 12944 examples to avoid logging too frequently
skipping logging after 12960 examples to avoid logging too frequently
skipping logging after 12976 examples to avoid logging too frequently
train stats after 12992 examples: {'rewards_train/chosen': '-0.20017', 'rewards_train/rejected': '-0.31631', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.11617', 'logps_train/rejected': '-103.66', 'logps_train/chosen': '-126.78', 'loss/train': '0.65138', 'examples_per_second': '5.0988', 'grad_norm': '15.438', 'counters/examples': 12992, 'counters/updates': 812}
skipping logging after 13008 examples to avoid logging too frequently
skipping logging after 13024 examples to avoid logging too frequently
skipping logging after 13040 examples to avoid logging too frequently
train stats after 13056 examples: {'rewards_train/chosen': '-0.25618', 'rewards_train/rejected': '-0.3853', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.12922', 'logps_train/rejected': '-103.24', 'logps_train/chosen': '-106.65', 'loss/train': '0.65007', 'examples_per_second': '5.6741', 'grad_norm': '14.5', 'counters/examples': 13056, 'counters/updates': 816}
skipping logging after 13072 examples to avoid logging too frequently
skipping logging after 13088 examples to avoid logging too frequently
skipping logging after 13104 examples to avoid logging too frequently
train stats after 13120 examples: {'rewards_train/chosen': '-0.26199', 'rewards_train/rejected': '-0.32795', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.066059', 'logps_train/rejected': '-110.95', 'logps_train/chosen': '-105.16', 'loss/train': '0.67334', 'examples_per_second': '4.8673', 'grad_norm': '16.75', 'counters/examples': 13120, 'counters/updates': 820}
skipping logging after 13136 examples to avoid logging too frequently
skipping logging after 13152 examples to avoid logging too frequently
skipping logging after 13168 examples to avoid logging too frequently
train stats after 13184 examples: {'rewards_train/chosen': '-0.23725', 'rewards_train/rejected': '-0.26151', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.024282', 'logps_train/rejected': '-123.91', 'logps_train/chosen': '-105.94', 'loss/train': '0.70108', 'examples_per_second': '4.4701', 'grad_norm': '16.125', 'counters/examples': 13184, 'counters/updates': 824}
skipping logging after 13200 examples to avoid logging too frequently
skipping logging after 13216 examples to avoid logging too frequently
skipping logging after 13232 examples to avoid logging too frequently
train stats after 13248 examples: {'rewards_train/chosen': '-0.13517', 'rewards_train/rejected': '-0.31879', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.18361', 'logps_train/rejected': '-115.5', 'logps_train/chosen': '-114.46', 'loss/train': '0.63895', 'examples_per_second': '4.9034', 'grad_norm': '15.938', 'counters/examples': 13248, 'counters/updates': 828}
skipping logging after 13264 examples to avoid logging too frequently
skipping logging after 13280 examples to avoid logging too frequently
skipping logging after 13296 examples to avoid logging too frequently
train stats after 13312 examples: {'rewards_train/chosen': '-0.24673', 'rewards_train/rejected': '-0.31413', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.067414', 'logps_train/rejected': '-124.06', 'logps_train/chosen': '-111.51', 'loss/train': '0.68323', 'examples_per_second': '5.8352', 'grad_norm': '22.375', 'counters/examples': 13312, 'counters/updates': 832}
skipping logging after 13328 examples to avoid logging too frequently
skipping logging after 13344 examples to avoid logging too frequently
skipping logging after 13360 examples to avoid logging too frequently
train stats after 13376 examples: {'rewards_train/chosen': '-0.29766', 'rewards_train/rejected': '-0.49234', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.19474', 'logps_train/rejected': '-105.58', 'logps_train/chosen': '-113.8', 'loss/train': '0.62263', 'examples_per_second': '5.9664', 'grad_norm': '14.438', 'counters/examples': 13376, 'counters/updates': 836}
skipping logging after 13392 examples to avoid logging too frequently
skipping logging after 13408 examples to avoid logging too frequently
skipping logging after 13424 examples to avoid logging too frequently
train stats after 13440 examples: {'rewards_train/chosen': '-0.30868', 'rewards_train/rejected': '-0.39093', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.082302', 'logps_train/rejected': '-149.21', 'logps_train/chosen': '-138.9', 'loss/train': '0.67503', 'examples_per_second': '4.3705', 'grad_norm': '19.125', 'counters/examples': 13440, 'counters/updates': 840}
skipping logging after 13456 examples to avoid logging too frequently
skipping logging after 13472 examples to avoid logging too frequently
skipping logging after 13488 examples to avoid logging too frequently
train stats after 13504 examples: {'rewards_train/chosen': '-0.31956', 'rewards_train/rejected': '-0.33658', 'rewards_train/accuracies': '0.42188', 'rewards_train/margins': '0.016979', 'logps_train/rejected': '-126.53', 'logps_train/chosen': '-131.41', 'loss/train': '0.70151', 'examples_per_second': '4.5108', 'grad_norm': '19.875', 'counters/examples': 13504, 'counters/updates': 844}
skipping logging after 13520 examples to avoid logging too frequently
skipping logging after 13536 examples to avoid logging too frequently
skipping logging after 13552 examples to avoid logging too frequently
train stats after 13568 examples: {'rewards_train/chosen': '-0.36523', 'rewards_train/rejected': '-0.40377', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.038549', 'logps_train/rejected': '-146.49', 'logps_train/chosen': '-118.4', 'loss/train': '0.69022', 'examples_per_second': '5.5532', 'grad_norm': '19.5', 'counters/examples': 13568, 'counters/updates': 848}
skipping logging after 13584 examples to avoid logging too frequently
skipping logging after 13600 examples to avoid logging too frequently
skipping logging after 13616 examples to avoid logging too frequently
train stats after 13632 examples: {'rewards_train/chosen': '-0.30581', 'rewards_train/rejected': '-0.30375', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '-0.0019951', 'logps_train/rejected': '-116.03', 'logps_train/chosen': '-105.81', 'loss/train': '0.70352', 'examples_per_second': '4.8447', 'grad_norm': '15.25', 'counters/examples': 13632, 'counters/updates': 852}
skipping logging after 13648 examples to avoid logging too frequently
skipping logging after 13664 examples to avoid logging too frequently
skipping logging after 13680 examples to avoid logging too frequently
train stats after 13696 examples: {'rewards_train/chosen': '-0.31587', 'rewards_train/rejected': '-0.37269', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.056854', 'logps_train/rejected': '-145.9', 'logps_train/chosen': '-141.95', 'loss/train': '0.68713', 'examples_per_second': '4.6162', 'grad_norm': '17.75', 'counters/examples': 13696, 'counters/updates': 856}
skipping logging after 13712 examples to avoid logging too frequently
skipping logging after 13728 examples to avoid logging too frequently
skipping logging after 13744 examples to avoid logging too frequently
train stats after 13760 examples: {'rewards_train/chosen': '-0.18958', 'rewards_train/rejected': '-0.34832', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.15882', 'logps_train/rejected': '-124.62', 'logps_train/chosen': '-145.11', 'loss/train': '0.62744', 'examples_per_second': '4.8974', 'grad_norm': '20.625', 'counters/examples': 13760, 'counters/updates': 860}
skipping logging after 13776 examples to avoid logging too frequently
skipping logging after 13792 examples to avoid logging too frequently
skipping logging after 13808 examples to avoid logging too frequently
train stats after 13824 examples: {'rewards_train/chosen': '-0.35729', 'rewards_train/rejected': '-0.42177', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.064417', 'logps_train/rejected': '-111.06', 'logps_train/chosen': '-120.82', 'loss/train': '0.68315', 'examples_per_second': '5.5151', 'grad_norm': '16.875', 'counters/examples': 13824, 'counters/updates': 864}
skipping logging after 13840 examples to avoid logging too frequently
skipping logging after 13856 examples to avoid logging too frequently
skipping logging after 13872 examples to avoid logging too frequently
train stats after 13888 examples: {'rewards_train/chosen': '-0.38625', 'rewards_train/rejected': '-0.3849', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '-0.0013447', 'logps_train/rejected': '-137.92', 'logps_train/chosen': '-140.54', 'loss/train': '0.70758', 'examples_per_second': '5.894', 'grad_norm': '20.875', 'counters/examples': 13888, 'counters/updates': 868}
Running evaluation after 13888 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<01:00,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:53,  1.83s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.63s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.25s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 13888: {'rewards_eval/chosen': '-0.29274', 'rewards_eval/rejected': '-0.35899', 'rewards_eval/accuracies': '0.53125', 'rewards_eval/margins': '0.066262', 'logps_eval/rejected': '-125.75', 'logps_eval/chosen': '-121.42', 'loss/eval': '0.67657'}
skipping logging after 13904 examples to avoid logging too frequently
skipping logging after 13920 examples to avoid logging too frequently
skipping logging after 13936 examples to avoid logging too frequently
train stats after 13952 examples: {'rewards_train/chosen': '-0.35455', 'rewards_train/rejected': '-0.37016', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '0.015503', 'logps_train/rejected': '-107.69', 'logps_train/chosen': '-99.687', 'loss/train': '0.70067', 'examples_per_second': '5.0451', 'grad_norm': '14.25', 'counters/examples': 13952, 'counters/updates': 872}
skipping logging after 13968 examples to avoid logging too frequently
skipping logging after 13984 examples to avoid logging too frequently
skipping logging after 14000 examples to avoid logging too frequently
train stats after 14016 examples: {'rewards_train/chosen': '-0.27209', 'rewards_train/rejected': '-0.31647', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.04439', 'logps_train/rejected': '-142.15', 'logps_train/chosen': '-150.1', 'loss/train': '0.68448', 'examples_per_second': '4.6778', 'grad_norm': '19.5', 'counters/examples': 14016, 'counters/updates': 876}
skipping logging after 14032 examples to avoid logging too frequently
skipping logging after 14048 examples to avoid logging too frequently
skipping logging after 14064 examples to avoid logging too frequently
train stats after 14080 examples: {'rewards_train/chosen': '-0.29901', 'rewards_train/rejected': '-0.4013', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.10232', 'logps_train/rejected': '-109.36', 'logps_train/chosen': '-133.7', 'loss/train': '0.65878', 'examples_per_second': '4.8923', 'grad_norm': '17.125', 'counters/examples': 14080, 'counters/updates': 880}
skipping logging after 14096 examples to avoid logging too frequently
skipping logging after 14112 examples to avoid logging too frequently
skipping logging after 14128 examples to avoid logging too frequently
train stats after 14144 examples: {'rewards_train/chosen': '-0.29711', 'rewards_train/rejected': '-0.38918', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.092103', 'logps_train/rejected': '-110.78', 'logps_train/chosen': '-119.63', 'loss/train': '0.66321', 'examples_per_second': '4.6284', 'grad_norm': '15.25', 'counters/examples': 14144, 'counters/updates': 884}
skipping logging after 14160 examples to avoid logging too frequently
skipping logging after 14176 examples to avoid logging too frequently
skipping logging after 14192 examples to avoid logging too frequently
train stats after 14208 examples: {'rewards_train/chosen': '-0.21697', 'rewards_train/rejected': '-0.34563', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.12859', 'logps_train/rejected': '-107.48', 'logps_train/chosen': '-115.15', 'loss/train': '0.64236', 'examples_per_second': '4.8856', 'grad_norm': '18.625', 'counters/examples': 14208, 'counters/updates': 888}
skipping logging after 14224 examples to avoid logging too frequently
skipping logging after 14240 examples to avoid logging too frequently
skipping logging after 14256 examples to avoid logging too frequently
train stats after 14272 examples: {'rewards_train/chosen': '-0.25006', 'rewards_train/rejected': '-0.40187', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.15169', 'logps_train/rejected': '-121.12', 'logps_train/chosen': '-125.73', 'loss/train': '0.64389', 'examples_per_second': '5.4085', 'grad_norm': '15.75', 'counters/examples': 14272, 'counters/updates': 892}
skipping logging after 14288 examples to avoid logging too frequently
skipping logging after 14304 examples to avoid logging too frequently
skipping logging after 14320 examples to avoid logging too frequently
train stats after 14336 examples: {'rewards_train/chosen': '-0.28054', 'rewards_train/rejected': '-0.45487', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.17429', 'logps_train/rejected': '-98.331', 'logps_train/chosen': '-87.755', 'loss/train': '0.62741', 'examples_per_second': '5.4342', 'grad_norm': '14.875', 'counters/examples': 14336, 'counters/updates': 896}
skipping logging after 14352 examples to avoid logging too frequently
skipping logging after 14368 examples to avoid logging too frequently
skipping logging after 14384 examples to avoid logging too frequently
train stats after 14400 examples: {'rewards_train/chosen': '-0.34627', 'rewards_train/rejected': '-0.43005', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.083885', 'logps_train/rejected': '-116.93', 'logps_train/chosen': '-113', 'loss/train': '0.67392', 'examples_per_second': '4.4695', 'grad_norm': '16', 'counters/examples': 14400, 'counters/updates': 900}
skipping logging after 14416 examples to avoid logging too frequently
skipping logging after 14432 examples to avoid logging too frequently
skipping logging after 14448 examples to avoid logging too frequently
train stats after 14464 examples: {'rewards_train/chosen': '-0.42701', 'rewards_train/rejected': '-0.47188', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.044872', 'logps_train/rejected': '-106.04', 'logps_train/chosen': '-133.19', 'loss/train': '0.69543', 'examples_per_second': '5.0235', 'grad_norm': '21.125', 'counters/examples': 14464, 'counters/updates': 904}
skipping logging after 14480 examples to avoid logging too frequently
skipping logging after 14496 examples to avoid logging too frequently
skipping logging after 14512 examples to avoid logging too frequently
train stats after 14528 examples: {'rewards_train/chosen': '-0.39545', 'rewards_train/rejected': '-0.50269', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.10717', 'logps_train/rejected': '-141.4', 'logps_train/chosen': '-142.04', 'loss/train': '0.65918', 'examples_per_second': '5.4754', 'grad_norm': '21.375', 'counters/examples': 14528, 'counters/updates': 908}
skipping logging after 14544 examples to avoid logging too frequently
skipping logging after 14560 examples to avoid logging too frequently
skipping logging after 14576 examples to avoid logging too frequently
train stats after 14592 examples: {'rewards_train/chosen': '-0.33996', 'rewards_train/rejected': '-0.34759', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.0076332', 'logps_train/rejected': '-127.08', 'logps_train/chosen': '-108.5', 'loss/train': '0.70181', 'examples_per_second': '5.0167', 'grad_norm': '18.375', 'counters/examples': 14592, 'counters/updates': 912}
skipping logging after 14608 examples to avoid logging too frequently
skipping logging after 14624 examples to avoid logging too frequently
skipping logging after 14640 examples to avoid logging too frequently
train stats after 14656 examples: {'rewards_train/chosen': '-0.35707', 'rewards_train/rejected': '-0.40556', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.048471', 'logps_train/rejected': '-120.71', 'logps_train/chosen': '-142.8', 'loss/train': '0.67938', 'examples_per_second': '4.7816', 'grad_norm': '16.625', 'counters/examples': 14656, 'counters/updates': 916}
skipping logging after 14672 examples to avoid logging too frequently
skipping logging after 14688 examples to avoid logging too frequently
skipping logging after 14704 examples to avoid logging too frequently
train stats after 14720 examples: {'rewards_train/chosen': '-0.28367', 'rewards_train/rejected': '-0.35655', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.072914', 'logps_train/rejected': '-122.64', 'logps_train/chosen': '-135.98', 'loss/train': '0.67175', 'examples_per_second': '5.4057', 'grad_norm': '19.25', 'counters/examples': 14720, 'counters/updates': 920}
skipping logging after 14736 examples to avoid logging too frequently
skipping logging after 14752 examples to avoid logging too frequently
skipping logging after 14768 examples to avoid logging too frequently
train stats after 14784 examples: {'rewards_train/chosen': '-0.30892', 'rewards_train/rejected': '-0.29237', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '-0.016586', 'logps_train/rejected': '-112.22', 'logps_train/chosen': '-122.44', 'loss/train': '0.71509', 'examples_per_second': '5.3278', 'grad_norm': '17.75', 'counters/examples': 14784, 'counters/updates': 924}
skipping logging after 14800 examples to avoid logging too frequently
skipping logging after 14816 examples to avoid logging too frequently
skipping logging after 14832 examples to avoid logging too frequently
train stats after 14848 examples: {'rewards_train/chosen': '-0.34154', 'rewards_train/rejected': '-0.36574', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.024193', 'logps_train/rejected': '-107.43', 'logps_train/chosen': '-120.03', 'loss/train': '0.68991', 'examples_per_second': '4.7258', 'grad_norm': '19', 'counters/examples': 14848, 'counters/updates': 928}
skipping logging after 14864 examples to avoid logging too frequently
skipping logging after 14880 examples to avoid logging too frequently
Running evaluation after 14880 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:13,  2.38s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:05,  2.18s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:55,  1.92s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.89s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.54s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 14880: {'rewards_eval/chosen': '-0.28947', 'rewards_eval/rejected': '-0.35274', 'rewards_eval/accuracies': '0.50977', 'rewards_eval/margins': '0.063279', 'logps_eval/rejected': '-125.68', 'logps_eval/chosen': '-121.39', 'loss/eval': '0.67852'}
skipping logging after 14896 examples to avoid logging too frequently
train stats after 14912 examples: {'rewards_train/chosen': '-0.39244', 'rewards_train/rejected': '-0.41653', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.024113', 'logps_train/rejected': '-127.25', 'logps_train/chosen': '-124.94', 'loss/train': '0.69357', 'examples_per_second': '5.3304', 'grad_norm': '19.625', 'counters/examples': 14912, 'counters/updates': 932}
skipping logging after 14928 examples to avoid logging too frequently
skipping logging after 14944 examples to avoid logging too frequently
skipping logging after 14960 examples to avoid logging too frequently
train stats after 14976 examples: {'rewards_train/chosen': '-0.31766', 'rewards_train/rejected': '-0.34142', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '0.023716', 'logps_train/rejected': '-127.38', 'logps_train/chosen': '-122.88', 'loss/train': '0.6983', 'examples_per_second': '4.4239', 'grad_norm': '16.25', 'counters/examples': 14976, 'counters/updates': 936}
skipping logging after 14992 examples to avoid logging too frequently
skipping logging after 15008 examples to avoid logging too frequently
skipping logging after 15024 examples to avoid logging too frequently
train stats after 15040 examples: {'rewards_train/chosen': '-0.26202', 'rewards_train/rejected': '-0.30676', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.044703', 'logps_train/rejected': '-114.11', 'logps_train/chosen': '-123.29', 'loss/train': '0.69025', 'examples_per_second': '5.938', 'grad_norm': '15.688', 'counters/examples': 15040, 'counters/updates': 940}
skipping logging after 15056 examples to avoid logging too frequently
skipping logging after 15072 examples to avoid logging too frequently
skipping logging after 15088 examples to avoid logging too frequently
train stats after 15104 examples: {'rewards_train/chosen': '-0.29043', 'rewards_train/rejected': '-0.31293', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.022511', 'logps_train/rejected': '-110.75', 'logps_train/chosen': '-102.74', 'loss/train': '0.70004', 'examples_per_second': '6.2399', 'grad_norm': '15.875', 'counters/examples': 15104, 'counters/updates': 944}
skipping logging after 15120 examples to avoid logging too frequently
skipping logging after 15136 examples to avoid logging too frequently
skipping logging after 15152 examples to avoid logging too frequently
train stats after 15168 examples: {'rewards_train/chosen': '-0.32016', 'rewards_train/rejected': '-0.22199', 'rewards_train/accuracies': '0.39062', 'rewards_train/margins': '-0.098179', 'logps_train/rejected': '-100.92', 'logps_train/chosen': '-127.56', 'loss/train': '0.75705', 'examples_per_second': '4.8058', 'grad_norm': '21.5', 'counters/examples': 15168, 'counters/updates': 948}
skipping logging after 15184 examples to avoid logging too frequently
skipping logging after 15200 examples to avoid logging too frequently
skipping logging after 15216 examples to avoid logging too frequently
train stats after 15232 examples: {'rewards_train/chosen': '-0.27127', 'rewards_train/rejected': '-0.23745', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '-0.033794', 'logps_train/rejected': '-140.73', 'logps_train/chosen': '-123.15', 'loss/train': '0.71933', 'examples_per_second': '4.8396', 'grad_norm': '17.5', 'counters/examples': 15232, 'counters/updates': 952}
skipping logging after 15248 examples to avoid logging too frequently
skipping logging after 15264 examples to avoid logging too frequently
skipping logging after 15280 examples to avoid logging too frequently
train stats after 15296 examples: {'rewards_train/chosen': '-0.15647', 'rewards_train/rejected': '-0.22191', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.065434', 'logps_train/rejected': '-99.287', 'logps_train/chosen': '-101.57', 'loss/train': '0.67264', 'examples_per_second': '5.01', 'grad_norm': '14.812', 'counters/examples': 15296, 'counters/updates': 956}
skipping logging after 15312 examples to avoid logging too frequently
skipping logging after 15328 examples to avoid logging too frequently
skipping logging after 15344 examples to avoid logging too frequently
train stats after 15360 examples: {'rewards_train/chosen': '-0.23295', 'rewards_train/rejected': '-0.25344', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '0.0205', 'logps_train/rejected': '-115.42', 'logps_train/chosen': '-137.83', 'loss/train': '0.69724', 'examples_per_second': '5.2516', 'grad_norm': '17.875', 'counters/examples': 15360, 'counters/updates': 960}
skipping logging after 15376 examples to avoid logging too frequently
skipping logging after 15392 examples to avoid logging too frequently
skipping logging after 15408 examples to avoid logging too frequently
train stats after 15424 examples: {'rewards_train/chosen': '-0.18007', 'rewards_train/rejected': '-0.28238', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.10236', 'logps_train/rejected': '-104.57', 'logps_train/chosen': '-111.2', 'loss/train': '0.65396', 'examples_per_second': '4.5448', 'grad_norm': '14.312', 'counters/examples': 15424, 'counters/updates': 964}
skipping logging after 15440 examples to avoid logging too frequently
skipping logging after 15456 examples to avoid logging too frequently
skipping logging after 15472 examples to avoid logging too frequently
train stats after 15488 examples: {'rewards_train/chosen': '-0.19957', 'rewards_train/rejected': '-0.22751', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.02787', 'logps_train/rejected': '-125.51', 'logps_train/chosen': '-128.42', 'loss/train': '0.69247', 'examples_per_second': '4.5679', 'grad_norm': '16.625', 'counters/examples': 15488, 'counters/updates': 968}
skipping logging after 15504 examples to avoid logging too frequently
skipping logging after 15520 examples to avoid logging too frequently
skipping logging after 15536 examples to avoid logging too frequently
train stats after 15552 examples: {'rewards_train/chosen': '-0.19782', 'rewards_train/rejected': '-0.31555', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.11774', 'logps_train/rejected': '-141.9', 'logps_train/chosen': '-123.43', 'loss/train': '0.64908', 'examples_per_second': '5.9738', 'grad_norm': '18.375', 'counters/examples': 15552, 'counters/updates': 972}
skipping logging after 15568 examples to avoid logging too frequently
skipping logging after 15584 examples to avoid logging too frequently
skipping logging after 15600 examples to avoid logging too frequently
train stats after 15616 examples: {'rewards_train/chosen': '-0.2907', 'rewards_train/rejected': '-0.3054', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.014702', 'logps_train/rejected': '-119.43', 'logps_train/chosen': '-116.65', 'loss/train': '0.69949', 'examples_per_second': '5.1639', 'grad_norm': '15.812', 'counters/examples': 15616, 'counters/updates': 976}
skipping logging after 15632 examples to avoid logging too frequently
skipping logging after 15648 examples to avoid logging too frequently
skipping logging after 15664 examples to avoid logging too frequently
train stats after 15680 examples: {'rewards_train/chosen': '-0.2685', 'rewards_train/rejected': '-0.32867', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.060093', 'logps_train/rejected': '-120.66', 'logps_train/chosen': '-106.9', 'loss/train': '0.68242', 'examples_per_second': '5.3906', 'grad_norm': '16.5', 'counters/examples': 15680, 'counters/updates': 980}
skipping logging after 15696 examples to avoid logging too frequently
skipping logging after 15712 examples to avoid logging too frequently
skipping logging after 15728 examples to avoid logging too frequently
train stats after 15744 examples: {'rewards_train/chosen': '-0.25488', 'rewards_train/rejected': '-0.2555', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.00052261', 'logps_train/rejected': '-110.19', 'logps_train/chosen': '-133.63', 'loss/train': '0.70294', 'examples_per_second': '5.0019', 'grad_norm': '18.625', 'counters/examples': 15744, 'counters/updates': 984}
skipping logging after 15760 examples to avoid logging too frequently
skipping logging after 15776 examples to avoid logging too frequently
skipping logging after 15792 examples to avoid logging too frequently
train stats after 15808 examples: {'rewards_train/chosen': '-0.38911', 'rewards_train/rejected': '-0.4404', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.051355', 'logps_train/rejected': '-101.78', 'logps_train/chosen': '-96.34', 'loss/train': '0.68602', 'examples_per_second': '6.2807', 'grad_norm': '15', 'counters/examples': 15808, 'counters/updates': 988}
skipping logging after 15824 examples to avoid logging too frequently
skipping logging after 15840 examples to avoid logging too frequently
skipping logging after 15856 examples to avoid logging too frequently
train stats after 15872 examples: {'rewards_train/chosen': '-0.15546', 'rewards_train/rejected': '-0.25364', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.098299', 'logps_train/rejected': '-155.85', 'logps_train/chosen': '-135.71', 'loss/train': '0.65784', 'examples_per_second': '4.7587', 'grad_norm': '17', 'counters/examples': 15872, 'counters/updates': 992}
Running evaluation after 15872 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.83s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.63s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.23s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.32s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.33s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 15872: {'rewards_eval/chosen': '-0.2724', 'rewards_eval/rejected': '-0.33169', 'rewards_eval/accuracies': '0.51367', 'rewards_eval/margins': '0.059304', 'logps_eval/rejected': '-125.47', 'logps_eval/chosen': '-121.22', 'loss/eval': '0.67824'}
skipping logging after 15888 examples to avoid logging too frequently
skipping logging after 15904 examples to avoid logging too frequently
skipping logging after 15920 examples to avoid logging too frequently
train stats after 15936 examples: {'rewards_train/chosen': '-0.26996', 'rewards_train/rejected': '-0.34253', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.072506', 'logps_train/rejected': '-150.86', 'logps_train/chosen': '-117.64', 'loss/train': '0.66986', 'examples_per_second': '3.9738', 'grad_norm': '15.688', 'counters/examples': 15936, 'counters/updates': 996}
skipping logging after 15952 examples to avoid logging too frequently
skipping logging after 15968 examples to avoid logging too frequently
skipping logging after 15984 examples to avoid logging too frequently
train stats after 16000 examples: {'rewards_train/chosen': '-0.27379', 'rewards_train/rejected': '-0.28161', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.0079098', 'logps_train/rejected': '-114.56', 'logps_train/chosen': '-140.18', 'loss/train': '0.70438', 'examples_per_second': '5.3874', 'grad_norm': '17.625', 'counters/examples': 16000, 'counters/updates': 1000}
skipping logging after 16016 examples to avoid logging too frequently
skipping logging after 16032 examples to avoid logging too frequently
skipping logging after 16048 examples to avoid logging too frequently
train stats after 16064 examples: {'rewards_train/chosen': '-0.24416', 'rewards_train/rejected': '-0.36249', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.11838', 'logps_train/rejected': '-101.14', 'logps_train/chosen': '-115.51', 'loss/train': '0.64539', 'examples_per_second': '5.4854', 'grad_norm': '16.125', 'counters/examples': 16064, 'counters/updates': 1004}
skipping logging after 16080 examples to avoid logging too frequently
skipping logging after 16096 examples to avoid logging too frequently
skipping logging after 16112 examples to avoid logging too frequently
train stats after 16128 examples: {'rewards_train/chosen': '-0.29172', 'rewards_train/rejected': '-0.33094', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.039131', 'logps_train/rejected': '-97.34', 'logps_train/chosen': '-116.38', 'loss/train': '0.68997', 'examples_per_second': '5.1119', 'grad_norm': '16.625', 'counters/examples': 16128, 'counters/updates': 1008}
skipping logging after 16144 examples to avoid logging too frequently
skipping logging after 16160 examples to avoid logging too frequently
skipping logging after 16176 examples to avoid logging too frequently
train stats after 16192 examples: {'rewards_train/chosen': '-0.29576', 'rewards_train/rejected': '-0.37121', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.075425', 'logps_train/rejected': '-115.99', 'logps_train/chosen': '-116.63', 'loss/train': '0.6716', 'examples_per_second': '4.2025', 'grad_norm': '18.875', 'counters/examples': 16192, 'counters/updates': 1012}
skipping logging after 16208 examples to avoid logging too frequently
skipping logging after 16224 examples to avoid logging too frequently
skipping logging after 16240 examples to avoid logging too frequently
train stats after 16256 examples: {'rewards_train/chosen': '-0.29699', 'rewards_train/rejected': '-0.44778', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.15078', 'logps_train/rejected': '-142.09', 'logps_train/chosen': '-143.55', 'loss/train': '0.62982', 'examples_per_second': '4.1382', 'grad_norm': '19.125', 'counters/examples': 16256, 'counters/updates': 1016}
skipping logging after 16272 examples to avoid logging too frequently
skipping logging after 16288 examples to avoid logging too frequently
skipping logging after 16304 examples to avoid logging too frequently
train stats after 16320 examples: {'rewards_train/chosen': '-0.31557', 'rewards_train/rejected': '-0.39443', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.078821', 'logps_train/rejected': '-104.26', 'logps_train/chosen': '-119.75', 'loss/train': '0.66986', 'examples_per_second': '6.0505', 'grad_norm': '15.375', 'counters/examples': 16320, 'counters/updates': 1020}
skipping logging after 16336 examples to avoid logging too frequently
skipping logging after 16352 examples to avoid logging too frequently
skipping logging after 16368 examples to avoid logging too frequently
train stats after 16384 examples: {'rewards_train/chosen': '-0.22305', 'rewards_train/rejected': '-0.32558', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.10248', 'logps_train/rejected': '-112.16', 'logps_train/chosen': '-92.614', 'loss/train': '0.65939', 'examples_per_second': '5.5706', 'grad_norm': '15.625', 'counters/examples': 16384, 'counters/updates': 1024}
skipping logging after 16400 examples to avoid logging too frequently
skipping logging after 16416 examples to avoid logging too frequently
skipping logging after 16432 examples to avoid logging too frequently
train stats after 16448 examples: {'rewards_train/chosen': '-0.31751', 'rewards_train/rejected': '-0.4064', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.089024', 'logps_train/rejected': '-116.76', 'logps_train/chosen': '-124.6', 'loss/train': '0.66272', 'examples_per_second': '6.3623', 'grad_norm': '17.75', 'counters/examples': 16448, 'counters/updates': 1028}
skipping logging after 16464 examples to avoid logging too frequently
skipping logging after 16480 examples to avoid logging too frequently
skipping logging after 16496 examples to avoid logging too frequently
train stats after 16512 examples: {'rewards_train/chosen': '-0.3896', 'rewards_train/rejected': '-0.41233', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.022728', 'logps_train/rejected': '-133.03', 'logps_train/chosen': '-126.12', 'loss/train': '0.70035', 'examples_per_second': '4.7346', 'grad_norm': '18', 'counters/examples': 16512, 'counters/updates': 1032}
skipping logging after 16528 examples to avoid logging too frequently
skipping logging after 16544 examples to avoid logging too frequently
skipping logging after 16560 examples to avoid logging too frequently
train stats after 16576 examples: {'rewards_train/chosen': '-0.38215', 'rewards_train/rejected': '-0.45679', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.074623', 'logps_train/rejected': '-120.98', 'logps_train/chosen': '-132.8', 'loss/train': '0.668', 'examples_per_second': '4.784', 'grad_norm': '16.875', 'counters/examples': 16576, 'counters/updates': 1036}
skipping logging after 16592 examples to avoid logging too frequently
skipping logging after 16608 examples to avoid logging too frequently
skipping logging after 16624 examples to avoid logging too frequently
train stats after 16640 examples: {'rewards_train/chosen': '-0.34313', 'rewards_train/rejected': '-0.40146', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.058308', 'logps_train/rejected': '-108.54', 'logps_train/chosen': '-106.44', 'loss/train': '0.67508', 'examples_per_second': '6.0171', 'grad_norm': '14.562', 'counters/examples': 16640, 'counters/updates': 1040}
skipping logging after 16656 examples to avoid logging too frequently
skipping logging after 16672 examples to avoid logging too frequently
skipping logging after 16688 examples to avoid logging too frequently
train stats after 16704 examples: {'rewards_train/chosen': '-0.3103', 'rewards_train/rejected': '-0.43383', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.12341', 'logps_train/rejected': '-121.58', 'logps_train/chosen': '-128.06', 'loss/train': '0.65421', 'examples_per_second': '4.6913', 'grad_norm': '16.375', 'counters/examples': 16704, 'counters/updates': 1044}
skipping logging after 16720 examples to avoid logging too frequently
skipping logging after 16736 examples to avoid logging too frequently
skipping logging after 16752 examples to avoid logging too frequently
train stats after 16768 examples: {'rewards_train/chosen': '-0.46686', 'rewards_train/rejected': '-0.51611', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.049267', 'logps_train/rejected': '-115.77', 'logps_train/chosen': '-108.32', 'loss/train': '0.68897', 'examples_per_second': '5.5101', 'grad_norm': '15.312', 'counters/examples': 16768, 'counters/updates': 1048}
skipping logging after 16784 examples to avoid logging too frequently
skipping logging after 16800 examples to avoid logging too frequently
skipping logging after 16816 examples to avoid logging too frequently
train stats after 16832 examples: {'rewards_train/chosen': '-0.46221', 'rewards_train/rejected': '-0.48155', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.019388', 'logps_train/rejected': '-100.85', 'logps_train/chosen': '-103.67', 'loss/train': '0.7141', 'examples_per_second': '5.4479', 'grad_norm': '18.25', 'counters/examples': 16832, 'counters/updates': 1052}
skipping logging after 16848 examples to avoid logging too frequently
skipping logging after 16864 examples to avoid logging too frequently
Running evaluation after 16864 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:15,  2.45s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:06,  2.21s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:56,  1.94s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.91s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.55s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.66s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.48s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.55s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 16864: {'rewards_eval/chosen': '-0.35754', 'rewards_eval/rejected': '-0.4217', 'rewards_eval/accuracies': '0.53516', 'rewards_eval/margins': '0.064158', 'logps_eval/rejected': '-126.37', 'logps_eval/chosen': '-122.07', 'loss/eval': '0.67645'}
skipping logging after 16880 examples to avoid logging too frequently
train stats after 16896 examples: {'rewards_train/chosen': '-0.35378', 'rewards_train/rejected': '-0.46774', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.11395', 'logps_train/rejected': '-156.6', 'logps_train/chosen': '-119.2', 'loss/train': '0.6521', 'examples_per_second': '4.5824', 'grad_norm': '22.75', 'counters/examples': 16896, 'counters/updates': 1056}
skipping logging after 16912 examples to avoid logging too frequently
skipping logging after 16928 examples to avoid logging too frequently
skipping logging after 16944 examples to avoid logging too frequently
train stats after 16960 examples: {'rewards_train/chosen': '-0.37562', 'rewards_train/rejected': '-0.42595', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.050232', 'logps_train/rejected': '-119.42', 'logps_train/chosen': '-111.13', 'loss/train': '0.6835', 'examples_per_second': '6.0006', 'grad_norm': '16.5', 'counters/examples': 16960, 'counters/updates': 1060}
skipping logging after 16976 examples to avoid logging too frequently
skipping logging after 16992 examples to avoid logging too frequently
skipping logging after 17008 examples to avoid logging too frequently
train stats after 17024 examples: {'rewards_train/chosen': '-0.36351', 'rewards_train/rejected': '-0.39978', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.036383', 'logps_train/rejected': '-138.03', 'logps_train/chosen': '-122.79', 'loss/train': '0.69186', 'examples_per_second': '5.3791', 'grad_norm': '17.5', 'counters/examples': 17024, 'counters/updates': 1064}
skipping logging after 17040 examples to avoid logging too frequently
skipping logging after 17056 examples to avoid logging too frequently
skipping logging after 17072 examples to avoid logging too frequently
train stats after 17088 examples: {'rewards_train/chosen': '-0.24898', 'rewards_train/rejected': '-0.27898', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.030009', 'logps_train/rejected': '-119.27', 'logps_train/chosen': '-133.84', 'loss/train': '0.69064', 'examples_per_second': '4.1557', 'grad_norm': '16.25', 'counters/examples': 17088, 'counters/updates': 1068}
skipping logging after 17104 examples to avoid logging too frequently
skipping logging after 17120 examples to avoid logging too frequently
skipping logging after 17136 examples to avoid logging too frequently
train stats after 17152 examples: {'rewards_train/chosen': '-0.39609', 'rewards_train/rejected': '-0.46523', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.069118', 'logps_train/rejected': '-96.303', 'logps_train/chosen': '-101.26', 'loss/train': '0.67589', 'examples_per_second': '5.9796', 'grad_norm': '13.688', 'counters/examples': 17152, 'counters/updates': 1072}
skipping logging after 17168 examples to avoid logging too frequently
skipping logging after 17184 examples to avoid logging too frequently
skipping logging after 17200 examples to avoid logging too frequently
train stats after 17216 examples: {'rewards_train/chosen': '-0.1998', 'rewards_train/rejected': '-0.25448', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.054615', 'logps_train/rejected': '-126.88', 'logps_train/chosen': '-108.85', 'loss/train': '0.68201', 'examples_per_second': '5.6313', 'grad_norm': '14.938', 'counters/examples': 17216, 'counters/updates': 1076}
skipping logging after 17232 examples to avoid logging too frequently
skipping logging after 17248 examples to avoid logging too frequently
skipping logging after 17264 examples to avoid logging too frequently
train stats after 17280 examples: {'rewards_train/chosen': '-0.22531', 'rewards_train/rejected': '-0.32232', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.097058', 'logps_train/rejected': '-129.04', 'logps_train/chosen': '-117.46', 'loss/train': '0.65384', 'examples_per_second': '5.0324', 'grad_norm': '14.812', 'counters/examples': 17280, 'counters/updates': 1080}
skipping logging after 17296 examples to avoid logging too frequently
skipping logging after 17312 examples to avoid logging too frequently
skipping logging after 17328 examples to avoid logging too frequently
train stats after 17344 examples: {'rewards_train/chosen': '-0.33083', 'rewards_train/rejected': '-0.40194', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.071133', 'logps_train/rejected': '-100.19', 'logps_train/chosen': '-107.42', 'loss/train': '0.67258', 'examples_per_second': '6.0643', 'grad_norm': '13.562', 'counters/examples': 17344, 'counters/updates': 1084}
skipping logging after 17360 examples to avoid logging too frequently
skipping logging after 17376 examples to avoid logging too frequently
skipping logging after 17392 examples to avoid logging too frequently
train stats after 17408 examples: {'rewards_train/chosen': '-0.32127', 'rewards_train/rejected': '-0.33921', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.018', 'logps_train/rejected': '-125.28', 'logps_train/chosen': '-123.66', 'loss/train': '0.7005', 'examples_per_second': '5.2915', 'grad_norm': '17.375', 'counters/examples': 17408, 'counters/updates': 1088}
skipping logging after 17424 examples to avoid logging too frequently
skipping logging after 17440 examples to avoid logging too frequently
skipping logging after 17456 examples to avoid logging too frequently
train stats after 17472 examples: {'rewards_train/chosen': '-0.35527', 'rewards_train/rejected': '-0.45131', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.0961', 'logps_train/rejected': '-101.6', 'logps_train/chosen': '-126.31', 'loss/train': '0.66191', 'examples_per_second': '5.2713', 'grad_norm': '16.875', 'counters/examples': 17472, 'counters/updates': 1092}
skipping logging after 17488 examples to avoid logging too frequently
skipping logging after 17504 examples to avoid logging too frequently
skipping logging after 17520 examples to avoid logging too frequently
train stats after 17536 examples: {'rewards_train/chosen': '-0.29241', 'rewards_train/rejected': '-0.39822', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.1058', 'logps_train/rejected': '-108.94', 'logps_train/chosen': '-103.34', 'loss/train': '0.65764', 'examples_per_second': '5.3645', 'grad_norm': '16.75', 'counters/examples': 17536, 'counters/updates': 1096}
skipping logging after 17552 examples to avoid logging too frequently
skipping logging after 17568 examples to avoid logging too frequently
skipping logging after 17584 examples to avoid logging too frequently
train stats after 17600 examples: {'rewards_train/chosen': '-0.30175', 'rewards_train/rejected': '-0.33748', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.035816', 'logps_train/rejected': '-114.5', 'logps_train/chosen': '-105.17', 'loss/train': '0.69043', 'examples_per_second': '5.8771', 'grad_norm': '16.625', 'counters/examples': 17600, 'counters/updates': 1100}
skipping logging after 17616 examples to avoid logging too frequently
skipping logging after 17632 examples to avoid logging too frequently
skipping logging after 17648 examples to avoid logging too frequently
train stats after 17664 examples: {'rewards_train/chosen': '-0.26298', 'rewards_train/rejected': '-0.30874', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.045792', 'logps_train/rejected': '-115.73', 'logps_train/chosen': '-126.54', 'loss/train': '0.68375', 'examples_per_second': '4.4457', 'grad_norm': '15.625', 'counters/examples': 17664, 'counters/updates': 1104}
skipping logging after 17680 examples to avoid logging too frequently
skipping logging after 17696 examples to avoid logging too frequently
skipping logging after 17712 examples to avoid logging too frequently
train stats after 17728 examples: {'rewards_train/chosen': '-0.3385', 'rewards_train/rejected': '-0.41174', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.073296', 'logps_train/rejected': '-113.85', 'logps_train/chosen': '-107.6', 'loss/train': '0.67236', 'examples_per_second': '4.7176', 'grad_norm': '16.125', 'counters/examples': 17728, 'counters/updates': 1108}
skipping logging after 17744 examples to avoid logging too frequently
skipping logging after 17760 examples to avoid logging too frequently
skipping logging after 17776 examples to avoid logging too frequently
train stats after 17792 examples: {'rewards_train/chosen': '-0.21143', 'rewards_train/rejected': '-0.26298', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.051555', 'logps_train/rejected': '-125.57', 'logps_train/chosen': '-129.14', 'loss/train': '0.68066', 'examples_per_second': '5.2281', 'grad_norm': '16.375', 'counters/examples': 17792, 'counters/updates': 1112}
skipping logging after 17808 examples to avoid logging too frequently
skipping logging after 17824 examples to avoid logging too frequently
skipping logging after 17840 examples to avoid logging too frequently
train stats after 17856 examples: {'rewards_train/chosen': '-0.19399', 'rewards_train/rejected': '-0.26985', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.075949', 'logps_train/rejected': '-96.068', 'logps_train/chosen': '-103.94', 'loss/train': '0.66998', 'examples_per_second': '5.1298', 'grad_norm': '15.625', 'counters/examples': 17856, 'counters/updates': 1116}
Running evaluation after 17856 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<01:00,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.83s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.63s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 17856: {'rewards_eval/chosen': '-0.29713', 'rewards_eval/rejected': '-0.36047', 'rewards_eval/accuracies': '0.52539', 'rewards_eval/margins': '0.063311', 'logps_eval/rejected': '-125.76', 'logps_eval/chosen': '-121.47', 'loss/eval': '0.67699'}
skipping logging after 17872 examples to avoid logging too frequently
skipping logging after 17888 examples to avoid logging too frequently
skipping logging after 17904 examples to avoid logging too frequently
train stats after 17920 examples: {'rewards_train/chosen': '-0.17788', 'rewards_train/rejected': '-0.35521', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.17749', 'logps_train/rejected': '-114.23', 'logps_train/chosen': '-94.936', 'loss/train': '0.62906', 'examples_per_second': '5.9058', 'grad_norm': '16.125', 'counters/examples': 17920, 'counters/updates': 1120}
skipping logging after 17936 examples to avoid logging too frequently
skipping logging after 17952 examples to avoid logging too frequently
skipping logging after 17968 examples to avoid logging too frequently
train stats after 17984 examples: {'rewards_train/chosen': '-0.30562', 'rewards_train/rejected': '-0.3484', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.042746', 'logps_train/rejected': '-112.01', 'logps_train/chosen': '-118.08', 'loss/train': '0.69055', 'examples_per_second': '4.6694', 'grad_norm': '17.625', 'counters/examples': 17984, 'counters/updates': 1124}
skipping logging after 18000 examples to avoid logging too frequently
skipping logging after 18016 examples to avoid logging too frequently
skipping logging after 18032 examples to avoid logging too frequently
train stats after 18048 examples: {'rewards_train/chosen': '-0.34196', 'rewards_train/rejected': '-0.41794', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.07608', 'logps_train/rejected': '-134.01', 'logps_train/chosen': '-132.22', 'loss/train': '0.6747', 'examples_per_second': '5.579', 'grad_norm': '15.812', 'counters/examples': 18048, 'counters/updates': 1128}
skipping logging after 18064 examples to avoid logging too frequently
skipping logging after 18080 examples to avoid logging too frequently
skipping logging after 18096 examples to avoid logging too frequently
train stats after 18112 examples: {'rewards_train/chosen': '-0.35828', 'rewards_train/rejected': '-0.43677', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.078526', 'logps_train/rejected': '-103.47', 'logps_train/chosen': '-96.641', 'loss/train': '0.66907', 'examples_per_second': '5.3627', 'grad_norm': '16.625', 'counters/examples': 18112, 'counters/updates': 1132}
skipping logging after 18128 examples to avoid logging too frequently
skipping logging after 18144 examples to avoid logging too frequently
skipping logging after 18160 examples to avoid logging too frequently
train stats after 18176 examples: {'rewards_train/chosen': '-0.31097', 'rewards_train/rejected': '-0.31123', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.00026703', 'logps_train/rejected': '-93.655', 'logps_train/chosen': '-102.06', 'loss/train': '0.7114', 'examples_per_second': '5.6884', 'grad_norm': '20.5', 'counters/examples': 18176, 'counters/updates': 1136}
skipping logging after 18192 examples to avoid logging too frequently
skipping logging after 18208 examples to avoid logging too frequently
skipping logging after 18224 examples to avoid logging too frequently
train stats after 18240 examples: {'rewards_train/chosen': '-0.38205', 'rewards_train/rejected': '-0.41172', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.029705', 'logps_train/rejected': '-109.38', 'logps_train/chosen': '-115.15', 'loss/train': '0.6983', 'examples_per_second': '5.3253', 'grad_norm': '21.25', 'counters/examples': 18240, 'counters/updates': 1140}
skipping logging after 18256 examples to avoid logging too frequently
skipping logging after 18272 examples to avoid logging too frequently
skipping logging after 18288 examples to avoid logging too frequently
train stats after 18304 examples: {'rewards_train/chosen': '-0.17939', 'rewards_train/rejected': '-0.19194', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.012542', 'logps_train/rejected': '-110.66', 'logps_train/chosen': '-119.23', 'loss/train': '0.69128', 'examples_per_second': '5.5391', 'grad_norm': '18.375', 'counters/examples': 18304, 'counters/updates': 1144}
skipping logging after 18320 examples to avoid logging too frequently
skipping logging after 18336 examples to avoid logging too frequently
skipping logging after 18352 examples to avoid logging too frequently
train stats after 18368 examples: {'rewards_train/chosen': '-0.22968', 'rewards_train/rejected': '-0.30811', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.078493', 'logps_train/rejected': '-109.83', 'logps_train/chosen': '-111.62', 'loss/train': '0.6655', 'examples_per_second': '5.7961', 'grad_norm': '16.125', 'counters/examples': 18368, 'counters/updates': 1148}
skipping logging after 18384 examples to avoid logging too frequently
skipping logging after 18400 examples to avoid logging too frequently
skipping logging after 18416 examples to avoid logging too frequently
train stats after 18432 examples: {'rewards_train/chosen': '-0.25391', 'rewards_train/rejected': '-0.25537', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.0015316', 'logps_train/rejected': '-121.96', 'logps_train/chosen': '-113.22', 'loss/train': '0.70624', 'examples_per_second': '4.852', 'grad_norm': '18.875', 'counters/examples': 18432, 'counters/updates': 1152}
skipping logging after 18448 examples to avoid logging too frequently
skipping logging after 18464 examples to avoid logging too frequently
skipping logging after 18480 examples to avoid logging too frequently
train stats after 18496 examples: {'rewards_train/chosen': '-0.18906', 'rewards_train/rejected': '-0.2946', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.10553', 'logps_train/rejected': '-124.1', 'logps_train/chosen': '-120.84', 'loss/train': '0.64868', 'examples_per_second': '5.7151', 'grad_norm': '17.75', 'counters/examples': 18496, 'counters/updates': 1156}
skipping logging after 18512 examples to avoid logging too frequently
skipping logging after 18528 examples to avoid logging too frequently
skipping logging after 18544 examples to avoid logging too frequently
train stats after 18560 examples: {'rewards_train/chosen': '-0.22894', 'rewards_train/rejected': '-0.27521', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.046228', 'logps_train/rejected': '-128.05', 'logps_train/chosen': '-136.55', 'loss/train': '0.68054', 'examples_per_second': '5.0915', 'grad_norm': '18.5', 'counters/examples': 18560, 'counters/updates': 1160}
skipping logging after 18576 examples to avoid logging too frequently
skipping logging after 18592 examples to avoid logging too frequently
skipping logging after 18608 examples to avoid logging too frequently
train stats after 18624 examples: {'rewards_train/chosen': '-0.17176', 'rewards_train/rejected': '-0.25544', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.083681', 'logps_train/rejected': '-109.94', 'logps_train/chosen': '-91.752', 'loss/train': '0.66287', 'examples_per_second': '5.2753', 'grad_norm': '16.25', 'counters/examples': 18624, 'counters/updates': 1164}
skipping logging after 18640 examples to avoid logging too frequently
skipping logging after 18656 examples to avoid logging too frequently
skipping logging after 18672 examples to avoid logging too frequently
train stats after 18688 examples: {'rewards_train/chosen': '-0.29976', 'rewards_train/rejected': '-0.38313', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.083307', 'logps_train/rejected': '-113.35', 'logps_train/chosen': '-119.22', 'loss/train': '0.66907', 'examples_per_second': '5.3849', 'grad_norm': '16.875', 'counters/examples': 18688, 'counters/updates': 1168}
skipping logging after 18704 examples to avoid logging too frequently
skipping logging after 18720 examples to avoid logging too frequently
skipping logging after 18736 examples to avoid logging too frequently
train stats after 18752 examples: {'rewards_train/chosen': '-0.31044', 'rewards_train/rejected': '-0.35112', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.040693', 'logps_train/rejected': '-129.3', 'logps_train/chosen': '-123.66', 'loss/train': '0.68127', 'examples_per_second': '4.3821', 'grad_norm': '19.375', 'counters/examples': 18752, 'counters/updates': 1172}
skipping logging after 18768 examples to avoid logging too frequently
skipping logging after 18784 examples to avoid logging too frequently
skipping logging after 18800 examples to avoid logging too frequently
train stats after 18816 examples: {'rewards_train/chosen': '-0.27399', 'rewards_train/rejected': '-0.28387', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.0099592', 'logps_train/rejected': '-122.96', 'logps_train/chosen': '-147.03', 'loss/train': '0.7056', 'examples_per_second': '4.2968', 'grad_norm': '16.5', 'counters/examples': 18816, 'counters/updates': 1176}
skipping logging after 18832 examples to avoid logging too frequently
skipping logging after 18848 examples to avoid logging too frequently
Running evaluation after 18848 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:09,  2.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:04,  2.13s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:55,  1.90s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.88s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.54s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 18848: {'rewards_eval/chosen': '-0.24477', 'rewards_eval/rejected': '-0.30183', 'rewards_eval/accuracies': '0.54492', 'rewards_eval/margins': '0.057026', 'logps_eval/rejected': '-125.17', 'logps_eval/chosen': '-120.94', 'loss/eval': '0.6778'}
skipping logging after 18864 examples to avoid logging too frequently
train stats after 18880 examples: {'rewards_train/chosen': '-0.19077', 'rewards_train/rejected': '-0.30649', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.11579', 'logps_train/rejected': '-113.63', 'logps_train/chosen': '-109.93', 'loss/train': '0.64966', 'examples_per_second': '4.671', 'grad_norm': '14.688', 'counters/examples': 18880, 'counters/updates': 1180}
skipping logging after 18896 examples to avoid logging too frequently
skipping logging after 18912 examples to avoid logging too frequently
skipping logging after 18928 examples to avoid logging too frequently
train stats after 18944 examples: {'rewards_train/chosen': '-0.2073', 'rewards_train/rejected': '-0.31464', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.10729', 'logps_train/rejected': '-132.94', 'logps_train/chosen': '-123.46', 'loss/train': '0.6541', 'examples_per_second': '5.0758', 'grad_norm': '16.75', 'counters/examples': 18944, 'counters/updates': 1184}
skipping logging after 18960 examples to avoid logging too frequently
skipping logging after 18976 examples to avoid logging too frequently
skipping logging after 18992 examples to avoid logging too frequently
train stats after 19008 examples: {'rewards_train/chosen': '-0.2769', 'rewards_train/rejected': '-0.31197', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.03508', 'logps_train/rejected': '-118.78', 'logps_train/chosen': '-127.45', 'loss/train': '0.69073', 'examples_per_second': '5.0662', 'grad_norm': '20.75', 'counters/examples': 19008, 'counters/updates': 1188}
skipping logging after 19024 examples to avoid logging too frequently
skipping logging after 19040 examples to avoid logging too frequently
skipping logging after 19056 examples to avoid logging too frequently
train stats after 19072 examples: {'rewards_train/chosen': '-0.28347', 'rewards_train/rejected': '-0.33683', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.053396', 'logps_train/rejected': '-127.23', 'logps_train/chosen': '-123.75', 'loss/train': '0.67932', 'examples_per_second': '4.8058', 'grad_norm': '17.5', 'counters/examples': 19072, 'counters/updates': 1192}
skipping logging after 19088 examples to avoid logging too frequently
skipping logging after 19104 examples to avoid logging too frequently
skipping logging after 19120 examples to avoid logging too frequently
train stats after 19136 examples: {'rewards_train/chosen': '-0.24658', 'rewards_train/rejected': '-0.33787', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.091255', 'logps_train/rejected': '-117.11', 'logps_train/chosen': '-111.27', 'loss/train': '0.65982', 'examples_per_second': '4.7528', 'grad_norm': '15.062', 'counters/examples': 19136, 'counters/updates': 1196}
skipping logging after 19152 examples to avoid logging too frequently
skipping logging after 19168 examples to avoid logging too frequently
skipping logging after 19184 examples to avoid logging too frequently
train stats after 19200 examples: {'rewards_train/chosen': '-0.27915', 'rewards_train/rejected': '-0.31318', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.034065', 'logps_train/rejected': '-115.22', 'logps_train/chosen': '-115.69', 'loss/train': '0.69077', 'examples_per_second': '4.8572', 'grad_norm': '16.375', 'counters/examples': 19200, 'counters/updates': 1200}
skipping logging after 19216 examples to avoid logging too frequently
skipping logging after 19232 examples to avoid logging too frequently
skipping logging after 19248 examples to avoid logging too frequently
train stats after 19264 examples: {'rewards_train/chosen': '-0.22967', 'rewards_train/rejected': '-0.29713', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.067533', 'logps_train/rejected': '-117.45', 'logps_train/chosen': '-106.75', 'loss/train': '0.6745', 'examples_per_second': '5.1254', 'grad_norm': '15.188', 'counters/examples': 19264, 'counters/updates': 1204}
skipping logging after 19280 examples to avoid logging too frequently
skipping logging after 19296 examples to avoid logging too frequently
skipping logging after 19312 examples to avoid logging too frequently
train stats after 19328 examples: {'rewards_train/chosen': '-0.27028', 'rewards_train/rejected': '-0.34586', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.075705', 'logps_train/rejected': '-130.36', 'logps_train/chosen': '-126.36', 'loss/train': '0.66859', 'examples_per_second': '5.1873', 'grad_norm': '17.25', 'counters/examples': 19328, 'counters/updates': 1208}
skipping logging after 19344 examples to avoid logging too frequently
skipping logging after 19360 examples to avoid logging too frequently
skipping logging after 19376 examples to avoid logging too frequently
train stats after 19392 examples: {'rewards_train/chosen': '-0.26616', 'rewards_train/rejected': '-0.33668', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.070532', 'logps_train/rejected': '-126.71', 'logps_train/chosen': '-114.93', 'loss/train': '0.66815', 'examples_per_second': '4.3262', 'grad_norm': '17.125', 'counters/examples': 19392, 'counters/updates': 1212}
skipping logging after 19408 examples to avoid logging too frequently
skipping logging after 19424 examples to avoid logging too frequently
skipping logging after 19440 examples to avoid logging too frequently
train stats after 19456 examples: {'rewards_train/chosen': '-0.22165', 'rewards_train/rejected': '-0.366', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.1443', 'logps_train/rejected': '-116.67', 'logps_train/chosen': '-109.36', 'loss/train': '0.64349', 'examples_per_second': '5.3646', 'grad_norm': '15.875', 'counters/examples': 19456, 'counters/updates': 1216}
skipping logging after 19472 examples to avoid logging too frequently
skipping logging after 19488 examples to avoid logging too frequently
skipping logging after 19504 examples to avoid logging too frequently
train stats after 19520 examples: {'rewards_train/chosen': '-0.33956', 'rewards_train/rejected': '-0.40358', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.064062', 'logps_train/rejected': '-114.75', 'logps_train/chosen': '-100.14', 'loss/train': '0.67877', 'examples_per_second': '4.9255', 'grad_norm': '16.5', 'counters/examples': 19520, 'counters/updates': 1220}
skipping logging after 19536 examples to avoid logging too frequently
skipping logging after 19552 examples to avoid logging too frequently
skipping logging after 19568 examples to avoid logging too frequently
train stats after 19584 examples: {'rewards_train/chosen': '-0.25455', 'rewards_train/rejected': '-0.2716', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.017006', 'logps_train/rejected': '-127.66', 'logps_train/chosen': '-132.96', 'loss/train': '0.70218', 'examples_per_second': '4.8853', 'grad_norm': '22.875', 'counters/examples': 19584, 'counters/updates': 1224}
skipping logging after 19600 examples to avoid logging too frequently
skipping logging after 19616 examples to avoid logging too frequently
skipping logging after 19632 examples to avoid logging too frequently
train stats after 19648 examples: {'rewards_train/chosen': '-0.24039', 'rewards_train/rejected': '-0.31881', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.078384', 'logps_train/rejected': '-140.53', 'logps_train/chosen': '-155.88', 'loss/train': '0.67267', 'examples_per_second': '5.6974', 'grad_norm': '22.75', 'counters/examples': 19648, 'counters/updates': 1228}
skipping logging after 19664 examples to avoid logging too frequently
skipping logging after 19680 examples to avoid logging too frequently
skipping logging after 19696 examples to avoid logging too frequently
train stats after 19712 examples: {'rewards_train/chosen': '-0.26132', 'rewards_train/rejected': '-0.36614', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.10469', 'logps_train/rejected': '-108.96', 'logps_train/chosen': '-104.18', 'loss/train': '0.66252', 'examples_per_second': '5.3041', 'grad_norm': '16.875', 'counters/examples': 19712, 'counters/updates': 1232}
skipping logging after 19728 examples to avoid logging too frequently
skipping logging after 19744 examples to avoid logging too frequently
skipping logging after 19760 examples to avoid logging too frequently
train stats after 19776 examples: {'rewards_train/chosen': '-0.23968', 'rewards_train/rejected': '-0.29384', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.054169', 'logps_train/rejected': '-115.72', 'logps_train/chosen': '-113.29', 'loss/train': '0.67368', 'examples_per_second': '4.5417', 'grad_norm': '16.25', 'counters/examples': 19776, 'counters/updates': 1236}
skipping logging after 19792 examples to avoid logging too frequently
skipping logging after 19808 examples to avoid logging too frequently
skipping logging after 19824 examples to avoid logging too frequently
train stats after 19840 examples: {'rewards_train/chosen': '-0.29221', 'rewards_train/rejected': '-0.36139', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.06905', 'logps_train/rejected': '-114.87', 'logps_train/chosen': '-134.98', 'loss/train': '0.68182', 'examples_per_second': '4.9187', 'grad_norm': '17.75', 'counters/examples': 19840, 'counters/updates': 1240}
Running evaluation after 19840 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 19840: {'rewards_eval/chosen': '-0.3121', 'rewards_eval/rejected': '-0.38816', 'rewards_eval/accuracies': '0.53711', 'rewards_eval/margins': '0.07609', 'logps_eval/rejected': '-126.04', 'logps_eval/chosen': '-121.61', 'loss/eval': '0.67217'}
skipping logging after 19856 examples to avoid logging too frequently
skipping logging after 19872 examples to avoid logging too frequently
skipping logging after 19888 examples to avoid logging too frequently
train stats after 19904 examples: {'rewards_train/chosen': '-0.28054', 'rewards_train/rejected': '-0.35298', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.072407', 'logps_train/rejected': '-151.05', 'logps_train/chosen': '-152.55', 'loss/train': '0.67126', 'examples_per_second': '4.6141', 'grad_norm': '17.125', 'counters/examples': 19904, 'counters/updates': 1244}
skipping logging after 19920 examples to avoid logging too frequently
skipping logging after 19936 examples to avoid logging too frequently
skipping logging after 19952 examples to avoid logging too frequently
train stats after 19968 examples: {'rewards_train/chosen': '-0.33918', 'rewards_train/rejected': '-0.43051', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.091286', 'logps_train/rejected': '-95.771', 'logps_train/chosen': '-91.969', 'loss/train': '0.66989', 'examples_per_second': '4.9593', 'grad_norm': '13.812', 'counters/examples': 19968, 'counters/updates': 1248}
skipping logging after 19984 examples to avoid logging too frequently
skipping logging after 20000 examples to avoid logging too frequently
skipping logging after 20016 examples to avoid logging too frequently
train stats after 20032 examples: {'rewards_train/chosen': '-0.46184', 'rewards_train/rejected': '-0.49016', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.028313', 'logps_train/rejected': '-123.94', 'logps_train/chosen': '-124.11', 'loss/train': '0.69727', 'examples_per_second': '5.8587', 'grad_norm': '17.75', 'counters/examples': 20032, 'counters/updates': 1252}
skipping logging after 20048 examples to avoid logging too frequently
skipping logging after 20064 examples to avoid logging too frequently
skipping logging after 20080 examples to avoid logging too frequently
train stats after 20096 examples: {'rewards_train/chosen': '-0.36963', 'rewards_train/rejected': '-0.38165', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.012005', 'logps_train/rejected': '-126.43', 'logps_train/chosen': '-139.92', 'loss/train': '0.702', 'examples_per_second': '5.5061', 'grad_norm': '19.25', 'counters/examples': 20096, 'counters/updates': 1256}
skipping logging after 20112 examples to avoid logging too frequently
skipping logging after 20128 examples to avoid logging too frequently
skipping logging after 20144 examples to avoid logging too frequently
train stats after 20160 examples: {'rewards_train/chosen': '-0.38745', 'rewards_train/rejected': '-0.47023', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.082893', 'logps_train/rejected': '-109.21', 'logps_train/chosen': '-137.46', 'loss/train': '0.67131', 'examples_per_second': '5.4861', 'grad_norm': '17.5', 'counters/examples': 20160, 'counters/updates': 1260}
skipping logging after 20176 examples to avoid logging too frequently
skipping logging after 20192 examples to avoid logging too frequently
skipping logging after 20208 examples to avoid logging too frequently
train stats after 20224 examples: {'rewards_train/chosen': '-0.42275', 'rewards_train/rejected': '-0.4034', 'rewards_train/accuracies': '0.42188', 'rewards_train/margins': '-0.019329', 'logps_train/rejected': '-151.96', 'logps_train/chosen': '-128.1', 'loss/train': '0.71683', 'examples_per_second': '4.9809', 'grad_norm': '18.5', 'counters/examples': 20224, 'counters/updates': 1264}
skipping logging after 20240 examples to avoid logging too frequently
skipping logging after 20256 examples to avoid logging too frequently
skipping logging after 20272 examples to avoid logging too frequently
train stats after 20288 examples: {'rewards_train/chosen': '-0.29169', 'rewards_train/rejected': '-0.33952', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.047821', 'logps_train/rejected': '-129.16', 'logps_train/chosen': '-124', 'loss/train': '0.68359', 'examples_per_second': '4.2096', 'grad_norm': '18.625', 'counters/examples': 20288, 'counters/updates': 1268}
skipping logging after 20304 examples to avoid logging too frequently
skipping logging after 20320 examples to avoid logging too frequently
skipping logging after 20336 examples to avoid logging too frequently
train stats after 20352 examples: {'rewards_train/chosen': '-0.37901', 'rewards_train/rejected': '-0.42279', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.043911', 'logps_train/rejected': '-91.621', 'logps_train/chosen': '-95.035', 'loss/train': '0.68954', 'examples_per_second': '5.8281', 'grad_norm': '14', 'counters/examples': 20352, 'counters/updates': 1272}
skipping logging after 20368 examples to avoid logging too frequently
skipping logging after 20384 examples to avoid logging too frequently
skipping logging after 20400 examples to avoid logging too frequently
train stats after 20416 examples: {'rewards_train/chosen': '-0.23532', 'rewards_train/rejected': '-0.36922', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.13396', 'logps_train/rejected': '-107.62', 'logps_train/chosen': '-133.19', 'loss/train': '0.63911', 'examples_per_second': '4.0008', 'grad_norm': '17', 'counters/examples': 20416, 'counters/updates': 1276}
skipping logging after 20432 examples to avoid logging too frequently
skipping logging after 20448 examples to avoid logging too frequently
skipping logging after 20464 examples to avoid logging too frequently
train stats after 20480 examples: {'rewards_train/chosen': '-0.29235', 'rewards_train/rejected': '-0.33078', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.038313', 'logps_train/rejected': '-133.63', 'logps_train/chosen': '-139.56', 'loss/train': '0.69101', 'examples_per_second': '4.6193', 'grad_norm': '21.25', 'counters/examples': 20480, 'counters/updates': 1280}
skipping logging after 20496 examples to avoid logging too frequently
skipping logging after 20512 examples to avoid logging too frequently
skipping logging after 20528 examples to avoid logging too frequently
train stats after 20544 examples: {'rewards_train/chosen': '-0.25857', 'rewards_train/rejected': '-0.36558', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.10713', 'logps_train/rejected': '-145.73', 'logps_train/chosen': '-133.65', 'loss/train': '0.65231', 'examples_per_second': '4.844', 'grad_norm': '15.875', 'counters/examples': 20544, 'counters/updates': 1284}
skipping logging after 20560 examples to avoid logging too frequently
skipping logging after 20576 examples to avoid logging too frequently
skipping logging after 20592 examples to avoid logging too frequently
train stats after 20608 examples: {'rewards_train/chosen': '-0.26873', 'rewards_train/rejected': '-0.35843', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.089607', 'logps_train/rejected': '-127.14', 'logps_train/chosen': '-131.52', 'loss/train': '0.6665', 'examples_per_second': '4.8126', 'grad_norm': '16.875', 'counters/examples': 20608, 'counters/updates': 1288}
skipping logging after 20624 examples to avoid logging too frequently
skipping logging after 20640 examples to avoid logging too frequently
skipping logging after 20656 examples to avoid logging too frequently
train stats after 20672 examples: {'rewards_train/chosen': '-0.28344', 'rewards_train/rejected': '-0.40665', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.12332', 'logps_train/rejected': '-106.75', 'logps_train/chosen': '-106.3', 'loss/train': '0.64682', 'examples_per_second': '4.2286', 'grad_norm': '14.875', 'counters/examples': 20672, 'counters/updates': 1292}
skipping logging after 20688 examples to avoid logging too frequently
skipping logging after 20704 examples to avoid logging too frequently
skipping logging after 20720 examples to avoid logging too frequently
train stats after 20736 examples: {'rewards_train/chosen': '-0.24387', 'rewards_train/rejected': '-0.32823', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.084466', 'logps_train/rejected': '-117.26', 'logps_train/chosen': '-138.55', 'loss/train': '0.66379', 'examples_per_second': '5.3225', 'grad_norm': '16.125', 'counters/examples': 20736, 'counters/updates': 1296}
skipping logging after 20752 examples to avoid logging too frequently
skipping logging after 20768 examples to avoid logging too frequently
skipping logging after 20784 examples to avoid logging too frequently
train stats after 20800 examples: {'rewards_train/chosen': '-0.39933', 'rewards_train/rejected': '-0.32771', 'rewards_train/accuracies': '0.42188', 'rewards_train/margins': '-0.071659', 'logps_train/rejected': '-116.2', 'logps_train/chosen': '-120.2', 'loss/train': '0.74683', 'examples_per_second': '4.4798', 'grad_norm': '20.125', 'counters/examples': 20800, 'counters/updates': 1300}
skipping logging after 20816 examples to avoid logging too frequently
skipping logging after 20832 examples to avoid logging too frequently
Running evaluation after 20832 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:16,  2.47s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:06,  2.22s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:56,  1.94s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.91s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.56s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.65s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 20832: {'rewards_eval/chosen': '-0.39419', 'rewards_eval/rejected': '-0.46387', 'rewards_eval/accuracies': '0.53516', 'rewards_eval/margins': '0.06969', 'logps_eval/rejected': '-126.79', 'logps_eval/chosen': '-122.44', 'loss/eval': '0.67537'}
skipping logging after 20848 examples to avoid logging too frequently
train stats after 20864 examples: {'rewards_train/chosen': '-0.38871', 'rewards_train/rejected': '-0.47314', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.084459', 'logps_train/rejected': '-127.88', 'logps_train/chosen': '-117.23', 'loss/train': '0.66736', 'examples_per_second': '4.6684', 'grad_norm': '15.188', 'counters/examples': 20864, 'counters/updates': 1304}
skipping logging after 20880 examples to avoid logging too frequently
skipping logging after 20896 examples to avoid logging too frequently
skipping logging after 20912 examples to avoid logging too frequently
train stats after 20928 examples: {'rewards_train/chosen': '-0.36462', 'rewards_train/rejected': '-0.48033', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.11574', 'logps_train/rejected': '-114.08', 'logps_train/chosen': '-149.57', 'loss/train': '0.65327', 'examples_per_second': '4.4924', 'grad_norm': '19.375', 'counters/examples': 20928, 'counters/updates': 1308}
skipping logging after 20944 examples to avoid logging too frequently
skipping logging after 20960 examples to avoid logging too frequently
skipping logging after 20976 examples to avoid logging too frequently
train stats after 20992 examples: {'rewards_train/chosen': '-0.41011', 'rewards_train/rejected': '-0.54364', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.13353', 'logps_train/rejected': '-131.21', 'logps_train/chosen': '-115.02', 'loss/train': '0.6481', 'examples_per_second': '5.5036', 'grad_norm': '15.75', 'counters/examples': 20992, 'counters/updates': 1312}
skipping logging after 21008 examples to avoid logging too frequently
skipping logging after 21024 examples to avoid logging too frequently
skipping logging after 21040 examples to avoid logging too frequently
train stats after 21056 examples: {'rewards_train/chosen': '-0.4396', 'rewards_train/rejected': '-0.46169', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.022071', 'logps_train/rejected': '-98.334', 'logps_train/chosen': '-106.4', 'loss/train': '0.70309', 'examples_per_second': '5.0993', 'grad_norm': '15.688', 'counters/examples': 21056, 'counters/updates': 1316}
skipping logging after 21072 examples to avoid logging too frequently
skipping logging after 21088 examples to avoid logging too frequently
skipping logging after 21104 examples to avoid logging too frequently
train stats after 21120 examples: {'rewards_train/chosen': '-0.53244', 'rewards_train/rejected': '-0.54328', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.010895', 'logps_train/rejected': '-114.62', 'logps_train/chosen': '-105.53', 'loss/train': '0.70255', 'examples_per_second': '5.1141', 'grad_norm': '15.5', 'counters/examples': 21120, 'counters/updates': 1320}
skipping logging after 21136 examples to avoid logging too frequently
skipping logging after 21152 examples to avoid logging too frequently
skipping logging after 21168 examples to avoid logging too frequently
train stats after 21184 examples: {'rewards_train/chosen': '-0.45319', 'rewards_train/rejected': '-0.53287', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.079735', 'logps_train/rejected': '-128.56', 'logps_train/chosen': '-143.78', 'loss/train': '0.67068', 'examples_per_second': '6.1612', 'grad_norm': '21.5', 'counters/examples': 21184, 'counters/updates': 1324}
skipping logging after 21200 examples to avoid logging too frequently
skipping logging after 21216 examples to avoid logging too frequently
skipping logging after 21232 examples to avoid logging too frequently
train stats after 21248 examples: {'rewards_train/chosen': '-0.39602', 'rewards_train/rejected': '-0.42282', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.026859', 'logps_train/rejected': '-136.43', 'logps_train/chosen': '-119.62', 'loss/train': '0.68939', 'examples_per_second': '4.3177', 'grad_norm': '18.5', 'counters/examples': 21248, 'counters/updates': 1328}
skipping logging after 21264 examples to avoid logging too frequently
skipping logging after 21280 examples to avoid logging too frequently
skipping logging after 21296 examples to avoid logging too frequently
train stats after 21312 examples: {'rewards_train/chosen': '-0.31029', 'rewards_train/rejected': '-0.37061', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.060319', 'logps_train/rejected': '-129.44', 'logps_train/chosen': '-113.35', 'loss/train': '0.67422', 'examples_per_second': '4.7878', 'grad_norm': '17.5', 'counters/examples': 21312, 'counters/updates': 1332}
skipping logging after 21328 examples to avoid logging too frequently
skipping logging after 21344 examples to avoid logging too frequently
skipping logging after 21360 examples to avoid logging too frequently
train stats after 21376 examples: {'rewards_train/chosen': '-0.35272', 'rewards_train/rejected': '-0.46766', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.11507', 'logps_train/rejected': '-124.67', 'logps_train/chosen': '-132.27', 'loss/train': '0.64795', 'examples_per_second': '5.5161', 'grad_norm': '16.125', 'counters/examples': 21376, 'counters/updates': 1336}
skipping logging after 21392 examples to avoid logging too frequently
skipping logging after 21408 examples to avoid logging too frequently
skipping logging after 21424 examples to avoid logging too frequently
train stats after 21440 examples: {'rewards_train/chosen': '-0.33351', 'rewards_train/rejected': '-0.46211', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.12854', 'logps_train/rejected': '-98.006', 'logps_train/chosen': '-132.56', 'loss/train': '0.65005', 'examples_per_second': '4.6402', 'grad_norm': '15.5', 'counters/examples': 21440, 'counters/updates': 1340}
skipping logging after 21456 examples to avoid logging too frequently
skipping logging after 21472 examples to avoid logging too frequently
skipping logging after 21488 examples to avoid logging too frequently
train stats after 21504 examples: {'rewards_train/chosen': '-0.41672', 'rewards_train/rejected': '-0.53693', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.12006', 'logps_train/rejected': '-109.3', 'logps_train/chosen': '-130', 'loss/train': '0.65433', 'examples_per_second': '4.9726', 'grad_norm': '17.375', 'counters/examples': 21504, 'counters/updates': 1344}
skipping logging after 21520 examples to avoid logging too frequently
skipping logging after 21536 examples to avoid logging too frequently
skipping logging after 21552 examples to avoid logging too frequently
train stats after 21568 examples: {'rewards_train/chosen': '-0.42985', 'rewards_train/rejected': '-0.48385', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.053894', 'logps_train/rejected': '-105.58', 'logps_train/chosen': '-108.1', 'loss/train': '0.69041', 'examples_per_second': '6.4386', 'grad_norm': '16.875', 'counters/examples': 21568, 'counters/updates': 1348}
skipping logging after 21584 examples to avoid logging too frequently
skipping logging after 21600 examples to avoid logging too frequently
skipping logging after 21616 examples to avoid logging too frequently
train stats after 21632 examples: {'rewards_train/chosen': '-0.3284', 'rewards_train/rejected': '-0.38661', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.058287', 'logps_train/rejected': '-111.85', 'logps_train/chosen': '-113.35', 'loss/train': '0.67545', 'examples_per_second': '4.4182', 'grad_norm': '15.5', 'counters/examples': 21632, 'counters/updates': 1352}
skipping logging after 21648 examples to avoid logging too frequently
skipping logging after 21664 examples to avoid logging too frequently
skipping logging after 21680 examples to avoid logging too frequently
train stats after 21696 examples: {'rewards_train/chosen': '-0.36961', 'rewards_train/rejected': '-0.37836', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '0.0088272', 'logps_train/rejected': '-130.25', 'logps_train/chosen': '-106.2', 'loss/train': '0.70789', 'examples_per_second': '4.3501', 'grad_norm': '19', 'counters/examples': 21696, 'counters/updates': 1356}
skipping logging after 21712 examples to avoid logging too frequently
skipping logging after 21728 examples to avoid logging too frequently
skipping logging after 21744 examples to avoid logging too frequently
train stats after 21760 examples: {'rewards_train/chosen': '-0.34782', 'rewards_train/rejected': '-0.42732', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.079533', 'logps_train/rejected': '-134', 'logps_train/chosen': '-128.33', 'loss/train': '0.67068', 'examples_per_second': '5.2983', 'grad_norm': '19.25', 'counters/examples': 21760, 'counters/updates': 1360}
skipping logging after 21776 examples to avoid logging too frequently
skipping logging after 21792 examples to avoid logging too frequently
skipping logging after 21808 examples to avoid logging too frequently
train stats after 21824 examples: {'rewards_train/chosen': '-0.38102', 'rewards_train/rejected': '-0.39546', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.014488', 'logps_train/rejected': '-131.22', 'logps_train/chosen': '-137.37', 'loss/train': '0.70715', 'examples_per_second': '4.9999', 'grad_norm': '17', 'counters/examples': 21824, 'counters/updates': 1364}
Running evaluation after 21824 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<01:00,  1.94s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<01:00,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.83s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 21824: {'rewards_eval/chosen': '-0.32834', 'rewards_eval/rejected': '-0.38986', 'rewards_eval/accuracies': '0.51562', 'rewards_eval/margins': '0.061513', 'logps_eval/rejected': '-126.05', 'logps_eval/chosen': '-121.78', 'loss/eval': '0.67859'}
skipping logging after 21840 examples to avoid logging too frequently
skipping logging after 21856 examples to avoid logging too frequently
skipping logging after 21872 examples to avoid logging too frequently
train stats after 21888 examples: {'rewards_train/chosen': '-0.35819', 'rewards_train/rejected': '-0.38562', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.027409', 'logps_train/rejected': '-112.52', 'logps_train/chosen': '-105.49', 'loss/train': '0.69363', 'examples_per_second': '4.9596', 'grad_norm': '15.5', 'counters/examples': 21888, 'counters/updates': 1368}
skipping logging after 21904 examples to avoid logging too frequently
skipping logging after 21920 examples to avoid logging too frequently
skipping logging after 21936 examples to avoid logging too frequently
train stats after 21952 examples: {'rewards_train/chosen': '-0.35892', 'rewards_train/rejected': '-0.4914', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.1325', 'logps_train/rejected': '-115.62', 'logps_train/chosen': '-146.27', 'loss/train': '0.64078', 'examples_per_second': '6.3417', 'grad_norm': '16.5', 'counters/examples': 21952, 'counters/updates': 1372}
skipping logging after 21968 examples to avoid logging too frequently
skipping logging after 21984 examples to avoid logging too frequently
skipping logging after 22000 examples to avoid logging too frequently
train stats after 22016 examples: {'rewards_train/chosen': '-0.31591', 'rewards_train/rejected': '-0.35502', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.039061', 'logps_train/rejected': '-111.23', 'logps_train/chosen': '-125.91', 'loss/train': '0.68613', 'examples_per_second': '5.0289', 'grad_norm': '16.25', 'counters/examples': 22016, 'counters/updates': 1376}
skipping logging after 22032 examples to avoid logging too frequently
skipping logging after 22048 examples to avoid logging too frequently
skipping logging after 22064 examples to avoid logging too frequently
train stats after 22080 examples: {'rewards_train/chosen': '-0.26073', 'rewards_train/rejected': '-0.35051', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.089764', 'logps_train/rejected': '-122.1', 'logps_train/chosen': '-108.8', 'loss/train': '0.66631', 'examples_per_second': '5.4927', 'grad_norm': '16.125', 'counters/examples': 22080, 'counters/updates': 1380}
skipping logging after 22096 examples to avoid logging too frequently
skipping logging after 22112 examples to avoid logging too frequently
skipping logging after 22128 examples to avoid logging too frequently
train stats after 22144 examples: {'rewards_train/chosen': '-0.33449', 'rewards_train/rejected': '-0.44909', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.11469', 'logps_train/rejected': '-116.12', 'logps_train/chosen': '-107.15', 'loss/train': '0.6553', 'examples_per_second': '5.7858', 'grad_norm': '16.75', 'counters/examples': 22144, 'counters/updates': 1384}
skipping logging after 22160 examples to avoid logging too frequently
skipping logging after 22176 examples to avoid logging too frequently
skipping logging after 22192 examples to avoid logging too frequently
train stats after 22208 examples: {'rewards_train/chosen': '-0.18747', 'rewards_train/rejected': '-0.27294', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.085573', 'logps_train/rejected': '-92.121', 'logps_train/chosen': '-99.712', 'loss/train': '0.6655', 'examples_per_second': '5.0754', 'grad_norm': '14.062', 'counters/examples': 22208, 'counters/updates': 1388}
skipping logging after 22224 examples to avoid logging too frequently
skipping logging after 22240 examples to avoid logging too frequently
skipping logging after 22256 examples to avoid logging too frequently
train stats after 22272 examples: {'rewards_train/chosen': '-0.2597', 'rewards_train/rejected': '-0.30563', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.045944', 'logps_train/rejected': '-125.47', 'logps_train/chosen': '-134.6', 'loss/train': '0.68744', 'examples_per_second': '5.0661', 'grad_norm': '16.875', 'counters/examples': 22272, 'counters/updates': 1392}
skipping logging after 22288 examples to avoid logging too frequently
skipping logging after 22304 examples to avoid logging too frequently
skipping logging after 22320 examples to avoid logging too frequently
train stats after 22336 examples: {'rewards_train/chosen': '-0.24631', 'rewards_train/rejected': '-0.34146', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.095144', 'logps_train/rejected': '-105.71', 'logps_train/chosen': '-136.63', 'loss/train': '0.6662', 'examples_per_second': '4.1255', 'grad_norm': '19', 'counters/examples': 22336, 'counters/updates': 1396}
skipping logging after 22352 examples to avoid logging too frequently
skipping logging after 22368 examples to avoid logging too frequently
skipping logging after 22384 examples to avoid logging too frequently
train stats after 22400 examples: {'rewards_train/chosen': '-0.31869', 'rewards_train/rejected': '-0.34902', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.030207', 'logps_train/rejected': '-90.326', 'logps_train/chosen': '-109.23', 'loss/train': '0.6976', 'examples_per_second': '5.2031', 'grad_norm': '19.125', 'counters/examples': 22400, 'counters/updates': 1400}
skipping logging after 22416 examples to avoid logging too frequently
skipping logging after 22432 examples to avoid logging too frequently
skipping logging after 22448 examples to avoid logging too frequently
train stats after 22464 examples: {'rewards_train/chosen': '-0.37903', 'rewards_train/rejected': '-0.459', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.079901', 'logps_train/rejected': '-121.11', 'logps_train/chosen': '-113.27', 'loss/train': '0.67334', 'examples_per_second': '5.6822', 'grad_norm': '15.562', 'counters/examples': 22464, 'counters/updates': 1404}
skipping logging after 22480 examples to avoid logging too frequently
skipping logging after 22496 examples to avoid logging too frequently
skipping logging after 22512 examples to avoid logging too frequently
train stats after 22528 examples: {'rewards_train/chosen': '-0.31803', 'rewards_train/rejected': '-0.42795', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.11009', 'logps_train/rejected': '-133.35', 'logps_train/chosen': '-125.35', 'loss/train': '0.65964', 'examples_per_second': '4.3109', 'grad_norm': '25.375', 'counters/examples': 22528, 'counters/updates': 1408}
skipping logging after 22544 examples to avoid logging too frequently
skipping logging after 22560 examples to avoid logging too frequently
skipping logging after 22576 examples to avoid logging too frequently
train stats after 22592 examples: {'rewards_train/chosen': '-0.41506', 'rewards_train/rejected': '-0.49237', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.077297', 'logps_train/rejected': '-124.9', 'logps_train/chosen': '-123.17', 'loss/train': '0.67004', 'examples_per_second': '6.14', 'grad_norm': '18.5', 'counters/examples': 22592, 'counters/updates': 1412}
skipping logging after 22608 examples to avoid logging too frequently
skipping logging after 22624 examples to avoid logging too frequently
skipping logging after 22640 examples to avoid logging too frequently
train stats after 22656 examples: {'rewards_train/chosen': '-0.41497', 'rewards_train/rejected': '-0.48113', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.066187', 'logps_train/rejected': '-111.84', 'logps_train/chosen': '-114.36', 'loss/train': '0.6705', 'examples_per_second': '4.1927', 'grad_norm': '15.562', 'counters/examples': 22656, 'counters/updates': 1416}
skipping logging after 22672 examples to avoid logging too frequently
skipping logging after 22688 examples to avoid logging too frequently
skipping logging after 22704 examples to avoid logging too frequently
train stats after 22720 examples: {'rewards_train/chosen': '-0.5344', 'rewards_train/rejected': '-0.5516', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.017193', 'logps_train/rejected': '-105.85', 'logps_train/chosen': '-113.36', 'loss/train': '0.69711', 'examples_per_second': '6.5867', 'grad_norm': '18.375', 'counters/examples': 22720, 'counters/updates': 1420}
skipping logging after 22736 examples to avoid logging too frequently
skipping logging after 22752 examples to avoid logging too frequently
skipping logging after 22768 examples to avoid logging too frequently
train stats after 22784 examples: {'rewards_train/chosen': '-0.40906', 'rewards_train/rejected': '-0.51788', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.10884', 'logps_train/rejected': '-150.51', 'logps_train/chosen': '-119.12', 'loss/train': '0.65402', 'examples_per_second': '5.0402', 'grad_norm': '19.5', 'counters/examples': 22784, 'counters/updates': 1424}
skipping logging after 22800 examples to avoid logging too frequently
skipping logging after 22816 examples to avoid logging too frequently
Running evaluation after 22816 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:19,  2.55s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:07,  2.25s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:56,  1.96s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:08<00:53,  1.92s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:42,  1.56s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.66s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.24s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 22816: {'rewards_eval/chosen': '-0.34741', 'rewards_eval/rejected': '-0.41156', 'rewards_eval/accuracies': '0.50781', 'rewards_eval/margins': '0.064164', 'logps_eval/rejected': '-126.27', 'logps_eval/chosen': '-121.97', 'loss/eval': '0.6783'}
skipping logging after 22832 examples to avoid logging too frequently
train stats after 22848 examples: {'rewards_train/chosen': '-0.39768', 'rewards_train/rejected': '-0.53235', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.13467', 'logps_train/rejected': '-98.964', 'logps_train/chosen': '-109.69', 'loss/train': '0.64581', 'examples_per_second': '4.0462', 'grad_norm': '15.188', 'counters/examples': 22848, 'counters/updates': 1428}
skipping logging after 22864 examples to avoid logging too frequently
skipping logging after 22880 examples to avoid logging too frequently
skipping logging after 22896 examples to avoid logging too frequently
train stats after 22912 examples: {'rewards_train/chosen': '-0.32291', 'rewards_train/rejected': '-0.40794', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.085056', 'logps_train/rejected': '-120.66', 'logps_train/chosen': '-150.44', 'loss/train': '0.66806', 'examples_per_second': '4.1038', 'grad_norm': '16.875', 'counters/examples': 22912, 'counters/updates': 1432}
skipping logging after 22928 examples to avoid logging too frequently
skipping logging after 22944 examples to avoid logging too frequently
skipping logging after 22960 examples to avoid logging too frequently
train stats after 22976 examples: {'rewards_train/chosen': '-0.32375', 'rewards_train/rejected': '-0.45798', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.13427', 'logps_train/rejected': '-113.27', 'logps_train/chosen': '-127.58', 'loss/train': '0.64873', 'examples_per_second': '4.955', 'grad_norm': '15.688', 'counters/examples': 22976, 'counters/updates': 1436}
skipping logging after 22992 examples to avoid logging too frequently
skipping logging after 23008 examples to avoid logging too frequently
skipping logging after 23024 examples to avoid logging too frequently
train stats after 23040 examples: {'rewards_train/chosen': '-0.35596', 'rewards_train/rejected': '-0.35712', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.0012178', 'logps_train/rejected': '-106.85', 'logps_train/chosen': '-122.42', 'loss/train': '0.70389', 'examples_per_second': '4.4702', 'grad_norm': '14.188', 'counters/examples': 23040, 'counters/updates': 1440}
skipping logging after 23056 examples to avoid logging too frequently
skipping logging after 23072 examples to avoid logging too frequently
skipping logging after 23088 examples to avoid logging too frequently
train stats after 23104 examples: {'rewards_train/chosen': '-0.32482', 'rewards_train/rejected': '-0.37436', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.049597', 'logps_train/rejected': '-93.699', 'logps_train/chosen': '-103.34', 'loss/train': '0.68057', 'examples_per_second': '6.3391', 'grad_norm': '17.25', 'counters/examples': 23104, 'counters/updates': 1444}
skipping logging after 23120 examples to avoid logging too frequently
skipping logging after 23136 examples to avoid logging too frequently
skipping logging after 23152 examples to avoid logging too frequently
train stats after 23168 examples: {'rewards_train/chosen': '-0.36683', 'rewards_train/rejected': '-0.36646', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '-0.00034904', 'logps_train/rejected': '-96.804', 'logps_train/chosen': '-120.82', 'loss/train': '0.70331', 'examples_per_second': '5.7143', 'grad_norm': '17.25', 'counters/examples': 23168, 'counters/updates': 1448}
skipping logging after 23184 examples to avoid logging too frequently
skipping logging after 23200 examples to avoid logging too frequently
skipping logging after 23216 examples to avoid logging too frequently
train stats after 23232 examples: {'rewards_train/chosen': '-0.37711', 'rewards_train/rejected': '-0.40954', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.032359', 'logps_train/rejected': '-135.7', 'logps_train/chosen': '-115.95', 'loss/train': '0.69394', 'examples_per_second': '4.3348', 'grad_norm': '21.25', 'counters/examples': 23232, 'counters/updates': 1452}
skipping logging after 23248 examples to avoid logging too frequently
skipping logging after 23264 examples to avoid logging too frequently
skipping logging after 23280 examples to avoid logging too frequently
train stats after 23296 examples: {'rewards_train/chosen': '-0.41993', 'rewards_train/rejected': '-0.45281', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.03289', 'logps_train/rejected': '-118.58', 'logps_train/chosen': '-131.55', 'loss/train': '0.68741', 'examples_per_second': '5.5955', 'grad_norm': '17.75', 'counters/examples': 23296, 'counters/updates': 1456}
skipping logging after 23312 examples to avoid logging too frequently
skipping logging after 23328 examples to avoid logging too frequently
skipping logging after 23344 examples to avoid logging too frequently
train stats after 23360 examples: {'rewards_train/chosen': '-0.43334', 'rewards_train/rejected': '-0.50957', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.076279', 'logps_train/rejected': '-142.83', 'logps_train/chosen': '-149.34', 'loss/train': '0.68057', 'examples_per_second': '5.0648', 'grad_norm': '17.5', 'counters/examples': 23360, 'counters/updates': 1460}
skipping logging after 23376 examples to avoid logging too frequently
skipping logging after 23392 examples to avoid logging too frequently
skipping logging after 23408 examples to avoid logging too frequently
train stats after 23424 examples: {'rewards_train/chosen': '-0.34797', 'rewards_train/rejected': '-0.38642', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.038424', 'logps_train/rejected': '-124.6', 'logps_train/chosen': '-145.42', 'loss/train': '0.68619', 'examples_per_second': '3.984', 'grad_norm': '16.875', 'counters/examples': 23424, 'counters/updates': 1464}
skipping logging after 23440 examples to avoid logging too frequently
skipping logging after 23456 examples to avoid logging too frequently
skipping logging after 23472 examples to avoid logging too frequently
train stats after 23488 examples: {'rewards_train/chosen': '-0.50369', 'rewards_train/rejected': '-0.52478', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.021204', 'logps_train/rejected': '-91.5', 'logps_train/chosen': '-124.28', 'loss/train': '0.70157', 'examples_per_second': '6.6547', 'grad_norm': '18.5', 'counters/examples': 23488, 'counters/updates': 1468}
skipping logging after 23504 examples to avoid logging too frequently
skipping logging after 23520 examples to avoid logging too frequently
skipping logging after 23536 examples to avoid logging too frequently
train stats after 23552 examples: {'rewards_train/chosen': '-0.40911', 'rewards_train/rejected': '-0.45992', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.050766', 'logps_train/rejected': '-144.48', 'logps_train/chosen': '-142.05', 'loss/train': '0.68317', 'examples_per_second': '4.3494', 'grad_norm': '17.75', 'counters/examples': 23552, 'counters/updates': 1472}
skipping logging after 23568 examples to avoid logging too frequently
skipping logging after 23584 examples to avoid logging too frequently
skipping logging after 23600 examples to avoid logging too frequently
train stats after 23616 examples: {'rewards_train/chosen': '-0.37352', 'rewards_train/rejected': '-0.4338', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.060318', 'logps_train/rejected': '-99.544', 'logps_train/chosen': '-107.35', 'loss/train': '0.67935', 'examples_per_second': '5.9833', 'grad_norm': '16', 'counters/examples': 23616, 'counters/updates': 1476}
skipping logging after 23632 examples to avoid logging too frequently
skipping logging after 23648 examples to avoid logging too frequently
skipping logging after 23664 examples to avoid logging too frequently
train stats after 23680 examples: {'rewards_train/chosen': '-0.27551', 'rewards_train/rejected': '-0.36339', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.087797', 'logps_train/rejected': '-124.2', 'logps_train/chosen': '-114.48', 'loss/train': '0.66745', 'examples_per_second': '5.1296', 'grad_norm': '18', 'counters/examples': 23680, 'counters/updates': 1480}
skipping logging after 23696 examples to avoid logging too frequently
skipping logging after 23712 examples to avoid logging too frequently
skipping logging after 23728 examples to avoid logging too frequently
train stats after 23744 examples: {'rewards_train/chosen': '-0.39825', 'rewards_train/rejected': '-0.45627', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '0.057997', 'logps_train/rejected': '-121.71', 'logps_train/chosen': '-123.08', 'loss/train': '0.68518', 'examples_per_second': '5.1534', 'grad_norm': '17.375', 'counters/examples': 23744, 'counters/updates': 1484}
skipping logging after 23760 examples to avoid logging too frequently
skipping logging after 23776 examples to avoid logging too frequently
skipping logging after 23792 examples to avoid logging too frequently
train stats after 23808 examples: {'rewards_train/chosen': '-0.35918', 'rewards_train/rejected': '-0.40295', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.043781', 'logps_train/rejected': '-131.32', 'logps_train/chosen': '-126.41', 'loss/train': '0.6876', 'examples_per_second': '4.4474', 'grad_norm': '16.625', 'counters/examples': 23808, 'counters/updates': 1488}
Running evaluation after 23808 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.53s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 23808: {'rewards_eval/chosen': '-0.40723', 'rewards_eval/rejected': '-0.469', 'rewards_eval/accuracies': '0.51953', 'rewards_eval/margins': '0.061796', 'logps_eval/rejected': '-126.85', 'logps_eval/chosen': '-122.57', 'loss/eval': '0.67773'}
skipping logging after 23824 examples to avoid logging too frequently
skipping logging after 23840 examples to avoid logging too frequently
skipping logging after 23856 examples to avoid logging too frequently
train stats after 23872 examples: {'rewards_train/chosen': '-0.42918', 'rewards_train/rejected': '-0.48538', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.056285', 'logps_train/rejected': '-103.85', 'logps_train/chosen': '-97.986', 'loss/train': '0.67587', 'examples_per_second': '4.5385', 'grad_norm': '14.062', 'counters/examples': 23872, 'counters/updates': 1492}
skipping logging after 23888 examples to avoid logging too frequently
skipping logging after 23904 examples to avoid logging too frequently
skipping logging after 23920 examples to avoid logging too frequently
train stats after 23936 examples: {'rewards_train/chosen': '-0.43954', 'rewards_train/rejected': '-0.48083', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.04122', 'logps_train/rejected': '-123.39', 'logps_train/chosen': '-136.58', 'loss/train': '0.69127', 'examples_per_second': '5.4218', 'grad_norm': '16.75', 'counters/examples': 23936, 'counters/updates': 1496}
skipping logging after 23952 examples to avoid logging too frequently
skipping logging after 23968 examples to avoid logging too frequently
skipping logging after 23984 examples to avoid logging too frequently
train stats after 24000 examples: {'rewards_train/chosen': '-0.35039', 'rewards_train/rejected': '-0.40858', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.058201', 'logps_train/rejected': '-126.01', 'logps_train/chosen': '-133.48', 'loss/train': '0.67604', 'examples_per_second': '4.5075', 'grad_norm': '18.375', 'counters/examples': 24000, 'counters/updates': 1500}
skipping logging after 24016 examples to avoid logging too frequently
skipping logging after 24032 examples to avoid logging too frequently
skipping logging after 24048 examples to avoid logging too frequently
train stats after 24064 examples: {'rewards_train/chosen': '-0.36148', 'rewards_train/rejected': '-0.40259', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.041061', 'logps_train/rejected': '-102.76', 'logps_train/chosen': '-98.23', 'loss/train': '0.68909', 'examples_per_second': '5.8651', 'grad_norm': '15', 'counters/examples': 24064, 'counters/updates': 1504}
skipping logging after 24080 examples to avoid logging too frequently
skipping logging after 24096 examples to avoid logging too frequently
skipping logging after 24112 examples to avoid logging too frequently
train stats after 24128 examples: {'rewards_train/chosen': '-0.41548', 'rewards_train/rejected': '-0.4636', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.04817', 'logps_train/rejected': '-118.29', 'logps_train/chosen': '-102.27', 'loss/train': '0.68121', 'examples_per_second': '5.0721', 'grad_norm': '15.562', 'counters/examples': 24128, 'counters/updates': 1508}
skipping logging after 24144 examples to avoid logging too frequently
skipping logging after 24160 examples to avoid logging too frequently
skipping logging after 24176 examples to avoid logging too frequently
train stats after 24192 examples: {'rewards_train/chosen': '-0.42759', 'rewards_train/rejected': '-0.52055', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.093025', 'logps_train/rejected': '-116.02', 'logps_train/chosen': '-142.12', 'loss/train': '0.66403', 'examples_per_second': '4.9898', 'grad_norm': '15.812', 'counters/examples': 24192, 'counters/updates': 1512}
skipping logging after 24208 examples to avoid logging too frequently
skipping logging after 24224 examples to avoid logging too frequently
skipping logging after 24240 examples to avoid logging too frequently
train stats after 24256 examples: {'rewards_train/chosen': '-0.35172', 'rewards_train/rejected': '-0.45132', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.09967', 'logps_train/rejected': '-111.8', 'logps_train/chosen': '-99.963', 'loss/train': '0.66223', 'examples_per_second': '5.0368', 'grad_norm': '16.125', 'counters/examples': 24256, 'counters/updates': 1516}
skipping logging after 24272 examples to avoid logging too frequently
skipping logging after 24288 examples to avoid logging too frequently
skipping logging after 24304 examples to avoid logging too frequently
train stats after 24320 examples: {'rewards_train/chosen': '-0.32723', 'rewards_train/rejected': '-0.40499', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.077769', 'logps_train/rejected': '-88.133', 'logps_train/chosen': '-106.18', 'loss/train': '0.66873', 'examples_per_second': '6.5702', 'grad_norm': '15.5', 'counters/examples': 24320, 'counters/updates': 1520}
skipping logging after 24336 examples to avoid logging too frequently
skipping logging after 24352 examples to avoid logging too frequently
skipping logging after 24368 examples to avoid logging too frequently
train stats after 24384 examples: {'rewards_train/chosen': '-0.31818', 'rewards_train/rejected': '-0.3746', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.056454', 'logps_train/rejected': '-108.73', 'logps_train/chosen': '-105.09', 'loss/train': '0.67111', 'examples_per_second': '5.9582', 'grad_norm': '17.25', 'counters/examples': 24384, 'counters/updates': 1524}
skipping logging after 24400 examples to avoid logging too frequently
skipping logging after 24416 examples to avoid logging too frequently
skipping logging after 24432 examples to avoid logging too frequently
train stats after 24448 examples: {'rewards_train/chosen': '-0.41792', 'rewards_train/rejected': '-0.39241', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '-0.025564', 'logps_train/rejected': '-119.99', 'logps_train/chosen': '-110.46', 'loss/train': '0.72519', 'examples_per_second': '4.3291', 'grad_norm': '17.875', 'counters/examples': 24448, 'counters/updates': 1528}
skipping logging after 24464 examples to avoid logging too frequently
skipping logging after 24480 examples to avoid logging too frequently
skipping logging after 24496 examples to avoid logging too frequently
train stats after 24512 examples: {'rewards_train/chosen': '-0.34397', 'rewards_train/rejected': '-0.32921', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '-0.014759', 'logps_train/rejected': '-117.41', 'logps_train/chosen': '-103.39', 'loss/train': '0.71335', 'examples_per_second': '5.4996', 'grad_norm': '20.375', 'counters/examples': 24512, 'counters/updates': 1532}
skipping logging after 24528 examples to avoid logging too frequently
skipping logging after 24544 examples to avoid logging too frequently
skipping logging after 24560 examples to avoid logging too frequently
train stats after 24576 examples: {'rewards_train/chosen': '-0.18071', 'rewards_train/rejected': '-0.29282', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.11206', 'logps_train/rejected': '-103.28', 'logps_train/chosen': '-124.8', 'loss/train': '0.6507', 'examples_per_second': '5.5719', 'grad_norm': '17.625', 'counters/examples': 24576, 'counters/updates': 1536}
skipping logging after 24592 examples to avoid logging too frequently
skipping logging after 24608 examples to avoid logging too frequently
skipping logging after 24624 examples to avoid logging too frequently
train stats after 24640 examples: {'rewards_train/chosen': '-0.2218', 'rewards_train/rejected': '-0.34931', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.12753', 'logps_train/rejected': '-160.79', 'logps_train/chosen': '-148.1', 'loss/train': '0.64813', 'examples_per_second': '3.9547', 'grad_norm': '16.625', 'counters/examples': 24640, 'counters/updates': 1540}
skipping logging after 24656 examples to avoid logging too frequently
skipping logging after 24672 examples to avoid logging too frequently
skipping logging after 24688 examples to avoid logging too frequently
train stats after 24704 examples: {'rewards_train/chosen': '-0.40981', 'rewards_train/rejected': '-0.42404', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.014278', 'logps_train/rejected': '-140.13', 'logps_train/chosen': '-125.91', 'loss/train': '0.70108', 'examples_per_second': '5.2848', 'grad_norm': '22.375', 'counters/examples': 24704, 'counters/updates': 1544}
skipping logging after 24720 examples to avoid logging too frequently
skipping logging after 24736 examples to avoid logging too frequently
skipping logging after 24752 examples to avoid logging too frequently
train stats after 24768 examples: {'rewards_train/chosen': '-0.34174', 'rewards_train/rejected': '-0.43518', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.09351', 'logps_train/rejected': '-97.605', 'logps_train/chosen': '-93.536', 'loss/train': '0.66306', 'examples_per_second': '4.8218', 'grad_norm': '18.75', 'counters/examples': 24768, 'counters/updates': 1548}
skipping logging after 24784 examples to avoid logging too frequently
skipping logging after 24800 examples to avoid logging too frequently
Running evaluation after 24800 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:11,  2.31s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:04,  2.16s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:55,  1.91s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.89s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.54s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 24800: {'rewards_eval/chosen': '-0.27711', 'rewards_eval/rejected': '-0.34015', 'rewards_eval/accuracies': '0.52734', 'rewards_eval/margins': '0.063052', 'logps_eval/rejected': '-125.56', 'logps_eval/chosen': '-121.27', 'loss/eval': '0.67748'}
skipping logging after 24816 examples to avoid logging too frequently
train stats after 24832 examples: {'rewards_train/chosen': '-0.19786', 'rewards_train/rejected': '-0.28812', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.090324', 'logps_train/rejected': '-133.74', 'logps_train/chosen': '-135.74', 'loss/train': '0.66287', 'examples_per_second': '5.2455', 'grad_norm': '15.688', 'counters/examples': 24832, 'counters/updates': 1552}
skipping logging after 24848 examples to avoid logging too frequently
skipping logging after 24864 examples to avoid logging too frequently
skipping logging after 24880 examples to avoid logging too frequently
train stats after 24896 examples: {'rewards_train/chosen': '-0.28675', 'rewards_train/rejected': '-0.38639', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.099741', 'logps_train/rejected': '-136.7', 'logps_train/chosen': '-138.71', 'loss/train': '0.66278', 'examples_per_second': '4.7604', 'grad_norm': '18.375', 'counters/examples': 24896, 'counters/updates': 1556}
skipping logging after 24912 examples to avoid logging too frequently
skipping logging after 24928 examples to avoid logging too frequently
skipping logging after 24944 examples to avoid logging too frequently
train stats after 24960 examples: {'rewards_train/chosen': '-0.26342', 'rewards_train/rejected': '-0.35785', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.094465', 'logps_train/rejected': '-108.94', 'logps_train/chosen': '-112.6', 'loss/train': '0.66466', 'examples_per_second': '5.333', 'grad_norm': '16.25', 'counters/examples': 24960, 'counters/updates': 1560}
skipping logging after 24976 examples to avoid logging too frequently
skipping logging after 24992 examples to avoid logging too frequently
skipping logging after 25008 examples to avoid logging too frequently
train stats after 25024 examples: {'rewards_train/chosen': '-0.26346', 'rewards_train/rejected': '-0.34657', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.083214', 'logps_train/rejected': '-142.21', 'logps_train/chosen': '-160.8', 'loss/train': '0.6757', 'examples_per_second': '4.4202', 'grad_norm': '19.5', 'counters/examples': 25024, 'counters/updates': 1564}
skipping logging after 25040 examples to avoid logging too frequently
skipping logging after 25056 examples to avoid logging too frequently
skipping logging after 25072 examples to avoid logging too frequently
train stats after 25088 examples: {'rewards_train/chosen': '-0.23508', 'rewards_train/rejected': '-0.30822', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.073034', 'logps_train/rejected': '-128.85', 'logps_train/chosen': '-117.77', 'loss/train': '0.66547', 'examples_per_second': '5.3624', 'grad_norm': '17.625', 'counters/examples': 25088, 'counters/updates': 1568}
skipping logging after 25104 examples to avoid logging too frequently
skipping logging after 25120 examples to avoid logging too frequently
skipping logging after 25136 examples to avoid logging too frequently
train stats after 25152 examples: {'rewards_train/chosen': '-0.17967', 'rewards_train/rejected': '-0.27619', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.096527', 'logps_train/rejected': '-140.35', 'logps_train/chosen': '-124.02', 'loss/train': '0.66464', 'examples_per_second': '4.1162', 'grad_norm': '17.25', 'counters/examples': 25152, 'counters/updates': 1572}
skipping logging after 25168 examples to avoid logging too frequently
skipping logging after 25184 examples to avoid logging too frequently
skipping logging after 25200 examples to avoid logging too frequently
train stats after 25216 examples: {'rewards_train/chosen': '-0.28323', 'rewards_train/rejected': '-0.31785', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.034658', 'logps_train/rejected': '-89.566', 'logps_train/chosen': '-119.77', 'loss/train': '0.68835', 'examples_per_second': '5.9219', 'grad_norm': '16.25', 'counters/examples': 25216, 'counters/updates': 1576}
skipping logging after 25232 examples to avoid logging too frequently
skipping logging after 25248 examples to avoid logging too frequently
skipping logging after 25264 examples to avoid logging too frequently
train stats after 25280 examples: {'rewards_train/chosen': '-0.19149', 'rewards_train/rejected': '-0.30815', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.11664', 'logps_train/rejected': '-132.82', 'logps_train/chosen': '-127.74', 'loss/train': '0.65152', 'examples_per_second': '4.8631', 'grad_norm': '15.562', 'counters/examples': 25280, 'counters/updates': 1580}
skipping logging after 25296 examples to avoid logging too frequently
skipping logging after 25312 examples to avoid logging too frequently
skipping logging after 25328 examples to avoid logging too frequently
train stats after 25344 examples: {'rewards_train/chosen': '-0.20122', 'rewards_train/rejected': '-0.31228', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.11111', 'logps_train/rejected': '-96.835', 'logps_train/chosen': '-105.13', 'loss/train': '0.65839', 'examples_per_second': '5.0271', 'grad_norm': '15.125', 'counters/examples': 25344, 'counters/updates': 1584}
skipping logging after 25360 examples to avoid logging too frequently
skipping logging after 25376 examples to avoid logging too frequently
skipping logging after 25392 examples to avoid logging too frequently
train stats after 25408 examples: {'rewards_train/chosen': '-0.29983', 'rewards_train/rejected': '-0.37407', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.074221', 'logps_train/rejected': '-122.18', 'logps_train/chosen': '-115.09', 'loss/train': '0.67862', 'examples_per_second': '5.2813', 'grad_norm': '18.125', 'counters/examples': 25408, 'counters/updates': 1588}
skipping logging after 25424 examples to avoid logging too frequently
skipping logging after 25440 examples to avoid logging too frequently
skipping logging after 25456 examples to avoid logging too frequently
train stats after 25472 examples: {'rewards_train/chosen': '-0.22136', 'rewards_train/rejected': '-0.2595', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.038182', 'logps_train/rejected': '-105.92', 'logps_train/chosen': '-97.044', 'loss/train': '0.6832', 'examples_per_second': '5.0787', 'grad_norm': '15.562', 'counters/examples': 25472, 'counters/updates': 1592}
skipping logging after 25488 examples to avoid logging too frequently
skipping logging after 25504 examples to avoid logging too frequently
skipping logging after 25520 examples to avoid logging too frequently
train stats after 25536 examples: {'rewards_train/chosen': '-0.24281', 'rewards_train/rejected': '-0.27643', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.033555', 'logps_train/rejected': '-102.31', 'logps_train/chosen': '-109.65', 'loss/train': '0.6871', 'examples_per_second': '5.6605', 'grad_norm': '16.625', 'counters/examples': 25536, 'counters/updates': 1596}
skipping logging after 25552 examples to avoid logging too frequently
skipping logging after 25568 examples to avoid logging too frequently
skipping logging after 25584 examples to avoid logging too frequently
train stats after 25600 examples: {'rewards_train/chosen': '-0.25786', 'rewards_train/rejected': '-0.26227', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.0044422', 'logps_train/rejected': '-126.35', 'logps_train/chosen': '-122.04', 'loss/train': '0.7048', 'examples_per_second': '4.2346', 'grad_norm': '17', 'counters/examples': 25600, 'counters/updates': 1600}
skipping logging after 25616 examples to avoid logging too frequently
skipping logging after 25632 examples to avoid logging too frequently
skipping logging after 25648 examples to avoid logging too frequently
train stats after 25664 examples: {'rewards_train/chosen': '-0.15278', 'rewards_train/rejected': '-0.27562', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.12285', 'logps_train/rejected': '-108.86', 'logps_train/chosen': '-134.95', 'loss/train': '0.64861', 'examples_per_second': '4.2083', 'grad_norm': '18', 'counters/examples': 25664, 'counters/updates': 1604}
skipping logging after 25680 examples to avoid logging too frequently
skipping logging after 25696 examples to avoid logging too frequently
skipping logging after 25712 examples to avoid logging too frequently
train stats after 25728 examples: {'rewards_train/chosen': '-0.31927', 'rewards_train/rejected': '-0.29322', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '-0.025997', 'logps_train/rejected': '-117.3', 'logps_train/chosen': '-134.69', 'loss/train': '0.7197', 'examples_per_second': '5.6409', 'grad_norm': '22.25', 'counters/examples': 25728, 'counters/updates': 1608}
skipping logging after 25744 examples to avoid logging too frequently
skipping logging after 25760 examples to avoid logging too frequently
skipping logging after 25776 examples to avoid logging too frequently
train stats after 25792 examples: {'rewards_train/chosen': '-0.17235', 'rewards_train/rejected': '-0.2515', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.079315', 'logps_train/rejected': '-142.12', 'logps_train/chosen': '-139.97', 'loss/train': '0.66437', 'examples_per_second': '4.2327', 'grad_norm': '18.875', 'counters/examples': 25792, 'counters/updates': 1612}
Running evaluation after 25792 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.45s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.53s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.46s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.53s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.42s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.30s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.31s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.39s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 25792: {'rewards_eval/chosen': '-0.21892', 'rewards_eval/rejected': '-0.28471', 'rewards_eval/accuracies': '0.53906', 'rewards_eval/margins': '0.065809', 'logps_eval/rejected': '-125', 'logps_eval/chosen': '-120.68', 'loss/eval': '0.67479'}
skipping logging after 25808 examples to avoid logging too frequently
skipping logging after 25824 examples to avoid logging too frequently
skipping logging after 25840 examples to avoid logging too frequently
train stats after 25856 examples: {'rewards_train/chosen': '-0.12518', 'rewards_train/rejected': '-0.23829', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.11321', 'logps_train/rejected': '-102.54', 'logps_train/chosen': '-126.69', 'loss/train': '0.64771', 'examples_per_second': '4.9874', 'grad_norm': '15.25', 'counters/examples': 25856, 'counters/updates': 1616}
skipping logging after 25872 examples to avoid logging too frequently
skipping logging after 25888 examples to avoid logging too frequently
skipping logging after 25904 examples to avoid logging too frequently
train stats after 25920 examples: {'rewards_train/chosen': '-0.24996', 'rewards_train/rejected': '-0.27913', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.029148', 'logps_train/rejected': '-138.41', 'logps_train/chosen': '-144.18', 'loss/train': '0.68985', 'examples_per_second': '4.5201', 'grad_norm': '16.75', 'counters/examples': 25920, 'counters/updates': 1620}
skipping logging after 25936 examples to avoid logging too frequently
skipping logging after 25952 examples to avoid logging too frequently
skipping logging after 25968 examples to avoid logging too frequently
train stats after 25984 examples: {'rewards_train/chosen': '-0.17273', 'rewards_train/rejected': '-0.32329', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.15057', 'logps_train/rejected': '-113.08', 'logps_train/chosen': '-135.84', 'loss/train': '0.63504', 'examples_per_second': '5.9718', 'grad_norm': '17.125', 'counters/examples': 25984, 'counters/updates': 1624}
skipping logging after 26000 examples to avoid logging too frequently
skipping logging after 26016 examples to avoid logging too frequently
skipping logging after 26032 examples to avoid logging too frequently
train stats after 26048 examples: {'rewards_train/chosen': '-0.34527', 'rewards_train/rejected': '-0.37974', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.034473', 'logps_train/rejected': '-95.786', 'logps_train/chosen': '-116.65', 'loss/train': '0.68906', 'examples_per_second': '4.7575', 'grad_norm': '16.125', 'counters/examples': 26048, 'counters/updates': 1628}
skipping logging after 26064 examples to avoid logging too frequently
skipping logging after 26080 examples to avoid logging too frequently
skipping logging after 26096 examples to avoid logging too frequently
train stats after 26112 examples: {'rewards_train/chosen': '-0.30437', 'rewards_train/rejected': '-0.36288', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.058353', 'logps_train/rejected': '-115', 'logps_train/chosen': '-113.06', 'loss/train': '0.68039', 'examples_per_second': '5.0067', 'grad_norm': '15.938', 'counters/examples': 26112, 'counters/updates': 1632}
skipping logging after 26128 examples to avoid logging too frequently
skipping logging after 26144 examples to avoid logging too frequently
skipping logging after 26160 examples to avoid logging too frequently
train stats after 26176 examples: {'rewards_train/chosen': '-0.16164', 'rewards_train/rejected': '-0.22489', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.063143', 'logps_train/rejected': '-128.96', 'logps_train/chosen': '-120.89', 'loss/train': '0.6727', 'examples_per_second': '5.9874', 'grad_norm': '14.875', 'counters/examples': 26176, 'counters/updates': 1636}
skipping logging after 26192 examples to avoid logging too frequently
skipping logging after 26208 examples to avoid logging too frequently
skipping logging after 26224 examples to avoid logging too frequently
train stats after 26240 examples: {'rewards_train/chosen': '-0.21955', 'rewards_train/rejected': '-0.27622', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.056669', 'logps_train/rejected': '-142.76', 'logps_train/chosen': '-134.92', 'loss/train': '0.67459', 'examples_per_second': '5.282', 'grad_norm': '17.375', 'counters/examples': 26240, 'counters/updates': 1640}
skipping logging after 26256 examples to avoid logging too frequently
skipping logging after 26272 examples to avoid logging too frequently
skipping logging after 26288 examples to avoid logging too frequently
train stats after 26304 examples: {'rewards_train/chosen': '-0.31499', 'rewards_train/rejected': '-0.37785', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.062744', 'logps_train/rejected': '-117.32', 'logps_train/chosen': '-110.06', 'loss/train': '0.6796', 'examples_per_second': '5.4691', 'grad_norm': '17.625', 'counters/examples': 26304, 'counters/updates': 1644}
skipping logging after 26320 examples to avoid logging too frequently
skipping logging after 26336 examples to avoid logging too frequently
skipping logging after 26352 examples to avoid logging too frequently
train stats after 26368 examples: {'rewards_train/chosen': '-0.22512', 'rewards_train/rejected': '-0.29803', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.073015', 'logps_train/rejected': '-93.103', 'logps_train/chosen': '-122.46', 'loss/train': '0.67154', 'examples_per_second': '4.4113', 'grad_norm': '15.125', 'counters/examples': 26368, 'counters/updates': 1648}
skipping logging after 26384 examples to avoid logging too frequently
skipping logging after 26400 examples to avoid logging too frequently
skipping logging after 26416 examples to avoid logging too frequently
train stats after 26432 examples: {'rewards_train/chosen': '-0.30457', 'rewards_train/rejected': '-0.31191', 'rewards_train/accuracies': '0.40625', 'rewards_train/margins': '0.0072937', 'logps_train/rejected': '-106.37', 'logps_train/chosen': '-116.18', 'loss/train': '0.70035', 'examples_per_second': '5.6715', 'grad_norm': '17.875', 'counters/examples': 26432, 'counters/updates': 1652}
skipping logging after 26448 examples to avoid logging too frequently
skipping logging after 26464 examples to avoid logging too frequently
skipping logging after 26480 examples to avoid logging too frequently
train stats after 26496 examples: {'rewards_train/chosen': '-0.24016', 'rewards_train/rejected': '-0.33177', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.091564', 'logps_train/rejected': '-119.8', 'logps_train/chosen': '-117.1', 'loss/train': '0.66208', 'examples_per_second': '5.5333', 'grad_norm': '15.312', 'counters/examples': 26496, 'counters/updates': 1656}
skipping logging after 26512 examples to avoid logging too frequently
skipping logging after 26528 examples to avoid logging too frequently
skipping logging after 26544 examples to avoid logging too frequently
train stats after 26560 examples: {'rewards_train/chosen': '-0.26484', 'rewards_train/rejected': '-0.30333', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.03862', 'logps_train/rejected': '-92.802', 'logps_train/chosen': '-127.29', 'loss/train': '0.69275', 'examples_per_second': '5.0367', 'grad_norm': '17.75', 'counters/examples': 26560, 'counters/updates': 1660}
skipping logging after 26576 examples to avoid logging too frequently
skipping logging after 26592 examples to avoid logging too frequently
skipping logging after 26608 examples to avoid logging too frequently
train stats after 26624 examples: {'rewards_train/chosen': '-0.30157', 'rewards_train/rejected': '-0.3682', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.066555', 'logps_train/rejected': '-108.67', 'logps_train/chosen': '-100.41', 'loss/train': '0.67288', 'examples_per_second': '6.8709', 'grad_norm': '15.938', 'counters/examples': 26624, 'counters/updates': 1664}
skipping logging after 26640 examples to avoid logging too frequently
skipping logging after 26656 examples to avoid logging too frequently
skipping logging after 26672 examples to avoid logging too frequently
train stats after 26688 examples: {'rewards_train/chosen': '-0.30599', 'rewards_train/rejected': '-0.35875', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.052804', 'logps_train/rejected': '-118.09', 'logps_train/chosen': '-126.51', 'loss/train': '0.68817', 'examples_per_second': '5.1133', 'grad_norm': '18.875', 'counters/examples': 26688, 'counters/updates': 1668}
skipping logging after 26704 examples to avoid logging too frequently
skipping logging after 26720 examples to avoid logging too frequently
skipping logging after 26736 examples to avoid logging too frequently
train stats after 26752 examples: {'rewards_train/chosen': '-0.28405', 'rewards_train/rejected': '-0.33034', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.046288', 'logps_train/rejected': '-128.46', 'logps_train/chosen': '-112.64', 'loss/train': '0.68787', 'examples_per_second': '4.6672', 'grad_norm': '17.375', 'counters/examples': 26752, 'counters/updates': 1672}
skipping logging after 26768 examples to avoid logging too frequently
skipping logging after 26784 examples to avoid logging too frequently
Running evaluation after 26784 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:11,  2.30s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:04,  2.14s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:55,  1.90s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.88s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.54s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 26784: {'rewards_eval/chosen': '-0.25243', 'rewards_eval/rejected': '-0.3161', 'rewards_eval/accuracies': '0.53516', 'rewards_eval/margins': '0.063663', 'logps_eval/rejected': '-125.32', 'logps_eval/chosen': '-121.02', 'loss/eval': '0.67739'}
skipping logging after 26800 examples to avoid logging too frequently
train stats after 26816 examples: {'rewards_train/chosen': '-0.23267', 'rewards_train/rejected': '-0.3429', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.11022', 'logps_train/rejected': '-110.38', 'logps_train/chosen': '-114.3', 'loss/train': '0.65149', 'examples_per_second': '4.6349', 'grad_norm': '14.125', 'counters/examples': 26816, 'counters/updates': 1676}
skipping logging after 26832 examples to avoid logging too frequently
skipping logging after 26848 examples to avoid logging too frequently
skipping logging after 26864 examples to avoid logging too frequently
train stats after 26880 examples: {'rewards_train/chosen': '-0.23663', 'rewards_train/rejected': '-0.33408', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.0975', 'logps_train/rejected': '-104.22', 'logps_train/chosen': '-113.76', 'loss/train': '0.66028', 'examples_per_second': '4.4035', 'grad_norm': '17.25', 'counters/examples': 26880, 'counters/updates': 1680}
skipping logging after 26896 examples to avoid logging too frequently
skipping logging after 26912 examples to avoid logging too frequently
skipping logging after 26928 examples to avoid logging too frequently
train stats after 26944 examples: {'rewards_train/chosen': '-0.2707', 'rewards_train/rejected': '-0.28009', 'rewards_train/accuracies': '0.40625', 'rewards_train/margins': '0.0094643', 'logps_train/rejected': '-129.61', 'logps_train/chosen': '-126.39', 'loss/train': '0.70465', 'examples_per_second': '4.7339', 'grad_norm': '17.25', 'counters/examples': 26944, 'counters/updates': 1684}
skipping logging after 26960 examples to avoid logging too frequently
skipping logging after 26976 examples to avoid logging too frequently
skipping logging after 26992 examples to avoid logging too frequently
train stats after 27008 examples: {'rewards_train/chosen': '-0.17434', 'rewards_train/rejected': '-0.26435', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.089996', 'logps_train/rejected': '-121.98', 'logps_train/chosen': '-123.76', 'loss/train': '0.65851', 'examples_per_second': '4.5725', 'grad_norm': '16.375', 'counters/examples': 27008, 'counters/updates': 1688}
skipping logging after 27024 examples to avoid logging too frequently
skipping logging after 27040 examples to avoid logging too frequently
skipping logging after 27056 examples to avoid logging too frequently
train stats after 27072 examples: {'rewards_train/chosen': '-0.1914', 'rewards_train/rejected': '-0.33846', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.14697', 'logps_train/rejected': '-123.47', 'logps_train/chosen': '-131.98', 'loss/train': '0.63007', 'examples_per_second': '4.4788', 'grad_norm': '17.5', 'counters/examples': 27072, 'counters/updates': 1692}
skipping logging after 27088 examples to avoid logging too frequently
skipping logging after 27104 examples to avoid logging too frequently
skipping logging after 27120 examples to avoid logging too frequently
train stats after 27136 examples: {'rewards_train/chosen': '-0.19425', 'rewards_train/rejected': '-0.32167', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.12749', 'logps_train/rejected': '-118.45', 'logps_train/chosen': '-122.62', 'loss/train': '0.65437', 'examples_per_second': '5.1863', 'grad_norm': '17.375', 'counters/examples': 27136, 'counters/updates': 1696}
skipping logging after 27152 examples to avoid logging too frequently
skipping logging after 27168 examples to avoid logging too frequently
skipping logging after 27184 examples to avoid logging too frequently
train stats after 27200 examples: {'rewards_train/chosen': '-0.22563', 'rewards_train/rejected': '-0.30577', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.080135', 'logps_train/rejected': '-132.2', 'logps_train/chosen': '-143.96', 'loss/train': '0.67256', 'examples_per_second': '4.4058', 'grad_norm': '18.375', 'counters/examples': 27200, 'counters/updates': 1700}
skipping logging after 27216 examples to avoid logging too frequently
skipping logging after 27232 examples to avoid logging too frequently
skipping logging after 27248 examples to avoid logging too frequently
train stats after 27264 examples: {'rewards_train/chosen': '-0.31409', 'rewards_train/rejected': '-0.43134', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.11721', 'logps_train/rejected': '-127.2', 'logps_train/chosen': '-129.03', 'loss/train': '0.65788', 'examples_per_second': '5.4401', 'grad_norm': '17.5', 'counters/examples': 27264, 'counters/updates': 1704}
skipping logging after 27280 examples to avoid logging too frequently
skipping logging after 27296 examples to avoid logging too frequently
skipping logging after 27312 examples to avoid logging too frequently
train stats after 27328 examples: {'rewards_train/chosen': '-0.32215', 'rewards_train/rejected': '-0.36489', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.042625', 'logps_train/rejected': '-145.7', 'logps_train/chosen': '-137.77', 'loss/train': '0.69153', 'examples_per_second': '4.3042', 'grad_norm': '19.25', 'counters/examples': 27328, 'counters/updates': 1708}
skipping logging after 27344 examples to avoid logging too frequently
skipping logging after 27360 examples to avoid logging too frequently
skipping logging after 27376 examples to avoid logging too frequently
train stats after 27392 examples: {'rewards_train/chosen': '-0.27824', 'rewards_train/rejected': '-0.43199', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.15381', 'logps_train/rejected': '-107.71', 'logps_train/chosen': '-138.83', 'loss/train': '0.63739', 'examples_per_second': '5.3558', 'grad_norm': '15.688', 'counters/examples': 27392, 'counters/updates': 1712}
skipping logging after 27408 examples to avoid logging too frequently
skipping logging after 27424 examples to avoid logging too frequently
skipping logging after 27440 examples to avoid logging too frequently
train stats after 27456 examples: {'rewards_train/chosen': '-0.43373', 'rewards_train/rejected': '-0.47775', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.044079', 'logps_train/rejected': '-127.57', 'logps_train/chosen': '-130.97', 'loss/train': '0.69086', 'examples_per_second': '5.4547', 'grad_norm': '21.5', 'counters/examples': 27456, 'counters/updates': 1716}
skipping logging after 27472 examples to avoid logging too frequently
skipping logging after 27488 examples to avoid logging too frequently
skipping logging after 27504 examples to avoid logging too frequently
train stats after 27520 examples: {'rewards_train/chosen': '-0.38754', 'rewards_train/rejected': '-0.45066', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.063148', 'logps_train/rejected': '-113.92', 'logps_train/chosen': '-124.47', 'loss/train': '0.67841', 'examples_per_second': '5.0977', 'grad_norm': '18.25', 'counters/examples': 27520, 'counters/updates': 1720}
skipping logging after 27536 examples to avoid logging too frequently
skipping logging after 27552 examples to avoid logging too frequently
skipping logging after 27568 examples to avoid logging too frequently
train stats after 27584 examples: {'rewards_train/chosen': '-0.4581', 'rewards_train/rejected': '-0.50837', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.050312', 'logps_train/rejected': '-109.05', 'logps_train/chosen': '-105.86', 'loss/train': '0.68756', 'examples_per_second': '5.2302', 'grad_norm': '16.375', 'counters/examples': 27584, 'counters/updates': 1724}
skipping logging after 27600 examples to avoid logging too frequently
skipping logging after 27616 examples to avoid logging too frequently
skipping logging after 27632 examples to avoid logging too frequently
train stats after 27648 examples: {'rewards_train/chosen': '-0.23413', 'rewards_train/rejected': '-0.35394', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.11989', 'logps_train/rejected': '-121.6', 'logps_train/chosen': '-121.28', 'loss/train': '0.64993', 'examples_per_second': '4.429', 'grad_norm': '16.875', 'counters/examples': 27648, 'counters/updates': 1728}
skipping logging after 27664 examples to avoid logging too frequently
skipping logging after 27680 examples to avoid logging too frequently
skipping logging after 27696 examples to avoid logging too frequently
train stats after 27712 examples: {'rewards_train/chosen': '-0.39875', 'rewards_train/rejected': '-0.5298', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.13125', 'logps_train/rejected': '-107.89', 'logps_train/chosen': '-106.79', 'loss/train': '0.64499', 'examples_per_second': '5.6546', 'grad_norm': '15.688', 'counters/examples': 27712, 'counters/updates': 1732}
skipping logging after 27728 examples to avoid logging too frequently
skipping logging after 27744 examples to avoid logging too frequently
skipping logging after 27760 examples to avoid logging too frequently
train stats after 27776 examples: {'rewards_train/chosen': '-0.36963', 'rewards_train/rejected': '-0.41866', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.049046', 'logps_train/rejected': '-112.34', 'logps_train/chosen': '-119.69', 'loss/train': '0.68585', 'examples_per_second': '5.1522', 'grad_norm': '17.625', 'counters/examples': 27776, 'counters/updates': 1736}
Running evaluation after 27776 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<01:00,  1.94s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<01:00,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.83s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 27776: {'rewards_eval/chosen': '-0.41624', 'rewards_eval/rejected': '-0.48564', 'rewards_eval/accuracies': '0.51367', 'rewards_eval/margins': '0.069427', 'logps_eval/rejected': '-127.01', 'logps_eval/chosen': '-122.66', 'loss/eval': '0.67747'}
skipping logging after 27792 examples to avoid logging too frequently
skipping logging after 27808 examples to avoid logging too frequently
skipping logging after 27824 examples to avoid logging too frequently
train stats after 27840 examples: {'rewards_train/chosen': '-0.43651', 'rewards_train/rejected': '-0.56192', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.12545', 'logps_train/rejected': '-109.95', 'logps_train/chosen': '-133.16', 'loss/train': '0.64529', 'examples_per_second': '5.4292', 'grad_norm': '18.625', 'counters/examples': 27840, 'counters/updates': 1740}
skipping logging after 27856 examples to avoid logging too frequently
skipping logging after 27872 examples to avoid logging too frequently
skipping logging after 27888 examples to avoid logging too frequently
train stats after 27904 examples: {'rewards_train/chosen': '-0.26296', 'rewards_train/rejected': '-0.36973', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.1068', 'logps_train/rejected': '-128.64', 'logps_train/chosen': '-124.75', 'loss/train': '0.65887', 'examples_per_second': '4.557', 'grad_norm': '16.5', 'counters/examples': 27904, 'counters/updates': 1744}
skipping logging after 27920 examples to avoid logging too frequently
skipping logging after 27936 examples to avoid logging too frequently
skipping logging after 27952 examples to avoid logging too frequently
train stats after 27968 examples: {'rewards_train/chosen': '-0.34065', 'rewards_train/rejected': '-0.42832', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.087708', 'logps_train/rejected': '-134.79', 'logps_train/chosen': '-113.88', 'loss/train': '0.66064', 'examples_per_second': '4.7438', 'grad_norm': '15.812', 'counters/examples': 27968, 'counters/updates': 1748}
skipping logging after 27984 examples to avoid logging too frequently
skipping logging after 28000 examples to avoid logging too frequently
skipping logging after 28016 examples to avoid logging too frequently
train stats after 28032 examples: {'rewards_train/chosen': '-0.4656', 'rewards_train/rejected': '-0.49429', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.028629', 'logps_train/rejected': '-124.71', 'logps_train/chosen': '-115.86', 'loss/train': '0.70044', 'examples_per_second': '5.0527', 'grad_norm': '17.75', 'counters/examples': 28032, 'counters/updates': 1752}
skipping logging after 28048 examples to avoid logging too frequently
skipping logging after 28064 examples to avoid logging too frequently
skipping logging after 28080 examples to avoid logging too frequently
train stats after 28096 examples: {'rewards_train/chosen': '-0.35012', 'rewards_train/rejected': '-0.39375', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.043633', 'logps_train/rejected': '-124.18', 'logps_train/chosen': '-113.85', 'loss/train': '0.68512', 'examples_per_second': '4.6493', 'grad_norm': '16.375', 'counters/examples': 28096, 'counters/updates': 1756}
skipping logging after 28112 examples to avoid logging too frequently
skipping logging after 28128 examples to avoid logging too frequently
skipping logging after 28144 examples to avoid logging too frequently
train stats after 28160 examples: {'rewards_train/chosen': '-0.44185', 'rewards_train/rejected': '-0.56312', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.12119', 'logps_train/rejected': '-122.38', 'logps_train/chosen': '-129.39', 'loss/train': '0.66144', 'examples_per_second': '5.5602', 'grad_norm': '19.5', 'counters/examples': 28160, 'counters/updates': 1760}
skipping logging after 28176 examples to avoid logging too frequently
skipping logging after 28192 examples to avoid logging too frequently
skipping logging after 28208 examples to avoid logging too frequently
train stats after 28224 examples: {'rewards_train/chosen': '-0.42731', 'rewards_train/rejected': '-0.53806', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.11068', 'logps_train/rejected': '-93.77', 'logps_train/chosen': '-90.613', 'loss/train': '0.65463', 'examples_per_second': '5.3247', 'grad_norm': '13.125', 'counters/examples': 28224, 'counters/updates': 1764}
skipping logging after 28240 examples to avoid logging too frequently
skipping logging after 28256 examples to avoid logging too frequently
skipping logging after 28272 examples to avoid logging too frequently
train stats after 28288 examples: {'rewards_train/chosen': '-0.40501', 'rewards_train/rejected': '-0.47213', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.067061', 'logps_train/rejected': '-122.62', 'logps_train/chosen': '-133.03', 'loss/train': '0.67699', 'examples_per_second': '4.6746', 'grad_norm': '16.25', 'counters/examples': 28288, 'counters/updates': 1768}
skipping logging after 28304 examples to avoid logging too frequently
skipping logging after 28320 examples to avoid logging too frequently
skipping logging after 28336 examples to avoid logging too frequently
train stats after 28352 examples: {'rewards_train/chosen': '-0.32491', 'rewards_train/rejected': '-0.46313', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.13829', 'logps_train/rejected': '-134.59', 'logps_train/chosen': '-110.19', 'loss/train': '0.64513', 'examples_per_second': '4.6541', 'grad_norm': '16.875', 'counters/examples': 28352, 'counters/updates': 1772}
skipping logging after 28368 examples to avoid logging too frequently
skipping logging after 28384 examples to avoid logging too frequently
skipping logging after 28400 examples to avoid logging too frequently
train stats after 28416 examples: {'rewards_train/chosen': '-0.32183', 'rewards_train/rejected': '-0.3955', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.073634', 'logps_train/rejected': '-108.2', 'logps_train/chosen': '-122.49', 'loss/train': '0.68095', 'examples_per_second': '6.4483', 'grad_norm': '17.125', 'counters/examples': 28416, 'counters/updates': 1776}
skipping logging after 28432 examples to avoid logging too frequently
skipping logging after 28448 examples to avoid logging too frequently
skipping logging after 28464 examples to avoid logging too frequently
train stats after 28480 examples: {'rewards_train/chosen': '-0.38696', 'rewards_train/rejected': '-0.42931', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.042322', 'logps_train/rejected': '-107.12', 'logps_train/chosen': '-110.31', 'loss/train': '0.69551', 'examples_per_second': '5.0288', 'grad_norm': '15.75', 'counters/examples': 28480, 'counters/updates': 1780}
skipping logging after 28496 examples to avoid logging too frequently
skipping logging after 28512 examples to avoid logging too frequently
skipping logging after 28528 examples to avoid logging too frequently
train stats after 28544 examples: {'rewards_train/chosen': '-0.352', 'rewards_train/rejected': '-0.33321', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '-0.018745', 'logps_train/rejected': '-147.54', 'logps_train/chosen': '-121.21', 'loss/train': '0.72186', 'examples_per_second': '4.7799', 'grad_norm': '20.75', 'counters/examples': 28544, 'counters/updates': 1784}
skipping logging after 28560 examples to avoid logging too frequently
skipping logging after 28576 examples to avoid logging too frequently
skipping logging after 28592 examples to avoid logging too frequently
train stats after 28608 examples: {'rewards_train/chosen': '-0.30584', 'rewards_train/rejected': '-0.45495', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.14897', 'logps_train/rejected': '-125.6', 'logps_train/chosen': '-132.26', 'loss/train': '0.63924', 'examples_per_second': '4.8805', 'grad_norm': '15.75', 'counters/examples': 28608, 'counters/updates': 1788}
skipping logging after 28624 examples to avoid logging too frequently
skipping logging after 28640 examples to avoid logging too frequently
skipping logging after 28656 examples to avoid logging too frequently
train stats after 28672 examples: {'rewards_train/chosen': '-0.37363', 'rewards_train/rejected': '-0.45366', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.079956', 'logps_train/rejected': '-135.02', 'logps_train/chosen': '-121.66', 'loss/train': '0.66904', 'examples_per_second': '4.7031', 'grad_norm': '18.125', 'counters/examples': 28672, 'counters/updates': 1792}
skipping logging after 28688 examples to avoid logging too frequently
skipping logging after 28704 examples to avoid logging too frequently
skipping logging after 28720 examples to avoid logging too frequently
train stats after 28736 examples: {'rewards_train/chosen': '-0.45278', 'rewards_train/rejected': '-0.46757', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.014671', 'logps_train/rejected': '-100.76', 'logps_train/chosen': '-132.41', 'loss/train': '0.70206', 'examples_per_second': '5.3732', 'grad_norm': '19.75', 'counters/examples': 28736, 'counters/updates': 1796}
skipping logging after 28752 examples to avoid logging too frequently
skipping logging after 28768 examples to avoid logging too frequently
Running evaluation after 28768 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:13,  2.38s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:05,  2.18s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:55,  1.92s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.89s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.54s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.65s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.12s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 28768: {'rewards_eval/chosen': '-0.32525', 'rewards_eval/rejected': '-0.39342', 'rewards_eval/accuracies': '0.52148', 'rewards_eval/margins': '0.068152', 'logps_eval/rejected': '-126.09', 'logps_eval/chosen': '-121.75', 'loss/eval': '0.67867'}
skipping logging after 28784 examples to avoid logging too frequently
train stats after 28800 examples: {'rewards_train/chosen': '-0.28791', 'rewards_train/rejected': '-0.39076', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.10281', 'logps_train/rejected': '-125.86', 'logps_train/chosen': '-113.57', 'loss/train': '0.66774', 'examples_per_second': '5.8311', 'grad_norm': '16.25', 'counters/examples': 28800, 'counters/updates': 1800}
skipping logging after 28816 examples to avoid logging too frequently
skipping logging after 28832 examples to avoid logging too frequently
skipping logging after 28848 examples to avoid logging too frequently
train stats after 28864 examples: {'rewards_train/chosen': '-0.34276', 'rewards_train/rejected': '-0.3809', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.038015', 'logps_train/rejected': '-142.08', 'logps_train/chosen': '-128.27', 'loss/train': '0.69598', 'examples_per_second': '4.3849', 'grad_norm': '19.625', 'counters/examples': 28864, 'counters/updates': 1804}
skipping logging after 28880 examples to avoid logging too frequently
skipping logging after 28896 examples to avoid logging too frequently
skipping logging after 28912 examples to avoid logging too frequently
train stats after 28928 examples: {'rewards_train/chosen': '-0.24611', 'rewards_train/rejected': '-0.38889', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.14299', 'logps_train/rejected': '-112.29', 'logps_train/chosen': '-131.36', 'loss/train': '0.64928', 'examples_per_second': '5.6724', 'grad_norm': '16.25', 'counters/examples': 28928, 'counters/updates': 1808}
skipping logging after 28944 examples to avoid logging too frequently
skipping logging after 28960 examples to avoid logging too frequently
skipping logging after 28976 examples to avoid logging too frequently
train stats after 28992 examples: {'rewards_train/chosen': '-0.24684', 'rewards_train/rejected': '-0.30287', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.056076', 'logps_train/rejected': '-132.96', 'logps_train/chosen': '-142.53', 'loss/train': '0.67941', 'examples_per_second': '5.2972', 'grad_norm': '18.75', 'counters/examples': 28992, 'counters/updates': 1812}
skipping logging after 29008 examples to avoid logging too frequently
skipping logging after 29024 examples to avoid logging too frequently
skipping logging after 29040 examples to avoid logging too frequently
train stats after 29056 examples: {'rewards_train/chosen': '-0.35146', 'rewards_train/rejected': '-0.40803', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.056497', 'logps_train/rejected': '-113.45', 'logps_train/chosen': '-109.47', 'loss/train': '0.67909', 'examples_per_second': '4.9351', 'grad_norm': '15.5', 'counters/examples': 29056, 'counters/updates': 1816}
skipping logging after 29072 examples to avoid logging too frequently
skipping logging after 29088 examples to avoid logging too frequently
skipping logging after 29104 examples to avoid logging too frequently
train stats after 29120 examples: {'rewards_train/chosen': '-0.37045', 'rewards_train/rejected': '-0.2997', 'rewards_train/accuracies': '0.39062', 'rewards_train/margins': '-0.07078', 'logps_train/rejected': '-107.82', 'logps_train/chosen': '-114.95', 'loss/train': '0.74109', 'examples_per_second': '4.5523', 'grad_norm': '22', 'counters/examples': 29120, 'counters/updates': 1820}
skipping logging after 29136 examples to avoid logging too frequently
skipping logging after 29152 examples to avoid logging too frequently
skipping logging after 29168 examples to avoid logging too frequently
train stats after 29184 examples: {'rewards_train/chosen': '-0.25879', 'rewards_train/rejected': '-0.41021', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.15145', 'logps_train/rejected': '-137.6', 'logps_train/chosen': '-132.07', 'loss/train': '0.64325', 'examples_per_second': '4.5479', 'grad_norm': '19.125', 'counters/examples': 29184, 'counters/updates': 1824}
skipping logging after 29200 examples to avoid logging too frequently
skipping logging after 29216 examples to avoid logging too frequently
skipping logging after 29232 examples to avoid logging too frequently
train stats after 29248 examples: {'rewards_train/chosen': '-0.23475', 'rewards_train/rejected': '-0.32775', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.092978', 'logps_train/rejected': '-131.23', 'logps_train/chosen': '-137.61', 'loss/train': '0.66592', 'examples_per_second': '5.5636', 'grad_norm': '18.625', 'counters/examples': 29248, 'counters/updates': 1828}
skipping logging after 29264 examples to avoid logging too frequently
skipping logging after 29280 examples to avoid logging too frequently
skipping logging after 29296 examples to avoid logging too frequently
train stats after 29312 examples: {'rewards_train/chosen': '-0.41498', 'rewards_train/rejected': '-0.44531', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.03027', 'logps_train/rejected': '-123.03', 'logps_train/chosen': '-104.28', 'loss/train': '0.698', 'examples_per_second': '4.261', 'grad_norm': '20', 'counters/examples': 29312, 'counters/updates': 1832}
skipping logging after 29328 examples to avoid logging too frequently
skipping logging after 29344 examples to avoid logging too frequently
skipping logging after 29360 examples to avoid logging too frequently
train stats after 29376 examples: {'rewards_train/chosen': '-0.28591', 'rewards_train/rejected': '-0.31716', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.031305', 'logps_train/rejected': '-136.52', 'logps_train/chosen': '-128.03', 'loss/train': '0.68707', 'examples_per_second': '4.1736', 'grad_norm': '16.5', 'counters/examples': 29376, 'counters/updates': 1836}
skipping logging after 29392 examples to avoid logging too frequently
skipping logging after 29408 examples to avoid logging too frequently
skipping logging after 29424 examples to avoid logging too frequently
train stats after 29440 examples: {'rewards_train/chosen': '-0.42058', 'rewards_train/rejected': '-0.457', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.036343', 'logps_train/rejected': '-158.47', 'logps_train/chosen': '-148.58', 'loss/train': '0.70421', 'examples_per_second': '4.4775', 'grad_norm': '20.5', 'counters/examples': 29440, 'counters/updates': 1840}
skipping logging after 29456 examples to avoid logging too frequently
skipping logging after 29472 examples to avoid logging too frequently
skipping logging after 29488 examples to avoid logging too frequently
train stats after 29504 examples: {'rewards_train/chosen': '-0.25164', 'rewards_train/rejected': '-0.3894', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.13784', 'logps_train/rejected': '-91.698', 'logps_train/chosen': '-118.39', 'loss/train': '0.6391', 'examples_per_second': '4.168', 'grad_norm': '14.938', 'counters/examples': 29504, 'counters/updates': 1844}
skipping logging after 29520 examples to avoid logging too frequently
skipping logging after 29536 examples to avoid logging too frequently
skipping logging after 29552 examples to avoid logging too frequently
train stats after 29568 examples: {'rewards_train/chosen': '-0.22752', 'rewards_train/rejected': '-0.36436', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.13689', 'logps_train/rejected': '-102.59', 'logps_train/chosen': '-129.35', 'loss/train': '0.64214', 'examples_per_second': '5.2383', 'grad_norm': '17.75', 'counters/examples': 29568, 'counters/updates': 1848}
skipping logging after 29584 examples to avoid logging too frequently
skipping logging after 29600 examples to avoid logging too frequently
skipping logging after 29616 examples to avoid logging too frequently
train stats after 29632 examples: {'rewards_train/chosen': '-0.3696', 'rewards_train/rejected': '-0.45652', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.086922', 'logps_train/rejected': '-116.76', 'logps_train/chosen': '-110.91', 'loss/train': '0.6615', 'examples_per_second': '5.4704', 'grad_norm': '14.812', 'counters/examples': 29632, 'counters/updates': 1852}
skipping logging after 29648 examples to avoid logging too frequently
skipping logging after 29664 examples to avoid logging too frequently
skipping logging after 29680 examples to avoid logging too frequently
train stats after 29696 examples: {'rewards_train/chosen': '-0.23349', 'rewards_train/rejected': '-0.26077', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.027297', 'logps_train/rejected': '-148.1', 'logps_train/chosen': '-145.52', 'loss/train': '0.69113', 'examples_per_second': '4.9534', 'grad_norm': '17.875', 'counters/examples': 29696, 'counters/updates': 1856}
skipping logging after 29712 examples to avoid logging too frequently
skipping logging after 29728 examples to avoid logging too frequently
skipping logging after 29744 examples to avoid logging too frequently
train stats after 29760 examples: {'rewards_train/chosen': '-0.38551', 'rewards_train/rejected': '-0.41917', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.033651', 'logps_train/rejected': '-130.03', 'logps_train/chosen': '-118.68', 'loss/train': '0.69557', 'examples_per_second': '5.4794', 'grad_norm': '19.375', 'counters/examples': 29760, 'counters/updates': 1860}
Running evaluation after 29760 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 29760: {'rewards_eval/chosen': '-0.2793', 'rewards_eval/rejected': '-0.34629', 'rewards_eval/accuracies': '0.53125', 'rewards_eval/margins': '0.067024', 'logps_eval/rejected': '-125.62', 'logps_eval/chosen': '-121.29', 'loss/eval': '0.6767'}
skipping logging after 29776 examples to avoid logging too frequently
skipping logging after 29792 examples to avoid logging too frequently
skipping logging after 29808 examples to avoid logging too frequently
train stats after 29824 examples: {'rewards_train/chosen': '-0.28905', 'rewards_train/rejected': '-0.27092', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '-0.018152', 'logps_train/rejected': '-145.49', 'logps_train/chosen': '-124.65', 'loss/train': '0.71466', 'examples_per_second': '4.6348', 'grad_norm': '22.875', 'counters/examples': 29824, 'counters/updates': 1864}
skipping logging after 29840 examples to avoid logging too frequently
skipping logging after 29856 examples to avoid logging too frequently
skipping logging after 29872 examples to avoid logging too frequently
train stats after 29888 examples: {'rewards_train/chosen': '-0.33107', 'rewards_train/rejected': '-0.38886', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.057693', 'logps_train/rejected': '-116.88', 'logps_train/chosen': '-154.78', 'loss/train': '0.67749', 'examples_per_second': '5.4149', 'grad_norm': '18.125', 'counters/examples': 29888, 'counters/updates': 1868}
skipping logging after 29904 examples to avoid logging too frequently
skipping logging after 29920 examples to avoid logging too frequently
skipping logging after 29936 examples to avoid logging too frequently
train stats after 29952 examples: {'rewards_train/chosen': '-0.22089', 'rewards_train/rejected': '-0.26409', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.043209', 'logps_train/rejected': '-109.96', 'logps_train/chosen': '-100.05', 'loss/train': '0.68915', 'examples_per_second': '5.4049', 'grad_norm': '15.688', 'counters/examples': 29952, 'counters/updates': 1872}
skipping logging after 29968 examples to avoid logging too frequently
skipping logging after 29984 examples to avoid logging too frequently
skipping logging after 30000 examples to avoid logging too frequently
train stats after 30016 examples: {'rewards_train/chosen': '-0.22931', 'rewards_train/rejected': '-0.29838', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.069019', 'logps_train/rejected': '-118.16', 'logps_train/chosen': '-129.26', 'loss/train': '0.67023', 'examples_per_second': '4.977', 'grad_norm': '16.25', 'counters/examples': 30016, 'counters/updates': 1876}
skipping logging after 30032 examples to avoid logging too frequently
skipping logging after 30048 examples to avoid logging too frequently
skipping logging after 30064 examples to avoid logging too frequently
train stats after 30080 examples: {'rewards_train/chosen': '-0.28818', 'rewards_train/rejected': '-0.31231', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.024159', 'logps_train/rejected': '-99.123', 'logps_train/chosen': '-104.73', 'loss/train': '0.69543', 'examples_per_second': '4.9515', 'grad_norm': '16', 'counters/examples': 30080, 'counters/updates': 1880}
skipping logging after 30096 examples to avoid logging too frequently
skipping logging after 30112 examples to avoid logging too frequently
skipping logging after 30128 examples to avoid logging too frequently
train stats after 30144 examples: {'rewards_train/chosen': '-0.28159', 'rewards_train/rejected': '-0.32694', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.045302', 'logps_train/rejected': '-154.49', 'logps_train/chosen': '-144.03', 'loss/train': '0.6813', 'examples_per_second': '4.6085', 'grad_norm': '18.5', 'counters/examples': 30144, 'counters/updates': 1884}
skipping logging after 30160 examples to avoid logging too frequently
skipping logging after 30176 examples to avoid logging too frequently
skipping logging after 30192 examples to avoid logging too frequently
train stats after 30208 examples: {'rewards_train/chosen': '-0.297', 'rewards_train/rejected': '-0.36143', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.064375', 'logps_train/rejected': '-111.16', 'logps_train/chosen': '-121.86', 'loss/train': '0.68002', 'examples_per_second': '5.392', 'grad_norm': '18.75', 'counters/examples': 30208, 'counters/updates': 1888}
skipping logging after 30224 examples to avoid logging too frequently
skipping logging after 30240 examples to avoid logging too frequently
skipping logging after 30256 examples to avoid logging too frequently
train stats after 30272 examples: {'rewards_train/chosen': '-0.24569', 'rewards_train/rejected': '-0.29597', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.050175', 'logps_train/rejected': '-113.04', 'logps_train/chosen': '-129.69', 'loss/train': '0.67963', 'examples_per_second': '6.2447', 'grad_norm': '17.5', 'counters/examples': 30272, 'counters/updates': 1892}
skipping logging after 30288 examples to avoid logging too frequently
skipping logging after 30304 examples to avoid logging too frequently
skipping logging after 30320 examples to avoid logging too frequently
train stats after 30336 examples: {'rewards_train/chosen': '-0.2942', 'rewards_train/rejected': '-0.29584', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.0016537', 'logps_train/rejected': '-90.696', 'logps_train/chosen': '-104.42', 'loss/train': '0.70621', 'examples_per_second': '5.6023', 'grad_norm': '15.938', 'counters/examples': 30336, 'counters/updates': 1896}
skipping logging after 30352 examples to avoid logging too frequently
skipping logging after 30368 examples to avoid logging too frequently
skipping logging after 30384 examples to avoid logging too frequently
train stats after 30400 examples: {'rewards_train/chosen': '-0.26918', 'rewards_train/rejected': '-0.31954', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.050365', 'logps_train/rejected': '-121.01', 'logps_train/chosen': '-134.5', 'loss/train': '0.68069', 'examples_per_second': '4.7161', 'grad_norm': '18.25', 'counters/examples': 30400, 'counters/updates': 1900}
skipping logging after 30416 examples to avoid logging too frequently
skipping logging after 30432 examples to avoid logging too frequently
skipping logging after 30448 examples to avoid logging too frequently
train stats after 30464 examples: {'rewards_train/chosen': '-0.30738', 'rewards_train/rejected': '-0.3736', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.066147', 'logps_train/rejected': '-91.147', 'logps_train/chosen': '-133.76', 'loss/train': '0.67114', 'examples_per_second': '6.3639', 'grad_norm': '20.375', 'counters/examples': 30464, 'counters/updates': 1904}
skipping logging after 30480 examples to avoid logging too frequently
skipping logging after 30496 examples to avoid logging too frequently
skipping logging after 30512 examples to avoid logging too frequently
train stats after 30528 examples: {'rewards_train/chosen': '-0.2439', 'rewards_train/rejected': '-0.30793', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.064028', 'logps_train/rejected': '-111.3', 'logps_train/chosen': '-106.55', 'loss/train': '0.67206', 'examples_per_second': '5.23', 'grad_norm': '17', 'counters/examples': 30528, 'counters/updates': 1908}
skipping logging after 30544 examples to avoid logging too frequently
skipping logging after 30560 examples to avoid logging too frequently
skipping logging after 30576 examples to avoid logging too frequently
train stats after 30592 examples: {'rewards_train/chosen': '-0.29863', 'rewards_train/rejected': '-0.37486', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.076215', 'logps_train/rejected': '-104.88', 'logps_train/chosen': '-105.6', 'loss/train': '0.67143', 'examples_per_second': '5.124', 'grad_norm': '17.625', 'counters/examples': 30592, 'counters/updates': 1912}
skipping logging after 30608 examples to avoid logging too frequently
skipping logging after 30624 examples to avoid logging too frequently
skipping logging after 30640 examples to avoid logging too frequently
train stats after 30656 examples: {'rewards_train/chosen': '-0.34075', 'rewards_train/rejected': '-0.32206', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '-0.018749', 'logps_train/rejected': '-106.64', 'logps_train/chosen': '-105.03', 'loss/train': '0.71286', 'examples_per_second': '4.408', 'grad_norm': '16', 'counters/examples': 30656, 'counters/updates': 1916}
skipping logging after 30672 examples to avoid logging too frequently
skipping logging after 30688 examples to avoid logging too frequently
skipping logging after 30704 examples to avoid logging too frequently
train stats after 30720 examples: {'rewards_train/chosen': '-0.3165', 'rewards_train/rejected': '-0.34489', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.028397', 'logps_train/rejected': '-124.53', 'logps_train/chosen': '-137.19', 'loss/train': '0.68997', 'examples_per_second': '5.6714', 'grad_norm': '18.25', 'counters/examples': 30720, 'counters/updates': 1920}
skipping logging after 30736 examples to avoid logging too frequently
skipping logging after 30752 examples to avoid logging too frequently
Running evaluation after 30752 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:16,  2.48s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:06,  2.22s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:56,  1.94s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.91s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.55s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.65s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 30752: {'rewards_eval/chosen': '-0.24539', 'rewards_eval/rejected': '-0.31104', 'rewards_eval/accuracies': '0.55273', 'rewards_eval/margins': '0.065632', 'logps_eval/rejected': '-125.27', 'logps_eval/chosen': '-120.95', 'loss/eval': '0.67472'}
skipping logging after 30768 examples to avoid logging too frequently
train stats after 30784 examples: {'rewards_train/chosen': '-0.23774', 'rewards_train/rejected': '-0.32127', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.083466', 'logps_train/rejected': '-122.84', 'logps_train/chosen': '-100.68', 'loss/train': '0.67444', 'examples_per_second': '5.099', 'grad_norm': '15.875', 'counters/examples': 30784, 'counters/updates': 1924}
skipping logging after 30800 examples to avoid logging too frequently
skipping logging after 30816 examples to avoid logging too frequently
skipping logging after 30832 examples to avoid logging too frequently
train stats after 30848 examples: {'rewards_train/chosen': '-0.27852', 'rewards_train/rejected': '-0.28171', 'rewards_train/accuracies': '0.42188', 'rewards_train/margins': '0.0032387', 'logps_train/rejected': '-110.59', 'logps_train/chosen': '-114.5', 'loss/train': '0.70917', 'examples_per_second': '5.7141', 'grad_norm': '16.625', 'counters/examples': 30848, 'counters/updates': 1928}
skipping logging after 30864 examples to avoid logging too frequently
skipping logging after 30880 examples to avoid logging too frequently
skipping logging after 30896 examples to avoid logging too frequently
train stats after 30912 examples: {'rewards_train/chosen': '-0.24045', 'rewards_train/rejected': '-0.35269', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.11218', 'logps_train/rejected': '-107.05', 'logps_train/chosen': '-94.784', 'loss/train': '0.65254', 'examples_per_second': '5.9021', 'grad_norm': '17', 'counters/examples': 30912, 'counters/updates': 1932}
skipping logging after 30928 examples to avoid logging too frequently
skipping logging after 30944 examples to avoid logging too frequently
skipping logging after 30960 examples to avoid logging too frequently
train stats after 30976 examples: {'rewards_train/chosen': '-0.21564', 'rewards_train/rejected': '-0.28745', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.071865', 'logps_train/rejected': '-108.27', 'logps_train/chosen': '-109.47', 'loss/train': '0.67416', 'examples_per_second': '5.5476', 'grad_norm': '17.25', 'counters/examples': 30976, 'counters/updates': 1936}
skipping logging after 30992 examples to avoid logging too frequently
skipping logging after 31008 examples to avoid logging too frequently
skipping logging after 31024 examples to avoid logging too frequently
train stats after 31040 examples: {'rewards_train/chosen': '-0.19751', 'rewards_train/rejected': '-0.2978', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.10023', 'logps_train/rejected': '-137.63', 'logps_train/chosen': '-138.96', 'loss/train': '0.66507', 'examples_per_second': '5.2961', 'grad_norm': '19.125', 'counters/examples': 31040, 'counters/updates': 1940}
skipping logging after 31056 examples to avoid logging too frequently
skipping logging after 31072 examples to avoid logging too frequently
skipping logging after 31088 examples to avoid logging too frequently
train stats after 31104 examples: {'rewards_train/chosen': '-0.30858', 'rewards_train/rejected': '-0.33554', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.026953', 'logps_train/rejected': '-110.81', 'logps_train/chosen': '-88.669', 'loss/train': '0.69427', 'examples_per_second': '5.9289', 'grad_norm': '16.375', 'counters/examples': 31104, 'counters/updates': 1944}
skipping logging after 31120 examples to avoid logging too frequently
skipping logging after 31136 examples to avoid logging too frequently
skipping logging after 31152 examples to avoid logging too frequently
train stats after 31168 examples: {'rewards_train/chosen': '-0.20628', 'rewards_train/rejected': '-0.26804', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.061634', 'logps_train/rejected': '-118.27', 'logps_train/chosen': '-110.11', 'loss/train': '0.67667', 'examples_per_second': '4.9462', 'grad_norm': '16.5', 'counters/examples': 31168, 'counters/updates': 1948}
skipping logging after 31184 examples to avoid logging too frequently
skipping logging after 31200 examples to avoid logging too frequently
skipping logging after 31216 examples to avoid logging too frequently
train stats after 31232 examples: {'rewards_train/chosen': '-0.21103', 'rewards_train/rejected': '-0.26444', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.053388', 'logps_train/rejected': '-109.88', 'logps_train/chosen': '-106.22', 'loss/train': '0.67261', 'examples_per_second': '5.0722', 'grad_norm': '16.375', 'counters/examples': 31232, 'counters/updates': 1952}
skipping logging after 31248 examples to avoid logging too frequently
skipping logging after 31264 examples to avoid logging too frequently
skipping logging after 31280 examples to avoid logging too frequently
train stats after 31296 examples: {'rewards_train/chosen': '-0.24038', 'rewards_train/rejected': '-0.31565', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.075258', 'logps_train/rejected': '-108.33', 'logps_train/chosen': '-104.92', 'loss/train': '0.66708', 'examples_per_second': '6.1314', 'grad_norm': '14.312', 'counters/examples': 31296, 'counters/updates': 1956}
skipping logging after 31312 examples to avoid logging too frequently
skipping logging after 31328 examples to avoid logging too frequently
skipping logging after 31344 examples to avoid logging too frequently
train stats after 31360 examples: {'rewards_train/chosen': '-0.24656', 'rewards_train/rejected': '-0.31454', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.068043', 'logps_train/rejected': '-105.2', 'logps_train/chosen': '-113.66', 'loss/train': '0.66861', 'examples_per_second': '6.0426', 'grad_norm': '21.75', 'counters/examples': 31360, 'counters/updates': 1960}
skipping logging after 31376 examples to avoid logging too frequently
skipping logging after 31392 examples to avoid logging too frequently
skipping logging after 31408 examples to avoid logging too frequently
train stats after 31424 examples: {'rewards_train/chosen': '-0.25829', 'rewards_train/rejected': '-0.37779', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.11936', 'logps_train/rejected': '-112.12', 'logps_train/chosen': '-135.89', 'loss/train': '0.65279', 'examples_per_second': '5.2785', 'grad_norm': '17.5', 'counters/examples': 31424, 'counters/updates': 1964}
skipping logging after 31440 examples to avoid logging too frequently
skipping logging after 31456 examples to avoid logging too frequently
skipping logging after 31472 examples to avoid logging too frequently
train stats after 31488 examples: {'rewards_train/chosen': '-0.33706', 'rewards_train/rejected': '-0.40088', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.063938', 'logps_train/rejected': '-175.46', 'logps_train/chosen': '-114.74', 'loss/train': '0.67532', 'examples_per_second': '3.6679', 'grad_norm': '16.875', 'counters/examples': 31488, 'counters/updates': 1968}
skipping logging after 31504 examples to avoid logging too frequently
skipping logging after 31520 examples to avoid logging too frequently
skipping logging after 31536 examples to avoid logging too frequently
train stats after 31552 examples: {'rewards_train/chosen': '-0.31026', 'rewards_train/rejected': '-0.42968', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.11943', 'logps_train/rejected': '-100.15', 'logps_train/chosen': '-102.26', 'loss/train': '0.64807', 'examples_per_second': '5.4688', 'grad_norm': '14.188', 'counters/examples': 31552, 'counters/updates': 1972}
skipping logging after 31568 examples to avoid logging too frequently
skipping logging after 31584 examples to avoid logging too frequently
skipping logging after 31600 examples to avoid logging too frequently
train stats after 31616 examples: {'rewards_train/chosen': '-0.31132', 'rewards_train/rejected': '-0.41591', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.1047', 'logps_train/rejected': '-108.02', 'logps_train/chosen': '-115.91', 'loss/train': '0.66699', 'examples_per_second': '4.8962', 'grad_norm': '17.25', 'counters/examples': 31616, 'counters/updates': 1976}
skipping logging after 31632 examples to avoid logging too frequently
skipping logging after 31648 examples to avoid logging too frequently
skipping logging after 31664 examples to avoid logging too frequently
train stats after 31680 examples: {'rewards_train/chosen': '-0.40665', 'rewards_train/rejected': '-0.3923', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '-0.014277', 'logps_train/rejected': '-122.24', 'logps_train/chosen': '-103.67', 'loss/train': '0.71655', 'examples_per_second': '5.5803', 'grad_norm': '17.25', 'counters/examples': 31680, 'counters/updates': 1980}
skipping logging after 31696 examples to avoid logging too frequently
skipping logging after 31712 examples to avoid logging too frequently
skipping logging after 31728 examples to avoid logging too frequently
train stats after 31744 examples: {'rewards_train/chosen': '-0.36331', 'rewards_train/rejected': '-0.44902', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.085598', 'logps_train/rejected': '-135.51', 'logps_train/chosen': '-118.34', 'loss/train': '0.67238', 'examples_per_second': '4.8458', 'grad_norm': '15.25', 'counters/examples': 31744, 'counters/updates': 1984}
Running evaluation after 31744 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.30s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 31744: {'rewards_eval/chosen': '-0.30048', 'rewards_eval/rejected': '-0.36974', 'rewards_eval/accuracies': '0.53906', 'rewards_eval/margins': '0.069246', 'logps_eval/rejected': '-125.85', 'logps_eval/chosen': '-121.5', 'loss/eval': '0.6756'}
skipping logging after 31760 examples to avoid logging too frequently
skipping logging after 31776 examples to avoid logging too frequently
skipping logging after 31792 examples to avoid logging too frequently
train stats after 31808 examples: {'rewards_train/chosen': '-0.32566', 'rewards_train/rejected': '-0.42603', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.10024', 'logps_train/rejected': '-115.61', 'logps_train/chosen': '-116.87', 'loss/train': '0.65918', 'examples_per_second': '5.6336', 'grad_norm': '15.25', 'counters/examples': 31808, 'counters/updates': 1988}
skipping logging after 31824 examples to avoid logging too frequently
skipping logging after 31840 examples to avoid logging too frequently
skipping logging after 31856 examples to avoid logging too frequently
train stats after 31872 examples: {'rewards_train/chosen': '-0.33773', 'rewards_train/rejected': '-0.3966', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.058865', 'logps_train/rejected': '-110.55', 'logps_train/chosen': '-112.86', 'loss/train': '0.67212', 'examples_per_second': '4.7679', 'grad_norm': '14.5', 'counters/examples': 31872, 'counters/updates': 1992}
skipping logging after 31888 examples to avoid logging too frequently
skipping logging after 31904 examples to avoid logging too frequently
skipping logging after 31920 examples to avoid logging too frequently
train stats after 31936 examples: {'rewards_train/chosen': '-0.31933', 'rewards_train/rejected': '-0.40848', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.089134', 'logps_train/rejected': '-113.76', 'logps_train/chosen': '-121.06', 'loss/train': '0.66373', 'examples_per_second': '5.2337', 'grad_norm': '14.25', 'counters/examples': 31936, 'counters/updates': 1996}
skipping logging after 31952 examples to avoid logging too frequently
skipping logging after 31968 examples to avoid logging too frequently
skipping logging after 31984 examples to avoid logging too frequently
train stats after 32000 examples: {'rewards_train/chosen': '-0.29685', 'rewards_train/rejected': '-0.38088', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.084046', 'logps_train/rejected': '-104.18', 'logps_train/chosen': '-108.73', 'loss/train': '0.66153', 'examples_per_second': '5.6297', 'grad_norm': '17.875', 'counters/examples': 32000, 'counters/updates': 2000}
skipping logging after 32016 examples to avoid logging too frequently
skipping logging after 32032 examples to avoid logging too frequently
skipping logging after 32048 examples to avoid logging too frequently
train stats after 32064 examples: {'rewards_train/chosen': '-0.31392', 'rewards_train/rejected': '-0.40119', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.087284', 'logps_train/rejected': '-156.35', 'logps_train/chosen': '-136.1', 'loss/train': '0.67004', 'examples_per_second': '4.7676', 'grad_norm': '17', 'counters/examples': 32064, 'counters/updates': 2004}
skipping logging after 32080 examples to avoid logging too frequently
skipping logging after 32096 examples to avoid logging too frequently
skipping logging after 32112 examples to avoid logging too frequently
train stats after 32128 examples: {'rewards_train/chosen': '-0.28243', 'rewards_train/rejected': '-0.31525', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.032768', 'logps_train/rejected': '-112.66', 'logps_train/chosen': '-116.54', 'loss/train': '0.68817', 'examples_per_second': '4.2043', 'grad_norm': '16.25', 'counters/examples': 32128, 'counters/updates': 2008}
skipping logging after 32144 examples to avoid logging too frequently
skipping logging after 32160 examples to avoid logging too frequently
skipping logging after 32176 examples to avoid logging too frequently
train stats after 32192 examples: {'rewards_train/chosen': '-0.2848', 'rewards_train/rejected': '-0.29098', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.0062389', 'logps_train/rejected': '-111.28', 'logps_train/chosen': '-126.29', 'loss/train': '0.70642', 'examples_per_second': '4.9641', 'grad_norm': '18.625', 'counters/examples': 32192, 'counters/updates': 2012}
skipping logging after 32208 examples to avoid logging too frequently
skipping logging after 32224 examples to avoid logging too frequently
skipping logging after 32240 examples to avoid logging too frequently
train stats after 32256 examples: {'rewards_train/chosen': '-0.27034', 'rewards_train/rejected': '-0.26817', 'rewards_train/accuracies': '0.39062', 'rewards_train/margins': '-0.0021286', 'logps_train/rejected': '-149.07', 'logps_train/chosen': '-147.59', 'loss/train': '0.70416', 'examples_per_second': '4.7359', 'grad_norm': '23.375', 'counters/examples': 32256, 'counters/updates': 2016}
skipping logging after 32272 examples to avoid logging too frequently
skipping logging after 32288 examples to avoid logging too frequently
skipping logging after 32304 examples to avoid logging too frequently
train stats after 32320 examples: {'rewards_train/chosen': '-0.31669', 'rewards_train/rejected': '-0.38195', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.065289', 'logps_train/rejected': '-106.26', 'logps_train/chosen': '-116.62', 'loss/train': '0.67151', 'examples_per_second': '5.3669', 'grad_norm': '16.375', 'counters/examples': 32320, 'counters/updates': 2020}
skipping logging after 32336 examples to avoid logging too frequently
skipping logging after 32352 examples to avoid logging too frequently
skipping logging after 32368 examples to avoid logging too frequently
train stats after 32384 examples: {'rewards_train/chosen': '-0.31477', 'rewards_train/rejected': '-0.46101', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.14615', 'logps_train/rejected': '-115.28', 'logps_train/chosen': '-126.3', 'loss/train': '0.63783', 'examples_per_second': '4.7665', 'grad_norm': '18', 'counters/examples': 32384, 'counters/updates': 2024}
skipping logging after 32400 examples to avoid logging too frequently
skipping logging after 32416 examples to avoid logging too frequently
skipping logging after 32432 examples to avoid logging too frequently
train stats after 32448 examples: {'rewards_train/chosen': '-0.43196', 'rewards_train/rejected': '-0.50349', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.071625', 'logps_train/rejected': '-123.66', 'logps_train/chosen': '-93.006', 'loss/train': '0.67062', 'examples_per_second': '5.0591', 'grad_norm': '15.438', 'counters/examples': 32448, 'counters/updates': 2028}
skipping logging after 32464 examples to avoid logging too frequently
skipping logging after 32480 examples to avoid logging too frequently
skipping logging after 32496 examples to avoid logging too frequently
train stats after 32512 examples: {'rewards_train/chosen': '-0.3537', 'rewards_train/rejected': '-0.39415', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.040524', 'logps_train/rejected': '-100.17', 'logps_train/chosen': '-114.91', 'loss/train': '0.69064', 'examples_per_second': '5.7517', 'grad_norm': '27.125', 'counters/examples': 32512, 'counters/updates': 2032}
skipping logging after 32528 examples to avoid logging too frequently
skipping logging after 32544 examples to avoid logging too frequently
skipping logging after 32560 examples to avoid logging too frequently
train stats after 32576 examples: {'rewards_train/chosen': '-0.34517', 'rewards_train/rejected': '-0.39957', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.054329', 'logps_train/rejected': '-127.2', 'logps_train/chosen': '-114.26', 'loss/train': '0.67871', 'examples_per_second': '4.5865', 'grad_norm': '16.375', 'counters/examples': 32576, 'counters/updates': 2036}
skipping logging after 32592 examples to avoid logging too frequently
skipping logging after 32608 examples to avoid logging too frequently
skipping logging after 32624 examples to avoid logging too frequently
train stats after 32640 examples: {'rewards_train/chosen': '-0.33269', 'rewards_train/rejected': '-0.39522', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.062462', 'logps_train/rejected': '-121.23', 'logps_train/chosen': '-111.67', 'loss/train': '0.67744', 'examples_per_second': '5.7556', 'grad_norm': '16.375', 'counters/examples': 32640, 'counters/updates': 2040}
skipping logging after 32656 examples to avoid logging too frequently
skipping logging after 32672 examples to avoid logging too frequently
skipping logging after 32688 examples to avoid logging too frequently
train stats after 32704 examples: {'rewards_train/chosen': '-0.43058', 'rewards_train/rejected': '-0.47441', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.043762', 'logps_train/rejected': '-121.35', 'logps_train/chosen': '-132.96', 'loss/train': '0.69446', 'examples_per_second': '4.8073', 'grad_norm': '18.25', 'counters/examples': 32704, 'counters/updates': 2044}
skipping logging after 32720 examples to avoid logging too frequently
skipping logging after 32736 examples to avoid logging too frequently
Running evaluation after 32736 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:14,  2.41s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:05,  2.20s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:56,  1.94s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.91s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.55s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.65s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.48s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.55s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 32736: {'rewards_eval/chosen': '-0.33673', 'rewards_eval/rejected': '-0.40551', 'rewards_eval/accuracies': '0.52734', 'rewards_eval/margins': '0.068782', 'logps_eval/rejected': '-126.21', 'logps_eval/chosen': '-121.86', 'loss/eval': '0.67676'}
skipping logging after 32752 examples to avoid logging too frequently
train stats after 32768 examples: {'rewards_train/chosen': '-0.36769', 'rewards_train/rejected': '-0.43033', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.062464', 'logps_train/rejected': '-105.41', 'logps_train/chosen': '-113.12', 'loss/train': '0.67963', 'examples_per_second': '5.7582', 'grad_norm': '15.812', 'counters/examples': 32768, 'counters/updates': 2048}
skipping logging after 32784 examples to avoid logging too frequently
skipping logging after 32800 examples to avoid logging too frequently
skipping logging after 32816 examples to avoid logging too frequently
train stats after 32832 examples: {'rewards_train/chosen': '-0.27222', 'rewards_train/rejected': '-0.37267', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.10056', 'logps_train/rejected': '-145.26', 'logps_train/chosen': '-136.6', 'loss/train': '0.6674', 'examples_per_second': '5.2434', 'grad_norm': '20.125', 'counters/examples': 32832, 'counters/updates': 2052}
skipping logging after 32848 examples to avoid logging too frequently
skipping logging after 32864 examples to avoid logging too frequently
skipping logging after 32880 examples to avoid logging too frequently
train stats after 32896 examples: {'rewards_train/chosen': '-0.39848', 'rewards_train/rejected': '-0.39053', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '-0.0079651', 'logps_train/rejected': '-123.99', 'logps_train/chosen': '-110.04', 'loss/train': '0.7198', 'examples_per_second': '6.0029', 'grad_norm': '20', 'counters/examples': 32896, 'counters/updates': 2056}
skipping logging after 32912 examples to avoid logging too frequently
skipping logging after 32928 examples to avoid logging too frequently
skipping logging after 32944 examples to avoid logging too frequently
train stats after 32960 examples: {'rewards_train/chosen': '-0.28295', 'rewards_train/rejected': '-0.34423', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.061174', 'logps_train/rejected': '-150.23', 'logps_train/chosen': '-147.15', 'loss/train': '0.67282', 'examples_per_second': '4.3626', 'grad_norm': '16.875', 'counters/examples': 32960, 'counters/updates': 2060}
skipping logging after 32976 examples to avoid logging too frequently
skipping logging after 32992 examples to avoid logging too frequently
skipping logging after 33008 examples to avoid logging too frequently
train stats after 33024 examples: {'rewards_train/chosen': '-0.34359', 'rewards_train/rejected': '-0.43864', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.095112', 'logps_train/rejected': '-114.59', 'logps_train/chosen': '-129.77', 'loss/train': '0.66141', 'examples_per_second': '5.01', 'grad_norm': '19.375', 'counters/examples': 33024, 'counters/updates': 2064}
skipping logging after 33040 examples to avoid logging too frequently
skipping logging after 33056 examples to avoid logging too frequently
skipping logging after 33072 examples to avoid logging too frequently
train stats after 33088 examples: {'rewards_train/chosen': '-0.3144', 'rewards_train/rejected': '-0.38553', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.071117', 'logps_train/rejected': '-124.63', 'logps_train/chosen': '-137.9', 'loss/train': '0.67307', 'examples_per_second': '5.5121', 'grad_norm': '20.75', 'counters/examples': 33088, 'counters/updates': 2068}
skipping logging after 33104 examples to avoid logging too frequently
skipping logging after 33120 examples to avoid logging too frequently
skipping logging after 33136 examples to avoid logging too frequently
train stats after 33152 examples: {'rewards_train/chosen': '-0.30496', 'rewards_train/rejected': '-0.42205', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.11711', 'logps_train/rejected': '-108.24', 'logps_train/chosen': '-124.43', 'loss/train': '0.65768', 'examples_per_second': '5.6379', 'grad_norm': '17.625', 'counters/examples': 33152, 'counters/updates': 2072}
skipping logging after 33168 examples to avoid logging too frequently
skipping logging after 33184 examples to avoid logging too frequently
skipping logging after 33200 examples to avoid logging too frequently
train stats after 33216 examples: {'rewards_train/chosen': '-0.38944', 'rewards_train/rejected': '-0.46184', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.072382', 'logps_train/rejected': '-108.86', 'logps_train/chosen': '-119.51', 'loss/train': '0.67549', 'examples_per_second': '4.9831', 'grad_norm': '16.25', 'counters/examples': 33216, 'counters/updates': 2076}
skipping logging after 33232 examples to avoid logging too frequently
skipping logging after 33248 examples to avoid logging too frequently
skipping logging after 33264 examples to avoid logging too frequently
train stats after 33280 examples: {'rewards_train/chosen': '-0.42301', 'rewards_train/rejected': '-0.45846', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.035494', 'logps_train/rejected': '-137.12', 'logps_train/chosen': '-100.9', 'loss/train': '0.69189', 'examples_per_second': '4.3818', 'grad_norm': '18.5', 'counters/examples': 33280, 'counters/updates': 2080}
skipping logging after 33296 examples to avoid logging too frequently
skipping logging after 33312 examples to avoid logging too frequently
skipping logging after 33328 examples to avoid logging too frequently
train stats after 33344 examples: {'rewards_train/chosen': '-0.36422', 'rewards_train/rejected': '-0.45071', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.086561', 'logps_train/rejected': '-121.53', 'logps_train/chosen': '-127.96', 'loss/train': '0.66211', 'examples_per_second': '4.7169', 'grad_norm': '18.25', 'counters/examples': 33344, 'counters/updates': 2084}
skipping logging after 33360 examples to avoid logging too frequently
skipping logging after 33376 examples to avoid logging too frequently
skipping logging after 33392 examples to avoid logging too frequently
train stats after 33408 examples: {'rewards_train/chosen': '-0.33811', 'rewards_train/rejected': '-0.39836', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.060139', 'logps_train/rejected': '-118.68', 'logps_train/chosen': '-118.75', 'loss/train': '0.67549', 'examples_per_second': '5.2145', 'grad_norm': '17.25', 'counters/examples': 33408, 'counters/updates': 2088}
skipping logging after 33424 examples to avoid logging too frequently
skipping logging after 33440 examples to avoid logging too frequently
skipping logging after 33456 examples to avoid logging too frequently
train stats after 33472 examples: {'rewards_train/chosen': '-0.26251', 'rewards_train/rejected': '-0.33835', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.075939', 'logps_train/rejected': '-123.21', 'logps_train/chosen': '-138.86', 'loss/train': '0.67097', 'examples_per_second': '5.2823', 'grad_norm': '16.5', 'counters/examples': 33472, 'counters/updates': 2092}
skipping logging after 33488 examples to avoid logging too frequently
skipping logging after 33504 examples to avoid logging too frequently
skipping logging after 33520 examples to avoid logging too frequently
train stats after 33536 examples: {'rewards_train/chosen': '-0.31988', 'rewards_train/rejected': '-0.44658', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.12669', 'logps_train/rejected': '-123.39', 'logps_train/chosen': '-117.58', 'loss/train': '0.6516', 'examples_per_second': '5.9806', 'grad_norm': '19.5', 'counters/examples': 33536, 'counters/updates': 2096}
skipping logging after 33552 examples to avoid logging too frequently
skipping logging after 33568 examples to avoid logging too frequently
skipping logging after 33584 examples to avoid logging too frequently
train stats after 33600 examples: {'rewards_train/chosen': '-0.35946', 'rewards_train/rejected': '-0.37724', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.017706', 'logps_train/rejected': '-94.429', 'logps_train/chosen': '-105.07', 'loss/train': '0.69315', 'examples_per_second': '5.1378', 'grad_norm': '19.125', 'counters/examples': 33600, 'counters/updates': 2100}
skipping logging after 33616 examples to avoid logging too frequently
skipping logging after 33632 examples to avoid logging too frequently
skipping logging after 33648 examples to avoid logging too frequently
train stats after 33664 examples: {'rewards_train/chosen': '-0.26749', 'rewards_train/rejected': '-0.26973', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.0022678', 'logps_train/rejected': '-123.56', 'logps_train/chosen': '-128.8', 'loss/train': '0.71149', 'examples_per_second': '4.4274', 'grad_norm': '18.875', 'counters/examples': 33664, 'counters/updates': 2104}
skipping logging after 33680 examples to avoid logging too frequently
skipping logging after 33696 examples to avoid logging too frequently
skipping logging after 33712 examples to avoid logging too frequently
train stats after 33728 examples: {'rewards_train/chosen': '-0.27391', 'rewards_train/rejected': '-0.35503', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.081211', 'logps_train/rejected': '-119.21', 'logps_train/chosen': '-109.18', 'loss/train': '0.6835', 'examples_per_second': '6.0683', 'grad_norm': '18.5', 'counters/examples': 33728, 'counters/updates': 2108}
Running evaluation after 33728 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 33728: {'rewards_eval/chosen': '-0.24493', 'rewards_eval/rejected': '-0.31396', 'rewards_eval/accuracies': '0.54297', 'rewards_eval/margins': '0.069016', 'logps_eval/rejected': '-125.29', 'logps_eval/chosen': '-120.94', 'loss/eval': '0.67547'}
skipping logging after 33744 examples to avoid logging too frequently
skipping logging after 33760 examples to avoid logging too frequently
skipping logging after 33776 examples to avoid logging too frequently
train stats after 33792 examples: {'rewards_train/chosen': '-0.32194', 'rewards_train/rejected': '-0.30731', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '-0.014687', 'logps_train/rejected': '-120.52', 'logps_train/chosen': '-109.76', 'loss/train': '0.71582', 'examples_per_second': '6.0712', 'grad_norm': '17.125', 'counters/examples': 33792, 'counters/updates': 2112}
skipping logging after 33808 examples to avoid logging too frequently
skipping logging after 33824 examples to avoid logging too frequently
skipping logging after 33840 examples to avoid logging too frequently
train stats after 33856 examples: {'rewards_train/chosen': '-0.29647', 'rewards_train/rejected': '-0.35171', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.055157', 'logps_train/rejected': '-127.08', 'logps_train/chosen': '-124.43', 'loss/train': '0.69138', 'examples_per_second': '4.6471', 'grad_norm': '17.375', 'counters/examples': 33856, 'counters/updates': 2116}
skipping logging after 33872 examples to avoid logging too frequently
skipping logging after 33888 examples to avoid logging too frequently
skipping logging after 33904 examples to avoid logging too frequently
train stats after 33920 examples: {'rewards_train/chosen': '-0.34145', 'rewards_train/rejected': '-0.33873', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '-0.0026703', 'logps_train/rejected': '-136.73', 'logps_train/chosen': '-160.52', 'loss/train': '0.715', 'examples_per_second': '4.5152', 'grad_norm': '19.5', 'counters/examples': 33920, 'counters/updates': 2120}
skipping logging after 33936 examples to avoid logging too frequently
skipping logging after 33952 examples to avoid logging too frequently
skipping logging after 33968 examples to avoid logging too frequently
train stats after 33984 examples: {'rewards_train/chosen': '-0.26966', 'rewards_train/rejected': '-0.31735', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.047672', 'logps_train/rejected': '-120.69', 'logps_train/chosen': '-133.15', 'loss/train': '0.67944', 'examples_per_second': '4.8152', 'grad_norm': '18.75', 'counters/examples': 33984, 'counters/updates': 2124}
skipping logging after 34000 examples to avoid logging too frequently
skipping logging after 34016 examples to avoid logging too frequently
skipping logging after 34032 examples to avoid logging too frequently
train stats after 34048 examples: {'rewards_train/chosen': '-0.28318', 'rewards_train/rejected': '-0.31734', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.034187', 'logps_train/rejected': '-122.88', 'logps_train/chosen': '-137.93', 'loss/train': '0.69702', 'examples_per_second': '5.5565', 'grad_norm': '18.75', 'counters/examples': 34048, 'counters/updates': 2128}
skipping logging after 34064 examples to avoid logging too frequently
skipping logging after 34080 examples to avoid logging too frequently
skipping logging after 34096 examples to avoid logging too frequently
train stats after 34112 examples: {'rewards_train/chosen': '-0.19149', 'rewards_train/rejected': '-0.24728', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.055847', 'logps_train/rejected': '-120.27', 'logps_train/chosen': '-116.63', 'loss/train': '0.67627', 'examples_per_second': '5.4319', 'grad_norm': '15.562', 'counters/examples': 34112, 'counters/updates': 2132}
skipping logging after 34128 examples to avoid logging too frequently
skipping logging after 34144 examples to avoid logging too frequently
skipping logging after 34160 examples to avoid logging too frequently
train stats after 34176 examples: {'rewards_train/chosen': '-0.28425', 'rewards_train/rejected': '-0.29364', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.0093555', 'logps_train/rejected': '-139.58', 'logps_train/chosen': '-137.03', 'loss/train': '0.70293', 'examples_per_second': '4.856', 'grad_norm': '18.625', 'counters/examples': 34176, 'counters/updates': 2136}
skipping logging after 34192 examples to avoid logging too frequently
skipping logging after 34208 examples to avoid logging too frequently
skipping logging after 34224 examples to avoid logging too frequently
train stats after 34240 examples: {'rewards_train/chosen': '-0.24839', 'rewards_train/rejected': '-0.23321', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '-0.015121', 'logps_train/rejected': '-128.3', 'logps_train/chosen': '-105.5', 'loss/train': '0.70779', 'examples_per_second': '4.6665', 'grad_norm': '17.25', 'counters/examples': 34240, 'counters/updates': 2140}
skipping logging after 34256 examples to avoid logging too frequently
skipping logging after 34272 examples to avoid logging too frequently
skipping logging after 34288 examples to avoid logging too frequently
train stats after 34304 examples: {'rewards_train/chosen': '-0.25148', 'rewards_train/rejected': '-0.27983', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.02832', 'logps_train/rejected': '-98.497', 'logps_train/chosen': '-102.3', 'loss/train': '0.6991', 'examples_per_second': '4.8304', 'grad_norm': '15.688', 'counters/examples': 34304, 'counters/updates': 2144}
skipping logging after 34320 examples to avoid logging too frequently
skipping logging after 34336 examples to avoid logging too frequently
skipping logging after 34352 examples to avoid logging too frequently
train stats after 34368 examples: {'rewards_train/chosen': '-0.25089', 'rewards_train/rejected': '-0.27656', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.025742', 'logps_train/rejected': '-113.12', 'logps_train/chosen': '-140.74', 'loss/train': '0.6915', 'examples_per_second': '5.1559', 'grad_norm': '18.25', 'counters/examples': 34368, 'counters/updates': 2148}
skipping logging after 34384 examples to avoid logging too frequently
skipping logging after 34400 examples to avoid logging too frequently
skipping logging after 34416 examples to avoid logging too frequently
train stats after 34432 examples: {'rewards_train/chosen': '-0.27138', 'rewards_train/rejected': '-0.33767', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.066336', 'logps_train/rejected': '-104.14', 'logps_train/chosen': '-127.9', 'loss/train': '0.67358', 'examples_per_second': '5.8205', 'grad_norm': '16.25', 'counters/examples': 34432, 'counters/updates': 2152}
skipping logging after 34448 examples to avoid logging too frequently
skipping logging after 34464 examples to avoid logging too frequently
skipping logging after 34480 examples to avoid logging too frequently
train stats after 34496 examples: {'rewards_train/chosen': '-0.17983', 'rewards_train/rejected': '-0.29869', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.11883', 'logps_train/rejected': '-131.99', 'logps_train/chosen': '-138.1', 'loss/train': '0.64767', 'examples_per_second': '5.1389', 'grad_norm': '21.125', 'counters/examples': 34496, 'counters/updates': 2156}
skipping logging after 34512 examples to avoid logging too frequently
skipping logging after 34528 examples to avoid logging too frequently
skipping logging after 34544 examples to avoid logging too frequently
train stats after 34560 examples: {'rewards_train/chosen': '-0.23972', 'rewards_train/rejected': '-0.25881', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.019077', 'logps_train/rejected': '-124.61', 'logps_train/chosen': '-121.85', 'loss/train': '0.69211', 'examples_per_second': '6.1443', 'grad_norm': '15.875', 'counters/examples': 34560, 'counters/updates': 2160}
skipping logging after 34576 examples to avoid logging too frequently
skipping logging after 34592 examples to avoid logging too frequently
skipping logging after 34608 examples to avoid logging too frequently
train stats after 34624 examples: {'rewards_train/chosen': '-0.28738', 'rewards_train/rejected': '-0.38041', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.092937', 'logps_train/rejected': '-132.04', 'logps_train/chosen': '-128.05', 'loss/train': '0.66982', 'examples_per_second': '6.676', 'grad_norm': '16.5', 'counters/examples': 34624, 'counters/updates': 2164}
skipping logging after 34640 examples to avoid logging too frequently
skipping logging after 34656 examples to avoid logging too frequently
skipping logging after 34672 examples to avoid logging too frequently
train stats after 34688 examples: {'rewards_train/chosen': '-0.24632', 'rewards_train/rejected': '-0.25832', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.011982', 'logps_train/rejected': '-123.34', 'logps_train/chosen': '-116.96', 'loss/train': '0.69232', 'examples_per_second': '5.2826', 'grad_norm': '16.25', 'counters/examples': 34688, 'counters/updates': 2168}
skipping logging after 34704 examples to avoid logging too frequently
skipping logging after 34720 examples to avoid logging too frequently
Running evaluation after 34720 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:13,  2.38s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:05,  2.18s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:55,  1.92s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.90s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.54s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.65s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 34720: {'rewards_eval/chosen': '-0.26428', 'rewards_eval/rejected': '-0.33305', 'rewards_eval/accuracies': '0.54883', 'rewards_eval/margins': '0.068758', 'logps_eval/rejected': '-125.49', 'logps_eval/chosen': '-121.14', 'loss/eval': '0.67471'}
skipping logging after 34736 examples to avoid logging too frequently
train stats after 34752 examples: {'rewards_train/chosen': '-0.2668', 'rewards_train/rejected': '-0.39093', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.12423', 'logps_train/rejected': '-117.38', 'logps_train/chosen': '-130.34', 'loss/train': '0.64545', 'examples_per_second': '3.8719', 'grad_norm': '16.5', 'counters/examples': 34752, 'counters/updates': 2172}
skipping logging after 34768 examples to avoid logging too frequently
skipping logging after 34784 examples to avoid logging too frequently
skipping logging after 34800 examples to avoid logging too frequently
train stats after 34816 examples: {'rewards_train/chosen': '-0.38682', 'rewards_train/rejected': '-0.40969', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.022858', 'logps_train/rejected': '-148.41', 'logps_train/chosen': '-103.3', 'loss/train': '0.70094', 'examples_per_second': '5.0493', 'grad_norm': '17.125', 'counters/examples': 34816, 'counters/updates': 2176}
skipping logging after 34832 examples to avoid logging too frequently
skipping logging after 34848 examples to avoid logging too frequently
skipping logging after 34864 examples to avoid logging too frequently
train stats after 34880 examples: {'rewards_train/chosen': '-0.27626', 'rewards_train/rejected': '-0.32827', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.051949', 'logps_train/rejected': '-115.48', 'logps_train/chosen': '-121.43', 'loss/train': '0.68097', 'examples_per_second': '5.3631', 'grad_norm': '16', 'counters/examples': 34880, 'counters/updates': 2180}
skipping logging after 34896 examples to avoid logging too frequently
skipping logging after 34912 examples to avoid logging too frequently
skipping logging after 34928 examples to avoid logging too frequently
train stats after 34944 examples: {'rewards_train/chosen': '-0.27751', 'rewards_train/rejected': '-0.3612', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.083698', 'logps_train/rejected': '-138.35', 'logps_train/chosen': '-119.36', 'loss/train': '0.66379', 'examples_per_second': '5.7978', 'grad_norm': '23.625', 'counters/examples': 34944, 'counters/updates': 2184}
skipping logging after 34960 examples to avoid logging too frequently
skipping logging after 34976 examples to avoid logging too frequently
skipping logging after 34992 examples to avoid logging too frequently
train stats after 35008 examples: {'rewards_train/chosen': '-0.24715', 'rewards_train/rejected': '-0.33156', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.08448', 'logps_train/rejected': '-137.97', 'logps_train/chosen': '-140.3', 'loss/train': '0.66949', 'examples_per_second': '5.0408', 'grad_norm': '20.375', 'counters/examples': 35008, 'counters/updates': 2188}
skipping logging after 35024 examples to avoid logging too frequently
skipping logging after 35040 examples to avoid logging too frequently
skipping logging after 35056 examples to avoid logging too frequently
train stats after 35072 examples: {'rewards_train/chosen': '-0.38687', 'rewards_train/rejected': '-0.35326', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '-0.033661', 'logps_train/rejected': '-108.58', 'logps_train/chosen': '-154.06', 'loss/train': '0.72699', 'examples_per_second': '4.3219', 'grad_norm': '18.375', 'counters/examples': 35072, 'counters/updates': 2192}
skipping logging after 35088 examples to avoid logging too frequently
skipping logging after 35104 examples to avoid logging too frequently
skipping logging after 35120 examples to avoid logging too frequently
train stats after 35136 examples: {'rewards_train/chosen': '-0.19955', 'rewards_train/rejected': '-0.31853', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.11905', 'logps_train/rejected': '-109.59', 'logps_train/chosen': '-137.46', 'loss/train': '0.6627', 'examples_per_second': '5.1037', 'grad_norm': '15.625', 'counters/examples': 35136, 'counters/updates': 2196}
skipping logging after 35152 examples to avoid logging too frequently
skipping logging after 35168 examples to avoid logging too frequently
skipping logging after 35184 examples to avoid logging too frequently
train stats after 35200 examples: {'rewards_train/chosen': '-0.27884', 'rewards_train/rejected': '-0.27299', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '-0.005928', 'logps_train/rejected': '-114.37', 'logps_train/chosen': '-117.85', 'loss/train': '0.71024', 'examples_per_second': '4.499', 'grad_norm': '15.875', 'counters/examples': 35200, 'counters/updates': 2200}
skipping logging after 35216 examples to avoid logging too frequently
skipping logging after 35232 examples to avoid logging too frequently
skipping logging after 35248 examples to avoid logging too frequently
train stats after 35264 examples: {'rewards_train/chosen': '-0.28206', 'rewards_train/rejected': '-0.33835', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.056225', 'logps_train/rejected': '-89.661', 'logps_train/chosen': '-94.535', 'loss/train': '0.67975', 'examples_per_second': '5.8042', 'grad_norm': '15.75', 'counters/examples': 35264, 'counters/updates': 2204}
skipping logging after 35280 examples to avoid logging too frequently
skipping logging after 35296 examples to avoid logging too frequently
skipping logging after 35312 examples to avoid logging too frequently
train stats after 35328 examples: {'rewards_train/chosen': '-0.24524', 'rewards_train/rejected': '-0.35655', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.1112', 'logps_train/rejected': '-120.09', 'logps_train/chosen': '-112.56', 'loss/train': '0.6557', 'examples_per_second': '4.6147', 'grad_norm': '18.25', 'counters/examples': 35328, 'counters/updates': 2208}
skipping logging after 35344 examples to avoid logging too frequently
skipping logging after 35360 examples to avoid logging too frequently
skipping logging after 35376 examples to avoid logging too frequently
train stats after 35392 examples: {'rewards_train/chosen': '-0.33963', 'rewards_train/rejected': '-0.37254', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.03289', 'logps_train/rejected': '-124.27', 'logps_train/chosen': '-114.45', 'loss/train': '0.68774', 'examples_per_second': '5.0618', 'grad_norm': '15.875', 'counters/examples': 35392, 'counters/updates': 2212}
skipping logging after 35408 examples to avoid logging too frequently
skipping logging after 35424 examples to avoid logging too frequently
skipping logging after 35440 examples to avoid logging too frequently
train stats after 35456 examples: {'rewards_train/chosen': '-0.29123', 'rewards_train/rejected': '-0.41129', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.12008', 'logps_train/rejected': '-133.53', 'logps_train/chosen': '-126.4', 'loss/train': '0.64276', 'examples_per_second': '5.4275', 'grad_norm': '19.125', 'counters/examples': 35456, 'counters/updates': 2216}
skipping logging after 35472 examples to avoid logging too frequently
skipping logging after 35488 examples to avoid logging too frequently
skipping logging after 35504 examples to avoid logging too frequently
train stats after 35520 examples: {'rewards_train/chosen': '-0.33713', 'rewards_train/rejected': '-0.41609', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.07901', 'logps_train/rejected': '-117.98', 'logps_train/chosen': '-137.83', 'loss/train': '0.67392', 'examples_per_second': '5.9863', 'grad_norm': '16.875', 'counters/examples': 35520, 'counters/updates': 2220}
skipping logging after 35536 examples to avoid logging too frequently
skipping logging after 35552 examples to avoid logging too frequently
skipping logging after 35568 examples to avoid logging too frequently
train stats after 35584 examples: {'rewards_train/chosen': '-0.28657', 'rewards_train/rejected': '-0.36959', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.083055', 'logps_train/rejected': '-124.51', 'logps_train/chosen': '-112.91', 'loss/train': '0.66573', 'examples_per_second': '5.4629', 'grad_norm': '15.562', 'counters/examples': 35584, 'counters/updates': 2224}
skipping logging after 35600 examples to avoid logging too frequently
skipping logging after 35616 examples to avoid logging too frequently
skipping logging after 35632 examples to avoid logging too frequently
train stats after 35648 examples: {'rewards_train/chosen': '-0.34403', 'rewards_train/rejected': '-0.40043', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.056337', 'logps_train/rejected': '-93.516', 'logps_train/chosen': '-91.072', 'loss/train': '0.67641', 'examples_per_second': '4.9281', 'grad_norm': '14.438', 'counters/examples': 35648, 'counters/updates': 2228}
skipping logging after 35664 examples to avoid logging too frequently
skipping logging after 35680 examples to avoid logging too frequently
skipping logging after 35696 examples to avoid logging too frequently
train stats after 35712 examples: {'rewards_train/chosen': '-0.30277', 'rewards_train/rejected': '-0.40624', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.10349', 'logps_train/rejected': '-116.18', 'logps_train/chosen': '-123.85', 'loss/train': '0.6507', 'examples_per_second': '4.5479', 'grad_norm': '18.5', 'counters/examples': 35712, 'counters/updates': 2232}
Running evaluation after 35712 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 35712: {'rewards_eval/chosen': '-0.33967', 'rewards_eval/rejected': '-0.41376', 'rewards_eval/accuracies': '0.52734', 'rewards_eval/margins': '0.074062', 'logps_eval/rejected': '-126.29', 'logps_eval/chosen': '-121.89', 'loss/eval': '0.6736'}
skipping logging after 35728 examples to avoid logging too frequently
skipping logging after 35744 examples to avoid logging too frequently
skipping logging after 35760 examples to avoid logging too frequently
train stats after 35776 examples: {'rewards_train/chosen': '-0.34353', 'rewards_train/rejected': '-0.42779', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.084301', 'logps_train/rejected': '-115.05', 'logps_train/chosen': '-122.85', 'loss/train': '0.66821', 'examples_per_second': '6.0173', 'grad_norm': '15.312', 'counters/examples': 35776, 'counters/updates': 2236}
skipping logging after 35792 examples to avoid logging too frequently
skipping logging after 35808 examples to avoid logging too frequently
skipping logging after 35824 examples to avoid logging too frequently
train stats after 35840 examples: {'rewards_train/chosen': '-0.42835', 'rewards_train/rejected': '-0.44869', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.020363', 'logps_train/rejected': '-132.23', 'logps_train/chosen': '-127.26', 'loss/train': '0.6944', 'examples_per_second': '6.0539', 'grad_norm': '19.875', 'counters/examples': 35840, 'counters/updates': 2240}
skipping logging after 35856 examples to avoid logging too frequently
skipping logging after 35872 examples to avoid logging too frequently
skipping logging after 35888 examples to avoid logging too frequently
train stats after 35904 examples: {'rewards_train/chosen': '-0.25414', 'rewards_train/rejected': '-0.29959', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.045509', 'logps_train/rejected': '-139.36', 'logps_train/chosen': '-154.73', 'loss/train': '0.68704', 'examples_per_second': '4.0718', 'grad_norm': '18.875', 'counters/examples': 35904, 'counters/updates': 2244}
skipping logging after 35920 examples to avoid logging too frequently
skipping logging after 35936 examples to avoid logging too frequently
skipping logging after 35952 examples to avoid logging too frequently
train stats after 35968 examples: {'rewards_train/chosen': '-0.28254', 'rewards_train/rejected': '-0.38948', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.10707', 'logps_train/rejected': '-127.87', 'logps_train/chosen': '-161.11', 'loss/train': '0.66566', 'examples_per_second': '4.4396', 'grad_norm': '18.5', 'counters/examples': 35968, 'counters/updates': 2248}
skipping logging after 35984 examples to avoid logging too frequently
skipping logging after 36000 examples to avoid logging too frequently
skipping logging after 36016 examples to avoid logging too frequently
train stats after 36032 examples: {'rewards_train/chosen': '-0.2668', 'rewards_train/rejected': '-0.3469', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.080118', 'logps_train/rejected': '-120.5', 'logps_train/chosen': '-142.73', 'loss/train': '0.66577', 'examples_per_second': '4.4419', 'grad_norm': '19', 'counters/examples': 36032, 'counters/updates': 2252}
skipping logging after 36048 examples to avoid logging too frequently
skipping logging after 36064 examples to avoid logging too frequently
skipping logging after 36080 examples to avoid logging too frequently
train stats after 36096 examples: {'rewards_train/chosen': '-0.32386', 'rewards_train/rejected': '-0.3135', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '-0.010363', 'logps_train/rejected': '-123.96', 'logps_train/chosen': '-129.51', 'loss/train': '0.71072', 'examples_per_second': '4.7038', 'grad_norm': '19.75', 'counters/examples': 36096, 'counters/updates': 2256}
skipping logging after 36112 examples to avoid logging too frequently
skipping logging after 36128 examples to avoid logging too frequently
skipping logging after 36144 examples to avoid logging too frequently
train stats after 36160 examples: {'rewards_train/chosen': '-0.31792', 'rewards_train/rejected': '-0.3381', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.020151', 'logps_train/rejected': '-134.01', 'logps_train/chosen': '-117.81', 'loss/train': '0.69287', 'examples_per_second': '5.0558', 'grad_norm': '18', 'counters/examples': 36160, 'counters/updates': 2260}
skipping logging after 36176 examples to avoid logging too frequently
skipping logging after 36192 examples to avoid logging too frequently
skipping logging after 36208 examples to avoid logging too frequently
train stats after 36224 examples: {'rewards_train/chosen': '-0.37591', 'rewards_train/rejected': '-0.4825', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.10651', 'logps_train/rejected': '-119.66', 'logps_train/chosen': '-113.55', 'loss/train': '0.66229', 'examples_per_second': '6.0603', 'grad_norm': '17.75', 'counters/examples': 36224, 'counters/updates': 2264}
skipping logging after 36240 examples to avoid logging too frequently
skipping logging after 36256 examples to avoid logging too frequently
skipping logging after 36272 examples to avoid logging too frequently
train stats after 36288 examples: {'rewards_train/chosen': '-0.25269', 'rewards_train/rejected': '-0.36471', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.112', 'logps_train/rejected': '-117.75', 'logps_train/chosen': '-113.07', 'loss/train': '0.653', 'examples_per_second': '4.7841', 'grad_norm': '16.5', 'counters/examples': 36288, 'counters/updates': 2268}
skipping logging after 36304 examples to avoid logging too frequently
skipping logging after 36320 examples to avoid logging too frequently
skipping logging after 36336 examples to avoid logging too frequently
train stats after 36352 examples: {'rewards_train/chosen': '-0.33834', 'rewards_train/rejected': '-0.41925', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.080959', 'logps_train/rejected': '-111.82', 'logps_train/chosen': '-107.12', 'loss/train': '0.65952', 'examples_per_second': '5.3496', 'grad_norm': '17.5', 'counters/examples': 36352, 'counters/updates': 2272}
skipping logging after 36368 examples to avoid logging too frequently
skipping logging after 36384 examples to avoid logging too frequently
skipping logging after 36400 examples to avoid logging too frequently
train stats after 36416 examples: {'rewards_train/chosen': '-0.27769', 'rewards_train/rejected': '-0.35566', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.077913', 'logps_train/rejected': '-107.64', 'logps_train/chosen': '-110.47', 'loss/train': '0.67245', 'examples_per_second': '4.9581', 'grad_norm': '13.938', 'counters/examples': 36416, 'counters/updates': 2276}
skipping logging after 36432 examples to avoid logging too frequently
skipping logging after 36448 examples to avoid logging too frequently
skipping logging after 36464 examples to avoid logging too frequently
train stats after 36480 examples: {'rewards_train/chosen': '-0.31174', 'rewards_train/rejected': '-0.42478', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.11306', 'logps_train/rejected': '-112.04', 'logps_train/chosen': '-122.03', 'loss/train': '0.65274', 'examples_per_second': '4.9627', 'grad_norm': '18.5', 'counters/examples': 36480, 'counters/updates': 2280}
skipping logging after 36496 examples to avoid logging too frequently
skipping logging after 36512 examples to avoid logging too frequently
skipping logging after 36528 examples to avoid logging too frequently
train stats after 36544 examples: {'rewards_train/chosen': '-0.301', 'rewards_train/rejected': '-0.40953', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.10856', 'logps_train/rejected': '-135.55', 'logps_train/chosen': '-125.26', 'loss/train': '0.65564', 'examples_per_second': '5.043', 'grad_norm': '18.5', 'counters/examples': 36544, 'counters/updates': 2284}
skipping logging after 36560 examples to avoid logging too frequently
skipping logging after 36576 examples to avoid logging too frequently
skipping logging after 36592 examples to avoid logging too frequently
train stats after 36608 examples: {'rewards_train/chosen': '-0.35271', 'rewards_train/rejected': '-0.45258', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.099915', 'logps_train/rejected': '-113.25', 'logps_train/chosen': '-136.24', 'loss/train': '0.65936', 'examples_per_second': '5.0959', 'grad_norm': '16.5', 'counters/examples': 36608, 'counters/updates': 2288}
skipping logging after 36624 examples to avoid logging too frequently
skipping logging after 36640 examples to avoid logging too frequently
skipping logging after 36656 examples to avoid logging too frequently
train stats after 36672 examples: {'rewards_train/chosen': '-0.28602', 'rewards_train/rejected': '-0.38562', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.099568', 'logps_train/rejected': '-143.62', 'logps_train/chosen': '-146.85', 'loss/train': '0.66418', 'examples_per_second': '4.8731', 'grad_norm': '17', 'counters/examples': 36672, 'counters/updates': 2292}
skipping logging after 36688 examples to avoid logging too frequently
skipping logging after 36704 examples to avoid logging too frequently
Running evaluation after 36704 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:14,  2.40s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:05,  2.20s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:56,  1.93s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.91s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.55s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.66s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.48s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.55s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.44s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 36704: {'rewards_eval/chosen': '-0.34954', 'rewards_eval/rejected': '-0.42236', 'rewards_eval/accuracies': '0.53711', 'rewards_eval/margins': '0.072816', 'logps_eval/rejected': '-126.38', 'logps_eval/chosen': '-121.99', 'loss/eval': '0.67624'}
skipping logging after 36720 examples to avoid logging too frequently
train stats after 36736 examples: {'rewards_train/chosen': '-0.27696', 'rewards_train/rejected': '-0.3892', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.11229', 'logps_train/rejected': '-114.64', 'logps_train/chosen': '-124.15', 'loss/train': '0.65472', 'examples_per_second': '4.5826', 'grad_norm': '15.5', 'counters/examples': 36736, 'counters/updates': 2296}
skipping logging after 36752 examples to avoid logging too frequently
skipping logging after 36768 examples to avoid logging too frequently
skipping logging after 36784 examples to avoid logging too frequently
train stats after 36800 examples: {'rewards_train/chosen': '-0.36211', 'rewards_train/rejected': '-0.39923', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.037109', 'logps_train/rejected': '-135.53', 'logps_train/chosen': '-122.54', 'loss/train': '0.686', 'examples_per_second': '4.724', 'grad_norm': '16.625', 'counters/examples': 36800, 'counters/updates': 2300}
skipping logging after 36816 examples to avoid logging too frequently
skipping logging after 36832 examples to avoid logging too frequently
skipping logging after 36848 examples to avoid logging too frequently
train stats after 36864 examples: {'rewards_train/chosen': '-0.39506', 'rewards_train/rejected': '-0.46865', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.073496', 'logps_train/rejected': '-106.35', 'logps_train/chosen': '-88.135', 'loss/train': '0.67902', 'examples_per_second': '5.4382', 'grad_norm': '20.875', 'counters/examples': 36864, 'counters/updates': 2304}
skipping logging after 36880 examples to avoid logging too frequently
skipping logging after 36896 examples to avoid logging too frequently
skipping logging after 36912 examples to avoid logging too frequently
train stats after 36928 examples: {'rewards_train/chosen': '-0.31928', 'rewards_train/rejected': '-0.38616', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.066809', 'logps_train/rejected': '-119.21', 'logps_train/chosen': '-123.17', 'loss/train': '0.6738', 'examples_per_second': '5.4312', 'grad_norm': '16.125', 'counters/examples': 36928, 'counters/updates': 2308}
skipping logging after 36944 examples to avoid logging too frequently
skipping logging after 36960 examples to avoid logging too frequently
skipping logging after 36976 examples to avoid logging too frequently
train stats after 36992 examples: {'rewards_train/chosen': '-0.28542', 'rewards_train/rejected': '-0.4001', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.1146', 'logps_train/rejected': '-150.12', 'logps_train/chosen': '-150.28', 'loss/train': '0.65381', 'examples_per_second': '4.0123', 'grad_norm': '17.375', 'counters/examples': 36992, 'counters/updates': 2312}
skipping logging after 37008 examples to avoid logging too frequently
skipping logging after 37024 examples to avoid logging too frequently
skipping logging after 37040 examples to avoid logging too frequently
train stats after 37056 examples: {'rewards_train/chosen': '-0.27837', 'rewards_train/rejected': '-0.37087', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.092457', 'logps_train/rejected': '-127.38', 'logps_train/chosen': '-128.29', 'loss/train': '0.66183', 'examples_per_second': '4.695', 'grad_norm': '16.125', 'counters/examples': 37056, 'counters/updates': 2316}
skipping logging after 37072 examples to avoid logging too frequently
skipping logging after 37088 examples to avoid logging too frequently
skipping logging after 37104 examples to avoid logging too frequently
train stats after 37120 examples: {'rewards_train/chosen': '-0.3711', 'rewards_train/rejected': '-0.35671', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '-0.014376', 'logps_train/rejected': '-103.69', 'logps_train/chosen': '-115.82', 'loss/train': '0.71609', 'examples_per_second': '4.918', 'grad_norm': '18', 'counters/examples': 37120, 'counters/updates': 2320}
skipping logging after 37136 examples to avoid logging too frequently
skipping logging after 37152 examples to avoid logging too frequently
skipping logging after 37168 examples to avoid logging too frequently
train stats after 37184 examples: {'rewards_train/chosen': '-0.22534', 'rewards_train/rejected': '-0.30029', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.074993', 'logps_train/rejected': '-121.04', 'logps_train/chosen': '-116.11', 'loss/train': '0.66464', 'examples_per_second': '4.9645', 'grad_norm': '14.062', 'counters/examples': 37184, 'counters/updates': 2324}
skipping logging after 37200 examples to avoid logging too frequently
skipping logging after 37216 examples to avoid logging too frequently
skipping logging after 37232 examples to avoid logging too frequently
train stats after 37248 examples: {'rewards_train/chosen': '-0.27642', 'rewards_train/rejected': '-0.33586', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.059286', 'logps_train/rejected': '-124.75', 'logps_train/chosen': '-134.17', 'loss/train': '0.68106', 'examples_per_second': '4.8808', 'grad_norm': '16.375', 'counters/examples': 37248, 'counters/updates': 2328}
skipping logging after 37264 examples to avoid logging too frequently
skipping logging after 37280 examples to avoid logging too frequently
skipping logging after 37296 examples to avoid logging too frequently
train stats after 37312 examples: {'rewards_train/chosen': '-0.22368', 'rewards_train/rejected': '-0.36643', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.14279', 'logps_train/rejected': '-127.69', 'logps_train/chosen': '-111.99', 'loss/train': '0.6384', 'examples_per_second': '3.9591', 'grad_norm': '15.875', 'counters/examples': 37312, 'counters/updates': 2332}
skipping logging after 37328 examples to avoid logging too frequently
skipping logging after 37344 examples to avoid logging too frequently
skipping logging after 37360 examples to avoid logging too frequently
train stats after 37376 examples: {'rewards_train/chosen': '-0.24359', 'rewards_train/rejected': '-0.41003', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.16636', 'logps_train/rejected': '-126.27', 'logps_train/chosen': '-132.59', 'loss/train': '0.63239', 'examples_per_second': '5.064', 'grad_norm': '16.75', 'counters/examples': 37376, 'counters/updates': 2336}
skipping logging after 37392 examples to avoid logging too frequently
skipping logging after 37408 examples to avoid logging too frequently
skipping logging after 37424 examples to avoid logging too frequently
train stats after 37440 examples: {'rewards_train/chosen': '-0.20185', 'rewards_train/rejected': '-0.35225', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.15049', 'logps_train/rejected': '-107.87', 'logps_train/chosen': '-129.16', 'loss/train': '0.64024', 'examples_per_second': '5.1587', 'grad_norm': '19.875', 'counters/examples': 37440, 'counters/updates': 2340}
skipping logging after 37456 examples to avoid logging too frequently
skipping logging after 37472 examples to avoid logging too frequently
skipping logging after 37488 examples to avoid logging too frequently
train stats after 37504 examples: {'rewards_train/chosen': '-0.28247', 'rewards_train/rejected': '-0.39193', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.10943', 'logps_train/rejected': '-111.61', 'logps_train/chosen': '-113.94', 'loss/train': '0.66287', 'examples_per_second': '5.0993', 'grad_norm': '15.938', 'counters/examples': 37504, 'counters/updates': 2344}
skipping logging after 37520 examples to avoid logging too frequently
skipping logging after 37536 examples to avoid logging too frequently
skipping logging after 37552 examples to avoid logging too frequently
train stats after 37568 examples: {'rewards_train/chosen': '-0.31278', 'rewards_train/rejected': '-0.41046', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.097691', 'logps_train/rejected': '-119.4', 'logps_train/chosen': '-114.89', 'loss/train': '0.66693', 'examples_per_second': '3.6948', 'grad_norm': '15.875', 'counters/examples': 37568, 'counters/updates': 2348}
skipping logging after 37584 examples to avoid logging too frequently
skipping logging after 37600 examples to avoid logging too frequently
skipping logging after 37616 examples to avoid logging too frequently
train stats after 37632 examples: {'rewards_train/chosen': '-0.25938', 'rewards_train/rejected': '-0.31574', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.056356', 'logps_train/rejected': '-148.36', 'logps_train/chosen': '-136.54', 'loss/train': '0.6796', 'examples_per_second': '4.9813', 'grad_norm': '16.625', 'counters/examples': 37632, 'counters/updates': 2352}
skipping logging after 37648 examples to avoid logging too frequently
skipping logging after 37664 examples to avoid logging too frequently
skipping logging after 37680 examples to avoid logging too frequently
train stats after 37696 examples: {'rewards_train/chosen': '-0.34561', 'rewards_train/rejected': '-0.42775', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '0.082167', 'logps_train/rejected': '-123.69', 'logps_train/chosen': '-100.08', 'loss/train': '0.66447', 'examples_per_second': '4.4079', 'grad_norm': '16', 'counters/examples': 37696, 'counters/updates': 2356}
Running evaluation after 37696 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 37696: {'rewards_eval/chosen': '-0.23856', 'rewards_eval/rejected': '-0.31526', 'rewards_eval/accuracies': '0.55859', 'rewards_eval/margins': '0.076674', 'logps_eval/rejected': '-125.31', 'logps_eval/chosen': '-120.88', 'loss/eval': '0.67257'}
skipping logging after 37712 examples to avoid logging too frequently
skipping logging after 37728 examples to avoid logging too frequently
skipping logging after 37744 examples to avoid logging too frequently
train stats after 37760 examples: {'rewards_train/chosen': '-0.18114', 'rewards_train/rejected': '-0.28506', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.10382', 'logps_train/rejected': '-131.43', 'logps_train/chosen': '-141.2', 'loss/train': '0.65753', 'examples_per_second': '4.9881', 'grad_norm': '16.75', 'counters/examples': 37760, 'counters/updates': 2360}
skipping logging after 37776 examples to avoid logging too frequently
skipping logging after 37792 examples to avoid logging too frequently
skipping logging after 37808 examples to avoid logging too frequently
train stats after 37824 examples: {'rewards_train/chosen': '-0.35782', 'rewards_train/rejected': '-0.33982', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '-0.017992', 'logps_train/rejected': '-98.598', 'logps_train/chosen': '-113.17', 'loss/train': '0.71521', 'examples_per_second': '6.3119', 'grad_norm': '19.125', 'counters/examples': 37824, 'counters/updates': 2364}
skipping logging after 37840 examples to avoid logging too frequently
skipping logging after 37856 examples to avoid logging too frequently
skipping logging after 37872 examples to avoid logging too frequently
train stats after 37888 examples: {'rewards_train/chosen': '-0.20833', 'rewards_train/rejected': '-0.27898', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.07066', 'logps_train/rejected': '-117.09', 'logps_train/chosen': '-119.75', 'loss/train': '0.6673', 'examples_per_second': '5.8762', 'grad_norm': '17.75', 'counters/examples': 37888, 'counters/updates': 2368}
skipping logging after 37904 examples to avoid logging too frequently
skipping logging after 37920 examples to avoid logging too frequently
skipping logging after 37936 examples to avoid logging too frequently
train stats after 37952 examples: {'rewards_train/chosen': '-0.22453', 'rewards_train/rejected': '-0.24063', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.016171', 'logps_train/rejected': '-136.31', 'logps_train/chosen': '-132.76', 'loss/train': '0.69907', 'examples_per_second': '4.8391', 'grad_norm': '18.875', 'counters/examples': 37952, 'counters/updates': 2372}
skipping logging after 37968 examples to avoid logging too frequently
skipping logging after 37984 examples to avoid logging too frequently
skipping logging after 38000 examples to avoid logging too frequently
train stats after 38016 examples: {'rewards_train/chosen': '-0.16683', 'rewards_train/rejected': '-0.21802', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.051205', 'logps_train/rejected': '-101.11', 'logps_train/chosen': '-116.6', 'loss/train': '0.6843', 'examples_per_second': '5.8081', 'grad_norm': '20.375', 'counters/examples': 38016, 'counters/updates': 2376}
skipping logging after 38032 examples to avoid logging too frequently
skipping logging after 38048 examples to avoid logging too frequently
skipping logging after 38064 examples to avoid logging too frequently
train stats after 38080 examples: {'rewards_train/chosen': '-0.2631', 'rewards_train/rejected': '-0.3172', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.054028', 'logps_train/rejected': '-141.52', 'logps_train/chosen': '-123.5', 'loss/train': '0.68364', 'examples_per_second': '5.0026', 'grad_norm': '15.688', 'counters/examples': 38080, 'counters/updates': 2380}
skipping logging after 38096 examples to avoid logging too frequently
skipping logging after 38112 examples to avoid logging too frequently
skipping logging after 38128 examples to avoid logging too frequently
train stats after 38144 examples: {'rewards_train/chosen': '-0.21938', 'rewards_train/rejected': '-0.30417', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.084715', 'logps_train/rejected': '-99.81', 'logps_train/chosen': '-115.18', 'loss/train': '0.66409', 'examples_per_second': '4.9203', 'grad_norm': '14.312', 'counters/examples': 38144, 'counters/updates': 2384}
skipping logging after 38160 examples to avoid logging too frequently
skipping logging after 38176 examples to avoid logging too frequently
skipping logging after 38192 examples to avoid logging too frequently
train stats after 38208 examples: {'rewards_train/chosen': '-0.21068', 'rewards_train/rejected': '-0.26005', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.049326', 'logps_train/rejected': '-103.16', 'logps_train/chosen': '-104.29', 'loss/train': '0.67996', 'examples_per_second': '5.8434', 'grad_norm': '17.75', 'counters/examples': 38208, 'counters/updates': 2388}
skipping logging after 38224 examples to avoid logging too frequently
skipping logging after 38240 examples to avoid logging too frequently
skipping logging after 38256 examples to avoid logging too frequently
train stats after 38272 examples: {'rewards_train/chosen': '-0.22593', 'rewards_train/rejected': '-0.27902', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.053041', 'logps_train/rejected': '-170.19', 'logps_train/chosen': '-138.67', 'loss/train': '0.69238', 'examples_per_second': '4.2908', 'grad_norm': '20.25', 'counters/examples': 38272, 'counters/updates': 2392}
skipping logging after 38288 examples to avoid logging too frequently
skipping logging after 38304 examples to avoid logging too frequently
skipping logging after 38320 examples to avoid logging too frequently
train stats after 38336 examples: {'rewards_train/chosen': '-0.22731', 'rewards_train/rejected': '-0.34317', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.11584', 'logps_train/rejected': '-95.597', 'logps_train/chosen': '-95.162', 'loss/train': '0.6557', 'examples_per_second': '5.0364', 'grad_norm': '15.5', 'counters/examples': 38336, 'counters/updates': 2396}
skipping logging after 38352 examples to avoid logging too frequently
skipping logging after 38368 examples to avoid logging too frequently
skipping logging after 38384 examples to avoid logging too frequently
train stats after 38400 examples: {'rewards_train/chosen': '-0.26778', 'rewards_train/rejected': '-0.3271', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.05932', 'logps_train/rejected': '-136.28', 'logps_train/chosen': '-132.67', 'loss/train': '0.67508', 'examples_per_second': '5.182', 'grad_norm': '18.125', 'counters/examples': 38400, 'counters/updates': 2400}
skipping logging after 38416 examples to avoid logging too frequently
skipping logging after 38432 examples to avoid logging too frequently
skipping logging after 38448 examples to avoid logging too frequently
train stats after 38464 examples: {'rewards_train/chosen': '-0.21941', 'rewards_train/rejected': '-0.26919', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.049826', 'logps_train/rejected': '-152.12', 'logps_train/chosen': '-118.63', 'loss/train': '0.68076', 'examples_per_second': '4.3563', 'grad_norm': '18', 'counters/examples': 38464, 'counters/updates': 2404}
skipping logging after 38480 examples to avoid logging too frequently
skipping logging after 38496 examples to avoid logging too frequently
skipping logging after 38512 examples to avoid logging too frequently
train stats after 38528 examples: {'rewards_train/chosen': '-0.23367', 'rewards_train/rejected': '-0.29092', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.057184', 'logps_train/rejected': '-116', 'logps_train/chosen': '-104.19', 'loss/train': '0.68039', 'examples_per_second': '4.6197', 'grad_norm': '15.438', 'counters/examples': 38528, 'counters/updates': 2408}
skipping logging after 38544 examples to avoid logging too frequently
skipping logging after 38560 examples to avoid logging too frequently
skipping logging after 38576 examples to avoid logging too frequently
train stats after 38592 examples: {'rewards_train/chosen': '-0.26984', 'rewards_train/rejected': '-0.33877', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.06897', 'logps_train/rejected': '-122.76', 'logps_train/chosen': '-132.82', 'loss/train': '0.67212', 'examples_per_second': '4.2258', 'grad_norm': '16.875', 'counters/examples': 38592, 'counters/updates': 2412}
skipping logging after 38608 examples to avoid logging too frequently
skipping logging after 38624 examples to avoid logging too frequently
skipping logging after 38640 examples to avoid logging too frequently
train stats after 38656 examples: {'rewards_train/chosen': '-0.19885', 'rewards_train/rejected': '-0.30902', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.11012', 'logps_train/rejected': '-102.05', 'logps_train/chosen': '-115.16', 'loss/train': '0.65067', 'examples_per_second': '5.9277', 'grad_norm': '15.5', 'counters/examples': 38656, 'counters/updates': 2416}
skipping logging after 38672 examples to avoid logging too frequently
skipping logging after 38688 examples to avoid logging too frequently
Running evaluation after 38688 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:07,  2.18s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:03,  2.10s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.88s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.87s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.25s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.29s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 38688: {'rewards_eval/chosen': '-0.29967', 'rewards_eval/rejected': '-0.37974', 'rewards_eval/accuracies': '0.54492', 'rewards_eval/margins': '0.080118', 'logps_eval/rejected': '-125.95', 'logps_eval/chosen': '-121.49', 'loss/eval': '0.67292'}
skipping logging after 38704 examples to avoid logging too frequently
train stats after 38720 examples: {'rewards_train/chosen': '-0.31597', 'rewards_train/rejected': '-0.36526', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.049332', 'logps_train/rejected': '-115.49', 'logps_train/chosen': '-142.08', 'loss/train': '0.68503', 'examples_per_second': '6.4246', 'grad_norm': '16.875', 'counters/examples': 38720, 'counters/updates': 2420}
skipping logging after 38736 examples to avoid logging too frequently
skipping logging after 38752 examples to avoid logging too frequently
skipping logging after 38768 examples to avoid logging too frequently
train stats after 38784 examples: {'rewards_train/chosen': '-0.2819', 'rewards_train/rejected': '-0.34016', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.058331', 'logps_train/rejected': '-125.38', 'logps_train/chosen': '-126.37', 'loss/train': '0.68018', 'examples_per_second': '5.2021', 'grad_norm': '16.875', 'counters/examples': 38784, 'counters/updates': 2424}
skipping logging after 38800 examples to avoid logging too frequently
skipping logging after 38816 examples to avoid logging too frequently
skipping logging after 38832 examples to avoid logging too frequently
train stats after 38848 examples: {'rewards_train/chosen': '-0.29727', 'rewards_train/rejected': '-0.36678', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.069571', 'logps_train/rejected': '-115.96', 'logps_train/chosen': '-129.07', 'loss/train': '0.67419', 'examples_per_second': '5.2641', 'grad_norm': '17.625', 'counters/examples': 38848, 'counters/updates': 2428}
skipping logging after 38864 examples to avoid logging too frequently
skipping logging after 38880 examples to avoid logging too frequently
skipping logging after 38896 examples to avoid logging too frequently
train stats after 38912 examples: {'rewards_train/chosen': '-0.2953', 'rewards_train/rejected': '-0.32738', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.031998', 'logps_train/rejected': '-119.94', 'logps_train/chosen': '-105.95', 'loss/train': '0.69623', 'examples_per_second': '4.9424', 'grad_norm': '20.125', 'counters/examples': 38912, 'counters/updates': 2432}
skipping logging after 38928 examples to avoid logging too frequently
skipping logging after 38944 examples to avoid logging too frequently
skipping logging after 38960 examples to avoid logging too frequently
train stats after 38976 examples: {'rewards_train/chosen': '-0.27863', 'rewards_train/rejected': '-0.27807', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '-0.00047588', 'logps_train/rejected': '-108.2', 'logps_train/chosen': '-111.54', 'loss/train': '0.7095', 'examples_per_second': '4.9589', 'grad_norm': '18', 'counters/examples': 38976, 'counters/updates': 2436}
skipping logging after 38992 examples to avoid logging too frequently
skipping logging after 39008 examples to avoid logging too frequently
skipping logging after 39024 examples to avoid logging too frequently
train stats after 39040 examples: {'rewards_train/chosen': '-0.31227', 'rewards_train/rejected': '-0.33453', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.022255', 'logps_train/rejected': '-107.33', 'logps_train/chosen': '-115.09', 'loss/train': '0.69315', 'examples_per_second': '5.9757', 'grad_norm': '17.5', 'counters/examples': 39040, 'counters/updates': 2440}
skipping logging after 39056 examples to avoid logging too frequently
skipping logging after 39072 examples to avoid logging too frequently
skipping logging after 39088 examples to avoid logging too frequently
train stats after 39104 examples: {'rewards_train/chosen': '-0.20672', 'rewards_train/rejected': '-0.30133', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.094624', 'logps_train/rejected': '-120.1', 'logps_train/chosen': '-115.28', 'loss/train': '0.65985', 'examples_per_second': '6.021', 'grad_norm': '14.938', 'counters/examples': 39104, 'counters/updates': 2444}
skipping logging after 39120 examples to avoid logging too frequently
skipping logging after 39136 examples to avoid logging too frequently
skipping logging after 39152 examples to avoid logging too frequently
train stats after 39168 examples: {'rewards_train/chosen': '-0.1729', 'rewards_train/rejected': '-0.20431', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.031416', 'logps_train/rejected': '-110.03', 'logps_train/chosen': '-115.82', 'loss/train': '0.68546', 'examples_per_second': '4.7388', 'grad_norm': '16.375', 'counters/examples': 39168, 'counters/updates': 2448}
skipping logging after 39184 examples to avoid logging too frequently
skipping logging after 39200 examples to avoid logging too frequently
skipping logging after 39216 examples to avoid logging too frequently
train stats after 39232 examples: {'rewards_train/chosen': '-0.26605', 'rewards_train/rejected': '-0.39475', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.1287', 'logps_train/rejected': '-131.04', 'logps_train/chosen': '-118.75', 'loss/train': '0.64398', 'examples_per_second': '4.3719', 'grad_norm': '16.625', 'counters/examples': 39232, 'counters/updates': 2452}
skipping logging after 39248 examples to avoid logging too frequently
skipping logging after 39264 examples to avoid logging too frequently
skipping logging after 39280 examples to avoid logging too frequently
train stats after 39296 examples: {'rewards_train/chosen': '-0.36578', 'rewards_train/rejected': '-0.36114', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '-0.0046883', 'logps_train/rejected': '-119.93', 'logps_train/chosen': '-152.58', 'loss/train': '0.70682', 'examples_per_second': '5.482', 'grad_norm': '19.375', 'counters/examples': 39296, 'counters/updates': 2456}
skipping logging after 39312 examples to avoid logging too frequently
skipping logging after 39328 examples to avoid logging too frequently
skipping logging after 39344 examples to avoid logging too frequently
train stats after 39360 examples: {'rewards_train/chosen': '-0.27969', 'rewards_train/rejected': '-0.34034', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.060646', 'logps_train/rejected': '-131.81', 'logps_train/chosen': '-126.44', 'loss/train': '0.67484', 'examples_per_second': '4.1865', 'grad_norm': '16.875', 'counters/examples': 39360, 'counters/updates': 2460}
skipping logging after 39376 examples to avoid logging too frequently
skipping logging after 39392 examples to avoid logging too frequently
skipping logging after 39408 examples to avoid logging too frequently
train stats after 39424 examples: {'rewards_train/chosen': '-0.29195', 'rewards_train/rejected': '-0.37189', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.079918', 'logps_train/rejected': '-122.91', 'logps_train/chosen': '-141.25', 'loss/train': '0.67458', 'examples_per_second': '4.6865', 'grad_norm': '19.5', 'counters/examples': 39424, 'counters/updates': 2464}
skipping logging after 39440 examples to avoid logging too frequently
skipping logging after 39456 examples to avoid logging too frequently
skipping logging after 39472 examples to avoid logging too frequently
train stats after 39488 examples: {'rewards_train/chosen': '-0.28177', 'rewards_train/rejected': '-0.37842', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.096642', 'logps_train/rejected': '-110.14', 'logps_train/chosen': '-99.397', 'loss/train': '0.66281', 'examples_per_second': '5.5724', 'grad_norm': '15.875', 'counters/examples': 39488, 'counters/updates': 2468}
skipping logging after 39504 examples to avoid logging too frequently
skipping logging after 39520 examples to avoid logging too frequently
skipping logging after 39536 examples to avoid logging too frequently
train stats after 39552 examples: {'rewards_train/chosen': '-0.3134', 'rewards_train/rejected': '-0.31066', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '-0.0026798', 'logps_train/rejected': '-123.04', 'logps_train/chosen': '-113.01', 'loss/train': '0.71341', 'examples_per_second': '4.8971', 'grad_norm': '19.125', 'counters/examples': 39552, 'counters/updates': 2472}
skipping logging after 39568 examples to avoid logging too frequently
skipping logging after 39584 examples to avoid logging too frequently
skipping logging after 39600 examples to avoid logging too frequently
train stats after 39616 examples: {'rewards_train/chosen': '-0.33765', 'rewards_train/rejected': '-0.4365', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.098896', 'logps_train/rejected': '-123.02', 'logps_train/chosen': '-118.03', 'loss/train': '0.66238', 'examples_per_second': '4.7073', 'grad_norm': '14.875', 'counters/examples': 39616, 'counters/updates': 2476}
skipping logging after 39632 examples to avoid logging too frequently
skipping logging after 39648 examples to avoid logging too frequently
skipping logging after 39664 examples to avoid logging too frequently
train stats after 39680 examples: {'rewards_train/chosen': '-0.34961', 'rewards_train/rejected': '-0.32084', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '-0.028749', 'logps_train/rejected': '-108.24', 'logps_train/chosen': '-89.792', 'loss/train': '0.72089', 'examples_per_second': '4.4429', 'grad_norm': '16.375', 'counters/examples': 39680, 'counters/updates': 2480}
Running evaluation after 39680 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.46s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.53s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.42s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.24s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.12s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 39680: {'rewards_eval/chosen': '-0.29896', 'rewards_eval/rejected': '-0.36802', 'rewards_eval/accuracies': '0.54102', 'rewards_eval/margins': '0.069097', 'logps_eval/rejected': '-125.84', 'logps_eval/chosen': '-121.48', 'loss/eval': '0.67586'}
skipping logging after 39696 examples to avoid logging too frequently
skipping logging after 39712 examples to avoid logging too frequently
skipping logging after 39728 examples to avoid logging too frequently
train stats after 39744 examples: {'rewards_train/chosen': '-0.26692', 'rewards_train/rejected': '-0.33022', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.063305', 'logps_train/rejected': '-132.23', 'logps_train/chosen': '-126.01', 'loss/train': '0.67288', 'examples_per_second': '5.2669', 'grad_norm': '18.25', 'counters/examples': 39744, 'counters/updates': 2484}
skipping logging after 39760 examples to avoid logging too frequently
skipping logging after 39776 examples to avoid logging too frequently
skipping logging after 39792 examples to avoid logging too frequently
train stats after 39808 examples: {'rewards_train/chosen': '-0.36454', 'rewards_train/rejected': '-0.4356', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.071068', 'logps_train/rejected': '-110.3', 'logps_train/chosen': '-107.83', 'loss/train': '0.67715', 'examples_per_second': '5.1616', 'grad_norm': '15.938', 'counters/examples': 39808, 'counters/updates': 2488}
skipping logging after 39824 examples to avoid logging too frequently
skipping logging after 39840 examples to avoid logging too frequently
skipping logging after 39856 examples to avoid logging too frequently
train stats after 39872 examples: {'rewards_train/chosen': '-0.33029', 'rewards_train/rejected': '-0.41984', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.089659', 'logps_train/rejected': '-135.81', 'logps_train/chosen': '-130.47', 'loss/train': '0.67294', 'examples_per_second': '5.0799', 'grad_norm': '17.75', 'counters/examples': 39872, 'counters/updates': 2492}
skipping logging after 39888 examples to avoid logging too frequently
skipping logging after 39904 examples to avoid logging too frequently
skipping logging after 39920 examples to avoid logging too frequently
train stats after 39936 examples: {'rewards_train/chosen': '-0.39608', 'rewards_train/rejected': '-0.44275', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.046745', 'logps_train/rejected': '-91.614', 'logps_train/chosen': '-121.79', 'loss/train': '0.6846', 'examples_per_second': '5.3044', 'grad_norm': '16.25', 'counters/examples': 39936, 'counters/updates': 2496}
skipping logging after 39952 examples to avoid logging too frequently
skipping logging after 39968 examples to avoid logging too frequently
skipping logging after 39984 examples to avoid logging too frequently
train stats after 40000 examples: {'rewards_train/chosen': '-0.28774', 'rewards_train/rejected': '-0.33539', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.04772', 'logps_train/rejected': '-104.79', 'logps_train/chosen': '-109.43', 'loss/train': '0.68929', 'examples_per_second': '5.4923', 'grad_norm': '18.125', 'counters/examples': 40000, 'counters/updates': 2500}
skipping logging after 40016 examples to avoid logging too frequently
skipping logging after 40032 examples to avoid logging too frequently
skipping logging after 40048 examples to avoid logging too frequently
train stats after 40064 examples: {'rewards_train/chosen': '-0.24583', 'rewards_train/rejected': '-0.40399', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.15812', 'logps_train/rejected': '-116.76', 'logps_train/chosen': '-109.3', 'loss/train': '0.62695', 'examples_per_second': '5.7939', 'grad_norm': '16.25', 'counters/examples': 40064, 'counters/updates': 2504}
skipping logging after 40080 examples to avoid logging too frequently
skipping logging after 40096 examples to avoid logging too frequently
skipping logging after 40112 examples to avoid logging too frequently
train stats after 40128 examples: {'rewards_train/chosen': '-0.22601', 'rewards_train/rejected': '-0.39674', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.17074', 'logps_train/rejected': '-110.69', 'logps_train/chosen': '-133.12', 'loss/train': '0.62436', 'examples_per_second': '5.3369', 'grad_norm': '15.812', 'counters/examples': 40128, 'counters/updates': 2508}
skipping logging after 40144 examples to avoid logging too frequently
skipping logging after 40160 examples to avoid logging too frequently
skipping logging after 40176 examples to avoid logging too frequently
train stats after 40192 examples: {'rewards_train/chosen': '-0.26565', 'rewards_train/rejected': '-0.35849', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.092878', 'logps_train/rejected': '-134.68', 'logps_train/chosen': '-112.52', 'loss/train': '0.6651', 'examples_per_second': '5.1163', 'grad_norm': '16.25', 'counters/examples': 40192, 'counters/updates': 2512}
skipping logging after 40208 examples to avoid logging too frequently
skipping logging after 40224 examples to avoid logging too frequently
skipping logging after 40240 examples to avoid logging too frequently
train stats after 40256 examples: {'rewards_train/chosen': '-0.34752', 'rewards_train/rejected': '-0.40215', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.054628', 'logps_train/rejected': '-119.76', 'logps_train/chosen': '-123', 'loss/train': '0.68649', 'examples_per_second': '6.8118', 'grad_norm': '17.5', 'counters/examples': 40256, 'counters/updates': 2516}
skipping logging after 40272 examples to avoid logging too frequently
skipping logging after 40288 examples to avoid logging too frequently
skipping logging after 40304 examples to avoid logging too frequently
train stats after 40320 examples: {'rewards_train/chosen': '-0.25791', 'rewards_train/rejected': '-0.33942', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.081638', 'logps_train/rejected': '-111.21', 'logps_train/chosen': '-126.44', 'loss/train': '0.67386', 'examples_per_second': '6.1517', 'grad_norm': '18.625', 'counters/examples': 40320, 'counters/updates': 2520}
skipping logging after 40336 examples to avoid logging too frequently
skipping logging after 40352 examples to avoid logging too frequently
skipping logging after 40368 examples to avoid logging too frequently
train stats after 40384 examples: {'rewards_train/chosen': '-0.35579', 'rewards_train/rejected': '-0.37327', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.017685', 'logps_train/rejected': '-114.48', 'logps_train/chosen': '-102.91', 'loss/train': '0.70493', 'examples_per_second': '5.3201', 'grad_norm': '17.125', 'counters/examples': 40384, 'counters/updates': 2524}
skipping logging after 40400 examples to avoid logging too frequently
skipping logging after 40416 examples to avoid logging too frequently
skipping logging after 40432 examples to avoid logging too frequently
train stats after 40448 examples: {'rewards_train/chosen': '-0.30241', 'rewards_train/rejected': '-0.36586', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.063488', 'logps_train/rejected': '-113.17', 'logps_train/chosen': '-95.273', 'loss/train': '0.67447', 'examples_per_second': '6.2891', 'grad_norm': '15.875', 'counters/examples': 40448, 'counters/updates': 2528}
skipping logging after 40464 examples to avoid logging too frequently
skipping logging after 40480 examples to avoid logging too frequently
skipping logging after 40496 examples to avoid logging too frequently
train stats after 40512 examples: {'rewards_train/chosen': '-0.34452', 'rewards_train/rejected': '-0.42701', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.082523', 'logps_train/rejected': '-103.28', 'logps_train/chosen': '-113.07', 'loss/train': '0.66122', 'examples_per_second': '6.4413', 'grad_norm': '14.312', 'counters/examples': 40512, 'counters/updates': 2532}
skipping logging after 40528 examples to avoid logging too frequently
skipping logging after 40544 examples to avoid logging too frequently
skipping logging after 40560 examples to avoid logging too frequently
train stats after 40576 examples: {'rewards_train/chosen': '-0.22388', 'rewards_train/rejected': '-0.28943', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.065632', 'logps_train/rejected': '-134.47', 'logps_train/chosen': '-143.7', 'loss/train': '0.67389', 'examples_per_second': '4.6133', 'grad_norm': '18.125', 'counters/examples': 40576, 'counters/updates': 2536}
skipping logging after 40592 examples to avoid logging too frequently
skipping logging after 40608 examples to avoid logging too frequently
skipping logging after 40624 examples to avoid logging too frequently
train stats after 40640 examples: {'rewards_train/chosen': '-0.30649', 'rewards_train/rejected': '-0.40339', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.096991', 'logps_train/rejected': '-129.44', 'logps_train/chosen': '-129.28', 'loss/train': '0.65881', 'examples_per_second': '4.4726', 'grad_norm': '16.875', 'counters/examples': 40640, 'counters/updates': 2540}
skipping logging after 40656 examples to avoid logging too frequently
skipping logging after 40672 examples to avoid logging too frequently
Running evaluation after 40672 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:18,  2.52s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:07,  2.25s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:56,  1.96s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:08<00:53,  1.92s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:42,  1.56s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.66s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.49s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.48s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.55s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.23s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 40672: {'rewards_eval/chosen': '-0.3683', 'rewards_eval/rejected': '-0.44237', 'rewards_eval/accuracies': '0.52148', 'rewards_eval/margins': '0.074107', 'logps_eval/rejected': '-126.58', 'logps_eval/chosen': '-122.18', 'loss/eval': '0.67535'}
skipping logging after 40688 examples to avoid logging too frequently
train stats after 40704 examples: {'rewards_train/chosen': '-0.38516', 'rewards_train/rejected': '-0.44469', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.059536', 'logps_train/rejected': '-140.45', 'logps_train/chosen': '-134.75', 'loss/train': '0.67935', 'examples_per_second': '4.8767', 'grad_norm': '17.75', 'counters/examples': 40704, 'counters/updates': 2544}
skipping logging after 40720 examples to avoid logging too frequently
skipping logging after 40736 examples to avoid logging too frequently
skipping logging after 40752 examples to avoid logging too frequently
train stats after 40768 examples: {'rewards_train/chosen': '-0.33253', 'rewards_train/rejected': '-0.38749', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.05492', 'logps_train/rejected': '-147.98', 'logps_train/chosen': '-123.2', 'loss/train': '0.68439', 'examples_per_second': '4.5847', 'grad_norm': '17.375', 'counters/examples': 40768, 'counters/updates': 2548}
skipping logging after 40784 examples to avoid logging too frequently
skipping logging after 40800 examples to avoid logging too frequently
skipping logging after 40816 examples to avoid logging too frequently
train stats after 40832 examples: {'rewards_train/chosen': '-0.41993', 'rewards_train/rejected': '-0.40469', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '-0.015228', 'logps_train/rejected': '-116.32', 'logps_train/chosen': '-125.7', 'loss/train': '0.71536', 'examples_per_second': '5.5796', 'grad_norm': '19.25', 'counters/examples': 40832, 'counters/updates': 2552}
skipping logging after 40848 examples to avoid logging too frequently
skipping logging after 40864 examples to avoid logging too frequently
skipping logging after 40880 examples to avoid logging too frequently
train stats after 40896 examples: {'rewards_train/chosen': '-0.41841', 'rewards_train/rejected': '-0.53654', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.11806', 'logps_train/rejected': '-131.76', 'logps_train/chosen': '-125.39', 'loss/train': '0.65706', 'examples_per_second': '5.1588', 'grad_norm': '17.625', 'counters/examples': 40896, 'counters/updates': 2556}
skipping logging after 40912 examples to avoid logging too frequently
skipping logging after 40928 examples to avoid logging too frequently
skipping logging after 40944 examples to avoid logging too frequently
train stats after 40960 examples: {'rewards_train/chosen': '-0.39647', 'rewards_train/rejected': '-0.42423', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.027721', 'logps_train/rejected': '-115.13', 'logps_train/chosen': '-106.75', 'loss/train': '0.69058', 'examples_per_second': '4.71', 'grad_norm': '17.75', 'counters/examples': 40960, 'counters/updates': 2560}
skipping logging after 40976 examples to avoid logging too frequently
skipping logging after 40992 examples to avoid logging too frequently
skipping logging after 41008 examples to avoid logging too frequently
train stats after 41024 examples: {'rewards_train/chosen': '-0.3207', 'rewards_train/rejected': '-0.45997', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.13934', 'logps_train/rejected': '-109.86', 'logps_train/chosen': '-140.32', 'loss/train': '0.63651', 'examples_per_second': '4.663', 'grad_norm': '16.75', 'counters/examples': 41024, 'counters/updates': 2564}
skipping logging after 41040 examples to avoid logging too frequently
skipping logging after 41056 examples to avoid logging too frequently
skipping logging after 41072 examples to avoid logging too frequently
train stats after 41088 examples: {'rewards_train/chosen': '-0.30222', 'rewards_train/rejected': '-0.361', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.058694', 'logps_train/rejected': '-131.94', 'logps_train/chosen': '-120.65', 'loss/train': '0.6832', 'examples_per_second': '5.0308', 'grad_norm': '17.25', 'counters/examples': 41088, 'counters/updates': 2568}
skipping logging after 41104 examples to avoid logging too frequently
skipping logging after 41120 examples to avoid logging too frequently
skipping logging after 41136 examples to avoid logging too frequently
train stats after 41152 examples: {'rewards_train/chosen': '-0.32642', 'rewards_train/rejected': '-0.39929', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.0728', 'logps_train/rejected': '-139.08', 'logps_train/chosen': '-134.03', 'loss/train': '0.67096', 'examples_per_second': '4.6796', 'grad_norm': '18.625', 'counters/examples': 41152, 'counters/updates': 2572}
skipping logging after 41168 examples to avoid logging too frequently
skipping logging after 41184 examples to avoid logging too frequently
skipping logging after 41200 examples to avoid logging too frequently
train stats after 41216 examples: {'rewards_train/chosen': '-0.25643', 'rewards_train/rejected': '-0.3795', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.1232', 'logps_train/rejected': '-123.55', 'logps_train/chosen': '-129.31', 'loss/train': '0.65378', 'examples_per_second': '4.2314', 'grad_norm': '18.625', 'counters/examples': 41216, 'counters/updates': 2576}
skipping logging after 41232 examples to avoid logging too frequently
skipping logging after 41248 examples to avoid logging too frequently
skipping logging after 41264 examples to avoid logging too frequently
train stats after 41280 examples: {'rewards_train/chosen': '-0.35343', 'rewards_train/rejected': '-0.38382', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.030449', 'logps_train/rejected': '-114.79', 'logps_train/chosen': '-119.34', 'loss/train': '0.69116', 'examples_per_second': '4.9463', 'grad_norm': '16.5', 'counters/examples': 41280, 'counters/updates': 2580}
skipping logging after 41296 examples to avoid logging too frequently
skipping logging after 41312 examples to avoid logging too frequently
skipping logging after 41328 examples to avoid logging too frequently
train stats after 41344 examples: {'rewards_train/chosen': '-0.34072', 'rewards_train/rejected': '-0.49323', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.15255', 'logps_train/rejected': '-133.31', 'logps_train/chosen': '-150.52', 'loss/train': '0.63144', 'examples_per_second': '5.3823', 'grad_norm': '17.375', 'counters/examples': 41344, 'counters/updates': 2584}
skipping logging after 41360 examples to avoid logging too frequently
skipping logging after 41376 examples to avoid logging too frequently
skipping logging after 41392 examples to avoid logging too frequently
train stats after 41408 examples: {'rewards_train/chosen': '-0.3734', 'rewards_train/rejected': '-0.46726', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.093845', 'logps_train/rejected': '-144.13', 'logps_train/chosen': '-115.38', 'loss/train': '0.66635', 'examples_per_second': '4.5394', 'grad_norm': '15.75', 'counters/examples': 41408, 'counters/updates': 2588}
skipping logging after 41424 examples to avoid logging too frequently
skipping logging after 41440 examples to avoid logging too frequently
skipping logging after 41456 examples to avoid logging too frequently
train stats after 41472 examples: {'rewards_train/chosen': '-0.24143', 'rewards_train/rejected': '-0.43268', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.19124', 'logps_train/rejected': '-93.239', 'logps_train/chosen': '-121.27', 'loss/train': '0.62308', 'examples_per_second': '6.1732', 'grad_norm': '18.25', 'counters/examples': 41472, 'counters/updates': 2592}
skipping logging after 41488 examples to avoid logging too frequently
skipping logging after 41504 examples to avoid logging too frequently
skipping logging after 41520 examples to avoid logging too frequently
train stats after 41536 examples: {'rewards_train/chosen': '-0.40135', 'rewards_train/rejected': '-0.58955', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.18829', 'logps_train/rejected': '-117.48', 'logps_train/chosen': '-125.75', 'loss/train': '0.63676', 'examples_per_second': '6.0416', 'grad_norm': '18.5', 'counters/examples': 41536, 'counters/updates': 2596}
skipping logging after 41552 examples to avoid logging too frequently
skipping logging after 41568 examples to avoid logging too frequently
skipping logging after 41584 examples to avoid logging too frequently
train stats after 41600 examples: {'rewards_train/chosen': '-0.40677', 'rewards_train/rejected': '-0.4284', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.021606', 'logps_train/rejected': '-112.41', 'logps_train/chosen': '-95.665', 'loss/train': '0.69595', 'examples_per_second': '4.2785', 'grad_norm': '14.188', 'counters/examples': 41600, 'counters/updates': 2600}
skipping logging after 41616 examples to avoid logging too frequently
skipping logging after 41632 examples to avoid logging too frequently
skipping logging after 41648 examples to avoid logging too frequently
train stats after 41664 examples: {'rewards_train/chosen': '-0.32402', 'rewards_train/rejected': '-0.45697', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.1329', 'logps_train/rejected': '-120.63', 'logps_train/chosen': '-119.8', 'loss/train': '0.64906', 'examples_per_second': '3.9242', 'grad_norm': '15.5', 'counters/examples': 41664, 'counters/updates': 2604}
Running evaluation after 41664 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 41664: {'rewards_eval/chosen': '-0.37607', 'rewards_eval/rejected': '-0.45745', 'rewards_eval/accuracies': '0.52344', 'rewards_eval/margins': '0.081446', 'logps_eval/rejected': '-126.73', 'logps_eval/chosen': '-122.25', 'loss/eval': '0.67312'}
skipping logging after 41680 examples to avoid logging too frequently
skipping logging after 41696 examples to avoid logging too frequently
skipping logging after 41712 examples to avoid logging too frequently
train stats after 41728 examples: {'rewards_train/chosen': '-0.39775', 'rewards_train/rejected': '-0.49135', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.093618', 'logps_train/rejected': '-139.47', 'logps_train/chosen': '-133.92', 'loss/train': '0.67502', 'examples_per_second': '5.303', 'grad_norm': '18.875', 'counters/examples': 41728, 'counters/updates': 2608}
skipping logging after 41744 examples to avoid logging too frequently
skipping logging after 41760 examples to avoid logging too frequently
skipping logging after 41776 examples to avoid logging too frequently
train stats after 41792 examples: {'rewards_train/chosen': '-0.40335', 'rewards_train/rejected': '-0.51159', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.10828', 'logps_train/rejected': '-146.61', 'logps_train/chosen': '-141.87', 'loss/train': '0.66751', 'examples_per_second': '4.5092', 'grad_norm': '20.25', 'counters/examples': 41792, 'counters/updates': 2612}
skipping logging after 41808 examples to avoid logging too frequently
skipping logging after 41824 examples to avoid logging too frequently
skipping logging after 41840 examples to avoid logging too frequently
train stats after 41856 examples: {'rewards_train/chosen': '-0.28585', 'rewards_train/rejected': '-0.41366', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.12789', 'logps_train/rejected': '-145.41', 'logps_train/chosen': '-170.47', 'loss/train': '0.65799', 'examples_per_second': '4.4374', 'grad_norm': '22.125', 'counters/examples': 41856, 'counters/updates': 2616}
skipping logging after 41872 examples to avoid logging too frequently
skipping logging after 41888 examples to avoid logging too frequently
skipping logging after 41904 examples to avoid logging too frequently
train stats after 41920 examples: {'rewards_train/chosen': '-0.36565', 'rewards_train/rejected': '-0.45463', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.089001', 'logps_train/rejected': '-108.76', 'logps_train/chosen': '-102.04', 'loss/train': '0.6626', 'examples_per_second': '4.5823', 'grad_norm': '19', 'counters/examples': 41920, 'counters/updates': 2620}
skipping logging after 41936 examples to avoid logging too frequently
skipping logging after 41952 examples to avoid logging too frequently
skipping logging after 41968 examples to avoid logging too frequently
train stats after 41984 examples: {'rewards_train/chosen': '-0.29268', 'rewards_train/rejected': '-0.366', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.073334', 'logps_train/rejected': '-149.32', 'logps_train/chosen': '-118.3', 'loss/train': '0.67859', 'examples_per_second': '4.6461', 'grad_norm': '19', 'counters/examples': 41984, 'counters/updates': 2624}
skipping logging after 42000 examples to avoid logging too frequently
skipping logging after 42016 examples to avoid logging too frequently
skipping logging after 42032 examples to avoid logging too frequently
train stats after 42048 examples: {'rewards_train/chosen': '-0.37285', 'rewards_train/rejected': '-0.46771', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.094774', 'logps_train/rejected': '-114.49', 'logps_train/chosen': '-99.82', 'loss/train': '0.67719', 'examples_per_second': '5.893', 'grad_norm': '18.875', 'counters/examples': 42048, 'counters/updates': 2628}
skipping logging after 42064 examples to avoid logging too frequently
skipping logging after 42080 examples to avoid logging too frequently
skipping logging after 42096 examples to avoid logging too frequently
train stats after 42112 examples: {'rewards_train/chosen': '-0.21958', 'rewards_train/rejected': '-0.35191', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.13245', 'logps_train/rejected': '-118.57', 'logps_train/chosen': '-119.08', 'loss/train': '0.64299', 'examples_per_second': '5.0412', 'grad_norm': '16.5', 'counters/examples': 42112, 'counters/updates': 2632}
skipping logging after 42128 examples to avoid logging too frequently
skipping logging after 42144 examples to avoid logging too frequently
skipping logging after 42160 examples to avoid logging too frequently
train stats after 42176 examples: {'rewards_train/chosen': '-0.24058', 'rewards_train/rejected': '-0.28749', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.046876', 'logps_train/rejected': '-130.2', 'logps_train/chosen': '-116.05', 'loss/train': '0.68582', 'examples_per_second': '5.5677', 'grad_norm': '16.625', 'counters/examples': 42176, 'counters/updates': 2636}
skipping logging after 42192 examples to avoid logging too frequently
skipping logging after 42208 examples to avoid logging too frequently
skipping logging after 42224 examples to avoid logging too frequently
train stats after 42240 examples: {'rewards_train/chosen': '-0.18559', 'rewards_train/rejected': '-0.3197', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.13411', 'logps_train/rejected': '-122.99', 'logps_train/chosen': '-130.32', 'loss/train': '0.64389', 'examples_per_second': '4.8205', 'grad_norm': '15.875', 'counters/examples': 42240, 'counters/updates': 2640}
skipping logging after 42256 examples to avoid logging too frequently
skipping logging after 42272 examples to avoid logging too frequently
skipping logging after 42288 examples to avoid logging too frequently
train stats after 42304 examples: {'rewards_train/chosen': '-0.33522', 'rewards_train/rejected': '-0.40512', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.070019', 'logps_train/rejected': '-121.51', 'logps_train/chosen': '-121.26', 'loss/train': '0.6734', 'examples_per_second': '4.5197', 'grad_norm': '16.75', 'counters/examples': 42304, 'counters/updates': 2644}
skipping logging after 42320 examples to avoid logging too frequently
skipping logging after 42336 examples to avoid logging too frequently
skipping logging after 42352 examples to avoid logging too frequently
train stats after 42368 examples: {'rewards_train/chosen': '-0.25795', 'rewards_train/rejected': '-0.37269', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.11475', 'logps_train/rejected': '-142.19', 'logps_train/chosen': '-121.1', 'loss/train': '0.65727', 'examples_per_second': '4.6047', 'grad_norm': '19.25', 'counters/examples': 42368, 'counters/updates': 2648}
skipping logging after 42384 examples to avoid logging too frequently
skipping logging after 42400 examples to avoid logging too frequently
skipping logging after 42416 examples to avoid logging too frequently
train stats after 42432 examples: {'rewards_train/chosen': '-0.31574', 'rewards_train/rejected': '-0.38326', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.06757', 'logps_train/rejected': '-113.63', 'logps_train/chosen': '-115.74', 'loss/train': '0.67856', 'examples_per_second': '4.9752', 'grad_norm': '16.25', 'counters/examples': 42432, 'counters/updates': 2652}
skipping logging after 42448 examples to avoid logging too frequently
skipping logging after 42464 examples to avoid logging too frequently
skipping logging after 42480 examples to avoid logging too frequently
train stats after 42496 examples: {'rewards_train/chosen': '-0.31519', 'rewards_train/rejected': '-0.41127', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.096083', 'logps_train/rejected': '-128.24', 'logps_train/chosen': '-119.48', 'loss/train': '0.65558', 'examples_per_second': '5.216', 'grad_norm': '17.75', 'counters/examples': 42496, 'counters/updates': 2656}
skipping logging after 42512 examples to avoid logging too frequently
skipping logging after 42528 examples to avoid logging too frequently
skipping logging after 42544 examples to avoid logging too frequently
train stats after 42560 examples: {'rewards_train/chosen': '-0.29496', 'rewards_train/rejected': '-0.41996', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.12498', 'logps_train/rejected': '-89.527', 'logps_train/chosen': '-100.11', 'loss/train': '0.64896', 'examples_per_second': '5.4649', 'grad_norm': '15.438', 'counters/examples': 42560, 'counters/updates': 2660}
skipping logging after 42576 examples to avoid logging too frequently
skipping logging after 42592 examples to avoid logging too frequently
skipping logging after 42608 examples to avoid logging too frequently
train stats after 42624 examples: {'rewards_train/chosen': '-0.24175', 'rewards_train/rejected': '-0.32636', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.084742', 'logps_train/rejected': '-105.21', 'logps_train/chosen': '-107.13', 'loss/train': '0.67288', 'examples_per_second': '4.3784', 'grad_norm': '16.125', 'counters/examples': 42624, 'counters/updates': 2664}
skipping logging after 42640 examples to avoid logging too frequently
skipping logging after 42656 examples to avoid logging too frequently
Running evaluation after 42656 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:07,  2.19s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:03,  2.10s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.88s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.87s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.52s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.63s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.39s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 42656: {'rewards_eval/chosen': '-0.2967', 'rewards_eval/rejected': '-0.38367', 'rewards_eval/accuracies': '0.54492', 'rewards_eval/margins': '0.086971', 'logps_eval/rejected': '-125.99', 'logps_eval/chosen': '-121.46', 'loss/eval': '0.67075'}
skipping logging after 42672 examples to avoid logging too frequently
train stats after 42688 examples: {'rewards_train/chosen': '-0.30261', 'rewards_train/rejected': '-0.42208', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.11939', 'logps_train/rejected': '-138.48', 'logps_train/chosen': '-125.36', 'loss/train': '0.65088', 'examples_per_second': '5.0729', 'grad_norm': '16', 'counters/examples': 42688, 'counters/updates': 2668}
skipping logging after 42704 examples to avoid logging too frequently
skipping logging after 42720 examples to avoid logging too frequently
skipping logging after 42736 examples to avoid logging too frequently
train stats after 42752 examples: {'rewards_train/chosen': '-0.33091', 'rewards_train/rejected': '-0.40434', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.073496', 'logps_train/rejected': '-107.68', 'logps_train/chosen': '-107.9', 'loss/train': '0.67053', 'examples_per_second': '4.8679', 'grad_norm': '14.688', 'counters/examples': 42752, 'counters/updates': 2672}
skipping logging after 42768 examples to avoid logging too frequently
skipping logging after 42784 examples to avoid logging too frequently
skipping logging after 42800 examples to avoid logging too frequently
train stats after 42816 examples: {'rewards_train/chosen': '-0.20985', 'rewards_train/rejected': '-0.22251', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.012638', 'logps_train/rejected': '-135.77', 'logps_train/chosen': '-150', 'loss/train': '0.70163', 'examples_per_second': '4.4774', 'grad_norm': '17.25', 'counters/examples': 42816, 'counters/updates': 2676}
skipping logging after 42832 examples to avoid logging too frequently
skipping logging after 42848 examples to avoid logging too frequently
skipping logging after 42864 examples to avoid logging too frequently
train stats after 42880 examples: {'rewards_train/chosen': '-0.27913', 'rewards_train/rejected': '-0.35581', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.076614', 'logps_train/rejected': '-132.28', 'logps_train/chosen': '-126.87', 'loss/train': '0.66962', 'examples_per_second': '4.872', 'grad_norm': '15.625', 'counters/examples': 42880, 'counters/updates': 2680}
skipping logging after 42896 examples to avoid logging too frequently
skipping logging after 42912 examples to avoid logging too frequently
skipping logging after 42928 examples to avoid logging too frequently
train stats after 42944 examples: {'rewards_train/chosen': '-0.2726', 'rewards_train/rejected': '-0.29721', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.024498', 'logps_train/rejected': '-119.13', 'logps_train/chosen': '-128.8', 'loss/train': '0.70537', 'examples_per_second': '6.1082', 'grad_norm': '21.25', 'counters/examples': 42944, 'counters/updates': 2684}
skipping logging after 42960 examples to avoid logging too frequently
skipping logging after 42976 examples to avoid logging too frequently
skipping logging after 42992 examples to avoid logging too frequently
train stats after 43008 examples: {'rewards_train/chosen': '-0.19815', 'rewards_train/rejected': '-0.28164', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.083551', 'logps_train/rejected': '-110.28', 'logps_train/chosen': '-136.11', 'loss/train': '0.67186', 'examples_per_second': '4.9066', 'grad_norm': '15.562', 'counters/examples': 43008, 'counters/updates': 2688}
skipping logging after 43024 examples to avoid logging too frequently
skipping logging after 43040 examples to avoid logging too frequently
skipping logging after 43056 examples to avoid logging too frequently
train stats after 43072 examples: {'rewards_train/chosen': '-0.22709', 'rewards_train/rejected': '-0.29191', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.064924', 'logps_train/rejected': '-147.44', 'logps_train/chosen': '-122.23', 'loss/train': '0.68002', 'examples_per_second': '5.052', 'grad_norm': '19.25', 'counters/examples': 43072, 'counters/updates': 2692}
skipping logging after 43088 examples to avoid logging too frequently
skipping logging after 43104 examples to avoid logging too frequently
skipping logging after 43120 examples to avoid logging too frequently
train stats after 43136 examples: {'rewards_train/chosen': '-0.35208', 'rewards_train/rejected': '-0.35819', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.0059853', 'logps_train/rejected': '-99.111', 'logps_train/chosen': '-108.72', 'loss/train': '0.71091', 'examples_per_second': '4.6158', 'grad_norm': '17.5', 'counters/examples': 43136, 'counters/updates': 2696}
skipping logging after 43152 examples to avoid logging too frequently
skipping logging after 43168 examples to avoid logging too frequently
skipping logging after 43184 examples to avoid logging too frequently
train stats after 43200 examples: {'rewards_train/chosen': '-0.37248', 'rewards_train/rejected': '-0.4276', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.05503', 'logps_train/rejected': '-121.84', 'logps_train/chosen': '-140.54', 'loss/train': '0.68355', 'examples_per_second': '5.2993', 'grad_norm': '17.25', 'counters/examples': 43200, 'counters/updates': 2700}
skipping logging after 43216 examples to avoid logging too frequently
skipping logging after 43232 examples to avoid logging too frequently
skipping logging after 43248 examples to avoid logging too frequently
train stats after 43264 examples: {'rewards_train/chosen': '-0.33376', 'rewards_train/rejected': '-0.43735', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.10368', 'logps_train/rejected': '-109.21', 'logps_train/chosen': '-115.82', 'loss/train': '0.65543', 'examples_per_second': '5.046', 'grad_norm': '16.125', 'counters/examples': 43264, 'counters/updates': 2704}
skipping logging after 43280 examples to avoid logging too frequently
skipping logging after 43296 examples to avoid logging too frequently
skipping logging after 43312 examples to avoid logging too frequently
train stats after 43328 examples: {'rewards_train/chosen': '-0.3346', 'rewards_train/rejected': '-0.41638', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.081814', 'logps_train/rejected': '-108.78', 'logps_train/chosen': '-134.08', 'loss/train': '0.67154', 'examples_per_second': '5.8191', 'grad_norm': '16.125', 'counters/examples': 43328, 'counters/updates': 2708}
skipping logging after 43344 examples to avoid logging too frequently
skipping logging after 43360 examples to avoid logging too frequently
skipping logging after 43376 examples to avoid logging too frequently
train stats after 43392 examples: {'rewards_train/chosen': '-0.35543', 'rewards_train/rejected': '-0.42306', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.067539', 'logps_train/rejected': '-96.284', 'logps_train/chosen': '-100.89', 'loss/train': '0.67218', 'examples_per_second': '5.0634', 'grad_norm': '13.375', 'counters/examples': 43392, 'counters/updates': 2712}
skipping logging after 43408 examples to avoid logging too frequently
skipping logging after 43424 examples to avoid logging too frequently
skipping logging after 43440 examples to avoid logging too frequently
train stats after 43456 examples: {'rewards_train/chosen': '-0.3289', 'rewards_train/rejected': '-0.38949', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.060635', 'logps_train/rejected': '-139.07', 'logps_train/chosen': '-120.9', 'loss/train': '0.68063', 'examples_per_second': '4.5214', 'grad_norm': '18.75', 'counters/examples': 43456, 'counters/updates': 2716}
skipping logging after 43472 examples to avoid logging too frequently
skipping logging after 43488 examples to avoid logging too frequently
skipping logging after 43504 examples to avoid logging too frequently
train stats after 43520 examples: {'rewards_train/chosen': '-0.30302', 'rewards_train/rejected': '-0.36246', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.05942', 'logps_train/rejected': '-96.238', 'logps_train/chosen': '-127.32', 'loss/train': '0.68802', 'examples_per_second': '5.254', 'grad_norm': '19.875', 'counters/examples': 43520, 'counters/updates': 2720}
skipping logging after 43536 examples to avoid logging too frequently
skipping logging after 43552 examples to avoid logging too frequently
skipping logging after 43568 examples to avoid logging too frequently
train stats after 43584 examples: {'rewards_train/chosen': '-0.28515', 'rewards_train/rejected': '-0.3628', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.077621', 'logps_train/rejected': '-98.693', 'logps_train/chosen': '-126.43', 'loss/train': '0.67111', 'examples_per_second': '4.1836', 'grad_norm': '15.375', 'counters/examples': 43584, 'counters/updates': 2724}
skipping logging after 43600 examples to avoid logging too frequently
skipping logging after 43616 examples to avoid logging too frequently
skipping logging after 43632 examples to avoid logging too frequently
train stats after 43648 examples: {'rewards_train/chosen': '-0.25566', 'rewards_train/rejected': '-0.33572', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.080087', 'logps_train/rejected': '-116.33', 'logps_train/chosen': '-134.16', 'loss/train': '0.66766', 'examples_per_second': '4.8549', 'grad_norm': '15.938', 'counters/examples': 43648, 'counters/updates': 2728}
Running evaluation after 43648 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:41,  1.61s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.45s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:12<00:36,  1.53s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.46s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.53s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.24s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.12s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 43648: {'rewards_eval/chosen': '-0.2593', 'rewards_eval/rejected': '-0.32946', 'rewards_eval/accuracies': '0.54297', 'rewards_eval/margins': '0.070183', 'logps_eval/rejected': '-125.45', 'logps_eval/chosen': '-121.09', 'loss/eval': '0.67464'}
skipping logging after 43664 examples to avoid logging too frequently
skipping logging after 43680 examples to avoid logging too frequently
skipping logging after 43696 examples to avoid logging too frequently
train stats after 43712 examples: {'rewards_train/chosen': '-0.20848', 'rewards_train/rejected': '-0.30767', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.099079', 'logps_train/rejected': '-119.38', 'logps_train/chosen': '-125.68', 'loss/train': '0.66092', 'examples_per_second': '6.1389', 'grad_norm': '17.5', 'counters/examples': 43712, 'counters/updates': 2732}
skipping logging after 43728 examples to avoid logging too frequently
skipping logging after 43744 examples to avoid logging too frequently
skipping logging after 43760 examples to avoid logging too frequently
train stats after 43776 examples: {'rewards_train/chosen': '-0.32697', 'rewards_train/rejected': '-0.30394', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '-0.023014', 'logps_train/rejected': '-127.02', 'logps_train/chosen': '-143.35', 'loss/train': '0.72437', 'examples_per_second': '5.071', 'grad_norm': '22.5', 'counters/examples': 43776, 'counters/updates': 2736}
skipping logging after 43792 examples to avoid logging too frequently
skipping logging after 43808 examples to avoid logging too frequently
skipping logging after 43824 examples to avoid logging too frequently
train stats after 43840 examples: {'rewards_train/chosen': '-0.21076', 'rewards_train/rejected': '-0.34973', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.13907', 'logps_train/rejected': '-142.15', 'logps_train/chosen': '-113.82', 'loss/train': '0.63989', 'examples_per_second': '4.7633', 'grad_norm': '18.75', 'counters/examples': 43840, 'counters/updates': 2740}
skipping logging after 43856 examples to avoid logging too frequently
skipping logging after 43872 examples to avoid logging too frequently
skipping logging after 43888 examples to avoid logging too frequently
train stats after 43904 examples: {'rewards_train/chosen': '-0.34184', 'rewards_train/rejected': '-0.39852', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.056847', 'logps_train/rejected': '-147.23', 'logps_train/chosen': '-141.38', 'loss/train': '0.68234', 'examples_per_second': '4.8289', 'grad_norm': '17.625', 'counters/examples': 43904, 'counters/updates': 2744}
skipping logging after 43920 examples to avoid logging too frequently
skipping logging after 43936 examples to avoid logging too frequently
skipping logging after 43952 examples to avoid logging too frequently
train stats after 43968 examples: {'rewards_train/chosen': '-0.28857', 'rewards_train/rejected': '-0.36096', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.072392', 'logps_train/rejected': '-110.62', 'logps_train/chosen': '-121.86', 'loss/train': '0.67648', 'examples_per_second': '6.7848', 'grad_norm': '16.5', 'counters/examples': 43968, 'counters/updates': 2748}
skipping logging after 43984 examples to avoid logging too frequently
skipping logging after 44000 examples to avoid logging too frequently
skipping logging after 44016 examples to avoid logging too frequently
train stats after 44032 examples: {'rewards_train/chosen': '-0.31036', 'rewards_train/rejected': '-0.36771', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.057329', 'logps_train/rejected': '-126.74', 'logps_train/chosen': '-120.51', 'loss/train': '0.67517', 'examples_per_second': '5.0954', 'grad_norm': '18.75', 'counters/examples': 44032, 'counters/updates': 2752}
skipping logging after 44048 examples to avoid logging too frequently
skipping logging after 44064 examples to avoid logging too frequently
skipping logging after 44080 examples to avoid logging too frequently
train stats after 44096 examples: {'rewards_train/chosen': '-0.49534', 'rewards_train/rejected': '-0.49481', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '-0.00047302', 'logps_train/rejected': '-99.337', 'logps_train/chosen': '-114.7', 'loss/train': '0.71442', 'examples_per_second': '6.5124', 'grad_norm': '17.125', 'counters/examples': 44096, 'counters/updates': 2756}
skipping logging after 44112 examples to avoid logging too frequently
skipping logging after 44128 examples to avoid logging too frequently
skipping logging after 44144 examples to avoid logging too frequently
train stats after 44160 examples: {'rewards_train/chosen': '-0.30443', 'rewards_train/rejected': '-0.37466', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.070164', 'logps_train/rejected': '-141.04', 'logps_train/chosen': '-130.06', 'loss/train': '0.67282', 'examples_per_second': '5.0311', 'grad_norm': '17.625', 'counters/examples': 44160, 'counters/updates': 2760}
skipping logging after 44176 examples to avoid logging too frequently
skipping logging after 44192 examples to avoid logging too frequently
skipping logging after 44208 examples to avoid logging too frequently
train stats after 44224 examples: {'rewards_train/chosen': '-0.32021', 'rewards_train/rejected': '-0.4068', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.086575', 'logps_train/rejected': '-106.07', 'logps_train/chosen': '-111.98', 'loss/train': '0.66702', 'examples_per_second': '4.3808', 'grad_norm': '15.312', 'counters/examples': 44224, 'counters/updates': 2764}
skipping logging after 44240 examples to avoid logging too frequently
skipping logging after 44256 examples to avoid logging too frequently
skipping logging after 44272 examples to avoid logging too frequently
train stats after 44288 examples: {'rewards_train/chosen': '-0.34727', 'rewards_train/rejected': '-0.47775', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.13049', 'logps_train/rejected': '-142.66', 'logps_train/chosen': '-122.77', 'loss/train': '0.64478', 'examples_per_second': '4.6953', 'grad_norm': '17.25', 'counters/examples': 44288, 'counters/updates': 2768}
skipping logging after 44304 examples to avoid logging too frequently
skipping logging after 44320 examples to avoid logging too frequently
skipping logging after 44336 examples to avoid logging too frequently
train stats after 44352 examples: {'rewards_train/chosen': '-0.36076', 'rewards_train/rejected': '-0.51162', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.1509', 'logps_train/rejected': '-102.27', 'logps_train/chosen': '-113.24', 'loss/train': '0.63988', 'examples_per_second': '6.7368', 'grad_norm': '17.625', 'counters/examples': 44352, 'counters/updates': 2772}
skipping logging after 44368 examples to avoid logging too frequently
skipping logging after 44384 examples to avoid logging too frequently
skipping logging after 44400 examples to avoid logging too frequently
train stats after 44416 examples: {'rewards_train/chosen': '-0.42586', 'rewards_train/rejected': '-0.53319', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.10737', 'logps_train/rejected': '-155.59', 'logps_train/chosen': '-160.59', 'loss/train': '0.6626', 'examples_per_second': '5.3556', 'grad_norm': '21.25', 'counters/examples': 44416, 'counters/updates': 2776}
skipping logging after 44432 examples to avoid logging too frequently
skipping logging after 44448 examples to avoid logging too frequently
skipping logging after 44464 examples to avoid logging too frequently
train stats after 44480 examples: {'rewards_train/chosen': '-0.23633', 'rewards_train/rejected': '-0.40244', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.16623', 'logps_train/rejected': '-127.97', 'logps_train/chosen': '-141.39', 'loss/train': '0.62671', 'examples_per_second': '4.6864', 'grad_norm': '16.875', 'counters/examples': 44480, 'counters/updates': 2780}
skipping logging after 44496 examples to avoid logging too frequently
skipping logging after 44512 examples to avoid logging too frequently
skipping logging after 44528 examples to avoid logging too frequently
train stats after 44544 examples: {'rewards_train/chosen': '-0.31326', 'rewards_train/rejected': '-0.36701', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.05377', 'logps_train/rejected': '-130.12', 'logps_train/chosen': '-124.38', 'loss/train': '0.68835', 'examples_per_second': '4.1838', 'grad_norm': '20.25', 'counters/examples': 44544, 'counters/updates': 2784}
skipping logging after 44560 examples to avoid logging too frequently
skipping logging after 44576 examples to avoid logging too frequently
skipping logging after 44592 examples to avoid logging too frequently
train stats after 44608 examples: {'rewards_train/chosen': '-0.32399', 'rewards_train/rejected': '-0.35927', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.035257', 'logps_train/rejected': '-120.06', 'logps_train/chosen': '-110.06', 'loss/train': '0.69162', 'examples_per_second': '4.0715', 'grad_norm': '16.875', 'counters/examples': 44608, 'counters/updates': 2788}
skipping logging after 44624 examples to avoid logging too frequently
skipping logging after 44640 examples to avoid logging too frequently
Running evaluation after 44640 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:08,  2.22s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:03,  2.12s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.89s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.88s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 44640: {'rewards_eval/chosen': '-0.37769', 'rewards_eval/rejected': '-0.46338', 'rewards_eval/accuracies': '0.51562', 'rewards_eval/margins': '0.085714', 'logps_eval/rejected': '-126.79', 'logps_eval/chosen': '-122.27', 'loss/eval': '0.67274'}
skipping logging after 44656 examples to avoid logging too frequently
train stats after 44672 examples: {'rewards_train/chosen': '-0.40262', 'rewards_train/rejected': '-0.56131', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.1588', 'logps_train/rejected': '-100.13', 'logps_train/chosen': '-122.88', 'loss/train': '0.6416', 'examples_per_second': '5.2226', 'grad_norm': '16.875', 'counters/examples': 44672, 'counters/updates': 2792}
skipping logging after 44688 examples to avoid logging too frequently
skipping logging after 44704 examples to avoid logging too frequently
skipping logging after 44720 examples to avoid logging too frequently
train stats after 44736 examples: {'rewards_train/chosen': '-0.42137', 'rewards_train/rejected': '-0.55145', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.13004', 'logps_train/rejected': '-121.84', 'logps_train/chosen': '-127.28', 'loss/train': '0.65239', 'examples_per_second': '5.663', 'grad_norm': '14.938', 'counters/examples': 44736, 'counters/updates': 2796}
skipping logging after 44752 examples to avoid logging too frequently
skipping logging after 44768 examples to avoid logging too frequently
skipping logging after 44784 examples to avoid logging too frequently
train stats after 44800 examples: {'rewards_train/chosen': '-0.36076', 'rewards_train/rejected': '-0.43412', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.073307', 'logps_train/rejected': '-135.78', 'logps_train/chosen': '-116.04', 'loss/train': '0.67389', 'examples_per_second': '5.5422', 'grad_norm': '17.5', 'counters/examples': 44800, 'counters/updates': 2800}
skipping logging after 44816 examples to avoid logging too frequently
skipping logging after 44832 examples to avoid logging too frequently
skipping logging after 44848 examples to avoid logging too frequently
train stats after 44864 examples: {'rewards_train/chosen': '-0.43725', 'rewards_train/rejected': '-0.49976', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.062548', 'logps_train/rejected': '-121.37', 'logps_train/chosen': '-110.89', 'loss/train': '0.68088', 'examples_per_second': '4.8232', 'grad_norm': '15.562', 'counters/examples': 44864, 'counters/updates': 2804}
skipping logging after 44880 examples to avoid logging too frequently
skipping logging after 44896 examples to avoid logging too frequently
skipping logging after 44912 examples to avoid logging too frequently
train stats after 44928 examples: {'rewards_train/chosen': '-0.4152', 'rewards_train/rejected': '-0.47284', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.05773', 'logps_train/rejected': '-109.43', 'logps_train/chosen': '-107.36', 'loss/train': '0.68144', 'examples_per_second': '4.6086', 'grad_norm': '16.625', 'counters/examples': 44928, 'counters/updates': 2808}
skipping logging after 44944 examples to avoid logging too frequently
skipping logging after 44960 examples to avoid logging too frequently
skipping logging after 44976 examples to avoid logging too frequently
train stats after 44992 examples: {'rewards_train/chosen': '-0.39614', 'rewards_train/rejected': '-0.46628', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.070099', 'logps_train/rejected': '-124.88', 'logps_train/chosen': '-132.06', 'loss/train': '0.6786', 'examples_per_second': '4.5115', 'grad_norm': '16.625', 'counters/examples': 44992, 'counters/updates': 2812}
skipping logging after 45008 examples to avoid logging too frequently
skipping logging after 45024 examples to avoid logging too frequently
skipping logging after 45040 examples to avoid logging too frequently
train stats after 45056 examples: {'rewards_train/chosen': '-0.47849', 'rewards_train/rejected': '-0.52219', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.043671', 'logps_train/rejected': '-110.91', 'logps_train/chosen': '-148.94', 'loss/train': '0.69559', 'examples_per_second': '5.4807', 'grad_norm': '20.875', 'counters/examples': 45056, 'counters/updates': 2816}
skipping logging after 45072 examples to avoid logging too frequently
skipping logging after 45088 examples to avoid logging too frequently
skipping logging after 45104 examples to avoid logging too frequently
train stats after 45120 examples: {'rewards_train/chosen': '-0.30567', 'rewards_train/rejected': '-0.4612', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.15562', 'logps_train/rejected': '-132.36', 'logps_train/chosen': '-125.4', 'loss/train': '0.63541', 'examples_per_second': '4.1601', 'grad_norm': '17.75', 'counters/examples': 45120, 'counters/updates': 2820}
skipping logging after 45136 examples to avoid logging too frequently
skipping logging after 45152 examples to avoid logging too frequently
skipping logging after 45168 examples to avoid logging too frequently
train stats after 45184 examples: {'rewards_train/chosen': '-0.37117', 'rewards_train/rejected': '-0.43341', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.06221', 'logps_train/rejected': '-146.41', 'logps_train/chosen': '-128.29', 'loss/train': '0.67691', 'examples_per_second': '5.5432', 'grad_norm': '16.75', 'counters/examples': 45184, 'counters/updates': 2824}
skipping logging after 45200 examples to avoid logging too frequently
skipping logging after 45216 examples to avoid logging too frequently
skipping logging after 45232 examples to avoid logging too frequently
train stats after 45248 examples: {'rewards_train/chosen': '-0.36859', 'rewards_train/rejected': '-0.47789', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.10935', 'logps_train/rejected': '-121.09', 'logps_train/chosen': '-131.13', 'loss/train': '0.66333', 'examples_per_second': '6.0235', 'grad_norm': '16.875', 'counters/examples': 45248, 'counters/updates': 2828}
skipping logging after 45264 examples to avoid logging too frequently
skipping logging after 45280 examples to avoid logging too frequently
skipping logging after 45296 examples to avoid logging too frequently
train stats after 45312 examples: {'rewards_train/chosen': '-0.47195', 'rewards_train/rejected': '-0.6952', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.22324', 'logps_train/rejected': '-96.25', 'logps_train/chosen': '-97.807', 'loss/train': '0.61298', 'examples_per_second': '6.4013', 'grad_norm': '17.5', 'counters/examples': 45312, 'counters/updates': 2832}
skipping logging after 45328 examples to avoid logging too frequently
skipping logging after 45344 examples to avoid logging too frequently
skipping logging after 45360 examples to avoid logging too frequently
train stats after 45376 examples: {'rewards_train/chosen': '-0.47229', 'rewards_train/rejected': '-0.56134', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.089071', 'logps_train/rejected': '-107.28', 'logps_train/chosen': '-110.92', 'loss/train': '0.67766', 'examples_per_second': '4.983', 'grad_norm': '16.125', 'counters/examples': 45376, 'counters/updates': 2836}
skipping logging after 45392 examples to avoid logging too frequently
skipping logging after 45408 examples to avoid logging too frequently
skipping logging after 45424 examples to avoid logging too frequently
train stats after 45440 examples: {'rewards_train/chosen': '-0.41186', 'rewards_train/rejected': '-0.62696', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.21513', 'logps_train/rejected': '-111.51', 'logps_train/chosen': '-94.022', 'loss/train': '0.62102', 'examples_per_second': '5.1207', 'grad_norm': '16.375', 'counters/examples': 45440, 'counters/updates': 2840}
skipping logging after 45456 examples to avoid logging too frequently
skipping logging after 45472 examples to avoid logging too frequently
skipping logging after 45488 examples to avoid logging too frequently
train stats after 45504 examples: {'rewards_train/chosen': '-0.37924', 'rewards_train/rejected': '-0.5504', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.17126', 'logps_train/rejected': '-123.92', 'logps_train/chosen': '-130.72', 'loss/train': '0.63139', 'examples_per_second': '5.5554', 'grad_norm': '17.75', 'counters/examples': 45504, 'counters/updates': 2844}
skipping logging after 45520 examples to avoid logging too frequently
skipping logging after 45536 examples to avoid logging too frequently
skipping logging after 45552 examples to avoid logging too frequently
train stats after 45568 examples: {'rewards_train/chosen': '-0.49811', 'rewards_train/rejected': '-0.62216', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.12408', 'logps_train/rejected': '-129.23', 'logps_train/chosen': '-149.61', 'loss/train': '0.66184', 'examples_per_second': '5.0516', 'grad_norm': '18.75', 'counters/examples': 45568, 'counters/updates': 2848}
skipping logging after 45584 examples to avoid logging too frequently
skipping logging after 45600 examples to avoid logging too frequently
skipping logging after 45616 examples to avoid logging too frequently
train stats after 45632 examples: {'rewards_train/chosen': '-0.48513', 'rewards_train/rejected': '-0.60008', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.11502', 'logps_train/rejected': '-124.76', 'logps_train/chosen': '-118.32', 'loss/train': '0.66259', 'examples_per_second': '6.0742', 'grad_norm': '17.375', 'counters/examples': 45632, 'counters/updates': 2852}
Running evaluation after 45632 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.91s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.81s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.45s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:12<00:36,  1.53s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.46s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.53s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.42s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.31s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.12s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 45632: {'rewards_eval/chosen': '-0.45391', 'rewards_eval/rejected': '-0.54615', 'rewards_eval/accuracies': '0.53125', 'rewards_eval/margins': '0.092258', 'logps_eval/rejected': '-127.62', 'logps_eval/chosen': '-123.03', 'loss/eval': '0.67059'}
skipping logging after 45648 examples to avoid logging too frequently
skipping logging after 45664 examples to avoid logging too frequently
skipping logging after 45680 examples to avoid logging too frequently
train stats after 45696 examples: {'rewards_train/chosen': '-0.52424', 'rewards_train/rejected': '-0.60548', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.081207', 'logps_train/rejected': '-101.23', 'logps_train/chosen': '-105.76', 'loss/train': '0.68443', 'examples_per_second': '5.5452', 'grad_norm': '16.625', 'counters/examples': 45696, 'counters/updates': 2856}
skipping logging after 45712 examples to avoid logging too frequently
skipping logging after 45728 examples to avoid logging too frequently
skipping logging after 45744 examples to avoid logging too frequently
train stats after 45760 examples: {'rewards_train/chosen': '-0.43191', 'rewards_train/rejected': '-0.57429', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.1424', 'logps_train/rejected': '-87.996', 'logps_train/chosen': '-125.88', 'loss/train': '0.6588', 'examples_per_second': '4.7508', 'grad_norm': '18.625', 'counters/examples': 45760, 'counters/updates': 2860}
skipping logging after 45776 examples to avoid logging too frequently
skipping logging after 45792 examples to avoid logging too frequently
skipping logging after 45808 examples to avoid logging too frequently
train stats after 45824 examples: {'rewards_train/chosen': '-0.43979', 'rewards_train/rejected': '-0.53977', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.09996', 'logps_train/rejected': '-124.41', 'logps_train/chosen': '-113', 'loss/train': '0.6611', 'examples_per_second': '4.9725', 'grad_norm': '16.75', 'counters/examples': 45824, 'counters/updates': 2864}
skipping logging after 45840 examples to avoid logging too frequently
skipping logging after 45856 examples to avoid logging too frequently
skipping logging after 45872 examples to avoid logging too frequently
train stats after 45888 examples: {'rewards_train/chosen': '-0.48326', 'rewards_train/rejected': '-0.62254', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.13938', 'logps_train/rejected': '-110.46', 'logps_train/chosen': '-132.22', 'loss/train': '0.6496', 'examples_per_second': '6.917', 'grad_norm': '16.5', 'counters/examples': 45888, 'counters/updates': 2868}
skipping logging after 45904 examples to avoid logging too frequently
skipping logging after 45920 examples to avoid logging too frequently
skipping logging after 45936 examples to avoid logging too frequently
train stats after 45952 examples: {'rewards_train/chosen': '-0.46265', 'rewards_train/rejected': '-0.50876', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.046131', 'logps_train/rejected': '-140.42', 'logps_train/chosen': '-115.27', 'loss/train': '0.68948', 'examples_per_second': '5.2019', 'grad_norm': '19.5', 'counters/examples': 45952, 'counters/updates': 2872}
skipping logging after 45968 examples to avoid logging too frequently
skipping logging after 45984 examples to avoid logging too frequently
skipping logging after 46000 examples to avoid logging too frequently
train stats after 46016 examples: {'rewards_train/chosen': '-0.36202', 'rewards_train/rejected': '-0.42545', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.063408', 'logps_train/rejected': '-118.97', 'logps_train/chosen': '-114.34', 'loss/train': '0.67508', 'examples_per_second': '4.519', 'grad_norm': '15.25', 'counters/examples': 46016, 'counters/updates': 2876}
skipping logging after 46032 examples to avoid logging too frequently
skipping logging after 46048 examples to avoid logging too frequently
skipping logging after 46064 examples to avoid logging too frequently
train stats after 46080 examples: {'rewards_train/chosen': '-0.37264', 'rewards_train/rejected': '-0.54518', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.17255', 'logps_train/rejected': '-108.83', 'logps_train/chosen': '-133.35', 'loss/train': '0.62961', 'examples_per_second': '5.8004', 'grad_norm': '15.812', 'counters/examples': 46080, 'counters/updates': 2880}
skipping logging after 46096 examples to avoid logging too frequently
skipping logging after 46112 examples to avoid logging too frequently
skipping logging after 46128 examples to avoid logging too frequently
train stats after 46144 examples: {'rewards_train/chosen': '-0.42783', 'rewards_train/rejected': '-0.47506', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.04713', 'logps_train/rejected': '-116.45', 'logps_train/chosen': '-103.41', 'loss/train': '0.69141', 'examples_per_second': '5.3211', 'grad_norm': '16.25', 'counters/examples': 46144, 'counters/updates': 2884}
skipping logging after 46160 examples to avoid logging too frequently
skipping logging after 46176 examples to avoid logging too frequently
skipping logging after 46192 examples to avoid logging too frequently
train stats after 46208 examples: {'rewards_train/chosen': '-0.51499', 'rewards_train/rejected': '-0.51678', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.0017414', 'logps_train/rejected': '-106.93', 'logps_train/chosen': '-97.273', 'loss/train': '0.71948', 'examples_per_second': '5.8916', 'grad_norm': '19.875', 'counters/examples': 46208, 'counters/updates': 2888}
skipping logging after 46224 examples to avoid logging too frequently
skipping logging after 46240 examples to avoid logging too frequently
skipping logging after 46256 examples to avoid logging too frequently
train stats after 46272 examples: {'rewards_train/chosen': '-0.35046', 'rewards_train/rejected': '-0.48246', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.132', 'logps_train/rejected': '-132.45', 'logps_train/chosen': '-129.88', 'loss/train': '0.65298', 'examples_per_second': '5.0483', 'grad_norm': '19.75', 'counters/examples': 46272, 'counters/updates': 2892}
skipping logging after 46288 examples to avoid logging too frequently
skipping logging after 46304 examples to avoid logging too frequently
skipping logging after 46320 examples to avoid logging too frequently
train stats after 46336 examples: {'rewards_train/chosen': '-0.42475', 'rewards_train/rejected': '-0.59322', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.16837', 'logps_train/rejected': '-151.32', 'logps_train/chosen': '-142.97', 'loss/train': '0.6376', 'examples_per_second': '6.3709', 'grad_norm': '16.5', 'counters/examples': 46336, 'counters/updates': 2896}
skipping logging after 46352 examples to avoid logging too frequently
skipping logging after 46368 examples to avoid logging too frequently
skipping logging after 46384 examples to avoid logging too frequently
train stats after 46400 examples: {'rewards_train/chosen': '-0.39219', 'rewards_train/rejected': '-0.50231', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.11012', 'logps_train/rejected': '-130.85', 'logps_train/chosen': '-149.93', 'loss/train': '0.65839', 'examples_per_second': '5.7755', 'grad_norm': '19.875', 'counters/examples': 46400, 'counters/updates': 2900}
skipping logging after 46416 examples to avoid logging too frequently
skipping logging after 46432 examples to avoid logging too frequently
skipping logging after 46448 examples to avoid logging too frequently
train stats after 46464 examples: {'rewards_train/chosen': '-0.36832', 'rewards_train/rejected': '-0.48392', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.11559', 'logps_train/rejected': '-141.15', 'logps_train/chosen': '-147.56', 'loss/train': '0.65515', 'examples_per_second': '5.1814', 'grad_norm': '19.75', 'counters/examples': 46464, 'counters/updates': 2904}
skipping logging after 46480 examples to avoid logging too frequently
skipping logging after 46496 examples to avoid logging too frequently
skipping logging after 46512 examples to avoid logging too frequently
train stats after 46528 examples: {'rewards_train/chosen': '-0.27337', 'rewards_train/rejected': '-0.35843', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.085133', 'logps_train/rejected': '-108.56', 'logps_train/chosen': '-134.31', 'loss/train': '0.67017', 'examples_per_second': '5.8597', 'grad_norm': '17.375', 'counters/examples': 46528, 'counters/updates': 2908}
skipping logging after 46544 examples to avoid logging too frequently
skipping logging after 46560 examples to avoid logging too frequently
skipping logging after 46576 examples to avoid logging too frequently
train stats after 46592 examples: {'rewards_train/chosen': '-0.37218', 'rewards_train/rejected': '-0.49749', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.12533', 'logps_train/rejected': '-113.2', 'logps_train/chosen': '-122.87', 'loss/train': '0.64943', 'examples_per_second': '4.9181', 'grad_norm': '17.375', 'counters/examples': 46592, 'counters/updates': 2912}
skipping logging after 46608 examples to avoid logging too frequently
skipping logging after 46624 examples to avoid logging too frequently
Running evaluation after 46624 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:17,  2.49s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:06,  2.23s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:56,  1.95s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:08<00:53,  1.92s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:42,  1.56s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.66s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.48s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.55s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.44s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 46624: {'rewards_eval/chosen': '-0.35223', 'rewards_eval/rejected': '-0.43579', 'rewards_eval/accuracies': '0.53906', 'rewards_eval/margins': '0.083591', 'logps_eval/rejected': '-126.51', 'logps_eval/chosen': '-122.02', 'loss/eval': '0.67279'}
skipping logging after 46640 examples to avoid logging too frequently
train stats after 46656 examples: {'rewards_train/chosen': '-0.31194', 'rewards_train/rejected': '-0.42332', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.11133', 'logps_train/rejected': '-133.28', 'logps_train/chosen': '-110.53', 'loss/train': '0.66518', 'examples_per_second': '5.3156', 'grad_norm': '16.75', 'counters/examples': 46656, 'counters/updates': 2916}
skipping logging after 46672 examples to avoid logging too frequently
skipping logging after 46688 examples to avoid logging too frequently
skipping logging after 46704 examples to avoid logging too frequently
train stats after 46720 examples: {'rewards_train/chosen': '-0.27664', 'rewards_train/rejected': '-0.42988', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.15326', 'logps_train/rejected': '-138.15', 'logps_train/chosen': '-131.75', 'loss/train': '0.63843', 'examples_per_second': '3.9997', 'grad_norm': '18', 'counters/examples': 46720, 'counters/updates': 2920}
skipping logging after 46736 examples to avoid logging too frequently
skipping logging after 46752 examples to avoid logging too frequently
skipping logging after 46768 examples to avoid logging too frequently
train stats after 46784 examples: {'rewards_train/chosen': '-0.31072', 'rewards_train/rejected': '-0.41352', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.1028', 'logps_train/rejected': '-104.36', 'logps_train/chosen': '-113.63', 'loss/train': '0.66228', 'examples_per_second': '4.3259', 'grad_norm': '16.875', 'counters/examples': 46784, 'counters/updates': 2924}
skipping logging after 46800 examples to avoid logging too frequently
skipping logging after 46816 examples to avoid logging too frequently
skipping logging after 46832 examples to avoid logging too frequently
train stats after 46848 examples: {'rewards_train/chosen': '-0.25186', 'rewards_train/rejected': '-0.35876', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.10687', 'logps_train/rejected': '-144.2', 'logps_train/chosen': '-133.41', 'loss/train': '0.65097', 'examples_per_second': '5.2589', 'grad_norm': '18.5', 'counters/examples': 46848, 'counters/updates': 2928}
skipping logging after 46864 examples to avoid logging too frequently
skipping logging after 46880 examples to avoid logging too frequently
skipping logging after 46896 examples to avoid logging too frequently
train stats after 46912 examples: {'rewards_train/chosen': '-0.35565', 'rewards_train/rejected': '-0.38639', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.030842', 'logps_train/rejected': '-115.57', 'logps_train/chosen': '-111.79', 'loss/train': '0.69238', 'examples_per_second': '5.2833', 'grad_norm': '17', 'counters/examples': 46912, 'counters/updates': 2932}
skipping logging after 46928 examples to avoid logging too frequently
skipping logging after 46944 examples to avoid logging too frequently
skipping logging after 46960 examples to avoid logging too frequently
train stats after 46976 examples: {'rewards_train/chosen': '-0.26898', 'rewards_train/rejected': '-0.39343', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.12454', 'logps_train/rejected': '-108.68', 'logps_train/chosen': '-106.5', 'loss/train': '0.6478', 'examples_per_second': '5.7518', 'grad_norm': '15.938', 'counters/examples': 46976, 'counters/updates': 2936}
skipping logging after 46992 examples to avoid logging too frequently
skipping logging after 47008 examples to avoid logging too frequently
skipping logging after 47024 examples to avoid logging too frequently
train stats after 47040 examples: {'rewards_train/chosen': '-0.43655', 'rewards_train/rejected': '-0.47255', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.036057', 'logps_train/rejected': '-115.6', 'logps_train/chosen': '-146.48', 'loss/train': '0.68893', 'examples_per_second': '5.5432', 'grad_norm': '20.125', 'counters/examples': 47040, 'counters/updates': 2940}
skipping logging after 47056 examples to avoid logging too frequently
skipping logging after 47072 examples to avoid logging too frequently
skipping logging after 47088 examples to avoid logging too frequently
train stats after 47104 examples: {'rewards_train/chosen': '-0.33758', 'rewards_train/rejected': '-0.46367', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.1262', 'logps_train/rejected': '-129.63', 'logps_train/chosen': '-129.65', 'loss/train': '0.64075', 'examples_per_second': '5.1973', 'grad_norm': '18.125', 'counters/examples': 47104, 'counters/updates': 2944}
skipping logging after 47120 examples to avoid logging too frequently
skipping logging after 47136 examples to avoid logging too frequently
skipping logging after 47152 examples to avoid logging too frequently
train stats after 47168 examples: {'rewards_train/chosen': '-0.34001', 'rewards_train/rejected': '-0.41292', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.072899', 'logps_train/rejected': '-139.94', 'logps_train/chosen': '-133.28', 'loss/train': '0.67889', 'examples_per_second': '4.2753', 'grad_norm': '17.625', 'counters/examples': 47168, 'counters/updates': 2948}
skipping logging after 47184 examples to avoid logging too frequently
skipping logging after 47200 examples to avoid logging too frequently
skipping logging after 47216 examples to avoid logging too frequently
train stats after 47232 examples: {'rewards_train/chosen': '-0.30607', 'rewards_train/rejected': '-0.39445', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.088322', 'logps_train/rejected': '-113.4', 'logps_train/chosen': '-147.67', 'loss/train': '0.6748', 'examples_per_second': '4.906', 'grad_norm': '21.375', 'counters/examples': 47232, 'counters/updates': 2952}
skipping logging after 47248 examples to avoid logging too frequently
skipping logging after 47264 examples to avoid logging too frequently
skipping logging after 47280 examples to avoid logging too frequently
train stats after 47296 examples: {'rewards_train/chosen': '-0.33479', 'rewards_train/rejected': '-0.45617', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.12145', 'logps_train/rejected': '-118.36', 'logps_train/chosen': '-132.57', 'loss/train': '0.65038', 'examples_per_second': '5.7057', 'grad_norm': '17.5', 'counters/examples': 47296, 'counters/updates': 2956}
skipping logging after 47312 examples to avoid logging too frequently
skipping logging after 47328 examples to avoid logging too frequently
skipping logging after 47344 examples to avoid logging too frequently
train stats after 47360 examples: {'rewards_train/chosen': '-0.41823', 'rewards_train/rejected': '-0.51525', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.096945', 'logps_train/rejected': '-136.57', 'logps_train/chosen': '-129.28', 'loss/train': '0.66513', 'examples_per_second': '4.5505', 'grad_norm': '17.5', 'counters/examples': 47360, 'counters/updates': 2960}
skipping logging after 47376 examples to avoid logging too frequently
skipping logging after 47392 examples to avoid logging too frequently
skipping logging after 47408 examples to avoid logging too frequently
train stats after 47424 examples: {'rewards_train/chosen': '-0.38726', 'rewards_train/rejected': '-0.45094', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.063595', 'logps_train/rejected': '-109.86', 'logps_train/chosen': '-118.44', 'loss/train': '0.68709', 'examples_per_second': '4.7721', 'grad_norm': '20.375', 'counters/examples': 47424, 'counters/updates': 2964}
skipping logging after 47440 examples to avoid logging too frequently
skipping logging after 47456 examples to avoid logging too frequently
skipping logging after 47472 examples to avoid logging too frequently
train stats after 47488 examples: {'rewards_train/chosen': '-0.38335', 'rewards_train/rejected': '-0.51986', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.13661', 'logps_train/rejected': '-134.49', 'logps_train/chosen': '-110.45', 'loss/train': '0.64044', 'examples_per_second': '4.7833', 'grad_norm': '19.375', 'counters/examples': 47488, 'counters/updates': 2968}
skipping logging after 47504 examples to avoid logging too frequently
skipping logging after 47520 examples to avoid logging too frequently
skipping logging after 47536 examples to avoid logging too frequently
train stats after 47552 examples: {'rewards_train/chosen': '-0.44102', 'rewards_train/rejected': '-0.54188', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.10073', 'logps_train/rejected': '-122.9', 'logps_train/chosen': '-95.937', 'loss/train': '0.6637', 'examples_per_second': '5.5982', 'grad_norm': '16.375', 'counters/examples': 47552, 'counters/updates': 2972}
skipping logging after 47568 examples to avoid logging too frequently
skipping logging after 47584 examples to avoid logging too frequently
skipping logging after 47600 examples to avoid logging too frequently
train stats after 47616 examples: {'rewards_train/chosen': '-0.5123', 'rewards_train/rejected': '-0.56521', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.052853', 'logps_train/rejected': '-99.349', 'logps_train/chosen': '-121.81', 'loss/train': '0.68987', 'examples_per_second': '5.453', 'grad_norm': '16.625', 'counters/examples': 47616, 'counters/updates': 2976}
Running evaluation after 47616 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.25s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 47616: {'rewards_eval/chosen': '-0.41795', 'rewards_eval/rejected': '-0.49569', 'rewards_eval/accuracies': '0.52734', 'rewards_eval/margins': '0.077768', 'logps_eval/rejected': '-127.11', 'logps_eval/chosen': '-122.67', 'loss/eval': '0.6763'}
skipping logging after 47632 examples to avoid logging too frequently
skipping logging after 47648 examples to avoid logging too frequently
skipping logging after 47664 examples to avoid logging too frequently
train stats after 47680 examples: {'rewards_train/chosen': '-0.36592', 'rewards_train/rejected': '-0.53852', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.17268', 'logps_train/rejected': '-107.62', 'logps_train/chosen': '-122.66', 'loss/train': '0.62759', 'examples_per_second': '5.4998', 'grad_norm': '16', 'counters/examples': 47680, 'counters/updates': 2980}
skipping logging after 47696 examples to avoid logging too frequently
skipping logging after 47712 examples to avoid logging too frequently
skipping logging after 47728 examples to avoid logging too frequently
train stats after 47744 examples: {'rewards_train/chosen': '-0.38405', 'rewards_train/rejected': '-0.43066', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.046642', 'logps_train/rejected': '-105', 'logps_train/chosen': '-108.56', 'loss/train': '0.6846', 'examples_per_second': '5.4839', 'grad_norm': '16.125', 'counters/examples': 47744, 'counters/updates': 2984}
skipping logging after 47760 examples to avoid logging too frequently
skipping logging after 47776 examples to avoid logging too frequently
skipping logging after 47792 examples to avoid logging too frequently
train stats after 47808 examples: {'rewards_train/chosen': '-0.32819', 'rewards_train/rejected': '-0.48025', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.15202', 'logps_train/rejected': '-148.09', 'logps_train/chosen': '-123.82', 'loss/train': '0.64203', 'examples_per_second': '4.4176', 'grad_norm': '17.75', 'counters/examples': 47808, 'counters/updates': 2988}
skipping logging after 47824 examples to avoid logging too frequently
skipping logging after 47840 examples to avoid logging too frequently
skipping logging after 47856 examples to avoid logging too frequently
train stats after 47872 examples: {'rewards_train/chosen': '-0.41693', 'rewards_train/rejected': '-0.49077', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.073937', 'logps_train/rejected': '-121.72', 'logps_train/chosen': '-109.95', 'loss/train': '0.67575', 'examples_per_second': '4.3601', 'grad_norm': '17.875', 'counters/examples': 47872, 'counters/updates': 2992}
skipping logging after 47888 examples to avoid logging too frequently
skipping logging after 47904 examples to avoid logging too frequently
skipping logging after 47920 examples to avoid logging too frequently
train stats after 47936 examples: {'rewards_train/chosen': '-0.37441', 'rewards_train/rejected': '-0.43288', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.058487', 'logps_train/rejected': '-130.04', 'logps_train/chosen': '-124.88', 'loss/train': '0.67468', 'examples_per_second': '4.9502', 'grad_norm': '16.75', 'counters/examples': 47936, 'counters/updates': 2996}
skipping logging after 47952 examples to avoid logging too frequently
skipping logging after 47968 examples to avoid logging too frequently
skipping logging after 47984 examples to avoid logging too frequently
train stats after 48000 examples: {'rewards_train/chosen': '-0.38386', 'rewards_train/rejected': '-0.40866', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.024853', 'logps_train/rejected': '-116.24', 'logps_train/chosen': '-117.14', 'loss/train': '0.69714', 'examples_per_second': '5.2711', 'grad_norm': '16.75', 'counters/examples': 48000, 'counters/updates': 3000}
skipping logging after 48016 examples to avoid logging too frequently
skipping logging after 48032 examples to avoid logging too frequently
skipping logging after 48048 examples to avoid logging too frequently
train stats after 48064 examples: {'rewards_train/chosen': '-0.30268', 'rewards_train/rejected': '-0.3614', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.058544', 'logps_train/rejected': '-115.2', 'logps_train/chosen': '-98.07', 'loss/train': '0.6803', 'examples_per_second': '4.1989', 'grad_norm': '16', 'counters/examples': 48064, 'counters/updates': 3004}
skipping logging after 48080 examples to avoid logging too frequently
skipping logging after 48096 examples to avoid logging too frequently
skipping logging after 48112 examples to avoid logging too frequently
train stats after 48128 examples: {'rewards_train/chosen': '-0.3857', 'rewards_train/rejected': '-0.45824', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.072647', 'logps_train/rejected': '-136.62', 'logps_train/chosen': '-119.14', 'loss/train': '0.67606', 'examples_per_second': '5.7313', 'grad_norm': '18', 'counters/examples': 48128, 'counters/updates': 3008}
skipping logging after 48144 examples to avoid logging too frequently
skipping logging after 48160 examples to avoid logging too frequently
skipping logging after 48176 examples to avoid logging too frequently
train stats after 48192 examples: {'rewards_train/chosen': '-0.3044', 'rewards_train/rejected': '-0.45079', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.14642', 'logps_train/rejected': '-142.9', 'logps_train/chosen': '-141.29', 'loss/train': '0.63922', 'examples_per_second': '6.139', 'grad_norm': '17.125', 'counters/examples': 48192, 'counters/updates': 3012}
skipping logging after 48208 examples to avoid logging too frequently
skipping logging after 48224 examples to avoid logging too frequently
skipping logging after 48240 examples to avoid logging too frequently
train stats after 48256 examples: {'rewards_train/chosen': '-0.309', 'rewards_train/rejected': '-0.36988', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.060963', 'logps_train/rejected': '-155.24', 'logps_train/chosen': '-154.43', 'loss/train': '0.68298', 'examples_per_second': '5.177', 'grad_norm': '18.375', 'counters/examples': 48256, 'counters/updates': 3016}
skipping logging after 48272 examples to avoid logging too frequently
skipping logging after 48288 examples to avoid logging too frequently
skipping logging after 48304 examples to avoid logging too frequently
train stats after 48320 examples: {'rewards_train/chosen': '-0.29602', 'rewards_train/rejected': '-0.48678', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.19065', 'logps_train/rejected': '-124.17', 'logps_train/chosen': '-107.41', 'loss/train': '0.62653', 'examples_per_second': '4.3845', 'grad_norm': '16.125', 'counters/examples': 48320, 'counters/updates': 3020}
skipping logging after 48336 examples to avoid logging too frequently
skipping logging after 48352 examples to avoid logging too frequently
skipping logging after 48368 examples to avoid logging too frequently
train stats after 48384 examples: {'rewards_train/chosen': '-0.34211', 'rewards_train/rejected': '-0.47997', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.13777', 'logps_train/rejected': '-108.78', 'logps_train/chosen': '-120.31', 'loss/train': '0.64905', 'examples_per_second': '5.6327', 'grad_norm': '17', 'counters/examples': 48384, 'counters/updates': 3024}
skipping logging after 48400 examples to avoid logging too frequently
skipping logging after 48416 examples to avoid logging too frequently
skipping logging after 48432 examples to avoid logging too frequently
train stats after 48448 examples: {'rewards_train/chosen': '-0.39777', 'rewards_train/rejected': '-0.55391', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.15617', 'logps_train/rejected': '-128.57', 'logps_train/chosen': '-108.98', 'loss/train': '0.6414', 'examples_per_second': '4.5006', 'grad_norm': '17.5', 'counters/examples': 48448, 'counters/updates': 3028}
skipping logging after 48464 examples to avoid logging too frequently
skipping logging after 48480 examples to avoid logging too frequently
skipping logging after 48496 examples to avoid logging too frequently
train stats after 48512 examples: {'rewards_train/chosen': '-0.34416', 'rewards_train/rejected': '-0.48331', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.13896', 'logps_train/rejected': '-109.76', 'logps_train/chosen': '-133.81', 'loss/train': '0.6472', 'examples_per_second': '5.2672', 'grad_norm': '16.375', 'counters/examples': 48512, 'counters/updates': 3032}
skipping logging after 48528 examples to avoid logging too frequently
skipping logging after 48544 examples to avoid logging too frequently
skipping logging after 48560 examples to avoid logging too frequently
train stats after 48576 examples: {'rewards_train/chosen': '-0.39785', 'rewards_train/rejected': '-0.50613', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.10823', 'logps_train/rejected': '-118.7', 'logps_train/chosen': '-122.69', 'loss/train': '0.66792', 'examples_per_second': '4.794', 'grad_norm': '17.75', 'counters/examples': 48576, 'counters/updates': 3036}
skipping logging after 48592 examples to avoid logging too frequently
skipping logging after 48608 examples to avoid logging too frequently
Running evaluation after 48608 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:11,  2.31s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:04,  2.15s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:55,  1.90s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.88s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 48608: {'rewards_eval/chosen': '-0.36298', 'rewards_eval/rejected': '-0.4497', 'rewards_eval/accuracies': '0.5332', 'rewards_eval/margins': '0.086743', 'logps_eval/rejected': '-126.65', 'logps_eval/chosen': '-122.12', 'loss/eval': '0.67254'}
skipping logging after 48624 examples to avoid logging too frequently
train stats after 48640 examples: {'rewards_train/chosen': '-0.31669', 'rewards_train/rejected': '-0.47758', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.1608', 'logps_train/rejected': '-116.71', 'logps_train/chosen': '-115.83', 'loss/train': '0.63997', 'examples_per_second': '5.5156', 'grad_norm': '15.812', 'counters/examples': 48640, 'counters/updates': 3040}
skipping logging after 48656 examples to avoid logging too frequently
skipping logging after 48672 examples to avoid logging too frequently
skipping logging after 48688 examples to avoid logging too frequently
train stats after 48704 examples: {'rewards_train/chosen': '-0.42804', 'rewards_train/rejected': '-0.51098', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.082939', 'logps_train/rejected': '-149.56', 'logps_train/chosen': '-134.93', 'loss/train': '0.66838', 'examples_per_second': '5.3599', 'grad_norm': '19.625', 'counters/examples': 48704, 'counters/updates': 3044}
skipping logging after 48720 examples to avoid logging too frequently
skipping logging after 48736 examples to avoid logging too frequently
skipping logging after 48752 examples to avoid logging too frequently
train stats after 48768 examples: {'rewards_train/chosen': '-0.36367', 'rewards_train/rejected': '-0.39935', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.035683', 'logps_train/rejected': '-99.123', 'logps_train/chosen': '-121.35', 'loss/train': '0.68686', 'examples_per_second': '5.2365', 'grad_norm': '15.812', 'counters/examples': 48768, 'counters/updates': 3048}
skipping logging after 48784 examples to avoid logging too frequently
skipping logging after 48800 examples to avoid logging too frequently
skipping logging after 48816 examples to avoid logging too frequently
train stats after 48832 examples: {'rewards_train/chosen': '-0.37628', 'rewards_train/rejected': '-0.5005', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.1242', 'logps_train/rejected': '-117.85', 'logps_train/chosen': '-116.09', 'loss/train': '0.65247', 'examples_per_second': '5.5198', 'grad_norm': '19', 'counters/examples': 48832, 'counters/updates': 3052}
skipping logging after 48848 examples to avoid logging too frequently
skipping logging after 48864 examples to avoid logging too frequently
skipping logging after 48880 examples to avoid logging too frequently
train stats after 48896 examples: {'rewards_train/chosen': '-0.36211', 'rewards_train/rejected': '-0.4714', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.10933', 'logps_train/rejected': '-146.1', 'logps_train/chosen': '-140.37', 'loss/train': '0.66371', 'examples_per_second': '4.9155', 'grad_norm': '18.125', 'counters/examples': 48896, 'counters/updates': 3056}
skipping logging after 48912 examples to avoid logging too frequently
skipping logging after 48928 examples to avoid logging too frequently
skipping logging after 48944 examples to avoid logging too frequently
train stats after 48960 examples: {'rewards_train/chosen': '-0.35554', 'rewards_train/rejected': '-0.48847', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.13293', 'logps_train/rejected': '-117.31', 'logps_train/chosen': '-138.94', 'loss/train': '0.64899', 'examples_per_second': '6.1664', 'grad_norm': '21.75', 'counters/examples': 48960, 'counters/updates': 3060}
skipping logging after 48976 examples to avoid logging too frequently
skipping logging after 48992 examples to avoid logging too frequently
skipping logging after 49008 examples to avoid logging too frequently
train stats after 49024 examples: {'rewards_train/chosen': '-0.45454', 'rewards_train/rejected': '-0.5899', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.13524', 'logps_train/rejected': '-117.55', 'logps_train/chosen': '-97.957', 'loss/train': '0.64301', 'examples_per_second': '5.7883', 'grad_norm': '17.5', 'counters/examples': 49024, 'counters/updates': 3064}
skipping logging after 49040 examples to avoid logging too frequently
skipping logging after 49056 examples to avoid logging too frequently
skipping logging after 49072 examples to avoid logging too frequently
train stats after 49088 examples: {'rewards_train/chosen': '-0.67539', 'rewards_train/rejected': '-0.72911', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.053753', 'logps_train/rejected': '-122.11', 'logps_train/chosen': '-115.81', 'loss/train': '0.69415', 'examples_per_second': '5.7471', 'grad_norm': '19.75', 'counters/examples': 49088, 'counters/updates': 3068}
skipping logging after 49104 examples to avoid logging too frequently
skipping logging after 49120 examples to avoid logging too frequently
skipping logging after 49136 examples to avoid logging too frequently
train stats after 49152 examples: {'rewards_train/chosen': '-0.50034', 'rewards_train/rejected': '-0.65601', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.15582', 'logps_train/rejected': '-148.76', 'logps_train/chosen': '-142.59', 'loss/train': '0.63718', 'examples_per_second': '4.8484', 'grad_norm': '18.125', 'counters/examples': 49152, 'counters/updates': 3072}
skipping logging after 49168 examples to avoid logging too frequently
skipping logging after 49184 examples to avoid logging too frequently
skipping logging after 49200 examples to avoid logging too frequently
train stats after 49216 examples: {'rewards_train/chosen': '-0.51123', 'rewards_train/rejected': '-0.55203', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.040836', 'logps_train/rejected': '-136.26', 'logps_train/chosen': '-127.7', 'loss/train': '0.69894', 'examples_per_second': '5.507', 'grad_norm': '19', 'counters/examples': 49216, 'counters/updates': 3076}
skipping logging after 49232 examples to avoid logging too frequently
skipping logging after 49248 examples to avoid logging too frequently
skipping logging after 49264 examples to avoid logging too frequently
train stats after 49280 examples: {'rewards_train/chosen': '-0.58886', 'rewards_train/rejected': '-0.61964', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.030788', 'logps_train/rejected': '-112.7', 'logps_train/chosen': '-103.76', 'loss/train': '0.69305', 'examples_per_second': '6.0721', 'grad_norm': '16.75', 'counters/examples': 49280, 'counters/updates': 3080}
skipping logging after 49296 examples to avoid logging too frequently
skipping logging after 49312 examples to avoid logging too frequently
skipping logging after 49328 examples to avoid logging too frequently
train stats after 49344 examples: {'rewards_train/chosen': '-0.46678', 'rewards_train/rejected': '-0.54483', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.078041', 'logps_train/rejected': '-121.9', 'logps_train/chosen': '-122.51', 'loss/train': '0.67456', 'examples_per_second': '4.674', 'grad_norm': '16.125', 'counters/examples': 49344, 'counters/updates': 3084}
skipping logging after 49360 examples to avoid logging too frequently
skipping logging after 49376 examples to avoid logging too frequently
skipping logging after 49392 examples to avoid logging too frequently
train stats after 49408 examples: {'rewards_train/chosen': '-0.57377', 'rewards_train/rejected': '-0.73598', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.16206', 'logps_train/rejected': '-112.05', 'logps_train/chosen': '-96.555', 'loss/train': '0.63994', 'examples_per_second': '4.2588', 'grad_norm': '18', 'counters/examples': 49408, 'counters/updates': 3088}
skipping logging after 49424 examples to avoid logging too frequently
skipping logging after 49440 examples to avoid logging too frequently
skipping logging after 49456 examples to avoid logging too frequently
train stats after 49472 examples: {'rewards_train/chosen': '-0.48118', 'rewards_train/rejected': '-0.62035', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.13913', 'logps_train/rejected': '-118.03', 'logps_train/chosen': '-136.51', 'loss/train': '0.65073', 'examples_per_second': '5.1071', 'grad_norm': '16.625', 'counters/examples': 49472, 'counters/updates': 3092}
skipping logging after 49488 examples to avoid logging too frequently
skipping logging after 49504 examples to avoid logging too frequently
skipping logging after 49520 examples to avoid logging too frequently
train stats after 49536 examples: {'rewards_train/chosen': '-0.60401', 'rewards_train/rejected': '-0.6718', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.06776', 'logps_train/rejected': '-95.758', 'logps_train/chosen': '-97.149', 'loss/train': '0.67859', 'examples_per_second': '4.6876', 'grad_norm': '14.875', 'counters/examples': 49536, 'counters/updates': 3096}
skipping logging after 49552 examples to avoid logging too frequently
skipping logging after 49568 examples to avoid logging too frequently
skipping logging after 49584 examples to avoid logging too frequently
train stats after 49600 examples: {'rewards_train/chosen': '-0.43749', 'rewards_train/rejected': '-0.50002', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.062504', 'logps_train/rejected': '-121.74', 'logps_train/chosen': '-115.99', 'loss/train': '0.68259', 'examples_per_second': '4.3256', 'grad_norm': '16.375', 'counters/examples': 49600, 'counters/updates': 3100}
Running evaluation after 49600 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.63s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.23s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 49600: {'rewards_eval/chosen': '-0.49451', 'rewards_eval/rejected': '-0.57723', 'rewards_eval/accuracies': '0.52344', 'rewards_eval/margins': '0.082752', 'logps_eval/rejected': '-127.93', 'logps_eval/chosen': '-123.44', 'loss/eval': '0.67427'}
skipping logging after 49616 examples to avoid logging too frequently
skipping logging after 49632 examples to avoid logging too frequently
skipping logging after 49648 examples to avoid logging too frequently
train stats after 49664 examples: {'rewards_train/chosen': '-0.55739', 'rewards_train/rejected': '-0.58788', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.030533', 'logps_train/rejected': '-100.7', 'logps_train/chosen': '-115.1', 'loss/train': '0.69595', 'examples_per_second': '5.4663', 'grad_norm': '21.625', 'counters/examples': 49664, 'counters/updates': 3104}
skipping logging after 49680 examples to avoid logging too frequently
skipping logging after 49696 examples to avoid logging too frequently
skipping logging after 49712 examples to avoid logging too frequently
train stats after 49728 examples: {'rewards_train/chosen': '-0.47711', 'rewards_train/rejected': '-0.54559', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.068562', 'logps_train/rejected': '-113.78', 'logps_train/chosen': '-112.99', 'loss/train': '0.67947', 'examples_per_second': '5.4216', 'grad_norm': '16.75', 'counters/examples': 49728, 'counters/updates': 3108}
skipping logging after 49744 examples to avoid logging too frequently
skipping logging after 49760 examples to avoid logging too frequently
skipping logging after 49776 examples to avoid logging too frequently
train stats after 49792 examples: {'rewards_train/chosen': '-0.54275', 'rewards_train/rejected': '-0.62123', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.078522', 'logps_train/rejected': '-143.29', 'logps_train/chosen': '-114.95', 'loss/train': '0.67279', 'examples_per_second': '4.9882', 'grad_norm': '18.125', 'counters/examples': 49792, 'counters/updates': 3112}
skipping logging after 49808 examples to avoid logging too frequently
skipping logging after 49824 examples to avoid logging too frequently
skipping logging after 49840 examples to avoid logging too frequently
train stats after 49856 examples: {'rewards_train/chosen': '-0.62292', 'rewards_train/rejected': '-0.65467', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.031708', 'logps_train/rejected': '-95.671', 'logps_train/chosen': '-117.23', 'loss/train': '0.69031', 'examples_per_second': '5.851', 'grad_norm': '16.625', 'counters/examples': 49856, 'counters/updates': 3116}
skipping logging after 49872 examples to avoid logging too frequently
skipping logging after 49888 examples to avoid logging too frequently
skipping logging after 49904 examples to avoid logging too frequently
train stats after 49920 examples: {'rewards_train/chosen': '-0.58979', 'rewards_train/rejected': '-0.66453', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.074795', 'logps_train/rejected': '-139.54', 'logps_train/chosen': '-134.14', 'loss/train': '0.6651', 'examples_per_second': '5.2896', 'grad_norm': '22.625', 'counters/examples': 49920, 'counters/updates': 3120}
skipping logging after 49936 examples to avoid logging too frequently
skipping logging after 49952 examples to avoid logging too frequently
skipping logging after 49968 examples to avoid logging too frequently
train stats after 49984 examples: {'rewards_train/chosen': '-0.48414', 'rewards_train/rejected': '-0.5518', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.067661', 'logps_train/rejected': '-111.45', 'logps_train/chosen': '-111.44', 'loss/train': '0.67358', 'examples_per_second': '5.0212', 'grad_norm': '19.375', 'counters/examples': 49984, 'counters/updates': 3124}
skipping logging after 50000 examples to avoid logging too frequently
skipping logging after 50016 examples to avoid logging too frequently
skipping logging after 50032 examples to avoid logging too frequently
train stats after 50048 examples: {'rewards_train/chosen': '-0.45028', 'rewards_train/rejected': '-0.45956', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.0092525', 'logps_train/rejected': '-115.83', 'logps_train/chosen': '-116.19', 'loss/train': '0.71234', 'examples_per_second': '5.1586', 'grad_norm': '17.25', 'counters/examples': 50048, 'counters/updates': 3128}
skipping logging after 50064 examples to avoid logging too frequently
skipping logging after 50080 examples to avoid logging too frequently
skipping logging after 50096 examples to avoid logging too frequently
train stats after 50112 examples: {'rewards_train/chosen': '-0.49627', 'rewards_train/rejected': '-0.58802', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.09185', 'logps_train/rejected': '-126.26', 'logps_train/chosen': '-145.51', 'loss/train': '0.66885', 'examples_per_second': '4.508', 'grad_norm': '18.625', 'counters/examples': 50112, 'counters/updates': 3132}
skipping logging after 50128 examples to avoid logging too frequently
skipping logging after 50144 examples to avoid logging too frequently
skipping logging after 50160 examples to avoid logging too frequently
train stats after 50176 examples: {'rewards_train/chosen': '-0.51085', 'rewards_train/rejected': '-0.58525', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.074251', 'logps_train/rejected': '-114.87', 'logps_train/chosen': '-113.69', 'loss/train': '0.68182', 'examples_per_second': '4.8447', 'grad_norm': '16.875', 'counters/examples': 50176, 'counters/updates': 3136}
skipping logging after 50192 examples to avoid logging too frequently
skipping logging after 50208 examples to avoid logging too frequently
skipping logging after 50224 examples to avoid logging too frequently
train stats after 50240 examples: {'rewards_train/chosen': '-0.48779', 'rewards_train/rejected': '-0.64096', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.15314', 'logps_train/rejected': '-126.44', 'logps_train/chosen': '-119.31', 'loss/train': '0.63979', 'examples_per_second': '5.6188', 'grad_norm': '17.125', 'counters/examples': 50240, 'counters/updates': 3140}
skipping logging after 50256 examples to avoid logging too frequently
skipping logging after 50272 examples to avoid logging too frequently
skipping logging after 50288 examples to avoid logging too frequently
train stats after 50304 examples: {'rewards_train/chosen': '-0.52293', 'rewards_train/rejected': '-0.60416', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.081192', 'logps_train/rejected': '-124.65', 'logps_train/chosen': '-151.23', 'loss/train': '0.67798', 'examples_per_second': '5.9285', 'grad_norm': '18.75', 'counters/examples': 50304, 'counters/updates': 3144}
skipping logging after 50320 examples to avoid logging too frequently
skipping logging after 50336 examples to avoid logging too frequently
skipping logging after 50352 examples to avoid logging too frequently
train stats after 50368 examples: {'rewards_train/chosen': '-0.45473', 'rewards_train/rejected': '-0.51793', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.063244', 'logps_train/rejected': '-123.3', 'logps_train/chosen': '-101.27', 'loss/train': '0.68095', 'examples_per_second': '4.7427', 'grad_norm': '18.875', 'counters/examples': 50368, 'counters/updates': 3148}
skipping logging after 50384 examples to avoid logging too frequently
skipping logging after 50400 examples to avoid logging too frequently
skipping logging after 50416 examples to avoid logging too frequently
train stats after 50432 examples: {'rewards_train/chosen': '-0.38529', 'rewards_train/rejected': '-0.51052', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.12517', 'logps_train/rejected': '-150.57', 'logps_train/chosen': '-133.15', 'loss/train': '0.65036', 'examples_per_second': '5.3975', 'grad_norm': '17.625', 'counters/examples': 50432, 'counters/updates': 3152}
skipping logging after 50448 examples to avoid logging too frequently
skipping logging after 50464 examples to avoid logging too frequently
skipping logging after 50480 examples to avoid logging too frequently
train stats after 50496 examples: {'rewards_train/chosen': '-0.38087', 'rewards_train/rejected': '-0.45416', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.07328', 'logps_train/rejected': '-150.1', 'logps_train/chosen': '-142.86', 'loss/train': '0.6698', 'examples_per_second': '4.1386', 'grad_norm': '18.25', 'counters/examples': 50496, 'counters/updates': 3156}
skipping logging after 50512 examples to avoid logging too frequently
skipping logging after 50528 examples to avoid logging too frequently
skipping logging after 50544 examples to avoid logging too frequently
train stats after 50560 examples: {'rewards_train/chosen': '-0.50173', 'rewards_train/rejected': '-0.52978', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.028049', 'logps_train/rejected': '-119.02', 'logps_train/chosen': '-136.27', 'loss/train': '0.70285', 'examples_per_second': '5.2383', 'grad_norm': '18.375', 'counters/examples': 50560, 'counters/updates': 3160}
skipping logging after 50576 examples to avoid logging too frequently
skipping logging after 50592 examples to avoid logging too frequently
Running evaluation after 50592 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:09,  2.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:03,  2.13s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:55,  1.90s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.89s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.54s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.48s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.23s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.32s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.33s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.25s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.29s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 50592: {'rewards_eval/chosen': '-0.43642', 'rewards_eval/rejected': '-0.51754', 'rewards_eval/accuracies': '0.52539', 'rewards_eval/margins': '0.081142', 'logps_eval/rejected': '-127.33', 'logps_eval/chosen': '-122.86', 'loss/eval': '0.67482'}
skipping logging after 50608 examples to avoid logging too frequently
train stats after 50624 examples: {'rewards_train/chosen': '-0.47397', 'rewards_train/rejected': '-0.54707', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.072859', 'logps_train/rejected': '-99.254', 'logps_train/chosen': '-96.647', 'loss/train': '0.6815', 'examples_per_second': '5.502', 'grad_norm': '17.375', 'counters/examples': 50624, 'counters/updates': 3164}
skipping logging after 50640 examples to avoid logging too frequently
skipping logging after 50656 examples to avoid logging too frequently
skipping logging after 50672 examples to avoid logging too frequently
train stats after 50688 examples: {'rewards_train/chosen': '-0.38205', 'rewards_train/rejected': '-0.36403', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '-0.017934', 'logps_train/rejected': '-98.498', 'logps_train/chosen': '-102.97', 'loss/train': '0.71667', 'examples_per_second': '4.3563', 'grad_norm': '17.375', 'counters/examples': 50688, 'counters/updates': 3168}
skipping logging after 50704 examples to avoid logging too frequently
skipping logging after 50720 examples to avoid logging too frequently
skipping logging after 50736 examples to avoid logging too frequently
train stats after 50752 examples: {'rewards_train/chosen': '-0.42798', 'rewards_train/rejected': '-0.49247', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.064419', 'logps_train/rejected': '-111.1', 'logps_train/chosen': '-112.47', 'loss/train': '0.67505', 'examples_per_second': '5.8297', 'grad_norm': '16.875', 'counters/examples': 50752, 'counters/updates': 3172}
skipping logging after 50768 examples to avoid logging too frequently
skipping logging after 50784 examples to avoid logging too frequently
skipping logging after 50800 examples to avoid logging too frequently
train stats after 50816 examples: {'rewards_train/chosen': '-0.34427', 'rewards_train/rejected': '-0.43828', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.094048', 'logps_train/rejected': '-129.72', 'logps_train/chosen': '-106.33', 'loss/train': '0.66345', 'examples_per_second': '5.202', 'grad_norm': '17.5', 'counters/examples': 50816, 'counters/updates': 3176}
skipping logging after 50832 examples to avoid logging too frequently
skipping logging after 50848 examples to avoid logging too frequently
skipping logging after 50864 examples to avoid logging too frequently
train stats after 50880 examples: {'rewards_train/chosen': '-0.4476', 'rewards_train/rejected': '-0.6296', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.18195', 'logps_train/rejected': '-129.46', 'logps_train/chosen': '-134.59', 'loss/train': '0.62395', 'examples_per_second': '5.176', 'grad_norm': '18.625', 'counters/examples': 50880, 'counters/updates': 3180}
skipping logging after 50896 examples to avoid logging too frequently
skipping logging after 50912 examples to avoid logging too frequently
skipping logging after 50928 examples to avoid logging too frequently
train stats after 50944 examples: {'rewards_train/chosen': '-0.40005', 'rewards_train/rejected': '-0.45921', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.059059', 'logps_train/rejected': '-122.27', 'logps_train/chosen': '-93.979', 'loss/train': '0.6792', 'examples_per_second': '5.8571', 'grad_norm': '18', 'counters/examples': 50944, 'counters/updates': 3184}
skipping logging after 50960 examples to avoid logging too frequently
skipping logging after 50976 examples to avoid logging too frequently
skipping logging after 50992 examples to avoid logging too frequently
train stats after 51008 examples: {'rewards_train/chosen': '-0.47426', 'rewards_train/rejected': '-0.48304', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.0087967', 'logps_train/rejected': '-119.7', 'logps_train/chosen': '-117.38', 'loss/train': '0.70609', 'examples_per_second': '5.7975', 'grad_norm': '17', 'counters/examples': 51008, 'counters/updates': 3188}
skipping logging after 51024 examples to avoid logging too frequently
skipping logging after 51040 examples to avoid logging too frequently
skipping logging after 51056 examples to avoid logging too frequently
train stats after 51072 examples: {'rewards_train/chosen': '-0.41799', 'rewards_train/rejected': '-0.46315', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.045094', 'logps_train/rejected': '-92.812', 'logps_train/chosen': '-123.93', 'loss/train': '0.68484', 'examples_per_second': '5.0845', 'grad_norm': '18', 'counters/examples': 51072, 'counters/updates': 3192}
skipping logging after 51088 examples to avoid logging too frequently
skipping logging after 51104 examples to avoid logging too frequently
skipping logging after 51120 examples to avoid logging too frequently
train stats after 51136 examples: {'rewards_train/chosen': '-0.43781', 'rewards_train/rejected': '-0.50368', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.065922', 'logps_train/rejected': '-120.92', 'logps_train/chosen': '-112.13', 'loss/train': '0.68384', 'examples_per_second': '5.3112', 'grad_norm': '17.25', 'counters/examples': 51136, 'counters/updates': 3196}
skipping logging after 51152 examples to avoid logging too frequently
skipping logging after 51168 examples to avoid logging too frequently
skipping logging after 51184 examples to avoid logging too frequently
train stats after 51200 examples: {'rewards_train/chosen': '-0.24533', 'rewards_train/rejected': '-0.34015', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.094707', 'logps_train/rejected': '-139.75', 'logps_train/chosen': '-137.08', 'loss/train': '0.66859', 'examples_per_second': '4.0824', 'grad_norm': '17.875', 'counters/examples': 51200, 'counters/updates': 3200}
skipping logging after 51216 examples to avoid logging too frequently
skipping logging after 51232 examples to avoid logging too frequently
skipping logging after 51248 examples to avoid logging too frequently
train stats after 51264 examples: {'rewards_train/chosen': '-0.2566', 'rewards_train/rejected': '-0.31009', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.053459', 'logps_train/rejected': '-123.6', 'logps_train/chosen': '-130.71', 'loss/train': '0.677', 'examples_per_second': '4.6088', 'grad_norm': '15.938', 'counters/examples': 51264, 'counters/updates': 3204}
skipping logging after 51280 examples to avoid logging too frequently
skipping logging after 51296 examples to avoid logging too frequently
skipping logging after 51312 examples to avoid logging too frequently
train stats after 51328 examples: {'rewards_train/chosen': '-0.3408', 'rewards_train/rejected': '-0.35959', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.018747', 'logps_train/rejected': '-137.9', 'logps_train/chosen': '-112.59', 'loss/train': '0.69577', 'examples_per_second': '5.1339', 'grad_norm': '17', 'counters/examples': 51328, 'counters/updates': 3208}
skipping logging after 51344 examples to avoid logging too frequently
skipping logging after 51360 examples to avoid logging too frequently
skipping logging after 51376 examples to avoid logging too frequently
train stats after 51392 examples: {'rewards_train/chosen': '-0.3595', 'rewards_train/rejected': '-0.44896', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.089537', 'logps_train/rejected': '-113.07', 'logps_train/chosen': '-107.97', 'loss/train': '0.67032', 'examples_per_second': '5.6714', 'grad_norm': '15.625', 'counters/examples': 51392, 'counters/updates': 3212}
skipping logging after 51408 examples to avoid logging too frequently
skipping logging after 51424 examples to avoid logging too frequently
skipping logging after 51440 examples to avoid logging too frequently
train stats after 51456 examples: {'rewards_train/chosen': '-0.25234', 'rewards_train/rejected': '-0.34873', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.096298', 'logps_train/rejected': '-134.72', 'logps_train/chosen': '-132.88', 'loss/train': '0.66911', 'examples_per_second': '4.6455', 'grad_norm': '17.375', 'counters/examples': 51456, 'counters/updates': 3216}
skipping logging after 51472 examples to avoid logging too frequently
skipping logging after 51488 examples to avoid logging too frequently
skipping logging after 51504 examples to avoid logging too frequently
train stats after 51520 examples: {'rewards_train/chosen': '-0.26243', 'rewards_train/rejected': '-0.40025', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.13788', 'logps_train/rejected': '-121.49', 'logps_train/chosen': '-113.96', 'loss/train': '0.6423', 'examples_per_second': '5.4141', 'grad_norm': '15.25', 'counters/examples': 51520, 'counters/updates': 3220}
skipping logging after 51536 examples to avoid logging too frequently
skipping logging after 51552 examples to avoid logging too frequently
skipping logging after 51568 examples to avoid logging too frequently
train stats after 51584 examples: {'rewards_train/chosen': '-0.26013', 'rewards_train/rejected': '-0.40171', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.14156', 'logps_train/rejected': '-123.68', 'logps_train/chosen': '-121.4', 'loss/train': '0.63927', 'examples_per_second': '5.1982', 'grad_norm': '16.5', 'counters/examples': 51584, 'counters/updates': 3224}
Running evaluation after 51584 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.25s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.29s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.41s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 51584: {'rewards_eval/chosen': '-0.34171', 'rewards_eval/rejected': '-0.41806', 'rewards_eval/accuracies': '0.53711', 'rewards_eval/margins': '0.076442', 'logps_eval/rejected': '-126.34', 'logps_eval/chosen': '-121.91', 'loss/eval': '0.67675'}
skipping logging after 51600 examples to avoid logging too frequently
skipping logging after 51616 examples to avoid logging too frequently
skipping logging after 51632 examples to avoid logging too frequently
train stats after 51648 examples: {'rewards_train/chosen': '-0.23055', 'rewards_train/rejected': '-0.40103', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.17065', 'logps_train/rejected': '-133.35', 'logps_train/chosen': '-141.07', 'loss/train': '0.63293', 'examples_per_second': '4.7763', 'grad_norm': '18.125', 'counters/examples': 51648, 'counters/updates': 3228}
skipping logging after 51664 examples to avoid logging too frequently
skipping logging after 51680 examples to avoid logging too frequently
skipping logging after 51696 examples to avoid logging too frequently
train stats after 51712 examples: {'rewards_train/chosen': '-0.31301', 'rewards_train/rejected': '-0.4104', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.097401', 'logps_train/rejected': '-129.04', 'logps_train/chosen': '-120.45', 'loss/train': '0.65994', 'examples_per_second': '4.8744', 'grad_norm': '16.875', 'counters/examples': 51712, 'counters/updates': 3232}
skipping logging after 51728 examples to avoid logging too frequently
skipping logging after 51744 examples to avoid logging too frequently
skipping logging after 51760 examples to avoid logging too frequently
train stats after 51776 examples: {'rewards_train/chosen': '-0.40065', 'rewards_train/rejected': '-0.48512', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.084564', 'logps_train/rejected': '-132.1', 'logps_train/chosen': '-129.91', 'loss/train': '0.67258', 'examples_per_second': '4.5621', 'grad_norm': '17.25', 'counters/examples': 51776, 'counters/updates': 3236}
skipping logging after 51792 examples to avoid logging too frequently
skipping logging after 51808 examples to avoid logging too frequently
skipping logging after 51824 examples to avoid logging too frequently
train stats after 51840 examples: {'rewards_train/chosen': '-0.40414', 'rewards_train/rejected': '-0.5377', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.1335', 'logps_train/rejected': '-99.311', 'logps_train/chosen': '-118.17', 'loss/train': '0.65482', 'examples_per_second': '5.0036', 'grad_norm': '14.312', 'counters/examples': 51840, 'counters/updates': 3240}
skipping logging after 51856 examples to avoid logging too frequently
skipping logging after 51872 examples to avoid logging too frequently
skipping logging after 51888 examples to avoid logging too frequently
train stats after 51904 examples: {'rewards_train/chosen': '-0.3338', 'rewards_train/rejected': '-0.47915', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.14539', 'logps_train/rejected': '-129.24', 'logps_train/chosen': '-128.82', 'loss/train': '0.64836', 'examples_per_second': '4.3728', 'grad_norm': '16', 'counters/examples': 51904, 'counters/updates': 3244}
skipping logging after 51920 examples to avoid logging too frequently
skipping logging after 51936 examples to avoid logging too frequently
skipping logging after 51952 examples to avoid logging too frequently
train stats after 51968 examples: {'rewards_train/chosen': '-0.40949', 'rewards_train/rejected': '-0.47674', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.067307', 'logps_train/rejected': '-108.92', 'logps_train/chosen': '-120.87', 'loss/train': '0.67346', 'examples_per_second': '4.7245', 'grad_norm': '17', 'counters/examples': 51968, 'counters/updates': 3248}
skipping logging after 51984 examples to avoid logging too frequently
skipping logging after 52000 examples to avoid logging too frequently
skipping logging after 52016 examples to avoid logging too frequently
train stats after 52032 examples: {'rewards_train/chosen': '-0.30063', 'rewards_train/rejected': '-0.36489', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.064272', 'logps_train/rejected': '-129.5', 'logps_train/chosen': '-119.36', 'loss/train': '0.67972', 'examples_per_second': '4.4868', 'grad_norm': '19.625', 'counters/examples': 52032, 'counters/updates': 3252}
skipping logging after 52048 examples to avoid logging too frequently
skipping logging after 52064 examples to avoid logging too frequently
skipping logging after 52080 examples to avoid logging too frequently
train stats after 52096 examples: {'rewards_train/chosen': '-0.32048', 'rewards_train/rejected': '-0.49486', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.17447', 'logps_train/rejected': '-130.72', 'logps_train/chosen': '-145.42', 'loss/train': '0.63684', 'examples_per_second': '4.555', 'grad_norm': '18.375', 'counters/examples': 52096, 'counters/updates': 3256}
skipping logging after 52112 examples to avoid logging too frequently
skipping logging after 52128 examples to avoid logging too frequently
skipping logging after 52144 examples to avoid logging too frequently
train stats after 52160 examples: {'rewards_train/chosen': '-0.30359', 'rewards_train/rejected': '-0.34968', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.046059', 'logps_train/rejected': '-119.03', 'logps_train/chosen': '-120.71', 'loss/train': '0.68939', 'examples_per_second': '4.9118', 'grad_norm': '16.875', 'counters/examples': 52160, 'counters/updates': 3260}
skipping logging after 52176 examples to avoid logging too frequently
skipping logging after 52192 examples to avoid logging too frequently
skipping logging after 52208 examples to avoid logging too frequently
train stats after 52224 examples: {'rewards_train/chosen': '-0.33642', 'rewards_train/rejected': '-0.42536', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.088978', 'logps_train/rejected': '-98.845', 'logps_train/chosen': '-133.07', 'loss/train': '0.66251', 'examples_per_second': '5.7618', 'grad_norm': '15.5', 'counters/examples': 52224, 'counters/updates': 3264}
skipping logging after 52240 examples to avoid logging too frequently
skipping logging after 52256 examples to avoid logging too frequently
skipping logging after 52272 examples to avoid logging too frequently
train stats after 52288 examples: {'rewards_train/chosen': '-0.36792', 'rewards_train/rejected': '-0.42984', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.061857', 'logps_train/rejected': '-126.86', 'logps_train/chosen': '-125.38', 'loss/train': '0.68433', 'examples_per_second': '4.6957', 'grad_norm': '20.375', 'counters/examples': 52288, 'counters/updates': 3268}
skipping logging after 52304 examples to avoid logging too frequently
skipping logging after 52320 examples to avoid logging too frequently
skipping logging after 52336 examples to avoid logging too frequently
train stats after 52352 examples: {'rewards_train/chosen': '-0.30394', 'rewards_train/rejected': '-0.44229', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.13842', 'logps_train/rejected': '-135.39', 'logps_train/chosen': '-135.96', 'loss/train': '0.64676', 'examples_per_second': '4.8679', 'grad_norm': '16.75', 'counters/examples': 52352, 'counters/updates': 3272}
skipping logging after 52368 examples to avoid logging too frequently
skipping logging after 52384 examples to avoid logging too frequently
skipping logging after 52400 examples to avoid logging too frequently
train stats after 52416 examples: {'rewards_train/chosen': '-0.33752', 'rewards_train/rejected': '-0.48441', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.14682', 'logps_train/rejected': '-125.57', 'logps_train/chosen': '-119.62', 'loss/train': '0.64398', 'examples_per_second': '5.2011', 'grad_norm': '16.125', 'counters/examples': 52416, 'counters/updates': 3276}
skipping logging after 52432 examples to avoid logging too frequently
skipping logging after 52448 examples to avoid logging too frequently
skipping logging after 52464 examples to avoid logging too frequently
train stats after 52480 examples: {'rewards_train/chosen': '-0.26867', 'rewards_train/rejected': '-0.38823', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.11955', 'logps_train/rejected': '-134.56', 'logps_train/chosen': '-136.01', 'loss/train': '0.6582', 'examples_per_second': '5.0048', 'grad_norm': '17', 'counters/examples': 52480, 'counters/updates': 3280}
skipping logging after 52496 examples to avoid logging too frequently
skipping logging after 52512 examples to avoid logging too frequently
skipping logging after 52528 examples to avoid logging too frequently
train stats after 52544 examples: {'rewards_train/chosen': '-0.3001', 'rewards_train/rejected': '-0.40888', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.10867', 'logps_train/rejected': '-129.62', 'logps_train/chosen': '-111.76', 'loss/train': '0.65918', 'examples_per_second': '4.6553', 'grad_norm': '15.562', 'counters/examples': 52544, 'counters/updates': 3284}
skipping logging after 52560 examples to avoid logging too frequently
skipping logging after 52576 examples to avoid logging too frequently
Running evaluation after 52576 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:07,  2.19s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:03,  2.10s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.88s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.87s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 52576: {'rewards_eval/chosen': '-0.35395', 'rewards_eval/rejected': '-0.43507', 'rewards_eval/accuracies': '0.53125', 'rewards_eval/margins': '0.081163', 'logps_eval/rejected': '-126.51', 'logps_eval/chosen': '-122.03', 'loss/eval': '0.67514'}
skipping logging after 52592 examples to avoid logging too frequently
train stats after 52608 examples: {'rewards_train/chosen': '-0.36033', 'rewards_train/rejected': '-0.47918', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.11895', 'logps_train/rejected': '-102.94', 'logps_train/chosen': '-129.5', 'loss/train': '0.65672', 'examples_per_second': '5.9971', 'grad_norm': '17.125', 'counters/examples': 52608, 'counters/updates': 3288}
skipping logging after 52624 examples to avoid logging too frequently
skipping logging after 52640 examples to avoid logging too frequently
skipping logging after 52656 examples to avoid logging too frequently
train stats after 52672 examples: {'rewards_train/chosen': '-0.33498', 'rewards_train/rejected': '-0.51633', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.18135', 'logps_train/rejected': '-152.47', 'logps_train/chosen': '-120.5', 'loss/train': '0.62628', 'examples_per_second': '5.1062', 'grad_norm': '18.125', 'counters/examples': 52672, 'counters/updates': 3292}
skipping logging after 52688 examples to avoid logging too frequently
skipping logging after 52704 examples to avoid logging too frequently
skipping logging after 52720 examples to avoid logging too frequently
train stats after 52736 examples: {'rewards_train/chosen': '-0.40832', 'rewards_train/rejected': '-0.41644', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.0080795', 'logps_train/rejected': '-130.63', 'logps_train/chosen': '-145.68', 'loss/train': '0.71606', 'examples_per_second': '4.8923', 'grad_norm': '19.625', 'counters/examples': 52736, 'counters/updates': 3296}
skipping logging after 52752 examples to avoid logging too frequently
skipping logging after 52768 examples to avoid logging too frequently
skipping logging after 52784 examples to avoid logging too frequently
train stats after 52800 examples: {'rewards_train/chosen': '-0.42504', 'rewards_train/rejected': '-0.4484', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.023367', 'logps_train/rejected': '-87.019', 'logps_train/chosen': '-93.857', 'loss/train': '0.69357', 'examples_per_second': '5.0487', 'grad_norm': '14.375', 'counters/examples': 52800, 'counters/updates': 3300}
skipping logging after 52816 examples to avoid logging too frequently
skipping logging after 52832 examples to avoid logging too frequently
skipping logging after 52848 examples to avoid logging too frequently
train stats after 52864 examples: {'rewards_train/chosen': '-0.38935', 'rewards_train/rejected': '-0.51357', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.12428', 'logps_train/rejected': '-115.9', 'logps_train/chosen': '-123.84', 'loss/train': '0.65765', 'examples_per_second': '4.5574', 'grad_norm': '17.625', 'counters/examples': 52864, 'counters/updates': 3304}
skipping logging after 52880 examples to avoid logging too frequently
skipping logging after 52896 examples to avoid logging too frequently
skipping logging after 52912 examples to avoid logging too frequently
train stats after 52928 examples: {'rewards_train/chosen': '-0.32499', 'rewards_train/rejected': '-0.41761', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.092613', 'logps_train/rejected': '-128.49', 'logps_train/chosen': '-124.98', 'loss/train': '0.67023', 'examples_per_second': '4.2014', 'grad_norm': '16.5', 'counters/examples': 52928, 'counters/updates': 3308}
skipping logging after 52944 examples to avoid logging too frequently
skipping logging after 52960 examples to avoid logging too frequently
skipping logging after 52976 examples to avoid logging too frequently
train stats after 52992 examples: {'rewards_train/chosen': '-0.34467', 'rewards_train/rejected': '-0.4455', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.10091', 'logps_train/rejected': '-120.42', 'logps_train/chosen': '-121.2', 'loss/train': '0.65726', 'examples_per_second': '5.0675', 'grad_norm': '16.625', 'counters/examples': 52992, 'counters/updates': 3312}
skipping logging after 53008 examples to avoid logging too frequently
skipping logging after 53024 examples to avoid logging too frequently
skipping logging after 53040 examples to avoid logging too frequently
train stats after 53056 examples: {'rewards_train/chosen': '-0.41812', 'rewards_train/rejected': '-0.57663', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.15857', 'logps_train/rejected': '-128.89', 'logps_train/chosen': '-127.77', 'loss/train': '0.6301', 'examples_per_second': '5.5508', 'grad_norm': '17.125', 'counters/examples': 53056, 'counters/updates': 3316}
skipping logging after 53072 examples to avoid logging too frequently
skipping logging after 53088 examples to avoid logging too frequently
skipping logging after 53104 examples to avoid logging too frequently
train stats after 53120 examples: {'rewards_train/chosen': '-0.3611', 'rewards_train/rejected': '-0.48603', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.12509', 'logps_train/rejected': '-131.69', 'logps_train/chosen': '-112.85', 'loss/train': '0.6507', 'examples_per_second': '5.9256', 'grad_norm': '17.625', 'counters/examples': 53120, 'counters/updates': 3320}
skipping logging after 53136 examples to avoid logging too frequently
skipping logging after 53152 examples to avoid logging too frequently
skipping logging after 53168 examples to avoid logging too frequently
train stats after 53184 examples: {'rewards_train/chosen': '-0.21499', 'rewards_train/rejected': '-0.37175', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.15681', 'logps_train/rejected': '-130.67', 'logps_train/chosen': '-114.97', 'loss/train': '0.64082', 'examples_per_second': '4.3916', 'grad_norm': '16.25', 'counters/examples': 53184, 'counters/updates': 3324}
skipping logging after 53200 examples to avoid logging too frequently
skipping logging after 53216 examples to avoid logging too frequently
skipping logging after 53232 examples to avoid logging too frequently
train stats after 53248 examples: {'rewards_train/chosen': '-0.33099', 'rewards_train/rejected': '-0.4737', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.14273', 'logps_train/rejected': '-98.673', 'logps_train/chosen': '-112.1', 'loss/train': '0.6501', 'examples_per_second': '5.4773', 'grad_norm': '15.75', 'counters/examples': 53248, 'counters/updates': 3328}
skipping logging after 53264 examples to avoid logging too frequently
skipping logging after 53280 examples to avoid logging too frequently
skipping logging after 53296 examples to avoid logging too frequently
train stats after 53312 examples: {'rewards_train/chosen': '-0.3601', 'rewards_train/rejected': '-0.42286', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.06271', 'logps_train/rejected': '-120.42', 'logps_train/chosen': '-114.48', 'loss/train': '0.68719', 'examples_per_second': '4.9252', 'grad_norm': '18.625', 'counters/examples': 53312, 'counters/updates': 3332}
skipping logging after 53328 examples to avoid logging too frequently
skipping logging after 53344 examples to avoid logging too frequently
skipping logging after 53360 examples to avoid logging too frequently
train stats after 53376 examples: {'rewards_train/chosen': '-0.28017', 'rewards_train/rejected': '-0.48445', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.20435', 'logps_train/rejected': '-134.87', 'logps_train/chosen': '-123.66', 'loss/train': '0.61151', 'examples_per_second': '5.0734', 'grad_norm': '18.375', 'counters/examples': 53376, 'counters/updates': 3336}
skipping logging after 53392 examples to avoid logging too frequently
skipping logging after 53408 examples to avoid logging too frequently
skipping logging after 53424 examples to avoid logging too frequently
train stats after 53440 examples: {'rewards_train/chosen': '-0.34288', 'rewards_train/rejected': '-0.37953', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.036652', 'logps_train/rejected': '-106.78', 'logps_train/chosen': '-119.86', 'loss/train': '0.68707', 'examples_per_second': '5.8033', 'grad_norm': '18.125', 'counters/examples': 53440, 'counters/updates': 3340}
skipping logging after 53456 examples to avoid logging too frequently
skipping logging after 53472 examples to avoid logging too frequently
skipping logging after 53488 examples to avoid logging too frequently
train stats after 53504 examples: {'rewards_train/chosen': '-0.41397', 'rewards_train/rejected': '-0.60106', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.18709', 'logps_train/rejected': '-138.65', 'logps_train/chosen': '-147.03', 'loss/train': '0.62332', 'examples_per_second': '4.9868', 'grad_norm': '19.375', 'counters/examples': 53504, 'counters/updates': 3344}
skipping logging after 53520 examples to avoid logging too frequently
skipping logging after 53536 examples to avoid logging too frequently
skipping logging after 53552 examples to avoid logging too frequently
train stats after 53568 examples: {'rewards_train/chosen': '-0.42064', 'rewards_train/rejected': '-0.48517', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.064457', 'logps_train/rejected': '-129.79', 'logps_train/chosen': '-147.63', 'loss/train': '0.68823', 'examples_per_second': '5.6338', 'grad_norm': '19.375', 'counters/examples': 53568, 'counters/updates': 3348}
Running evaluation after 53568 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.83s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 53568: {'rewards_eval/chosen': '-0.43346', 'rewards_eval/rejected': '-0.52076', 'rewards_eval/accuracies': '0.52734', 'rewards_eval/margins': '0.087285', 'logps_eval/rejected': '-127.36', 'logps_eval/chosen': '-122.83', 'loss/eval': '0.67472'}
skipping logging after 53584 examples to avoid logging too frequently
skipping logging after 53600 examples to avoid logging too frequently
skipping logging after 53616 examples to avoid logging too frequently
train stats after 53632 examples: {'rewards_train/chosen': '-0.5051', 'rewards_train/rejected': '-0.68431', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.17915', 'logps_train/rejected': '-129.59', 'logps_train/chosen': '-117.34', 'loss/train': '0.62572', 'examples_per_second': '6.3354', 'grad_norm': '19.25', 'counters/examples': 53632, 'counters/updates': 3352}
skipping logging after 53648 examples to avoid logging too frequently
skipping logging after 53664 examples to avoid logging too frequently
skipping logging after 53680 examples to avoid logging too frequently
train stats after 53696 examples: {'rewards_train/chosen': '-0.33294', 'rewards_train/rejected': '-0.45882', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.12599', 'logps_train/rejected': '-112.67', 'logps_train/chosen': '-121.18', 'loss/train': '0.65475', 'examples_per_second': '4.299', 'grad_norm': '19', 'counters/examples': 53696, 'counters/updates': 3356}
skipping logging after 53712 examples to avoid logging too frequently
skipping logging after 53728 examples to avoid logging too frequently
skipping logging after 53744 examples to avoid logging too frequently
train stats after 53760 examples: {'rewards_train/chosen': '-0.44895', 'rewards_train/rejected': '-0.54284', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.093937', 'logps_train/rejected': '-115.34', 'logps_train/chosen': '-119.1', 'loss/train': '0.67479', 'examples_per_second': '6.2502', 'grad_norm': '19.25', 'counters/examples': 53760, 'counters/updates': 3360}
skipping logging after 53776 examples to avoid logging too frequently
skipping logging after 53792 examples to avoid logging too frequently
skipping logging after 53808 examples to avoid logging too frequently
train stats after 53824 examples: {'rewards_train/chosen': '-0.49906', 'rewards_train/rejected': '-0.55629', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.057272', 'logps_train/rejected': '-139.44', 'logps_train/chosen': '-104.57', 'loss/train': '0.69626', 'examples_per_second': '4.5373', 'grad_norm': '18.875', 'counters/examples': 53824, 'counters/updates': 3364}
skipping logging after 53840 examples to avoid logging too frequently
skipping logging after 53856 examples to avoid logging too frequently
skipping logging after 53872 examples to avoid logging too frequently
train stats after 53888 examples: {'rewards_train/chosen': '-0.45467', 'rewards_train/rejected': '-0.53582', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.081174', 'logps_train/rejected': '-132.12', 'logps_train/chosen': '-135.96', 'loss/train': '0.67401', 'examples_per_second': '5.1835', 'grad_norm': '17.25', 'counters/examples': 53888, 'counters/updates': 3368}
skipping logging after 53904 examples to avoid logging too frequently
skipping logging after 53920 examples to avoid logging too frequently
skipping logging after 53936 examples to avoid logging too frequently
train stats after 53952 examples: {'rewards_train/chosen': '-0.44372', 'rewards_train/rejected': '-0.5382', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.094444', 'logps_train/rejected': '-114.12', 'logps_train/chosen': '-104.87', 'loss/train': '0.66632', 'examples_per_second': '5.7527', 'grad_norm': '16.5', 'counters/examples': 53952, 'counters/updates': 3372}
skipping logging after 53968 examples to avoid logging too frequently
skipping logging after 53984 examples to avoid logging too frequently
skipping logging after 54000 examples to avoid logging too frequently
train stats after 54016 examples: {'rewards_train/chosen': '-0.35633', 'rewards_train/rejected': '-0.52876', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.17247', 'logps_train/rejected': '-121.34', 'logps_train/chosen': '-118.13', 'loss/train': '0.63978', 'examples_per_second': '4.6847', 'grad_norm': '16.375', 'counters/examples': 54016, 'counters/updates': 3376}
skipping logging after 54032 examples to avoid logging too frequently
skipping logging after 54048 examples to avoid logging too frequently
skipping logging after 54064 examples to avoid logging too frequently
train stats after 54080 examples: {'rewards_train/chosen': '-0.43251', 'rewards_train/rejected': '-0.51336', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.080738', 'logps_train/rejected': '-115.76', 'logps_train/chosen': '-114.96', 'loss/train': '0.66879', 'examples_per_second': '4.8551', 'grad_norm': '19.5', 'counters/examples': 54080, 'counters/updates': 3380}
skipping logging after 54096 examples to avoid logging too frequently
skipping logging after 54112 examples to avoid logging too frequently
skipping logging after 54128 examples to avoid logging too frequently
train stats after 54144 examples: {'rewards_train/chosen': '-0.47502', 'rewards_train/rejected': '-0.51226', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.037123', 'logps_train/rejected': '-95.136', 'logps_train/chosen': '-104.22', 'loss/train': '0.69209', 'examples_per_second': '5.4661', 'grad_norm': '17.875', 'counters/examples': 54144, 'counters/updates': 3384}
skipping logging after 54160 examples to avoid logging too frequently
skipping logging after 54176 examples to avoid logging too frequently
skipping logging after 54192 examples to avoid logging too frequently
train stats after 54208 examples: {'rewards_train/chosen': '-0.43631', 'rewards_train/rejected': '-0.51423', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.077721', 'logps_train/rejected': '-123.15', 'logps_train/chosen': '-136.54', 'loss/train': '0.68219', 'examples_per_second': '4.8123', 'grad_norm': '18.625', 'counters/examples': 54208, 'counters/updates': 3388}
skipping logging after 54224 examples to avoid logging too frequently
skipping logging after 54240 examples to avoid logging too frequently
skipping logging after 54256 examples to avoid logging too frequently
train stats after 54272 examples: {'rewards_train/chosen': '-0.38702', 'rewards_train/rejected': '-0.4925', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.10555', 'logps_train/rejected': '-123.02', 'logps_train/chosen': '-139.68', 'loss/train': '0.66762', 'examples_per_second': '5.2243', 'grad_norm': '21.625', 'counters/examples': 54272, 'counters/updates': 3392}
skipping logging after 54288 examples to avoid logging too frequently
skipping logging after 54304 examples to avoid logging too frequently
skipping logging after 54320 examples to avoid logging too frequently
train stats after 54336 examples: {'rewards_train/chosen': '-0.47558', 'rewards_train/rejected': '-0.64871', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.17315', 'logps_train/rejected': '-162.82', 'logps_train/chosen': '-131.77', 'loss/train': '0.62769', 'examples_per_second': '4.6242', 'grad_norm': '19', 'counters/examples': 54336, 'counters/updates': 3396}
skipping logging after 54352 examples to avoid logging too frequently
skipping logging after 54368 examples to avoid logging too frequently
skipping logging after 54384 examples to avoid logging too frequently
train stats after 54400 examples: {'rewards_train/chosen': '-0.42093', 'rewards_train/rejected': '-0.48836', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.067469', 'logps_train/rejected': '-121.3', 'logps_train/chosen': '-123.64', 'loss/train': '0.67749', 'examples_per_second': '5.3127', 'grad_norm': '17.625', 'counters/examples': 54400, 'counters/updates': 3400}
skipping logging after 54416 examples to avoid logging too frequently
skipping logging after 54432 examples to avoid logging too frequently
skipping logging after 54448 examples to avoid logging too frequently
train stats after 54464 examples: {'rewards_train/chosen': '-0.43941', 'rewards_train/rejected': '-0.47847', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.039097', 'logps_train/rejected': '-153.09', 'logps_train/chosen': '-138.87', 'loss/train': '0.69476', 'examples_per_second': '4.8024', 'grad_norm': '18.75', 'counters/examples': 54464, 'counters/updates': 3404}
skipping logging after 54480 examples to avoid logging too frequently
skipping logging after 54496 examples to avoid logging too frequently
skipping logging after 54512 examples to avoid logging too frequently
train stats after 54528 examples: {'rewards_train/chosen': '-0.5793', 'rewards_train/rejected': '-0.6248', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.045349', 'logps_train/rejected': '-121.36', 'logps_train/chosen': '-106.77', 'loss/train': '0.70001', 'examples_per_second': '5.8516', 'grad_norm': '21.875', 'counters/examples': 54528, 'counters/updates': 3408}
skipping logging after 54544 examples to avoid logging too frequently
skipping logging after 54560 examples to avoid logging too frequently
Running evaluation after 54560 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:17,  2.50s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:07,  2.23s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:56,  1.95s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:08<00:53,  1.92s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:42,  1.56s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.66s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.48s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.55s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.44s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 54560: {'rewards_eval/chosen': '-0.40248', 'rewards_eval/rejected': '-0.49251', 'rewards_eval/accuracies': '0.53516', 'rewards_eval/margins': '0.090025', 'logps_eval/rejected': '-127.08', 'logps_eval/chosen': '-122.52', 'loss/eval': '0.67193'}
skipping logging after 54576 examples to avoid logging too frequently
train stats after 54592 examples: {'rewards_train/chosen': '-0.38615', 'rewards_train/rejected': '-0.53492', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.14877', 'logps_train/rejected': '-144.6', 'logps_train/chosen': '-123.35', 'loss/train': '0.64366', 'examples_per_second': '5.3489', 'grad_norm': '16.875', 'counters/examples': 54592, 'counters/updates': 3412}
skipping logging after 54608 examples to avoid logging too frequently
skipping logging after 54624 examples to avoid logging too frequently
skipping logging after 54640 examples to avoid logging too frequently
train stats after 54656 examples: {'rewards_train/chosen': '-0.32395', 'rewards_train/rejected': '-0.3824', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.058601', 'logps_train/rejected': '-108.72', 'logps_train/chosen': '-113.97', 'loss/train': '0.68153', 'examples_per_second': '4.8422', 'grad_norm': '16.375', 'counters/examples': 54656, 'counters/updates': 3416}
skipping logging after 54672 examples to avoid logging too frequently
skipping logging after 54688 examples to avoid logging too frequently
skipping logging after 54704 examples to avoid logging too frequently
train stats after 54720 examples: {'rewards_train/chosen': '-0.36341', 'rewards_train/rejected': '-0.44977', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.086359', 'logps_train/rejected': '-114.08', 'logps_train/chosen': '-132.04', 'loss/train': '0.66376', 'examples_per_second': '5.3929', 'grad_norm': '19.375', 'counters/examples': 54720, 'counters/updates': 3420}
skipping logging after 54736 examples to avoid logging too frequently
skipping logging after 54752 examples to avoid logging too frequently
skipping logging after 54768 examples to avoid logging too frequently
train stats after 54784 examples: {'rewards_train/chosen': '-0.43471', 'rewards_train/rejected': '-0.54746', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.1128', 'logps_train/rejected': '-127.8', 'logps_train/chosen': '-115.09', 'loss/train': '0.65994', 'examples_per_second': '4.2658', 'grad_norm': '16.375', 'counters/examples': 54784, 'counters/updates': 3424}
skipping logging after 54800 examples to avoid logging too frequently
skipping logging after 54816 examples to avoid logging too frequently
skipping logging after 54832 examples to avoid logging too frequently
train stats after 54848 examples: {'rewards_train/chosen': '-0.32718', 'rewards_train/rejected': '-0.49127', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.16419', 'logps_train/rejected': '-140.09', 'logps_train/chosen': '-133.84', 'loss/train': '0.63571', 'examples_per_second': '3.8451', 'grad_norm': '19.625', 'counters/examples': 54848, 'counters/updates': 3428}
skipping logging after 54864 examples to avoid logging too frequently
skipping logging after 54880 examples to avoid logging too frequently
skipping logging after 54896 examples to avoid logging too frequently
train stats after 54912 examples: {'rewards_train/chosen': '-0.27947', 'rewards_train/rejected': '-0.45973', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.18025', 'logps_train/rejected': '-104.42', 'logps_train/chosen': '-102.36', 'loss/train': '0.62767', 'examples_per_second': '5.7063', 'grad_norm': '14.375', 'counters/examples': 54912, 'counters/updates': 3432}
skipping logging after 54928 examples to avoid logging too frequently
skipping logging after 54944 examples to avoid logging too frequently
skipping logging after 54960 examples to avoid logging too frequently
train stats after 54976 examples: {'rewards_train/chosen': '-0.28738', 'rewards_train/rejected': '-0.46112', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.1738', 'logps_train/rejected': '-114.28', 'logps_train/chosen': '-101.21', 'loss/train': '0.63074', 'examples_per_second': '6.166', 'grad_norm': '15.812', 'counters/examples': 54976, 'counters/updates': 3436}
skipping logging after 54992 examples to avoid logging too frequently
skipping logging after 55008 examples to avoid logging too frequently
skipping logging after 55024 examples to avoid logging too frequently
train stats after 55040 examples: {'rewards_train/chosen': '-0.34899', 'rewards_train/rejected': '-0.40368', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.054794', 'logps_train/rejected': '-136.45', 'logps_train/chosen': '-159.03', 'loss/train': '0.68701', 'examples_per_second': '4.5367', 'grad_norm': '17.75', 'counters/examples': 55040, 'counters/updates': 3440}
skipping logging after 55056 examples to avoid logging too frequently
skipping logging after 55072 examples to avoid logging too frequently
skipping logging after 55088 examples to avoid logging too frequently
train stats after 55104 examples: {'rewards_train/chosen': '-0.41268', 'rewards_train/rejected': '-0.49785', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.085093', 'logps_train/rejected': '-137.38', 'logps_train/chosen': '-106.32', 'loss/train': '0.67007', 'examples_per_second': '5.379', 'grad_norm': '17', 'counters/examples': 55104, 'counters/updates': 3444}
skipping logging after 55120 examples to avoid logging too frequently
skipping logging after 55136 examples to avoid logging too frequently
skipping logging after 55152 examples to avoid logging too frequently
train stats after 55168 examples: {'rewards_train/chosen': '-0.37796', 'rewards_train/rejected': '-0.54395', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.16605', 'logps_train/rejected': '-102.23', 'logps_train/chosen': '-115.11', 'loss/train': '0.64297', 'examples_per_second': '5.202', 'grad_norm': '17.125', 'counters/examples': 55168, 'counters/updates': 3448}
skipping logging after 55184 examples to avoid logging too frequently
skipping logging after 55200 examples to avoid logging too frequently
skipping logging after 55216 examples to avoid logging too frequently
train stats after 55232 examples: {'rewards_train/chosen': '-0.46983', 'rewards_train/rejected': '-0.56406', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.094266', 'logps_train/rejected': '-127', 'logps_train/chosen': '-126.75', 'loss/train': '0.67354', 'examples_per_second': '5.0349', 'grad_norm': '19.125', 'counters/examples': 55232, 'counters/updates': 3452}
skipping logging after 55248 examples to avoid logging too frequently
skipping logging after 55264 examples to avoid logging too frequently
skipping logging after 55280 examples to avoid logging too frequently
train stats after 55296 examples: {'rewards_train/chosen': '-0.34771', 'rewards_train/rejected': '-0.52974', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.18213', 'logps_train/rejected': '-136.09', 'logps_train/chosen': '-143.61', 'loss/train': '0.62274', 'examples_per_second': '4.7488', 'grad_norm': '17.375', 'counters/examples': 55296, 'counters/updates': 3456}
skipping logging after 55312 examples to avoid logging too frequently
skipping logging after 55328 examples to avoid logging too frequently
skipping logging after 55344 examples to avoid logging too frequently
train stats after 55360 examples: {'rewards_train/chosen': '-0.49019', 'rewards_train/rejected': '-0.63387', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.14371', 'logps_train/rejected': '-147.75', 'logps_train/chosen': '-114.09', 'loss/train': '0.64734', 'examples_per_second': '5.3175', 'grad_norm': '16.5', 'counters/examples': 55360, 'counters/updates': 3460}
skipping logging after 55376 examples to avoid logging too frequently
skipping logging after 55392 examples to avoid logging too frequently
skipping logging after 55408 examples to avoid logging too frequently
train stats after 55424 examples: {'rewards_train/chosen': '-0.51202', 'rewards_train/rejected': '-0.56589', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.053844', 'logps_train/rejected': '-93.585', 'logps_train/chosen': '-91.883', 'loss/train': '0.68449', 'examples_per_second': '6.0191', 'grad_norm': '18.75', 'counters/examples': 55424, 'counters/updates': 3464}
skipping logging after 55440 examples to avoid logging too frequently
skipping logging after 55456 examples to avoid logging too frequently
skipping logging after 55472 examples to avoid logging too frequently
train stats after 55488 examples: {'rewards_train/chosen': '-0.38153', 'rewards_train/rejected': '-0.43408', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.052635', 'logps_train/rejected': '-147.32', 'logps_train/chosen': '-138.17', 'loss/train': '0.67996', 'examples_per_second': '5.0607', 'grad_norm': '17.875', 'counters/examples': 55488, 'counters/updates': 3468}
skipping logging after 55504 examples to avoid logging too frequently
skipping logging after 55520 examples to avoid logging too frequently
skipping logging after 55536 examples to avoid logging too frequently
train stats after 55552 examples: {'rewards_train/chosen': '-0.36062', 'rewards_train/rejected': '-0.46872', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.10801', 'logps_train/rejected': '-109.88', 'logps_train/chosen': '-102.72', 'loss/train': '0.65976', 'examples_per_second': '5.7055', 'grad_norm': '15.375', 'counters/examples': 55552, 'counters/updates': 3472}
Running evaluation after 55552 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<01:00,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:53,  1.83s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.63s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.23s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 55552: {'rewards_eval/chosen': '-0.39555', 'rewards_eval/rejected': '-0.49191', 'rewards_eval/accuracies': '0.53906', 'rewards_eval/margins': '0.096388', 'logps_eval/rejected': '-127.07', 'logps_eval/chosen': '-122.45', 'loss/eval': '0.67028'}
skipping logging after 55568 examples to avoid logging too frequently
skipping logging after 55584 examples to avoid logging too frequently
skipping logging after 55600 examples to avoid logging too frequently
train stats after 55616 examples: {'rewards_train/chosen': '-0.34703', 'rewards_train/rejected': '-0.5275', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.1805', 'logps_train/rejected': '-104.38', 'logps_train/chosen': '-110.49', 'loss/train': '0.64319', 'examples_per_second': '4.7843', 'grad_norm': '17.5', 'counters/examples': 55616, 'counters/updates': 3476}
skipping logging after 55632 examples to avoid logging too frequently
skipping logging after 55648 examples to avoid logging too frequently
skipping logging after 55664 examples to avoid logging too frequently
train stats after 55680 examples: {'rewards_train/chosen': '-0.40573', 'rewards_train/rejected': '-0.53026', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.12463', 'logps_train/rejected': '-91.876', 'logps_train/chosen': '-113.58', 'loss/train': '0.65201', 'examples_per_second': '5.1574', 'grad_norm': '17', 'counters/examples': 55680, 'counters/updates': 3480}
skipping logging after 55696 examples to avoid logging too frequently
skipping logging after 55712 examples to avoid logging too frequently
skipping logging after 55728 examples to avoid logging too frequently
train stats after 55744 examples: {'rewards_train/chosen': '-0.35966', 'rewards_train/rejected': '-0.46268', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.10297', 'logps_train/rejected': '-132.4', 'logps_train/chosen': '-115.53', 'loss/train': '0.66277', 'examples_per_second': '5.462', 'grad_norm': '18.5', 'counters/examples': 55744, 'counters/updates': 3484}
skipping logging after 55760 examples to avoid logging too frequently
skipping logging after 55776 examples to avoid logging too frequently
skipping logging after 55792 examples to avoid logging too frequently
train stats after 55808 examples: {'rewards_train/chosen': '-0.38314', 'rewards_train/rejected': '-0.42965', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.046501', 'logps_train/rejected': '-121.07', 'logps_train/chosen': '-109.74', 'loss/train': '0.69722', 'examples_per_second': '5.2049', 'grad_norm': '16.25', 'counters/examples': 55808, 'counters/updates': 3488}
skipping logging after 55824 examples to avoid logging too frequently
skipping logging after 55840 examples to avoid logging too frequently
skipping logging after 55856 examples to avoid logging too frequently
train stats after 55872 examples: {'rewards_train/chosen': '-0.48212', 'rewards_train/rejected': '-0.60867', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.12658', 'logps_train/rejected': '-134.77', 'logps_train/chosen': '-153.98', 'loss/train': '0.66083', 'examples_per_second': '5.1215', 'grad_norm': '18.625', 'counters/examples': 55872, 'counters/updates': 3492}
skipping logging after 55888 examples to avoid logging too frequently
skipping logging after 55904 examples to avoid logging too frequently
skipping logging after 55920 examples to avoid logging too frequently
train stats after 55936 examples: {'rewards_train/chosen': '-0.45869', 'rewards_train/rejected': '-0.56849', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.10971', 'logps_train/rejected': '-115', 'logps_train/chosen': '-123.53', 'loss/train': '0.66705', 'examples_per_second': '5.3724', 'grad_norm': '19.5', 'counters/examples': 55936, 'counters/updates': 3496}
skipping logging after 55952 examples to avoid logging too frequently
skipping logging after 55968 examples to avoid logging too frequently
skipping logging after 55984 examples to avoid logging too frequently
train stats after 56000 examples: {'rewards_train/chosen': '-0.48079', 'rewards_train/rejected': '-0.57034', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.089592', 'logps_train/rejected': '-129.36', 'logps_train/chosen': '-117.31', 'loss/train': '0.67921', 'examples_per_second': '5.1387', 'grad_norm': '16.625', 'counters/examples': 56000, 'counters/updates': 3500}
skipping logging after 56016 examples to avoid logging too frequently
skipping logging after 56032 examples to avoid logging too frequently
skipping logging after 56048 examples to avoid logging too frequently
train stats after 56064 examples: {'rewards_train/chosen': '-0.4016', 'rewards_train/rejected': '-0.49836', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.096798', 'logps_train/rejected': '-115.36', 'logps_train/chosen': '-106.23', 'loss/train': '0.67052', 'examples_per_second': '5.0645', 'grad_norm': '19.625', 'counters/examples': 56064, 'counters/updates': 3504}
skipping logging after 56080 examples to avoid logging too frequently
skipping logging after 56096 examples to avoid logging too frequently
skipping logging after 56112 examples to avoid logging too frequently
train stats after 56128 examples: {'rewards_train/chosen': '-0.34472', 'rewards_train/rejected': '-0.49672', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.15198', 'logps_train/rejected': '-157.04', 'logps_train/chosen': '-131.28', 'loss/train': '0.63815', 'examples_per_second': '5.2957', 'grad_norm': '15.375', 'counters/examples': 56128, 'counters/updates': 3508}
skipping logging after 56144 examples to avoid logging too frequently
skipping logging after 56160 examples to avoid logging too frequently
skipping logging after 56176 examples to avoid logging too frequently
train stats after 56192 examples: {'rewards_train/chosen': '-0.41586', 'rewards_train/rejected': '-0.51415', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.098293', 'logps_train/rejected': '-107.82', 'logps_train/chosen': '-105.82', 'loss/train': '0.66612', 'examples_per_second': '5.5091', 'grad_norm': '15', 'counters/examples': 56192, 'counters/updates': 3512}
skipping logging after 56208 examples to avoid logging too frequently
skipping logging after 56224 examples to avoid logging too frequently
skipping logging after 56240 examples to avoid logging too frequently
train stats after 56256 examples: {'rewards_train/chosen': '-0.46966', 'rewards_train/rejected': '-0.54781', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.07821', 'logps_train/rejected': '-114.51', 'logps_train/chosen': '-108.4', 'loss/train': '0.67664', 'examples_per_second': '5.3207', 'grad_norm': '16.75', 'counters/examples': 56256, 'counters/updates': 3516}
skipping logging after 56272 examples to avoid logging too frequently
skipping logging after 56288 examples to avoid logging too frequently
skipping logging after 56304 examples to avoid logging too frequently
train stats after 56320 examples: {'rewards_train/chosen': '-0.32044', 'rewards_train/rejected': '-0.44535', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.12494', 'logps_train/rejected': '-141.56', 'logps_train/chosen': '-128.51', 'loss/train': '0.65109', 'examples_per_second': '5.3362', 'grad_norm': '15.625', 'counters/examples': 56320, 'counters/updates': 3520}
skipping logging after 56336 examples to avoid logging too frequently
skipping logging after 56352 examples to avoid logging too frequently
skipping logging after 56368 examples to avoid logging too frequently
train stats after 56384 examples: {'rewards_train/chosen': '-0.42359', 'rewards_train/rejected': '-0.4995', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.07589', 'logps_train/rejected': '-118.59', 'logps_train/chosen': '-115', 'loss/train': '0.67905', 'examples_per_second': '4.8762', 'grad_norm': '18.75', 'counters/examples': 56384, 'counters/updates': 3524}
skipping logging after 56400 examples to avoid logging too frequently
skipping logging after 56416 examples to avoid logging too frequently
skipping logging after 56432 examples to avoid logging too frequently
train stats after 56448 examples: {'rewards_train/chosen': '-0.45854', 'rewards_train/rejected': '-0.43136', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '-0.027142', 'logps_train/rejected': '-106.7', 'logps_train/chosen': '-94.014', 'loss/train': '0.73119', 'examples_per_second': '4.8608', 'grad_norm': '20.125', 'counters/examples': 56448, 'counters/updates': 3528}
skipping logging after 56464 examples to avoid logging too frequently
skipping logging after 56480 examples to avoid logging too frequently
skipping logging after 56496 examples to avoid logging too frequently
train stats after 56512 examples: {'rewards_train/chosen': '-0.39892', 'rewards_train/rejected': '-0.45187', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.053011', 'logps_train/rejected': '-105.54', 'logps_train/chosen': '-114.2', 'loss/train': '0.68665', 'examples_per_second': '5.294', 'grad_norm': '15.688', 'counters/examples': 56512, 'counters/updates': 3532}
skipping logging after 56528 examples to avoid logging too frequently
skipping logging after 56544 examples to avoid logging too frequently
Running evaluation after 56544 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:10,  2.27s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:04,  2.14s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:55,  1.90s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.88s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.54s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 56544: {'rewards_eval/chosen': '-0.37127', 'rewards_eval/rejected': '-0.46332', 'rewards_eval/accuracies': '0.53516', 'rewards_eval/margins': '0.092035', 'logps_eval/rejected': '-126.79', 'logps_eval/chosen': '-122.21', 'loss/eval': '0.67146'}
skipping logging after 56560 examples to avoid logging too frequently
train stats after 56576 examples: {'rewards_train/chosen': '-0.32417', 'rewards_train/rejected': '-0.37502', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.05088', 'logps_train/rejected': '-122', 'logps_train/chosen': '-118.11', 'loss/train': '0.68396', 'examples_per_second': '5.5814', 'grad_norm': '17.5', 'counters/examples': 56576, 'counters/updates': 3536}
skipping logging after 56592 examples to avoid logging too frequently
skipping logging after 56608 examples to avoid logging too frequently
skipping logging after 56624 examples to avoid logging too frequently
train stats after 56640 examples: {'rewards_train/chosen': '-0.26883', 'rewards_train/rejected': '-0.41853', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.14969', 'logps_train/rejected': '-111.24', 'logps_train/chosen': '-113.14', 'loss/train': '0.64398', 'examples_per_second': '4.425', 'grad_norm': '16.75', 'counters/examples': 56640, 'counters/updates': 3540}
skipping logging after 56656 examples to avoid logging too frequently
skipping logging after 56672 examples to avoid logging too frequently
skipping logging after 56688 examples to avoid logging too frequently
train stats after 56704 examples: {'rewards_train/chosen': '-0.47125', 'rewards_train/rejected': '-0.50842', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.03717', 'logps_train/rejected': '-132.98', 'logps_train/chosen': '-140.33', 'loss/train': '0.70357', 'examples_per_second': '4.7912', 'grad_norm': '20.625', 'counters/examples': 56704, 'counters/updates': 3544}
skipping logging after 56720 examples to avoid logging too frequently
skipping logging after 56736 examples to avoid logging too frequently
skipping logging after 56752 examples to avoid logging too frequently
train stats after 56768 examples: {'rewards_train/chosen': '-0.39398', 'rewards_train/rejected': '-0.45533', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.061371', 'logps_train/rejected': '-102.3', 'logps_train/chosen': '-106.8', 'loss/train': '0.67676', 'examples_per_second': '5.6388', 'grad_norm': '16.875', 'counters/examples': 56768, 'counters/updates': 3548}
skipping logging after 56784 examples to avoid logging too frequently
skipping logging after 56800 examples to avoid logging too frequently
skipping logging after 56816 examples to avoid logging too frequently
train stats after 56832 examples: {'rewards_train/chosen': '-0.29133', 'rewards_train/rejected': '-0.36959', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.078274', 'logps_train/rejected': '-121.22', 'logps_train/chosen': '-84.762', 'loss/train': '0.66772', 'examples_per_second': '6.2196', 'grad_norm': '18.125', 'counters/examples': 56832, 'counters/updates': 3552}
skipping logging after 56848 examples to avoid logging too frequently
skipping logging after 56864 examples to avoid logging too frequently
skipping logging after 56880 examples to avoid logging too frequently
train stats after 56896 examples: {'rewards_train/chosen': '-0.32477', 'rewards_train/rejected': '-0.43657', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.11183', 'logps_train/rejected': '-108.6', 'logps_train/chosen': '-101.51', 'loss/train': '0.65259', 'examples_per_second': '5.1442', 'grad_norm': '18.375', 'counters/examples': 56896, 'counters/updates': 3556}
skipping logging after 56912 examples to avoid logging too frequently
skipping logging after 56928 examples to avoid logging too frequently
skipping logging after 56944 examples to avoid logging too frequently
train stats after 56960 examples: {'rewards_train/chosen': '-0.38356', 'rewards_train/rejected': '-0.53387', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.15036', 'logps_train/rejected': '-98.393', 'logps_train/chosen': '-89.318', 'loss/train': '0.64226', 'examples_per_second': '6.228', 'grad_norm': '16.625', 'counters/examples': 56960, 'counters/updates': 3560}
skipping logging after 56976 examples to avoid logging too frequently
skipping logging after 56992 examples to avoid logging too frequently
skipping logging after 57008 examples to avoid logging too frequently
train stats after 57024 examples: {'rewards_train/chosen': '-0.2955', 'rewards_train/rejected': '-0.36411', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.068578', 'logps_train/rejected': '-102.31', 'logps_train/chosen': '-94.173', 'loss/train': '0.67325', 'examples_per_second': '6.2544', 'grad_norm': '22.625', 'counters/examples': 57024, 'counters/updates': 3564}
skipping logging after 57040 examples to avoid logging too frequently
skipping logging after 57056 examples to avoid logging too frequently
skipping logging after 57072 examples to avoid logging too frequently
train stats after 57088 examples: {'rewards_train/chosen': '-0.3344', 'rewards_train/rejected': '-0.47951', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.14511', 'logps_train/rejected': '-109.83', 'logps_train/chosen': '-111.7', 'loss/train': '0.63486', 'examples_per_second': '5.4306', 'grad_norm': '17.75', 'counters/examples': 57088, 'counters/updates': 3568}
skipping logging after 57104 examples to avoid logging too frequently
skipping logging after 57120 examples to avoid logging too frequently
skipping logging after 57136 examples to avoid logging too frequently
train stats after 57152 examples: {'rewards_train/chosen': '-0.38454', 'rewards_train/rejected': '-0.46064', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.076233', 'logps_train/rejected': '-136.04', 'logps_train/chosen': '-142.73', 'loss/train': '0.68509', 'examples_per_second': '4.738', 'grad_norm': '19.75', 'counters/examples': 57152, 'counters/updates': 3572}
skipping logging after 57168 examples to avoid logging too frequently
skipping logging after 57184 examples to avoid logging too frequently
skipping logging after 57200 examples to avoid logging too frequently
train stats after 57216 examples: {'rewards_train/chosen': '-0.34672', 'rewards_train/rejected': '-0.42884', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.08218', 'logps_train/rejected': '-107.26', 'logps_train/chosen': '-113.09', 'loss/train': '0.66956', 'examples_per_second': '6.2487', 'grad_norm': '16.125', 'counters/examples': 57216, 'counters/updates': 3576}
skipping logging after 57232 examples to avoid logging too frequently
skipping logging after 57248 examples to avoid logging too frequently
skipping logging after 57264 examples to avoid logging too frequently
train stats after 57280 examples: {'rewards_train/chosen': '-0.35619', 'rewards_train/rejected': '-0.37688', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.020727', 'logps_train/rejected': '-124.2', 'logps_train/chosen': '-132.39', 'loss/train': '0.70084', 'examples_per_second': '4.9454', 'grad_norm': '20.25', 'counters/examples': 57280, 'counters/updates': 3580}
skipping logging after 57296 examples to avoid logging too frequently
skipping logging after 57312 examples to avoid logging too frequently
skipping logging after 57328 examples to avoid logging too frequently
train stats after 57344 examples: {'rewards_train/chosen': '-0.39247', 'rewards_train/rejected': '-0.57721', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.18474', 'logps_train/rejected': '-107.5', 'logps_train/chosen': '-87.278', 'loss/train': '0.6339', 'examples_per_second': '6.1592', 'grad_norm': '17', 'counters/examples': 57344, 'counters/updates': 3584}
skipping logging after 57360 examples to avoid logging too frequently
skipping logging after 57376 examples to avoid logging too frequently
skipping logging after 57392 examples to avoid logging too frequently
train stats after 57408 examples: {'rewards_train/chosen': '-0.41647', 'rewards_train/rejected': '-0.50806', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.091795', 'logps_train/rejected': '-100.78', 'logps_train/chosen': '-146.97', 'loss/train': '0.67265', 'examples_per_second': '5.2202', 'grad_norm': '20.125', 'counters/examples': 57408, 'counters/updates': 3588}
skipping logging after 57424 examples to avoid logging too frequently
skipping logging after 57440 examples to avoid logging too frequently
skipping logging after 57456 examples to avoid logging too frequently
train stats after 57472 examples: {'rewards_train/chosen': '-0.28763', 'rewards_train/rejected': '-0.33185', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.044312', 'logps_train/rejected': '-103.35', 'logps_train/chosen': '-89.012', 'loss/train': '0.69147', 'examples_per_second': '6.3762', 'grad_norm': '17.25', 'counters/examples': 57472, 'counters/updates': 3592}
skipping logging after 57488 examples to avoid logging too frequently
skipping logging after 57504 examples to avoid logging too frequently
skipping logging after 57520 examples to avoid logging too frequently
train stats after 57536 examples: {'rewards_train/chosen': '-0.29604', 'rewards_train/rejected': '-0.44495', 'rewards_train/accuracies': '0.71875', 'rewards_train/margins': '0.14892', 'logps_train/rejected': '-137.42', 'logps_train/chosen': '-131.76', 'loss/train': '0.64374', 'examples_per_second': '5.7936', 'grad_norm': '18.5', 'counters/examples': 57536, 'counters/updates': 3596}
Running evaluation after 57536 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.46s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.53s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 57536: {'rewards_eval/chosen': '-0.33803', 'rewards_eval/rejected': '-0.42255', 'rewards_eval/accuracies': '0.53906', 'rewards_eval/margins': '0.084559', 'logps_eval/rejected': '-126.38', 'logps_eval/chosen': '-121.87', 'loss/eval': '0.67319'}
skipping logging after 57552 examples to avoid logging too frequently
skipping logging after 57568 examples to avoid logging too frequently
skipping logging after 57584 examples to avoid logging too frequently
train stats after 57600 examples: {'rewards_train/chosen': '-0.45154', 'rewards_train/rejected': '-0.47827', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.026806', 'logps_train/rejected': '-132.42', 'logps_train/chosen': '-142.07', 'loss/train': '0.7009', 'examples_per_second': '4.909', 'grad_norm': '20.125', 'counters/examples': 57600, 'counters/updates': 3600}
skipping logging after 57616 examples to avoid logging too frequently
skipping logging after 57632 examples to avoid logging too frequently
skipping logging after 57648 examples to avoid logging too frequently
train stats after 57664 examples: {'rewards_train/chosen': '-0.27171', 'rewards_train/rejected': '-0.40375', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.13201', 'logps_train/rejected': '-133.56', 'logps_train/chosen': '-123.9', 'loss/train': '0.6524', 'examples_per_second': '5.0183', 'grad_norm': '17.375', 'counters/examples': 57664, 'counters/updates': 3604}
skipping logging after 57680 examples to avoid logging too frequently
skipping logging after 57696 examples to avoid logging too frequently
skipping logging after 57712 examples to avoid logging too frequently
train stats after 57728 examples: {'rewards_train/chosen': '-0.38811', 'rewards_train/rejected': '-0.45265', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.064564', 'logps_train/rejected': '-114.18', 'logps_train/chosen': '-113.28', 'loss/train': '0.67648', 'examples_per_second': '6.1259', 'grad_norm': '17.375', 'counters/examples': 57728, 'counters/updates': 3608}
skipping logging after 57744 examples to avoid logging too frequently
skipping logging after 57760 examples to avoid logging too frequently
skipping logging after 57776 examples to avoid logging too frequently
train stats after 57792 examples: {'rewards_train/chosen': '-0.30136', 'rewards_train/rejected': '-0.43811', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.1367', 'logps_train/rejected': '-129.13', 'logps_train/chosen': '-124.79', 'loss/train': '0.64627', 'examples_per_second': '4.1507', 'grad_norm': '19.875', 'counters/examples': 57792, 'counters/updates': 3612}
skipping logging after 57808 examples to avoid logging too frequently
skipping logging after 57824 examples to avoid logging too frequently
skipping logging after 57840 examples to avoid logging too frequently
train stats after 57856 examples: {'rewards_train/chosen': '-0.30211', 'rewards_train/rejected': '-0.40134', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.09934', 'logps_train/rejected': '-134.75', 'logps_train/chosen': '-118.57', 'loss/train': '0.66443', 'examples_per_second': '5.4668', 'grad_norm': '19', 'counters/examples': 57856, 'counters/updates': 3616}
skipping logging after 57872 examples to avoid logging too frequently
skipping logging after 57888 examples to avoid logging too frequently
skipping logging after 57904 examples to avoid logging too frequently
train stats after 57920 examples: {'rewards_train/chosen': '-0.34556', 'rewards_train/rejected': '-0.44055', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.094994', 'logps_train/rejected': '-120.8', 'logps_train/chosen': '-98.163', 'loss/train': '0.65871', 'examples_per_second': '5.7894', 'grad_norm': '16.75', 'counters/examples': 57920, 'counters/updates': 3620}
skipping logging after 57936 examples to avoid logging too frequently
skipping logging after 57952 examples to avoid logging too frequently
skipping logging after 57968 examples to avoid logging too frequently
train stats after 57984 examples: {'rewards_train/chosen': '-0.44829', 'rewards_train/rejected': '-0.47892', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.030617', 'logps_train/rejected': '-109.9', 'logps_train/chosen': '-126.42', 'loss/train': '0.69788', 'examples_per_second': '4.8822', 'grad_norm': '19.125', 'counters/examples': 57984, 'counters/updates': 3624}
skipping logging after 58000 examples to avoid logging too frequently
skipping logging after 58016 examples to avoid logging too frequently
skipping logging after 58032 examples to avoid logging too frequently
train stats after 58048 examples: {'rewards_train/chosen': '-0.38544', 'rewards_train/rejected': '-0.49343', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.10801', 'logps_train/rejected': '-133.39', 'logps_train/chosen': '-135.23', 'loss/train': '0.65929', 'examples_per_second': '4.7971', 'grad_norm': '17.125', 'counters/examples': 58048, 'counters/updates': 3628}
skipping logging after 58064 examples to avoid logging too frequently
skipping logging after 58080 examples to avoid logging too frequently
skipping logging after 58096 examples to avoid logging too frequently
train stats after 58112 examples: {'rewards_train/chosen': '-0.41037', 'rewards_train/rejected': '-0.45184', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.041355', 'logps_train/rejected': '-118.7', 'logps_train/chosen': '-119.07', 'loss/train': '0.68893', 'examples_per_second': '5.0287', 'grad_norm': '27.25', 'counters/examples': 58112, 'counters/updates': 3632}
skipping logging after 58128 examples to avoid logging too frequently
skipping logging after 58144 examples to avoid logging too frequently
skipping logging after 58160 examples to avoid logging too frequently
train stats after 58176 examples: {'rewards_train/chosen': '-0.40873', 'rewards_train/rejected': '-0.53724', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.12858', 'logps_train/rejected': '-108.02', 'logps_train/chosen': '-130.19', 'loss/train': '0.64973', 'examples_per_second': '5.4533', 'grad_norm': '17.875', 'counters/examples': 58176, 'counters/updates': 3636}
skipping logging after 58192 examples to avoid logging too frequently
skipping logging after 58208 examples to avoid logging too frequently
skipping logging after 58224 examples to avoid logging too frequently
train stats after 58240 examples: {'rewards_train/chosen': '-0.37349', 'rewards_train/rejected': '-0.54864', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.1751', 'logps_train/rejected': '-119.35', 'logps_train/chosen': '-127.54', 'loss/train': '0.62308', 'examples_per_second': '5.6151', 'grad_norm': '19.125', 'counters/examples': 58240, 'counters/updates': 3640}
skipping logging after 58256 examples to avoid logging too frequently
skipping logging after 58272 examples to avoid logging too frequently
skipping logging after 58288 examples to avoid logging too frequently
train stats after 58304 examples: {'rewards_train/chosen': '-0.54243', 'rewards_train/rejected': '-0.67728', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.13496', 'logps_train/rejected': '-110.31', 'logps_train/chosen': '-119.78', 'loss/train': '0.65039', 'examples_per_second': '7.399', 'grad_norm': '17.875', 'counters/examples': 58304, 'counters/updates': 3644}
skipping logging after 58320 examples to avoid logging too frequently
skipping logging after 58336 examples to avoid logging too frequently
skipping logging after 58352 examples to avoid logging too frequently
train stats after 58368 examples: {'rewards_train/chosen': '-0.40846', 'rewards_train/rejected': '-0.51804', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.1096', 'logps_train/rejected': '-139.25', 'logps_train/chosen': '-131', 'loss/train': '0.658', 'examples_per_second': '5.0823', 'grad_norm': '15.875', 'counters/examples': 58368, 'counters/updates': 3648}
skipping logging after 58384 examples to avoid logging too frequently
skipping logging after 58400 examples to avoid logging too frequently
skipping logging after 58416 examples to avoid logging too frequently
train stats after 58432 examples: {'rewards_train/chosen': '-0.40229', 'rewards_train/rejected': '-0.55898', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.15676', 'logps_train/rejected': '-132.66', 'logps_train/chosen': '-137.43', 'loss/train': '0.63647', 'examples_per_second': '5.1154', 'grad_norm': '16.875', 'counters/examples': 58432, 'counters/updates': 3652}
skipping logging after 58448 examples to avoid logging too frequently
skipping logging after 58464 examples to avoid logging too frequently
skipping logging after 58480 examples to avoid logging too frequently
train stats after 58496 examples: {'rewards_train/chosen': '-0.38901', 'rewards_train/rejected': '-0.52062', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.1317', 'logps_train/rejected': '-121.58', 'logps_train/chosen': '-124.39', 'loss/train': '0.65002', 'examples_per_second': '5.4051', 'grad_norm': '16.5', 'counters/examples': 58496, 'counters/updates': 3656}
skipping logging after 58512 examples to avoid logging too frequently
skipping logging after 58528 examples to avoid logging too frequently
Running evaluation after 58528 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:15,  2.43s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:06,  2.20s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:56,  1.93s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.90s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.55s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.65s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 58528: {'rewards_eval/chosen': '-0.49984', 'rewards_eval/rejected': '-0.5943', 'rewards_eval/accuracies': '0.53711', 'rewards_eval/margins': '0.094454', 'logps_eval/rejected': '-128.1', 'logps_eval/chosen': '-123.49', 'loss/eval': '0.67198'}
skipping logging after 58544 examples to avoid logging too frequently
train stats after 58560 examples: {'rewards_train/chosen': '-0.48285', 'rewards_train/rejected': '-0.51459', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.03175', 'logps_train/rejected': '-141.45', 'logps_train/chosen': '-141.58', 'loss/train': '0.70193', 'examples_per_second': '4.4693', 'grad_norm': '22.875', 'counters/examples': 58560, 'counters/updates': 3660}
skipping logging after 58576 examples to avoid logging too frequently
skipping logging after 58592 examples to avoid logging too frequently
skipping logging after 58608 examples to avoid logging too frequently
train stats after 58624 examples: {'rewards_train/chosen': '-0.7134', 'rewards_train/rejected': '-0.7179', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.0043564', 'logps_train/rejected': '-130.01', 'logps_train/chosen': '-128.57', 'loss/train': '0.71564', 'examples_per_second': '4.904', 'grad_norm': '22', 'counters/examples': 58624, 'counters/updates': 3664}
skipping logging after 58640 examples to avoid logging too frequently
skipping logging after 58656 examples to avoid logging too frequently
skipping logging after 58672 examples to avoid logging too frequently
train stats after 58688 examples: {'rewards_train/chosen': '-0.56554', 'rewards_train/rejected': '-0.61869', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.053139', 'logps_train/rejected': '-110.62', 'logps_train/chosen': '-102.88', 'loss/train': '0.6891', 'examples_per_second': '4.7871', 'grad_norm': '19.25', 'counters/examples': 58688, 'counters/updates': 3668}
skipping logging after 58704 examples to avoid logging too frequently
skipping logging after 58720 examples to avoid logging too frequently
skipping logging after 58736 examples to avoid logging too frequently
train stats after 58752 examples: {'rewards_train/chosen': '-0.40583', 'rewards_train/rejected': '-0.49213', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.086193', 'logps_train/rejected': '-99.172', 'logps_train/chosen': '-97.082', 'loss/train': '0.67029', 'examples_per_second': '5.6556', 'grad_norm': '17.75', 'counters/examples': 58752, 'counters/updates': 3672}
skipping logging after 58768 examples to avoid logging too frequently
skipping logging after 58784 examples to avoid logging too frequently
skipping logging after 58800 examples to avoid logging too frequently
train stats after 58816 examples: {'rewards_train/chosen': '-0.38809', 'rewards_train/rejected': '-0.55831', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.17033', 'logps_train/rejected': '-156.94', 'logps_train/chosen': '-180.38', 'loss/train': '0.64557', 'examples_per_second': '4.2797', 'grad_norm': '19.125', 'counters/examples': 58816, 'counters/updates': 3676}
skipping logging after 58832 examples to avoid logging too frequently
skipping logging after 58848 examples to avoid logging too frequently
skipping logging after 58864 examples to avoid logging too frequently
train stats after 58880 examples: {'rewards_train/chosen': '-0.37251', 'rewards_train/rejected': '-0.50144', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.129', 'logps_train/rejected': '-120.34', 'logps_train/chosen': '-118.18', 'loss/train': '0.65411', 'examples_per_second': '5.0617', 'grad_norm': '17.5', 'counters/examples': 58880, 'counters/updates': 3680}
skipping logging after 58896 examples to avoid logging too frequently
skipping logging after 58912 examples to avoid logging too frequently
skipping logging after 58928 examples to avoid logging too frequently
train stats after 58944 examples: {'rewards_train/chosen': '-0.45594', 'rewards_train/rejected': '-0.53096', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.075056', 'logps_train/rejected': '-120.48', 'logps_train/chosen': '-111.27', 'loss/train': '0.68193', 'examples_per_second': '5.3144', 'grad_norm': '17.125', 'counters/examples': 58944, 'counters/updates': 3684}
skipping logging after 58960 examples to avoid logging too frequently
skipping logging after 58976 examples to avoid logging too frequently
skipping logging after 58992 examples to avoid logging too frequently
train stats after 59008 examples: {'rewards_train/chosen': '-0.35572', 'rewards_train/rejected': '-0.54207', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.18639', 'logps_train/rejected': '-134.36', 'logps_train/chosen': '-139.14', 'loss/train': '0.63223', 'examples_per_second': '4.6772', 'grad_norm': '17', 'counters/examples': 59008, 'counters/updates': 3688}
skipping logging after 59024 examples to avoid logging too frequently
skipping logging after 59040 examples to avoid logging too frequently
skipping logging after 59056 examples to avoid logging too frequently
train stats after 59072 examples: {'rewards_train/chosen': '-0.53546', 'rewards_train/rejected': '-0.61708', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.081587', 'logps_train/rejected': '-115.89', 'logps_train/chosen': '-110.5', 'loss/train': '0.66983', 'examples_per_second': '5.1763', 'grad_norm': '17.875', 'counters/examples': 59072, 'counters/updates': 3692}
skipping logging after 59088 examples to avoid logging too frequently
skipping logging after 59104 examples to avoid logging too frequently
skipping logging after 59120 examples to avoid logging too frequently
train stats after 59136 examples: {'rewards_train/chosen': '-0.51732', 'rewards_train/rejected': '-0.61026', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.092876', 'logps_train/rejected': '-141.72', 'logps_train/chosen': '-134.53', 'loss/train': '0.67635', 'examples_per_second': '4.2814', 'grad_norm': '21.625', 'counters/examples': 59136, 'counters/updates': 3696}
skipping logging after 59152 examples to avoid logging too frequently
skipping logging after 59168 examples to avoid logging too frequently
skipping logging after 59184 examples to avoid logging too frequently
train stats after 59200 examples: {'rewards_train/chosen': '-0.40616', 'rewards_train/rejected': '-0.5752', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.16884', 'logps_train/rejected': '-119.91', 'logps_train/chosen': '-115.56', 'loss/train': '0.63708', 'examples_per_second': '5.5543', 'grad_norm': '16.75', 'counters/examples': 59200, 'counters/updates': 3700}
skipping logging after 59216 examples to avoid logging too frequently
skipping logging after 59232 examples to avoid logging too frequently
skipping logging after 59248 examples to avoid logging too frequently
train stats after 59264 examples: {'rewards_train/chosen': '-0.5152', 'rewards_train/rejected': '-0.6095', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.094315', 'logps_train/rejected': '-116.62', 'logps_train/chosen': '-126.37', 'loss/train': '0.66525', 'examples_per_second': '5.8229', 'grad_norm': '20.375', 'counters/examples': 59264, 'counters/updates': 3704}
skipping logging after 59280 examples to avoid logging too frequently
skipping logging after 59296 examples to avoid logging too frequently
skipping logging after 59312 examples to avoid logging too frequently
train stats after 59328 examples: {'rewards_train/chosen': '-0.44365', 'rewards_train/rejected': '-0.49275', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.049164', 'logps_train/rejected': '-120.98', 'logps_train/chosen': '-112.98', 'loss/train': '0.68332', 'examples_per_second': '6.023', 'grad_norm': '18.125', 'counters/examples': 59328, 'counters/updates': 3708}
skipping logging after 59344 examples to avoid logging too frequently
skipping logging after 59360 examples to avoid logging too frequently
skipping logging after 59376 examples to avoid logging too frequently
train stats after 59392 examples: {'rewards_train/chosen': '-0.39734', 'rewards_train/rejected': '-0.5221', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.12473', 'logps_train/rejected': '-124.37', 'logps_train/chosen': '-160.05', 'loss/train': '0.65137', 'examples_per_second': '4.3478', 'grad_norm': '19.75', 'counters/examples': 59392, 'counters/updates': 3712}
skipping logging after 59408 examples to avoid logging too frequently
skipping logging after 59424 examples to avoid logging too frequently
skipping logging after 59440 examples to avoid logging too frequently
train stats after 59456 examples: {'rewards_train/chosen': '-0.47353', 'rewards_train/rejected': '-0.59086', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.1174', 'logps_train/rejected': '-103.5', 'logps_train/chosen': '-94.592', 'loss/train': '0.65149', 'examples_per_second': '4.9868', 'grad_norm': '15.938', 'counters/examples': 59456, 'counters/updates': 3716}
skipping logging after 59472 examples to avoid logging too frequently
skipping logging after 59488 examples to avoid logging too frequently
skipping logging after 59504 examples to avoid logging too frequently
train stats after 59520 examples: {'rewards_train/chosen': '-0.52294', 'rewards_train/rejected': '-0.55189', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.028889', 'logps_train/rejected': '-142.19', 'logps_train/chosen': '-123.8', 'loss/train': '0.69702', 'examples_per_second': '4.9286', 'grad_norm': '18.125', 'counters/examples': 59520, 'counters/updates': 3720}
Running evaluation after 59520 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.46s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 59520: {'rewards_eval/chosen': '-0.47076', 'rewards_eval/rejected': '-0.55939', 'rewards_eval/accuracies': '0.5293', 'rewards_eval/margins': '0.0886', 'logps_eval/rejected': '-127.75', 'logps_eval/chosen': '-123.2', 'loss/eval': '0.67471'}
skipping logging after 59536 examples to avoid logging too frequently
skipping logging after 59552 examples to avoid logging too frequently
skipping logging after 59568 examples to avoid logging too frequently
train stats after 59584 examples: {'rewards_train/chosen': '-0.44966', 'rewards_train/rejected': '-0.52573', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.076128', 'logps_train/rejected': '-111.89', 'logps_train/chosen': '-108.65', 'loss/train': '0.67648', 'examples_per_second': '5.6469', 'grad_norm': '16.625', 'counters/examples': 59584, 'counters/updates': 3724}
skipping logging after 59600 examples to avoid logging too frequently
skipping logging after 59616 examples to avoid logging too frequently
skipping logging after 59632 examples to avoid logging too frequently
train stats after 59648 examples: {'rewards_train/chosen': '-0.48163', 'rewards_train/rejected': '-0.5563', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.074686', 'logps_train/rejected': '-133.05', 'logps_train/chosen': '-118.16', 'loss/train': '0.67635', 'examples_per_second': '5.5849', 'grad_norm': '18.375', 'counters/examples': 59648, 'counters/updates': 3728}
skipping logging after 59664 examples to avoid logging too frequently
skipping logging after 59680 examples to avoid logging too frequently
skipping logging after 59696 examples to avoid logging too frequently
train stats after 59712 examples: {'rewards_train/chosen': '-0.43136', 'rewards_train/rejected': '-0.66224', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.23096', 'logps_train/rejected': '-118.3', 'logps_train/chosen': '-103.58', 'loss/train': '0.6084', 'examples_per_second': '5.3972', 'grad_norm': '15.125', 'counters/examples': 59712, 'counters/updates': 3732}
skipping logging after 59728 examples to avoid logging too frequently
skipping logging after 59744 examples to avoid logging too frequently
skipping logging after 59760 examples to avoid logging too frequently
train stats after 59776 examples: {'rewards_train/chosen': '-0.40519', 'rewards_train/rejected': '-0.52057', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.11532', 'logps_train/rejected': '-139.6', 'logps_train/chosen': '-142.95', 'loss/train': '0.6532', 'examples_per_second': '4.9352', 'grad_norm': '17.5', 'counters/examples': 59776, 'counters/updates': 3736}
skipping logging after 59792 examples to avoid logging too frequently
skipping logging after 59808 examples to avoid logging too frequently
skipping logging after 59824 examples to avoid logging too frequently
train stats after 59840 examples: {'rewards_train/chosen': '-0.4632', 'rewards_train/rejected': '-0.51905', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.055798', 'logps_train/rejected': '-98.992', 'logps_train/chosen': '-124.93', 'loss/train': '0.68124', 'examples_per_second': '4.9442', 'grad_norm': '19.375', 'counters/examples': 59840, 'counters/updates': 3740}
skipping logging after 59856 examples to avoid logging too frequently
skipping logging after 59872 examples to avoid logging too frequently
skipping logging after 59888 examples to avoid logging too frequently
train stats after 59904 examples: {'rewards_train/chosen': '-0.43683', 'rewards_train/rejected': '-0.58716', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.15028', 'logps_train/rejected': '-151.73', 'logps_train/chosen': '-133.83', 'loss/train': '0.64354', 'examples_per_second': '4.7674', 'grad_norm': '19.5', 'counters/examples': 59904, 'counters/updates': 3744}
skipping logging after 59920 examples to avoid logging too frequently
skipping logging after 59936 examples to avoid logging too frequently
skipping logging after 59952 examples to avoid logging too frequently
train stats after 59968 examples: {'rewards_train/chosen': '-0.40605', 'rewards_train/rejected': '-0.52014', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.11403', 'logps_train/rejected': '-143.22', 'logps_train/chosen': '-116.74', 'loss/train': '0.65796', 'examples_per_second': '4.8154', 'grad_norm': '16.875', 'counters/examples': 59968, 'counters/updates': 3748}
skipping logging after 59984 examples to avoid logging too frequently
skipping logging after 60000 examples to avoid logging too frequently
skipping logging after 60016 examples to avoid logging too frequently
train stats after 60032 examples: {'rewards_train/chosen': '-0.45003', 'rewards_train/rejected': '-0.5654', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.11549', 'logps_train/rejected': '-121.05', 'logps_train/chosen': '-114.35', 'loss/train': '0.66147', 'examples_per_second': '5.2325', 'grad_norm': '20.625', 'counters/examples': 60032, 'counters/updates': 3752}
skipping logging after 60048 examples to avoid logging too frequently
skipping logging after 60064 examples to avoid logging too frequently
skipping logging after 60080 examples to avoid logging too frequently
train stats after 60096 examples: {'rewards_train/chosen': '-0.43468', 'rewards_train/rejected': '-0.48764', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.05294', 'logps_train/rejected': '-147.52', 'logps_train/chosen': '-166.67', 'loss/train': '0.68253', 'examples_per_second': '4.3458', 'grad_norm': '20.375', 'counters/examples': 60096, 'counters/updates': 3756}
skipping logging after 60112 examples to avoid logging too frequently
skipping logging after 60128 examples to avoid logging too frequently
skipping logging after 60144 examples to avoid logging too frequently
train stats after 60160 examples: {'rewards_train/chosen': '-0.31589', 'rewards_train/rejected': '-0.42789', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.11198', 'logps_train/rejected': '-150.64', 'logps_train/chosen': '-125.03', 'loss/train': '0.67253', 'examples_per_second': '4.7015', 'grad_norm': '19.25', 'counters/examples': 60160, 'counters/updates': 3760}
skipping logging after 60176 examples to avoid logging too frequently
skipping logging after 60192 examples to avoid logging too frequently
skipping logging after 60208 examples to avoid logging too frequently
train stats after 60224 examples: {'rewards_train/chosen': '-0.48684', 'rewards_train/rejected': '-0.52488', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.037935', 'logps_train/rejected': '-108.13', 'logps_train/chosen': '-111.88', 'loss/train': '0.69731', 'examples_per_second': '5.7165', 'grad_norm': '18.875', 'counters/examples': 60224, 'counters/updates': 3764}
skipping logging after 60240 examples to avoid logging too frequently
skipping logging after 60256 examples to avoid logging too frequently
skipping logging after 60272 examples to avoid logging too frequently
train stats after 60288 examples: {'rewards_train/chosen': '-0.31035', 'rewards_train/rejected': '-0.4328', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.12251', 'logps_train/rejected': '-129.2', 'logps_train/chosen': '-125.55', 'loss/train': '0.64993', 'examples_per_second': '5.5409', 'grad_norm': '19.5', 'counters/examples': 60288, 'counters/updates': 3768}
skipping logging after 60304 examples to avoid logging too frequently
skipping logging after 60320 examples to avoid logging too frequently
skipping logging after 60336 examples to avoid logging too frequently
train stats after 60352 examples: {'rewards_train/chosen': '-0.41381', 'rewards_train/rejected': '-0.56691', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.15315', 'logps_train/rejected': '-116', 'logps_train/chosen': '-120.39', 'loss/train': '0.63983', 'examples_per_second': '5.12', 'grad_norm': '16.125', 'counters/examples': 60352, 'counters/updates': 3772}
skipping logging after 60368 examples to avoid logging too frequently
skipping logging after 60384 examples to avoid logging too frequently
skipping logging after 60400 examples to avoid logging too frequently
train stats after 60416 examples: {'rewards_train/chosen': '-0.38847', 'rewards_train/rejected': '-0.49387', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.10556', 'logps_train/rejected': '-123.97', 'logps_train/chosen': '-121.43', 'loss/train': '0.66026', 'examples_per_second': '6.1178', 'grad_norm': '18.875', 'counters/examples': 60416, 'counters/updates': 3776}
skipping logging after 60432 examples to avoid logging too frequently
skipping logging after 60448 examples to avoid logging too frequently
skipping logging after 60464 examples to avoid logging too frequently
train stats after 60480 examples: {'rewards_train/chosen': '-0.35098', 'rewards_train/rejected': '-0.46215', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.11123', 'logps_train/rejected': '-108.86', 'logps_train/chosen': '-123.55', 'loss/train': '0.66039', 'examples_per_second': '5.1721', 'grad_norm': '17', 'counters/examples': 60480, 'counters/updates': 3780}
skipping logging after 60496 examples to avoid logging too frequently
skipping logging after 60512 examples to avoid logging too frequently
Running evaluation after 60512 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:16,  2.46s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:06,  2.22s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:56,  1.94s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.91s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.56s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.66s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.48s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.55s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 60512: {'rewards_eval/chosen': '-0.40749', 'rewards_eval/rejected': '-0.49716', 'rewards_eval/accuracies': '0.55273', 'rewards_eval/margins': '0.089678', 'logps_eval/rejected': '-127.13', 'logps_eval/chosen': '-122.57', 'loss/eval': '0.67359'}
skipping logging after 60528 examples to avoid logging too frequently
train stats after 60544 examples: {'rewards_train/chosen': '-0.41971', 'rewards_train/rejected': '-0.5319', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.112', 'logps_train/rejected': '-105.62', 'logps_train/chosen': '-146.31', 'loss/train': '0.66589', 'examples_per_second': '5.9008', 'grad_norm': '18.5', 'counters/examples': 60544, 'counters/updates': 3784}
skipping logging after 60560 examples to avoid logging too frequently
skipping logging after 60576 examples to avoid logging too frequently
skipping logging after 60592 examples to avoid logging too frequently
train stats after 60608 examples: {'rewards_train/chosen': '-0.50796', 'rewards_train/rejected': '-0.52649', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.018414', 'logps_train/rejected': '-107.29', 'logps_train/chosen': '-117.68', 'loss/train': '0.69971', 'examples_per_second': '5.2557', 'grad_norm': '17', 'counters/examples': 60608, 'counters/updates': 3788}
skipping logging after 60624 examples to avoid logging too frequently
skipping logging after 60640 examples to avoid logging too frequently
skipping logging after 60656 examples to avoid logging too frequently
train stats after 60672 examples: {'rewards_train/chosen': '-0.39535', 'rewards_train/rejected': '-0.40807', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.012577', 'logps_train/rejected': '-131.88', 'logps_train/chosen': '-137.24', 'loss/train': '0.70007', 'examples_per_second': '4.8242', 'grad_norm': '34.25', 'counters/examples': 60672, 'counters/updates': 3792}
skipping logging after 60688 examples to avoid logging too frequently
skipping logging after 60704 examples to avoid logging too frequently
skipping logging after 60720 examples to avoid logging too frequently
train stats after 60736 examples: {'rewards_train/chosen': '-0.30862', 'rewards_train/rejected': '-0.41033', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.1017', 'logps_train/rejected': '-107.88', 'logps_train/chosen': '-116.96', 'loss/train': '0.65765', 'examples_per_second': '4.9298', 'grad_norm': '15', 'counters/examples': 60736, 'counters/updates': 3796}
skipping logging after 60752 examples to avoid logging too frequently
skipping logging after 60768 examples to avoid logging too frequently
skipping logging after 60784 examples to avoid logging too frequently
train stats after 60800 examples: {'rewards_train/chosen': '-0.3981', 'rewards_train/rejected': '-0.40285', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.0047874', 'logps_train/rejected': '-153.55', 'logps_train/chosen': '-127.02', 'loss/train': '0.70938', 'examples_per_second': '3.9876', 'grad_norm': '20.25', 'counters/examples': 60800, 'counters/updates': 3800}
skipping logging after 60816 examples to avoid logging too frequently
skipping logging after 60832 examples to avoid logging too frequently
skipping logging after 60848 examples to avoid logging too frequently
train stats after 60864 examples: {'rewards_train/chosen': '-0.34761', 'rewards_train/rejected': '-0.44203', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.094425', 'logps_train/rejected': '-133.45', 'logps_train/chosen': '-143.78', 'loss/train': '0.66733', 'examples_per_second': '4.6914', 'grad_norm': '19.875', 'counters/examples': 60864, 'counters/updates': 3804}
skipping logging after 60880 examples to avoid logging too frequently
skipping logging after 60896 examples to avoid logging too frequently
skipping logging after 60912 examples to avoid logging too frequently
train stats after 60928 examples: {'rewards_train/chosen': '-0.39892', 'rewards_train/rejected': '-0.55964', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.1608', 'logps_train/rejected': '-98.278', 'logps_train/chosen': '-91.087', 'loss/train': '0.63844', 'examples_per_second': '5.6641', 'grad_norm': '17.5', 'counters/examples': 60928, 'counters/updates': 3808}
skipping logging after 60944 examples to avoid logging too frequently
skipping logging after 60960 examples to avoid logging too frequently
skipping logging after 60976 examples to avoid logging too frequently
train stats after 60992 examples: {'rewards_train/chosen': '-0.47243', 'rewards_train/rejected': '-0.52892', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.056511', 'logps_train/rejected': '-130.83', 'logps_train/chosen': '-136.22', 'loss/train': '0.6832', 'examples_per_second': '5.7343', 'grad_norm': '20', 'counters/examples': 60992, 'counters/updates': 3812}
skipping logging after 61008 examples to avoid logging too frequently
skipping logging after 61024 examples to avoid logging too frequently
skipping logging after 61040 examples to avoid logging too frequently
train stats after 61056 examples: {'rewards_train/chosen': '-0.45785', 'rewards_train/rejected': '-0.51349', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.055637', 'logps_train/rejected': '-113.19', 'logps_train/chosen': '-130.47', 'loss/train': '0.67853', 'examples_per_second': '5.2086', 'grad_norm': '19.625', 'counters/examples': 61056, 'counters/updates': 3816}
skipping logging after 61072 examples to avoid logging too frequently
skipping logging after 61088 examples to avoid logging too frequently
skipping logging after 61104 examples to avoid logging too frequently
train stats after 61120 examples: {'rewards_train/chosen': '-0.52852', 'rewards_train/rejected': '-0.55831', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.029819', 'logps_train/rejected': '-120.61', 'logps_train/chosen': '-114.75', 'loss/train': '0.70412', 'examples_per_second': '5.1683', 'grad_norm': '18.25', 'counters/examples': 61120, 'counters/updates': 3820}
skipping logging after 61136 examples to avoid logging too frequently
skipping logging after 61152 examples to avoid logging too frequently
skipping logging after 61168 examples to avoid logging too frequently
train stats after 61184 examples: {'rewards_train/chosen': '-0.42403', 'rewards_train/rejected': '-0.48609', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.06205', 'logps_train/rejected': '-128.66', 'logps_train/chosen': '-121.1', 'loss/train': '0.68462', 'examples_per_second': '4.3905', 'grad_norm': '19.25', 'counters/examples': 61184, 'counters/updates': 3824}
skipping logging after 61200 examples to avoid logging too frequently
skipping logging after 61216 examples to avoid logging too frequently
skipping logging after 61232 examples to avoid logging too frequently
train stats after 61248 examples: {'rewards_train/chosen': '-0.52089', 'rewards_train/rejected': '-0.77722', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.25622', 'logps_train/rejected': '-124.17', 'logps_train/chosen': '-119.63', 'loss/train': '0.58969', 'examples_per_second': '5.2091', 'grad_norm': '21', 'counters/examples': 61248, 'counters/updates': 3828}
skipping logging after 61264 examples to avoid logging too frequently
skipping logging after 61280 examples to avoid logging too frequently
skipping logging after 61296 examples to avoid logging too frequently
train stats after 61312 examples: {'rewards_train/chosen': '-0.46556', 'rewards_train/rejected': '-0.51812', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.052582', 'logps_train/rejected': '-117.59', 'logps_train/chosen': '-123.49', 'loss/train': '0.68057', 'examples_per_second': '4.2156', 'grad_norm': '17', 'counters/examples': 61312, 'counters/updates': 3832}
skipping logging after 61328 examples to avoid logging too frequently
skipping logging after 61344 examples to avoid logging too frequently
skipping logging after 61360 examples to avoid logging too frequently
train stats after 61376 examples: {'rewards_train/chosen': '-0.33695', 'rewards_train/rejected': '-0.52209', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.18514', 'logps_train/rejected': '-128.8', 'logps_train/chosen': '-147.12', 'loss/train': '0.6169', 'examples_per_second': '5.8344', 'grad_norm': '16.25', 'counters/examples': 61376, 'counters/updates': 3836}
skipping logging after 61392 examples to avoid logging too frequently
skipping logging after 61408 examples to avoid logging too frequently
skipping logging after 61424 examples to avoid logging too frequently
train stats after 61440 examples: {'rewards_train/chosen': '-0.43547', 'rewards_train/rejected': '-0.53873', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.10335', 'logps_train/rejected': '-124.06', 'logps_train/chosen': '-118.09', 'loss/train': '0.66687', 'examples_per_second': '5.0858', 'grad_norm': '17.875', 'counters/examples': 61440, 'counters/updates': 3840}
skipping logging after 61456 examples to avoid logging too frequently
skipping logging after 61472 examples to avoid logging too frequently
skipping logging after 61488 examples to avoid logging too frequently
train stats after 61504 examples: {'rewards_train/chosen': '-0.38451', 'rewards_train/rejected': '-0.55047', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.16602', 'logps_train/rejected': '-122.53', 'logps_train/chosen': '-111.91', 'loss/train': '0.63469', 'examples_per_second': '5.3853', 'grad_norm': '16.375', 'counters/examples': 61504, 'counters/updates': 3844}
Running evaluation after 61504 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<01:00,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.83s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.63s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.33s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.29s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.41s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 61504: {'rewards_eval/chosen': '-0.39304', 'rewards_eval/rejected': '-0.47327', 'rewards_eval/accuracies': '0.54492', 'rewards_eval/margins': '0.08024', 'logps_eval/rejected': '-126.89', 'logps_eval/chosen': '-122.42', 'loss/eval': '0.67719'}
skipping logging after 61520 examples to avoid logging too frequently
skipping logging after 61536 examples to avoid logging too frequently
skipping logging after 61552 examples to avoid logging too frequently
train stats after 61568 examples: {'rewards_train/chosen': '-0.43151', 'rewards_train/rejected': '-0.48099', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.049376', 'logps_train/rejected': '-114.75', 'logps_train/chosen': '-119.74', 'loss/train': '0.68573', 'examples_per_second': '4.9382', 'grad_norm': '22.125', 'counters/examples': 61568, 'counters/updates': 3848}
skipping logging after 61584 examples to avoid logging too frequently
skipping logging after 61600 examples to avoid logging too frequently
skipping logging after 61616 examples to avoid logging too frequently
train stats after 61632 examples: {'rewards_train/chosen': '-0.37589', 'rewards_train/rejected': '-0.45271', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '0.07671', 'logps_train/rejected': '-97.416', 'logps_train/chosen': '-105.15', 'loss/train': '0.67154', 'examples_per_second': '5.0642', 'grad_norm': '13.812', 'counters/examples': 61632, 'counters/updates': 3852}
skipping logging after 61648 examples to avoid logging too frequently
skipping logging after 61664 examples to avoid logging too frequently
skipping logging after 61680 examples to avoid logging too frequently
train stats after 61696 examples: {'rewards_train/chosen': '-0.33995', 'rewards_train/rejected': '-0.46975', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.12976', 'logps_train/rejected': '-119.59', 'logps_train/chosen': '-128.92', 'loss/train': '0.65007', 'examples_per_second': '5.8448', 'grad_norm': '19.5', 'counters/examples': 61696, 'counters/updates': 3856}
skipping logging after 61712 examples to avoid logging too frequently
skipping logging after 61728 examples to avoid logging too frequently
skipping logging after 61744 examples to avoid logging too frequently
train stats after 61760 examples: {'rewards_train/chosen': '-0.35238', 'rewards_train/rejected': '-0.42487', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.072563', 'logps_train/rejected': '-138.06', 'logps_train/chosen': '-115.92', 'loss/train': '0.66962', 'examples_per_second': '6.2884', 'grad_norm': '19.625', 'counters/examples': 61760, 'counters/updates': 3860}
skipping logging after 61776 examples to avoid logging too frequently
skipping logging after 61792 examples to avoid logging too frequently
skipping logging after 61808 examples to avoid logging too frequently
train stats after 61824 examples: {'rewards_train/chosen': '-0.33435', 'rewards_train/rejected': '-0.54095', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.20647', 'logps_train/rejected': '-109.44', 'logps_train/chosen': '-109.65', 'loss/train': '0.62396', 'examples_per_second': '5.8991', 'grad_norm': '17.5', 'counters/examples': 61824, 'counters/updates': 3864}
skipping logging after 61840 examples to avoid logging too frequently
skipping logging after 61856 examples to avoid logging too frequently
skipping logging after 61872 examples to avoid logging too frequently
train stats after 61888 examples: {'rewards_train/chosen': '-0.45028', 'rewards_train/rejected': '-0.58189', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.13163', 'logps_train/rejected': '-130.31', 'logps_train/chosen': '-146.69', 'loss/train': '0.66095', 'examples_per_second': '4.3869', 'grad_norm': '20.5', 'counters/examples': 61888, 'counters/updates': 3868}
skipping logging after 61904 examples to avoid logging too frequently
skipping logging after 61920 examples to avoid logging too frequently
skipping logging after 61936 examples to avoid logging too frequently
train stats after 61952 examples: {'rewards_train/chosen': '-0.37873', 'rewards_train/rejected': '-0.45992', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.081184', 'logps_train/rejected': '-107.72', 'logps_train/chosen': '-131.11', 'loss/train': '0.6748', 'examples_per_second': '3.9448', 'grad_norm': '19.375', 'counters/examples': 61952, 'counters/updates': 3872}
skipping logging after 61968 examples to avoid logging too frequently
skipping logging after 61984 examples to avoid logging too frequently
skipping logging after 62000 examples to avoid logging too frequently
train stats after 62016 examples: {'rewards_train/chosen': '-0.41252', 'rewards_train/rejected': '-0.43921', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.026653', 'logps_train/rejected': '-177.21', 'logps_train/chosen': '-164.72', 'loss/train': '0.69733', 'examples_per_second': '4.3949', 'grad_norm': '20', 'counters/examples': 62016, 'counters/updates': 3876}
skipping logging after 62032 examples to avoid logging too frequently
skipping logging after 62048 examples to avoid logging too frequently
skipping logging after 62064 examples to avoid logging too frequently
train stats after 62080 examples: {'rewards_train/chosen': '-0.42687', 'rewards_train/rejected': '-0.43022', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.0032921', 'logps_train/rejected': '-122.75', 'logps_train/chosen': '-108.02', 'loss/train': '0.71973', 'examples_per_second': '5.058', 'grad_norm': '19.125', 'counters/examples': 62080, 'counters/updates': 3880}
skipping logging after 62096 examples to avoid logging too frequently
skipping logging after 62112 examples to avoid logging too frequently
skipping logging after 62128 examples to avoid logging too frequently
train stats after 62144 examples: {'rewards_train/chosen': '-0.38811', 'rewards_train/rejected': '-0.41921', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.031021', 'logps_train/rejected': '-113.25', 'logps_train/chosen': '-126.38', 'loss/train': '0.69046', 'examples_per_second': '5.045', 'grad_norm': '17', 'counters/examples': 62144, 'counters/updates': 3884}
skipping logging after 62160 examples to avoid logging too frequently
skipping logging after 62176 examples to avoid logging too frequently
skipping logging after 62192 examples to avoid logging too frequently
train stats after 62208 examples: {'rewards_train/chosen': '-0.38581', 'rewards_train/rejected': '-0.44429', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.058432', 'logps_train/rejected': '-140.49', 'logps_train/chosen': '-150.94', 'loss/train': '0.67612', 'examples_per_second': '5.5839', 'grad_norm': '18.125', 'counters/examples': 62208, 'counters/updates': 3888}
skipping logging after 62224 examples to avoid logging too frequently
skipping logging after 62240 examples to avoid logging too frequently
skipping logging after 62256 examples to avoid logging too frequently
train stats after 62272 examples: {'rewards_train/chosen': '-0.47735', 'rewards_train/rejected': '-0.61483', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.13754', 'logps_train/rejected': '-123.22', 'logps_train/chosen': '-122.45', 'loss/train': '0.64755', 'examples_per_second': '5.0412', 'grad_norm': '19.5', 'counters/examples': 62272, 'counters/updates': 3892}
skipping logging after 62288 examples to avoid logging too frequently
skipping logging after 62304 examples to avoid logging too frequently
skipping logging after 62320 examples to avoid logging too frequently
train stats after 62336 examples: {'rewards_train/chosen': '-0.40482', 'rewards_train/rejected': '-0.43769', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.032898', 'logps_train/rejected': '-122.46', 'logps_train/chosen': '-139.42', 'loss/train': '0.69257', 'examples_per_second': '4.885', 'grad_norm': '18', 'counters/examples': 62336, 'counters/updates': 3896}
skipping logging after 62352 examples to avoid logging too frequently
skipping logging after 62368 examples to avoid logging too frequently
skipping logging after 62384 examples to avoid logging too frequently
train stats after 62400 examples: {'rewards_train/chosen': '-0.37844', 'rewards_train/rejected': '-0.46433', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.085901', 'logps_train/rejected': '-114.74', 'logps_train/chosen': '-125.94', 'loss/train': '0.67267', 'examples_per_second': '4.994', 'grad_norm': '16.75', 'counters/examples': 62400, 'counters/updates': 3900}
skipping logging after 62416 examples to avoid logging too frequently
skipping logging after 62432 examples to avoid logging too frequently
skipping logging after 62448 examples to avoid logging too frequently
train stats after 62464 examples: {'rewards_train/chosen': '-0.43453', 'rewards_train/rejected': '-0.50621', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.071741', 'logps_train/rejected': '-120.07', 'logps_train/chosen': '-129.68', 'loss/train': '0.67569', 'examples_per_second': '4.7335', 'grad_norm': '16.875', 'counters/examples': 62464, 'counters/updates': 3904}
skipping logging after 62480 examples to avoid logging too frequently
skipping logging after 62496 examples to avoid logging too frequently
Running evaluation after 62496 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:06,  2.16s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:02,  2.10s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.88s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.87s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.48s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.25s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.29s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 62496: {'rewards_eval/chosen': '-0.43216', 'rewards_eval/rejected': '-0.51015', 'rewards_eval/accuracies': '0.53125', 'rewards_eval/margins': '0.077993', 'logps_eval/rejected': '-127.26', 'logps_eval/chosen': '-122.82', 'loss/eval': '0.67723'}
skipping logging after 62512 examples to avoid logging too frequently
train stats after 62528 examples: {'rewards_train/chosen': '-0.32679', 'rewards_train/rejected': '-0.49891', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.17222', 'logps_train/rejected': '-138.19', 'logps_train/chosen': '-134.85', 'loss/train': '0.63002', 'examples_per_second': '5.6589', 'grad_norm': '16.5', 'counters/examples': 62528, 'counters/updates': 3908}
skipping logging after 62544 examples to avoid logging too frequently
skipping logging after 62560 examples to avoid logging too frequently
skipping logging after 62576 examples to avoid logging too frequently
train stats after 62592 examples: {'rewards_train/chosen': '-0.44139', 'rewards_train/rejected': '-0.58338', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.14196', 'logps_train/rejected': '-138.9', 'logps_train/chosen': '-127.09', 'loss/train': '0.6423', 'examples_per_second': '4.722', 'grad_norm': '17.125', 'counters/examples': 62592, 'counters/updates': 3912}
skipping logging after 62608 examples to avoid logging too frequently
skipping logging after 62624 examples to avoid logging too frequently
skipping logging after 62640 examples to avoid logging too frequently
train stats after 62656 examples: {'rewards_train/chosen': '-0.36662', 'rewards_train/rejected': '-0.45189', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.085249', 'logps_train/rejected': '-128.89', 'logps_train/chosen': '-107.07', 'loss/train': '0.66257', 'examples_per_second': '4.9081', 'grad_norm': '14.5', 'counters/examples': 62656, 'counters/updates': 3916}
skipping logging after 62672 examples to avoid logging too frequently
skipping logging after 62688 examples to avoid logging too frequently
skipping logging after 62704 examples to avoid logging too frequently
train stats after 62720 examples: {'rewards_train/chosen': '-0.40918', 'rewards_train/rejected': '-0.52697', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.11774', 'logps_train/rejected': '-141.96', 'logps_train/chosen': '-122.56', 'loss/train': '0.66052', 'examples_per_second': '5.024', 'grad_norm': '18.125', 'counters/examples': 62720, 'counters/updates': 3920}
skipping logging after 62736 examples to avoid logging too frequently
skipping logging after 62752 examples to avoid logging too frequently
skipping logging after 62768 examples to avoid logging too frequently
train stats after 62784 examples: {'rewards_train/chosen': '-0.48135', 'rewards_train/rejected': '-0.51061', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.029171', 'logps_train/rejected': '-114.71', 'logps_train/chosen': '-106.12', 'loss/train': '0.69409', 'examples_per_second': '5.8951', 'grad_norm': '16.625', 'counters/examples': 62784, 'counters/updates': 3924}
skipping logging after 62800 examples to avoid logging too frequently
skipping logging after 62816 examples to avoid logging too frequently
skipping logging after 62832 examples to avoid logging too frequently
train stats after 62848 examples: {'rewards_train/chosen': '-0.28676', 'rewards_train/rejected': '-0.42417', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.13743', 'logps_train/rejected': '-124.38', 'logps_train/chosen': '-114.13', 'loss/train': '0.64526', 'examples_per_second': '4.8579', 'grad_norm': '16.625', 'counters/examples': 62848, 'counters/updates': 3928}
skipping logging after 62864 examples to avoid logging too frequently
skipping logging after 62880 examples to avoid logging too frequently
skipping logging after 62896 examples to avoid logging too frequently
train stats after 62912 examples: {'rewards_train/chosen': '-0.37606', 'rewards_train/rejected': '-0.55026', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.1741', 'logps_train/rejected': '-116.77', 'logps_train/chosen': '-106.63', 'loss/train': '0.6301', 'examples_per_second': '6.15', 'grad_norm': '15.875', 'counters/examples': 62912, 'counters/updates': 3932}
skipping logging after 62928 examples to avoid logging too frequently
skipping logging after 62944 examples to avoid logging too frequently
skipping logging after 62960 examples to avoid logging too frequently
train stats after 62976 examples: {'rewards_train/chosen': '-0.42326', 'rewards_train/rejected': '-0.52466', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.10127', 'logps_train/rejected': '-132.27', 'logps_train/chosen': '-132.29', 'loss/train': '0.66893', 'examples_per_second': '5.1427', 'grad_norm': '18.125', 'counters/examples': 62976, 'counters/updates': 3936}
skipping logging after 62992 examples to avoid logging too frequently
skipping logging after 63008 examples to avoid logging too frequently
skipping logging after 63024 examples to avoid logging too frequently
train stats after 63040 examples: {'rewards_train/chosen': '-0.28247', 'rewards_train/rejected': '-0.39209', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.10973', 'logps_train/rejected': '-124.52', 'logps_train/chosen': '-122.98', 'loss/train': '0.65329', 'examples_per_second': '4.5731', 'grad_norm': '18.875', 'counters/examples': 63040, 'counters/updates': 3940}
skipping logging after 63056 examples to avoid logging too frequently
skipping logging after 63072 examples to avoid logging too frequently
skipping logging after 63088 examples to avoid logging too frequently
train stats after 63104 examples: {'rewards_train/chosen': '-0.40844', 'rewards_train/rejected': '-0.45957', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.051125', 'logps_train/rejected': '-107.58', 'logps_train/chosen': '-127.51', 'loss/train': '0.68518', 'examples_per_second': '5.6855', 'grad_norm': '17.125', 'counters/examples': 63104, 'counters/updates': 3944}
skipping logging after 63120 examples to avoid logging too frequently
skipping logging after 63136 examples to avoid logging too frequently
skipping logging after 63152 examples to avoid logging too frequently
train stats after 63168 examples: {'rewards_train/chosen': '-0.33344', 'rewards_train/rejected': '-0.41654', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.083042', 'logps_train/rejected': '-111.78', 'logps_train/chosen': '-142.71', 'loss/train': '0.66724', 'examples_per_second': '5.2246', 'grad_norm': '21.875', 'counters/examples': 63168, 'counters/updates': 3948}
skipping logging after 63184 examples to avoid logging too frequently
skipping logging after 63200 examples to avoid logging too frequently
skipping logging after 63216 examples to avoid logging too frequently
train stats after 63232 examples: {'rewards_train/chosen': '-0.30503', 'rewards_train/rejected': '-0.46651', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.16152', 'logps_train/rejected': '-129.33', 'logps_train/chosen': '-147.02', 'loss/train': '0.63541', 'examples_per_second': '4.8116', 'grad_norm': '19.5', 'counters/examples': 63232, 'counters/updates': 3952}
skipping logging after 63248 examples to avoid logging too frequently
skipping logging after 63264 examples to avoid logging too frequently
skipping logging after 63280 examples to avoid logging too frequently
train stats after 63296 examples: {'rewards_train/chosen': '-0.37302', 'rewards_train/rejected': '-0.47773', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.10477', 'logps_train/rejected': '-115.9', 'logps_train/chosen': '-128.14', 'loss/train': '0.66669', 'examples_per_second': '6.0402', 'grad_norm': '18.375', 'counters/examples': 63296, 'counters/updates': 3956}
skipping logging after 63312 examples to avoid logging too frequently
skipping logging after 63328 examples to avoid logging too frequently
skipping logging after 63344 examples to avoid logging too frequently
train stats after 63360 examples: {'rewards_train/chosen': '-0.33126', 'rewards_train/rejected': '-0.45605', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.12492', 'logps_train/rejected': '-131.19', 'logps_train/chosen': '-138.66', 'loss/train': '0.64798', 'examples_per_second': '4.6665', 'grad_norm': '19.625', 'counters/examples': 63360, 'counters/updates': 3960}
skipping logging after 63376 examples to avoid logging too frequently
skipping logging after 63392 examples to avoid logging too frequently
skipping logging after 63408 examples to avoid logging too frequently
train stats after 63424 examples: {'rewards_train/chosen': '-0.33198', 'rewards_train/rejected': '-0.4795', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.1474', 'logps_train/rejected': '-113.78', 'logps_train/chosen': '-102.7', 'loss/train': '0.63687', 'examples_per_second': '5.0019', 'grad_norm': '15.188', 'counters/examples': 63424, 'counters/updates': 3964}
skipping logging after 63440 examples to avoid logging too frequently
skipping logging after 63456 examples to avoid logging too frequently
skipping logging after 63472 examples to avoid logging too frequently
train stats after 63488 examples: {'rewards_train/chosen': '-0.39366', 'rewards_train/rejected': '-0.48361', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.089935', 'logps_train/rejected': '-138.8', 'logps_train/chosen': '-98.81', 'loss/train': '0.66187', 'examples_per_second': '4.7377', 'grad_norm': '18', 'counters/examples': 63488, 'counters/updates': 3968}
Running evaluation after 63488 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 63488: {'rewards_eval/chosen': '-0.34711', 'rewards_eval/rejected': '-0.43114', 'rewards_eval/accuracies': '0.54883', 'rewards_eval/margins': '0.084005', 'logps_eval/rejected': '-126.47', 'logps_eval/chosen': '-121.97', 'loss/eval': '0.67408'}
skipping logging after 63504 examples to avoid logging too frequently
skipping logging after 63520 examples to avoid logging too frequently
skipping logging after 63536 examples to avoid logging too frequently
train stats after 63552 examples: {'rewards_train/chosen': '-0.32598', 'rewards_train/rejected': '-0.43821', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.11216', 'logps_train/rejected': '-121.04', 'logps_train/chosen': '-123.13', 'loss/train': '0.66496', 'examples_per_second': '6.7607', 'grad_norm': '18', 'counters/examples': 63552, 'counters/updates': 3972}
skipping logging after 63568 examples to avoid logging too frequently
skipping logging after 63584 examples to avoid logging too frequently
skipping logging after 63600 examples to avoid logging too frequently
train stats after 63616 examples: {'rewards_train/chosen': '-0.3688', 'rewards_train/rejected': '-0.52633', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.15758', 'logps_train/rejected': '-141.17', 'logps_train/chosen': '-127.87', 'loss/train': '0.64986', 'examples_per_second': '6.3795', 'grad_norm': '23', 'counters/examples': 63616, 'counters/updates': 3976}
skipping logging after 63632 examples to avoid logging too frequently
skipping logging after 63648 examples to avoid logging too frequently
skipping logging after 63664 examples to avoid logging too frequently
train stats after 63680 examples: {'rewards_train/chosen': '-0.27474', 'rewards_train/rejected': '-0.4744', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.19975', 'logps_train/rejected': '-121.2', 'logps_train/chosen': '-132.41', 'loss/train': '0.62128', 'examples_per_second': '5.9586', 'grad_norm': '17.625', 'counters/examples': 63680, 'counters/updates': 3980}
skipping logging after 63696 examples to avoid logging too frequently
skipping logging after 63712 examples to avoid logging too frequently
skipping logging after 63728 examples to avoid logging too frequently
train stats after 63744 examples: {'rewards_train/chosen': '-0.36516', 'rewards_train/rejected': '-0.49074', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.12572', 'logps_train/rejected': '-122.99', 'logps_train/chosen': '-122.53', 'loss/train': '0.65677', 'examples_per_second': '5.8198', 'grad_norm': '19.75', 'counters/examples': 63744, 'counters/updates': 3984}
skipping logging after 63760 examples to avoid logging too frequently
skipping logging after 63776 examples to avoid logging too frequently
skipping logging after 63792 examples to avoid logging too frequently
train stats after 63808 examples: {'rewards_train/chosen': '-0.32966', 'rewards_train/rejected': '-0.50378', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.17414', 'logps_train/rejected': '-108.91', 'logps_train/chosen': '-108.91', 'loss/train': '0.63002', 'examples_per_second': '4.9967', 'grad_norm': '16.875', 'counters/examples': 63808, 'counters/updates': 3988}
skipping logging after 63824 examples to avoid logging too frequently
skipping logging after 63840 examples to avoid logging too frequently
skipping logging after 63856 examples to avoid logging too frequently
train stats after 63872 examples: {'rewards_train/chosen': '-0.36098', 'rewards_train/rejected': '-0.50288', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.14185', 'logps_train/rejected': '-105.01', 'logps_train/chosen': '-131.36', 'loss/train': '0.63824', 'examples_per_second': '4.6655', 'grad_norm': '19.5', 'counters/examples': 63872, 'counters/updates': 3992}
skipping logging after 63888 examples to avoid logging too frequently
skipping logging after 63904 examples to avoid logging too frequently
skipping logging after 63920 examples to avoid logging too frequently
train stats after 63936 examples: {'rewards_train/chosen': '-0.31027', 'rewards_train/rejected': '-0.48389', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.17379', 'logps_train/rejected': '-132.04', 'logps_train/chosen': '-137.64', 'loss/train': '0.63356', 'examples_per_second': '4.8481', 'grad_norm': '19.125', 'counters/examples': 63936, 'counters/updates': 3996}
skipping logging after 63952 examples to avoid logging too frequently
skipping logging after 63968 examples to avoid logging too frequently
skipping logging after 63984 examples to avoid logging too frequently
train stats after 64000 examples: {'rewards_train/chosen': '-0.32821', 'rewards_train/rejected': '-0.4579', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.12968', 'logps_train/rejected': '-141.01', 'logps_train/chosen': '-166.06', 'loss/train': '0.66022', 'examples_per_second': '4.744', 'grad_norm': '23.25', 'counters/examples': 64000, 'counters/updates': 4000}
skipping logging after 64016 examples to avoid logging too frequently
skipping logging after 64032 examples to avoid logging too frequently
skipping logging after 64048 examples to avoid logging too frequently
train stats after 64064 examples: {'rewards_train/chosen': '-0.49783', 'rewards_train/rejected': '-0.71097', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.2131', 'logps_train/rejected': '-136.33', 'logps_train/chosen': '-119.43', 'loss/train': '0.61688', 'examples_per_second': '3.7881', 'grad_norm': '18.875', 'counters/examples': 64064, 'counters/updates': 4004}
skipping logging after 64080 examples to avoid logging too frequently
skipping logging after 64096 examples to avoid logging too frequently
skipping logging after 64112 examples to avoid logging too frequently
train stats after 64128 examples: {'rewards_train/chosen': '-0.57329', 'rewards_train/rejected': '-0.76246', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.18923', 'logps_train/rejected': '-119.63', 'logps_train/chosen': '-117.17', 'loss/train': '0.62691', 'examples_per_second': '5.1667', 'grad_norm': '18.125', 'counters/examples': 64128, 'counters/updates': 4008}
skipping logging after 64144 examples to avoid logging too frequently
skipping logging after 64160 examples to avoid logging too frequently
skipping logging after 64176 examples to avoid logging too frequently
train stats after 64192 examples: {'rewards_train/chosen': '-0.58242', 'rewards_train/rejected': '-0.75374', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.17122', 'logps_train/rejected': '-114.86', 'logps_train/chosen': '-131.21', 'loss/train': '0.64287', 'examples_per_second': '4.7174', 'grad_norm': '22.25', 'counters/examples': 64192, 'counters/updates': 4012}
skipping logging after 64208 examples to avoid logging too frequently
skipping logging after 64224 examples to avoid logging too frequently
skipping logging after 64240 examples to avoid logging too frequently
train stats after 64256 examples: {'rewards_train/chosen': '-0.32848', 'rewards_train/rejected': '-0.47649', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.14801', 'logps_train/rejected': '-136.05', 'logps_train/chosen': '-117.81', 'loss/train': '0.64816', 'examples_per_second': '4.7427', 'grad_norm': '19.25', 'counters/examples': 64256, 'counters/updates': 4016}
skipping logging after 64272 examples to avoid logging too frequently
skipping logging after 64288 examples to avoid logging too frequently
skipping logging after 64304 examples to avoid logging too frequently
train stats after 64320 examples: {'rewards_train/chosen': '-0.53437', 'rewards_train/rejected': '-0.66823', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.13382', 'logps_train/rejected': '-110.03', 'logps_train/chosen': '-131.56', 'loss/train': '0.6507', 'examples_per_second': '5.4247', 'grad_norm': '20.875', 'counters/examples': 64320, 'counters/updates': 4020}
skipping logging after 64336 examples to avoid logging too frequently
skipping logging after 64352 examples to avoid logging too frequently
skipping logging after 64368 examples to avoid logging too frequently
train stats after 64384 examples: {'rewards_train/chosen': '-0.43038', 'rewards_train/rejected': '-0.52303', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.092655', 'logps_train/rejected': '-121.14', 'logps_train/chosen': '-114.9', 'loss/train': '0.67166', 'examples_per_second': '4.2955', 'grad_norm': '19', 'counters/examples': 64384, 'counters/updates': 4024}
skipping logging after 64400 examples to avoid logging too frequently
skipping logging after 64416 examples to avoid logging too frequently
skipping logging after 64432 examples to avoid logging too frequently
train stats after 64448 examples: {'rewards_train/chosen': '-0.44255', 'rewards_train/rejected': '-0.54682', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.10424', 'logps_train/rejected': '-116.31', 'logps_train/chosen': '-109.63', 'loss/train': '0.66385', 'examples_per_second': '6.8659', 'grad_norm': '18.125', 'counters/examples': 64448, 'counters/updates': 4028}
skipping logging after 64464 examples to avoid logging too frequently
skipping logging after 64480 examples to avoid logging too frequently
Running evaluation after 64480 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:07,  2.16s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:02,  2.09s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.88s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.87s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.25s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.29s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 64480: {'rewards_eval/chosen': '-0.44579', 'rewards_eval/rejected': '-0.54675', 'rewards_eval/accuracies': '0.54102', 'rewards_eval/margins': '0.10101', 'logps_eval/rejected': '-127.62', 'logps_eval/chosen': '-122.95', 'loss/eval': '0.67216'}
skipping logging after 64496 examples to avoid logging too frequently
train stats after 64512 examples: {'rewards_train/chosen': '-0.45716', 'rewards_train/rejected': '-0.60127', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.14425', 'logps_train/rejected': '-122.41', 'logps_train/chosen': '-131.69', 'loss/train': '0.65118', 'examples_per_second': '5.2035', 'grad_norm': '19', 'counters/examples': 64512, 'counters/updates': 4032}
skipping logging after 64528 examples to avoid logging too frequently
skipping logging after 64544 examples to avoid logging too frequently
skipping logging after 64560 examples to avoid logging too frequently
train stats after 64576 examples: {'rewards_train/chosen': '-0.47284', 'rewards_train/rejected': '-0.58912', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.11625', 'logps_train/rejected': '-125.89', 'logps_train/chosen': '-109.92', 'loss/train': '0.66322', 'examples_per_second': '4.7161', 'grad_norm': '19.5', 'counters/examples': 64576, 'counters/updates': 4036}
skipping logging after 64592 examples to avoid logging too frequently
skipping logging after 64608 examples to avoid logging too frequently
skipping logging after 64624 examples to avoid logging too frequently
train stats after 64640 examples: {'rewards_train/chosen': '-0.38721', 'rewards_train/rejected': '-0.46201', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.074772', 'logps_train/rejected': '-95.095', 'logps_train/chosen': '-86.982', 'loss/train': '0.67673', 'examples_per_second': '5.6958', 'grad_norm': '15.938', 'counters/examples': 64640, 'counters/updates': 4040}
skipping logging after 64656 examples to avoid logging too frequently
skipping logging after 64672 examples to avoid logging too frequently
skipping logging after 64688 examples to avoid logging too frequently
train stats after 64704 examples: {'rewards_train/chosen': '-0.45963', 'rewards_train/rejected': '-0.47384', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.014282', 'logps_train/rejected': '-150.83', 'logps_train/chosen': '-131.26', 'loss/train': '0.71863', 'examples_per_second': '4.6887', 'grad_norm': '21.5', 'counters/examples': 64704, 'counters/updates': 4044}
skipping logging after 64720 examples to avoid logging too frequently
skipping logging after 64736 examples to avoid logging too frequently
skipping logging after 64752 examples to avoid logging too frequently
train stats after 64768 examples: {'rewards_train/chosen': '-0.38089', 'rewards_train/rejected': '-0.40166', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.020834', 'logps_train/rejected': '-129.33', 'logps_train/chosen': '-113.74', 'loss/train': '0.70129', 'examples_per_second': '5.4869', 'grad_norm': '22.375', 'counters/examples': 64768, 'counters/updates': 4048}
skipping logging after 64784 examples to avoid logging too frequently
skipping logging after 64800 examples to avoid logging too frequently
skipping logging after 64816 examples to avoid logging too frequently
train stats after 64832 examples: {'rewards_train/chosen': '-0.46121', 'rewards_train/rejected': '-0.52808', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.066925', 'logps_train/rejected': '-133.92', 'logps_train/chosen': '-131.09', 'loss/train': '0.67807', 'examples_per_second': '4.2259', 'grad_norm': '17.5', 'counters/examples': 64832, 'counters/updates': 4052}
skipping logging after 64848 examples to avoid logging too frequently
skipping logging after 64864 examples to avoid logging too frequently
skipping logging after 64880 examples to avoid logging too frequently
train stats after 64896 examples: {'rewards_train/chosen': '-0.47499', 'rewards_train/rejected': '-0.59353', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.11846', 'logps_train/rejected': '-110.31', 'logps_train/chosen': '-126.25', 'loss/train': '0.65237', 'examples_per_second': '4.9823', 'grad_norm': '17.125', 'counters/examples': 64896, 'counters/updates': 4056}
skipping logging after 64912 examples to avoid logging too frequently
skipping logging after 64928 examples to avoid logging too frequently
skipping logging after 64944 examples to avoid logging too frequently
train stats after 64960 examples: {'rewards_train/chosen': '-0.40788', 'rewards_train/rejected': '-0.45014', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.042107', 'logps_train/rejected': '-120.81', 'logps_train/chosen': '-145.19', 'loss/train': '0.707', 'examples_per_second': '4.5964', 'grad_norm': '21.5', 'counters/examples': 64960, 'counters/updates': 4060}
skipping logging after 64976 examples to avoid logging too frequently
skipping logging after 64992 examples to avoid logging too frequently
skipping logging after 65008 examples to avoid logging too frequently
train stats after 65024 examples: {'rewards_train/chosen': '-0.44725', 'rewards_train/rejected': '-0.52762', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.080345', 'logps_train/rejected': '-116.71', 'logps_train/chosen': '-121.89', 'loss/train': '0.66849', 'examples_per_second': '4.9791', 'grad_norm': '18.75', 'counters/examples': 65024, 'counters/updates': 4064}
skipping logging after 65040 examples to avoid logging too frequently
skipping logging after 65056 examples to avoid logging too frequently
skipping logging after 65072 examples to avoid logging too frequently
train stats after 65088 examples: {'rewards_train/chosen': '-0.47083', 'rewards_train/rejected': '-0.68929', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.21854', 'logps_train/rejected': '-123.73', 'logps_train/chosen': '-121.73', 'loss/train': '0.62251', 'examples_per_second': '4.0349', 'grad_norm': '15.312', 'counters/examples': 65088, 'counters/updates': 4068}
skipping logging after 65104 examples to avoid logging too frequently
skipping logging after 65120 examples to avoid logging too frequently
skipping logging after 65136 examples to avoid logging too frequently
train stats after 65152 examples: {'rewards_train/chosen': '-0.46329', 'rewards_train/rejected': '-0.62002', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.15684', 'logps_train/rejected': '-106.44', 'logps_train/chosen': '-114.88', 'loss/train': '0.64391', 'examples_per_second': '6.0623', 'grad_norm': '16.25', 'counters/examples': 65152, 'counters/updates': 4072}
skipping logging after 65168 examples to avoid logging too frequently
skipping logging after 65184 examples to avoid logging too frequently
skipping logging after 65200 examples to avoid logging too frequently
train stats after 65216 examples: {'rewards_train/chosen': '-0.49842', 'rewards_train/rejected': '-0.60419', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.10582', 'logps_train/rejected': '-127.78', 'logps_train/chosen': '-135.24', 'loss/train': '0.6631', 'examples_per_second': '5.4647', 'grad_norm': '16.125', 'counters/examples': 65216, 'counters/updates': 4076}
skipping logging after 65232 examples to avoid logging too frequently
skipping logging after 65248 examples to avoid logging too frequently
skipping logging after 65264 examples to avoid logging too frequently
train stats after 65280 examples: {'rewards_train/chosen': '-0.51778', 'rewards_train/rejected': '-0.53605', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.018311', 'logps_train/rejected': '-137.85', 'logps_train/chosen': '-151.81', 'loss/train': '0.70596', 'examples_per_second': '5.7846', 'grad_norm': '20.375', 'counters/examples': 65280, 'counters/updates': 4080}
skipping logging after 65296 examples to avoid logging too frequently
skipping logging after 65312 examples to avoid logging too frequently
skipping logging after 65328 examples to avoid logging too frequently
train stats after 65344 examples: {'rewards_train/chosen': '-0.39355', 'rewards_train/rejected': '-0.53601', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.14253', 'logps_train/rejected': '-131.99', 'logps_train/chosen': '-122.74', 'loss/train': '0.65504', 'examples_per_second': '4.0897', 'grad_norm': '16.75', 'counters/examples': 65344, 'counters/updates': 4084}
skipping logging after 65360 examples to avoid logging too frequently
skipping logging after 65376 examples to avoid logging too frequently
skipping logging after 65392 examples to avoid logging too frequently
train stats after 65408 examples: {'rewards_train/chosen': '-0.29046', 'rewards_train/rejected': '-0.4537', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.1632', 'logps_train/rejected': '-121.27', 'logps_train/chosen': '-138.98', 'loss/train': '0.63713', 'examples_per_second': '5.4279', 'grad_norm': '18.5', 'counters/examples': 65408, 'counters/updates': 4088}
skipping logging after 65424 examples to avoid logging too frequently
skipping logging after 65440 examples to avoid logging too frequently
skipping logging after 65456 examples to avoid logging too frequently
train stats after 65472 examples: {'rewards_train/chosen': '-0.47384', 'rewards_train/rejected': '-0.48322', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.0093899', 'logps_train/rejected': '-91.138', 'logps_train/chosen': '-108.47', 'loss/train': '0.70587', 'examples_per_second': '6.5875', 'grad_norm': '19.5', 'counters/examples': 65472, 'counters/updates': 4092}
Running evaluation after 65472 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.53s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 65472: {'rewards_eval/chosen': '-0.42436', 'rewards_eval/rejected': '-0.5174', 'rewards_eval/accuracies': '0.55078', 'rewards_eval/margins': '0.093004', 'logps_eval/rejected': '-127.33', 'logps_eval/chosen': '-122.74', 'loss/eval': '0.67299'}
skipping logging after 65488 examples to avoid logging too frequently
skipping logging after 65504 examples to avoid logging too frequently
skipping logging after 65520 examples to avoid logging too frequently
train stats after 65536 examples: {'rewards_train/chosen': '-0.38443', 'rewards_train/rejected': '-0.345', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '-0.039471', 'logps_train/rejected': '-123.93', 'logps_train/chosen': '-123.75', 'loss/train': '0.72729', 'examples_per_second': '5.1372', 'grad_norm': '17.625', 'counters/examples': 65536, 'counters/updates': 4096}
skipping logging after 65552 examples to avoid logging too frequently
skipping logging after 65568 examples to avoid logging too frequently
skipping logging after 65584 examples to avoid logging too frequently
train stats after 65600 examples: {'rewards_train/chosen': '-0.3457', 'rewards_train/rejected': '-0.50966', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.16381', 'logps_train/rejected': '-109.65', 'logps_train/chosen': '-116.53', 'loss/train': '0.65042', 'examples_per_second': '4.9072', 'grad_norm': '25.75', 'counters/examples': 65600, 'counters/updates': 4100}
skipping logging after 65616 examples to avoid logging too frequently
skipping logging after 65632 examples to avoid logging too frequently
skipping logging after 65648 examples to avoid logging too frequently
train stats after 65664 examples: {'rewards_train/chosen': '-0.36929', 'rewards_train/rejected': '-0.41959', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.050388', 'logps_train/rejected': '-127.18', 'logps_train/chosen': '-122.91', 'loss/train': '0.68765', 'examples_per_second': '5.0984', 'grad_norm': '18.5', 'counters/examples': 65664, 'counters/updates': 4104}
skipping logging after 65680 examples to avoid logging too frequently
skipping logging after 65696 examples to avoid logging too frequently
skipping logging after 65712 examples to avoid logging too frequently
train stats after 65728 examples: {'rewards_train/chosen': '-0.35988', 'rewards_train/rejected': '-0.4637', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.10384', 'logps_train/rejected': '-117.2', 'logps_train/chosen': '-106.55', 'loss/train': '0.6651', 'examples_per_second': '5.5054', 'grad_norm': '18', 'counters/examples': 65728, 'counters/updates': 4108}
skipping logging after 65744 examples to avoid logging too frequently
skipping logging after 65760 examples to avoid logging too frequently
skipping logging after 65776 examples to avoid logging too frequently
train stats after 65792 examples: {'rewards_train/chosen': '-0.36989', 'rewards_train/rejected': '-0.52573', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.1559', 'logps_train/rejected': '-134.02', 'logps_train/chosen': '-125.74', 'loss/train': '0.64366', 'examples_per_second': '4.6869', 'grad_norm': '19.75', 'counters/examples': 65792, 'counters/updates': 4112}
skipping logging after 65808 examples to avoid logging too frequently
skipping logging after 65824 examples to avoid logging too frequently
skipping logging after 65840 examples to avoid logging too frequently
train stats after 65856 examples: {'rewards_train/chosen': '-0.30062', 'rewards_train/rejected': '-0.46724', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.16665', 'logps_train/rejected': '-117.64', 'logps_train/chosen': '-112.96', 'loss/train': '0.63425', 'examples_per_second': '6.2578', 'grad_norm': '23.375', 'counters/examples': 65856, 'counters/updates': 4116}
skipping logging after 65872 examples to avoid logging too frequently
skipping logging after 65888 examples to avoid logging too frequently
skipping logging after 65904 examples to avoid logging too frequently
train stats after 65920 examples: {'rewards_train/chosen': '-0.38878', 'rewards_train/rejected': '-0.45683', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.067978', 'logps_train/rejected': '-116.86', 'logps_train/chosen': '-115.85', 'loss/train': '0.67468', 'examples_per_second': '4.8923', 'grad_norm': '16.75', 'counters/examples': 65920, 'counters/updates': 4120}
skipping logging after 65936 examples to avoid logging too frequently
skipping logging after 65952 examples to avoid logging too frequently
skipping logging after 65968 examples to avoid logging too frequently
train stats after 65984 examples: {'rewards_train/chosen': '-0.346', 'rewards_train/rejected': '-0.41129', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.065138', 'logps_train/rejected': '-147.31', 'logps_train/chosen': '-137.71', 'loss/train': '0.68741', 'examples_per_second': '3.7176', 'grad_norm': '20.5', 'counters/examples': 65984, 'counters/updates': 4124}
skipping logging after 66000 examples to avoid logging too frequently
skipping logging after 66016 examples to avoid logging too frequently
skipping logging after 66032 examples to avoid logging too frequently
train stats after 66048 examples: {'rewards_train/chosen': '-0.3826', 'rewards_train/rejected': '-0.46542', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.082764', 'logps_train/rejected': '-86.484', 'logps_train/chosen': '-106.22', 'loss/train': '0.66841', 'examples_per_second': '4.8509', 'grad_norm': '16.375', 'counters/examples': 66048, 'counters/updates': 4128}
skipping logging after 66064 examples to avoid logging too frequently
skipping logging after 66080 examples to avoid logging too frequently
skipping logging after 66096 examples to avoid logging too frequently
train stats after 66112 examples: {'rewards_train/chosen': '-0.44791', 'rewards_train/rejected': '-0.61454', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.16663', 'logps_train/rejected': '-137.71', 'logps_train/chosen': '-134.44', 'loss/train': '0.63239', 'examples_per_second': '4.3632', 'grad_norm': '19', 'counters/examples': 66112, 'counters/updates': 4132}
skipping logging after 66128 examples to avoid logging too frequently
skipping logging after 66144 examples to avoid logging too frequently
skipping logging after 66160 examples to avoid logging too frequently
train stats after 66176 examples: {'rewards_train/chosen': '-0.38816', 'rewards_train/rejected': '-0.55159', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.16345', 'logps_train/rejected': '-118.55', 'logps_train/chosen': '-111.76', 'loss/train': '0.63568', 'examples_per_second': '5.5865', 'grad_norm': '17.25', 'counters/examples': 66176, 'counters/updates': 4136}
skipping logging after 66192 examples to avoid logging too frequently
skipping logging after 66208 examples to avoid logging too frequently
skipping logging after 66224 examples to avoid logging too frequently
train stats after 66240 examples: {'rewards_train/chosen': '-0.38266', 'rewards_train/rejected': '-0.47888', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.096249', 'logps_train/rejected': '-108.67', 'logps_train/chosen': '-104.08', 'loss/train': '0.67223', 'examples_per_second': '5.6984', 'grad_norm': '17.125', 'counters/examples': 66240, 'counters/updates': 4140}
skipping logging after 66256 examples to avoid logging too frequently
skipping logging after 66272 examples to avoid logging too frequently
skipping logging after 66288 examples to avoid logging too frequently
train stats after 66304 examples: {'rewards_train/chosen': '-0.327', 'rewards_train/rejected': '-0.57033', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.24362', 'logps_train/rejected': '-126.87', 'logps_train/chosen': '-95.021', 'loss/train': '0.61046', 'examples_per_second': '5.6131', 'grad_norm': '18.875', 'counters/examples': 66304, 'counters/updates': 4144}
skipping logging after 66320 examples to avoid logging too frequently
skipping logging after 66336 examples to avoid logging too frequently
skipping logging after 66352 examples to avoid logging too frequently
train stats after 66368 examples: {'rewards_train/chosen': '-0.5283', 'rewards_train/rejected': '-0.59431', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.066021', 'logps_train/rejected': '-130.18', 'logps_train/chosen': '-146.21', 'loss/train': '0.69411', 'examples_per_second': '5.1357', 'grad_norm': '25.75', 'counters/examples': 66368, 'counters/updates': 4148}
skipping logging after 66384 examples to avoid logging too frequently
skipping logging after 66400 examples to avoid logging too frequently
skipping logging after 66416 examples to avoid logging too frequently
train stats after 66432 examples: {'rewards_train/chosen': '-0.40771', 'rewards_train/rejected': '-0.46913', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.061504', 'logps_train/rejected': '-131.25', 'logps_train/chosen': '-104.77', 'loss/train': '0.6897', 'examples_per_second': '5.3472', 'grad_norm': '20.125', 'counters/examples': 66432, 'counters/updates': 4152}
skipping logging after 66448 examples to avoid logging too frequently
skipping logging after 66464 examples to avoid logging too frequently
Running evaluation after 66464 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:11,  2.30s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:04,  2.15s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:55,  1.90s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.88s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.54s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 66464: {'rewards_eval/chosen': '-0.3943', 'rewards_eval/rejected': '-0.48078', 'rewards_eval/accuracies': '0.53125', 'rewards_eval/margins': '0.086505', 'logps_eval/rejected': '-126.96', 'logps_eval/chosen': '-122.44', 'loss/eval': '0.67591'}
skipping logging after 66480 examples to avoid logging too frequently
train stats after 66496 examples: {'rewards_train/chosen': '-0.39024', 'rewards_train/rejected': '-0.5219', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.13181', 'logps_train/rejected': '-116.44', 'logps_train/chosen': '-103.11', 'loss/train': '0.66334', 'examples_per_second': '5.996', 'grad_norm': '15.562', 'counters/examples': 66496, 'counters/updates': 4156}
skipping logging after 66512 examples to avoid logging too frequently
skipping logging after 66528 examples to avoid logging too frequently
skipping logging after 66544 examples to avoid logging too frequently
train stats after 66560 examples: {'rewards_train/chosen': '-0.41896', 'rewards_train/rejected': '-0.57479', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.1558', 'logps_train/rejected': '-140.14', 'logps_train/chosen': '-119.12', 'loss/train': '0.64078', 'examples_per_second': '5.3012', 'grad_norm': '18.75', 'counters/examples': 66560, 'counters/updates': 4160}
skipping logging after 66576 examples to avoid logging too frequently
skipping logging after 66592 examples to avoid logging too frequently
skipping logging after 66608 examples to avoid logging too frequently
train stats after 66624 examples: {'rewards_train/chosen': '-0.43891', 'rewards_train/rejected': '-0.61515', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.17643', 'logps_train/rejected': '-101.45', 'logps_train/chosen': '-116.94', 'loss/train': '0.6346', 'examples_per_second': '6.4711', 'grad_norm': '25.125', 'counters/examples': 66624, 'counters/updates': 4164}
skipping logging after 66640 examples to avoid logging too frequently
skipping logging after 66656 examples to avoid logging too frequently
skipping logging after 66672 examples to avoid logging too frequently
train stats after 66688 examples: {'rewards_train/chosen': '-0.29642', 'rewards_train/rejected': '-0.43235', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.13594', 'logps_train/rejected': '-119.68', 'logps_train/chosen': '-107.46', 'loss/train': '0.64496', 'examples_per_second': '5.644', 'grad_norm': '16.75', 'counters/examples': 66688, 'counters/updates': 4168}
skipping logging after 66704 examples to avoid logging too frequently
skipping logging after 66720 examples to avoid logging too frequently
skipping logging after 66736 examples to avoid logging too frequently
train stats after 66752 examples: {'rewards_train/chosen': '-0.36946', 'rewards_train/rejected': '-0.45126', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.081799', 'logps_train/rejected': '-147.18', 'logps_train/chosen': '-115.39', 'loss/train': '0.67848', 'examples_per_second': '5.4197', 'grad_norm': '18.75', 'counters/examples': 66752, 'counters/updates': 4172}
skipping logging after 66768 examples to avoid logging too frequently
skipping logging after 66784 examples to avoid logging too frequently
skipping logging after 66800 examples to avoid logging too frequently
train stats after 66816 examples: {'rewards_train/chosen': '-0.38937', 'rewards_train/rejected': '-0.52366', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.13428', 'logps_train/rejected': '-116', 'logps_train/chosen': '-124.12', 'loss/train': '0.65756', 'examples_per_second': '4.9903', 'grad_norm': '16.625', 'counters/examples': 66816, 'counters/updates': 4176}
skipping logging after 66832 examples to avoid logging too frequently
skipping logging after 66848 examples to avoid logging too frequently
skipping logging after 66864 examples to avoid logging too frequently
train stats after 66880 examples: {'rewards_train/chosen': '-0.36002', 'rewards_train/rejected': '-0.36503', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.0049095', 'logps_train/rejected': '-123.82', 'logps_train/chosen': '-114.17', 'loss/train': '0.70575', 'examples_per_second': '4.6264', 'grad_norm': '18', 'counters/examples': 66880, 'counters/updates': 4180}
skipping logging after 66896 examples to avoid logging too frequently
skipping logging after 66912 examples to avoid logging too frequently
skipping logging after 66928 examples to avoid logging too frequently
train stats after 66944 examples: {'rewards_train/chosen': '-0.33361', 'rewards_train/rejected': '-0.5206', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.1871', 'logps_train/rejected': '-121.45', 'logps_train/chosen': '-105.51', 'loss/train': '0.62497', 'examples_per_second': '5.4412', 'grad_norm': '17', 'counters/examples': 66944, 'counters/updates': 4184}
skipping logging after 66960 examples to avoid logging too frequently
skipping logging after 66976 examples to avoid logging too frequently
skipping logging after 66992 examples to avoid logging too frequently
train stats after 67008 examples: {'rewards_train/chosen': '-0.41657', 'rewards_train/rejected': '-0.44225', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.025818', 'logps_train/rejected': '-135.6', 'logps_train/chosen': '-129.45', 'loss/train': '0.70676', 'examples_per_second': '4.1175', 'grad_norm': '20', 'counters/examples': 67008, 'counters/updates': 4188}
skipping logging after 67024 examples to avoid logging too frequently
skipping logging after 67040 examples to avoid logging too frequently
skipping logging after 67056 examples to avoid logging too frequently
train stats after 67072 examples: {'rewards_train/chosen': '-0.43424', 'rewards_train/rejected': '-0.60787', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.1736', 'logps_train/rejected': '-118.96', 'logps_train/chosen': '-116.91', 'loss/train': '0.6301', 'examples_per_second': '5.3749', 'grad_norm': '15.438', 'counters/examples': 67072, 'counters/updates': 4192}
skipping logging after 67088 examples to avoid logging too frequently
skipping logging after 67104 examples to avoid logging too frequently
skipping logging after 67120 examples to avoid logging too frequently
train stats after 67136 examples: {'rewards_train/chosen': '-0.43143', 'rewards_train/rejected': '-0.53384', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.10236', 'logps_train/rejected': '-116.46', 'logps_train/chosen': '-120.98', 'loss/train': '0.66507', 'examples_per_second': '6.2606', 'grad_norm': '16.375', 'counters/examples': 67136, 'counters/updates': 4196}
skipping logging after 67152 examples to avoid logging too frequently
skipping logging after 67168 examples to avoid logging too frequently
skipping logging after 67184 examples to avoid logging too frequently
train stats after 67200 examples: {'rewards_train/chosen': '-0.40657', 'rewards_train/rejected': '-0.55118', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.14473', 'logps_train/rejected': '-135.95', 'logps_train/chosen': '-132.4', 'loss/train': '0.65434', 'examples_per_second': '5.238', 'grad_norm': '16.25', 'counters/examples': 67200, 'counters/updates': 4200}
skipping logging after 67216 examples to avoid logging too frequently
skipping logging after 67232 examples to avoid logging too frequently
skipping logging after 67248 examples to avoid logging too frequently
train stats after 67264 examples: {'rewards_train/chosen': '-0.42958', 'rewards_train/rejected': '-0.50221', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.072678', 'logps_train/rejected': '-125.07', 'logps_train/chosen': '-128.41', 'loss/train': '0.68179', 'examples_per_second': '5.5061', 'grad_norm': '19.25', 'counters/examples': 67264, 'counters/updates': 4204}
skipping logging after 67280 examples to avoid logging too frequently
skipping logging after 67296 examples to avoid logging too frequently
skipping logging after 67312 examples to avoid logging too frequently
train stats after 67328 examples: {'rewards_train/chosen': '-0.49535', 'rewards_train/rejected': '-0.54508', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.049648', 'logps_train/rejected': '-134.4', 'logps_train/chosen': '-123.47', 'loss/train': '0.68817', 'examples_per_second': '4.6154', 'grad_norm': '17.75', 'counters/examples': 67328, 'counters/updates': 4208}
skipping logging after 67344 examples to avoid logging too frequently
skipping logging after 67360 examples to avoid logging too frequently
skipping logging after 67376 examples to avoid logging too frequently
train stats after 67392 examples: {'rewards_train/chosen': '-0.44384', 'rewards_train/rejected': '-0.47867', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.034859', 'logps_train/rejected': '-129.13', 'logps_train/chosen': '-150.54', 'loss/train': '0.69801', 'examples_per_second': '4.9053', 'grad_norm': '24.625', 'counters/examples': 67392, 'counters/updates': 4212}
skipping logging after 67408 examples to avoid logging too frequently
skipping logging after 67424 examples to avoid logging too frequently
skipping logging after 67440 examples to avoid logging too frequently
train stats after 67456 examples: {'rewards_train/chosen': '-0.3495', 'rewards_train/rejected': '-0.38356', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.033968', 'logps_train/rejected': '-159.09', 'logps_train/chosen': '-140.81', 'loss/train': '0.70361', 'examples_per_second': '5.0752', 'grad_norm': '19.5', 'counters/examples': 67456, 'counters/updates': 4216}
Running evaluation after 67456 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.46s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.53s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 67456: {'rewards_eval/chosen': '-0.37832', 'rewards_eval/rejected': '-0.46125', 'rewards_eval/accuracies': '0.53711', 'rewards_eval/margins': '0.082924', 'logps_eval/rejected': '-126.77', 'logps_eval/chosen': '-122.28', 'loss/eval': '0.6757'}
skipping logging after 67472 examples to avoid logging too frequently
skipping logging after 67488 examples to avoid logging too frequently
skipping logging after 67504 examples to avoid logging too frequently
train stats after 67520 examples: {'rewards_train/chosen': '-0.34089', 'rewards_train/rejected': '-0.51471', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.17385', 'logps_train/rejected': '-142.61', 'logps_train/chosen': '-133.02', 'loss/train': '0.63165', 'examples_per_second': '5.2649', 'grad_norm': '17', 'counters/examples': 67520, 'counters/updates': 4220}
skipping logging after 67536 examples to avoid logging too frequently
skipping logging after 67552 examples to avoid logging too frequently
skipping logging after 67568 examples to avoid logging too frequently
train stats after 67584 examples: {'rewards_train/chosen': '-0.32842', 'rewards_train/rejected': '-0.49062', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.16204', 'logps_train/rejected': '-118.07', 'logps_train/chosen': '-125.76', 'loss/train': '0.63486', 'examples_per_second': '4.7597', 'grad_norm': '15.875', 'counters/examples': 67584, 'counters/updates': 4224}
skipping logging after 67600 examples to avoid logging too frequently
skipping logging after 67616 examples to avoid logging too frequently
skipping logging after 67632 examples to avoid logging too frequently
train stats after 67648 examples: {'rewards_train/chosen': '-0.36917', 'rewards_train/rejected': '-0.5669', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.19763', 'logps_train/rejected': '-122.55', 'logps_train/chosen': '-123.35', 'loss/train': '0.62077', 'examples_per_second': '4.4221', 'grad_norm': '17.625', 'counters/examples': 67648, 'counters/updates': 4228}
skipping logging after 67664 examples to avoid logging too frequently
skipping logging after 67680 examples to avoid logging too frequently
skipping logging after 67696 examples to avoid logging too frequently
train stats after 67712 examples: {'rewards_train/chosen': '-0.30258', 'rewards_train/rejected': '-0.39987', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.097263', 'logps_train/rejected': '-123.7', 'logps_train/chosen': '-131.5', 'loss/train': '0.67404', 'examples_per_second': '5.7568', 'grad_norm': '17.5', 'counters/examples': 67712, 'counters/updates': 4232}
skipping logging after 67728 examples to avoid logging too frequently
skipping logging after 67744 examples to avoid logging too frequently
skipping logging after 67760 examples to avoid logging too frequently
train stats after 67776 examples: {'rewards_train/chosen': '-0.32722', 'rewards_train/rejected': '-0.45371', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.12656', 'logps_train/rejected': '-112.2', 'logps_train/chosen': '-118.02', 'loss/train': '0.64975', 'examples_per_second': '5.276', 'grad_norm': '17', 'counters/examples': 67776, 'counters/updates': 4236}
skipping logging after 67792 examples to avoid logging too frequently
skipping logging after 67808 examples to avoid logging too frequently
skipping logging after 67824 examples to avoid logging too frequently
train stats after 67840 examples: {'rewards_train/chosen': '-0.27945', 'rewards_train/rejected': '-0.33101', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.051472', 'logps_train/rejected': '-111.47', 'logps_train/chosen': '-109.25', 'loss/train': '0.68954', 'examples_per_second': '3.9376', 'grad_norm': '19.375', 'counters/examples': 67840, 'counters/updates': 4240}
skipping logging after 67856 examples to avoid logging too frequently
skipping logging after 67872 examples to avoid logging too frequently
skipping logging after 67888 examples to avoid logging too frequently
train stats after 67904 examples: {'rewards_train/chosen': '-0.33901', 'rewards_train/rejected': '-0.41543', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.076618', 'logps_train/rejected': '-105', 'logps_train/chosen': '-114.87', 'loss/train': '0.69287', 'examples_per_second': '5.4429', 'grad_norm': '18.625', 'counters/examples': 67904, 'counters/updates': 4244}
skipping logging after 67920 examples to avoid logging too frequently
skipping logging after 67936 examples to avoid logging too frequently
skipping logging after 67952 examples to avoid logging too frequently
train stats after 67968 examples: {'rewards_train/chosen': '-0.41777', 'rewards_train/rejected': '-0.55863', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.14089', 'logps_train/rejected': '-152.36', 'logps_train/chosen': '-149.58', 'loss/train': '0.64996', 'examples_per_second': '5.8298', 'grad_norm': '23.25', 'counters/examples': 67968, 'counters/updates': 4248}
skipping logging after 67984 examples to avoid logging too frequently
skipping logging after 68000 examples to avoid logging too frequently
skipping logging after 68016 examples to avoid logging too frequently
train stats after 68032 examples: {'rewards_train/chosen': '-0.36902', 'rewards_train/rejected': '-0.6059', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.23708', 'logps_train/rejected': '-124.78', 'logps_train/chosen': '-132.5', 'loss/train': '0.61399', 'examples_per_second': '5.3219', 'grad_norm': '15.5', 'counters/examples': 68032, 'counters/updates': 4252}
skipping logging after 68048 examples to avoid logging too frequently
skipping logging after 68064 examples to avoid logging too frequently
skipping logging after 68080 examples to avoid logging too frequently
train stats after 68096 examples: {'rewards_train/chosen': '-0.33404', 'rewards_train/rejected': '-0.40566', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.071651', 'logps_train/rejected': '-114.57', 'logps_train/chosen': '-112.53', 'loss/train': '0.67465', 'examples_per_second': '4.5451', 'grad_norm': '17.125', 'counters/examples': 68096, 'counters/updates': 4256}
skipping logging after 68112 examples to avoid logging too frequently
skipping logging after 68128 examples to avoid logging too frequently
skipping logging after 68144 examples to avoid logging too frequently
train stats after 68160 examples: {'rewards_train/chosen': '-0.33645', 'rewards_train/rejected': '-0.44874', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.11247', 'logps_train/rejected': '-112.21', 'logps_train/chosen': '-133.75', 'loss/train': '0.66005', 'examples_per_second': '4.5503', 'grad_norm': '16.25', 'counters/examples': 68160, 'counters/updates': 4260}
skipping logging after 68176 examples to avoid logging too frequently
skipping logging after 68192 examples to avoid logging too frequently
skipping logging after 68208 examples to avoid logging too frequently
train stats after 68224 examples: {'rewards_train/chosen': '-0.348', 'rewards_train/rejected': '-0.3878', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.039875', 'logps_train/rejected': '-140.11', 'logps_train/chosen': '-132.61', 'loss/train': '0.7001', 'examples_per_second': '3.9991', 'grad_norm': '21.25', 'counters/examples': 68224, 'counters/updates': 4264}
skipping logging after 68240 examples to avoid logging too frequently
skipping logging after 68256 examples to avoid logging too frequently
skipping logging after 68272 examples to avoid logging too frequently
train stats after 68288 examples: {'rewards_train/chosen': '-0.30008', 'rewards_train/rejected': '-0.41486', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.1149', 'logps_train/rejected': '-101.91', 'logps_train/chosen': '-99.038', 'loss/train': '0.66312', 'examples_per_second': '4.7399', 'grad_norm': '17.875', 'counters/examples': 68288, 'counters/updates': 4268}
skipping logging after 68304 examples to avoid logging too frequently
skipping logging after 68320 examples to avoid logging too frequently
skipping logging after 68336 examples to avoid logging too frequently
train stats after 68352 examples: {'rewards_train/chosen': '-0.27123', 'rewards_train/rejected': '-0.49448', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.22338', 'logps_train/rejected': '-123.45', 'logps_train/chosen': '-108.24', 'loss/train': '0.61389', 'examples_per_second': '4.5067', 'grad_norm': '17.625', 'counters/examples': 68352, 'counters/updates': 4272}
skipping logging after 68368 examples to avoid logging too frequently
skipping logging after 68384 examples to avoid logging too frequently
skipping logging after 68400 examples to avoid logging too frequently
train stats after 68416 examples: {'rewards_train/chosen': '-0.29621', 'rewards_train/rejected': '-0.39256', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.09631', 'logps_train/rejected': '-128.27', 'logps_train/chosen': '-139.34', 'loss/train': '0.65869', 'examples_per_second': '4.4354', 'grad_norm': '17.25', 'counters/examples': 68416, 'counters/updates': 4276}
skipping logging after 68432 examples to avoid logging too frequently
skipping logging after 68448 examples to avoid logging too frequently
Running evaluation after 68448 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:17,  2.50s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:06,  2.23s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:56,  1.95s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:08<00:53,  1.91s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.55s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.65s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.48s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 68448: {'rewards_eval/chosen': '-0.38802', 'rewards_eval/rejected': '-0.47952', 'rewards_eval/accuracies': '0.54688', 'rewards_eval/margins': '0.091523', 'logps_eval/rejected': '-126.95', 'logps_eval/chosen': '-122.37', 'loss/eval': '0.67501'}
skipping logging after 68464 examples to avoid logging too frequently
train stats after 68480 examples: {'rewards_train/chosen': '-0.42656', 'rewards_train/rejected': '-0.53987', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.11342', 'logps_train/rejected': '-128.09', 'logps_train/chosen': '-109.15', 'loss/train': '0.6604', 'examples_per_second': '4.8333', 'grad_norm': '16.5', 'counters/examples': 68480, 'counters/updates': 4280}
skipping logging after 68496 examples to avoid logging too frequently
skipping logging after 68512 examples to avoid logging too frequently
skipping logging after 68528 examples to avoid logging too frequently
train stats after 68544 examples: {'rewards_train/chosen': '-0.3487', 'rewards_train/rejected': '-0.51224', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.16357', 'logps_train/rejected': '-132.1', 'logps_train/chosen': '-95.623', 'loss/train': '0.63916', 'examples_per_second': '5.5544', 'grad_norm': '16.625', 'counters/examples': 68544, 'counters/updates': 4284}
skipping logging after 68560 examples to avoid logging too frequently
skipping logging after 68576 examples to avoid logging too frequently
skipping logging after 68592 examples to avoid logging too frequently
train stats after 68608 examples: {'rewards_train/chosen': '-0.3427', 'rewards_train/rejected': '-0.39816', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.055344', 'logps_train/rejected': '-121.17', 'logps_train/chosen': '-122.83', 'loss/train': '0.6864', 'examples_per_second': '4.7886', 'grad_norm': '22', 'counters/examples': 68608, 'counters/updates': 4288}
skipping logging after 68624 examples to avoid logging too frequently
skipping logging after 68640 examples to avoid logging too frequently
skipping logging after 68656 examples to avoid logging too frequently
train stats after 68672 examples: {'rewards_train/chosen': '-0.34854', 'rewards_train/rejected': '-0.4886', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.14006', 'logps_train/rejected': '-129.91', 'logps_train/chosen': '-101.36', 'loss/train': '0.64178', 'examples_per_second': '4.7981', 'grad_norm': '19', 'counters/examples': 68672, 'counters/updates': 4292}
skipping logging after 68688 examples to avoid logging too frequently
skipping logging after 68704 examples to avoid logging too frequently
skipping logging after 68720 examples to avoid logging too frequently
train stats after 68736 examples: {'rewards_train/chosen': '-0.37003', 'rewards_train/rejected': '-0.48359', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.11356', 'logps_train/rejected': '-121.36', 'logps_train/chosen': '-123.15', 'loss/train': '0.65442', 'examples_per_second': '6.3993', 'grad_norm': '15.5', 'counters/examples': 68736, 'counters/updates': 4296}
skipping logging after 68752 examples to avoid logging too frequently
skipping logging after 68768 examples to avoid logging too frequently
skipping logging after 68784 examples to avoid logging too frequently
train stats after 68800 examples: {'rewards_train/chosen': '-0.3047', 'rewards_train/rejected': '-0.43845', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.13366', 'logps_train/rejected': '-125.37', 'logps_train/chosen': '-137.65', 'loss/train': '0.66616', 'examples_per_second': '6.0364', 'grad_norm': '19.875', 'counters/examples': 68800, 'counters/updates': 4300}
skipping logging after 68816 examples to avoid logging too frequently
skipping logging after 68832 examples to avoid logging too frequently
skipping logging after 68848 examples to avoid logging too frequently
train stats after 68864 examples: {'rewards_train/chosen': '-0.39522', 'rewards_train/rejected': '-0.50628', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.11111', 'logps_train/rejected': '-118.18', 'logps_train/chosen': '-114.91', 'loss/train': '0.66512', 'examples_per_second': '5.5129', 'grad_norm': '18', 'counters/examples': 68864, 'counters/updates': 4304}
skipping logging after 68880 examples to avoid logging too frequently
skipping logging after 68896 examples to avoid logging too frequently
skipping logging after 68912 examples to avoid logging too frequently
train stats after 68928 examples: {'rewards_train/chosen': '-0.41325', 'rewards_train/rejected': '-0.61527', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.20191', 'logps_train/rejected': '-144.46', 'logps_train/chosen': '-140.22', 'loss/train': '0.62173', 'examples_per_second': '4.9159', 'grad_norm': '18.75', 'counters/examples': 68928, 'counters/updates': 4308}
skipping logging after 68944 examples to avoid logging too frequently
skipping logging after 68960 examples to avoid logging too frequently
skipping logging after 68976 examples to avoid logging too frequently
train stats after 68992 examples: {'rewards_train/chosen': '-0.52998', 'rewards_train/rejected': '-0.57849', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.048431', 'logps_train/rejected': '-104.47', 'logps_train/chosen': '-115.16', 'loss/train': '0.69681', 'examples_per_second': '4.9451', 'grad_norm': '19.75', 'counters/examples': 68992, 'counters/updates': 4312}
skipping logging after 69008 examples to avoid logging too frequently
skipping logging after 69024 examples to avoid logging too frequently
skipping logging after 69040 examples to avoid logging too frequently
train stats after 69056 examples: {'rewards_train/chosen': '-0.39295', 'rewards_train/rejected': '-0.42358', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.030602', 'logps_train/rejected': '-116.68', 'logps_train/chosen': '-128.86', 'loss/train': '0.69284', 'examples_per_second': '5.5285', 'grad_norm': '20.125', 'counters/examples': 69056, 'counters/updates': 4316}
skipping logging after 69072 examples to avoid logging too frequently
skipping logging after 69088 examples to avoid logging too frequently
skipping logging after 69104 examples to avoid logging too frequently
train stats after 69120 examples: {'rewards_train/chosen': '-0.47484', 'rewards_train/rejected': '-0.49831', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.023388', 'logps_train/rejected': '-114.37', 'logps_train/chosen': '-128.82', 'loss/train': '0.70743', 'examples_per_second': '5.43', 'grad_norm': '18.5', 'counters/examples': 69120, 'counters/updates': 4320}
skipping logging after 69136 examples to avoid logging too frequently
skipping logging after 69152 examples to avoid logging too frequently
skipping logging after 69168 examples to avoid logging too frequently
train stats after 69184 examples: {'rewards_train/chosen': '-0.29885', 'rewards_train/rejected': '-0.38816', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.089378', 'logps_train/rejected': '-105.71', 'logps_train/chosen': '-103.83', 'loss/train': '0.66602', 'examples_per_second': '5.2365', 'grad_norm': '17.25', 'counters/examples': 69184, 'counters/updates': 4324}
skipping logging after 69200 examples to avoid logging too frequently
skipping logging after 69216 examples to avoid logging too frequently
skipping logging after 69232 examples to avoid logging too frequently
train stats after 69248 examples: {'rewards_train/chosen': '-0.42382', 'rewards_train/rejected': '-0.53308', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.1095', 'logps_train/rejected': '-127.03', 'logps_train/chosen': '-160.41', 'loss/train': '0.66179', 'examples_per_second': '4.7069', 'grad_norm': '19.125', 'counters/examples': 69248, 'counters/updates': 4328}
skipping logging after 69264 examples to avoid logging too frequently
skipping logging after 69280 examples to avoid logging too frequently
skipping logging after 69296 examples to avoid logging too frequently
train stats after 69312 examples: {'rewards_train/chosen': '-0.46789', 'rewards_train/rejected': '-0.59338', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.12545', 'logps_train/rejected': '-121.83', 'logps_train/chosen': '-123.64', 'loss/train': '0.65524', 'examples_per_second': '5.7448', 'grad_norm': '18.875', 'counters/examples': 69312, 'counters/updates': 4332}
skipping logging after 69328 examples to avoid logging too frequently
skipping logging after 69344 examples to avoid logging too frequently
skipping logging after 69360 examples to avoid logging too frequently
train stats after 69376 examples: {'rewards_train/chosen': '-0.39049', 'rewards_train/rejected': '-0.51137', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.12085', 'logps_train/rejected': '-115.49', 'logps_train/chosen': '-118.08', 'loss/train': '0.65939', 'examples_per_second': '4.8409', 'grad_norm': '15.25', 'counters/examples': 69376, 'counters/updates': 4336}
skipping logging after 69392 examples to avoid logging too frequently
skipping logging after 69408 examples to avoid logging too frequently
skipping logging after 69424 examples to avoid logging too frequently
train stats after 69440 examples: {'rewards_train/chosen': '-0.3326', 'rewards_train/rejected': '-0.4287', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.096107', 'logps_train/rejected': '-122.88', 'logps_train/chosen': '-122.36', 'loss/train': '0.66733', 'examples_per_second': '4.7113', 'grad_norm': '18.125', 'counters/examples': 69440, 'counters/updates': 4340}
Running evaluation after 69440 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 69440: {'rewards_eval/chosen': '-0.37516', 'rewards_eval/rejected': '-0.46509', 'rewards_eval/accuracies': '0.54492', 'rewards_eval/margins': '0.089919', 'logps_eval/rejected': '-126.81', 'logps_eval/chosen': '-122.25', 'loss/eval': '0.67322'}
skipping logging after 69456 examples to avoid logging too frequently
skipping logging after 69472 examples to avoid logging too frequently
skipping logging after 69488 examples to avoid logging too frequently
train stats after 69504 examples: {'rewards_train/chosen': '-0.3656', 'rewards_train/rejected': '-0.47593', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.11033', 'logps_train/rejected': '-107.97', 'logps_train/chosen': '-110.22', 'loss/train': '0.65739', 'examples_per_second': '4.7983', 'grad_norm': '18.25', 'counters/examples': 69504, 'counters/updates': 4344}
skipping logging after 69520 examples to avoid logging too frequently
skipping logging after 69536 examples to avoid logging too frequently
skipping logging after 69552 examples to avoid logging too frequently
train stats after 69568 examples: {'rewards_train/chosen': '-0.35024', 'rewards_train/rejected': '-0.4953', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.14506', 'logps_train/rejected': '-139.32', 'logps_train/chosen': '-140.44', 'loss/train': '0.64824', 'examples_per_second': '4.1075', 'grad_norm': '19.5', 'counters/examples': 69568, 'counters/updates': 4348}
skipping logging after 69584 examples to avoid logging too frequently
skipping logging after 69600 examples to avoid logging too frequently
skipping logging after 69616 examples to avoid logging too frequently
train stats after 69632 examples: {'rewards_train/chosen': '-0.3425', 'rewards_train/rejected': '-0.44563', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.10317', 'logps_train/rejected': '-101.25', 'logps_train/chosen': '-109.31', 'loss/train': '0.66367', 'examples_per_second': '5.0347', 'grad_norm': '15', 'counters/examples': 69632, 'counters/updates': 4352}
skipping logging after 69648 examples to avoid logging too frequently
skipping logging after 69664 examples to avoid logging too frequently
skipping logging after 69680 examples to avoid logging too frequently
train stats after 69696 examples: {'rewards_train/chosen': '-0.27979', 'rewards_train/rejected': '-0.45292', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.17305', 'logps_train/rejected': '-110.8', 'logps_train/chosen': '-110.44', 'loss/train': '0.63046', 'examples_per_second': '5.9054', 'grad_norm': '17.25', 'counters/examples': 69696, 'counters/updates': 4356}
skipping logging after 69712 examples to avoid logging too frequently
skipping logging after 69728 examples to avoid logging too frequently
skipping logging after 69744 examples to avoid logging too frequently
train stats after 69760 examples: {'rewards_train/chosen': '-0.33798', 'rewards_train/rejected': '-0.50407', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.16597', 'logps_train/rejected': '-124.01', 'logps_train/chosen': '-141.11', 'loss/train': '0.63968', 'examples_per_second': '4.3413', 'grad_norm': '18.5', 'counters/examples': 69760, 'counters/updates': 4360}
skipping logging after 69776 examples to avoid logging too frequently
skipping logging after 69792 examples to avoid logging too frequently
skipping logging after 69808 examples to avoid logging too frequently
train stats after 69824 examples: {'rewards_train/chosen': '-0.45119', 'rewards_train/rejected': '-0.49928', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.048023', 'logps_train/rejected': '-120.6', 'logps_train/chosen': '-116.58', 'loss/train': '0.69102', 'examples_per_second': '5.421', 'grad_norm': '21.125', 'counters/examples': 69824, 'counters/updates': 4364}
skipping logging after 69840 examples to avoid logging too frequently
skipping logging after 69856 examples to avoid logging too frequently
skipping logging after 69872 examples to avoid logging too frequently
train stats after 69888 examples: {'rewards_train/chosen': '-0.34826', 'rewards_train/rejected': '-0.45622', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.10787', 'logps_train/rejected': '-97.196', 'logps_train/chosen': '-115.93', 'loss/train': '0.66823', 'examples_per_second': '5.6513', 'grad_norm': '17', 'counters/examples': 69888, 'counters/updates': 4368}
skipping logging after 69904 examples to avoid logging too frequently
skipping logging after 69920 examples to avoid logging too frequently
skipping logging after 69936 examples to avoid logging too frequently
train stats after 69952 examples: {'rewards_train/chosen': '-0.3115', 'rewards_train/rejected': '-0.464', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.15242', 'logps_train/rejected': '-131.3', 'logps_train/chosen': '-131.87', 'loss/train': '0.64549', 'examples_per_second': '5.1761', 'grad_norm': '17.875', 'counters/examples': 69952, 'counters/updates': 4372}
skipping logging after 69968 examples to avoid logging too frequently
skipping logging after 69984 examples to avoid logging too frequently
skipping logging after 70000 examples to avoid logging too frequently
train stats after 70016 examples: {'rewards_train/chosen': '-0.24765', 'rewards_train/rejected': '-0.41352', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.16589', 'logps_train/rejected': '-127.84', 'logps_train/chosen': '-111.9', 'loss/train': '0.63736', 'examples_per_second': '4.6276', 'grad_norm': '17.875', 'counters/examples': 70016, 'counters/updates': 4376}
skipping logging after 70032 examples to avoid logging too frequently
skipping logging after 70048 examples to avoid logging too frequently
skipping logging after 70064 examples to avoid logging too frequently
train stats after 70080 examples: {'rewards_train/chosen': '-0.43376', 'rewards_train/rejected': '-0.43697', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.0032349', 'logps_train/rejected': '-127.38', 'logps_train/chosen': '-119.52', 'loss/train': '0.70898', 'examples_per_second': '4.7455', 'grad_norm': '24.25', 'counters/examples': 70080, 'counters/updates': 4380}
skipping logging after 70096 examples to avoid logging too frequently
skipping logging after 70112 examples to avoid logging too frequently
skipping logging after 70128 examples to avoid logging too frequently
train stats after 70144 examples: {'rewards_train/chosen': '-0.21481', 'rewards_train/rejected': '-0.30962', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.094784', 'logps_train/rejected': '-97.62', 'logps_train/chosen': '-116.64', 'loss/train': '0.66306', 'examples_per_second': '5.6172', 'grad_norm': '16.125', 'counters/examples': 70144, 'counters/updates': 4384}
skipping logging after 70160 examples to avoid logging too frequently
skipping logging after 70176 examples to avoid logging too frequently
skipping logging after 70192 examples to avoid logging too frequently
train stats after 70208 examples: {'rewards_train/chosen': '-0.33251', 'rewards_train/rejected': '-0.39117', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.058632', 'logps_train/rejected': '-111.85', 'logps_train/chosen': '-107.83', 'loss/train': '0.6842', 'examples_per_second': '5.2322', 'grad_norm': '16.25', 'counters/examples': 70208, 'counters/updates': 4388}
skipping logging after 70224 examples to avoid logging too frequently
skipping logging after 70240 examples to avoid logging too frequently
skipping logging after 70256 examples to avoid logging too frequently
train stats after 70272 examples: {'rewards_train/chosen': '-0.35948', 'rewards_train/rejected': '-0.3343', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '-0.025131', 'logps_train/rejected': '-109.69', 'logps_train/chosen': '-116.14', 'loss/train': '0.71503', 'examples_per_second': '5.7199', 'grad_norm': '19.625', 'counters/examples': 70272, 'counters/updates': 4392}
skipping logging after 70288 examples to avoid logging too frequently
skipping logging after 70304 examples to avoid logging too frequently
skipping logging after 70320 examples to avoid logging too frequently
train stats after 70336 examples: {'rewards_train/chosen': '-0.26606', 'rewards_train/rejected': '-0.36016', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.094017', 'logps_train/rejected': '-121.81', 'logps_train/chosen': '-125.38', 'loss/train': '0.65649', 'examples_per_second': '3.9727', 'grad_norm': '16.125', 'counters/examples': 70336, 'counters/updates': 4396}
skipping logging after 70352 examples to avoid logging too frequently
skipping logging after 70368 examples to avoid logging too frequently
skipping logging after 70384 examples to avoid logging too frequently
train stats after 70400 examples: {'rewards_train/chosen': '-0.45592', 'rewards_train/rejected': '-0.52202', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.066277', 'logps_train/rejected': '-127.55', 'logps_train/chosen': '-109.9', 'loss/train': '0.68056', 'examples_per_second': '5.9249', 'grad_norm': '18.25', 'counters/examples': 70400, 'counters/updates': 4400}
skipping logging after 70416 examples to avoid logging too frequently
skipping logging after 70432 examples to avoid logging too frequently
Running evaluation after 70432 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:09,  2.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:03,  2.13s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.90s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.88s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.25s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.29s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 70432: {'rewards_eval/chosen': '-0.32735', 'rewards_eval/rejected': '-0.41257', 'rewards_eval/accuracies': '0.55469', 'rewards_eval/margins': '0.085258', 'logps_eval/rejected': '-126.28', 'logps_eval/chosen': '-121.77', 'loss/eval': '0.67352'}
skipping logging after 70448 examples to avoid logging too frequently
train stats after 70464 examples: {'rewards_train/chosen': '-0.31599', 'rewards_train/rejected': '-0.43629', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.12031', 'logps_train/rejected': '-122.67', 'logps_train/chosen': '-143.72', 'loss/train': '0.65804', 'examples_per_second': '6.2532', 'grad_norm': '18.125', 'counters/examples': 70464, 'counters/updates': 4404}
skipping logging after 70480 examples to avoid logging too frequently
skipping logging after 70496 examples to avoid logging too frequently
skipping logging after 70512 examples to avoid logging too frequently
train stats after 70528 examples: {'rewards_train/chosen': '-0.36443', 'rewards_train/rejected': '-0.49672', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.13238', 'logps_train/rejected': '-98.037', 'logps_train/chosen': '-117.8', 'loss/train': '0.64742', 'examples_per_second': '5.8195', 'grad_norm': '18.75', 'counters/examples': 70528, 'counters/updates': 4408}
skipping logging after 70544 examples to avoid logging too frequently
skipping logging after 70560 examples to avoid logging too frequently
skipping logging after 70576 examples to avoid logging too frequently
train stats after 70592 examples: {'rewards_train/chosen': '-0.39793', 'rewards_train/rejected': '-0.50314', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.10522', 'logps_train/rejected': '-127.87', 'logps_train/chosen': '-116.02', 'loss/train': '0.66269', 'examples_per_second': '5.0665', 'grad_norm': '17.875', 'counters/examples': 70592, 'counters/updates': 4412}
skipping logging after 70608 examples to avoid logging too frequently
skipping logging after 70624 examples to avoid logging too frequently
skipping logging after 70640 examples to avoid logging too frequently
train stats after 70656 examples: {'rewards_train/chosen': '-0.32752', 'rewards_train/rejected': '-0.41163', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.084202', 'logps_train/rejected': '-145.06', 'logps_train/chosen': '-142.4', 'loss/train': '0.67435', 'examples_per_second': '4.5133', 'grad_norm': '19.625', 'counters/examples': 70656, 'counters/updates': 4416}
skipping logging after 70672 examples to avoid logging too frequently
skipping logging after 70688 examples to avoid logging too frequently
skipping logging after 70704 examples to avoid logging too frequently
train stats after 70720 examples: {'rewards_train/chosen': '-0.35762', 'rewards_train/rejected': '-0.43615', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.078394', 'logps_train/rejected': '-117.3', 'logps_train/chosen': '-105.6', 'loss/train': '0.68301', 'examples_per_second': '5.7879', 'grad_norm': '17.875', 'counters/examples': 70720, 'counters/updates': 4420}
skipping logging after 70736 examples to avoid logging too frequently
skipping logging after 70752 examples to avoid logging too frequently
skipping logging after 70768 examples to avoid logging too frequently
train stats after 70784 examples: {'rewards_train/chosen': '-0.43305', 'rewards_train/rejected': '-0.47908', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.045952', 'logps_train/rejected': '-106.31', 'logps_train/chosen': '-104.76', 'loss/train': '0.69453', 'examples_per_second': '5.7086', 'grad_norm': '19.625', 'counters/examples': 70784, 'counters/updates': 4424}
skipping logging after 70800 examples to avoid logging too frequently
skipping logging after 70816 examples to avoid logging too frequently
skipping logging after 70832 examples to avoid logging too frequently
train stats after 70848 examples: {'rewards_train/chosen': '-0.31067', 'rewards_train/rejected': '-0.36935', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.058693', 'logps_train/rejected': '-114.31', 'logps_train/chosen': '-100.44', 'loss/train': '0.68852', 'examples_per_second': '4.2251', 'grad_norm': '17.5', 'counters/examples': 70848, 'counters/updates': 4428}
skipping logging after 70864 examples to avoid logging too frequently
skipping logging after 70880 examples to avoid logging too frequently
skipping logging after 70896 examples to avoid logging too frequently
train stats after 70912 examples: {'rewards_train/chosen': '-0.34356', 'rewards_train/rejected': '-0.51773', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.17432', 'logps_train/rejected': '-118.36', 'logps_train/chosen': '-129.14', 'loss/train': '0.63498', 'examples_per_second': '5.9662', 'grad_norm': '18.625', 'counters/examples': 70912, 'counters/updates': 4432}
skipping logging after 70928 examples to avoid logging too frequently
skipping logging after 70944 examples to avoid logging too frequently
skipping logging after 70960 examples to avoid logging too frequently
train stats after 70976 examples: {'rewards_train/chosen': '-0.3995', 'rewards_train/rejected': '-0.58542', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.1859', 'logps_train/rejected': '-98.83', 'logps_train/chosen': '-129.64', 'loss/train': '0.62265', 'examples_per_second': '5.0818', 'grad_norm': '14.938', 'counters/examples': 70976, 'counters/updates': 4436}
skipping logging after 70992 examples to avoid logging too frequently
skipping logging after 71008 examples to avoid logging too frequently
skipping logging after 71024 examples to avoid logging too frequently
train stats after 71040 examples: {'rewards_train/chosen': '-0.42405', 'rewards_train/rejected': '-0.55366', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.12953', 'logps_train/rejected': '-147.2', 'logps_train/chosen': '-133.43', 'loss/train': '0.6514', 'examples_per_second': '4.7368', 'grad_norm': '20.625', 'counters/examples': 71040, 'counters/updates': 4440}
skipping logging after 71056 examples to avoid logging too frequently
skipping logging after 71072 examples to avoid logging too frequently
skipping logging after 71088 examples to avoid logging too frequently
train stats after 71104 examples: {'rewards_train/chosen': '-0.32585', 'rewards_train/rejected': '-0.42379', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.09782', 'logps_train/rejected': '-109.81', 'logps_train/chosen': '-114.26', 'loss/train': '0.67222', 'examples_per_second': '4.3767', 'grad_norm': '18.375', 'counters/examples': 71104, 'counters/updates': 4444}
skipping logging after 71120 examples to avoid logging too frequently
skipping logging after 71136 examples to avoid logging too frequently
skipping logging after 71152 examples to avoid logging too frequently
train stats after 71168 examples: {'rewards_train/chosen': '-0.48019', 'rewards_train/rejected': '-0.55912', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.078724', 'logps_train/rejected': '-115.04', 'logps_train/chosen': '-141.16', 'loss/train': '0.68489', 'examples_per_second': '5.4266', 'grad_norm': '23.625', 'counters/examples': 71168, 'counters/updates': 4448}
skipping logging after 71184 examples to avoid logging too frequently
skipping logging after 71200 examples to avoid logging too frequently
skipping logging after 71216 examples to avoid logging too frequently
train stats after 71232 examples: {'rewards_train/chosen': '-0.3167', 'rewards_train/rejected': '-0.45211', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.13546', 'logps_train/rejected': '-125.38', 'logps_train/chosen': '-118.91', 'loss/train': '0.64789', 'examples_per_second': '6.0366', 'grad_norm': '20.625', 'counters/examples': 71232, 'counters/updates': 4452}
skipping logging after 71248 examples to avoid logging too frequently
skipping logging after 71264 examples to avoid logging too frequently
skipping logging after 71280 examples to avoid logging too frequently
train stats after 71296 examples: {'rewards_train/chosen': '-0.34703', 'rewards_train/rejected': '-0.41231', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.065399', 'logps_train/rejected': '-121.43', 'logps_train/chosen': '-98.262', 'loss/train': '0.67982', 'examples_per_second': '4.4891', 'grad_norm': '19.25', 'counters/examples': 71296, 'counters/updates': 4456}
skipping logging after 71312 examples to avoid logging too frequently
skipping logging after 71328 examples to avoid logging too frequently
skipping logging after 71344 examples to avoid logging too frequently
train stats after 71360 examples: {'rewards_train/chosen': '-0.26962', 'rewards_train/rejected': '-0.40602', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.13653', 'logps_train/rejected': '-106.56', 'logps_train/chosen': '-101.89', 'loss/train': '0.64352', 'examples_per_second': '5.6379', 'grad_norm': '15.812', 'counters/examples': 71360, 'counters/updates': 4460}
skipping logging after 71376 examples to avoid logging too frequently
skipping logging after 71392 examples to avoid logging too frequently
skipping logging after 71408 examples to avoid logging too frequently
train stats after 71424 examples: {'rewards_train/chosen': '-0.36989', 'rewards_train/rejected': '-0.44136', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.07149', 'logps_train/rejected': '-100.46', 'logps_train/chosen': '-79.551', 'loss/train': '0.67596', 'examples_per_second': '6.5192', 'grad_norm': '19', 'counters/examples': 71424, 'counters/updates': 4464}
Running evaluation after 71424 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.53s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 71424: {'rewards_eval/chosen': '-0.30152', 'rewards_eval/rejected': '-0.3828', 'rewards_eval/accuracies': '0.54688', 'rewards_eval/margins': '0.081293', 'logps_eval/rejected': '-125.98', 'logps_eval/chosen': '-121.51', 'loss/eval': '0.67492'}
skipping logging after 71440 examples to avoid logging too frequently
skipping logging after 71456 examples to avoid logging too frequently
skipping logging after 71472 examples to avoid logging too frequently
train stats after 71488 examples: {'rewards_train/chosen': '-0.27447', 'rewards_train/rejected': '-0.3425', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.067989', 'logps_train/rejected': '-131.3', 'logps_train/chosen': '-152.64', 'loss/train': '0.68346', 'examples_per_second': '4.4936', 'grad_norm': '20.75', 'counters/examples': 71488, 'counters/updates': 4468}
skipping logging after 71504 examples to avoid logging too frequently
skipping logging after 71520 examples to avoid logging too frequently
skipping logging after 71536 examples to avoid logging too frequently
train stats after 71552 examples: {'rewards_train/chosen': '-0.23334', 'rewards_train/rejected': '-0.36036', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.12709', 'logps_train/rejected': '-112.98', 'logps_train/chosen': '-104.92', 'loss/train': '0.64655', 'examples_per_second': '4.6881', 'grad_norm': '18.625', 'counters/examples': 71552, 'counters/updates': 4472}
skipping logging after 71568 examples to avoid logging too frequently
skipping logging after 71584 examples to avoid logging too frequently
skipping logging after 71600 examples to avoid logging too frequently
train stats after 71616 examples: {'rewards_train/chosen': '-0.32837', 'rewards_train/rejected': '-0.41573', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.087368', 'logps_train/rejected': '-104.58', 'logps_train/chosen': '-122.84', 'loss/train': '0.67767', 'examples_per_second': '5.2615', 'grad_norm': '17.25', 'counters/examples': 71616, 'counters/updates': 4476}
skipping logging after 71632 examples to avoid logging too frequently
skipping logging after 71648 examples to avoid logging too frequently
skipping logging after 71664 examples to avoid logging too frequently
train stats after 71680 examples: {'rewards_train/chosen': '-0.26272', 'rewards_train/rejected': '-0.41916', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.15654', 'logps_train/rejected': '-141.79', 'logps_train/chosen': '-123.87', 'loss/train': '0.64188', 'examples_per_second': '5.476', 'grad_norm': '18.625', 'counters/examples': 71680, 'counters/updates': 4480}
skipping logging after 71696 examples to avoid logging too frequently
skipping logging after 71712 examples to avoid logging too frequently
skipping logging after 71728 examples to avoid logging too frequently
train stats after 71744 examples: {'rewards_train/chosen': '-0.35674', 'rewards_train/rejected': '-0.39209', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.03528', 'logps_train/rejected': '-96.703', 'logps_train/chosen': '-127.1', 'loss/train': '0.68823', 'examples_per_second': '5.8694', 'grad_norm': '21.5', 'counters/examples': 71744, 'counters/updates': 4484}
skipping logging after 71760 examples to avoid logging too frequently
skipping logging after 71776 examples to avoid logging too frequently
skipping logging after 71792 examples to avoid logging too frequently
train stats after 71808 examples: {'rewards_train/chosen': '-0.30912', 'rewards_train/rejected': '-0.5338', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.22461', 'logps_train/rejected': '-103.22', 'logps_train/chosen': '-110.29', 'loss/train': '0.60754', 'examples_per_second': '6.2135', 'grad_norm': '25.875', 'counters/examples': 71808, 'counters/updates': 4488}
skipping logging after 71824 examples to avoid logging too frequently
skipping logging after 71840 examples to avoid logging too frequently
skipping logging after 71856 examples to avoid logging too frequently
train stats after 71872 examples: {'rewards_train/chosen': '-0.40088', 'rewards_train/rejected': '-0.54201', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.1411', 'logps_train/rejected': '-112.92', 'logps_train/chosen': '-127.44', 'loss/train': '0.65225', 'examples_per_second': '4.9339', 'grad_norm': '19', 'counters/examples': 71872, 'counters/updates': 4492}
skipping logging after 71888 examples to avoid logging too frequently
skipping logging after 71904 examples to avoid logging too frequently
skipping logging after 71920 examples to avoid logging too frequently
train stats after 71936 examples: {'rewards_train/chosen': '-0.4107', 'rewards_train/rejected': '-0.54268', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.13204', 'logps_train/rejected': '-130.7', 'logps_train/chosen': '-110.33', 'loss/train': '0.65555', 'examples_per_second': '5.6907', 'grad_norm': '20.625', 'counters/examples': 71936, 'counters/updates': 4496}
skipping logging after 71952 examples to avoid logging too frequently
skipping logging after 71968 examples to avoid logging too frequently
skipping logging after 71984 examples to avoid logging too frequently
train stats after 72000 examples: {'rewards_train/chosen': '-0.4798', 'rewards_train/rejected': '-0.56193', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.082275', 'logps_train/rejected': '-130.71', 'logps_train/chosen': '-129.36', 'loss/train': '0.68367', 'examples_per_second': '4.928', 'grad_norm': '20.375', 'counters/examples': 72000, 'counters/updates': 4500}
skipping logging after 72016 examples to avoid logging too frequently
skipping logging after 72032 examples to avoid logging too frequently
skipping logging after 72048 examples to avoid logging too frequently
train stats after 72064 examples: {'rewards_train/chosen': '-0.52347', 'rewards_train/rejected': '-0.63667', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.11317', 'logps_train/rejected': '-105.57', 'logps_train/chosen': '-123.72', 'loss/train': '0.66541', 'examples_per_second': '6.3602', 'grad_norm': '16.75', 'counters/examples': 72064, 'counters/updates': 4504}
skipping logging after 72080 examples to avoid logging too frequently
skipping logging after 72096 examples to avoid logging too frequently
skipping logging after 72112 examples to avoid logging too frequently
train stats after 72128 examples: {'rewards_train/chosen': '-0.34759', 'rewards_train/rejected': '-0.48354', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.13613', 'logps_train/rejected': '-114.29', 'logps_train/chosen': '-97.676', 'loss/train': '0.64613', 'examples_per_second': '5.7571', 'grad_norm': '16', 'counters/examples': 72128, 'counters/updates': 4508}
skipping logging after 72144 examples to avoid logging too frequently
skipping logging after 72160 examples to avoid logging too frequently
skipping logging after 72176 examples to avoid logging too frequently
train stats after 72192 examples: {'rewards_train/chosen': '-0.44238', 'rewards_train/rejected': '-0.56587', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.12358', 'logps_train/rejected': '-122.3', 'logps_train/chosen': '-117.84', 'loss/train': '0.6541', 'examples_per_second': '5.3867', 'grad_norm': '18.875', 'counters/examples': 72192, 'counters/updates': 4512}
skipping logging after 72208 examples to avoid logging too frequently
skipping logging after 72224 examples to avoid logging too frequently
skipping logging after 72240 examples to avoid logging too frequently
train stats after 72256 examples: {'rewards_train/chosen': '-0.48684', 'rewards_train/rejected': '-0.60813', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.12137', 'logps_train/rejected': '-123.92', 'logps_train/chosen': '-102.65', 'loss/train': '0.65662', 'examples_per_second': '5.1482', 'grad_norm': '18.375', 'counters/examples': 72256, 'counters/updates': 4516}
skipping logging after 72272 examples to avoid logging too frequently
skipping logging after 72288 examples to avoid logging too frequently
skipping logging after 72304 examples to avoid logging too frequently
train stats after 72320 examples: {'rewards_train/chosen': '-0.46565', 'rewards_train/rejected': '-0.53149', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.065933', 'logps_train/rejected': '-110.48', 'logps_train/chosen': '-136.6', 'loss/train': '0.67969', 'examples_per_second': '4.3924', 'grad_norm': '18.875', 'counters/examples': 72320, 'counters/updates': 4520}
skipping logging after 72336 examples to avoid logging too frequently
skipping logging after 72352 examples to avoid logging too frequently
skipping logging after 72368 examples to avoid logging too frequently
train stats after 72384 examples: {'rewards_train/chosen': '-0.40197', 'rewards_train/rejected': '-0.46474', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.062824', 'logps_train/rejected': '-144.92', 'logps_train/chosen': '-128.77', 'loss/train': '0.68143', 'examples_per_second': '4.8194', 'grad_norm': '19.25', 'counters/examples': 72384, 'counters/updates': 4524}
skipping logging after 72400 examples to avoid logging too frequently
skipping logging after 72416 examples to avoid logging too frequently
Running evaluation after 72416 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:08,  2.20s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:03,  2.10s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.88s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.87s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.63s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.30s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.24s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.12s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 72416: {'rewards_eval/chosen': '-0.407', 'rewards_eval/rejected': '-0.50687', 'rewards_eval/accuracies': '0.55273', 'rewards_eval/margins': '0.09988', 'logps_eval/rejected': '-127.22', 'logps_eval/chosen': '-122.56', 'loss/eval': '0.67163'}
skipping logging after 72432 examples to avoid logging too frequently
train stats after 72448 examples: {'rewards_train/chosen': '-0.38769', 'rewards_train/rejected': '-0.54427', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.15653', 'logps_train/rejected': '-129.62', 'logps_train/chosen': '-106.14', 'loss/train': '0.63702', 'examples_per_second': '6.0368', 'grad_norm': '17.5', 'counters/examples': 72448, 'counters/updates': 4528}
skipping logging after 72464 examples to avoid logging too frequently
skipping logging after 72480 examples to avoid logging too frequently
skipping logging after 72496 examples to avoid logging too frequently
train stats after 72512 examples: {'rewards_train/chosen': '-0.51421', 'rewards_train/rejected': '-0.64138', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.12724', 'logps_train/rejected': '-89.43', 'logps_train/chosen': '-107.32', 'loss/train': '0.65636', 'examples_per_second': '7.1849', 'grad_norm': '18.375', 'counters/examples': 72512, 'counters/updates': 4532}
skipping logging after 72528 examples to avoid logging too frequently
skipping logging after 72544 examples to avoid logging too frequently
skipping logging after 72560 examples to avoid logging too frequently
train stats after 72576 examples: {'rewards_train/chosen': '-0.41689', 'rewards_train/rejected': '-0.51709', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.10027', 'logps_train/rejected': '-143.53', 'logps_train/chosen': '-140', 'loss/train': '0.65793', 'examples_per_second': '5.13', 'grad_norm': '19.5', 'counters/examples': 72576, 'counters/updates': 4536}
skipping logging after 72592 examples to avoid logging too frequently
skipping logging after 72608 examples to avoid logging too frequently
skipping logging after 72624 examples to avoid logging too frequently
train stats after 72640 examples: {'rewards_train/chosen': '-0.42159', 'rewards_train/rejected': '-0.56268', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.14117', 'logps_train/rejected': '-93.601', 'logps_train/chosen': '-132.81', 'loss/train': '0.65866', 'examples_per_second': '5.5792', 'grad_norm': '20', 'counters/examples': 72640, 'counters/updates': 4540}
skipping logging after 72656 examples to avoid logging too frequently
skipping logging after 72672 examples to avoid logging too frequently
skipping logging after 72688 examples to avoid logging too frequently
train stats after 72704 examples: {'rewards_train/chosen': '-0.37588', 'rewards_train/rejected': '-0.46661', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.090595', 'logps_train/rejected': '-114.1', 'logps_train/chosen': '-125.27', 'loss/train': '0.67119', 'examples_per_second': '5.6188', 'grad_norm': '17.75', 'counters/examples': 72704, 'counters/updates': 4544}
skipping logging after 72720 examples to avoid logging too frequently
skipping logging after 72736 examples to avoid logging too frequently
skipping logging after 72752 examples to avoid logging too frequently
train stats after 72768 examples: {'rewards_train/chosen': '-0.35879', 'rewards_train/rejected': '-0.43938', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.080563', 'logps_train/rejected': '-116.81', 'logps_train/chosen': '-117.3', 'loss/train': '0.67528', 'examples_per_second': '5.166', 'grad_norm': '16.625', 'counters/examples': 72768, 'counters/updates': 4548}
skipping logging after 72784 examples to avoid logging too frequently
skipping logging after 72800 examples to avoid logging too frequently
skipping logging after 72816 examples to avoid logging too frequently
train stats after 72832 examples: {'rewards_train/chosen': '-0.47807', 'rewards_train/rejected': '-0.60801', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.12993', 'logps_train/rejected': '-117.49', 'logps_train/chosen': '-123.05', 'loss/train': '0.65759', 'examples_per_second': '5.4169', 'grad_norm': '17.625', 'counters/examples': 72832, 'counters/updates': 4552}
skipping logging after 72848 examples to avoid logging too frequently
skipping logging after 72864 examples to avoid logging too frequently
skipping logging after 72880 examples to avoid logging too frequently
train stats after 72896 examples: {'rewards_train/chosen': '-0.4076', 'rewards_train/rejected': '-0.56517', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.15751', 'logps_train/rejected': '-118.15', 'logps_train/chosen': '-136.24', 'loss/train': '0.63881', 'examples_per_second': '6.0213', 'grad_norm': '20.125', 'counters/examples': 72896, 'counters/updates': 4556}
skipping logging after 72912 examples to avoid logging too frequently
skipping logging after 72928 examples to avoid logging too frequently
skipping logging after 72944 examples to avoid logging too frequently
train stats after 72960 examples: {'rewards_train/chosen': '-0.36651', 'rewards_train/rejected': '-0.60674', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.24029', 'logps_train/rejected': '-98.25', 'logps_train/chosen': '-107.47', 'loss/train': '0.61035', 'examples_per_second': '5.1139', 'grad_norm': '17', 'counters/examples': 72960, 'counters/updates': 4560}
skipping logging after 72976 examples to avoid logging too frequently
skipping logging after 72992 examples to avoid logging too frequently
skipping logging after 73008 examples to avoid logging too frequently
train stats after 73024 examples: {'rewards_train/chosen': '-0.32196', 'rewards_train/rejected': '-0.48836', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.16645', 'logps_train/rejected': '-153.76', 'logps_train/chosen': '-115.34', 'loss/train': '0.62744', 'examples_per_second': '4.2895', 'grad_norm': '17.75', 'counters/examples': 73024, 'counters/updates': 4564}
skipping logging after 73040 examples to avoid logging too frequently
skipping logging after 73056 examples to avoid logging too frequently
skipping logging after 73072 examples to avoid logging too frequently
train stats after 73088 examples: {'rewards_train/chosen': '-0.43958', 'rewards_train/rejected': '-0.52095', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.081356', 'logps_train/rejected': '-116.58', 'logps_train/chosen': '-126.45', 'loss/train': '0.67462', 'examples_per_second': '4.376', 'grad_norm': '17.5', 'counters/examples': 73088, 'counters/updates': 4568}
skipping logging after 73104 examples to avoid logging too frequently
skipping logging after 73120 examples to avoid logging too frequently
skipping logging after 73136 examples to avoid logging too frequently
train stats after 73152 examples: {'rewards_train/chosen': '-0.4457', 'rewards_train/rejected': '-0.59406', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.14841', 'logps_train/rejected': '-119.37', 'logps_train/chosen': '-126.77', 'loss/train': '0.65611', 'examples_per_second': '5.2807', 'grad_norm': '16.75', 'counters/examples': 73152, 'counters/updates': 4572}
skipping logging after 73168 examples to avoid logging too frequently
skipping logging after 73184 examples to avoid logging too frequently
skipping logging after 73200 examples to avoid logging too frequently
train stats after 73216 examples: {'rewards_train/chosen': '-0.4765', 'rewards_train/rejected': '-0.61511', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.13862', 'logps_train/rejected': '-128.03', 'logps_train/chosen': '-129.76', 'loss/train': '0.65268', 'examples_per_second': '5.2775', 'grad_norm': '20', 'counters/examples': 73216, 'counters/updates': 4576}
skipping logging after 73232 examples to avoid logging too frequently
skipping logging after 73248 examples to avoid logging too frequently
skipping logging after 73264 examples to avoid logging too frequently
train stats after 73280 examples: {'rewards_train/chosen': '-0.48425', 'rewards_train/rejected': '-0.59135', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.10716', 'logps_train/rejected': '-129.05', 'logps_train/chosen': '-127.97', 'loss/train': '0.66971', 'examples_per_second': '5.1062', 'grad_norm': '20.125', 'counters/examples': 73280, 'counters/updates': 4580}
skipping logging after 73296 examples to avoid logging too frequently
skipping logging after 73312 examples to avoid logging too frequently
skipping logging after 73328 examples to avoid logging too frequently
train stats after 73344 examples: {'rewards_train/chosen': '-0.62725', 'rewards_train/rejected': '-0.71766', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.090439', 'logps_train/rejected': '-111.11', 'logps_train/chosen': '-119.73', 'loss/train': '0.67647', 'examples_per_second': '5.5933', 'grad_norm': '17.25', 'counters/examples': 73344, 'counters/updates': 4584}
skipping logging after 73360 examples to avoid logging too frequently
skipping logging after 73376 examples to avoid logging too frequently
skipping logging after 73392 examples to avoid logging too frequently
train stats after 73408 examples: {'rewards_train/chosen': '-0.53078', 'rewards_train/rejected': '-0.67349', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.1425', 'logps_train/rejected': '-139.23', 'logps_train/chosen': '-139.44', 'loss/train': '0.65724', 'examples_per_second': '5.0222', 'grad_norm': '20', 'counters/examples': 73408, 'counters/updates': 4588}
Running evaluation after 73408 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.53s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.46s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.53s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.31s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.24s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.12s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 73408: {'rewards_eval/chosen': '-0.51852', 'rewards_eval/rejected': '-0.61857', 'rewards_eval/accuracies': '0.52734', 'rewards_eval/margins': '0.10006', 'logps_eval/rejected': '-128.34', 'logps_eval/chosen': '-123.68', 'loss/eval': '0.67388'}
skipping logging after 73424 examples to avoid logging too frequently
skipping logging after 73440 examples to avoid logging too frequently
skipping logging after 73456 examples to avoid logging too frequently
train stats after 73472 examples: {'rewards_train/chosen': '-0.54845', 'rewards_train/rejected': '-0.62829', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.079937', 'logps_train/rejected': '-136.31', 'logps_train/chosen': '-119.54', 'loss/train': '0.67899', 'examples_per_second': '5.9585', 'grad_norm': '19.5', 'counters/examples': 73472, 'counters/updates': 4592}
skipping logging after 73488 examples to avoid logging too frequently
skipping logging after 73504 examples to avoid logging too frequently
skipping logging after 73520 examples to avoid logging too frequently
train stats after 73536 examples: {'rewards_train/chosen': '-0.36958', 'rewards_train/rejected': '-0.55128', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.18166', 'logps_train/rejected': '-119.25', 'logps_train/chosen': '-128.17', 'loss/train': '0.64024', 'examples_per_second': '4.5656', 'grad_norm': '17', 'counters/examples': 73536, 'counters/updates': 4596}
skipping logging after 73552 examples to avoid logging too frequently
skipping logging after 73568 examples to avoid logging too frequently
skipping logging after 73584 examples to avoid logging too frequently
train stats after 73600 examples: {'rewards_train/chosen': '-0.43128', 'rewards_train/rejected': '-0.65095', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.21979', 'logps_train/rejected': '-156.77', 'logps_train/chosen': '-132.85', 'loss/train': '0.61104', 'examples_per_second': '4.6954', 'grad_norm': '18', 'counters/examples': 73600, 'counters/updates': 4600}
skipping logging after 73616 examples to avoid logging too frequently
skipping logging after 73632 examples to avoid logging too frequently
skipping logging after 73648 examples to avoid logging too frequently
train stats after 73664 examples: {'rewards_train/chosen': '-0.54927', 'rewards_train/rejected': '-0.67709', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.12782', 'logps_train/rejected': '-133.34', 'logps_train/chosen': '-153.49', 'loss/train': '0.65468', 'examples_per_second': '4.3912', 'grad_norm': '18.625', 'counters/examples': 73664, 'counters/updates': 4604}
skipping logging after 73680 examples to avoid logging too frequently
skipping logging after 73696 examples to avoid logging too frequently
skipping logging after 73712 examples to avoid logging too frequently
train stats after 73728 examples: {'rewards_train/chosen': '-0.47524', 'rewards_train/rejected': '-0.56121', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.085964', 'logps_train/rejected': '-114.84', 'logps_train/chosen': '-104.68', 'loss/train': '0.66895', 'examples_per_second': '5.4265', 'grad_norm': '19.625', 'counters/examples': 73728, 'counters/updates': 4608}
skipping logging after 73744 examples to avoid logging too frequently
skipping logging after 73760 examples to avoid logging too frequently
skipping logging after 73776 examples to avoid logging too frequently
train stats after 73792 examples: {'rewards_train/chosen': '-0.4405', 'rewards_train/rejected': '-0.69728', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.25698', 'logps_train/rejected': '-127.92', 'logps_train/chosen': '-113.68', 'loss/train': '0.60619', 'examples_per_second': '5.3924', 'grad_norm': '16.125', 'counters/examples': 73792, 'counters/updates': 4612}
skipping logging after 73808 examples to avoid logging too frequently
skipping logging after 73824 examples to avoid logging too frequently
skipping logging after 73840 examples to avoid logging too frequently
train stats after 73856 examples: {'rewards_train/chosen': '-0.48196', 'rewards_train/rejected': '-0.49778', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.015747', 'logps_train/rejected': '-97.836', 'logps_train/chosen': '-109.01', 'loss/train': '0.7052', 'examples_per_second': '5.5483', 'grad_norm': '19.5', 'counters/examples': 73856, 'counters/updates': 4616}
skipping logging after 73872 examples to avoid logging too frequently
skipping logging after 73888 examples to avoid logging too frequently
skipping logging after 73904 examples to avoid logging too frequently
train stats after 73920 examples: {'rewards_train/chosen': '-0.37671', 'rewards_train/rejected': '-0.59962', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.22303', 'logps_train/rejected': '-119.33', 'logps_train/chosen': '-104.45', 'loss/train': '0.61813', 'examples_per_second': '4.9453', 'grad_norm': '16.125', 'counters/examples': 73920, 'counters/updates': 4620}
skipping logging after 73936 examples to avoid logging too frequently
skipping logging after 73952 examples to avoid logging too frequently
skipping logging after 73968 examples to avoid logging too frequently
train stats after 73984 examples: {'rewards_train/chosen': '-0.45832', 'rewards_train/rejected': '-0.60305', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.14464', 'logps_train/rejected': '-120.33', 'logps_train/chosen': '-113.93', 'loss/train': '0.64246', 'examples_per_second': '4.5417', 'grad_norm': '21.625', 'counters/examples': 73984, 'counters/updates': 4624}
skipping logging after 74000 examples to avoid logging too frequently
skipping logging after 74016 examples to avoid logging too frequently
skipping logging after 74032 examples to avoid logging too frequently
train stats after 74048 examples: {'rewards_train/chosen': '-0.53255', 'rewards_train/rejected': '-0.61083', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.078224', 'logps_train/rejected': '-121.24', 'logps_train/chosen': '-111.59', 'loss/train': '0.67648', 'examples_per_second': '5.3804', 'grad_norm': '17.375', 'counters/examples': 74048, 'counters/updates': 4628}
skipping logging after 74064 examples to avoid logging too frequently
skipping logging after 74080 examples to avoid logging too frequently
skipping logging after 74096 examples to avoid logging too frequently
train stats after 74112 examples: {'rewards_train/chosen': '-0.56211', 'rewards_train/rejected': '-0.65503', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.092934', 'logps_train/rejected': '-157.21', 'logps_train/chosen': '-138.99', 'loss/train': '0.66965', 'examples_per_second': '4.5775', 'grad_norm': '24.125', 'counters/examples': 74112, 'counters/updates': 4632}
skipping logging after 74128 examples to avoid logging too frequently
skipping logging after 74144 examples to avoid logging too frequently
skipping logging after 74160 examples to avoid logging too frequently
train stats after 74176 examples: {'rewards_train/chosen': '-0.49252', 'rewards_train/rejected': '-0.67275', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.18021', 'logps_train/rejected': '-150.87', 'logps_train/chosen': '-120.38', 'loss/train': '0.63666', 'examples_per_second': '4.3252', 'grad_norm': '18.75', 'counters/examples': 74176, 'counters/updates': 4636}
skipping logging after 74192 examples to avoid logging too frequently
skipping logging after 74208 examples to avoid logging too frequently
skipping logging after 74224 examples to avoid logging too frequently
train stats after 74240 examples: {'rewards_train/chosen': '-0.36135', 'rewards_train/rejected': '-0.64751', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.28606', 'logps_train/rejected': '-101.2', 'logps_train/chosen': '-105.91', 'loss/train': '0.59579', 'examples_per_second': '4.5086', 'grad_norm': '17', 'counters/examples': 74240, 'counters/updates': 4640}
skipping logging after 74256 examples to avoid logging too frequently
skipping logging after 74272 examples to avoid logging too frequently
skipping logging after 74288 examples to avoid logging too frequently
train stats after 74304 examples: {'rewards_train/chosen': '-0.40501', 'rewards_train/rejected': '-0.52921', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.12432', 'logps_train/rejected': '-114.44', 'logps_train/chosen': '-136.86', 'loss/train': '0.668', 'examples_per_second': '5.6529', 'grad_norm': '21.125', 'counters/examples': 74304, 'counters/updates': 4644}
skipping logging after 74320 examples to avoid logging too frequently
skipping logging after 74336 examples to avoid logging too frequently
skipping logging after 74352 examples to avoid logging too frequently
train stats after 74368 examples: {'rewards_train/chosen': '-0.54647', 'rewards_train/rejected': '-0.65827', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.11185', 'logps_train/rejected': '-128', 'logps_train/chosen': '-130.96', 'loss/train': '0.67126', 'examples_per_second': '5.4519', 'grad_norm': '22.375', 'counters/examples': 74368, 'counters/updates': 4648}
skipping logging after 74384 examples to avoid logging too frequently
skipping logging after 74400 examples to avoid logging too frequently
Running evaluation after 74400 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:13,  2.36s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:05,  2.18s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:55,  1.92s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.90s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.54s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 74400: {'rewards_eval/chosen': '-0.48505', 'rewards_eval/rejected': '-0.5923', 'rewards_eval/accuracies': '0.54492', 'rewards_eval/margins': '0.1073', 'logps_eval/rejected': '-128.08', 'logps_eval/chosen': '-123.34', 'loss/eval': '0.67183'}
skipping logging after 74416 examples to avoid logging too frequently
train stats after 74432 examples: {'rewards_train/chosen': '-0.34284', 'rewards_train/rejected': '-0.55043', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.20752', 'logps_train/rejected': '-116.92', 'logps_train/chosen': '-140.34', 'loss/train': '0.6342', 'examples_per_second': '4.5724', 'grad_norm': '18.375', 'counters/examples': 74432, 'counters/updates': 4652}
skipping logging after 74448 examples to avoid logging too frequently
skipping logging after 74464 examples to avoid logging too frequently
skipping logging after 74480 examples to avoid logging too frequently
train stats after 74496 examples: {'rewards_train/chosen': '-0.4733', 'rewards_train/rejected': '-0.67742', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.20419', 'logps_train/rejected': '-105.19', 'logps_train/chosen': '-129.81', 'loss/train': '0.6264', 'examples_per_second': '6.825', 'grad_norm': '22.875', 'counters/examples': 74496, 'counters/updates': 4656}
skipping logging after 74512 examples to avoid logging too frequently
skipping logging after 74528 examples to avoid logging too frequently
skipping logging after 74544 examples to avoid logging too frequently
train stats after 74560 examples: {'rewards_train/chosen': '-0.66566', 'rewards_train/rejected': '-0.81724', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.15174', 'logps_train/rejected': '-119.25', 'logps_train/chosen': '-112.83', 'loss/train': '0.64993', 'examples_per_second': '6.0091', 'grad_norm': '23.375', 'counters/examples': 74560, 'counters/updates': 4660}
skipping logging after 74576 examples to avoid logging too frequently
skipping logging after 74592 examples to avoid logging too frequently
skipping logging after 74608 examples to avoid logging too frequently
train stats after 74624 examples: {'rewards_train/chosen': '-0.52188', 'rewards_train/rejected': '-0.65961', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.13772', 'logps_train/rejected': '-135.02', 'logps_train/chosen': '-132.38', 'loss/train': '0.65866', 'examples_per_second': '5.388', 'grad_norm': '21.375', 'counters/examples': 74624, 'counters/updates': 4664}
skipping logging after 74640 examples to avoid logging too frequently
skipping logging after 74656 examples to avoid logging too frequently
skipping logging after 74672 examples to avoid logging too frequently
train stats after 74688 examples: {'rewards_train/chosen': '-0.53688', 'rewards_train/rejected': '-0.62791', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.091108', 'logps_train/rejected': '-157.3', 'logps_train/chosen': '-144.91', 'loss/train': '0.68205', 'examples_per_second': '4.7321', 'grad_norm': '28.25', 'counters/examples': 74688, 'counters/updates': 4668}
skipping logging after 74704 examples to avoid logging too frequently
skipping logging after 74720 examples to avoid logging too frequently
skipping logging after 74736 examples to avoid logging too frequently
train stats after 74752 examples: {'rewards_train/chosen': '-0.38532', 'rewards_train/rejected': '-0.49117', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.10582', 'logps_train/rejected': '-103.05', 'logps_train/chosen': '-112.59', 'loss/train': '0.65216', 'examples_per_second': '5.1885', 'grad_norm': '18.5', 'counters/examples': 74752, 'counters/updates': 4672}
skipping logging after 74768 examples to avoid logging too frequently
skipping logging after 74784 examples to avoid logging too frequently
skipping logging after 74800 examples to avoid logging too frequently
train stats after 74816 examples: {'rewards_train/chosen': '-0.48986', 'rewards_train/rejected': '-0.55526', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.065273', 'logps_train/rejected': '-115.19', 'logps_train/chosen': '-134.24', 'loss/train': '0.68765', 'examples_per_second': '4.9904', 'grad_norm': '17', 'counters/examples': 74816, 'counters/updates': 4676}
skipping logging after 74832 examples to avoid logging too frequently
skipping logging after 74848 examples to avoid logging too frequently
skipping logging after 74864 examples to avoid logging too frequently
train stats after 74880 examples: {'rewards_train/chosen': '-0.46361', 'rewards_train/rejected': '-0.69013', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.22663', 'logps_train/rejected': '-117.38', 'logps_train/chosen': '-116.71', 'loss/train': '0.62256', 'examples_per_second': '6.0261', 'grad_norm': '22.625', 'counters/examples': 74880, 'counters/updates': 4680}
skipping logging after 74896 examples to avoid logging too frequently
skipping logging after 74912 examples to avoid logging too frequently
skipping logging after 74928 examples to avoid logging too frequently
train stats after 74944 examples: {'rewards_train/chosen': '-0.47117', 'rewards_train/rejected': '-0.62007', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.14906', 'logps_train/rejected': '-132.97', 'logps_train/chosen': '-130.91', 'loss/train': '0.64252', 'examples_per_second': '4.9276', 'grad_norm': '17.625', 'counters/examples': 74944, 'counters/updates': 4684}
skipping logging after 74960 examples to avoid logging too frequently
skipping logging after 74976 examples to avoid logging too frequently
skipping logging after 74992 examples to avoid logging too frequently
train stats after 75008 examples: {'rewards_train/chosen': '-0.42639', 'rewards_train/rejected': '-0.45576', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.029278', 'logps_train/rejected': '-137.91', 'logps_train/chosen': '-132.62', 'loss/train': '0.70648', 'examples_per_second': '5.632', 'grad_norm': '21.75', 'counters/examples': 75008, 'counters/updates': 4688}
skipping logging after 75024 examples to avoid logging too frequently
skipping logging after 75040 examples to avoid logging too frequently
skipping logging after 75056 examples to avoid logging too frequently
train stats after 75072 examples: {'rewards_train/chosen': '-0.44529', 'rewards_train/rejected': '-0.50292', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.057714', 'logps_train/rejected': '-122.76', 'logps_train/chosen': '-117.8', 'loss/train': '0.6868', 'examples_per_second': '5.3437', 'grad_norm': '17.5', 'counters/examples': 75072, 'counters/updates': 4692}
skipping logging after 75088 examples to avoid logging too frequently
skipping logging after 75104 examples to avoid logging too frequently
skipping logging after 75120 examples to avoid logging too frequently
train stats after 75136 examples: {'rewards_train/chosen': '-0.34035', 'rewards_train/rejected': '-0.45559', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.11534', 'logps_train/rejected': '-127.34', 'logps_train/chosen': '-140.69', 'loss/train': '0.66519', 'examples_per_second': '4.5862', 'grad_norm': '21.375', 'counters/examples': 75136, 'counters/updates': 4696}
skipping logging after 75152 examples to avoid logging too frequently
skipping logging after 75168 examples to avoid logging too frequently
skipping logging after 75184 examples to avoid logging too frequently
train stats after 75200 examples: {'rewards_train/chosen': '-0.40002', 'rewards_train/rejected': '-0.54983', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.15005', 'logps_train/rejected': '-111.78', 'logps_train/chosen': '-119.45', 'loss/train': '0.64787', 'examples_per_second': '5.1253', 'grad_norm': '18.5', 'counters/examples': 75200, 'counters/updates': 4700}
skipping logging after 75216 examples to avoid logging too frequently
skipping logging after 75232 examples to avoid logging too frequently
skipping logging after 75248 examples to avoid logging too frequently
train stats after 75264 examples: {'rewards_train/chosen': '-0.35464', 'rewards_train/rejected': '-0.49957', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.14499', 'logps_train/rejected': '-121.5', 'logps_train/chosen': '-126.54', 'loss/train': '0.65341', 'examples_per_second': '6.2917', 'grad_norm': '19.75', 'counters/examples': 75264, 'counters/updates': 4704}
skipping logging after 75280 examples to avoid logging too frequently
skipping logging after 75296 examples to avoid logging too frequently
skipping logging after 75312 examples to avoid logging too frequently
train stats after 75328 examples: {'rewards_train/chosen': '-0.36801', 'rewards_train/rejected': '-0.46529', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.097218', 'logps_train/rejected': '-133.81', 'logps_train/chosen': '-124.08', 'loss/train': '0.66272', 'examples_per_second': '4.2877', 'grad_norm': '17.25', 'counters/examples': 75328, 'counters/updates': 4708}
skipping logging after 75344 examples to avoid logging too frequently
skipping logging after 75360 examples to avoid logging too frequently
skipping logging after 75376 examples to avoid logging too frequently
train stats after 75392 examples: {'rewards_train/chosen': '-0.41903', 'rewards_train/rejected': '-0.56735', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.1484', 'logps_train/rejected': '-123.92', 'logps_train/chosen': '-133.52', 'loss/train': '0.64427', 'examples_per_second': '4.4651', 'grad_norm': '19.375', 'counters/examples': 75392, 'counters/updates': 4712}
Running evaluation after 75392 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.83s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 75392: {'rewards_eval/chosen': '-0.36805', 'rewards_eval/rejected': '-0.45914', 'rewards_eval/accuracies': '0.53516', 'rewards_eval/margins': '0.091061', 'logps_eval/rejected': '-126.75', 'logps_eval/chosen': '-122.17', 'loss/eval': '0.6739'}
skipping logging after 75408 examples to avoid logging too frequently
skipping logging after 75424 examples to avoid logging too frequently
skipping logging after 75440 examples to avoid logging too frequently
train stats after 75456 examples: {'rewards_train/chosen': '-0.40056', 'rewards_train/rejected': '-0.46108', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.060577', 'logps_train/rejected': '-124.8', 'logps_train/chosen': '-127.94', 'loss/train': '0.68347', 'examples_per_second': '4.4835', 'grad_norm': '21.375', 'counters/examples': 75456, 'counters/updates': 4716}
skipping logging after 75472 examples to avoid logging too frequently
skipping logging after 75488 examples to avoid logging too frequently
skipping logging after 75504 examples to avoid logging too frequently
train stats after 75520 examples: {'rewards_train/chosen': '-0.35057', 'rewards_train/rejected': '-0.45939', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.1089', 'logps_train/rejected': '-96.541', 'logps_train/chosen': '-106.52', 'loss/train': '0.66168', 'examples_per_second': '5.5209', 'grad_norm': '15.438', 'counters/examples': 75520, 'counters/updates': 4720}
skipping logging after 75536 examples to avoid logging too frequently
skipping logging after 75552 examples to avoid logging too frequently
skipping logging after 75568 examples to avoid logging too frequently
train stats after 75584 examples: {'rewards_train/chosen': '-0.33508', 'rewards_train/rejected': '-0.50007', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.16501', 'logps_train/rejected': '-103.21', 'logps_train/chosen': '-107.89', 'loss/train': '0.63698', 'examples_per_second': '4.0648', 'grad_norm': '15.375', 'counters/examples': 75584, 'counters/updates': 4724}
skipping logging after 75600 examples to avoid logging too frequently
skipping logging after 75616 examples to avoid logging too frequently
skipping logging after 75632 examples to avoid logging too frequently
train stats after 75648 examples: {'rewards_train/chosen': '-0.41721', 'rewards_train/rejected': '-0.4739', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.05666', 'logps_train/rejected': '-107.25', 'logps_train/chosen': '-113.1', 'loss/train': '0.69006', 'examples_per_second': '4.7664', 'grad_norm': '21', 'counters/examples': 75648, 'counters/updates': 4728}
skipping logging after 75664 examples to avoid logging too frequently
skipping logging after 75680 examples to avoid logging too frequently
skipping logging after 75696 examples to avoid logging too frequently
train stats after 75712 examples: {'rewards_train/chosen': '-0.28502', 'rewards_train/rejected': '-0.36285', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.077839', 'logps_train/rejected': '-127.8', 'logps_train/chosen': '-120.71', 'loss/train': '0.66971', 'examples_per_second': '6.031', 'grad_norm': '18', 'counters/examples': 75712, 'counters/updates': 4732}
skipping logging after 75728 examples to avoid logging too frequently
skipping logging after 75744 examples to avoid logging too frequently
skipping logging after 75760 examples to avoid logging too frequently
train stats after 75776 examples: {'rewards_train/chosen': '-0.3094', 'rewards_train/rejected': '-0.41713', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.10779', 'logps_train/rejected': '-114.32', 'logps_train/chosen': '-107.39', 'loss/train': '0.66031', 'examples_per_second': '6.1063', 'grad_norm': '18.125', 'counters/examples': 75776, 'counters/updates': 4736}
skipping logging after 75792 examples to avoid logging too frequently
skipping logging after 75808 examples to avoid logging too frequently
skipping logging after 75824 examples to avoid logging too frequently
train stats after 75840 examples: {'rewards_train/chosen': '-0.24195', 'rewards_train/rejected': '-0.41794', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.176', 'logps_train/rejected': '-147.54', 'logps_train/chosen': '-129.84', 'loss/train': '0.63553', 'examples_per_second': '4.174', 'grad_norm': '18.125', 'counters/examples': 75840, 'counters/updates': 4740}
skipping logging after 75856 examples to avoid logging too frequently
skipping logging after 75872 examples to avoid logging too frequently
skipping logging after 75888 examples to avoid logging too frequently
train stats after 75904 examples: {'rewards_train/chosen': '-0.33731', 'rewards_train/rejected': '-0.50826', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.17123', 'logps_train/rejected': '-136.53', 'logps_train/chosen': '-128.27', 'loss/train': '0.63634', 'examples_per_second': '5.5709', 'grad_norm': '20.875', 'counters/examples': 75904, 'counters/updates': 4744}
skipping logging after 75920 examples to avoid logging too frequently
skipping logging after 75936 examples to avoid logging too frequently
skipping logging after 75952 examples to avoid logging too frequently
train stats after 75968 examples: {'rewards_train/chosen': '-0.3627', 'rewards_train/rejected': '-0.43077', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.068138', 'logps_train/rejected': '-114.29', 'logps_train/chosen': '-118.29', 'loss/train': '0.68114', 'examples_per_second': '4.8343', 'grad_norm': '18.875', 'counters/examples': 75968, 'counters/updates': 4748}
skipping logging after 75984 examples to avoid logging too frequently
skipping logging after 76000 examples to avoid logging too frequently
skipping logging after 76016 examples to avoid logging too frequently
train stats after 76032 examples: {'rewards_train/chosen': '-0.51655', 'rewards_train/rejected': '-0.62697', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.11058', 'logps_train/rejected': '-103.88', 'logps_train/chosen': '-115.39', 'loss/train': '0.67891', 'examples_per_second': '5.6733', 'grad_norm': '22.875', 'counters/examples': 76032, 'counters/updates': 4752}
skipping logging after 76048 examples to avoid logging too frequently
skipping logging after 76064 examples to avoid logging too frequently
skipping logging after 76080 examples to avoid logging too frequently
train stats after 76096 examples: {'rewards_train/chosen': '-0.36845', 'rewards_train/rejected': '-0.48547', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.11693', 'logps_train/rejected': '-138.17', 'logps_train/chosen': '-132.59', 'loss/train': '0.65393', 'examples_per_second': '5.4695', 'grad_norm': '17.625', 'counters/examples': 76096, 'counters/updates': 4756}
skipping logging after 76112 examples to avoid logging too frequently
skipping logging after 76128 examples to avoid logging too frequently
skipping logging after 76144 examples to avoid logging too frequently
train stats after 76160 examples: {'rewards_train/chosen': '-0.35894', 'rewards_train/rejected': '-0.52787', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.16895', 'logps_train/rejected': '-117.92', 'logps_train/chosen': '-103.92', 'loss/train': '0.63252', 'examples_per_second': '4.2832', 'grad_norm': '16.875', 'counters/examples': 76160, 'counters/updates': 4760}
skipping logging after 76176 examples to avoid logging too frequently
skipping logging after 76192 examples to avoid logging too frequently
skipping logging after 76208 examples to avoid logging too frequently
train stats after 76224 examples: {'rewards_train/chosen': '-0.465', 'rewards_train/rejected': '-0.52084', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.055759', 'logps_train/rejected': '-135.76', 'logps_train/chosen': '-94.454', 'loss/train': '0.69095', 'examples_per_second': '5.7025', 'grad_norm': '18.375', 'counters/examples': 76224, 'counters/updates': 4764}
skipping logging after 76240 examples to avoid logging too frequently
skipping logging after 76256 examples to avoid logging too frequently
skipping logging after 76272 examples to avoid logging too frequently
train stats after 76288 examples: {'rewards_train/chosen': '-0.40454', 'rewards_train/rejected': '-0.56384', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.15938', 'logps_train/rejected': '-126.22', 'logps_train/chosen': '-120.29', 'loss/train': '0.6369', 'examples_per_second': '5.2527', 'grad_norm': '17.625', 'counters/examples': 76288, 'counters/updates': 4768}
skipping logging after 76304 examples to avoid logging too frequently
skipping logging after 76320 examples to avoid logging too frequently
skipping logging after 76336 examples to avoid logging too frequently
train stats after 76352 examples: {'rewards_train/chosen': '-0.39648', 'rewards_train/rejected': '-0.43806', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.041595', 'logps_train/rejected': '-106.05', 'logps_train/chosen': '-109.7', 'loss/train': '0.70222', 'examples_per_second': '4.8907', 'grad_norm': '20.5', 'counters/examples': 76352, 'counters/updates': 4772}
skipping logging after 76368 examples to avoid logging too frequently
skipping logging after 76384 examples to avoid logging too frequently
Running evaluation after 76384 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:18,  2.52s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:07,  2.24s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:56,  1.96s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:08<00:53,  1.92s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:42,  1.56s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.66s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.49s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.48s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.55s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.44s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.23s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.25s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:37<00:07,  1.29s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 76384: {'rewards_eval/chosen': '-0.39298', 'rewards_eval/rejected': '-0.4921', 'rewards_eval/accuracies': '0.53711', 'rewards_eval/margins': '0.099143', 'logps_eval/rejected': '-127.08', 'logps_eval/chosen': '-122.43', 'loss/eval': '0.67293'}
skipping logging after 76400 examples to avoid logging too frequently
train stats after 76416 examples: {'rewards_train/chosen': '-0.39748', 'rewards_train/rejected': '-0.55433', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.15685', 'logps_train/rejected': '-137.98', 'logps_train/chosen': '-122.16', 'loss/train': '0.64211', 'examples_per_second': '4.9036', 'grad_norm': '19.125', 'counters/examples': 76416, 'counters/updates': 4776}
skipping logging after 76432 examples to avoid logging too frequently
skipping logging after 76448 examples to avoid logging too frequently
skipping logging after 76464 examples to avoid logging too frequently
train stats after 76480 examples: {'rewards_train/chosen': '-0.41622', 'rewards_train/rejected': '-0.51976', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.1036', 'logps_train/rejected': '-123.81', 'logps_train/chosen': '-114.87', 'loss/train': '0.66632', 'examples_per_second': '5.2538', 'grad_norm': '20.875', 'counters/examples': 76480, 'counters/updates': 4780}
skipping logging after 76496 examples to avoid logging too frequently
skipping logging after 76512 examples to avoid logging too frequently
skipping logging after 76528 examples to avoid logging too frequently
train stats after 76544 examples: {'rewards_train/chosen': '-0.33261', 'rewards_train/rejected': '-0.45362', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.12116', 'logps_train/rejected': '-111.29', 'logps_train/chosen': '-110.91', 'loss/train': '0.65515', 'examples_per_second': '6.3349', 'grad_norm': '16.375', 'counters/examples': 76544, 'counters/updates': 4784}
skipping logging after 76560 examples to avoid logging too frequently
skipping logging after 76576 examples to avoid logging too frequently
skipping logging after 76592 examples to avoid logging too frequently
train stats after 76608 examples: {'rewards_train/chosen': '-0.35176', 'rewards_train/rejected': '-0.3668', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.015013', 'logps_train/rejected': '-115.19', 'logps_train/chosen': '-136.65', 'loss/train': '0.71381', 'examples_per_second': '5.3062', 'grad_norm': '23', 'counters/examples': 76608, 'counters/updates': 4788}
skipping logging after 76624 examples to avoid logging too frequently
skipping logging after 76640 examples to avoid logging too frequently
skipping logging after 76656 examples to avoid logging too frequently
train stats after 76672 examples: {'rewards_train/chosen': '-0.34582', 'rewards_train/rejected': '-0.31905', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '-0.026798', 'logps_train/rejected': '-111.81', 'logps_train/chosen': '-132.73', 'loss/train': '0.72229', 'examples_per_second': '5.024', 'grad_norm': '19.875', 'counters/examples': 76672, 'counters/updates': 4792}
skipping logging after 76688 examples to avoid logging too frequently
skipping logging after 76704 examples to avoid logging too frequently
skipping logging after 76720 examples to avoid logging too frequently
train stats after 76736 examples: {'rewards_train/chosen': '-0.36554', 'rewards_train/rejected': '-0.53671', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.17117', 'logps_train/rejected': '-123.96', 'logps_train/chosen': '-132.23', 'loss/train': '0.63974', 'examples_per_second': '5.8008', 'grad_norm': '20.5', 'counters/examples': 76736, 'counters/updates': 4796}
skipping logging after 76752 examples to avoid logging too frequently
skipping logging after 76768 examples to avoid logging too frequently
skipping logging after 76784 examples to avoid logging too frequently
train stats after 76800 examples: {'rewards_train/chosen': '-0.35093', 'rewards_train/rejected': '-0.4666', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.11561', 'logps_train/rejected': '-112.61', 'logps_train/chosen': '-107.45', 'loss/train': '0.65736', 'examples_per_second': '4.4978', 'grad_norm': '17.375', 'counters/examples': 76800, 'counters/updates': 4800}
skipping logging after 76816 examples to avoid logging too frequently
skipping logging after 76832 examples to avoid logging too frequently
skipping logging after 76848 examples to avoid logging too frequently
train stats after 76864 examples: {'rewards_train/chosen': '-0.43894', 'rewards_train/rejected': '-0.54785', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.10897', 'logps_train/rejected': '-102.09', 'logps_train/chosen': '-111.55', 'loss/train': '0.65393', 'examples_per_second': '5.9724', 'grad_norm': '17.125', 'counters/examples': 76864, 'counters/updates': 4804}
skipping logging after 76880 examples to avoid logging too frequently
skipping logging after 76896 examples to avoid logging too frequently
skipping logging after 76912 examples to avoid logging too frequently
train stats after 76928 examples: {'rewards_train/chosen': '-0.32416', 'rewards_train/rejected': '-0.46325', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.13912', 'logps_train/rejected': '-112.58', 'logps_train/chosen': '-118.99', 'loss/train': '0.64789', 'examples_per_second': '4.8801', 'grad_norm': '17.875', 'counters/examples': 76928, 'counters/updates': 4808}
skipping logging after 76944 examples to avoid logging too frequently
skipping logging after 76960 examples to avoid logging too frequently
skipping logging after 76976 examples to avoid logging too frequently
train stats after 76992 examples: {'rewards_train/chosen': '-0.31991', 'rewards_train/rejected': '-0.45551', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.1357', 'logps_train/rejected': '-117.47', 'logps_train/chosen': '-120.32', 'loss/train': '0.6412', 'examples_per_second': '5.3382', 'grad_norm': '20.875', 'counters/examples': 76992, 'counters/updates': 4812}
skipping logging after 77008 examples to avoid logging too frequently
skipping logging after 77024 examples to avoid logging too frequently
skipping logging after 77040 examples to avoid logging too frequently
train stats after 77056 examples: {'rewards_train/chosen': '-0.3587', 'rewards_train/rejected': '-0.54996', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.19122', 'logps_train/rejected': '-119.51', 'logps_train/chosen': '-121.68', 'loss/train': '0.62752', 'examples_per_second': '5.1473', 'grad_norm': '21', 'counters/examples': 77056, 'counters/updates': 4816}
skipping logging after 77072 examples to avoid logging too frequently
skipping logging after 77088 examples to avoid logging too frequently
skipping logging after 77104 examples to avoid logging too frequently
train stats after 77120 examples: {'rewards_train/chosen': '-0.51273', 'rewards_train/rejected': '-0.62701', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.11417', 'logps_train/rejected': '-133.53', 'logps_train/chosen': '-109.58', 'loss/train': '0.66255', 'examples_per_second': '4.823', 'grad_norm': '16.5', 'counters/examples': 77120, 'counters/updates': 4820}
skipping logging after 77136 examples to avoid logging too frequently
skipping logging after 77152 examples to avoid logging too frequently
skipping logging after 77168 examples to avoid logging too frequently
train stats after 77184 examples: {'rewards_train/chosen': '-0.51103', 'rewards_train/rejected': '-0.48463', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '-0.026375', 'logps_train/rejected': '-124.51', 'logps_train/chosen': '-127.16', 'loss/train': '0.72955', 'examples_per_second': '4.9992', 'grad_norm': '20.375', 'counters/examples': 77184, 'counters/updates': 4824}
skipping logging after 77200 examples to avoid logging too frequently
skipping logging after 77216 examples to avoid logging too frequently
skipping logging after 77232 examples to avoid logging too frequently
train stats after 77248 examples: {'rewards_train/chosen': '-0.40774', 'rewards_train/rejected': '-0.52712', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.11927', 'logps_train/rejected': '-121.38', 'logps_train/chosen': '-128.57', 'loss/train': '0.65805', 'examples_per_second': '5.5047', 'grad_norm': '16.25', 'counters/examples': 77248, 'counters/updates': 4828}
skipping logging after 77264 examples to avoid logging too frequently
skipping logging after 77280 examples to avoid logging too frequently
skipping logging after 77296 examples to avoid logging too frequently
train stats after 77312 examples: {'rewards_train/chosen': '-0.46284', 'rewards_train/rejected': '-0.53301', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.070156', 'logps_train/rejected': '-113.25', 'logps_train/chosen': '-110.03', 'loss/train': '0.69479', 'examples_per_second': '5.5747', 'grad_norm': '22.875', 'counters/examples': 77312, 'counters/updates': 4832}
skipping logging after 77328 examples to avoid logging too frequently
skipping logging after 77344 examples to avoid logging too frequently
skipping logging after 77360 examples to avoid logging too frequently
train stats after 77376 examples: {'rewards_train/chosen': '-0.39406', 'rewards_train/rejected': '-0.43163', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.037518', 'logps_train/rejected': '-134.56', 'logps_train/chosen': '-125.1', 'loss/train': '0.6951', 'examples_per_second': '4.6703', 'grad_norm': '19.5', 'counters/examples': 77376, 'counters/updates': 4836}
Running evaluation after 77376 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 77376: {'rewards_eval/chosen': '-0.4081', 'rewards_eval/rejected': '-0.5081', 'rewards_eval/accuracies': '0.55664', 'rewards_eval/margins': '0.10003', 'logps_eval/rejected': '-127.24', 'logps_eval/chosen': '-122.57', 'loss/eval': '0.67249'}
skipping logging after 77392 examples to avoid logging too frequently
skipping logging after 77408 examples to avoid logging too frequently
skipping logging after 77424 examples to avoid logging too frequently
train stats after 77440 examples: {'rewards_train/chosen': '-0.3851', 'rewards_train/rejected': '-0.49815', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.1132', 'logps_train/rejected': '-115.54', 'logps_train/chosen': '-103.04', 'loss/train': '0.65121', 'examples_per_second': '4.1434', 'grad_norm': '16.875', 'counters/examples': 77440, 'counters/updates': 4840}
skipping logging after 77456 examples to avoid logging too frequently
skipping logging after 77472 examples to avoid logging too frequently
skipping logging after 77488 examples to avoid logging too frequently
train stats after 77504 examples: {'rewards_train/chosen': '-0.40414', 'rewards_train/rejected': '-0.45257', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.048485', 'logps_train/rejected': '-171.99', 'logps_train/chosen': '-151.81', 'loss/train': '0.69923', 'examples_per_second': '4.5499', 'grad_norm': '21.75', 'counters/examples': 77504, 'counters/updates': 4844}
skipping logging after 77520 examples to avoid logging too frequently
skipping logging after 77536 examples to avoid logging too frequently
skipping logging after 77552 examples to avoid logging too frequently
train stats after 77568 examples: {'rewards_train/chosen': '-0.40578', 'rewards_train/rejected': '-0.4247', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.019077', 'logps_train/rejected': '-107.66', 'logps_train/chosen': '-121.02', 'loss/train': '0.71048', 'examples_per_second': '5.0004', 'grad_norm': '20', 'counters/examples': 77568, 'counters/updates': 4848}
skipping logging after 77584 examples to avoid logging too frequently
skipping logging after 77600 examples to avoid logging too frequently
skipping logging after 77616 examples to avoid logging too frequently
train stats after 77632 examples: {'rewards_train/chosen': '-0.27755', 'rewards_train/rejected': '-0.34404', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.066519', 'logps_train/rejected': '-164.38', 'logps_train/chosen': '-149.58', 'loss/train': '0.68855', 'examples_per_second': '4.0403', 'grad_norm': '21.25', 'counters/examples': 77632, 'counters/updates': 4852}
skipping logging after 77648 examples to avoid logging too frequently
skipping logging after 77664 examples to avoid logging too frequently
skipping logging after 77680 examples to avoid logging too frequently
train stats after 77696 examples: {'rewards_train/chosen': '-0.40324', 'rewards_train/rejected': '-0.61042', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.20719', 'logps_train/rejected': '-125.37', 'logps_train/chosen': '-129.74', 'loss/train': '0.62506', 'examples_per_second': '5.5771', 'grad_norm': '20.375', 'counters/examples': 77696, 'counters/updates': 4856}
skipping logging after 77712 examples to avoid logging too frequently
skipping logging after 77728 examples to avoid logging too frequently
skipping logging after 77744 examples to avoid logging too frequently
train stats after 77760 examples: {'rewards_train/chosen': '-0.32408', 'rewards_train/rejected': '-0.48406', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.15995', 'logps_train/rejected': '-123.99', 'logps_train/chosen': '-107.18', 'loss/train': '0.63895', 'examples_per_second': '4.9034', 'grad_norm': '17.25', 'counters/examples': 77760, 'counters/updates': 4860}
skipping logging after 77776 examples to avoid logging too frequently
skipping logging after 77792 examples to avoid logging too frequently
skipping logging after 77808 examples to avoid logging too frequently
train stats after 77824 examples: {'rewards_train/chosen': '-0.40163', 'rewards_train/rejected': '-0.54589', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.14434', 'logps_train/rejected': '-145.85', 'logps_train/chosen': '-131.17', 'loss/train': '0.64687', 'examples_per_second': '4.811', 'grad_norm': '17.25', 'counters/examples': 77824, 'counters/updates': 4864}
skipping logging after 77840 examples to avoid logging too frequently
skipping logging after 77856 examples to avoid logging too frequently
skipping logging after 77872 examples to avoid logging too frequently
train stats after 77888 examples: {'rewards_train/chosen': '-0.35473', 'rewards_train/rejected': '-0.52284', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.16802', 'logps_train/rejected': '-156.47', 'logps_train/chosen': '-135.65', 'loss/train': '0.62787', 'examples_per_second': '5.0262', 'grad_norm': '19', 'counters/examples': 77888, 'counters/updates': 4868}
skipping logging after 77904 examples to avoid logging too frequently
skipping logging after 77920 examples to avoid logging too frequently
skipping logging after 77936 examples to avoid logging too frequently
train stats after 77952 examples: {'rewards_train/chosen': '-0.43295', 'rewards_train/rejected': '-0.48427', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.051357', 'logps_train/rejected': '-129', 'logps_train/chosen': '-110.72', 'loss/train': '0.702', 'examples_per_second': '4.8781', 'grad_norm': '21.625', 'counters/examples': 77952, 'counters/updates': 4872}
skipping logging after 77968 examples to avoid logging too frequently
skipping logging after 77984 examples to avoid logging too frequently
skipping logging after 78000 examples to avoid logging too frequently
train stats after 78016 examples: {'rewards_train/chosen': '-0.40293', 'rewards_train/rejected': '-0.57442', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.17135', 'logps_train/rejected': '-122.76', 'logps_train/chosen': '-128.91', 'loss/train': '0.63651', 'examples_per_second': '5.8512', 'grad_norm': '23.5', 'counters/examples': 78016, 'counters/updates': 4876}
skipping logging after 78032 examples to avoid logging too frequently
skipping logging after 78048 examples to avoid logging too frequently
skipping logging after 78064 examples to avoid logging too frequently
train stats after 78080 examples: {'rewards_train/chosen': '-0.34503', 'rewards_train/rejected': '-0.35142', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.0065498', 'logps_train/rejected': '-131.79', 'logps_train/chosen': '-132.95', 'loss/train': '0.71716', 'examples_per_second': '4.153', 'grad_norm': '20.625', 'counters/examples': 78080, 'counters/updates': 4880}
skipping logging after 78096 examples to avoid logging too frequently
skipping logging after 78112 examples to avoid logging too frequently
skipping logging after 78128 examples to avoid logging too frequently
train stats after 78144 examples: {'rewards_train/chosen': '-0.33434', 'rewards_train/rejected': '-0.47833', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.14388', 'logps_train/rejected': '-111.86', 'logps_train/chosen': '-132.45', 'loss/train': '0.64177', 'examples_per_second': '5.898', 'grad_norm': '17.375', 'counters/examples': 78144, 'counters/updates': 4884}
skipping logging after 78160 examples to avoid logging too frequently
skipping logging after 78176 examples to avoid logging too frequently
skipping logging after 78192 examples to avoid logging too frequently
train stats after 78208 examples: {'rewards_train/chosen': '-0.38739', 'rewards_train/rejected': '-0.3815', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '-0.0058365', 'logps_train/rejected': '-120.38', 'logps_train/chosen': '-121.08', 'loss/train': '0.71634', 'examples_per_second': '4.7938', 'grad_norm': '23.5', 'counters/examples': 78208, 'counters/updates': 4888}
skipping logging after 78224 examples to avoid logging too frequently
skipping logging after 78240 examples to avoid logging too frequently
skipping logging after 78256 examples to avoid logging too frequently
train stats after 78272 examples: {'rewards_train/chosen': '-0.4673', 'rewards_train/rejected': '-0.47358', 'rewards_train/accuracies': '0.40625', 'rewards_train/margins': '0.0062561', 'logps_train/rejected': '-135.15', 'logps_train/chosen': '-147.65', 'loss/train': '0.70261', 'examples_per_second': '5.3332', 'grad_norm': '23.875', 'counters/examples': 78272, 'counters/updates': 4892}
skipping logging after 78288 examples to avoid logging too frequently
skipping logging after 78304 examples to avoid logging too frequently
skipping logging after 78320 examples to avoid logging too frequently
train stats after 78336 examples: {'rewards_train/chosen': '-0.32164', 'rewards_train/rejected': '-0.46046', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.13874', 'logps_train/rejected': '-139.64', 'logps_train/chosen': '-146.21', 'loss/train': '0.64536', 'examples_per_second': '4.5357', 'grad_norm': '17.375', 'counters/examples': 78336, 'counters/updates': 4896}
skipping logging after 78352 examples to avoid logging too frequently
skipping logging after 78368 examples to avoid logging too frequently
Running evaluation after 78368 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:10,  2.27s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:03,  2.13s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.90s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.88s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 78368: {'rewards_eval/chosen': '-0.36546', 'rewards_eval/rejected': '-0.45785', 'rewards_eval/accuracies': '0.54492', 'rewards_eval/margins': '0.092404', 'logps_eval/rejected': '-126.73', 'logps_eval/chosen': '-122.15', 'loss/eval': '0.67274'}
skipping logging after 78384 examples to avoid logging too frequently
train stats after 78400 examples: {'rewards_train/chosen': '-0.29784', 'rewards_train/rejected': '-0.41687', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.11904', 'logps_train/rejected': '-121.62', 'logps_train/chosen': '-108.57', 'loss/train': '0.6609', 'examples_per_second': '6.129', 'grad_norm': '17.625', 'counters/examples': 78400, 'counters/updates': 4900}
skipping logging after 78416 examples to avoid logging too frequently
skipping logging after 78432 examples to avoid logging too frequently
skipping logging after 78448 examples to avoid logging too frequently
train stats after 78464 examples: {'rewards_train/chosen': '-0.34931', 'rewards_train/rejected': '-0.39426', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.044933', 'logps_train/rejected': '-111.69', 'logps_train/chosen': '-116.59', 'loss/train': '0.68724', 'examples_per_second': '4.9955', 'grad_norm': '21.25', 'counters/examples': 78464, 'counters/updates': 4904}
skipping logging after 78480 examples to avoid logging too frequently
skipping logging after 78496 examples to avoid logging too frequently
skipping logging after 78512 examples to avoid logging too frequently
train stats after 78528 examples: {'rewards_train/chosen': '-0.22692', 'rewards_train/rejected': '-0.38836', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.16153', 'logps_train/rejected': '-120.4', 'logps_train/chosen': '-131.03', 'loss/train': '0.64116', 'examples_per_second': '4.4652', 'grad_norm': '16.25', 'counters/examples': 78528, 'counters/updates': 4908}
skipping logging after 78544 examples to avoid logging too frequently
skipping logging after 78560 examples to avoid logging too frequently
skipping logging after 78576 examples to avoid logging too frequently
train stats after 78592 examples: {'rewards_train/chosen': '-0.35576', 'rewards_train/rejected': '-0.49447', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.13873', 'logps_train/rejected': '-124.96', 'logps_train/chosen': '-137.96', 'loss/train': '0.64856', 'examples_per_second': '5.5387', 'grad_norm': '18.125', 'counters/examples': 78592, 'counters/updates': 4912}
skipping logging after 78608 examples to avoid logging too frequently
skipping logging after 78624 examples to avoid logging too frequently
skipping logging after 78640 examples to avoid logging too frequently
train stats after 78656 examples: {'rewards_train/chosen': '-0.27457', 'rewards_train/rejected': '-0.38366', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.10905', 'logps_train/rejected': '-118.51', 'logps_train/chosen': '-118.37', 'loss/train': '0.66211', 'examples_per_second': '4.8088', 'grad_norm': '17.5', 'counters/examples': 78656, 'counters/updates': 4916}
skipping logging after 78672 examples to avoid logging too frequently
skipping logging after 78688 examples to avoid logging too frequently
skipping logging after 78704 examples to avoid logging too frequently
train stats after 78720 examples: {'rewards_train/chosen': '-0.3724', 'rewards_train/rejected': '-0.50495', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.1326', 'logps_train/rejected': '-116.78', 'logps_train/chosen': '-132.62', 'loss/train': '0.65053', 'examples_per_second': '5.0851', 'grad_norm': '20.75', 'counters/examples': 78720, 'counters/updates': 4920}
skipping logging after 78736 examples to avoid logging too frequently
skipping logging after 78752 examples to avoid logging too frequently
skipping logging after 78768 examples to avoid logging too frequently
train stats after 78784 examples: {'rewards_train/chosen': '-0.31288', 'rewards_train/rejected': '-0.46774', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.15494', 'logps_train/rejected': '-109.64', 'logps_train/chosen': '-102.53', 'loss/train': '0.63512', 'examples_per_second': '4.5049', 'grad_norm': '17.875', 'counters/examples': 78784, 'counters/updates': 4924}
skipping logging after 78800 examples to avoid logging too frequently
skipping logging after 78816 examples to avoid logging too frequently
skipping logging after 78832 examples to avoid logging too frequently
train stats after 78848 examples: {'rewards_train/chosen': '-0.40681', 'rewards_train/rejected': '-0.48027', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.073427', 'logps_train/rejected': '-131.83', 'logps_train/chosen': '-113.53', 'loss/train': '0.6799', 'examples_per_second': '5.9776', 'grad_norm': '21.5', 'counters/examples': 78848, 'counters/updates': 4928}
skipping logging after 78864 examples to avoid logging too frequently
skipping logging after 78880 examples to avoid logging too frequently
skipping logging after 78896 examples to avoid logging too frequently
train stats after 78912 examples: {'rewards_train/chosen': '-0.27006', 'rewards_train/rejected': '-0.45809', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.1878', 'logps_train/rejected': '-142.84', 'logps_train/chosen': '-98.872', 'loss/train': '0.62761', 'examples_per_second': '5.3492', 'grad_norm': '15.812', 'counters/examples': 78912, 'counters/updates': 4932}
skipping logging after 78928 examples to avoid logging too frequently
skipping logging after 78944 examples to avoid logging too frequently
skipping logging after 78960 examples to avoid logging too frequently
train stats after 78976 examples: {'rewards_train/chosen': '-0.33997', 'rewards_train/rejected': '-0.54013', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.20014', 'logps_train/rejected': '-148.13', 'logps_train/chosen': '-120', 'loss/train': '0.62576', 'examples_per_second': '5.9316', 'grad_norm': '16.625', 'counters/examples': 78976, 'counters/updates': 4936}
skipping logging after 78992 examples to avoid logging too frequently
skipping logging after 79008 examples to avoid logging too frequently
skipping logging after 79024 examples to avoid logging too frequently
train stats after 79040 examples: {'rewards_train/chosen': '-0.4658', 'rewards_train/rejected': '-0.51504', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.049171', 'logps_train/rejected': '-124.81', 'logps_train/chosen': '-138.95', 'loss/train': '0.68991', 'examples_per_second': '5.8816', 'grad_norm': '22.25', 'counters/examples': 79040, 'counters/updates': 4940}
skipping logging after 79056 examples to avoid logging too frequently
skipping logging after 79072 examples to avoid logging too frequently
skipping logging after 79088 examples to avoid logging too frequently
train stats after 79104 examples: {'rewards_train/chosen': '-0.37747', 'rewards_train/rejected': '-0.5391', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.16151', 'logps_train/rejected': '-99.458', 'logps_train/chosen': '-109.14', 'loss/train': '0.6483', 'examples_per_second': '5.0163', 'grad_norm': '16.5', 'counters/examples': 79104, 'counters/updates': 4944}
skipping logging after 79120 examples to avoid logging too frequently
skipping logging after 79136 examples to avoid logging too frequently
skipping logging after 79152 examples to avoid logging too frequently
train stats after 79168 examples: {'rewards_train/chosen': '-0.4173', 'rewards_train/rejected': '-0.53224', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.11495', 'logps_train/rejected': '-122.2', 'logps_train/chosen': '-104.19', 'loss/train': '0.65732', 'examples_per_second': '4.9245', 'grad_norm': '16.5', 'counters/examples': 79168, 'counters/updates': 4948}
skipping logging after 79184 examples to avoid logging too frequently
skipping logging after 79200 examples to avoid logging too frequently
skipping logging after 79216 examples to avoid logging too frequently
train stats after 79232 examples: {'rewards_train/chosen': '-0.41882', 'rewards_train/rejected': '-0.50511', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.086189', 'logps_train/rejected': '-128.88', 'logps_train/chosen': '-125.7', 'loss/train': '0.66483', 'examples_per_second': '5.7096', 'grad_norm': '16.5', 'counters/examples': 79232, 'counters/updates': 4952}
skipping logging after 79248 examples to avoid logging too frequently
skipping logging after 79264 examples to avoid logging too frequently
skipping logging after 79280 examples to avoid logging too frequently
train stats after 79296 examples: {'rewards_train/chosen': '-0.53461', 'rewards_train/rejected': '-0.66387', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.1293', 'logps_train/rejected': '-138.7', 'logps_train/chosen': '-134.95', 'loss/train': '0.67162', 'examples_per_second': '5.2115', 'grad_norm': '19.375', 'counters/examples': 79296, 'counters/updates': 4956}
skipping logging after 79312 examples to avoid logging too frequently
skipping logging after 79328 examples to avoid logging too frequently
skipping logging after 79344 examples to avoid logging too frequently
train stats after 79360 examples: {'rewards_train/chosen': '-0.46002', 'rewards_train/rejected': '-0.53588', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.07577', 'logps_train/rejected': '-126.49', 'logps_train/chosen': '-139.94', 'loss/train': '0.68701', 'examples_per_second': '4.8788', 'grad_norm': '22.25', 'counters/examples': 79360, 'counters/updates': 4960}
Running evaluation after 79360 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.46s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.53s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.42s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 79360: {'rewards_eval/chosen': '-0.43327', 'rewards_eval/rejected': '-0.53308', 'rewards_eval/accuracies': '0.54492', 'rewards_eval/margins': '0.099862', 'logps_eval/rejected': '-127.49', 'logps_eval/chosen': '-122.83', 'loss/eval': '0.67053'}
skipping logging after 79376 examples to avoid logging too frequently
skipping logging after 79392 examples to avoid logging too frequently
skipping logging after 79408 examples to avoid logging too frequently
train stats after 79424 examples: {'rewards_train/chosen': '-0.46376', 'rewards_train/rejected': '-0.45971', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '-0.0040207', 'logps_train/rejected': '-121.23', 'logps_train/chosen': '-136.81', 'loss/train': '0.71919', 'examples_per_second': '5.5372', 'grad_norm': '18.25', 'counters/examples': 79424, 'counters/updates': 4964}
skipping logging after 79440 examples to avoid logging too frequently
skipping logging after 79456 examples to avoid logging too frequently
skipping logging after 79472 examples to avoid logging too frequently
train stats after 79488 examples: {'rewards_train/chosen': '-0.43979', 'rewards_train/rejected': '-0.56504', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.12535', 'logps_train/rejected': '-136.33', 'logps_train/chosen': '-142.19', 'loss/train': '0.66087', 'examples_per_second': '5.1611', 'grad_norm': '17.25', 'counters/examples': 79488, 'counters/updates': 4968}
skipping logging after 79504 examples to avoid logging too frequently
skipping logging after 79520 examples to avoid logging too frequently
skipping logging after 79536 examples to avoid logging too frequently
train stats after 79552 examples: {'rewards_train/chosen': '-0.45099', 'rewards_train/rejected': '-0.47979', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.028614', 'logps_train/rejected': '-116.95', 'logps_train/chosen': '-123.13', 'loss/train': '0.71457', 'examples_per_second': '5.3588', 'grad_norm': '22', 'counters/examples': 79552, 'counters/updates': 4972}
skipping logging after 79568 examples to avoid logging too frequently
skipping logging after 79584 examples to avoid logging too frequently
skipping logging after 79600 examples to avoid logging too frequently
train stats after 79616 examples: {'rewards_train/chosen': '-0.42429', 'rewards_train/rejected': '-0.50911', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.08485', 'logps_train/rejected': '-128.43', 'logps_train/chosen': '-129.14', 'loss/train': '0.68607', 'examples_per_second': '5.5174', 'grad_norm': '21.125', 'counters/examples': 79616, 'counters/updates': 4976}
skipping logging after 79632 examples to avoid logging too frequently
skipping logging after 79648 examples to avoid logging too frequently
skipping logging after 79664 examples to avoid logging too frequently
train stats after 79680 examples: {'rewards_train/chosen': '-0.39559', 'rewards_train/rejected': '-0.51438', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.11873', 'logps_train/rejected': '-128.89', 'logps_train/chosen': '-149.68', 'loss/train': '0.66237', 'examples_per_second': '4.3922', 'grad_norm': '20.25', 'counters/examples': 79680, 'counters/updates': 4980}
skipping logging after 79696 examples to avoid logging too frequently
skipping logging after 79712 examples to avoid logging too frequently
skipping logging after 79728 examples to avoid logging too frequently
train stats after 79744 examples: {'rewards_train/chosen': '-0.36724', 'rewards_train/rejected': '-0.51232', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.14497', 'logps_train/rejected': '-110.48', 'logps_train/chosen': '-116.39', 'loss/train': '0.64424', 'examples_per_second': '5.1321', 'grad_norm': '16.5', 'counters/examples': 79744, 'counters/updates': 4984}
skipping logging after 79760 examples to avoid logging too frequently
skipping logging after 79776 examples to avoid logging too frequently
skipping logging after 79792 examples to avoid logging too frequently
train stats after 79808 examples: {'rewards_train/chosen': '-0.3537', 'rewards_train/rejected': '-0.38661', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.033009', 'logps_train/rejected': '-121.06', 'logps_train/chosen': '-105.13', 'loss/train': '0.69763', 'examples_per_second': '5.3555', 'grad_norm': '18', 'counters/examples': 79808, 'counters/updates': 4988}
skipping logging after 79824 examples to avoid logging too frequently
skipping logging after 79840 examples to avoid logging too frequently
skipping logging after 79856 examples to avoid logging too frequently
train stats after 79872 examples: {'rewards_train/chosen': '-0.3673', 'rewards_train/rejected': '-0.536', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.16856', 'logps_train/rejected': '-119.04', 'logps_train/chosen': '-92.263', 'loss/train': '0.65743', 'examples_per_second': '5.9269', 'grad_norm': '19.75', 'counters/examples': 79872, 'counters/updates': 4992}
skipping logging after 79888 examples to avoid logging too frequently
skipping logging after 79904 examples to avoid logging too frequently
skipping logging after 79920 examples to avoid logging too frequently
train stats after 79936 examples: {'rewards_train/chosen': '-0.30163', 'rewards_train/rejected': '-0.44706', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.14541', 'logps_train/rejected': '-117.17', 'logps_train/chosen': '-120.83', 'loss/train': '0.6395', 'examples_per_second': '4.771', 'grad_norm': '15.062', 'counters/examples': 79936, 'counters/updates': 4996}
skipping logging after 79952 examples to avoid logging too frequently
skipping logging after 79968 examples to avoid logging too frequently
skipping logging after 79984 examples to avoid logging too frequently
train stats after 80000 examples: {'rewards_train/chosen': '-0.38598', 'rewards_train/rejected': '-0.67593', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.29015', 'logps_train/rejected': '-118.81', 'logps_train/chosen': '-118.27', 'loss/train': '0.58789', 'examples_per_second': '5.9046', 'grad_norm': '18.875', 'counters/examples': 80000, 'counters/updates': 5000}
skipping logging after 80016 examples to avoid logging too frequently
skipping logging after 80032 examples to avoid logging too frequently
skipping logging after 80048 examples to avoid logging too frequently
train stats after 80064 examples: {'rewards_train/chosen': '-0.39282', 'rewards_train/rejected': '-0.49401', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.10122', 'logps_train/rejected': '-118.53', 'logps_train/chosen': '-120.29', 'loss/train': '0.65677', 'examples_per_second': '5.718', 'grad_norm': '17.375', 'counters/examples': 80064, 'counters/updates': 5004}
skipping logging after 80080 examples to avoid logging too frequently
skipping logging after 80096 examples to avoid logging too frequently
skipping logging after 80112 examples to avoid logging too frequently
train stats after 80128 examples: {'rewards_train/chosen': '-0.303', 'rewards_train/rejected': '-0.44366', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.1406', 'logps_train/rejected': '-117.6', 'logps_train/chosen': '-124.41', 'loss/train': '0.64294', 'examples_per_second': '5.5646', 'grad_norm': '17.125', 'counters/examples': 80128, 'counters/updates': 5008}
skipping logging after 80144 examples to avoid logging too frequently
skipping logging after 80160 examples to avoid logging too frequently
skipping logging after 80176 examples to avoid logging too frequently
train stats after 80192 examples: {'rewards_train/chosen': '-0.35069', 'rewards_train/rejected': '-0.49558', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.14493', 'logps_train/rejected': '-129.02', 'logps_train/chosen': '-119.85', 'loss/train': '0.64246', 'examples_per_second': '4.6002', 'grad_norm': '17.875', 'counters/examples': 80192, 'counters/updates': 5012}
skipping logging after 80208 examples to avoid logging too frequently
skipping logging after 80224 examples to avoid logging too frequently
skipping logging after 80240 examples to avoid logging too frequently
train stats after 80256 examples: {'rewards_train/chosen': '-0.57339', 'rewards_train/rejected': '-0.78091', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.20751', 'logps_train/rejected': '-93.902', 'logps_train/chosen': '-99.954', 'loss/train': '0.61906', 'examples_per_second': '5.9304', 'grad_norm': '17.125', 'counters/examples': 80256, 'counters/updates': 5016}
skipping logging after 80272 examples to avoid logging too frequently
skipping logging after 80288 examples to avoid logging too frequently
skipping logging after 80304 examples to avoid logging too frequently
train stats after 80320 examples: {'rewards_train/chosen': '-0.58467', 'rewards_train/rejected': '-0.66457', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.080017', 'logps_train/rejected': '-127.41', 'logps_train/chosen': '-125.99', 'loss/train': '0.68468', 'examples_per_second': '4.687', 'grad_norm': '18.125', 'counters/examples': 80320, 'counters/updates': 5020}
skipping logging after 80336 examples to avoid logging too frequently
skipping logging after 80352 examples to avoid logging too frequently
Running evaluation after 80352 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:10,  2.26s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:04,  2.14s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:55,  1.90s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.89s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.54s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.65s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.48s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.55s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.44s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.23s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 80352: {'rewards_eval/chosen': '-0.5216', 'rewards_eval/rejected': '-0.6222', 'rewards_eval/accuracies': '0.5293', 'rewards_eval/margins': '0.10058', 'logps_eval/rejected': '-128.38', 'logps_eval/chosen': '-123.71', 'loss/eval': '0.67158'}
skipping logging after 80368 examples to avoid logging too frequently
train stats after 80384 examples: {'rewards_train/chosen': '-0.52187', 'rewards_train/rejected': '-0.64803', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.12615', 'logps_train/rejected': '-117.5', 'logps_train/chosen': '-128.28', 'loss/train': '0.66403', 'examples_per_second': '5.1529', 'grad_norm': '19.625', 'counters/examples': 80384, 'counters/updates': 5024}
skipping logging after 80400 examples to avoid logging too frequently
skipping logging after 80416 examples to avoid logging too frequently
skipping logging after 80432 examples to avoid logging too frequently
train stats after 80448 examples: {'rewards_train/chosen': '-0.48604', 'rewards_train/rejected': '-0.65779', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.17186', 'logps_train/rejected': '-121.62', 'logps_train/chosen': '-126.01', 'loss/train': '0.64238', 'examples_per_second': '5.3324', 'grad_norm': '18.375', 'counters/examples': 80448, 'counters/updates': 5028}
skipping logging after 80464 examples to avoid logging too frequently
skipping logging after 80480 examples to avoid logging too frequently
skipping logging after 80496 examples to avoid logging too frequently
train stats after 80512 examples: {'rewards_train/chosen': '-0.61701', 'rewards_train/rejected': '-0.77626', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.1593', 'logps_train/rejected': '-155.7', 'logps_train/chosen': '-160.36', 'loss/train': '0.65163', 'examples_per_second': '5.2459', 'grad_norm': '21.375', 'counters/examples': 80512, 'counters/updates': 5032}
skipping logging after 80528 examples to avoid logging too frequently
skipping logging after 80544 examples to avoid logging too frequently
skipping logging after 80560 examples to avoid logging too frequently
train stats after 80576 examples: {'rewards_train/chosen': '-0.40398', 'rewards_train/rejected': '-0.49594', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.09193', 'logps_train/rejected': '-102.73', 'logps_train/chosen': '-106.26', 'loss/train': '0.66858', 'examples_per_second': '5.0262', 'grad_norm': '15.938', 'counters/examples': 80576, 'counters/updates': 5036}
skipping logging after 80592 examples to avoid logging too frequently
skipping logging after 80608 examples to avoid logging too frequently
skipping logging after 80624 examples to avoid logging too frequently
train stats after 80640 examples: {'rewards_train/chosen': '-0.46854', 'rewards_train/rejected': '-0.54851', 'rewards_train/accuracies': '0.42188', 'rewards_train/margins': '0.079903', 'logps_train/rejected': '-152.41', 'logps_train/chosen': '-135.38', 'loss/train': '0.67334', 'examples_per_second': '4.3368', 'grad_norm': '25', 'counters/examples': 80640, 'counters/updates': 5040}
skipping logging after 80656 examples to avoid logging too frequently
skipping logging after 80672 examples to avoid logging too frequently
skipping logging after 80688 examples to avoid logging too frequently
train stats after 80704 examples: {'rewards_train/chosen': '-0.59487', 'rewards_train/rejected': '-0.60208', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.007246', 'logps_train/rejected': '-103.46', 'logps_train/chosen': '-121.35', 'loss/train': '0.70508', 'examples_per_second': '5.1503', 'grad_norm': '17.75', 'counters/examples': 80704, 'counters/updates': 5044}
skipping logging after 80720 examples to avoid logging too frequently
skipping logging after 80736 examples to avoid logging too frequently
skipping logging after 80752 examples to avoid logging too frequently
train stats after 80768 examples: {'rewards_train/chosen': '-0.56492', 'rewards_train/rejected': '-0.61518', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.050226', 'logps_train/rejected': '-132.9', 'logps_train/chosen': '-142.22', 'loss/train': '0.69563', 'examples_per_second': '4.12', 'grad_norm': '21.625', 'counters/examples': 80768, 'counters/updates': 5048}
skipping logging after 80784 examples to avoid logging too frequently
skipping logging after 80800 examples to avoid logging too frequently
skipping logging after 80816 examples to avoid logging too frequently
train stats after 80832 examples: {'rewards_train/chosen': '-0.58073', 'rewards_train/rejected': '-0.71207', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.13127', 'logps_train/rejected': '-127.37', 'logps_train/chosen': '-142.32', 'loss/train': '0.6571', 'examples_per_second': '5.9046', 'grad_norm': '20.75', 'counters/examples': 80832, 'counters/updates': 5052}
skipping logging after 80848 examples to avoid logging too frequently
skipping logging after 80864 examples to avoid logging too frequently
skipping logging after 80880 examples to avoid logging too frequently
train stats after 80896 examples: {'rewards_train/chosen': '-0.53519', 'rewards_train/rejected': '-0.58551', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.05027', 'logps_train/rejected': '-131.05', 'logps_train/chosen': '-119.66', 'loss/train': '0.69644', 'examples_per_second': '4.7588', 'grad_norm': '27', 'counters/examples': 80896, 'counters/updates': 5056}
skipping logging after 80912 examples to avoid logging too frequently
skipping logging after 80928 examples to avoid logging too frequently
skipping logging after 80944 examples to avoid logging too frequently
train stats after 80960 examples: {'rewards_train/chosen': '-0.47201', 'rewards_train/rejected': '-0.60411', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.13212', 'logps_train/rejected': '-123.6', 'logps_train/chosen': '-125', 'loss/train': '0.65358', 'examples_per_second': '4.3678', 'grad_norm': '19.75', 'counters/examples': 80960, 'counters/updates': 5060}
skipping logging after 80976 examples to avoid logging too frequently
skipping logging after 80992 examples to avoid logging too frequently
skipping logging after 81008 examples to avoid logging too frequently
train stats after 81024 examples: {'rewards_train/chosen': '-0.50237', 'rewards_train/rejected': '-0.61736', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.1149', 'logps_train/rejected': '-136.5', 'logps_train/chosen': '-112.83', 'loss/train': '0.6615', 'examples_per_second': '5.3314', 'grad_norm': '20.375', 'counters/examples': 81024, 'counters/updates': 5064}
skipping logging after 81040 examples to avoid logging too frequently
skipping logging after 81056 examples to avoid logging too frequently
skipping logging after 81072 examples to avoid logging too frequently
train stats after 81088 examples: {'rewards_train/chosen': '-0.42014', 'rewards_train/rejected': '-0.50498', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.084923', 'logps_train/rejected': '-121.46', 'logps_train/chosen': '-137.45', 'loss/train': '0.67072', 'examples_per_second': '4.1333', 'grad_norm': '22.25', 'counters/examples': 81088, 'counters/updates': 5068}
skipping logging after 81104 examples to avoid logging too frequently
skipping logging after 81120 examples to avoid logging too frequently
skipping logging after 81136 examples to avoid logging too frequently
train stats after 81152 examples: {'rewards_train/chosen': '-0.3639', 'rewards_train/rejected': '-0.52723', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.1633', 'logps_train/rejected': '-146.2', 'logps_train/chosen': '-131.57', 'loss/train': '0.6355', 'examples_per_second': '5.1498', 'grad_norm': '16.625', 'counters/examples': 81152, 'counters/updates': 5072}
skipping logging after 81168 examples to avoid logging too frequently
skipping logging after 81184 examples to avoid logging too frequently
skipping logging after 81200 examples to avoid logging too frequently
train stats after 81216 examples: {'rewards_train/chosen': '-0.46427', 'rewards_train/rejected': '-0.59604', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.13179', 'logps_train/rejected': '-131.22', 'logps_train/chosen': '-141.03', 'loss/train': '0.64758', 'examples_per_second': '4.4544', 'grad_norm': '19.125', 'counters/examples': 81216, 'counters/updates': 5076}
skipping logging after 81232 examples to avoid logging too frequently
skipping logging after 81248 examples to avoid logging too frequently
skipping logging after 81264 examples to avoid logging too frequently
train stats after 81280 examples: {'rewards_train/chosen': '-0.412', 'rewards_train/rejected': '-0.5729', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.161', 'logps_train/rejected': '-113.93', 'logps_train/chosen': '-118.83', 'loss/train': '0.63831', 'examples_per_second': '5.562', 'grad_norm': '16.625', 'counters/examples': 81280, 'counters/updates': 5080}
skipping logging after 81296 examples to avoid logging too frequently
skipping logging after 81312 examples to avoid logging too frequently
skipping logging after 81328 examples to avoid logging too frequently
train stats after 81344 examples: {'rewards_train/chosen': '-0.53106', 'rewards_train/rejected': '-0.66095', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.12981', 'logps_train/rejected': '-115.01', 'logps_train/chosen': '-124.07', 'loss/train': '0.65837', 'examples_per_second': '5.2906', 'grad_norm': '18.125', 'counters/examples': 81344, 'counters/updates': 5084}
Running evaluation after 81344 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<01:00,  1.94s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<01:00,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.83s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.63s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 81344: {'rewards_eval/chosen': '-0.46049', 'rewards_eval/rejected': '-0.55404', 'rewards_eval/accuracies': '0.52539', 'rewards_eval/margins': '0.093511', 'logps_eval/rejected': '-127.7', 'logps_eval/chosen': '-123.1', 'loss/eval': '0.6724'}
skipping logging after 81360 examples to avoid logging too frequently
skipping logging after 81376 examples to avoid logging too frequently
skipping logging after 81392 examples to avoid logging too frequently
train stats after 81408 examples: {'rewards_train/chosen': '-0.41388', 'rewards_train/rejected': '-0.52984', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.116', 'logps_train/rejected': '-115.43', 'logps_train/chosen': '-124.2', 'loss/train': '0.66623', 'examples_per_second': '4.7679', 'grad_norm': '20.625', 'counters/examples': 81408, 'counters/updates': 5088}
skipping logging after 81424 examples to avoid logging too frequently
skipping logging after 81440 examples to avoid logging too frequently
skipping logging after 81456 examples to avoid logging too frequently
train stats after 81472 examples: {'rewards_train/chosen': '-0.46095', 'rewards_train/rejected': '-0.53996', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.079086', 'logps_train/rejected': '-111.7', 'logps_train/chosen': '-124.69', 'loss/train': '0.67493', 'examples_per_second': '5.2422', 'grad_norm': '19.5', 'counters/examples': 81472, 'counters/updates': 5092}
skipping logging after 81488 examples to avoid logging too frequently
skipping logging after 81504 examples to avoid logging too frequently
skipping logging after 81520 examples to avoid logging too frequently
train stats after 81536 examples: {'rewards_train/chosen': '-0.36125', 'rewards_train/rejected': '-0.46296', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.10169', 'logps_train/rejected': '-105.88', 'logps_train/chosen': '-101.42', 'loss/train': '0.65692', 'examples_per_second': '4.3412', 'grad_norm': '17', 'counters/examples': 81536, 'counters/updates': 5096}
skipping logging after 81552 examples to avoid logging too frequently
skipping logging after 81568 examples to avoid logging too frequently
skipping logging after 81584 examples to avoid logging too frequently
train stats after 81600 examples: {'rewards_train/chosen': '-0.47675', 'rewards_train/rejected': '-0.67901', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.20218', 'logps_train/rejected': '-131.53', 'logps_train/chosen': '-145.51', 'loss/train': '0.61899', 'examples_per_second': '6.2167', 'grad_norm': '22.75', 'counters/examples': 81600, 'counters/updates': 5100}
skipping logging after 81616 examples to avoid logging too frequently
skipping logging after 81632 examples to avoid logging too frequently
skipping logging after 81648 examples to avoid logging too frequently
train stats after 81664 examples: {'rewards_train/chosen': '-0.44779', 'rewards_train/rejected': '-0.53613', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.088382', 'logps_train/rejected': '-142.45', 'logps_train/chosen': '-113.53', 'loss/train': '0.66904', 'examples_per_second': '4.59', 'grad_norm': '21.875', 'counters/examples': 81664, 'counters/updates': 5104}
skipping logging after 81680 examples to avoid logging too frequently
skipping logging after 81696 examples to avoid logging too frequently
skipping logging after 81712 examples to avoid logging too frequently
train stats after 81728 examples: {'rewards_train/chosen': '-0.4455', 'rewards_train/rejected': '-0.4873', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.041851', 'logps_train/rejected': '-107.56', 'logps_train/chosen': '-107.83', 'loss/train': '0.68835', 'examples_per_second': '5.3192', 'grad_norm': '16.75', 'counters/examples': 81728, 'counters/updates': 5108}
skipping logging after 81744 examples to avoid logging too frequently
skipping logging after 81760 examples to avoid logging too frequently
skipping logging after 81776 examples to avoid logging too frequently
train stats after 81792 examples: {'rewards_train/chosen': '-0.50774', 'rewards_train/rejected': '-0.62465', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.11691', 'logps_train/rejected': '-131.99', 'logps_train/chosen': '-125.48', 'loss/train': '0.65343', 'examples_per_second': '4.1325', 'grad_norm': '18.125', 'counters/examples': 81792, 'counters/updates': 5112}
skipping logging after 81808 examples to avoid logging too frequently
skipping logging after 81824 examples to avoid logging too frequently
skipping logging after 81840 examples to avoid logging too frequently
train stats after 81856 examples: {'rewards_train/chosen': '-0.50739', 'rewards_train/rejected': '-0.62221', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.11479', 'logps_train/rejected': '-113.84', 'logps_train/chosen': '-113.6', 'loss/train': '0.6593', 'examples_per_second': '5.5879', 'grad_norm': '18.125', 'counters/examples': 81856, 'counters/updates': 5116}
skipping logging after 81872 examples to avoid logging too frequently
skipping logging after 81888 examples to avoid logging too frequently
skipping logging after 81904 examples to avoid logging too frequently
train stats after 81920 examples: {'rewards_train/chosen': '-0.48368', 'rewards_train/rejected': '-0.61058', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.12687', 'logps_train/rejected': '-99.96', 'logps_train/chosen': '-114.48', 'loss/train': '0.65271', 'examples_per_second': '5.3165', 'grad_norm': '16.625', 'counters/examples': 81920, 'counters/updates': 5120}
skipping logging after 81936 examples to avoid logging too frequently
skipping logging after 81952 examples to avoid logging too frequently
skipping logging after 81968 examples to avoid logging too frequently
train stats after 81984 examples: {'rewards_train/chosen': '-0.38769', 'rewards_train/rejected': '-0.57257', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.18491', 'logps_train/rejected': '-123.61', 'logps_train/chosen': '-125.6', 'loss/train': '0.62451', 'examples_per_second': '4.7315', 'grad_norm': '16.5', 'counters/examples': 81984, 'counters/updates': 5124}
skipping logging after 82000 examples to avoid logging too frequently
skipping logging after 82016 examples to avoid logging too frequently
skipping logging after 82032 examples to avoid logging too frequently
train stats after 82048 examples: {'rewards_train/chosen': '-0.60331', 'rewards_train/rejected': '-0.69866', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.095406', 'logps_train/rejected': '-109.15', 'logps_train/chosen': '-109.25', 'loss/train': '0.65906', 'examples_per_second': '5.7141', 'grad_norm': '18.75', 'counters/examples': 82048, 'counters/updates': 5128}
skipping logging after 82064 examples to avoid logging too frequently
skipping logging after 82080 examples to avoid logging too frequently
skipping logging after 82096 examples to avoid logging too frequently
train stats after 82112 examples: {'rewards_train/chosen': '-0.37976', 'rewards_train/rejected': '-0.49426', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.11452', 'logps_train/rejected': '-131.43', 'logps_train/chosen': '-128.3', 'loss/train': '0.66456', 'examples_per_second': '4.3884', 'grad_norm': '19.875', 'counters/examples': 82112, 'counters/updates': 5132}
skipping logging after 82128 examples to avoid logging too frequently
skipping logging after 82144 examples to avoid logging too frequently
skipping logging after 82160 examples to avoid logging too frequently
train stats after 82176 examples: {'rewards_train/chosen': '-0.39965', 'rewards_train/rejected': '-0.58529', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.18553', 'logps_train/rejected': '-112.53', 'logps_train/chosen': '-132.96', 'loss/train': '0.63437', 'examples_per_second': '5.4676', 'grad_norm': '18.25', 'counters/examples': 82176, 'counters/updates': 5136}
skipping logging after 82192 examples to avoid logging too frequently
skipping logging after 82208 examples to avoid logging too frequently
skipping logging after 82224 examples to avoid logging too frequently
train stats after 82240 examples: {'rewards_train/chosen': '-0.42692', 'rewards_train/rejected': '-0.52358', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.096474', 'logps_train/rejected': '-134.14', 'logps_train/chosen': '-140.23', 'loss/train': '0.6651', 'examples_per_second': '5.4605', 'grad_norm': '19.25', 'counters/examples': 82240, 'counters/updates': 5140}
skipping logging after 82256 examples to avoid logging too frequently
skipping logging after 82272 examples to avoid logging too frequently
skipping logging after 82288 examples to avoid logging too frequently
train stats after 82304 examples: {'rewards_train/chosen': '-0.38563', 'rewards_train/rejected': '-0.5027', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.11715', 'logps_train/rejected': '-113.48', 'logps_train/chosen': '-123.24', 'loss/train': '0.65625', 'examples_per_second': '6.2823', 'grad_norm': '19.625', 'counters/examples': 82304, 'counters/updates': 5144}
skipping logging after 82320 examples to avoid logging too frequently
skipping logging after 82336 examples to avoid logging too frequently
Running evaluation after 82336 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:12,  2.35s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:05,  2.17s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:55,  1.92s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.90s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.55s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.65s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.48s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.55s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.23s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 82336: {'rewards_eval/chosen': '-0.44428', 'rewards_eval/rejected': '-0.5359', 'rewards_eval/accuracies': '0.5293', 'rewards_eval/margins': '0.091602', 'logps_eval/rejected': '-127.51', 'logps_eval/chosen': '-122.94', 'loss/eval': '0.67342'}
skipping logging after 82352 examples to avoid logging too frequently
train stats after 82368 examples: {'rewards_train/chosen': '-0.50538', 'rewards_train/rejected': '-0.6377', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.13232', 'logps_train/rejected': '-115.33', 'logps_train/chosen': '-120.5', 'loss/train': '0.64685', 'examples_per_second': '4.13', 'grad_norm': '16.125', 'counters/examples': 82368, 'counters/updates': 5148}
skipping logging after 82384 examples to avoid logging too frequently
skipping logging after 82400 examples to avoid logging too frequently
skipping logging after 82416 examples to avoid logging too frequently
train stats after 82432 examples: {'rewards_train/chosen': '-0.46759', 'rewards_train/rejected': '-0.49879', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.03109', 'logps_train/rejected': '-116.29', 'logps_train/chosen': '-127.41', 'loss/train': '0.70169', 'examples_per_second': '5.3088', 'grad_norm': '17.875', 'counters/examples': 82432, 'counters/updates': 5152}
skipping logging after 82448 examples to avoid logging too frequently
skipping logging after 82464 examples to avoid logging too frequently
skipping logging after 82480 examples to avoid logging too frequently
train stats after 82496 examples: {'rewards_train/chosen': '-0.52364', 'rewards_train/rejected': '-0.60007', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.076469', 'logps_train/rejected': '-111.58', 'logps_train/chosen': '-111.97', 'loss/train': '0.67166', 'examples_per_second': '5.5148', 'grad_norm': '15.25', 'counters/examples': 82496, 'counters/updates': 5156}
skipping logging after 82512 examples to avoid logging too frequently
skipping logging after 82528 examples to avoid logging too frequently
skipping logging after 82544 examples to avoid logging too frequently
train stats after 82560 examples: {'rewards_train/chosen': '-0.50491', 'rewards_train/rejected': '-0.63999', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.13516', 'logps_train/rejected': '-113.81', 'logps_train/chosen': '-104.17', 'loss/train': '0.66164', 'examples_per_second': '6.1928', 'grad_norm': '16.375', 'counters/examples': 82560, 'counters/updates': 5160}
skipping logging after 82576 examples to avoid logging too frequently
skipping logging after 82592 examples to avoid logging too frequently
skipping logging after 82608 examples to avoid logging too frequently
train stats after 82624 examples: {'rewards_train/chosen': '-0.4917', 'rewards_train/rejected': '-0.54743', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.055714', 'logps_train/rejected': '-124.62', 'logps_train/chosen': '-144.39', 'loss/train': '0.68323', 'examples_per_second': '4.6803', 'grad_norm': '20.125', 'counters/examples': 82624, 'counters/updates': 5164}
skipping logging after 82640 examples to avoid logging too frequently
skipping logging after 82656 examples to avoid logging too frequently
skipping logging after 82672 examples to avoid logging too frequently
train stats after 82688 examples: {'rewards_train/chosen': '-0.49893', 'rewards_train/rejected': '-0.5998', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.1008', 'logps_train/rejected': '-116.27', 'logps_train/chosen': '-98.161', 'loss/train': '0.67353', 'examples_per_second': '5.363', 'grad_norm': '15.438', 'counters/examples': 82688, 'counters/updates': 5168}
skipping logging after 82704 examples to avoid logging too frequently
skipping logging after 82720 examples to avoid logging too frequently
skipping logging after 82736 examples to avoid logging too frequently
train stats after 82752 examples: {'rewards_train/chosen': '-0.38989', 'rewards_train/rejected': '-0.57911', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.18914', 'logps_train/rejected': '-110.28', 'logps_train/chosen': '-109.7', 'loss/train': '0.61591', 'examples_per_second': '6.0142', 'grad_norm': '20.875', 'counters/examples': 82752, 'counters/updates': 5172}
skipping logging after 82768 examples to avoid logging too frequently
skipping logging after 82784 examples to avoid logging too frequently
skipping logging after 82800 examples to avoid logging too frequently
train stats after 82816 examples: {'rewards_train/chosen': '-0.37125', 'rewards_train/rejected': '-0.54862', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.17722', 'logps_train/rejected': '-106.33', 'logps_train/chosen': '-104.39', 'loss/train': '0.62781', 'examples_per_second': '4.9822', 'grad_norm': '22.875', 'counters/examples': 82816, 'counters/updates': 5176}
skipping logging after 82832 examples to avoid logging too frequently
skipping logging after 82848 examples to avoid logging too frequently
skipping logging after 82864 examples to avoid logging too frequently
train stats after 82880 examples: {'rewards_train/chosen': '-0.49351', 'rewards_train/rejected': '-0.59548', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.10207', 'logps_train/rejected': '-115.62', 'logps_train/chosen': '-109.48', 'loss/train': '0.67133', 'examples_per_second': '5.6405', 'grad_norm': '18.625', 'counters/examples': 82880, 'counters/updates': 5180}
skipping logging after 82896 examples to avoid logging too frequently
skipping logging after 82912 examples to avoid logging too frequently
skipping logging after 82928 examples to avoid logging too frequently
train stats after 82944 examples: {'rewards_train/chosen': '-0.41006', 'rewards_train/rejected': '-0.45745', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.047344', 'logps_train/rejected': '-125.51', 'logps_train/chosen': '-91.192', 'loss/train': '0.68646', 'examples_per_second': '5.236', 'grad_norm': '17.625', 'counters/examples': 82944, 'counters/updates': 5184}
skipping logging after 82960 examples to avoid logging too frequently
skipping logging after 82976 examples to avoid logging too frequently
skipping logging after 82992 examples to avoid logging too frequently
train stats after 83008 examples: {'rewards_train/chosen': '-0.42876', 'rewards_train/rejected': '-0.61669', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.18803', 'logps_train/rejected': '-120.5', 'logps_train/chosen': '-109.59', 'loss/train': '0.62891', 'examples_per_second': '5.0829', 'grad_norm': '17.5', 'counters/examples': 83008, 'counters/updates': 5188}
skipping logging after 83024 examples to avoid logging too frequently
skipping logging after 83040 examples to avoid logging too frequently
skipping logging after 83056 examples to avoid logging too frequently
train stats after 83072 examples: {'rewards_train/chosen': '-0.49393', 'rewards_train/rejected': '-0.53391', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.039871', 'logps_train/rejected': '-119.92', 'logps_train/chosen': '-140', 'loss/train': '0.70671', 'examples_per_second': '6.3507', 'grad_norm': '20.5', 'counters/examples': 83072, 'counters/updates': 5192}
skipping logging after 83088 examples to avoid logging too frequently
skipping logging after 83104 examples to avoid logging too frequently
skipping logging after 83120 examples to avoid logging too frequently
train stats after 83136 examples: {'rewards_train/chosen': '-0.37009', 'rewards_train/rejected': '-0.43839', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.068375', 'logps_train/rejected': '-148.72', 'logps_train/chosen': '-123.15', 'loss/train': '0.67215', 'examples_per_second': '4.8101', 'grad_norm': '16.125', 'counters/examples': 83136, 'counters/updates': 5196}
skipping logging after 83152 examples to avoid logging too frequently
skipping logging after 83168 examples to avoid logging too frequently
skipping logging after 83184 examples to avoid logging too frequently
train stats after 83200 examples: {'rewards_train/chosen': '-0.37728', 'rewards_train/rejected': '-0.50228', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.12506', 'logps_train/rejected': '-135.79', 'logps_train/chosen': '-151.16', 'loss/train': '0.65414', 'examples_per_second': '3.7436', 'grad_norm': '19.25', 'counters/examples': 83200, 'counters/updates': 5200}
skipping logging after 83216 examples to avoid logging too frequently
skipping logging after 83232 examples to avoid logging too frequently
skipping logging after 83248 examples to avoid logging too frequently
train stats after 83264 examples: {'rewards_train/chosen': '-0.42549', 'rewards_train/rejected': '-0.45906', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.033638', 'logps_train/rejected': '-107.62', 'logps_train/chosen': '-109.74', 'loss/train': '0.68903', 'examples_per_second': '4.6733', 'grad_norm': '20', 'counters/examples': 83264, 'counters/updates': 5204}
skipping logging after 83280 examples to avoid logging too frequently
skipping logging after 83296 examples to avoid logging too frequently
skipping logging after 83312 examples to avoid logging too frequently
train stats after 83328 examples: {'rewards_train/chosen': '-0.58224', 'rewards_train/rejected': '-0.59525', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.012909', 'logps_train/rejected': '-121.04', 'logps_train/chosen': '-125.88', 'loss/train': '0.70792', 'examples_per_second': '6.1975', 'grad_norm': '21.625', 'counters/examples': 83328, 'counters/updates': 5208}
Running evaluation after 83328 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<01:00,  1.94s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<01:00,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:53,  1.83s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.63s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.33s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.25s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 83328: {'rewards_eval/chosen': '-0.42953', 'rewards_eval/rejected': '-0.52261', 'rewards_eval/accuracies': '0.54297', 'rewards_eval/margins': '0.093014', 'logps_eval/rejected': '-127.38', 'logps_eval/chosen': '-122.79', 'loss/eval': '0.67364'}
skipping logging after 83344 examples to avoid logging too frequently
skipping logging after 83360 examples to avoid logging too frequently
skipping logging after 83376 examples to avoid logging too frequently
train stats after 83392 examples: {'rewards_train/chosen': '-0.46041', 'rewards_train/rejected': '-0.52729', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.066936', 'logps_train/rejected': '-101.02', 'logps_train/chosen': '-105.84', 'loss/train': '0.67807', 'examples_per_second': '4.7711', 'grad_norm': '14.812', 'counters/examples': 83392, 'counters/updates': 5212}
skipping logging after 83408 examples to avoid logging too frequently
skipping logging after 83424 examples to avoid logging too frequently
skipping logging after 83440 examples to avoid logging too frequently
train stats after 83456 examples: {'rewards_train/chosen': '-0.3643', 'rewards_train/rejected': '-0.4461', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.08182', 'logps_train/rejected': '-123.15', 'logps_train/chosen': '-109.47', 'loss/train': '0.66727', 'examples_per_second': '4.6483', 'grad_norm': '16.125', 'counters/examples': 83456, 'counters/updates': 5216}
skipping logging after 83472 examples to avoid logging too frequently
skipping logging after 83488 examples to avoid logging too frequently
skipping logging after 83504 examples to avoid logging too frequently
train stats after 83520 examples: {'rewards_train/chosen': '-0.358', 'rewards_train/rejected': '-0.56556', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.20753', 'logps_train/rejected': '-157.66', 'logps_train/chosen': '-125.66', 'loss/train': '0.6227', 'examples_per_second': '4.7084', 'grad_norm': '21', 'counters/examples': 83520, 'counters/updates': 5220}
skipping logging after 83536 examples to avoid logging too frequently
skipping logging after 83552 examples to avoid logging too frequently
skipping logging after 83568 examples to avoid logging too frequently
train stats after 83584 examples: {'rewards_train/chosen': '-0.38862', 'rewards_train/rejected': '-0.37932', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '-0.0092049', 'logps_train/rejected': '-123.86', 'logps_train/chosen': '-113.95', 'loss/train': '0.71494', 'examples_per_second': '4.2091', 'grad_norm': '18.5', 'counters/examples': 83584, 'counters/updates': 5224}
skipping logging after 83600 examples to avoid logging too frequently
skipping logging after 83616 examples to avoid logging too frequently
skipping logging after 83632 examples to avoid logging too frequently
train stats after 83648 examples: {'rewards_train/chosen': '-0.33815', 'rewards_train/rejected': '-0.46255', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.12445', 'logps_train/rejected': '-107.2', 'logps_train/chosen': '-122.42', 'loss/train': '0.65167', 'examples_per_second': '5.1756', 'grad_norm': '19', 'counters/examples': 83648, 'counters/updates': 5228}
skipping logging after 83664 examples to avoid logging too frequently
skipping logging after 83680 examples to avoid logging too frequently
skipping logging after 83696 examples to avoid logging too frequently
train stats after 83712 examples: {'rewards_train/chosen': '-0.46676', 'rewards_train/rejected': '-0.63365', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.16696', 'logps_train/rejected': '-148.13', 'logps_train/chosen': '-117.52', 'loss/train': '0.64008', 'examples_per_second': '5.6708', 'grad_norm': '19.125', 'counters/examples': 83712, 'counters/updates': 5232}
skipping logging after 83728 examples to avoid logging too frequently
skipping logging after 83744 examples to avoid logging too frequently
skipping logging after 83760 examples to avoid logging too frequently
train stats after 83776 examples: {'rewards_train/chosen': '-0.51132', 'rewards_train/rejected': '-0.55538', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.044106', 'logps_train/rejected': '-112.45', 'logps_train/chosen': '-114.24', 'loss/train': '0.69141', 'examples_per_second': '5.3084', 'grad_norm': '18.875', 'counters/examples': 83776, 'counters/updates': 5236}
skipping logging after 83792 examples to avoid logging too frequently
skipping logging after 83808 examples to avoid logging too frequently
skipping logging after 83824 examples to avoid logging too frequently
train stats after 83840 examples: {'rewards_train/chosen': '-0.36729', 'rewards_train/rejected': '-0.47112', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.10393', 'logps_train/rejected': '-113.83', 'logps_train/chosen': '-100.88', 'loss/train': '0.66756', 'examples_per_second': '6.3179', 'grad_norm': '16.125', 'counters/examples': 83840, 'counters/updates': 5240}
skipping logging after 83856 examples to avoid logging too frequently
skipping logging after 83872 examples to avoid logging too frequently
skipping logging after 83888 examples to avoid logging too frequently
train stats after 83904 examples: {'rewards_train/chosen': '-0.43678', 'rewards_train/rejected': '-0.54654', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.10984', 'logps_train/rejected': '-142.77', 'logps_train/chosen': '-122.63', 'loss/train': '0.67296', 'examples_per_second': '4.6148', 'grad_norm': '17.625', 'counters/examples': 83904, 'counters/updates': 5244}
skipping logging after 83920 examples to avoid logging too frequently
skipping logging after 83936 examples to avoid logging too frequently
skipping logging after 83952 examples to avoid logging too frequently
train stats after 83968 examples: {'rewards_train/chosen': '-0.36356', 'rewards_train/rejected': '-0.56015', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.19647', 'logps_train/rejected': '-135.72', 'logps_train/chosen': '-127.18', 'loss/train': '0.6234', 'examples_per_second': '4.1476', 'grad_norm': '17.5', 'counters/examples': 83968, 'counters/updates': 5248}
skipping logging after 83984 examples to avoid logging too frequently
skipping logging after 84000 examples to avoid logging too frequently
skipping logging after 84016 examples to avoid logging too frequently
train stats after 84032 examples: {'rewards_train/chosen': '-0.44376', 'rewards_train/rejected': '-0.5592', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.11542', 'logps_train/rejected': '-114.19', 'logps_train/chosen': '-114.59', 'loss/train': '0.64902', 'examples_per_second': '5.5196', 'grad_norm': '15.688', 'counters/examples': 84032, 'counters/updates': 5252}
skipping logging after 84048 examples to avoid logging too frequently
skipping logging after 84064 examples to avoid logging too frequently
skipping logging after 84080 examples to avoid logging too frequently
train stats after 84096 examples: {'rewards_train/chosen': '-0.56307', 'rewards_train/rejected': '-0.61871', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.055727', 'logps_train/rejected': '-112.75', 'logps_train/chosen': '-125.56', 'loss/train': '0.68544', 'examples_per_second': '4.9592', 'grad_norm': '20.125', 'counters/examples': 84096, 'counters/updates': 5256}
skipping logging after 84112 examples to avoid logging too frequently
skipping logging after 84128 examples to avoid logging too frequently
skipping logging after 84144 examples to avoid logging too frequently
train stats after 84160 examples: {'rewards_train/chosen': '-0.40707', 'rewards_train/rejected': '-0.57049', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.16347', 'logps_train/rejected': '-122.42', 'logps_train/chosen': '-125.91', 'loss/train': '0.64418', 'examples_per_second': '4.6765', 'grad_norm': '16.125', 'counters/examples': 84160, 'counters/updates': 5260}
skipping logging after 84176 examples to avoid logging too frequently
skipping logging after 84192 examples to avoid logging too frequently
skipping logging after 84208 examples to avoid logging too frequently
train stats after 84224 examples: {'rewards_train/chosen': '-0.50812', 'rewards_train/rejected': '-0.70935', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.20126', 'logps_train/rejected': '-150.53', 'logps_train/chosen': '-144.55', 'loss/train': '0.62085', 'examples_per_second': '4.8549', 'grad_norm': '20.25', 'counters/examples': 84224, 'counters/updates': 5264}
skipping logging after 84240 examples to avoid logging too frequently
skipping logging after 84256 examples to avoid logging too frequently
skipping logging after 84272 examples to avoid logging too frequently
train stats after 84288 examples: {'rewards_train/chosen': '-0.58886', 'rewards_train/rejected': '-0.82723', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.2384', 'logps_train/rejected': '-142.04', 'logps_train/chosen': '-111.44', 'loss/train': '0.59723', 'examples_per_second': '4.8948', 'grad_norm': '20.125', 'counters/examples': 84288, 'counters/updates': 5268}
skipping logging after 84304 examples to avoid logging too frequently
skipping logging after 84320 examples to avoid logging too frequently
Running evaluation after 84320 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:10,  2.26s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:04,  2.14s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:55,  1.90s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.88s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.54s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 84320: {'rewards_eval/chosen': '-0.50168', 'rewards_eval/rejected': '-0.60218', 'rewards_eval/accuracies': '0.53906', 'rewards_eval/margins': '0.1005', 'logps_eval/rejected': '-128.18', 'logps_eval/chosen': '-123.51', 'loss/eval': '0.67272'}
skipping logging after 84336 examples to avoid logging too frequently
train stats after 84352 examples: {'rewards_train/chosen': '-0.50795', 'rewards_train/rejected': '-0.64808', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.14005', 'logps_train/rejected': '-121.12', 'logps_train/chosen': '-111.33', 'loss/train': '0.6557', 'examples_per_second': '5.4463', 'grad_norm': '27.125', 'counters/examples': 84352, 'counters/updates': 5272}
skipping logging after 84368 examples to avoid logging too frequently
skipping logging after 84384 examples to avoid logging too frequently
skipping logging after 84400 examples to avoid logging too frequently
train stats after 84416 examples: {'rewards_train/chosen': '-0.46416', 'rewards_train/rejected': '-0.56736', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.10311', 'logps_train/rejected': '-103.66', 'logps_train/chosen': '-114.09', 'loss/train': '0.66354', 'examples_per_second': '5.167', 'grad_norm': '17.25', 'counters/examples': 84416, 'counters/updates': 5276}
skipping logging after 84432 examples to avoid logging too frequently
skipping logging after 84448 examples to avoid logging too frequently
skipping logging after 84464 examples to avoid logging too frequently
train stats after 84480 examples: {'rewards_train/chosen': '-0.53419', 'rewards_train/rejected': '-0.73614', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.20208', 'logps_train/rejected': '-131.7', 'logps_train/chosen': '-122.76', 'loss/train': '0.62341', 'examples_per_second': '5.1342', 'grad_norm': '18.625', 'counters/examples': 84480, 'counters/updates': 5280}
skipping logging after 84496 examples to avoid logging too frequently
skipping logging after 84512 examples to avoid logging too frequently
skipping logging after 84528 examples to avoid logging too frequently
train stats after 84544 examples: {'rewards_train/chosen': '-0.41301', 'rewards_train/rejected': '-0.56577', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.15276', 'logps_train/rejected': '-122.84', 'logps_train/chosen': '-97.749', 'loss/train': '0.646', 'examples_per_second': '5.7839', 'grad_norm': '20.125', 'counters/examples': 84544, 'counters/updates': 5284}
skipping logging after 84560 examples to avoid logging too frequently
skipping logging after 84576 examples to avoid logging too frequently
skipping logging after 84592 examples to avoid logging too frequently
train stats after 84608 examples: {'rewards_train/chosen': '-0.43304', 'rewards_train/rejected': '-0.53631', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.10319', 'logps_train/rejected': '-125.3', 'logps_train/chosen': '-130.16', 'loss/train': '0.67493', 'examples_per_second': '4.6595', 'grad_norm': '20', 'counters/examples': 84608, 'counters/updates': 5288}
skipping logging after 84624 examples to avoid logging too frequently
skipping logging after 84640 examples to avoid logging too frequently
skipping logging after 84656 examples to avoid logging too frequently
train stats after 84672 examples: {'rewards_train/chosen': '-0.49615', 'rewards_train/rejected': '-0.70076', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.20474', 'logps_train/rejected': '-132.25', 'logps_train/chosen': '-113.5', 'loss/train': '0.62849', 'examples_per_second': '5.0757', 'grad_norm': '18.25', 'counters/examples': 84672, 'counters/updates': 5292}
skipping logging after 84688 examples to avoid logging too frequently
skipping logging after 84704 examples to avoid logging too frequently
skipping logging after 84720 examples to avoid logging too frequently
train stats after 84736 examples: {'rewards_train/chosen': '-0.56398', 'rewards_train/rejected': '-0.73798', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.17393', 'logps_train/rejected': '-112.08', 'logps_train/chosen': '-98.885', 'loss/train': '0.6331', 'examples_per_second': '5.6414', 'grad_norm': '17.75', 'counters/examples': 84736, 'counters/updates': 5296}
skipping logging after 84752 examples to avoid logging too frequently
skipping logging after 84768 examples to avoid logging too frequently
skipping logging after 84784 examples to avoid logging too frequently
train stats after 84800 examples: {'rewards_train/chosen': '-0.55802', 'rewards_train/rejected': '-0.74366', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.18565', 'logps_train/rejected': '-137.3', 'logps_train/chosen': '-161.29', 'loss/train': '0.64052', 'examples_per_second': '5.1176', 'grad_norm': '16.75', 'counters/examples': 84800, 'counters/updates': 5300}
skipping logging after 84816 examples to avoid logging too frequently
skipping logging after 84832 examples to avoid logging too frequently
skipping logging after 84848 examples to avoid logging too frequently
train stats after 84864 examples: {'rewards_train/chosen': '-0.52587', 'rewards_train/rejected': '-0.58903', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.063276', 'logps_train/rejected': '-116.94', 'logps_train/chosen': '-130.28', 'loss/train': '0.69366', 'examples_per_second': '5.9994', 'grad_norm': '21', 'counters/examples': 84864, 'counters/updates': 5304}
skipping logging after 84880 examples to avoid logging too frequently
skipping logging after 84896 examples to avoid logging too frequently
skipping logging after 84912 examples to avoid logging too frequently
train stats after 84928 examples: {'rewards_train/chosen': '-0.55031', 'rewards_train/rejected': '-0.58106', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.030617', 'logps_train/rejected': '-110.27', 'logps_train/chosen': '-136.12', 'loss/train': '0.70912', 'examples_per_second': '5.2821', 'grad_norm': '21.5', 'counters/examples': 84928, 'counters/updates': 5308}
skipping logging after 84944 examples to avoid logging too frequently
skipping logging after 84960 examples to avoid logging too frequently
skipping logging after 84976 examples to avoid logging too frequently
train stats after 84992 examples: {'rewards_train/chosen': '-0.51352', 'rewards_train/rejected': '-0.73287', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.21947', 'logps_train/rejected': '-112.94', 'logps_train/chosen': '-114.37', 'loss/train': '0.61163', 'examples_per_second': '5.798', 'grad_norm': '17', 'counters/examples': 84992, 'counters/updates': 5312}
skipping logging after 85008 examples to avoid logging too frequently
skipping logging after 85024 examples to avoid logging too frequently
skipping logging after 85040 examples to avoid logging too frequently
train stats after 85056 examples: {'rewards_train/chosen': '-0.50537', 'rewards_train/rejected': '-0.55954', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.053988', 'logps_train/rejected': '-134.19', 'logps_train/chosen': '-115.78', 'loss/train': '0.68481', 'examples_per_second': '4.3895', 'grad_norm': '23.25', 'counters/examples': 85056, 'counters/updates': 5316}
skipping logging after 85072 examples to avoid logging too frequently
skipping logging after 85088 examples to avoid logging too frequently
skipping logging after 85104 examples to avoid logging too frequently
train stats after 85120 examples: {'rewards_train/chosen': '-0.39277', 'rewards_train/rejected': '-0.53106', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.13831', 'logps_train/rejected': '-145.7', 'logps_train/chosen': '-127.79', 'loss/train': '0.65277', 'examples_per_second': '4.5714', 'grad_norm': '18.5', 'counters/examples': 85120, 'counters/updates': 5320}
skipping logging after 85136 examples to avoid logging too frequently
skipping logging after 85152 examples to avoid logging too frequently
skipping logging after 85168 examples to avoid logging too frequently
train stats after 85184 examples: {'rewards_train/chosen': '-0.44972', 'rewards_train/rejected': '-0.54247', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.09285', 'logps_train/rejected': '-112.62', 'logps_train/chosen': '-121.83', 'loss/train': '0.66562', 'examples_per_second': '4.595', 'grad_norm': '22.75', 'counters/examples': 85184, 'counters/updates': 5324}
skipping logging after 85200 examples to avoid logging too frequently
skipping logging after 85216 examples to avoid logging too frequently
skipping logging after 85232 examples to avoid logging too frequently
train stats after 85248 examples: {'rewards_train/chosen': '-0.48819', 'rewards_train/rejected': '-0.54633', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.058311', 'logps_train/rejected': '-109.82', 'logps_train/chosen': '-112.25', 'loss/train': '0.68936', 'examples_per_second': '3.9407', 'grad_norm': '17.625', 'counters/examples': 85248, 'counters/updates': 5328}
skipping logging after 85264 examples to avoid logging too frequently
skipping logging after 85280 examples to avoid logging too frequently
skipping logging after 85296 examples to avoid logging too frequently
train stats after 85312 examples: {'rewards_train/chosen': '-0.32664', 'rewards_train/rejected': '-0.48353', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.15694', 'logps_train/rejected': '-136.33', 'logps_train/chosen': '-120.56', 'loss/train': '0.64398', 'examples_per_second': '4.7048', 'grad_norm': '20.75', 'counters/examples': 85312, 'counters/updates': 5332}
Running evaluation after 85312 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<01:00,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:53,  1.83s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.44s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.23s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 85312: {'rewards_eval/chosen': '-0.45733', 'rewards_eval/rejected': '-0.56996', 'rewards_eval/accuracies': '0.56055', 'rewards_eval/margins': '0.11261', 'logps_eval/rejected': '-127.86', 'logps_eval/chosen': '-123.07', 'loss/eval': '0.66689'}
skipping logging after 85328 examples to avoid logging too frequently
skipping logging after 85344 examples to avoid logging too frequently
skipping logging after 85360 examples to avoid logging too frequently
train stats after 85376 examples: {'rewards_train/chosen': '-0.44108', 'rewards_train/rejected': '-0.52892', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.087898', 'logps_train/rejected': '-107.4', 'logps_train/chosen': '-113.21', 'loss/train': '0.67209', 'examples_per_second': '6.2434', 'grad_norm': '20.625', 'counters/examples': 85376, 'counters/updates': 5336}
skipping logging after 85392 examples to avoid logging too frequently
skipping logging after 85408 examples to avoid logging too frequently
skipping logging after 85424 examples to avoid logging too frequently
train stats after 85440 examples: {'rewards_train/chosen': '-0.45724', 'rewards_train/rejected': '-0.62856', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.17126', 'logps_train/rejected': '-153.69', 'logps_train/chosen': '-120.68', 'loss/train': '0.63261', 'examples_per_second': '4.4271', 'grad_norm': '18.5', 'counters/examples': 85440, 'counters/updates': 5340}
skipping logging after 85456 examples to avoid logging too frequently
skipping logging after 85472 examples to avoid logging too frequently
skipping logging after 85488 examples to avoid logging too frequently
train stats after 85504 examples: {'rewards_train/chosen': '-0.44963', 'rewards_train/rejected': '-0.57865', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.12901', 'logps_train/rejected': '-118.01', 'logps_train/chosen': '-115.17', 'loss/train': '0.66217', 'examples_per_second': '4.4239', 'grad_norm': '16.75', 'counters/examples': 85504, 'counters/updates': 5344}
skipping logging after 85520 examples to avoid logging too frequently
skipping logging after 85536 examples to avoid logging too frequently
skipping logging after 85552 examples to avoid logging too frequently
train stats after 85568 examples: {'rewards_train/chosen': '-0.50651', 'rewards_train/rejected': '-0.60709', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.10067', 'logps_train/rejected': '-138.62', 'logps_train/chosen': '-137.48', 'loss/train': '0.68381', 'examples_per_second': '5.7286', 'grad_norm': '24', 'counters/examples': 85568, 'counters/updates': 5348}
skipping logging after 85584 examples to avoid logging too frequently
skipping logging after 85600 examples to avoid logging too frequently
skipping logging after 85616 examples to avoid logging too frequently
train stats after 85632 examples: {'rewards_train/chosen': '-0.49607', 'rewards_train/rejected': '-0.60513', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.10937', 'logps_train/rejected': '-113.23', 'logps_train/chosen': '-126.99', 'loss/train': '0.67613', 'examples_per_second': '5.6096', 'grad_norm': '18.375', 'counters/examples': 85632, 'counters/updates': 5352}
skipping logging after 85648 examples to avoid logging too frequently
skipping logging after 85664 examples to avoid logging too frequently
skipping logging after 85680 examples to avoid logging too frequently
train stats after 85696 examples: {'rewards_train/chosen': '-0.3564', 'rewards_train/rejected': '-0.56797', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.21164', 'logps_train/rejected': '-120.52', 'logps_train/chosen': '-107.98', 'loss/train': '0.62518', 'examples_per_second': '5.216', 'grad_norm': '16.25', 'counters/examples': 85696, 'counters/updates': 5356}
skipping logging after 85712 examples to avoid logging too frequently
skipping logging after 85728 examples to avoid logging too frequently
skipping logging after 85744 examples to avoid logging too frequently
train stats after 85760 examples: {'rewards_train/chosen': '-0.56243', 'rewards_train/rejected': '-0.56108', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '-0.0014', 'logps_train/rejected': '-97.599', 'logps_train/chosen': '-126.07', 'loss/train': '0.71634', 'examples_per_second': '5.4673', 'grad_norm': '20', 'counters/examples': 85760, 'counters/updates': 5360}
skipping logging after 85776 examples to avoid logging too frequently
skipping logging after 85792 examples to avoid logging too frequently
skipping logging after 85808 examples to avoid logging too frequently
train stats after 85824 examples: {'rewards_train/chosen': '-0.49225', 'rewards_train/rejected': '-0.56936', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.077072', 'logps_train/rejected': '-130.21', 'logps_train/chosen': '-135.23', 'loss/train': '0.69043', 'examples_per_second': '5.3062', 'grad_norm': '19.375', 'counters/examples': 85824, 'counters/updates': 5364}
skipping logging after 85840 examples to avoid logging too frequently
skipping logging after 85856 examples to avoid logging too frequently
skipping logging after 85872 examples to avoid logging too frequently
train stats after 85888 examples: {'rewards_train/chosen': '-0.40076', 'rewards_train/rejected': '-0.51992', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.11895', 'logps_train/rejected': '-114.14', 'logps_train/chosen': '-137.93', 'loss/train': '0.66508', 'examples_per_second': '5.1774', 'grad_norm': '19.375', 'counters/examples': 85888, 'counters/updates': 5368}
skipping logging after 85904 examples to avoid logging too frequently
skipping logging after 85920 examples to avoid logging too frequently
skipping logging after 85936 examples to avoid logging too frequently
train stats after 85952 examples: {'rewards_train/chosen': '-0.51799', 'rewards_train/rejected': '-0.60876', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.090847', 'logps_train/rejected': '-120.18', 'logps_train/chosen': '-133.75', 'loss/train': '0.68291', 'examples_per_second': '4.7668', 'grad_norm': '21.375', 'counters/examples': 85952, 'counters/updates': 5372}
skipping logging after 85968 examples to avoid logging too frequently
skipping logging after 85984 examples to avoid logging too frequently
skipping logging after 86000 examples to avoid logging too frequently
train stats after 86016 examples: {'rewards_train/chosen': '-0.38236', 'rewards_train/rejected': '-0.44465', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.062311', 'logps_train/rejected': '-133.51', 'logps_train/chosen': '-155.19', 'loss/train': '0.67078', 'examples_per_second': '4.2308', 'grad_norm': '20', 'counters/examples': 86016, 'counters/updates': 5376}
skipping logging after 86032 examples to avoid logging too frequently
skipping logging after 86048 examples to avoid logging too frequently
skipping logging after 86064 examples to avoid logging too frequently
train stats after 86080 examples: {'rewards_train/chosen': '-0.47993', 'rewards_train/rejected': '-0.45678', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '-0.023127', 'logps_train/rejected': '-119.61', 'logps_train/chosen': '-137.06', 'loss/train': '0.72229', 'examples_per_second': '4.1937', 'grad_norm': '20', 'counters/examples': 86080, 'counters/updates': 5380}
skipping logging after 86096 examples to avoid logging too frequently
skipping logging after 86112 examples to avoid logging too frequently
skipping logging after 86128 examples to avoid logging too frequently
train stats after 86144 examples: {'rewards_train/chosen': '-0.35964', 'rewards_train/rejected': '-0.51059', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.15105', 'logps_train/rejected': '-117.93', 'logps_train/chosen': '-132.76', 'loss/train': '0.64847', 'examples_per_second': '4.6713', 'grad_norm': '17.25', 'counters/examples': 86144, 'counters/updates': 5384}
skipping logging after 86160 examples to avoid logging too frequently
skipping logging after 86176 examples to avoid logging too frequently
skipping logging after 86192 examples to avoid logging too frequently
train stats after 86208 examples: {'rewards_train/chosen': '-0.4682', 'rewards_train/rejected': '-0.52823', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.059959', 'logps_train/rejected': '-110.13', 'logps_train/chosen': '-122.14', 'loss/train': '0.68288', 'examples_per_second': '5.53', 'grad_norm': '19.125', 'counters/examples': 86208, 'counters/updates': 5388}
skipping logging after 86224 examples to avoid logging too frequently
skipping logging after 86240 examples to avoid logging too frequently
skipping logging after 86256 examples to avoid logging too frequently
train stats after 86272 examples: {'rewards_train/chosen': '-0.49547', 'rewards_train/rejected': '-0.59285', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.097183', 'logps_train/rejected': '-91.386', 'logps_train/chosen': '-103.78', 'loss/train': '0.66116', 'examples_per_second': '5.4302', 'grad_norm': '16.125', 'counters/examples': 86272, 'counters/updates': 5392}
skipping logging after 86288 examples to avoid logging too frequently
skipping logging after 86304 examples to avoid logging too frequently
Running evaluation after 86304 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:12,  2.33s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:04,  2.16s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:55,  1.91s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.89s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.54s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 86304: {'rewards_eval/chosen': '-0.44776', 'rewards_eval/rejected': '-0.54898', 'rewards_eval/accuracies': '0.55859', 'rewards_eval/margins': '0.10121', 'logps_eval/rejected': '-127.65', 'logps_eval/chosen': '-122.97', 'loss/eval': '0.67009'}
skipping logging after 86320 examples to avoid logging too frequently
train stats after 86336 examples: {'rewards_train/chosen': '-0.46451', 'rewards_train/rejected': '-0.56457', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.099934', 'logps_train/rejected': '-139.63', 'logps_train/chosen': '-149.81', 'loss/train': '0.65857', 'examples_per_second': '4.9936', 'grad_norm': '20.5', 'counters/examples': 86336, 'counters/updates': 5396}
skipping logging after 86352 examples to avoid logging too frequently
skipping logging after 86368 examples to avoid logging too frequently
skipping logging after 86384 examples to avoid logging too frequently
train stats after 86400 examples: {'rewards_train/chosen': '-0.45443', 'rewards_train/rejected': '-0.49619', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.041748', 'logps_train/rejected': '-127.38', 'logps_train/chosen': '-114.32', 'loss/train': '0.69751', 'examples_per_second': '4.7722', 'grad_norm': '20', 'counters/examples': 86400, 'counters/updates': 5400}
skipping logging after 86416 examples to avoid logging too frequently
skipping logging after 86432 examples to avoid logging too frequently
skipping logging after 86448 examples to avoid logging too frequently
train stats after 86464 examples: {'rewards_train/chosen': '-0.41615', 'rewards_train/rejected': '-0.53191', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.11572', 'logps_train/rejected': '-131.46', 'logps_train/chosen': '-127.67', 'loss/train': '0.66373', 'examples_per_second': '4.598', 'grad_norm': '19.875', 'counters/examples': 86464, 'counters/updates': 5404}
skipping logging after 86480 examples to avoid logging too frequently
skipping logging after 86496 examples to avoid logging too frequently
skipping logging after 86512 examples to avoid logging too frequently
train stats after 86528 examples: {'rewards_train/chosen': '-0.42184', 'rewards_train/rejected': '-0.59029', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.16843', 'logps_train/rejected': '-146.87', 'logps_train/chosen': '-131.78', 'loss/train': '0.63979', 'examples_per_second': '4.9388', 'grad_norm': '20.625', 'counters/examples': 86528, 'counters/updates': 5408}
skipping logging after 86544 examples to avoid logging too frequently
skipping logging after 86560 examples to avoid logging too frequently
skipping logging after 86576 examples to avoid logging too frequently
train stats after 86592 examples: {'rewards_train/chosen': '-0.35799', 'rewards_train/rejected': '-0.4805', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.12252', 'logps_train/rejected': '-105.95', 'logps_train/chosen': '-124.67', 'loss/train': '0.64749', 'examples_per_second': '5.4772', 'grad_norm': '16.875', 'counters/examples': 86592, 'counters/updates': 5412}
skipping logging after 86608 examples to avoid logging too frequently
skipping logging after 86624 examples to avoid logging too frequently
skipping logging after 86640 examples to avoid logging too frequently
train stats after 86656 examples: {'rewards_train/chosen': '-0.48132', 'rewards_train/rejected': '-0.58187', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.10046', 'logps_train/rejected': '-136.54', 'logps_train/chosen': '-114.59', 'loss/train': '0.67184', 'examples_per_second': '5.0545', 'grad_norm': '19.5', 'counters/examples': 86656, 'counters/updates': 5416}
skipping logging after 86672 examples to avoid logging too frequently
skipping logging after 86688 examples to avoid logging too frequently
skipping logging after 86704 examples to avoid logging too frequently
train stats after 86720 examples: {'rewards_train/chosen': '-0.51932', 'rewards_train/rejected': '-0.62069', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.10134', 'logps_train/rejected': '-112.89', 'logps_train/chosen': '-121.35', 'loss/train': '0.67258', 'examples_per_second': '5.5171', 'grad_norm': '18.125', 'counters/examples': 86720, 'counters/updates': 5420}
skipping logging after 86736 examples to avoid logging too frequently
skipping logging after 86752 examples to avoid logging too frequently
skipping logging after 86768 examples to avoid logging too frequently
train stats after 86784 examples: {'rewards_train/chosen': '-0.40637', 'rewards_train/rejected': '-0.52481', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.11841', 'logps_train/rejected': '-122.34', 'logps_train/chosen': '-128.03', 'loss/train': '0.65147', 'examples_per_second': '4.9605', 'grad_norm': '16.125', 'counters/examples': 86784, 'counters/updates': 5424}
skipping logging after 86800 examples to avoid logging too frequently
skipping logging after 86816 examples to avoid logging too frequently
skipping logging after 86832 examples to avoid logging too frequently
train stats after 86848 examples: {'rewards_train/chosen': '-0.36636', 'rewards_train/rejected': '-0.40247', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.036133', 'logps_train/rejected': '-116.1', 'logps_train/chosen': '-125.11', 'loss/train': '0.69736', 'examples_per_second': '4.9674', 'grad_norm': '20.625', 'counters/examples': 86848, 'counters/updates': 5428}
skipping logging after 86864 examples to avoid logging too frequently
skipping logging after 86880 examples to avoid logging too frequently
skipping logging after 86896 examples to avoid logging too frequently
train stats after 86912 examples: {'rewards_train/chosen': '-0.36655', 'rewards_train/rejected': '-0.45135', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.084915', 'logps_train/rejected': '-117.79', 'logps_train/chosen': '-124.5', 'loss/train': '0.68042', 'examples_per_second': '4.2776', 'grad_norm': '20.75', 'counters/examples': 86912, 'counters/updates': 5432}
skipping logging after 86928 examples to avoid logging too frequently
skipping logging after 86944 examples to avoid logging too frequently
skipping logging after 86960 examples to avoid logging too frequently
train stats after 86976 examples: {'rewards_train/chosen': '-0.30034', 'rewards_train/rejected': '-0.45569', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.15533', 'logps_train/rejected': '-118.47', 'logps_train/chosen': '-116.89', 'loss/train': '0.63863', 'examples_per_second': '4.485', 'grad_norm': '16.875', 'counters/examples': 86976, 'counters/updates': 5436}
skipping logging after 86992 examples to avoid logging too frequently
skipping logging after 87008 examples to avoid logging too frequently
skipping logging after 87024 examples to avoid logging too frequently
train stats after 87040 examples: {'rewards_train/chosen': '-0.40899', 'rewards_train/rejected': '-0.4937', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.084755', 'logps_train/rejected': '-117.59', 'logps_train/chosen': '-116.74', 'loss/train': '0.66916', 'examples_per_second': '5.2142', 'grad_norm': '17.25', 'counters/examples': 87040, 'counters/updates': 5440}
skipping logging after 87056 examples to avoid logging too frequently
skipping logging after 87072 examples to avoid logging too frequently
skipping logging after 87088 examples to avoid logging too frequently
train stats after 87104 examples: {'rewards_train/chosen': '-0.43252', 'rewards_train/rejected': '-0.50217', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.0695', 'logps_train/rejected': '-117.29', 'logps_train/chosen': '-98.531', 'loss/train': '0.68973', 'examples_per_second': '5.1856', 'grad_norm': '19', 'counters/examples': 87104, 'counters/updates': 5444}
skipping logging after 87120 examples to avoid logging too frequently
skipping logging after 87136 examples to avoid logging too frequently
skipping logging after 87152 examples to avoid logging too frequently
train stats after 87168 examples: {'rewards_train/chosen': '-0.35043', 'rewards_train/rejected': '-0.4578', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.10733', 'logps_train/rejected': '-108.29', 'logps_train/chosen': '-106.55', 'loss/train': '0.66708', 'examples_per_second': '5.7012', 'grad_norm': '17.875', 'counters/examples': 87168, 'counters/updates': 5448}
skipping logging after 87184 examples to avoid logging too frequently
skipping logging after 87200 examples to avoid logging too frequently
skipping logging after 87216 examples to avoid logging too frequently
train stats after 87232 examples: {'rewards_train/chosen': '-0.33054', 'rewards_train/rejected': '-0.33422', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.0036087', 'logps_train/rejected': '-158.07', 'logps_train/chosen': '-139.45', 'loss/train': '0.71451', 'examples_per_second': '4.8881', 'grad_norm': '25.75', 'counters/examples': 87232, 'counters/updates': 5452}
skipping logging after 87248 examples to avoid logging too frequently
skipping logging after 87264 examples to avoid logging too frequently
skipping logging after 87280 examples to avoid logging too frequently
train stats after 87296 examples: {'rewards_train/chosen': '-0.31957', 'rewards_train/rejected': '-0.44352', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.12396', 'logps_train/rejected': '-141.55', 'logps_train/chosen': '-127.76', 'loss/train': '0.6571', 'examples_per_second': '5.2711', 'grad_norm': '19.375', 'counters/examples': 87296, 'counters/updates': 5456}
Running evaluation after 87296 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<01:00,  1.94s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<01:00,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.83s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.63s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 87296: {'rewards_eval/chosen': '-0.31554', 'rewards_eval/rejected': '-0.40649', 'rewards_eval/accuracies': '0.53516', 'rewards_eval/margins': '0.090981', 'logps_eval/rejected': '-126.22', 'logps_eval/chosen': '-121.65', 'loss/eval': '0.66992'}
skipping logging after 87312 examples to avoid logging too frequently
skipping logging after 87328 examples to avoid logging too frequently
skipping logging after 87344 examples to avoid logging too frequently
train stats after 87360 examples: {'rewards_train/chosen': '-0.25937', 'rewards_train/rejected': '-0.38187', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.12246', 'logps_train/rejected': '-129.01', 'logps_train/chosen': '-122.01', 'loss/train': '0.64703', 'examples_per_second': '5.6984', 'grad_norm': '16.25', 'counters/examples': 87360, 'counters/updates': 5460}
skipping logging after 87376 examples to avoid logging too frequently
skipping logging after 87392 examples to avoid logging too frequently
skipping logging after 87408 examples to avoid logging too frequently
train stats after 87424 examples: {'rewards_train/chosen': '-0.36732', 'rewards_train/rejected': '-0.50424', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.137', 'logps_train/rejected': '-98.471', 'logps_train/chosen': '-103.69', 'loss/train': '0.65329', 'examples_per_second': '5.7347', 'grad_norm': '17.5', 'counters/examples': 87424, 'counters/updates': 5464}
skipping logging after 87440 examples to avoid logging too frequently
skipping logging after 87456 examples to avoid logging too frequently
skipping logging after 87472 examples to avoid logging too frequently
train stats after 87488 examples: {'rewards_train/chosen': '-0.34822', 'rewards_train/rejected': '-0.38392', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.035648', 'logps_train/rejected': '-124.91', 'logps_train/chosen': '-121.88', 'loss/train': '0.69339', 'examples_per_second': '5.5893', 'grad_norm': '21.75', 'counters/examples': 87488, 'counters/updates': 5468}
skipping logging after 87504 examples to avoid logging too frequently
skipping logging after 87520 examples to avoid logging too frequently
skipping logging after 87536 examples to avoid logging too frequently
train stats after 87552 examples: {'rewards_train/chosen': '-0.31325', 'rewards_train/rejected': '-0.42213', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.10894', 'logps_train/rejected': '-118.54', 'logps_train/chosen': '-118.36', 'loss/train': '0.65326', 'examples_per_second': '4.1066', 'grad_norm': '16.75', 'counters/examples': 87552, 'counters/updates': 5472}
skipping logging after 87568 examples to avoid logging too frequently
skipping logging after 87584 examples to avoid logging too frequently
skipping logging after 87600 examples to avoid logging too frequently
train stats after 87616 examples: {'rewards_train/chosen': '-0.28405', 'rewards_train/rejected': '-0.42367', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.13966', 'logps_train/rejected': '-129.48', 'logps_train/chosen': '-118.98', 'loss/train': '0.6476', 'examples_per_second': '4.7874', 'grad_norm': '21.125', 'counters/examples': 87616, 'counters/updates': 5476}
skipping logging after 87632 examples to avoid logging too frequently
skipping logging after 87648 examples to avoid logging too frequently
skipping logging after 87664 examples to avoid logging too frequently
train stats after 87680 examples: {'rewards_train/chosen': '-0.37686', 'rewards_train/rejected': '-0.47126', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.094467', 'logps_train/rejected': '-147.12', 'logps_train/chosen': '-139.84', 'loss/train': '0.66492', 'examples_per_second': '5.2427', 'grad_norm': '20.5', 'counters/examples': 87680, 'counters/updates': 5480}
skipping logging after 87696 examples to avoid logging too frequently
skipping logging after 87712 examples to avoid logging too frequently
skipping logging after 87728 examples to avoid logging too frequently
train stats after 87744 examples: {'rewards_train/chosen': '-0.40188', 'rewards_train/rejected': '-0.47373', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.071732', 'logps_train/rejected': '-105.9', 'logps_train/chosen': '-107.35', 'loss/train': '0.67676', 'examples_per_second': '6.1294', 'grad_norm': '18.375', 'counters/examples': 87744, 'counters/updates': 5484}
skipping logging after 87760 examples to avoid logging too frequently
skipping logging after 87776 examples to avoid logging too frequently
skipping logging after 87792 examples to avoid logging too frequently
train stats after 87808 examples: {'rewards_train/chosen': '-0.43039', 'rewards_train/rejected': '-0.46962', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.039146', 'logps_train/rejected': '-125.66', 'logps_train/chosen': '-130.8', 'loss/train': '0.70045', 'examples_per_second': '5.2674', 'grad_norm': '20.625', 'counters/examples': 87808, 'counters/updates': 5488}
skipping logging after 87824 examples to avoid logging too frequently
skipping logging after 87840 examples to avoid logging too frequently
skipping logging after 87856 examples to avoid logging too frequently
train stats after 87872 examples: {'rewards_train/chosen': '-0.37369', 'rewards_train/rejected': '-0.42682', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.053211', 'logps_train/rejected': '-126.05', 'logps_train/chosen': '-123.9', 'loss/train': '0.69099', 'examples_per_second': '5.2971', 'grad_norm': '19', 'counters/examples': 87872, 'counters/updates': 5492}
skipping logging after 87888 examples to avoid logging too frequently
skipping logging after 87904 examples to avoid logging too frequently
skipping logging after 87920 examples to avoid logging too frequently
train stats after 87936 examples: {'rewards_train/chosen': '-0.41855', 'rewards_train/rejected': '-0.51165', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.09304', 'logps_train/rejected': '-112.54', 'logps_train/chosen': '-111.14', 'loss/train': '0.67177', 'examples_per_second': '4.239', 'grad_norm': '17.375', 'counters/examples': 87936, 'counters/updates': 5496}
skipping logging after 87952 examples to avoid logging too frequently
skipping logging after 87968 examples to avoid logging too frequently
skipping logging after 87984 examples to avoid logging too frequently
train stats after 88000 examples: {'rewards_train/chosen': '-0.3734', 'rewards_train/rejected': '-0.60014', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.22676', 'logps_train/rejected': '-133.33', 'logps_train/chosen': '-99.15', 'loss/train': '0.60738', 'examples_per_second': '4.645', 'grad_norm': '18.75', 'counters/examples': 88000, 'counters/updates': 5500}
skipping logging after 88016 examples to avoid logging too frequently
skipping logging after 88032 examples to avoid logging too frequently
skipping logging after 88048 examples to avoid logging too frequently
train stats after 88064 examples: {'rewards_train/chosen': '-0.35798', 'rewards_train/rejected': '-0.61534', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.25763', 'logps_train/rejected': '-128.26', 'logps_train/chosen': '-111.79', 'loss/train': '0.60454', 'examples_per_second': '6.0347', 'grad_norm': '18.5', 'counters/examples': 88064, 'counters/updates': 5504}
skipping logging after 88080 examples to avoid logging too frequently
skipping logging after 88096 examples to avoid logging too frequently
skipping logging after 88112 examples to avoid logging too frequently
train stats after 88128 examples: {'rewards_train/chosen': '-0.41523', 'rewards_train/rejected': '-0.50009', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.08494', 'logps_train/rejected': '-119.6', 'logps_train/chosen': '-117.83', 'loss/train': '0.67984', 'examples_per_second': '6.0221', 'grad_norm': '18.875', 'counters/examples': 88128, 'counters/updates': 5508}
skipping logging after 88144 examples to avoid logging too frequently
skipping logging after 88160 examples to avoid logging too frequently
skipping logging after 88176 examples to avoid logging too frequently
train stats after 88192 examples: {'rewards_train/chosen': '-0.37751', 'rewards_train/rejected': '-0.48998', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.11227', 'logps_train/rejected': '-113.1', 'logps_train/chosen': '-117.63', 'loss/train': '0.66005', 'examples_per_second': '5.1709', 'grad_norm': '19.5', 'counters/examples': 88192, 'counters/updates': 5512}
skipping logging after 88208 examples to avoid logging too frequently
skipping logging after 88224 examples to avoid logging too frequently
skipping logging after 88240 examples to avoid logging too frequently
train stats after 88256 examples: {'rewards_train/chosen': '-0.35294', 'rewards_train/rejected': '-0.4118', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.058825', 'logps_train/rejected': '-113.34', 'logps_train/chosen': '-144.03', 'loss/train': '0.68437', 'examples_per_second': '4.361', 'grad_norm': '18.375', 'counters/examples': 88256, 'counters/updates': 5516}
skipping logging after 88272 examples to avoid logging too frequently
skipping logging after 88288 examples to avoid logging too frequently
Running evaluation after 88288 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:10,  2.27s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:04,  2.14s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:55,  1.90s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.88s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 88288: {'rewards_eval/chosen': '-0.42192', 'rewards_eval/rejected': '-0.5253', 'rewards_eval/accuracies': '0.54297', 'rewards_eval/margins': '0.10338', 'logps_eval/rejected': '-127.41', 'logps_eval/chosen': '-122.71', 'loss/eval': '0.66945'}
skipping logging after 88304 examples to avoid logging too frequently
train stats after 88320 examples: {'rewards_train/chosen': '-0.42652', 'rewards_train/rejected': '-0.62916', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.20271', 'logps_train/rejected': '-106.47', 'logps_train/chosen': '-107.44', 'loss/train': '0.62151', 'examples_per_second': '6.7348', 'grad_norm': '15.75', 'counters/examples': 88320, 'counters/updates': 5520}
skipping logging after 88336 examples to avoid logging too frequently
skipping logging after 88352 examples to avoid logging too frequently
skipping logging after 88368 examples to avoid logging too frequently
train stats after 88384 examples: {'rewards_train/chosen': '-0.44144', 'rewards_train/rejected': '-0.56683', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.12541', 'logps_train/rejected': '-148.93', 'logps_train/chosen': '-162.3', 'loss/train': '0.66318', 'examples_per_second': '4.7597', 'grad_norm': '24.5', 'counters/examples': 88384, 'counters/updates': 5524}
skipping logging after 88400 examples to avoid logging too frequently
skipping logging after 88416 examples to avoid logging too frequently
skipping logging after 88432 examples to avoid logging too frequently
train stats after 88448 examples: {'rewards_train/chosen': '-0.40465', 'rewards_train/rejected': '-0.51188', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.10718', 'logps_train/rejected': '-101.7', 'logps_train/chosen': '-114.89', 'loss/train': '0.65756', 'examples_per_second': '5.9285', 'grad_norm': '18.375', 'counters/examples': 88448, 'counters/updates': 5528}
skipping logging after 88464 examples to avoid logging too frequently
skipping logging after 88480 examples to avoid logging too frequently
skipping logging after 88496 examples to avoid logging too frequently
train stats after 88512 examples: {'rewards_train/chosen': '-0.32461', 'rewards_train/rejected': '-0.52871', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.20423', 'logps_train/rejected': '-104.17', 'logps_train/chosen': '-121.54', 'loss/train': '0.61304', 'examples_per_second': '4.5517', 'grad_norm': '17.5', 'counters/examples': 88512, 'counters/updates': 5532}
skipping logging after 88528 examples to avoid logging too frequently
skipping logging after 88544 examples to avoid logging too frequently
skipping logging after 88560 examples to avoid logging too frequently
train stats after 88576 examples: {'rewards_train/chosen': '-0.46311', 'rewards_train/rejected': '-0.62652', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.16367', 'logps_train/rejected': '-112.61', 'logps_train/chosen': '-129.49', 'loss/train': '0.64252', 'examples_per_second': '4.5531', 'grad_norm': '17', 'counters/examples': 88576, 'counters/updates': 5536}
skipping logging after 88592 examples to avoid logging too frequently
skipping logging after 88608 examples to avoid logging too frequently
skipping logging after 88624 examples to avoid logging too frequently
train stats after 88640 examples: {'rewards_train/chosen': '-0.45175', 'rewards_train/rejected': '-0.54408', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.092327', 'logps_train/rejected': '-95.129', 'logps_train/chosen': '-121.51', 'loss/train': '0.6644', 'examples_per_second': '5.3376', 'grad_norm': '17.625', 'counters/examples': 88640, 'counters/updates': 5540}
skipping logging after 88656 examples to avoid logging too frequently
skipping logging after 88672 examples to avoid logging too frequently
skipping logging after 88688 examples to avoid logging too frequently
train stats after 88704 examples: {'rewards_train/chosen': '-0.41575', 'rewards_train/rejected': '-0.48969', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.074028', 'logps_train/rejected': '-126.7', 'logps_train/chosen': '-97.502', 'loss/train': '0.67682', 'examples_per_second': '5.0282', 'grad_norm': '16.375', 'counters/examples': 88704, 'counters/updates': 5544}
skipping logging after 88720 examples to avoid logging too frequently
skipping logging after 88736 examples to avoid logging too frequently
skipping logging after 88752 examples to avoid logging too frequently
train stats after 88768 examples: {'rewards_train/chosen': '-0.55128', 'rewards_train/rejected': '-0.66414', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.11285', 'logps_train/rejected': '-101.68', 'logps_train/chosen': '-109.17', 'loss/train': '0.66071', 'examples_per_second': '4.6138', 'grad_norm': '17.5', 'counters/examples': 88768, 'counters/updates': 5548}
skipping logging after 88784 examples to avoid logging too frequently
skipping logging after 88800 examples to avoid logging too frequently
skipping logging after 88816 examples to avoid logging too frequently
train stats after 88832 examples: {'rewards_train/chosen': '-0.5364', 'rewards_train/rejected': '-0.59628', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.059826', 'logps_train/rejected': '-117.51', 'logps_train/chosen': '-93.343', 'loss/train': '0.69145', 'examples_per_second': '5.3791', 'grad_norm': '20.75', 'counters/examples': 88832, 'counters/updates': 5552}
skipping logging after 88848 examples to avoid logging too frequently
skipping logging after 88864 examples to avoid logging too frequently
skipping logging after 88880 examples to avoid logging too frequently
train stats after 88896 examples: {'rewards_train/chosen': '-0.33645', 'rewards_train/rejected': '-0.55653', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.22007', 'logps_train/rejected': '-115.26', 'logps_train/chosen': '-133.94', 'loss/train': '0.60603', 'examples_per_second': '5.9968', 'grad_norm': '19.5', 'counters/examples': 88896, 'counters/updates': 5556}
skipping logging after 88912 examples to avoid logging too frequently
skipping logging after 88928 examples to avoid logging too frequently
skipping logging after 88944 examples to avoid logging too frequently
train stats after 88960 examples: {'rewards_train/chosen': '-0.44949', 'rewards_train/rejected': '-0.5619', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.11215', 'logps_train/rejected': '-124.41', 'logps_train/chosen': '-143.11', 'loss/train': '0.67139', 'examples_per_second': '5.7992', 'grad_norm': '19.5', 'counters/examples': 88960, 'counters/updates': 5560}
skipping logging after 88976 examples to avoid logging too frequently
skipping logging after 88992 examples to avoid logging too frequently
skipping logging after 89008 examples to avoid logging too frequently
train stats after 89024 examples: {'rewards_train/chosen': '-0.44114', 'rewards_train/rejected': '-0.57184', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.13078', 'logps_train/rejected': '-140.48', 'logps_train/chosen': '-115.45', 'loss/train': '0.65269', 'examples_per_second': '5.8019', 'grad_norm': '19', 'counters/examples': 89024, 'counters/updates': 5564}
skipping logging after 89040 examples to avoid logging too frequently
skipping logging after 89056 examples to avoid logging too frequently
skipping logging after 89072 examples to avoid logging too frequently
train stats after 89088 examples: {'rewards_train/chosen': '-0.40906', 'rewards_train/rejected': '-0.44006', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.030849', 'logps_train/rejected': '-132.17', 'logps_train/chosen': '-148.95', 'loss/train': '0.70856', 'examples_per_second': '4.724', 'grad_norm': '19.875', 'counters/examples': 89088, 'counters/updates': 5568}
skipping logging after 89104 examples to avoid logging too frequently
skipping logging after 89120 examples to avoid logging too frequently
skipping logging after 89136 examples to avoid logging too frequently
train stats after 89152 examples: {'rewards_train/chosen': '-0.42374', 'rewards_train/rejected': '-0.55467', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.13092', 'logps_train/rejected': '-113.38', 'logps_train/chosen': '-122.19', 'loss/train': '0.65741', 'examples_per_second': '4.5081', 'grad_norm': '18', 'counters/examples': 89152, 'counters/updates': 5572}
skipping logging after 89168 examples to avoid logging too frequently
skipping logging after 89184 examples to avoid logging too frequently
skipping logging after 89200 examples to avoid logging too frequently
train stats after 89216 examples: {'rewards_train/chosen': '-0.37415', 'rewards_train/rejected': '-0.46871', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.094589', 'logps_train/rejected': '-136.99', 'logps_train/chosen': '-121.29', 'loss/train': '0.66656', 'examples_per_second': '4.5126', 'grad_norm': '17.375', 'counters/examples': 89216, 'counters/updates': 5576}
skipping logging after 89232 examples to avoid logging too frequently
skipping logging after 89248 examples to avoid logging too frequently
skipping logging after 89264 examples to avoid logging too frequently
train stats after 89280 examples: {'rewards_train/chosen': '-0.34432', 'rewards_train/rejected': '-0.48183', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.13753', 'logps_train/rejected': '-141.71', 'logps_train/chosen': '-126.67', 'loss/train': '0.64215', 'examples_per_second': '4.1938', 'grad_norm': '15.625', 'counters/examples': 89280, 'counters/updates': 5580}
Running evaluation after 89280 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 89280: {'rewards_eval/chosen': '-0.37091', 'rewards_eval/rejected': '-0.46462', 'rewards_eval/accuracies': '0.53516', 'rewards_eval/margins': '0.09374', 'logps_eval/rejected': '-126.8', 'logps_eval/chosen': '-122.2', 'loss/eval': '0.67243'}
skipping logging after 89296 examples to avoid logging too frequently
skipping logging after 89312 examples to avoid logging too frequently
skipping logging after 89328 examples to avoid logging too frequently
train stats after 89344 examples: {'rewards_train/chosen': '-0.31328', 'rewards_train/rejected': '-0.57763', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.26427', 'logps_train/rejected': '-110.35', 'logps_train/chosen': '-111.05', 'loss/train': '0.59628', 'examples_per_second': '4.4475', 'grad_norm': '20', 'counters/examples': 89344, 'counters/updates': 5584}
skipping logging after 89360 examples to avoid logging too frequently
skipping logging after 89376 examples to avoid logging too frequently
skipping logging after 89392 examples to avoid logging too frequently
train stats after 89408 examples: {'rewards_train/chosen': '-0.46581', 'rewards_train/rejected': '-0.51437', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.04858', 'logps_train/rejected': '-138.57', 'logps_train/chosen': '-109.63', 'loss/train': '0.68568', 'examples_per_second': '5.0225', 'grad_norm': '17.125', 'counters/examples': 89408, 'counters/updates': 5588}
skipping logging after 89424 examples to avoid logging too frequently
skipping logging after 89440 examples to avoid logging too frequently
skipping logging after 89456 examples to avoid logging too frequently
train stats after 89472 examples: {'rewards_train/chosen': '-0.35232', 'rewards_train/rejected': '-0.4677', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.11543', 'logps_train/rejected': '-137.21', 'logps_train/chosen': '-124.81', 'loss/train': '0.66256', 'examples_per_second': '4.5837', 'grad_norm': '17.375', 'counters/examples': 89472, 'counters/updates': 5592}
skipping logging after 89488 examples to avoid logging too frequently
skipping logging after 89504 examples to avoid logging too frequently
skipping logging after 89520 examples to avoid logging too frequently
train stats after 89536 examples: {'rewards_train/chosen': '-0.42531', 'rewards_train/rejected': '-0.61731', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.19202', 'logps_train/rejected': '-122.68', 'logps_train/chosen': '-112.56', 'loss/train': '0.62613', 'examples_per_second': '5.1489', 'grad_norm': '18', 'counters/examples': 89536, 'counters/updates': 5596}
skipping logging after 89552 examples to avoid logging too frequently
skipping logging after 89568 examples to avoid logging too frequently
skipping logging after 89584 examples to avoid logging too frequently
train stats after 89600 examples: {'rewards_train/chosen': '-0.42067', 'rewards_train/rejected': '-0.59412', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.17339', 'logps_train/rejected': '-132.45', 'logps_train/chosen': '-122.6', 'loss/train': '0.63921', 'examples_per_second': '4.5596', 'grad_norm': '19.375', 'counters/examples': 89600, 'counters/updates': 5600}
skipping logging after 89616 examples to avoid logging too frequently
skipping logging after 89632 examples to avoid logging too frequently
skipping logging after 89648 examples to avoid logging too frequently
train stats after 89664 examples: {'rewards_train/chosen': '-0.43566', 'rewards_train/rejected': '-0.5253', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.089689', 'logps_train/rejected': '-132.09', 'logps_train/chosen': '-135.97', 'loss/train': '0.6705', 'examples_per_second': '4.0702', 'grad_norm': '16.25', 'counters/examples': 89664, 'counters/updates': 5604}
skipping logging after 89680 examples to avoid logging too frequently
skipping logging after 89696 examples to avoid logging too frequently
skipping logging after 89712 examples to avoid logging too frequently
train stats after 89728 examples: {'rewards_train/chosen': '-0.40504', 'rewards_train/rejected': '-0.59391', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.1889', 'logps_train/rejected': '-127.49', 'logps_train/chosen': '-143.65', 'loss/train': '0.62906', 'examples_per_second': '4.3148', 'grad_norm': '18.5', 'counters/examples': 89728, 'counters/updates': 5608}
skipping logging after 89744 examples to avoid logging too frequently
skipping logging after 89760 examples to avoid logging too frequently
skipping logging after 89776 examples to avoid logging too frequently
train stats after 89792 examples: {'rewards_train/chosen': '-0.4193', 'rewards_train/rejected': '-0.62182', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.20274', 'logps_train/rejected': '-129.18', 'logps_train/chosen': '-114.48', 'loss/train': '0.62118', 'examples_per_second': '4.2126', 'grad_norm': '19.625', 'counters/examples': 89792, 'counters/updates': 5612}
skipping logging after 89808 examples to avoid logging too frequently
skipping logging after 89824 examples to avoid logging too frequently
skipping logging after 89840 examples to avoid logging too frequently
train stats after 89856 examples: {'rewards_train/chosen': '-0.48165', 'rewards_train/rejected': '-0.48313', 'rewards_train/accuracies': '0.42188', 'rewards_train/margins': '0.0015106', 'logps_train/rejected': '-110.85', 'logps_train/chosen': '-110.93', 'loss/train': '0.71649', 'examples_per_second': '6.0483', 'grad_norm': '18', 'counters/examples': 89856, 'counters/updates': 5616}
skipping logging after 89872 examples to avoid logging too frequently
skipping logging after 89888 examples to avoid logging too frequently
skipping logging after 89904 examples to avoid logging too frequently
train stats after 89920 examples: {'rewards_train/chosen': '-0.46719', 'rewards_train/rejected': '-0.55542', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.088181', 'logps_train/rejected': '-127.31', 'logps_train/chosen': '-126.15', 'loss/train': '0.67941', 'examples_per_second': '5.2568', 'grad_norm': '18.375', 'counters/examples': 89920, 'counters/updates': 5620}
skipping logging after 89936 examples to avoid logging too frequently
skipping logging after 89952 examples to avoid logging too frequently
skipping logging after 89968 examples to avoid logging too frequently
train stats after 89984 examples: {'rewards_train/chosen': '-0.36866', 'rewards_train/rejected': '-0.58378', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.21529', 'logps_train/rejected': '-125.38', 'logps_train/chosen': '-105.55', 'loss/train': '0.61438', 'examples_per_second': '4.3837', 'grad_norm': '16.625', 'counters/examples': 89984, 'counters/updates': 5624}
skipping logging after 90000 examples to avoid logging too frequently
skipping logging after 90016 examples to avoid logging too frequently
skipping logging after 90032 examples to avoid logging too frequently
train stats after 90048 examples: {'rewards_train/chosen': '-0.47778', 'rewards_train/rejected': '-0.6573', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.17966', 'logps_train/rejected': '-101.86', 'logps_train/chosen': '-130.63', 'loss/train': '0.63598', 'examples_per_second': '4.7357', 'grad_norm': '20.5', 'counters/examples': 90048, 'counters/updates': 5628}
skipping logging after 90064 examples to avoid logging too frequently
skipping logging after 90080 examples to avoid logging too frequently
skipping logging after 90096 examples to avoid logging too frequently
train stats after 90112 examples: {'rewards_train/chosen': '-0.40036', 'rewards_train/rejected': '-0.54426', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.14397', 'logps_train/rejected': '-109.99', 'logps_train/chosen': '-87.042', 'loss/train': '0.6433', 'examples_per_second': '6.3646', 'grad_norm': '19.625', 'counters/examples': 90112, 'counters/updates': 5632}
skipping logging after 90128 examples to avoid logging too frequently
skipping logging after 90144 examples to avoid logging too frequently
skipping logging after 90160 examples to avoid logging too frequently
train stats after 90176 examples: {'rewards_train/chosen': '-0.46644', 'rewards_train/rejected': '-0.62033', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.15393', 'logps_train/rejected': '-128.93', 'logps_train/chosen': '-140.34', 'loss/train': '0.65329', 'examples_per_second': '4.9986', 'grad_norm': '21.875', 'counters/examples': 90176, 'counters/updates': 5636}
skipping logging after 90192 examples to avoid logging too frequently
skipping logging after 90208 examples to avoid logging too frequently
skipping logging after 90224 examples to avoid logging too frequently
train stats after 90240 examples: {'rewards_train/chosen': '-0.57354', 'rewards_train/rejected': '-0.67894', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.10528', 'logps_train/rejected': '-121.28', 'logps_train/chosen': '-116.55', 'loss/train': '0.66977', 'examples_per_second': '5.6186', 'grad_norm': '18.5', 'counters/examples': 90240, 'counters/updates': 5640}
skipping logging after 90256 examples to avoid logging too frequently
skipping logging after 90272 examples to avoid logging too frequently
Running evaluation after 90272 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:08,  2.22s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:03,  2.12s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.88s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.87s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 90272: {'rewards_eval/chosen': '-0.47774', 'rewards_eval/rejected': '-0.58427', 'rewards_eval/accuracies': '0.54883', 'rewards_eval/margins': '0.10654', 'logps_eval/rejected': '-128', 'logps_eval/chosen': '-123.27', 'loss/eval': '0.67061'}
skipping logging after 90288 examples to avoid logging too frequently
train stats after 90304 examples: {'rewards_train/chosen': '-0.52368', 'rewards_train/rejected': '-0.61374', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.090012', 'logps_train/rejected': '-98.457', 'logps_train/chosen': '-130.4', 'loss/train': '0.67696', 'examples_per_second': '5.0208', 'grad_norm': '19.75', 'counters/examples': 90304, 'counters/updates': 5644}
skipping logging after 90320 examples to avoid logging too frequently
skipping logging after 90336 examples to avoid logging too frequently
skipping logging after 90352 examples to avoid logging too frequently
train stats after 90368 examples: {'rewards_train/chosen': '-0.52298', 'rewards_train/rejected': '-0.6429', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.11993', 'logps_train/rejected': '-122.92', 'logps_train/chosen': '-128.14', 'loss/train': '0.66074', 'examples_per_second': '4.604', 'grad_norm': '17.875', 'counters/examples': 90368, 'counters/updates': 5648}
skipping logging after 90384 examples to avoid logging too frequently
skipping logging after 90400 examples to avoid logging too frequently
skipping logging after 90416 examples to avoid logging too frequently
train stats after 90432 examples: {'rewards_train/chosen': '-0.51418', 'rewards_train/rejected': '-0.71931', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.20504', 'logps_train/rejected': '-114.82', 'logps_train/chosen': '-111.08', 'loss/train': '0.62022', 'examples_per_second': '4.4613', 'grad_norm': '18.25', 'counters/examples': 90432, 'counters/updates': 5652}
skipping logging after 90448 examples to avoid logging too frequently
skipping logging after 90464 examples to avoid logging too frequently
skipping logging after 90480 examples to avoid logging too frequently
train stats after 90496 examples: {'rewards_train/chosen': '-0.58923', 'rewards_train/rejected': '-0.56424', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '-0.024914', 'logps_train/rejected': '-139.54', 'logps_train/chosen': '-130.25', 'loss/train': '0.72778', 'examples_per_second': '4.9146', 'grad_norm': '24', 'counters/examples': 90496, 'counters/updates': 5656}
skipping logging after 90512 examples to avoid logging too frequently
skipping logging after 90528 examples to avoid logging too frequently
skipping logging after 90544 examples to avoid logging too frequently
train stats after 90560 examples: {'rewards_train/chosen': '-0.40544', 'rewards_train/rejected': '-0.63837', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.2329', 'logps_train/rejected': '-118.59', 'logps_train/chosen': '-117.54', 'loss/train': '0.60861', 'examples_per_second': '5.5074', 'grad_norm': '18.5', 'counters/examples': 90560, 'counters/updates': 5660}
skipping logging after 90576 examples to avoid logging too frequently
skipping logging after 90592 examples to avoid logging too frequently
skipping logging after 90608 examples to avoid logging too frequently
train stats after 90624 examples: {'rewards_train/chosen': '-0.39242', 'rewards_train/rejected': '-0.58213', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.18972', 'logps_train/rejected': '-134', 'logps_train/chosen': '-153.85', 'loss/train': '0.63075', 'examples_per_second': '4.2977', 'grad_norm': '19.25', 'counters/examples': 90624, 'counters/updates': 5664}
skipping logging after 90640 examples to avoid logging too frequently
skipping logging after 90656 examples to avoid logging too frequently
skipping logging after 90672 examples to avoid logging too frequently
train stats after 90688 examples: {'rewards_train/chosen': '-0.45728', 'rewards_train/rejected': '-0.64783', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.19064', 'logps_train/rejected': '-106.96', 'logps_train/chosen': '-133.24', 'loss/train': '0.63303', 'examples_per_second': '5.2428', 'grad_norm': '19', 'counters/examples': 90688, 'counters/updates': 5668}
skipping logging after 90704 examples to avoid logging too frequently
skipping logging after 90720 examples to avoid logging too frequently
skipping logging after 90736 examples to avoid logging too frequently
train stats after 90752 examples: {'rewards_train/chosen': '-0.4363', 'rewards_train/rejected': '-0.59167', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.15527', 'logps_train/rejected': '-136.51', 'logps_train/chosen': '-114.85', 'loss/train': '0.64998', 'examples_per_second': '6.0599', 'grad_norm': '21.125', 'counters/examples': 90752, 'counters/updates': 5672}
skipping logging after 90768 examples to avoid logging too frequently
skipping logging after 90784 examples to avoid logging too frequently
skipping logging after 90800 examples to avoid logging too frequently
train stats after 90816 examples: {'rewards_train/chosen': '-0.44624', 'rewards_train/rejected': '-0.55491', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.10863', 'logps_train/rejected': '-129.4', 'logps_train/chosen': '-124.83', 'loss/train': '0.65765', 'examples_per_second': '4.8058', 'grad_norm': '17.875', 'counters/examples': 90816, 'counters/updates': 5676}
skipping logging after 90832 examples to avoid logging too frequently
skipping logging after 90848 examples to avoid logging too frequently
skipping logging after 90864 examples to avoid logging too frequently
train stats after 90880 examples: {'rewards_train/chosen': '-0.44922', 'rewards_train/rejected': '-0.58547', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.13606', 'logps_train/rejected': '-131.53', 'logps_train/chosen': '-128.5', 'loss/train': '0.66762', 'examples_per_second': '4.4125', 'grad_norm': '21.25', 'counters/examples': 90880, 'counters/updates': 5680}
skipping logging after 90896 examples to avoid logging too frequently
skipping logging after 90912 examples to avoid logging too frequently
skipping logging after 90928 examples to avoid logging too frequently
train stats after 90944 examples: {'rewards_train/chosen': '-0.48042', 'rewards_train/rejected': '-0.54495', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.064648', 'logps_train/rejected': '-111.08', 'logps_train/chosen': '-126.94', 'loss/train': '0.69058', 'examples_per_second': '6.1132', 'grad_norm': '21.125', 'counters/examples': 90944, 'counters/updates': 5684}
skipping logging after 90960 examples to avoid logging too frequently
skipping logging after 90976 examples to avoid logging too frequently
skipping logging after 90992 examples to avoid logging too frequently
train stats after 91008 examples: {'rewards_train/chosen': '-0.37257', 'rewards_train/rejected': '-0.5095', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.13707', 'logps_train/rejected': '-120.65', 'logps_train/chosen': '-144.86', 'loss/train': '0.65903', 'examples_per_second': '4.2193', 'grad_norm': '19.5', 'counters/examples': 91008, 'counters/updates': 5688}
skipping logging after 91024 examples to avoid logging too frequently
skipping logging after 91040 examples to avoid logging too frequently
skipping logging after 91056 examples to avoid logging too frequently
train stats after 91072 examples: {'rewards_train/chosen': '-0.46684', 'rewards_train/rejected': '-0.63531', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.16851', 'logps_train/rejected': '-133.69', 'logps_train/chosen': '-131.33', 'loss/train': '0.63941', 'examples_per_second': '5.3878', 'grad_norm': '20.125', 'counters/examples': 91072, 'counters/updates': 5692}
skipping logging after 91088 examples to avoid logging too frequently
skipping logging after 91104 examples to avoid logging too frequently
skipping logging after 91120 examples to avoid logging too frequently
train stats after 91136 examples: {'rewards_train/chosen': '-0.48676', 'rewards_train/rejected': '-0.63474', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.14786', 'logps_train/rejected': '-146.36', 'logps_train/chosen': '-138.62', 'loss/train': '0.65929', 'examples_per_second': '4.2432', 'grad_norm': '19.875', 'counters/examples': 91136, 'counters/updates': 5696}
skipping logging after 91152 examples to avoid logging too frequently
skipping logging after 91168 examples to avoid logging too frequently
skipping logging after 91184 examples to avoid logging too frequently
train stats after 91200 examples: {'rewards_train/chosen': '-0.52285', 'rewards_train/rejected': '-0.61708', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.094307', 'logps_train/rejected': '-128.44', 'logps_train/chosen': '-141.56', 'loss/train': '0.67416', 'examples_per_second': '4.5087', 'grad_norm': '21.75', 'counters/examples': 91200, 'counters/updates': 5700}
skipping logging after 91216 examples to avoid logging too frequently
skipping logging after 91232 examples to avoid logging too frequently
skipping logging after 91248 examples to avoid logging too frequently
train stats after 91264 examples: {'rewards_train/chosen': '-0.34147', 'rewards_train/rejected': '-0.52931', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.18793', 'logps_train/rejected': '-184.53', 'logps_train/chosen': '-168.56', 'loss/train': '0.6235', 'examples_per_second': '4.251', 'grad_norm': '21.875', 'counters/examples': 91264, 'counters/updates': 5704}
Running evaluation after 91264 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<01:00,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.25s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.29s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.41s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 91264: {'rewards_eval/chosen': '-0.48086', 'rewards_eval/rejected': '-0.59155', 'rewards_eval/accuracies': '0.55469', 'rewards_eval/margins': '0.11074', 'logps_eval/rejected': '-128.07', 'logps_eval/chosen': '-123.3', 'loss/eval': '0.67113'}
skipping logging after 91280 examples to avoid logging too frequently
skipping logging after 91296 examples to avoid logging too frequently
skipping logging after 91312 examples to avoid logging too frequently
train stats after 91328 examples: {'rewards_train/chosen': '-0.5621', 'rewards_train/rejected': '-0.56427', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.0021019', 'logps_train/rejected': '-123.79', 'logps_train/chosen': '-122.3', 'loss/train': '0.71866', 'examples_per_second': '4.7889', 'grad_norm': '23.625', 'counters/examples': 91328, 'counters/updates': 5708}
skipping logging after 91344 examples to avoid logging too frequently
skipping logging after 91360 examples to avoid logging too frequently
skipping logging after 91376 examples to avoid logging too frequently
train stats after 91392 examples: {'rewards_train/chosen': '-0.52526', 'rewards_train/rejected': '-0.59433', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.068909', 'logps_train/rejected': '-131.96', 'logps_train/chosen': '-122.87', 'loss/train': '0.688', 'examples_per_second': '5.8227', 'grad_norm': '23.125', 'counters/examples': 91392, 'counters/updates': 5712}
skipping logging after 91408 examples to avoid logging too frequently
skipping logging after 91424 examples to avoid logging too frequently
skipping logging after 91440 examples to avoid logging too frequently
train stats after 91456 examples: {'rewards_train/chosen': '-0.44088', 'rewards_train/rejected': '-0.59283', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.15195', 'logps_train/rejected': '-109.94', 'logps_train/chosen': '-121.83', 'loss/train': '0.64987', 'examples_per_second': '5.5428', 'grad_norm': '21', 'counters/examples': 91456, 'counters/updates': 5716}
skipping logging after 91472 examples to avoid logging too frequently
skipping logging after 91488 examples to avoid logging too frequently
skipping logging after 91504 examples to avoid logging too frequently
train stats after 91520 examples: {'rewards_train/chosen': '-0.41789', 'rewards_train/rejected': '-0.56237', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.1445', 'logps_train/rejected': '-120.1', 'logps_train/chosen': '-135.44', 'loss/train': '0.64337', 'examples_per_second': '4.9518', 'grad_norm': '19.375', 'counters/examples': 91520, 'counters/updates': 5720}
skipping logging after 91536 examples to avoid logging too frequently
skipping logging after 91552 examples to avoid logging too frequently
skipping logging after 91568 examples to avoid logging too frequently
train stats after 91584 examples: {'rewards_train/chosen': '-0.50629', 'rewards_train/rejected': '-0.66844', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.16204', 'logps_train/rejected': '-128.92', 'logps_train/chosen': '-118.52', 'loss/train': '0.65156', 'examples_per_second': '5.5247', 'grad_norm': '18.375', 'counters/examples': 91584, 'counters/updates': 5724}
skipping logging after 91600 examples to avoid logging too frequently
skipping logging after 91616 examples to avoid logging too frequently
skipping logging after 91632 examples to avoid logging too frequently
train stats after 91648 examples: {'rewards_train/chosen': '-0.38316', 'rewards_train/rejected': '-0.5929', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.20981', 'logps_train/rejected': '-128.24', 'logps_train/chosen': '-132.65', 'loss/train': '0.62886', 'examples_per_second': '5.3646', 'grad_norm': '20.25', 'counters/examples': 91648, 'counters/updates': 5728}
skipping logging after 91664 examples to avoid logging too frequently
skipping logging after 91680 examples to avoid logging too frequently
skipping logging after 91696 examples to avoid logging too frequently
train stats after 91712 examples: {'rewards_train/chosen': '-0.41047', 'rewards_train/rejected': '-0.49765', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.087311', 'logps_train/rejected': '-117.83', 'logps_train/chosen': '-113.12', 'loss/train': '0.67088', 'examples_per_second': '5.171', 'grad_norm': '18.125', 'counters/examples': 91712, 'counters/updates': 5732}
skipping logging after 91728 examples to avoid logging too frequently
skipping logging after 91744 examples to avoid logging too frequently
skipping logging after 91760 examples to avoid logging too frequently
train stats after 91776 examples: {'rewards_train/chosen': '-0.39906', 'rewards_train/rejected': '-0.54875', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.14974', 'logps_train/rejected': '-132.72', 'logps_train/chosen': '-155.96', 'loss/train': '0.65009', 'examples_per_second': '5.5793', 'grad_norm': '19.75', 'counters/examples': 91776, 'counters/updates': 5736}
skipping logging after 91792 examples to avoid logging too frequently
skipping logging after 91808 examples to avoid logging too frequently
skipping logging after 91824 examples to avoid logging too frequently
train stats after 91840 examples: {'rewards_train/chosen': '-0.49833', 'rewards_train/rejected': '-0.43589', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '-0.062351', 'logps_train/rejected': '-118.91', 'logps_train/chosen': '-119.89', 'loss/train': '0.74728', 'examples_per_second': '4.4534', 'grad_norm': '23.75', 'counters/examples': 91840, 'counters/updates': 5740}
skipping logging after 91856 examples to avoid logging too frequently
skipping logging after 91872 examples to avoid logging too frequently
skipping logging after 91888 examples to avoid logging too frequently
train stats after 91904 examples: {'rewards_train/chosen': '-0.44844', 'rewards_train/rejected': '-0.49617', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.047817', 'logps_train/rejected': '-124.25', 'logps_train/chosen': '-124.17', 'loss/train': '0.69897', 'examples_per_second': '4.8425', 'grad_norm': '21.125', 'counters/examples': 91904, 'counters/updates': 5744}
skipping logging after 91920 examples to avoid logging too frequently
skipping logging after 91936 examples to avoid logging too frequently
skipping logging after 91952 examples to avoid logging too frequently
train stats after 91968 examples: {'rewards_train/chosen': '-0.34376', 'rewards_train/rejected': '-0.52188', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.17809', 'logps_train/rejected': '-124.13', 'logps_train/chosen': '-120.15', 'loss/train': '0.63402', 'examples_per_second': '4.5606', 'grad_norm': '16.125', 'counters/examples': 91968, 'counters/updates': 5748}
skipping logging after 91984 examples to avoid logging too frequently
skipping logging after 92000 examples to avoid logging too frequently
skipping logging after 92016 examples to avoid logging too frequently
train stats after 92032 examples: {'rewards_train/chosen': '-0.47716', 'rewards_train/rejected': '-0.5914', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.11425', 'logps_train/rejected': '-97.275', 'logps_train/chosen': '-112.66', 'loss/train': '0.65889', 'examples_per_second': '6.7044', 'grad_norm': '18.25', 'counters/examples': 92032, 'counters/updates': 5752}
skipping logging after 92048 examples to avoid logging too frequently
skipping logging after 92064 examples to avoid logging too frequently
skipping logging after 92080 examples to avoid logging too frequently
train stats after 92096 examples: {'rewards_train/chosen': '-0.52951', 'rewards_train/rejected': '-0.62256', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.093102', 'logps_train/rejected': '-106.78', 'logps_train/chosen': '-100.17', 'loss/train': '0.66827', 'examples_per_second': '5.4069', 'grad_norm': '17.375', 'counters/examples': 92096, 'counters/updates': 5756}
skipping logging after 92112 examples to avoid logging too frequently
skipping logging after 92128 examples to avoid logging too frequently
skipping logging after 92144 examples to avoid logging too frequently
train stats after 92160 examples: {'rewards_train/chosen': '-0.56292', 'rewards_train/rejected': '-0.66392', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.10088', 'logps_train/rejected': '-139.8', 'logps_train/chosen': '-127.22', 'loss/train': '0.6724', 'examples_per_second': '6.4075', 'grad_norm': '20.125', 'counters/examples': 92160, 'counters/updates': 5760}
skipping logging after 92176 examples to avoid logging too frequently
skipping logging after 92192 examples to avoid logging too frequently
skipping logging after 92208 examples to avoid logging too frequently
train stats after 92224 examples: {'rewards_train/chosen': '-0.44989', 'rewards_train/rejected': '-0.57426', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.12439', 'logps_train/rejected': '-118.95', 'logps_train/chosen': '-119.95', 'loss/train': '0.6507', 'examples_per_second': '5.2901', 'grad_norm': '16.875', 'counters/examples': 92224, 'counters/updates': 5764}
skipping logging after 92240 examples to avoid logging too frequently
skipping logging after 92256 examples to avoid logging too frequently
Running evaluation after 92256 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:11,  2.30s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:04,  2.14s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:55,  1.90s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.88s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.54s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 92256: {'rewards_eval/chosen': '-0.48177', 'rewards_eval/rejected': '-0.58425', 'rewards_eval/accuracies': '0.54492', 'rewards_eval/margins': '0.1025', 'logps_eval/rejected': '-128', 'logps_eval/chosen': '-123.31', 'loss/eval': '0.67272'}
skipping logging after 92272 examples to avoid logging too frequently
train stats after 92288 examples: {'rewards_train/chosen': '-0.46848', 'rewards_train/rejected': '-0.62456', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.15611', 'logps_train/rejected': '-111.38', 'logps_train/chosen': '-98.039', 'loss/train': '0.64424', 'examples_per_second': '4.8378', 'grad_norm': '17.75', 'counters/examples': 92288, 'counters/updates': 5768}
skipping logging after 92304 examples to avoid logging too frequently
skipping logging after 92320 examples to avoid logging too frequently
skipping logging after 92336 examples to avoid logging too frequently
train stats after 92352 examples: {'rewards_train/chosen': '-0.53926', 'rewards_train/rejected': '-0.68679', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.14732', 'logps_train/rejected': '-124.66', 'logps_train/chosen': '-107.25', 'loss/train': '0.65237', 'examples_per_second': '5.3406', 'grad_norm': '20', 'counters/examples': 92352, 'counters/updates': 5772}
skipping logging after 92368 examples to avoid logging too frequently
skipping logging after 92384 examples to avoid logging too frequently
skipping logging after 92400 examples to avoid logging too frequently
train stats after 92416 examples: {'rewards_train/chosen': '-0.43765', 'rewards_train/rejected': '-0.50515', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.067516', 'logps_train/rejected': '-128.96', 'logps_train/chosen': '-113.64', 'loss/train': '0.67966', 'examples_per_second': '4.2796', 'grad_norm': '21.5', 'counters/examples': 92416, 'counters/updates': 5776}
skipping logging after 92432 examples to avoid logging too frequently
skipping logging after 92448 examples to avoid logging too frequently
skipping logging after 92464 examples to avoid logging too frequently
train stats after 92480 examples: {'rewards_train/chosen': '-0.51339', 'rewards_train/rejected': '-0.66925', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.15598', 'logps_train/rejected': '-137.04', 'logps_train/chosen': '-120.91', 'loss/train': '0.64645', 'examples_per_second': '4.7264', 'grad_norm': '18.375', 'counters/examples': 92480, 'counters/updates': 5780}
skipping logging after 92496 examples to avoid logging too frequently
skipping logging after 92512 examples to avoid logging too frequently
skipping logging after 92528 examples to avoid logging too frequently
train stats after 92544 examples: {'rewards_train/chosen': '-0.31424', 'rewards_train/rejected': '-0.50681', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.1926', 'logps_train/rejected': '-107.2', 'logps_train/chosen': '-118.25', 'loss/train': '0.6329', 'examples_per_second': '4.6885', 'grad_norm': '15.938', 'counters/examples': 92544, 'counters/updates': 5784}
skipping logging after 92560 examples to avoid logging too frequently
skipping logging after 92576 examples to avoid logging too frequently
skipping logging after 92592 examples to avoid logging too frequently
train stats after 92608 examples: {'rewards_train/chosen': '-0.40079', 'rewards_train/rejected': '-0.5128', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.1119', 'logps_train/rejected': '-137.58', 'logps_train/chosen': '-132.35', 'loss/train': '0.66144', 'examples_per_second': '4.3472', 'grad_norm': '18.25', 'counters/examples': 92608, 'counters/updates': 5788}
skipping logging after 92624 examples to avoid logging too frequently
skipping logging after 92640 examples to avoid logging too frequently
skipping logging after 92656 examples to avoid logging too frequently
train stats after 92672 examples: {'rewards_train/chosen': '-0.53667', 'rewards_train/rejected': '-0.49806', 'rewards_train/accuracies': '0.375', 'rewards_train/margins': '-0.038658', 'logps_train/rejected': '-112.47', 'logps_train/chosen': '-103.49', 'loss/train': '0.7309', 'examples_per_second': '3.9867', 'grad_norm': '17.75', 'counters/examples': 92672, 'counters/updates': 5792}
skipping logging after 92688 examples to avoid logging too frequently
skipping logging after 92704 examples to avoid logging too frequently
skipping logging after 92720 examples to avoid logging too frequently
train stats after 92736 examples: {'rewards_train/chosen': '-0.46559', 'rewards_train/rejected': '-0.62087', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.15537', 'logps_train/rejected': '-137.5', 'logps_train/chosen': '-139.81', 'loss/train': '0.64059', 'examples_per_second': '5.8613', 'grad_norm': '20.125', 'counters/examples': 92736, 'counters/updates': 5796}
skipping logging after 92752 examples to avoid logging too frequently
skipping logging after 92768 examples to avoid logging too frequently
skipping logging after 92784 examples to avoid logging too frequently
train stats after 92800 examples: {'rewards_train/chosen': '-0.44096', 'rewards_train/rejected': '-0.59674', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.15569', 'logps_train/rejected': '-114.13', 'logps_train/chosen': '-110.63', 'loss/train': '0.65884', 'examples_per_second': '5.4467', 'grad_norm': '20.125', 'counters/examples': 92800, 'counters/updates': 5800}
skipping logging after 92816 examples to avoid logging too frequently
skipping logging after 92832 examples to avoid logging too frequently
skipping logging after 92848 examples to avoid logging too frequently
train stats after 92864 examples: {'rewards_train/chosen': '-0.52796', 'rewards_train/rejected': '-0.61985', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.091835', 'logps_train/rejected': '-121.93', 'logps_train/chosen': '-118.79', 'loss/train': '0.67148', 'examples_per_second': '5.1076', 'grad_norm': '18.375', 'counters/examples': 92864, 'counters/updates': 5804}
skipping logging after 92880 examples to avoid logging too frequently
skipping logging after 92896 examples to avoid logging too frequently
skipping logging after 92912 examples to avoid logging too frequently
train stats after 92928 examples: {'rewards_train/chosen': '-0.51654', 'rewards_train/rejected': '-0.62337', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.10683', 'logps_train/rejected': '-103.92', 'logps_train/chosen': '-117.53', 'loss/train': '0.65625', 'examples_per_second': '4.5407', 'grad_norm': '15.625', 'counters/examples': 92928, 'counters/updates': 5808}
skipping logging after 92944 examples to avoid logging too frequently
skipping logging after 92960 examples to avoid logging too frequently
skipping logging after 92976 examples to avoid logging too frequently
train stats after 92992 examples: {'rewards_train/chosen': '-0.50177', 'rewards_train/rejected': '-0.65236', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.15059', 'logps_train/rejected': '-129.9', 'logps_train/chosen': '-125.77', 'loss/train': '0.64366', 'examples_per_second': '5.1299', 'grad_norm': '24.125', 'counters/examples': 92992, 'counters/updates': 5812}
skipping logging after 93008 examples to avoid logging too frequently
skipping logging after 93024 examples to avoid logging too frequently
skipping logging after 93040 examples to avoid logging too frequently
train stats after 93056 examples: {'rewards_train/chosen': '-0.51172', 'rewards_train/rejected': '-0.58902', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.077393', 'logps_train/rejected': '-106.94', 'logps_train/chosen': '-129.17', 'loss/train': '0.67642', 'examples_per_second': '5.4819', 'grad_norm': '20.625', 'counters/examples': 93056, 'counters/updates': 5816}
skipping logging after 93072 examples to avoid logging too frequently
skipping logging after 93088 examples to avoid logging too frequently
skipping logging after 93104 examples to avoid logging too frequently
train stats after 93120 examples: {'rewards_train/chosen': '-0.38215', 'rewards_train/rejected': '-0.6006', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.2186', 'logps_train/rejected': '-120.16', 'logps_train/chosen': '-143.69', 'loss/train': '0.6276', 'examples_per_second': '4.9672', 'grad_norm': '18.875', 'counters/examples': 93120, 'counters/updates': 5820}
skipping logging after 93136 examples to avoid logging too frequently
skipping logging after 93152 examples to avoid logging too frequently
skipping logging after 93168 examples to avoid logging too frequently
train stats after 93184 examples: {'rewards_train/chosen': '-0.44227', 'rewards_train/rejected': '-0.5734', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.13119', 'logps_train/rejected': '-122', 'logps_train/chosen': '-126.89', 'loss/train': '0.65341', 'examples_per_second': '5.4603', 'grad_norm': '19.75', 'counters/examples': 93184, 'counters/updates': 5824}
skipping logging after 93200 examples to avoid logging too frequently
skipping logging after 93216 examples to avoid logging too frequently
skipping logging after 93232 examples to avoid logging too frequently
train stats after 93248 examples: {'rewards_train/chosen': '-0.40618', 'rewards_train/rejected': '-0.58226', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.17609', 'logps_train/rejected': '-138.95', 'logps_train/chosen': '-177.85', 'loss/train': '0.63251', 'examples_per_second': '3.9842', 'grad_norm': '19.5', 'counters/examples': 93248, 'counters/updates': 5828}
Running evaluation after 93248 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 93248: {'rewards_eval/chosen': '-0.50237', 'rewards_eval/rejected': '-0.60802', 'rewards_eval/accuracies': '0.55469', 'rewards_eval/margins': '0.10568', 'logps_eval/rejected': '-128.24', 'logps_eval/chosen': '-123.52', 'loss/eval': '0.67447'}
skipping logging after 93264 examples to avoid logging too frequently
skipping logging after 93280 examples to avoid logging too frequently
skipping logging after 93296 examples to avoid logging too frequently
train stats after 93312 examples: {'rewards_train/chosen': '-0.50888', 'rewards_train/rejected': '-0.68105', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.17223', 'logps_train/rejected': '-107.79', 'logps_train/chosen': '-115.17', 'loss/train': '0.63333', 'examples_per_second': '4.8827', 'grad_norm': '16.875', 'counters/examples': 93312, 'counters/updates': 5832}
skipping logging after 93328 examples to avoid logging too frequently
skipping logging after 93344 examples to avoid logging too frequently
skipping logging after 93360 examples to avoid logging too frequently
train stats after 93376 examples: {'rewards_train/chosen': '-0.336', 'rewards_train/rejected': '-0.57545', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.23954', 'logps_train/rejected': '-113.76', 'logps_train/chosen': '-126.07', 'loss/train': '0.61513', 'examples_per_second': '5.8437', 'grad_norm': '21.625', 'counters/examples': 93376, 'counters/updates': 5836}
skipping logging after 93392 examples to avoid logging too frequently
skipping logging after 93408 examples to avoid logging too frequently
skipping logging after 93424 examples to avoid logging too frequently
train stats after 93440 examples: {'rewards_train/chosen': '-0.49217', 'rewards_train/rejected': '-0.67727', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.18478', 'logps_train/rejected': '-124.16', 'logps_train/chosen': '-119.44', 'loss/train': '0.64229', 'examples_per_second': '4.8287', 'grad_norm': '21.875', 'counters/examples': 93440, 'counters/updates': 5840}
skipping logging after 93456 examples to avoid logging too frequently
skipping logging after 93472 examples to avoid logging too frequently
skipping logging after 93488 examples to avoid logging too frequently
train stats after 93504 examples: {'rewards_train/chosen': '-0.51181', 'rewards_train/rejected': '-0.81965', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.30792', 'logps_train/rejected': '-145.61', 'logps_train/chosen': '-133.74', 'loss/train': '0.60561', 'examples_per_second': '4.7371', 'grad_norm': '18.75', 'counters/examples': 93504, 'counters/updates': 5844}
skipping logging after 93520 examples to avoid logging too frequently
skipping logging after 93536 examples to avoid logging too frequently
skipping logging after 93552 examples to avoid logging too frequently
train stats after 93568 examples: {'rewards_train/chosen': '-0.68659', 'rewards_train/rejected': '-0.76472', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.078072', 'logps_train/rejected': '-141.38', 'logps_train/chosen': '-110.35', 'loss/train': '0.68561', 'examples_per_second': '6.2511', 'grad_norm': '20.25', 'counters/examples': 93568, 'counters/updates': 5848}
skipping logging after 93584 examples to avoid logging too frequently
skipping logging after 93600 examples to avoid logging too frequently
skipping logging after 93616 examples to avoid logging too frequently
train stats after 93632 examples: {'rewards_train/chosen': '-0.54044', 'rewards_train/rejected': '-0.70015', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.15972', 'logps_train/rejected': '-113.87', 'logps_train/chosen': '-134.98', 'loss/train': '0.63803', 'examples_per_second': '7.0203', 'grad_norm': '20.125', 'counters/examples': 93632, 'counters/updates': 5852}
skipping logging after 93648 examples to avoid logging too frequently
skipping logging after 93664 examples to avoid logging too frequently
skipping logging after 93680 examples to avoid logging too frequently
train stats after 93696 examples: {'rewards_train/chosen': '-0.70843', 'rewards_train/rejected': '-0.76659', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.058258', 'logps_train/rejected': '-127.88', 'logps_train/chosen': '-114.74', 'loss/train': '0.7073', 'examples_per_second': '4.7553', 'grad_norm': '25.25', 'counters/examples': 93696, 'counters/updates': 5856}
skipping logging after 93712 examples to avoid logging too frequently
skipping logging after 93728 examples to avoid logging too frequently
skipping logging after 93744 examples to avoid logging too frequently
train stats after 93760 examples: {'rewards_train/chosen': '-0.63608', 'rewards_train/rejected': '-0.82087', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.18491', 'logps_train/rejected': '-151.13', 'logps_train/chosen': '-118.51', 'loss/train': '0.64474', 'examples_per_second': '5.5078', 'grad_norm': '17', 'counters/examples': 93760, 'counters/updates': 5860}
skipping logging after 93776 examples to avoid logging too frequently
skipping logging after 93792 examples to avoid logging too frequently
skipping logging after 93808 examples to avoid logging too frequently
train stats after 93824 examples: {'rewards_train/chosen': '-0.67931', 'rewards_train/rejected': '-0.75541', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.076134', 'logps_train/rejected': '-150.47', 'logps_train/chosen': '-138.6', 'loss/train': '0.68927', 'examples_per_second': '4.4172', 'grad_norm': '22.25', 'counters/examples': 93824, 'counters/updates': 5864}
skipping logging after 93840 examples to avoid logging too frequently
skipping logging after 93856 examples to avoid logging too frequently
skipping logging after 93872 examples to avoid logging too frequently
train stats after 93888 examples: {'rewards_train/chosen': '-0.41435', 'rewards_train/rejected': '-0.60006', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.18558', 'logps_train/rejected': '-136.13', 'logps_train/chosen': '-118.77', 'loss/train': '0.64053', 'examples_per_second': '3.8748', 'grad_norm': '20', 'counters/examples': 93888, 'counters/updates': 5868}
skipping logging after 93904 examples to avoid logging too frequently
skipping logging after 93920 examples to avoid logging too frequently
skipping logging after 93936 examples to avoid logging too frequently
train stats after 93952 examples: {'rewards_train/chosen': '-0.41151', 'rewards_train/rejected': '-0.56242', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.15092', 'logps_train/rejected': '-134.99', 'logps_train/chosen': '-125.7', 'loss/train': '0.64044', 'examples_per_second': '5.6647', 'grad_norm': '18.25', 'counters/examples': 93952, 'counters/updates': 5872}
skipping logging after 93968 examples to avoid logging too frequently
skipping logging after 93984 examples to avoid logging too frequently
skipping logging after 94000 examples to avoid logging too frequently
train stats after 94016 examples: {'rewards_train/chosen': '-0.51668', 'rewards_train/rejected': '-0.6266', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.11007', 'logps_train/rejected': '-132.02', 'logps_train/chosen': '-143.46', 'loss/train': '0.67796', 'examples_per_second': '4.8497', 'grad_norm': '21.125', 'counters/examples': 94016, 'counters/updates': 5876}
skipping logging after 94032 examples to avoid logging too frequently
skipping logging after 94048 examples to avoid logging too frequently
skipping logging after 94064 examples to avoid logging too frequently
train stats after 94080 examples: {'rewards_train/chosen': '-0.4282', 'rewards_train/rejected': '-0.61934', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.19116', 'logps_train/rejected': '-98.819', 'logps_train/chosen': '-110.38', 'loss/train': '0.62584', 'examples_per_second': '5.0414', 'grad_norm': '18.125', 'counters/examples': 94080, 'counters/updates': 5880}
skipping logging after 94096 examples to avoid logging too frequently
skipping logging after 94112 examples to avoid logging too frequently
skipping logging after 94128 examples to avoid logging too frequently
train stats after 94144 examples: {'rewards_train/chosen': '-0.47401', 'rewards_train/rejected': '-0.60077', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.12693', 'logps_train/rejected': '-135.84', 'logps_train/chosen': '-140.7', 'loss/train': '0.66359', 'examples_per_second': '5.8075', 'grad_norm': '21.625', 'counters/examples': 94144, 'counters/updates': 5884}
skipping logging after 94160 examples to avoid logging too frequently
skipping logging after 94176 examples to avoid logging too frequently
skipping logging after 94192 examples to avoid logging too frequently
train stats after 94208 examples: {'rewards_train/chosen': '-0.4432', 'rewards_train/rejected': '-0.65818', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.21506', 'logps_train/rejected': '-102.47', 'logps_train/chosen': '-107.97', 'loss/train': '0.61819', 'examples_per_second': '6.1397', 'grad_norm': '19.25', 'counters/examples': 94208, 'counters/updates': 5888}
skipping logging after 94224 examples to avoid logging too frequently
skipping logging after 94240 examples to avoid logging too frequently
Running evaluation after 94240 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:11,  2.31s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:04,  2.15s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:55,  1.91s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.88s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.54s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 94240: {'rewards_eval/chosen': '-0.47388', 'rewards_eval/rejected': '-0.5878', 'rewards_eval/accuracies': '0.54883', 'rewards_eval/margins': '0.11391', 'logps_eval/rejected': '-128.03', 'logps_eval/chosen': '-123.23', 'loss/eval': '0.66913'}
skipping logging after 94256 examples to avoid logging too frequently
train stats after 94272 examples: {'rewards_train/chosen': '-0.47237', 'rewards_train/rejected': '-0.55168', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.079182', 'logps_train/rejected': '-116.62', 'logps_train/chosen': '-113.16', 'loss/train': '0.68365', 'examples_per_second': '4.8615', 'grad_norm': '20.375', 'counters/examples': 94272, 'counters/updates': 5892}
skipping logging after 94288 examples to avoid logging too frequently
skipping logging after 94304 examples to avoid logging too frequently
skipping logging after 94320 examples to avoid logging too frequently
train stats after 94336 examples: {'rewards_train/chosen': '-0.44012', 'rewards_train/rejected': '-0.53951', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.099312', 'logps_train/rejected': '-107.05', 'logps_train/chosen': '-129.42', 'loss/train': '0.66214', 'examples_per_second': '4.6643', 'grad_norm': '19.125', 'counters/examples': 94336, 'counters/updates': 5896}
skipping logging after 94352 examples to avoid logging too frequently
skipping logging after 94368 examples to avoid logging too frequently
skipping logging after 94384 examples to avoid logging too frequently
train stats after 94400 examples: {'rewards_train/chosen': '-0.55623', 'rewards_train/rejected': '-0.65208', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.095863', 'logps_train/rejected': '-108.96', 'logps_train/chosen': '-105.79', 'loss/train': '0.66583', 'examples_per_second': '4.5449', 'grad_norm': '17', 'counters/examples': 94400, 'counters/updates': 5900}
skipping logging after 94416 examples to avoid logging too frequently
skipping logging after 94432 examples to avoid logging too frequently
skipping logging after 94448 examples to avoid logging too frequently
train stats after 94464 examples: {'rewards_train/chosen': '-0.3294', 'rewards_train/rejected': '-0.48704', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.15778', 'logps_train/rejected': '-96.97', 'logps_train/chosen': '-111.29', 'loss/train': '0.64517', 'examples_per_second': '5.7873', 'grad_norm': '23.75', 'counters/examples': 94464, 'counters/updates': 5904}
skipping logging after 94480 examples to avoid logging too frequently
skipping logging after 94496 examples to avoid logging too frequently
skipping logging after 94512 examples to avoid logging too frequently
train stats after 94528 examples: {'rewards_train/chosen': '-0.46752', 'rewards_train/rejected': '-0.66279', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.19526', 'logps_train/rejected': '-142.73', 'logps_train/chosen': '-110.65', 'loss/train': '0.62032', 'examples_per_second': '5.8097', 'grad_norm': '21.375', 'counters/examples': 94528, 'counters/updates': 5908}
skipping logging after 94544 examples to avoid logging too frequently
skipping logging after 94560 examples to avoid logging too frequently
skipping logging after 94576 examples to avoid logging too frequently
train stats after 94592 examples: {'rewards_train/chosen': '-0.63825', 'rewards_train/rejected': '-0.64287', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.0044918', 'logps_train/rejected': '-108.74', 'logps_train/chosen': '-142.32', 'loss/train': '0.71194', 'examples_per_second': '4.07', 'grad_norm': '24.75', 'counters/examples': 94592, 'counters/updates': 5912}
skipping logging after 94608 examples to avoid logging too frequently
skipping logging after 94624 examples to avoid logging too frequently
skipping logging after 94640 examples to avoid logging too frequently
train stats after 94656 examples: {'rewards_train/chosen': '-0.53155', 'rewards_train/rejected': '-0.75363', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.22221', 'logps_train/rejected': '-148.48', 'logps_train/chosen': '-141.98', 'loss/train': '0.64343', 'examples_per_second': '4.0553', 'grad_norm': '27.125', 'counters/examples': 94656, 'counters/updates': 5916}
skipping logging after 94672 examples to avoid logging too frequently
skipping logging after 94688 examples to avoid logging too frequently
skipping logging after 94704 examples to avoid logging too frequently
train stats after 94720 examples: {'rewards_train/chosen': '-0.47537', 'rewards_train/rejected': '-0.67134', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.19604', 'logps_train/rejected': '-153.23', 'logps_train/chosen': '-128.09', 'loss/train': '0.62311', 'examples_per_second': '5.5657', 'grad_norm': '21.75', 'counters/examples': 94720, 'counters/updates': 5920}
skipping logging after 94736 examples to avoid logging too frequently
skipping logging after 94752 examples to avoid logging too frequently
skipping logging after 94768 examples to avoid logging too frequently
train stats after 94784 examples: {'rewards_train/chosen': '-0.52189', 'rewards_train/rejected': '-0.77602', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.25411', 'logps_train/rejected': '-122.38', 'logps_train/chosen': '-135.96', 'loss/train': '0.61111', 'examples_per_second': '6.0584', 'grad_norm': '19.375', 'counters/examples': 94784, 'counters/updates': 5924}
skipping logging after 94800 examples to avoid logging too frequently
skipping logging after 94816 examples to avoid logging too frequently
skipping logging after 94832 examples to avoid logging too frequently
train stats after 94848 examples: {'rewards_train/chosen': '-0.65762', 'rewards_train/rejected': '-0.76036', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.10275', 'logps_train/rejected': '-145.33', 'logps_train/chosen': '-114.31', 'loss/train': '0.67681', 'examples_per_second': '5.3767', 'grad_norm': '20.625', 'counters/examples': 94848, 'counters/updates': 5928}
skipping logging after 94864 examples to avoid logging too frequently
skipping logging after 94880 examples to avoid logging too frequently
skipping logging after 94896 examples to avoid logging too frequently
train stats after 94912 examples: {'rewards_train/chosen': '-0.56688', 'rewards_train/rejected': '-0.76532', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.19843', 'logps_train/rejected': '-113.19', 'logps_train/chosen': '-139.7', 'loss/train': '0.62909', 'examples_per_second': '4.5364', 'grad_norm': '17.125', 'counters/examples': 94912, 'counters/updates': 5932}
skipping logging after 94928 examples to avoid logging too frequently
skipping logging after 94944 examples to avoid logging too frequently
skipping logging after 94960 examples to avoid logging too frequently
train stats after 94976 examples: {'rewards_train/chosen': '-0.64735', 'rewards_train/rejected': '-0.8012', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.15379', 'logps_train/rejected': '-86.589', 'logps_train/chosen': '-98.257', 'loss/train': '0.64598', 'examples_per_second': '5.6241', 'grad_norm': '18.25', 'counters/examples': 94976, 'counters/updates': 5936}
skipping logging after 94992 examples to avoid logging too frequently
skipping logging after 95008 examples to avoid logging too frequently
skipping logging after 95024 examples to avoid logging too frequently
train stats after 95040 examples: {'rewards_train/chosen': '-0.73787', 'rewards_train/rejected': '-0.82066', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.082897', 'logps_train/rejected': '-142.27', 'logps_train/chosen': '-139.62', 'loss/train': '0.67957', 'examples_per_second': '6.2398', 'grad_norm': '22.75', 'counters/examples': 95040, 'counters/updates': 5940}
skipping logging after 95056 examples to avoid logging too frequently
skipping logging after 95072 examples to avoid logging too frequently
skipping logging after 95088 examples to avoid logging too frequently
train stats after 95104 examples: {'rewards_train/chosen': '-0.56146', 'rewards_train/rejected': '-0.69138', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.13004', 'logps_train/rejected': '-126.98', 'logps_train/chosen': '-122.22', 'loss/train': '0.65805', 'examples_per_second': '4.8048', 'grad_norm': '20.5', 'counters/examples': 95104, 'counters/updates': 5944}
skipping logging after 95120 examples to avoid logging too frequently
skipping logging after 95136 examples to avoid logging too frequently
skipping logging after 95152 examples to avoid logging too frequently
train stats after 95168 examples: {'rewards_train/chosen': '-0.54078', 'rewards_train/rejected': '-0.58695', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.046188', 'logps_train/rejected': '-114.71', 'logps_train/chosen': '-143.72', 'loss/train': '0.69937', 'examples_per_second': '6.6233', 'grad_norm': '25', 'counters/examples': 95168, 'counters/updates': 5948}
skipping logging after 95184 examples to avoid logging too frequently
skipping logging after 95200 examples to avoid logging too frequently
skipping logging after 95216 examples to avoid logging too frequently
train stats after 95232 examples: {'rewards_train/chosen': '-0.48304', 'rewards_train/rejected': '-0.53705', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.053932', 'logps_train/rejected': '-126.04', 'logps_train/chosen': '-137.79', 'loss/train': '0.68881', 'examples_per_second': '4.3276', 'grad_norm': '17.5', 'counters/examples': 95232, 'counters/updates': 5952}
Running evaluation after 95232 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 95232: {'rewards_eval/chosen': '-0.56548', 'rewards_eval/rejected': '-0.66532', 'rewards_eval/accuracies': '0.53516', 'rewards_eval/margins': '0.099859', 'logps_eval/rejected': '-128.81', 'logps_eval/chosen': '-124.15', 'loss/eval': '0.67447'}
skipping logging after 95248 examples to avoid logging too frequently
skipping logging after 95264 examples to avoid logging too frequently
skipping logging after 95280 examples to avoid logging too frequently
train stats after 95296 examples: {'rewards_train/chosen': '-0.61215', 'rewards_train/rejected': '-0.6852', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.073009', 'logps_train/rejected': '-126.11', 'logps_train/chosen': '-132.43', 'loss/train': '0.67709', 'examples_per_second': '3.8975', 'grad_norm': '22.875', 'counters/examples': 95296, 'counters/updates': 5956}
skipping logging after 95312 examples to avoid logging too frequently
skipping logging after 95328 examples to avoid logging too frequently
skipping logging after 95344 examples to avoid logging too frequently
train stats after 95360 examples: {'rewards_train/chosen': '-0.51198', 'rewards_train/rejected': '-0.66', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.14794', 'logps_train/rejected': '-109.55', 'logps_train/chosen': '-126.44', 'loss/train': '0.64249', 'examples_per_second': '3.9723', 'grad_norm': '19', 'counters/examples': 95360, 'counters/updates': 5960}
skipping logging after 95376 examples to avoid logging too frequently
skipping logging after 95392 examples to avoid logging too frequently
skipping logging after 95408 examples to avoid logging too frequently
train stats after 95424 examples: {'rewards_train/chosen': '-0.68484', 'rewards_train/rejected': '-0.77177', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.08688', 'logps_train/rejected': '-125.87', 'logps_train/chosen': '-125.9', 'loss/train': '0.67836', 'examples_per_second': '5.5077', 'grad_norm': '21', 'counters/examples': 95424, 'counters/updates': 5964}
skipping logging after 95440 examples to avoid logging too frequently
skipping logging after 95456 examples to avoid logging too frequently
skipping logging after 95472 examples to avoid logging too frequently
train stats after 95488 examples: {'rewards_train/chosen': '-0.57591', 'rewards_train/rejected': '-0.78885', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.21282', 'logps_train/rejected': '-127.49', 'logps_train/chosen': '-115.41', 'loss/train': '0.61798', 'examples_per_second': '4.9411', 'grad_norm': '21.125', 'counters/examples': 95488, 'counters/updates': 5968}
skipping logging after 95504 examples to avoid logging too frequently
skipping logging after 95520 examples to avoid logging too frequently
skipping logging after 95536 examples to avoid logging too frequently
train stats after 95552 examples: {'rewards_train/chosen': '-0.49337', 'rewards_train/rejected': '-0.69877', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.20556', 'logps_train/rejected': '-135.05', 'logps_train/chosen': '-126', 'loss/train': '0.62567', 'examples_per_second': '4.6871', 'grad_norm': '17.875', 'counters/examples': 95552, 'counters/updates': 5972}
skipping logging after 95568 examples to avoid logging too frequently
skipping logging after 95584 examples to avoid logging too frequently
skipping logging after 95600 examples to avoid logging too frequently
train stats after 95616 examples: {'rewards_train/chosen': '-0.62149', 'rewards_train/rejected': '-0.78277', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.16125', 'logps_train/rejected': '-97.83', 'logps_train/chosen': '-102.04', 'loss/train': '0.64365', 'examples_per_second': '4.7252', 'grad_norm': '17.5', 'counters/examples': 95616, 'counters/updates': 5976}
skipping logging after 95632 examples to avoid logging too frequently
skipping logging after 95648 examples to avoid logging too frequently
skipping logging after 95664 examples to avoid logging too frequently
train stats after 95680 examples: {'rewards_train/chosen': '-0.52045', 'rewards_train/rejected': '-0.65926', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.13895', 'logps_train/rejected': '-109.91', 'logps_train/chosen': '-109.75', 'loss/train': '0.65092', 'examples_per_second': '4.73', 'grad_norm': '18.375', 'counters/examples': 95680, 'counters/updates': 5980}
skipping logging after 95696 examples to avoid logging too frequently
skipping logging after 95712 examples to avoid logging too frequently
skipping logging after 95728 examples to avoid logging too frequently
train stats after 95744 examples: {'rewards_train/chosen': '-0.64569', 'rewards_train/rejected': '-0.75717', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.11158', 'logps_train/rejected': '-101.63', 'logps_train/chosen': '-120.78', 'loss/train': '0.65836', 'examples_per_second': '5.0194', 'grad_norm': '17.5', 'counters/examples': 95744, 'counters/updates': 5984}
skipping logging after 95760 examples to avoid logging too frequently
skipping logging after 95776 examples to avoid logging too frequently
skipping logging after 95792 examples to avoid logging too frequently
train stats after 95808 examples: {'rewards_train/chosen': '-0.53781', 'rewards_train/rejected': '-0.65187', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.11405', 'logps_train/rejected': '-110.72', 'logps_train/chosen': '-109.08', 'loss/train': '0.65918', 'examples_per_second': '4.2295', 'grad_norm': '17', 'counters/examples': 95808, 'counters/updates': 5988}
skipping logging after 95824 examples to avoid logging too frequently
skipping logging after 95840 examples to avoid logging too frequently
skipping logging after 95856 examples to avoid logging too frequently
train stats after 95872 examples: {'rewards_train/chosen': '-0.61276', 'rewards_train/rejected': '-0.72251', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.10968', 'logps_train/rejected': '-112.89', 'logps_train/chosen': '-121.14', 'loss/train': '0.6651', 'examples_per_second': '4.3771', 'grad_norm': '20.875', 'counters/examples': 95872, 'counters/updates': 5992}
skipping logging after 95888 examples to avoid logging too frequently
skipping logging after 95904 examples to avoid logging too frequently
skipping logging after 95920 examples to avoid logging too frequently
train stats after 95936 examples: {'rewards_train/chosen': '-0.56971', 'rewards_train/rejected': '-0.74353', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.17384', 'logps_train/rejected': '-96.885', 'logps_train/chosen': '-120.87', 'loss/train': '0.64101', 'examples_per_second': '4.8491', 'grad_norm': '17.75', 'counters/examples': 95936, 'counters/updates': 5996}
skipping logging after 95952 examples to avoid logging too frequently
skipping logging after 95968 examples to avoid logging too frequently
skipping logging after 95984 examples to avoid logging too frequently
train stats after 96000 examples: {'rewards_train/chosen': '-0.49123', 'rewards_train/rejected': '-0.63699', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.14566', 'logps_train/rejected': '-154.96', 'logps_train/chosen': '-180.32', 'loss/train': '0.65503', 'examples_per_second': '4.917', 'grad_norm': '20.75', 'counters/examples': 96000, 'counters/updates': 6000}
skipping logging after 96016 examples to avoid logging too frequently
skipping logging after 96032 examples to avoid logging too frequently
skipping logging after 96048 examples to avoid logging too frequently
train stats after 96064 examples: {'rewards_train/chosen': '-0.58091', 'rewards_train/rejected': '-0.63932', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.058411', 'logps_train/rejected': '-138.73', 'logps_train/chosen': '-130.54', 'loss/train': '0.68373', 'examples_per_second': '4.6135', 'grad_norm': '22.5', 'counters/examples': 96064, 'counters/updates': 6004}
skipping logging after 96080 examples to avoid logging too frequently
skipping logging after 96096 examples to avoid logging too frequently
skipping logging after 96112 examples to avoid logging too frequently
train stats after 96128 examples: {'rewards_train/chosen': '-0.58916', 'rewards_train/rejected': '-0.71523', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.12615', 'logps_train/rejected': '-108.44', 'logps_train/chosen': '-116', 'loss/train': '0.65669', 'examples_per_second': '5.3205', 'grad_norm': '17.375', 'counters/examples': 96128, 'counters/updates': 6008}
skipping logging after 96144 examples to avoid logging too frequently
skipping logging after 96160 examples to avoid logging too frequently
skipping logging after 96176 examples to avoid logging too frequently
train stats after 96192 examples: {'rewards_train/chosen': '-0.43535', 'rewards_train/rejected': '-0.65415', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.21894', 'logps_train/rejected': '-115.18', 'logps_train/chosen': '-121.36', 'loss/train': '0.62347', 'examples_per_second': '5.1068', 'grad_norm': '17.125', 'counters/examples': 96192, 'counters/updates': 6012}
skipping logging after 96208 examples to avoid logging too frequently
skipping logging after 96224 examples to avoid logging too frequently
Running evaluation after 96224 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:06,  2.13s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:02,  2.08s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.86s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.86s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.52s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.63s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.12s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 96224: {'rewards_eval/chosen': '-0.5301', 'rewards_eval/rejected': '-0.64271', 'rewards_eval/accuracies': '0.53906', 'rewards_eval/margins': '0.11264', 'logps_eval/rejected': '-128.58', 'logps_eval/chosen': '-123.79', 'loss/eval': '0.67161'}
skipping logging after 96240 examples to avoid logging too frequently
train stats after 96256 examples: {'rewards_train/chosen': '-0.60558', 'rewards_train/rejected': '-0.81673', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.21121', 'logps_train/rejected': '-137.46', 'logps_train/chosen': '-112.46', 'loss/train': '0.61093', 'examples_per_second': '5.5427', 'grad_norm': '18.875', 'counters/examples': 96256, 'counters/updates': 6016}
skipping logging after 96272 examples to avoid logging too frequently
skipping logging after 96288 examples to avoid logging too frequently
skipping logging after 96304 examples to avoid logging too frequently
train stats after 96320 examples: {'rewards_train/chosen': '-0.53888', 'rewards_train/rejected': '-0.65035', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.11141', 'logps_train/rejected': '-126.93', 'logps_train/chosen': '-115.8', 'loss/train': '0.67058', 'examples_per_second': '4.97', 'grad_norm': '17.375', 'counters/examples': 96320, 'counters/updates': 6020}
skipping logging after 96336 examples to avoid logging too frequently
skipping logging after 96352 examples to avoid logging too frequently
skipping logging after 96368 examples to avoid logging too frequently
train stats after 96384 examples: {'rewards_train/chosen': '-0.5495', 'rewards_train/rejected': '-0.81344', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.26402', 'logps_train/rejected': '-112.41', 'logps_train/chosen': '-118.26', 'loss/train': '0.61577', 'examples_per_second': '5.2564', 'grad_norm': '18.75', 'counters/examples': 96384, 'counters/updates': 6024}
skipping logging after 96400 examples to avoid logging too frequently
skipping logging after 96416 examples to avoid logging too frequently
skipping logging after 96432 examples to avoid logging too frequently
train stats after 96448 examples: {'rewards_train/chosen': '-0.52592', 'rewards_train/rejected': '-0.66041', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.13448', 'logps_train/rejected': '-111.42', 'logps_train/chosen': '-121.89', 'loss/train': '0.65515', 'examples_per_second': '4.4484', 'grad_norm': '18.5', 'counters/examples': 96448, 'counters/updates': 6028}
skipping logging after 96464 examples to avoid logging too frequently
skipping logging after 96480 examples to avoid logging too frequently
skipping logging after 96496 examples to avoid logging too frequently
train stats after 96512 examples: {'rewards_train/chosen': '-0.47615', 'rewards_train/rejected': '-0.66528', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.18902', 'logps_train/rejected': '-151.39', 'logps_train/chosen': '-129.97', 'loss/train': '0.63177', 'examples_per_second': '5.9922', 'grad_norm': '19.75', 'counters/examples': 96512, 'counters/updates': 6032}
skipping logging after 96528 examples to avoid logging too frequently
skipping logging after 96544 examples to avoid logging too frequently
skipping logging after 96560 examples to avoid logging too frequently
train stats after 96576 examples: {'rewards_train/chosen': '-0.50568', 'rewards_train/rejected': '-0.63887', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.13314', 'logps_train/rejected': '-123', 'logps_train/chosen': '-126.39', 'loss/train': '0.65765', 'examples_per_second': '5.0388', 'grad_norm': '19.25', 'counters/examples': 96576, 'counters/updates': 6036}
skipping logging after 96592 examples to avoid logging too frequently
skipping logging after 96608 examples to avoid logging too frequently
skipping logging after 96624 examples to avoid logging too frequently
train stats after 96640 examples: {'rewards_train/chosen': '-0.52314', 'rewards_train/rejected': '-0.6983', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.17531', 'logps_train/rejected': '-105.98', 'logps_train/chosen': '-90.82', 'loss/train': '0.64012', 'examples_per_second': '5.2724', 'grad_norm': '19', 'counters/examples': 96640, 'counters/updates': 6040}
skipping logging after 96656 examples to avoid logging too frequently
skipping logging after 96672 examples to avoid logging too frequently
skipping logging after 96688 examples to avoid logging too frequently
train stats after 96704 examples: {'rewards_train/chosen': '-0.54494', 'rewards_train/rejected': '-0.61224', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.067223', 'logps_train/rejected': '-131.53', 'logps_train/chosen': '-109.03', 'loss/train': '0.69679', 'examples_per_second': '4.9486', 'grad_norm': '21.75', 'counters/examples': 96704, 'counters/updates': 6044}
skipping logging after 96720 examples to avoid logging too frequently
skipping logging after 96736 examples to avoid logging too frequently
skipping logging after 96752 examples to avoid logging too frequently
train stats after 96768 examples: {'rewards_train/chosen': '-0.46253', 'rewards_train/rejected': '-0.57994', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.11738', 'logps_train/rejected': '-133.43', 'logps_train/chosen': '-118.04', 'loss/train': '0.66415', 'examples_per_second': '5.5924', 'grad_norm': '16.75', 'counters/examples': 96768, 'counters/updates': 6048}
skipping logging after 96784 examples to avoid logging too frequently
skipping logging after 96800 examples to avoid logging too frequently
skipping logging after 96816 examples to avoid logging too frequently
train stats after 96832 examples: {'rewards_train/chosen': '-0.60046', 'rewards_train/rejected': '-0.79556', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.19501', 'logps_train/rejected': '-134.43', 'logps_train/chosen': '-118.12', 'loss/train': '0.62724', 'examples_per_second': '5.0733', 'grad_norm': '19.875', 'counters/examples': 96832, 'counters/updates': 6052}
skipping logging after 96848 examples to avoid logging too frequently
skipping logging after 96864 examples to avoid logging too frequently
skipping logging after 96880 examples to avoid logging too frequently
train stats after 96896 examples: {'rewards_train/chosen': '-0.50229', 'rewards_train/rejected': '-0.69527', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.19292', 'logps_train/rejected': '-155.19', 'logps_train/chosen': '-133.69', 'loss/train': '0.63068', 'examples_per_second': '4.8764', 'grad_norm': '23.875', 'counters/examples': 96896, 'counters/updates': 6056}
skipping logging after 96912 examples to avoid logging too frequently
skipping logging after 96928 examples to avoid logging too frequently
skipping logging after 96944 examples to avoid logging too frequently
train stats after 96960 examples: {'rewards_train/chosen': '-0.47034', 'rewards_train/rejected': '-0.63639', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.16613', 'logps_train/rejected': '-133.58', 'logps_train/chosen': '-132.28', 'loss/train': '0.64198', 'examples_per_second': '5.1927', 'grad_norm': '20.75', 'counters/examples': 96960, 'counters/updates': 6060}
skipping logging after 96976 examples to avoid logging too frequently
skipping logging after 96992 examples to avoid logging too frequently
skipping logging after 97008 examples to avoid logging too frequently
train stats after 97024 examples: {'rewards_train/chosen': '-0.48411', 'rewards_train/rejected': '-0.60113', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.11701', 'logps_train/rejected': '-125.75', 'logps_train/chosen': '-125.14', 'loss/train': '0.66959', 'examples_per_second': '5.6535', 'grad_norm': '21', 'counters/examples': 97024, 'counters/updates': 6064}
skipping logging after 97040 examples to avoid logging too frequently
skipping logging after 97056 examples to avoid logging too frequently
skipping logging after 97072 examples to avoid logging too frequently
train stats after 97088 examples: {'rewards_train/chosen': '-0.38402', 'rewards_train/rejected': '-0.56319', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.17918', 'logps_train/rejected': '-92.907', 'logps_train/chosen': '-100.58', 'loss/train': '0.63941', 'examples_per_second': '5.9356', 'grad_norm': '18.625', 'counters/examples': 97088, 'counters/updates': 6068}
skipping logging after 97104 examples to avoid logging too frequently
skipping logging after 97120 examples to avoid logging too frequently
skipping logging after 97136 examples to avoid logging too frequently
train stats after 97152 examples: {'rewards_train/chosen': '-0.4244', 'rewards_train/rejected': '-0.61815', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.19392', 'logps_train/rejected': '-121.7', 'logps_train/chosen': '-122.41', 'loss/train': '0.62621', 'examples_per_second': '5.1709', 'grad_norm': '17.125', 'counters/examples': 97152, 'counters/updates': 6072}
skipping logging after 97168 examples to avoid logging too frequently
skipping logging after 97184 examples to avoid logging too frequently
skipping logging after 97200 examples to avoid logging too frequently
train stats after 97216 examples: {'rewards_train/chosen': '-0.52406', 'rewards_train/rejected': '-0.68025', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.15609', 'logps_train/rejected': '-116.54', 'logps_train/chosen': '-115.41', 'loss/train': '0.64944', 'examples_per_second': '5.4119', 'grad_norm': '21.5', 'counters/examples': 97216, 'counters/updates': 6076}
Running evaluation after 97216 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 97216: {'rewards_eval/chosen': '-0.51957', 'rewards_eval/rejected': '-0.637', 'rewards_eval/accuracies': '0.53906', 'rewards_eval/margins': '0.11751', 'logps_eval/rejected': '-128.53', 'logps_eval/chosen': '-123.69', 'loss/eval': '0.66828'}
skipping logging after 97232 examples to avoid logging too frequently
skipping logging after 97248 examples to avoid logging too frequently
skipping logging after 97264 examples to avoid logging too frequently
train stats after 97280 examples: {'rewards_train/chosen': '-0.43372', 'rewards_train/rejected': '-0.55875', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.12509', 'logps_train/rejected': '-115.23', 'logps_train/chosen': '-136.28', 'loss/train': '0.65652', 'examples_per_second': '5.4923', 'grad_norm': '18.75', 'counters/examples': 97280, 'counters/updates': 6080}
skipping logging after 97296 examples to avoid logging too frequently
skipping logging after 97312 examples to avoid logging too frequently
skipping logging after 97328 examples to avoid logging too frequently
train stats after 97344 examples: {'rewards_train/chosen': '-0.55362', 'rewards_train/rejected': '-0.6395', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.0858', 'logps_train/rejected': '-135.23', 'logps_train/chosen': '-135.36', 'loss/train': '0.68066', 'examples_per_second': '4.8248', 'grad_norm': '17.375', 'counters/examples': 97344, 'counters/updates': 6084}
skipping logging after 97360 examples to avoid logging too frequently
skipping logging after 97376 examples to avoid logging too frequently
skipping logging after 97392 examples to avoid logging too frequently
train stats after 97408 examples: {'rewards_train/chosen': '-0.56728', 'rewards_train/rejected': '-0.76283', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.19548', 'logps_train/rejected': '-134.92', 'logps_train/chosen': '-128.93', 'loss/train': '0.63991', 'examples_per_second': '4.9892', 'grad_norm': '19.125', 'counters/examples': 97408, 'counters/updates': 6088}
skipping logging after 97424 examples to avoid logging too frequently
skipping logging after 97440 examples to avoid logging too frequently
skipping logging after 97456 examples to avoid logging too frequently
train stats after 97472 examples: {'rewards_train/chosen': '-0.31447', 'rewards_train/rejected': '-0.51304', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.1984', 'logps_train/rejected': '-142.49', 'logps_train/chosen': '-126.75', 'loss/train': '0.62766', 'examples_per_second': '4.4366', 'grad_norm': '19.375', 'counters/examples': 97472, 'counters/updates': 6092}
skipping logging after 97488 examples to avoid logging too frequently
skipping logging after 97504 examples to avoid logging too frequently
skipping logging after 97520 examples to avoid logging too frequently
train stats after 97536 examples: {'rewards_train/chosen': '-0.56277', 'rewards_train/rejected': '-0.65004', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.087322', 'logps_train/rejected': '-132.7', 'logps_train/chosen': '-139.39', 'loss/train': '0.68924', 'examples_per_second': '4.7479', 'grad_norm': '22.625', 'counters/examples': 97536, 'counters/updates': 6096}
skipping logging after 97552 examples to avoid logging too frequently
skipping logging after 97568 examples to avoid logging too frequently
skipping logging after 97584 examples to avoid logging too frequently
train stats after 97600 examples: {'rewards_train/chosen': '-0.5189', 'rewards_train/rejected': '-0.59671', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.077774', 'logps_train/rejected': '-132.12', 'logps_train/chosen': '-119.91', 'loss/train': '0.6662', 'examples_per_second': '4.718', 'grad_norm': '19.125', 'counters/examples': 97600, 'counters/updates': 6100}
skipping logging after 97616 examples to avoid logging too frequently
skipping logging after 97632 examples to avoid logging too frequently
skipping logging after 97648 examples to avoid logging too frequently
train stats after 97664 examples: {'rewards_train/chosen': '-0.31796', 'rewards_train/rejected': '-0.46376', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.14573', 'logps_train/rejected': '-116.04', 'logps_train/chosen': '-132.47', 'loss/train': '0.64008', 'examples_per_second': '4.7349', 'grad_norm': '17.875', 'counters/examples': 97664, 'counters/updates': 6104}
skipping logging after 97680 examples to avoid logging too frequently
skipping logging after 97696 examples to avoid logging too frequently
skipping logging after 97712 examples to avoid logging too frequently
train stats after 97728 examples: {'rewards_train/chosen': '-0.58012', 'rewards_train/rejected': '-0.5589', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '-0.021233', 'logps_train/rejected': '-113.79', 'logps_train/chosen': '-132.86', 'loss/train': '0.72406', 'examples_per_second': '4.9126', 'grad_norm': '18.25', 'counters/examples': 97728, 'counters/updates': 6108}
skipping logging after 97744 examples to avoid logging too frequently
skipping logging after 97760 examples to avoid logging too frequently
skipping logging after 97776 examples to avoid logging too frequently
train stats after 97792 examples: {'rewards_train/chosen': '-0.50861', 'rewards_train/rejected': '-0.59318', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.084522', 'logps_train/rejected': '-131.83', 'logps_train/chosen': '-127.77', 'loss/train': '0.68472', 'examples_per_second': '5.6918', 'grad_norm': '17.875', 'counters/examples': 97792, 'counters/updates': 6112}
skipping logging after 97808 examples to avoid logging too frequently
skipping logging after 97824 examples to avoid logging too frequently
skipping logging after 97840 examples to avoid logging too frequently
train stats after 97856 examples: {'rewards_train/chosen': '-0.43217', 'rewards_train/rejected': '-0.50895', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.076809', 'logps_train/rejected': '-112.15', 'logps_train/chosen': '-105.24', 'loss/train': '0.67197', 'examples_per_second': '5.6554', 'grad_norm': '17', 'counters/examples': 97856, 'counters/updates': 6116}
skipping logging after 97872 examples to avoid logging too frequently
skipping logging after 97888 examples to avoid logging too frequently
skipping logging after 97904 examples to avoid logging too frequently
train stats after 97920 examples: {'rewards_train/chosen': '-0.44732', 'rewards_train/rejected': '-0.52217', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.074841', 'logps_train/rejected': '-136.09', 'logps_train/chosen': '-131.51', 'loss/train': '0.6705', 'examples_per_second': '5.6671', 'grad_norm': '19.875', 'counters/examples': 97920, 'counters/updates': 6120}
skipping logging after 97936 examples to avoid logging too frequently
skipping logging after 97952 examples to avoid logging too frequently
skipping logging after 97968 examples to avoid logging too frequently
train stats after 97984 examples: {'rewards_train/chosen': '-0.45152', 'rewards_train/rejected': '-0.61668', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.16527', 'logps_train/rejected': '-118.53', 'logps_train/chosen': '-136.06', 'loss/train': '0.64723', 'examples_per_second': '5.5021', 'grad_norm': '18.375', 'counters/examples': 97984, 'counters/updates': 6124}
skipping logging after 98000 examples to avoid logging too frequently
skipping logging after 98016 examples to avoid logging too frequently
skipping logging after 98032 examples to avoid logging too frequently
train stats after 98048 examples: {'rewards_train/chosen': '-0.45849', 'rewards_train/rejected': '-0.63799', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.17958', 'logps_train/rejected': '-142.37', 'logps_train/chosen': '-136.95', 'loss/train': '0.63783', 'examples_per_second': '4.9827', 'grad_norm': '21.125', 'counters/examples': 98048, 'counters/updates': 6128}
skipping logging after 98064 examples to avoid logging too frequently
skipping logging after 98080 examples to avoid logging too frequently
skipping logging after 98096 examples to avoid logging too frequently
train stats after 98112 examples: {'rewards_train/chosen': '-0.41139', 'rewards_train/rejected': '-0.50165', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.09029', 'logps_train/rejected': '-134.27', 'logps_train/chosen': '-115.68', 'loss/train': '0.66452', 'examples_per_second': '4.3231', 'grad_norm': '17.375', 'counters/examples': 98112, 'counters/updates': 6132}
skipping logging after 98128 examples to avoid logging too frequently
skipping logging after 98144 examples to avoid logging too frequently
skipping logging after 98160 examples to avoid logging too frequently
train stats after 98176 examples: {'rewards_train/chosen': '-0.44995', 'rewards_train/rejected': '-0.63415', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.18412', 'logps_train/rejected': '-107.79', 'logps_train/chosen': '-119.32', 'loss/train': '0.63234', 'examples_per_second': '4.0214', 'grad_norm': '17.125', 'counters/examples': 98176, 'counters/updates': 6136}
skipping logging after 98192 examples to avoid logging too frequently
skipping logging after 98208 examples to avoid logging too frequently
Running evaluation after 98208 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:09,  2.24s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:03,  2.12s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.89s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.88s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 98208: {'rewards_eval/chosen': '-0.48364', 'rewards_eval/rejected': '-0.59062', 'rewards_eval/accuracies': '0.55469', 'rewards_eval/margins': '0.10695', 'logps_eval/rejected': '-128.06', 'logps_eval/chosen': '-123.33', 'loss/eval': '0.67121'}
skipping logging after 98224 examples to avoid logging too frequently
train stats after 98240 examples: {'rewards_train/chosen': '-0.42233', 'rewards_train/rejected': '-0.58038', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.15819', 'logps_train/rejected': '-125.69', 'logps_train/chosen': '-143.4', 'loss/train': '0.64467', 'examples_per_second': '5.2914', 'grad_norm': '18.5', 'counters/examples': 98240, 'counters/updates': 6140}
skipping logging after 98256 examples to avoid logging too frequently
skipping logging after 98272 examples to avoid logging too frequently
skipping logging after 98288 examples to avoid logging too frequently
train stats after 98304 examples: {'rewards_train/chosen': '-0.50971', 'rewards_train/rejected': '-0.56347', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.053859', 'logps_train/rejected': '-114.08', 'logps_train/chosen': '-126.45', 'loss/train': '0.68674', 'examples_per_second': '5.0034', 'grad_norm': '16.625', 'counters/examples': 98304, 'counters/updates': 6144}
skipping logging after 98320 examples to avoid logging too frequently
skipping logging after 98336 examples to avoid logging too frequently
skipping logging after 98352 examples to avoid logging too frequently
train stats after 98368 examples: {'rewards_train/chosen': '-0.35232', 'rewards_train/rejected': '-0.46486', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.11248', 'logps_train/rejected': '-110.9', 'logps_train/chosen': '-120.88', 'loss/train': '0.65781', 'examples_per_second': '4.7178', 'grad_norm': '16.5', 'counters/examples': 98368, 'counters/updates': 6148}
skipping logging after 98384 examples to avoid logging too frequently
skipping logging after 98400 examples to avoid logging too frequently
skipping logging after 98416 examples to avoid logging too frequently
train stats after 98432 examples: {'rewards_train/chosen': '-0.37924', 'rewards_train/rejected': '-0.56217', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.18308', 'logps_train/rejected': '-120.53', 'logps_train/chosen': '-110.27', 'loss/train': '0.63315', 'examples_per_second': '5.0273', 'grad_norm': '18.75', 'counters/examples': 98432, 'counters/updates': 6152}
skipping logging after 98448 examples to avoid logging too frequently
skipping logging after 98464 examples to avoid logging too frequently
skipping logging after 98480 examples to avoid logging too frequently
train stats after 98496 examples: {'rewards_train/chosen': '-0.46924', 'rewards_train/rejected': '-0.54113', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.071964', 'logps_train/rejected': '-108.18', 'logps_train/chosen': '-115.45', 'loss/train': '0.6745', 'examples_per_second': '5.7752', 'grad_norm': '17.5', 'counters/examples': 98496, 'counters/updates': 6156}
skipping logging after 98512 examples to avoid logging too frequently
skipping logging after 98528 examples to avoid logging too frequently
skipping logging after 98544 examples to avoid logging too frequently
train stats after 98560 examples: {'rewards_train/chosen': '-0.38577', 'rewards_train/rejected': '-0.48526', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.099525', 'logps_train/rejected': '-154.02', 'logps_train/chosen': '-149.82', 'loss/train': '0.66614', 'examples_per_second': '3.8665', 'grad_norm': '19.125', 'counters/examples': 98560, 'counters/updates': 6160}
skipping logging after 98576 examples to avoid logging too frequently
skipping logging after 98592 examples to avoid logging too frequently
skipping logging after 98608 examples to avoid logging too frequently
train stats after 98624 examples: {'rewards_train/chosen': '-0.50177', 'rewards_train/rejected': '-0.65604', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.15412', 'logps_train/rejected': '-96.738', 'logps_train/chosen': '-106.43', 'loss/train': '0.64693', 'examples_per_second': '4.7131', 'grad_norm': '14.75', 'counters/examples': 98624, 'counters/updates': 6164}
skipping logging after 98640 examples to avoid logging too frequently
skipping logging after 98656 examples to avoid logging too frequently
skipping logging after 98672 examples to avoid logging too frequently
train stats after 98688 examples: {'rewards_train/chosen': '-0.50378', 'rewards_train/rejected': '-0.62868', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.1249', 'logps_train/rejected': '-117.38', 'logps_train/chosen': '-112.42', 'loss/train': '0.64767', 'examples_per_second': '6.0373', 'grad_norm': '19.375', 'counters/examples': 98688, 'counters/updates': 6168}
skipping logging after 98704 examples to avoid logging too frequently
skipping logging after 98720 examples to avoid logging too frequently
skipping logging after 98736 examples to avoid logging too frequently
train stats after 98752 examples: {'rewards_train/chosen': '-0.53196', 'rewards_train/rejected': '-0.54733', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.015331', 'logps_train/rejected': '-111', 'logps_train/chosen': '-111.78', 'loss/train': '0.7139', 'examples_per_second': '5.7253', 'grad_norm': '19.125', 'counters/examples': 98752, 'counters/updates': 6172}
skipping logging after 98768 examples to avoid logging too frequently
skipping logging after 98784 examples to avoid logging too frequently
skipping logging after 98800 examples to avoid logging too frequently
train stats after 98816 examples: {'rewards_train/chosen': '-0.44215', 'rewards_train/rejected': '-0.5422', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.1002', 'logps_train/rejected': '-118.18', 'logps_train/chosen': '-121.6', 'loss/train': '0.67221', 'examples_per_second': '4.9342', 'grad_norm': '19.75', 'counters/examples': 98816, 'counters/updates': 6176}
skipping logging after 98832 examples to avoid logging too frequently
skipping logging after 98848 examples to avoid logging too frequently
skipping logging after 98864 examples to avoid logging too frequently
train stats after 98880 examples: {'rewards_train/chosen': '-0.4866', 'rewards_train/rejected': '-0.60816', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.12155', 'logps_train/rejected': '-119.89', 'logps_train/chosen': '-131.99', 'loss/train': '0.66507', 'examples_per_second': '4.5623', 'grad_norm': '18.75', 'counters/examples': 98880, 'counters/updates': 6180}
skipping logging after 98896 examples to avoid logging too frequently
skipping logging after 98912 examples to avoid logging too frequently
skipping logging after 98928 examples to avoid logging too frequently
train stats after 98944 examples: {'rewards_train/chosen': '-0.39702', 'rewards_train/rejected': '-0.51662', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.11975', 'logps_train/rejected': '-113.65', 'logps_train/chosen': '-128.49', 'loss/train': '0.65878', 'examples_per_second': '5.1868', 'grad_norm': '16.5', 'counters/examples': 98944, 'counters/updates': 6184}
skipping logging after 98960 examples to avoid logging too frequently
skipping logging after 98976 examples to avoid logging too frequently
skipping logging after 98992 examples to avoid logging too frequently
train stats after 99008 examples: {'rewards_train/chosen': '-0.42461', 'rewards_train/rejected': '-0.57943', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.15482', 'logps_train/rejected': '-110.34', 'logps_train/chosen': '-119.7', 'loss/train': '0.64401', 'examples_per_second': '4.9943', 'grad_norm': '17', 'counters/examples': 99008, 'counters/updates': 6188}
skipping logging after 99024 examples to avoid logging too frequently
skipping logging after 99040 examples to avoid logging too frequently
skipping logging after 99056 examples to avoid logging too frequently
train stats after 99072 examples: {'rewards_train/chosen': '-0.43674', 'rewards_train/rejected': '-0.59818', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.1615', 'logps_train/rejected': '-115.9', 'logps_train/chosen': '-129.75', 'loss/train': '0.63811', 'examples_per_second': '5.3127', 'grad_norm': '21.625', 'counters/examples': 99072, 'counters/updates': 6192}
skipping logging after 99088 examples to avoid logging too frequently
skipping logging after 99104 examples to avoid logging too frequently
skipping logging after 99120 examples to avoid logging too frequently
train stats after 99136 examples: {'rewards_train/chosen': '-0.57669', 'rewards_train/rejected': '-0.68378', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.10718', 'logps_train/rejected': '-128.28', 'logps_train/chosen': '-115.28', 'loss/train': '0.66168', 'examples_per_second': '4.8061', 'grad_norm': '17.5', 'counters/examples': 99136, 'counters/updates': 6196}
skipping logging after 99152 examples to avoid logging too frequently
skipping logging after 99168 examples to avoid logging too frequently
skipping logging after 99184 examples to avoid logging too frequently
train stats after 99200 examples: {'rewards_train/chosen': '-0.48424', 'rewards_train/rejected': '-0.53232', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '0.04805', 'logps_train/rejected': '-145.58', 'logps_train/chosen': '-153.97', 'loss/train': '0.69037', 'examples_per_second': '4.9912', 'grad_norm': '21.375', 'counters/examples': 99200, 'counters/updates': 6200}
Running evaluation after 99200 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.46s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.53s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 99200: {'rewards_eval/chosen': '-0.54615', 'rewards_eval/rejected': '-0.65569', 'rewards_eval/accuracies': '0.54688', 'rewards_eval/margins': '0.10958', 'logps_eval/rejected': '-128.71', 'logps_eval/chosen': '-123.96', 'loss/eval': '0.66996'}
skipping logging after 99216 examples to avoid logging too frequently
skipping logging after 99232 examples to avoid logging too frequently
skipping logging after 99248 examples to avoid logging too frequently
train stats after 99264 examples: {'rewards_train/chosen': '-0.35601', 'rewards_train/rejected': '-0.5214', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.16537', 'logps_train/rejected': '-128.29', 'logps_train/chosen': '-131.49', 'loss/train': '0.63297', 'examples_per_second': '4.4215', 'grad_norm': '17.25', 'counters/examples': 99264, 'counters/updates': 6204}
skipping logging after 99280 examples to avoid logging too frequently
skipping logging after 99296 examples to avoid logging too frequently
skipping logging after 99312 examples to avoid logging too frequently
train stats after 99328 examples: {'rewards_train/chosen': '-0.4555', 'rewards_train/rejected': '-0.56629', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.11085', 'logps_train/rejected': '-130.64', 'logps_train/chosen': '-101.41', 'loss/train': '0.6635', 'examples_per_second': '5.9159', 'grad_norm': '18.75', 'counters/examples': 99328, 'counters/updates': 6208}
skipping logging after 99344 examples to avoid logging too frequently
skipping logging after 99360 examples to avoid logging too frequently
skipping logging after 99376 examples to avoid logging too frequently
train stats after 99392 examples: {'rewards_train/chosen': '-0.42611', 'rewards_train/rejected': '-0.56031', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.13413', 'logps_train/rejected': '-131.65', 'logps_train/chosen': '-105.24', 'loss/train': '0.63831', 'examples_per_second': '5.0351', 'grad_norm': '17.75', 'counters/examples': 99392, 'counters/updates': 6212}
skipping logging after 99408 examples to avoid logging too frequently
skipping logging after 99424 examples to avoid logging too frequently
skipping logging after 99440 examples to avoid logging too frequently
train stats after 99456 examples: {'rewards_train/chosen': '-0.41706', 'rewards_train/rejected': '-0.57945', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.1625', 'logps_train/rejected': '-130.82', 'logps_train/chosen': '-121.05', 'loss/train': '0.63373', 'examples_per_second': '5.5552', 'grad_norm': '17.5', 'counters/examples': 99456, 'counters/updates': 6216}
skipping logging after 99472 examples to avoid logging too frequently
skipping logging after 99488 examples to avoid logging too frequently
skipping logging after 99504 examples to avoid logging too frequently
train stats after 99520 examples: {'rewards_train/chosen': '-0.49709', 'rewards_train/rejected': '-0.71073', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.21359', 'logps_train/rejected': '-98.352', 'logps_train/chosen': '-82.79', 'loss/train': '0.61977', 'examples_per_second': '6.5452', 'grad_norm': '15.438', 'counters/examples': 99520, 'counters/updates': 6220}
skipping logging after 99536 examples to avoid logging too frequently
skipping logging after 99552 examples to avoid logging too frequently
skipping logging after 99568 examples to avoid logging too frequently
train stats after 99584 examples: {'rewards_train/chosen': '-0.49737', 'rewards_train/rejected': '-0.55891', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.061481', 'logps_train/rejected': '-128.78', 'logps_train/chosen': '-129.6', 'loss/train': '0.69882', 'examples_per_second': '4.9744', 'grad_norm': '21.25', 'counters/examples': 99584, 'counters/updates': 6224}
skipping logging after 99600 examples to avoid logging too frequently
skipping logging after 99616 examples to avoid logging too frequently
skipping logging after 99632 examples to avoid logging too frequently
train stats after 99648 examples: {'rewards_train/chosen': '-0.54302', 'rewards_train/rejected': '-0.55421', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.011238', 'logps_train/rejected': '-136.27', 'logps_train/chosen': '-135.74', 'loss/train': '0.71577', 'examples_per_second': '4.9882', 'grad_norm': '23.125', 'counters/examples': 99648, 'counters/updates': 6228}
skipping logging after 99664 examples to avoid logging too frequently
skipping logging after 99680 examples to avoid logging too frequently
skipping logging after 99696 examples to avoid logging too frequently
train stats after 99712 examples: {'rewards_train/chosen': '-0.41725', 'rewards_train/rejected': '-0.60074', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.18351', 'logps_train/rejected': '-137.32', 'logps_train/chosen': '-121.71', 'loss/train': '0.62732', 'examples_per_second': '5.0371', 'grad_norm': '17.125', 'counters/examples': 99712, 'counters/updates': 6232}
skipping logging after 99728 examples to avoid logging too frequently
skipping logging after 99744 examples to avoid logging too frequently
skipping logging after 99760 examples to avoid logging too frequently
train stats after 99776 examples: {'rewards_train/chosen': '-0.4305', 'rewards_train/rejected': '-0.63482', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.20435', 'logps_train/rejected': '-155.25', 'logps_train/chosen': '-116.94', 'loss/train': '0.62076', 'examples_per_second': '5.5023', 'grad_norm': '19.875', 'counters/examples': 99776, 'counters/updates': 6236}
skipping logging after 99792 examples to avoid logging too frequently
skipping logging after 99808 examples to avoid logging too frequently
skipping logging after 99824 examples to avoid logging too frequently
train stats after 99840 examples: {'rewards_train/chosen': '-0.46039', 'rewards_train/rejected': '-0.57605', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.11557', 'logps_train/rejected': '-102.45', 'logps_train/chosen': '-117.72', 'loss/train': '0.6602', 'examples_per_second': '5.3016', 'grad_norm': '17.5', 'counters/examples': 99840, 'counters/updates': 6240}
skipping logging after 99856 examples to avoid logging too frequently
skipping logging after 99872 examples to avoid logging too frequently
skipping logging after 99888 examples to avoid logging too frequently
train stats after 99904 examples: {'rewards_train/chosen': '-0.6832', 'rewards_train/rejected': '-0.81957', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.13624', 'logps_train/rejected': '-111.77', 'logps_train/chosen': '-99.528', 'loss/train': '0.65125', 'examples_per_second': '6.0712', 'grad_norm': '20.125', 'counters/examples': 99904, 'counters/updates': 6244}
skipping logging after 99920 examples to avoid logging too frequently
skipping logging after 99936 examples to avoid logging too frequently
skipping logging after 99952 examples to avoid logging too frequently
train stats after 99968 examples: {'rewards_train/chosen': '-0.49889', 'rewards_train/rejected': '-0.60869', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.10973', 'logps_train/rejected': '-124.88', 'logps_train/chosen': '-116.43', 'loss/train': '0.66089', 'examples_per_second': '4.825', 'grad_norm': '19.5', 'counters/examples': 99968, 'counters/updates': 6248}
skipping logging after 99984 examples to avoid logging too frequently
skipping logging after 100000 examples to avoid logging too frequently
skipping logging after 100016 examples to avoid logging too frequently
train stats after 100032 examples: {'rewards_train/chosen': '-0.50248', 'rewards_train/rejected': '-0.68069', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.17833', 'logps_train/rejected': '-131.08', 'logps_train/chosen': '-112.3', 'loss/train': '0.63733', 'examples_per_second': '4.6648', 'grad_norm': '18.375', 'counters/examples': 100032, 'counters/updates': 6252}
skipping logging after 100048 examples to avoid logging too frequently
skipping logging after 100064 examples to avoid logging too frequently
skipping logging after 100080 examples to avoid logging too frequently
train stats after 100096 examples: {'rewards_train/chosen': '-0.64923', 'rewards_train/rejected': '-0.76818', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.11902', 'logps_train/rejected': '-122.33', 'logps_train/chosen': '-151.59', 'loss/train': '0.6665', 'examples_per_second': '4.6868', 'grad_norm': '24.25', 'counters/examples': 100096, 'counters/updates': 6256}
skipping logging after 100112 examples to avoid logging too frequently
skipping logging after 100128 examples to avoid logging too frequently
skipping logging after 100144 examples to avoid logging too frequently
train stats after 100160 examples: {'rewards_train/chosen': '-0.44598', 'rewards_train/rejected': '-0.54487', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.098751', 'logps_train/rejected': '-111.55', 'logps_train/chosen': '-101.09', 'loss/train': '0.67307', 'examples_per_second': '4.4557', 'grad_norm': '21', 'counters/examples': 100160, 'counters/updates': 6260}
skipping logging after 100176 examples to avoid logging too frequently
skipping logging after 100192 examples to avoid logging too frequently
Running evaluation after 100192 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:13,  2.37s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:05,  2.17s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:55,  1.92s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.89s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.54s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 100192: {'rewards_eval/chosen': '-0.52709', 'rewards_eval/rejected': '-0.64375', 'rewards_eval/accuracies': '0.54492', 'rewards_eval/margins': '0.11664', 'logps_eval/rejected': '-128.59', 'logps_eval/chosen': '-123.76', 'loss/eval': '0.67031'}
skipping logging after 100208 examples to avoid logging too frequently
train stats after 100224 examples: {'rewards_train/chosen': '-0.51539', 'rewards_train/rejected': '-0.59941', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.084133', 'logps_train/rejected': '-106.15', 'logps_train/chosen': '-117.86', 'loss/train': '0.6821', 'examples_per_second': '6.0418', 'grad_norm': '24', 'counters/examples': 100224, 'counters/updates': 6264}
skipping logging after 100240 examples to avoid logging too frequently
skipping logging after 100256 examples to avoid logging too frequently
skipping logging after 100272 examples to avoid logging too frequently
train stats after 100288 examples: {'rewards_train/chosen': '-0.3914', 'rewards_train/rejected': '-0.58648', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.19514', 'logps_train/rejected': '-116.09', 'logps_train/chosen': '-129.08', 'loss/train': '0.62814', 'examples_per_second': '5.3787', 'grad_norm': '16.25', 'counters/examples': 100288, 'counters/updates': 6268}
skipping logging after 100304 examples to avoid logging too frequently
skipping logging after 100320 examples to avoid logging too frequently
skipping logging after 100336 examples to avoid logging too frequently
train stats after 100352 examples: {'rewards_train/chosen': '-0.4284', 'rewards_train/rejected': '-0.66981', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.24152', 'logps_train/rejected': '-145.72', 'logps_train/chosen': '-130.24', 'loss/train': '0.62769', 'examples_per_second': '4.6215', 'grad_norm': '19.125', 'counters/examples': 100352, 'counters/updates': 6272}
skipping logging after 100368 examples to avoid logging too frequently
skipping logging after 100384 examples to avoid logging too frequently
skipping logging after 100400 examples to avoid logging too frequently
train stats after 100416 examples: {'rewards_train/chosen': '-0.5439', 'rewards_train/rejected': '-0.70829', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.16438', 'logps_train/rejected': '-117.02', 'logps_train/chosen': '-136.5', 'loss/train': '0.64503', 'examples_per_second': '5.6955', 'grad_norm': '18.625', 'counters/examples': 100416, 'counters/updates': 6276}
skipping logging after 100432 examples to avoid logging too frequently
skipping logging after 100448 examples to avoid logging too frequently
skipping logging after 100464 examples to avoid logging too frequently
train stats after 100480 examples: {'rewards_train/chosen': '-0.35845', 'rewards_train/rejected': '-0.58781', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.22946', 'logps_train/rejected': '-121.87', 'logps_train/chosen': '-117.39', 'loss/train': '0.61478', 'examples_per_second': '5.7771', 'grad_norm': '18.625', 'counters/examples': 100480, 'counters/updates': 6280}
skipping logging after 100496 examples to avoid logging too frequently
skipping logging after 100512 examples to avoid logging too frequently
skipping logging after 100528 examples to avoid logging too frequently
train stats after 100544 examples: {'rewards_train/chosen': '-0.60713', 'rewards_train/rejected': '-0.73706', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.12993', 'logps_train/rejected': '-129.97', 'logps_train/chosen': '-137.32', 'loss/train': '0.65669', 'examples_per_second': '4.0911', 'grad_norm': '21', 'counters/examples': 100544, 'counters/updates': 6284}
skipping logging after 100560 examples to avoid logging too frequently
skipping logging after 100576 examples to avoid logging too frequently
skipping logging after 100592 examples to avoid logging too frequently
train stats after 100608 examples: {'rewards_train/chosen': '-0.59652', 'rewards_train/rejected': '-0.75922', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.16276', 'logps_train/rejected': '-115.28', 'logps_train/chosen': '-122.33', 'loss/train': '0.64655', 'examples_per_second': '5.928', 'grad_norm': '17', 'counters/examples': 100608, 'counters/updates': 6288}
skipping logging after 100624 examples to avoid logging too frequently
skipping logging after 100640 examples to avoid logging too frequently
skipping logging after 100656 examples to avoid logging too frequently
train stats after 100672 examples: {'rewards_train/chosen': '-0.66686', 'rewards_train/rejected': '-0.78167', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.1148', 'logps_train/rejected': '-131.51', 'logps_train/chosen': '-141.73', 'loss/train': '0.67139', 'examples_per_second': '5.0427', 'grad_norm': '18.5', 'counters/examples': 100672, 'counters/updates': 6292}
skipping logging after 100688 examples to avoid logging too frequently
skipping logging after 100704 examples to avoid logging too frequently
skipping logging after 100720 examples to avoid logging too frequently
train stats after 100736 examples: {'rewards_train/chosen': '-0.61165', 'rewards_train/rejected': '-0.7606', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.14894', 'logps_train/rejected': '-114.27', 'logps_train/chosen': '-99.771', 'loss/train': '0.65413', 'examples_per_second': '5.4981', 'grad_norm': '19.75', 'counters/examples': 100736, 'counters/updates': 6296}
skipping logging after 100752 examples to avoid logging too frequently
skipping logging after 100768 examples to avoid logging too frequently
skipping logging after 100784 examples to avoid logging too frequently
train stats after 100800 examples: {'rewards_train/chosen': '-0.40808', 'rewards_train/rejected': '-0.51561', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.10746', 'logps_train/rejected': '-108.18', 'logps_train/chosen': '-99.825', 'loss/train': '0.6579', 'examples_per_second': '5.7657', 'grad_norm': '17.75', 'counters/examples': 100800, 'counters/updates': 6300}
skipping logging after 100816 examples to avoid logging too frequently
skipping logging after 100832 examples to avoid logging too frequently
skipping logging after 100848 examples to avoid logging too frequently
train stats after 100864 examples: {'rewards_train/chosen': '-0.53784', 'rewards_train/rejected': '-0.64515', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.1074', 'logps_train/rejected': '-123.58', 'logps_train/chosen': '-101.24', 'loss/train': '0.67441', 'examples_per_second': '5.7215', 'grad_norm': '21.125', 'counters/examples': 100864, 'counters/updates': 6304}
skipping logging after 100880 examples to avoid logging too frequently
skipping logging after 100896 examples to avoid logging too frequently
skipping logging after 100912 examples to avoid logging too frequently
train stats after 100928 examples: {'rewards_train/chosen': '-0.65152', 'rewards_train/rejected': '-0.79753', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.14601', 'logps_train/rejected': '-106.99', 'logps_train/chosen': '-108.06', 'loss/train': '0.64404', 'examples_per_second': '5.475', 'grad_norm': '20', 'counters/examples': 100928, 'counters/updates': 6308}
skipping logging after 100944 examples to avoid logging too frequently
skipping logging after 100960 examples to avoid logging too frequently
skipping logging after 100976 examples to avoid logging too frequently
train stats after 100992 examples: {'rewards_train/chosen': '-0.45326', 'rewards_train/rejected': '-0.64329', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.19001', 'logps_train/rejected': '-114.34', 'logps_train/chosen': '-119.26', 'loss/train': '0.63517', 'examples_per_second': '4.27', 'grad_norm': '19.125', 'counters/examples': 100992, 'counters/updates': 6312}
skipping logging after 101008 examples to avoid logging too frequently
skipping logging after 101024 examples to avoid logging too frequently
skipping logging after 101040 examples to avoid logging too frequently
train stats after 101056 examples: {'rewards_train/chosen': '-0.66262', 'rewards_train/rejected': '-0.71854', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.056068', 'logps_train/rejected': '-101.92', 'logps_train/chosen': '-95.672', 'loss/train': '0.69308', 'examples_per_second': '5.2841', 'grad_norm': '23.625', 'counters/examples': 101056, 'counters/updates': 6316}
skipping logging after 101072 examples to avoid logging too frequently
skipping logging after 101088 examples to avoid logging too frequently
skipping logging after 101104 examples to avoid logging too frequently
train stats after 101120 examples: {'rewards_train/chosen': '-0.52389', 'rewards_train/rejected': '-0.61848', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.094589', 'logps_train/rejected': '-107.71', 'logps_train/chosen': '-129.3', 'loss/train': '0.67819', 'examples_per_second': '6.3492', 'grad_norm': '22.375', 'counters/examples': 101120, 'counters/updates': 6320}
skipping logging after 101136 examples to avoid logging too frequently
skipping logging after 101152 examples to avoid logging too frequently
skipping logging after 101168 examples to avoid logging too frequently
train stats after 101184 examples: {'rewards_train/chosen': '-0.47753', 'rewards_train/rejected': '-0.56045', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.082958', 'logps_train/rejected': '-113.31', 'logps_train/chosen': '-132.05', 'loss/train': '0.68068', 'examples_per_second': '5.2331', 'grad_norm': '18.5', 'counters/examples': 101184, 'counters/updates': 6324}
Running evaluation after 101184 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 101184: {'rewards_eval/chosen': '-0.53839', 'rewards_eval/rejected': '-0.64982', 'rewards_eval/accuracies': '0.55078', 'rewards_eval/margins': '0.1114', 'logps_eval/rejected': '-128.65', 'logps_eval/chosen': '-123.88', 'loss/eval': '0.67104'}
skipping logging after 101200 examples to avoid logging too frequently
skipping logging after 101216 examples to avoid logging too frequently
skipping logging after 101232 examples to avoid logging too frequently
train stats after 101248 examples: {'rewards_train/chosen': '-0.51561', 'rewards_train/rejected': '-0.64804', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.13237', 'logps_train/rejected': '-111.37', 'logps_train/chosen': '-126.21', 'loss/train': '0.65863', 'examples_per_second': '5.6893', 'grad_norm': '18.5', 'counters/examples': 101248, 'counters/updates': 6328}
skipping logging after 101264 examples to avoid logging too frequently
skipping logging after 101280 examples to avoid logging too frequently
skipping logging after 101296 examples to avoid logging too frequently
train stats after 101312 examples: {'rewards_train/chosen': '-0.62928', 'rewards_train/rejected': '-0.79772', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.16842', 'logps_train/rejected': '-87.965', 'logps_train/chosen': '-127.95', 'loss/train': '0.647', 'examples_per_second': '5.9166', 'grad_norm': '18.5', 'counters/examples': 101312, 'counters/updates': 6332}
skipping logging after 101328 examples to avoid logging too frequently
skipping logging after 101344 examples to avoid logging too frequently
skipping logging after 101360 examples to avoid logging too frequently
train stats after 101376 examples: {'rewards_train/chosen': '-0.52495', 'rewards_train/rejected': '-0.70805', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.183', 'logps_train/rejected': '-137.62', 'logps_train/chosen': '-140.64', 'loss/train': '0.63438', 'examples_per_second': '5.2027', 'grad_norm': '19.375', 'counters/examples': 101376, 'counters/updates': 6336}
skipping logging after 101392 examples to avoid logging too frequently
skipping logging after 101408 examples to avoid logging too frequently
skipping logging after 101424 examples to avoid logging too frequently
train stats after 101440 examples: {'rewards_train/chosen': '-0.52602', 'rewards_train/rejected': '-0.60815', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.082214', 'logps_train/rejected': '-120.1', 'logps_train/chosen': '-145.72', 'loss/train': '0.6945', 'examples_per_second': '6.0361', 'grad_norm': '24.25', 'counters/examples': 101440, 'counters/updates': 6340}
skipping logging after 101456 examples to avoid logging too frequently
skipping logging after 101472 examples to avoid logging too frequently
skipping logging after 101488 examples to avoid logging too frequently
train stats after 101504 examples: {'rewards_train/chosen': '-0.45423', 'rewards_train/rejected': '-0.56468', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.11049', 'logps_train/rejected': '-140.98', 'logps_train/chosen': '-117.1', 'loss/train': '0.6618', 'examples_per_second': '5.3427', 'grad_norm': '19.375', 'counters/examples': 101504, 'counters/updates': 6344}
skipping logging after 101520 examples to avoid logging too frequently
skipping logging after 101536 examples to avoid logging too frequently
skipping logging after 101552 examples to avoid logging too frequently
train stats after 101568 examples: {'rewards_train/chosen': '-0.37946', 'rewards_train/rejected': '-0.56156', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.18216', 'logps_train/rejected': '-119.59', 'logps_train/chosen': '-113.01', 'loss/train': '0.62958', 'examples_per_second': '4.9566', 'grad_norm': '16.25', 'counters/examples': 101568, 'counters/updates': 6348}
skipping logging after 101584 examples to avoid logging too frequently
skipping logging after 101600 examples to avoid logging too frequently
skipping logging after 101616 examples to avoid logging too frequently
train stats after 101632 examples: {'rewards_train/chosen': '-0.4626', 'rewards_train/rejected': '-0.62506', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.16252', 'logps_train/rejected': '-119.99', 'logps_train/chosen': '-113.72', 'loss/train': '0.64021', 'examples_per_second': '5.1811', 'grad_norm': '18.75', 'counters/examples': 101632, 'counters/updates': 6352}
skipping logging after 101648 examples to avoid logging too frequently
skipping logging after 101664 examples to avoid logging too frequently
skipping logging after 101680 examples to avoid logging too frequently
train stats after 101696 examples: {'rewards_train/chosen': '-0.55171', 'rewards_train/rejected': '-0.71946', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.16764', 'logps_train/rejected': '-133.25', 'logps_train/chosen': '-129.08', 'loss/train': '0.64642', 'examples_per_second': '4.6995', 'grad_norm': '18.25', 'counters/examples': 101696, 'counters/updates': 6356}
skipping logging after 101712 examples to avoid logging too frequently
skipping logging after 101728 examples to avoid logging too frequently
skipping logging after 101744 examples to avoid logging too frequently
train stats after 101760 examples: {'rewards_train/chosen': '-0.42506', 'rewards_train/rejected': '-0.56596', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.14093', 'logps_train/rejected': '-126.24', 'logps_train/chosen': '-119', 'loss/train': '0.65285', 'examples_per_second': '5.5309', 'grad_norm': '16.25', 'counters/examples': 101760, 'counters/updates': 6360}
skipping logging after 101776 examples to avoid logging too frequently
skipping logging after 101792 examples to avoid logging too frequently
skipping logging after 101808 examples to avoid logging too frequently
train stats after 101824 examples: {'rewards_train/chosen': '-0.46026', 'rewards_train/rejected': '-0.53378', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.073437', 'logps_train/rejected': '-119.18', 'logps_train/chosen': '-123.71', 'loss/train': '0.68201', 'examples_per_second': '4.5774', 'grad_norm': '17.875', 'counters/examples': 101824, 'counters/updates': 6364}
skipping logging after 101840 examples to avoid logging too frequently
skipping logging after 101856 examples to avoid logging too frequently
skipping logging after 101872 examples to avoid logging too frequently
train stats after 101888 examples: {'rewards_train/chosen': '-0.54994', 'rewards_train/rejected': '-0.61749', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.06765', 'logps_train/rejected': '-114.9', 'logps_train/chosen': '-115.22', 'loss/train': '0.6893', 'examples_per_second': '5.2345', 'grad_norm': '17.75', 'counters/examples': 101888, 'counters/updates': 6368}
skipping logging after 101904 examples to avoid logging too frequently
skipping logging after 101920 examples to avoid logging too frequently
skipping logging after 101936 examples to avoid logging too frequently
train stats after 101952 examples: {'rewards_train/chosen': '-0.49405', 'rewards_train/rejected': '-0.64739', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.15344', 'logps_train/rejected': '-137.43', 'logps_train/chosen': '-108.67', 'loss/train': '0.63696', 'examples_per_second': '5.1205', 'grad_norm': '20.375', 'counters/examples': 101952, 'counters/updates': 6372}
skipping logging after 101968 examples to avoid logging too frequently
skipping logging after 101984 examples to avoid logging too frequently
skipping logging after 102000 examples to avoid logging too frequently
train stats after 102016 examples: {'rewards_train/chosen': '-0.56048', 'rewards_train/rejected': '-0.71349', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.15298', 'logps_train/rejected': '-105.96', 'logps_train/chosen': '-113.93', 'loss/train': '0.65253', 'examples_per_second': '4.7129', 'grad_norm': '15.438', 'counters/examples': 102016, 'counters/updates': 6376}
skipping logging after 102032 examples to avoid logging too frequently
skipping logging after 102048 examples to avoid logging too frequently
skipping logging after 102064 examples to avoid logging too frequently
train stats after 102080 examples: {'rewards_train/chosen': '-0.61358', 'rewards_train/rejected': '-0.75286', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.13918', 'logps_train/rejected': '-127.04', 'logps_train/chosen': '-126.85', 'loss/train': '0.65007', 'examples_per_second': '4.465', 'grad_norm': '19', 'counters/examples': 102080, 'counters/updates': 6380}
skipping logging after 102096 examples to avoid logging too frequently
skipping logging after 102112 examples to avoid logging too frequently
skipping logging after 102128 examples to avoid logging too frequently
train stats after 102144 examples: {'rewards_train/chosen': '-0.45042', 'rewards_train/rejected': '-0.68374', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.23335', 'logps_train/rejected': '-126.36', 'logps_train/chosen': '-129.6', 'loss/train': '0.6249', 'examples_per_second': '4.1469', 'grad_norm': '17.75', 'counters/examples': 102144, 'counters/updates': 6384}
skipping logging after 102160 examples to avoid logging too frequently
skipping logging after 102176 examples to avoid logging too frequently
Running evaluation after 102176 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:08,  2.22s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:03,  2.11s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.88s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.87s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 102176: {'rewards_eval/chosen': '-0.59475', 'rewards_eval/rejected': '-0.71328', 'rewards_eval/accuracies': '0.53516', 'rewards_eval/margins': '0.11851', 'logps_eval/rejected': '-129.29', 'logps_eval/chosen': '-124.44', 'loss/eval': '0.67019'}
skipping logging after 102192 examples to avoid logging too frequently
train stats after 102208 examples: {'rewards_train/chosen': '-0.54162', 'rewards_train/rejected': '-0.68793', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.14635', 'logps_train/rejected': '-108.07', 'logps_train/chosen': '-133.54', 'loss/train': '0.6519', 'examples_per_second': '5.5055', 'grad_norm': '22.125', 'counters/examples': 102208, 'counters/updates': 6388}
skipping logging after 102224 examples to avoid logging too frequently
skipping logging after 102240 examples to avoid logging too frequently
skipping logging after 102256 examples to avoid logging too frequently
train stats after 102272 examples: {'rewards_train/chosen': '-0.60744', 'rewards_train/rejected': '-0.79732', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.18985', 'logps_train/rejected': '-134.29', 'logps_train/chosen': '-133.21', 'loss/train': '0.63275', 'examples_per_second': '6.0915', 'grad_norm': '19.875', 'counters/examples': 102272, 'counters/updates': 6392}
skipping logging after 102288 examples to avoid logging too frequently
skipping logging after 102304 examples to avoid logging too frequently
skipping logging after 102320 examples to avoid logging too frequently
train stats after 102336 examples: {'rewards_train/chosen': '-0.4951', 'rewards_train/rejected': '-0.56776', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.072716', 'logps_train/rejected': '-113.11', 'logps_train/chosen': '-106.1', 'loss/train': '0.67889', 'examples_per_second': '4.8026', 'grad_norm': '21.625', 'counters/examples': 102336, 'counters/updates': 6396}
skipping logging after 102352 examples to avoid logging too frequently
skipping logging after 102368 examples to avoid logging too frequently
skipping logging after 102384 examples to avoid logging too frequently
train stats after 102400 examples: {'rewards_train/chosen': '-0.59225', 'rewards_train/rejected': '-0.62375', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.031525', 'logps_train/rejected': '-135.12', 'logps_train/chosen': '-120.53', 'loss/train': '0.70737', 'examples_per_second': '4.8219', 'grad_norm': '21.875', 'counters/examples': 102400, 'counters/updates': 6400}
skipping logging after 102416 examples to avoid logging too frequently
skipping logging after 102432 examples to avoid logging too frequently
skipping logging after 102448 examples to avoid logging too frequently
train stats after 102464 examples: {'rewards_train/chosen': '-0.5607', 'rewards_train/rejected': '-0.78871', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.22826', 'logps_train/rejected': '-152.18', 'logps_train/chosen': '-121.25', 'loss/train': '0.6186', 'examples_per_second': '5.2809', 'grad_norm': '22.375', 'counters/examples': 102464, 'counters/updates': 6404}
skipping logging after 102480 examples to avoid logging too frequently
skipping logging after 102496 examples to avoid logging too frequently
skipping logging after 102512 examples to avoid logging too frequently
train stats after 102528 examples: {'rewards_train/chosen': '-0.47879', 'rewards_train/rejected': '-0.63166', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.15283', 'logps_train/rejected': '-156.09', 'logps_train/chosen': '-153.7', 'loss/train': '0.63562', 'examples_per_second': '4.6551', 'grad_norm': '19.375', 'counters/examples': 102528, 'counters/updates': 6408}
skipping logging after 102544 examples to avoid logging too frequently
skipping logging after 102560 examples to avoid logging too frequently
skipping logging after 102576 examples to avoid logging too frequently
train stats after 102592 examples: {'rewards_train/chosen': '-0.57216', 'rewards_train/rejected': '-0.65413', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.081833', 'logps_train/rejected': '-124.24', 'logps_train/chosen': '-136.76', 'loss/train': '0.68163', 'examples_per_second': '4.9176', 'grad_norm': '19.625', 'counters/examples': 102592, 'counters/updates': 6412}
skipping logging after 102608 examples to avoid logging too frequently
skipping logging after 102624 examples to avoid logging too frequently
skipping logging after 102640 examples to avoid logging too frequently
train stats after 102656 examples: {'rewards_train/chosen': '-0.64412', 'rewards_train/rejected': '-0.7725', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.12844', 'logps_train/rejected': '-109.16', 'logps_train/chosen': '-148.71', 'loss/train': '0.65881', 'examples_per_second': '5.4167', 'grad_norm': '21.75', 'counters/examples': 102656, 'counters/updates': 6416}
skipping logging after 102672 examples to avoid logging too frequently
skipping logging after 102688 examples to avoid logging too frequently
skipping logging after 102704 examples to avoid logging too frequently
train stats after 102720 examples: {'rewards_train/chosen': '-0.5703', 'rewards_train/rejected': '-0.66414', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.093876', 'logps_train/rejected': '-155.96', 'logps_train/chosen': '-128.42', 'loss/train': '0.6806', 'examples_per_second': '4.4901', 'grad_norm': '23.375', 'counters/examples': 102720, 'counters/updates': 6420}
skipping logging after 102736 examples to avoid logging too frequently
skipping logging after 102752 examples to avoid logging too frequently
skipping logging after 102768 examples to avoid logging too frequently
train stats after 102784 examples: {'rewards_train/chosen': '-0.54442', 'rewards_train/rejected': '-0.68716', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.14268', 'logps_train/rejected': '-104.16', 'logps_train/chosen': '-105.22', 'loss/train': '0.65724', 'examples_per_second': '5.6192', 'grad_norm': '17.125', 'counters/examples': 102784, 'counters/updates': 6424}
skipping logging after 102800 examples to avoid logging too frequently
skipping logging after 102816 examples to avoid logging too frequently
skipping logging after 102832 examples to avoid logging too frequently
train stats after 102848 examples: {'rewards_train/chosen': '-0.53479', 'rewards_train/rejected': '-0.66496', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.12998', 'logps_train/rejected': '-105.82', 'logps_train/chosen': '-113.12', 'loss/train': '0.65552', 'examples_per_second': '5.7272', 'grad_norm': '17.75', 'counters/examples': 102848, 'counters/updates': 6428}
skipping logging after 102864 examples to avoid logging too frequently
skipping logging after 102880 examples to avoid logging too frequently
skipping logging after 102896 examples to avoid logging too frequently
train stats after 102912 examples: {'rewards_train/chosen': '-0.47576', 'rewards_train/rejected': '-0.74935', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.27377', 'logps_train/rejected': '-115.48', 'logps_train/chosen': '-122.29', 'loss/train': '0.6019', 'examples_per_second': '4.6986', 'grad_norm': '19.125', 'counters/examples': 102912, 'counters/updates': 6432}
skipping logging after 102928 examples to avoid logging too frequently
skipping logging after 102944 examples to avoid logging too frequently
skipping logging after 102960 examples to avoid logging too frequently
train stats after 102976 examples: {'rewards_train/chosen': '-0.54824', 'rewards_train/rejected': '-0.63014', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.082031', 'logps_train/rejected': '-120.51', 'logps_train/chosen': '-106.85', 'loss/train': '0.69194', 'examples_per_second': '5.2355', 'grad_norm': '20.5', 'counters/examples': 102976, 'counters/updates': 6436}
skipping logging after 102992 examples to avoid logging too frequently
skipping logging after 103008 examples to avoid logging too frequently
skipping logging after 103024 examples to avoid logging too frequently
train stats after 103040 examples: {'rewards_train/chosen': '-0.51466', 'rewards_train/rejected': '-0.64451', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.12993', 'logps_train/rejected': '-136.58', 'logps_train/chosen': '-128.45', 'loss/train': '0.66251', 'examples_per_second': '4.6295', 'grad_norm': '23.5', 'counters/examples': 103040, 'counters/updates': 6440}
skipping logging after 103056 examples to avoid logging too frequently
skipping logging after 103072 examples to avoid logging too frequently
skipping logging after 103088 examples to avoid logging too frequently
train stats after 103104 examples: {'rewards_train/chosen': '-0.42743', 'rewards_train/rejected': '-0.63592', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.2086', 'logps_train/rejected': '-112.43', 'logps_train/chosen': '-112.28', 'loss/train': '0.62038', 'examples_per_second': '6.5191', 'grad_norm': '16.5', 'counters/examples': 103104, 'counters/updates': 6444}
skipping logging after 103120 examples to avoid logging too frequently
skipping logging after 103136 examples to avoid logging too frequently
skipping logging after 103152 examples to avoid logging too frequently
train stats after 103168 examples: {'rewards_train/chosen': '-0.49052', 'rewards_train/rejected': '-0.58612', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.095779', 'logps_train/rejected': '-152.63', 'logps_train/chosen': '-133.79', 'loss/train': '0.67343', 'examples_per_second': '4.6315', 'grad_norm': '22.5', 'counters/examples': 103168, 'counters/updates': 6448}
Running evaluation after 103168 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 103168: {'rewards_eval/chosen': '-0.54125', 'rewards_eval/rejected': '-0.66285', 'rewards_eval/accuracies': '0.55078', 'rewards_eval/margins': '0.12164', 'logps_eval/rejected': '-128.78', 'logps_eval/chosen': '-123.91', 'loss/eval': '0.66919'}
skipping logging after 103184 examples to avoid logging too frequently
skipping logging after 103200 examples to avoid logging too frequently
skipping logging after 103216 examples to avoid logging too frequently
train stats after 103232 examples: {'rewards_train/chosen': '-0.47566', 'rewards_train/rejected': '-0.68305', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.20733', 'logps_train/rejected': '-117.46', 'logps_train/chosen': '-107.35', 'loss/train': '0.62099', 'examples_per_second': '4.5388', 'grad_norm': '20.25', 'counters/examples': 103232, 'counters/updates': 6452}
skipping logging after 103248 examples to avoid logging too frequently
skipping logging after 103264 examples to avoid logging too frequently
skipping logging after 103280 examples to avoid logging too frequently
train stats after 103296 examples: {'rewards_train/chosen': '-0.51574', 'rewards_train/rejected': '-0.6441', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.12841', 'logps_train/rejected': '-106.69', 'logps_train/chosen': '-148.6', 'loss/train': '0.66782', 'examples_per_second': '6.0701', 'grad_norm': '18.625', 'counters/examples': 103296, 'counters/updates': 6456}
skipping logging after 103312 examples to avoid logging too frequently
skipping logging after 103328 examples to avoid logging too frequently
skipping logging after 103344 examples to avoid logging too frequently
train stats after 103360 examples: {'rewards_train/chosen': '-0.53428', 'rewards_train/rejected': '-0.64225', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.10811', 'logps_train/rejected': '-123.78', 'logps_train/chosen': '-150.29', 'loss/train': '0.66815', 'examples_per_second': '4.2711', 'grad_norm': '18.75', 'counters/examples': 103360, 'counters/updates': 6460}
skipping logging after 103376 examples to avoid logging too frequently
skipping logging after 103392 examples to avoid logging too frequently
skipping logging after 103408 examples to avoid logging too frequently
train stats after 103424 examples: {'rewards_train/chosen': '-0.61205', 'rewards_train/rejected': '-0.672', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.060019', 'logps_train/rejected': '-125.05', 'logps_train/chosen': '-131.66', 'loss/train': '0.69125', 'examples_per_second': '3.9069', 'grad_norm': '22.125', 'counters/examples': 103424, 'counters/updates': 6464}
skipping logging after 103440 examples to avoid logging too frequently
skipping logging after 103456 examples to avoid logging too frequently
skipping logging after 103472 examples to avoid logging too frequently
train stats after 103488 examples: {'rewards_train/chosen': '-0.5793', 'rewards_train/rejected': '-0.68792', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.10863', 'logps_train/rejected': '-149.1', 'logps_train/chosen': '-142.33', 'loss/train': '0.66403', 'examples_per_second': '5.5025', 'grad_norm': '18.875', 'counters/examples': 103488, 'counters/updates': 6468}
skipping logging after 103504 examples to avoid logging too frequently
skipping logging after 103520 examples to avoid logging too frequently
skipping logging after 103536 examples to avoid logging too frequently
train stats after 103552 examples: {'rewards_train/chosen': '-0.58953', 'rewards_train/rejected': '-0.68864', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.098953', 'logps_train/rejected': '-101.34', 'logps_train/chosen': '-95.039', 'loss/train': '0.67529', 'examples_per_second': '6.0748', 'grad_norm': '18.75', 'counters/examples': 103552, 'counters/updates': 6472}
skipping logging after 103568 examples to avoid logging too frequently
skipping logging after 103584 examples to avoid logging too frequently
skipping logging after 103600 examples to avoid logging too frequently
train stats after 103616 examples: {'rewards_train/chosen': '-0.55113', 'rewards_train/rejected': '-0.61362', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.06249', 'logps_train/rejected': '-97.078', 'logps_train/chosen': '-113.55', 'loss/train': '0.68994', 'examples_per_second': '4.9318', 'grad_norm': '17.75', 'counters/examples': 103616, 'counters/updates': 6476}
skipping logging after 103632 examples to avoid logging too frequently
skipping logging after 103648 examples to avoid logging too frequently
skipping logging after 103664 examples to avoid logging too frequently
train stats after 103680 examples: {'rewards_train/chosen': '-0.50459', 'rewards_train/rejected': '-0.62112', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.11643', 'logps_train/rejected': '-135.81', 'logps_train/chosen': '-139.17', 'loss/train': '0.6762', 'examples_per_second': '5.9226', 'grad_norm': '21.375', 'counters/examples': 103680, 'counters/updates': 6480}
skipping logging after 103696 examples to avoid logging too frequently
skipping logging after 103712 examples to avoid logging too frequently
skipping logging after 103728 examples to avoid logging too frequently
train stats after 103744 examples: {'rewards_train/chosen': '-0.49219', 'rewards_train/rejected': '-0.63179', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.1396', 'logps_train/rejected': '-137.2', 'logps_train/chosen': '-135.85', 'loss/train': '0.65866', 'examples_per_second': '4.1467', 'grad_norm': '20.5', 'counters/examples': 103744, 'counters/updates': 6484}
skipping logging after 103760 examples to avoid logging too frequently
skipping logging after 103776 examples to avoid logging too frequently
skipping logging after 103792 examples to avoid logging too frequently
train stats after 103808 examples: {'rewards_train/chosen': '-0.42578', 'rewards_train/rejected': '-0.61002', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.18415', 'logps_train/rejected': '-99.217', 'logps_train/chosen': '-107.7', 'loss/train': '0.62956', 'examples_per_second': '5.874', 'grad_norm': '16.625', 'counters/examples': 103808, 'counters/updates': 6488}
skipping logging after 103824 examples to avoid logging too frequently
skipping logging after 103840 examples to avoid logging too frequently
skipping logging after 103856 examples to avoid logging too frequently
train stats after 103872 examples: {'rewards_train/chosen': '-0.70144', 'rewards_train/rejected': '-0.7818', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.080315', 'logps_train/rejected': '-119.51', 'logps_train/chosen': '-103.72', 'loss/train': '0.68915', 'examples_per_second': '5.854', 'grad_norm': '20', 'counters/examples': 103872, 'counters/updates': 6492}
skipping logging after 103888 examples to avoid logging too frequently
skipping logging after 103904 examples to avoid logging too frequently
skipping logging after 103920 examples to avoid logging too frequently
train stats after 103936 examples: {'rewards_train/chosen': '-0.48357', 'rewards_train/rejected': '-0.72089', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.23726', 'logps_train/rejected': '-125.62', 'logps_train/chosen': '-122.85', 'loss/train': '0.62161', 'examples_per_second': '4.8655', 'grad_norm': '16.375', 'counters/examples': 103936, 'counters/updates': 6496}
skipping logging after 103952 examples to avoid logging too frequently
skipping logging after 103968 examples to avoid logging too frequently
skipping logging after 103984 examples to avoid logging too frequently
train stats after 104000 examples: {'rewards_train/chosen': '-0.52985', 'rewards_train/rejected': '-0.6277', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '0.097778', 'logps_train/rejected': '-121.17', 'logps_train/chosen': '-120.14', 'loss/train': '0.66187', 'examples_per_second': '4.4098', 'grad_norm': '21.25', 'counters/examples': 104000, 'counters/updates': 6500}
skipping logging after 104016 examples to avoid logging too frequently
skipping logging after 104032 examples to avoid logging too frequently
skipping logging after 104048 examples to avoid logging too frequently
train stats after 104064 examples: {'rewards_train/chosen': '-0.63401', 'rewards_train/rejected': '-0.68049', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.046471', 'logps_train/rejected': '-164.83', 'logps_train/chosen': '-110.71', 'loss/train': '0.69873', 'examples_per_second': '4.8736', 'grad_norm': '29.125', 'counters/examples': 104064, 'counters/updates': 6504}
skipping logging after 104080 examples to avoid logging too frequently
skipping logging after 104096 examples to avoid logging too frequently
skipping logging after 104112 examples to avoid logging too frequently
train stats after 104128 examples: {'rewards_train/chosen': '-0.48497', 'rewards_train/rejected': '-0.68106', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.19609', 'logps_train/rejected': '-126.8', 'logps_train/chosen': '-120.99', 'loss/train': '0.63449', 'examples_per_second': '5.4022', 'grad_norm': '16.5', 'counters/examples': 104128, 'counters/updates': 6508}
skipping logging after 104144 examples to avoid logging too frequently
skipping logging after 104160 examples to avoid logging too frequently
Running evaluation after 104160 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:13,  2.36s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:05,  2.17s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:55,  1.92s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.89s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.54s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.65s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 104160: {'rewards_eval/chosen': '-0.53365', 'rewards_eval/rejected': '-0.64482', 'rewards_eval/accuracies': '0.54883', 'rewards_eval/margins': '0.11122', 'logps_eval/rejected': '-128.6', 'logps_eval/chosen': '-123.83', 'loss/eval': '0.67128'}
skipping logging after 104176 examples to avoid logging too frequently
train stats after 104192 examples: {'rewards_train/chosen': '-0.55574', 'rewards_train/rejected': '-0.77249', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.21668', 'logps_train/rejected': '-128.58', 'logps_train/chosen': '-131.74', 'loss/train': '0.61792', 'examples_per_second': '4.9763', 'grad_norm': '17.625', 'counters/examples': 104192, 'counters/updates': 6512}
skipping logging after 104208 examples to avoid logging too frequently
skipping logging after 104224 examples to avoid logging too frequently
skipping logging after 104240 examples to avoid logging too frequently
train stats after 104256 examples: {'rewards_train/chosen': '-0.65321', 'rewards_train/rejected': '-0.65792', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.0046692', 'logps_train/rejected': '-130.98', 'logps_train/chosen': '-118.09', 'loss/train': '0.7224', 'examples_per_second': '5.3283', 'grad_norm': '24.25', 'counters/examples': 104256, 'counters/updates': 6516}
skipping logging after 104272 examples to avoid logging too frequently
skipping logging after 104288 examples to avoid logging too frequently
skipping logging after 104304 examples to avoid logging too frequently
train stats after 104320 examples: {'rewards_train/chosen': '-0.42163', 'rewards_train/rejected': '-0.54438', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.12266', 'logps_train/rejected': '-123.77', 'logps_train/chosen': '-114.55', 'loss/train': '0.66739', 'examples_per_second': '5.0569', 'grad_norm': '19', 'counters/examples': 104320, 'counters/updates': 6520}
skipping logging after 104336 examples to avoid logging too frequently
skipping logging after 104352 examples to avoid logging too frequently
skipping logging after 104368 examples to avoid logging too frequently
train stats after 104384 examples: {'rewards_train/chosen': '-0.4707', 'rewards_train/rejected': '-0.62777', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.15717', 'logps_train/rejected': '-117.8', 'logps_train/chosen': '-114.45', 'loss/train': '0.65424', 'examples_per_second': '5.6529', 'grad_norm': '16.25', 'counters/examples': 104384, 'counters/updates': 6524}
skipping logging after 104400 examples to avoid logging too frequently
skipping logging after 104416 examples to avoid logging too frequently
skipping logging after 104432 examples to avoid logging too frequently
train stats after 104448 examples: {'rewards_train/chosen': '-0.59169', 'rewards_train/rejected': '-0.71565', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.12393', 'logps_train/rejected': '-107.13', 'logps_train/chosen': '-116.65', 'loss/train': '0.65964', 'examples_per_second': '5.4406', 'grad_norm': '19.375', 'counters/examples': 104448, 'counters/updates': 6528}
skipping logging after 104464 examples to avoid logging too frequently
skipping logging after 104480 examples to avoid logging too frequently
skipping logging after 104496 examples to avoid logging too frequently
train stats after 104512 examples: {'rewards_train/chosen': '-0.56375', 'rewards_train/rejected': '-0.52886', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '-0.034992', 'logps_train/rejected': '-110.01', 'logps_train/chosen': '-113.92', 'loss/train': '0.73508', 'examples_per_second': '4.9108', 'grad_norm': '19.625', 'counters/examples': 104512, 'counters/updates': 6532}
skipping logging after 104528 examples to avoid logging too frequently
skipping logging after 104544 examples to avoid logging too frequently
skipping logging after 104560 examples to avoid logging too frequently
train stats after 104576 examples: {'rewards_train/chosen': '-0.5112', 'rewards_train/rejected': '-0.67607', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.16493', 'logps_train/rejected': '-113.25', 'logps_train/chosen': '-104.73', 'loss/train': '0.64232', 'examples_per_second': '5.4583', 'grad_norm': '19.75', 'counters/examples': 104576, 'counters/updates': 6536}
skipping logging after 104592 examples to avoid logging too frequently
skipping logging after 104608 examples to avoid logging too frequently
skipping logging after 104624 examples to avoid logging too frequently
train stats after 104640 examples: {'rewards_train/chosen': '-0.53522', 'rewards_train/rejected': '-0.68955', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.15441', 'logps_train/rejected': '-122.78', 'logps_train/chosen': '-159.67', 'loss/train': '0.65474', 'examples_per_second': '5.6624', 'grad_norm': '20.625', 'counters/examples': 104640, 'counters/updates': 6540}
skipping logging after 104656 examples to avoid logging too frequently
skipping logging after 104672 examples to avoid logging too frequently
skipping logging after 104688 examples to avoid logging too frequently
train stats after 104704 examples: {'rewards_train/chosen': '-0.55726', 'rewards_train/rejected': '-0.63084', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.073711', 'logps_train/rejected': '-132.55', 'logps_train/chosen': '-137.74', 'loss/train': '0.69217', 'examples_per_second': '5.1147', 'grad_norm': '25.25', 'counters/examples': 104704, 'counters/updates': 6544}
skipping logging after 104720 examples to avoid logging too frequently
skipping logging after 104736 examples to avoid logging too frequently
skipping logging after 104752 examples to avoid logging too frequently
train stats after 104768 examples: {'rewards_train/chosen': '-0.45016', 'rewards_train/rejected': '-0.57913', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.12906', 'logps_train/rejected': '-128.18', 'logps_train/chosen': '-117.73', 'loss/train': '0.65494', 'examples_per_second': '4.943', 'grad_norm': '17.25', 'counters/examples': 104768, 'counters/updates': 6548}
skipping logging after 104784 examples to avoid logging too frequently
skipping logging after 104800 examples to avoid logging too frequently
skipping logging after 104816 examples to avoid logging too frequently
train stats after 104832 examples: {'rewards_train/chosen': '-0.50307', 'rewards_train/rejected': '-0.66074', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.15765', 'logps_train/rejected': '-128.04', 'logps_train/chosen': '-130.68', 'loss/train': '0.64555', 'examples_per_second': '5.2059', 'grad_norm': '19.25', 'counters/examples': 104832, 'counters/updates': 6552}
skipping logging after 104848 examples to avoid logging too frequently
skipping logging after 104864 examples to avoid logging too frequently
skipping logging after 104880 examples to avoid logging too frequently
train stats after 104896 examples: {'rewards_train/chosen': '-0.51178', 'rewards_train/rejected': '-0.71531', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.20338', 'logps_train/rejected': '-128.3', 'logps_train/chosen': '-119.97', 'loss/train': '0.61778', 'examples_per_second': '5.0958', 'grad_norm': '20.25', 'counters/examples': 104896, 'counters/updates': 6556}
skipping logging after 104912 examples to avoid logging too frequently
skipping logging after 104928 examples to avoid logging too frequently
skipping logging after 104944 examples to avoid logging too frequently
train stats after 104960 examples: {'rewards_train/chosen': '-0.63889', 'rewards_train/rejected': '-0.78511', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.14635', 'logps_train/rejected': '-103.97', 'logps_train/chosen': '-119.22', 'loss/train': '0.64998', 'examples_per_second': '5.5557', 'grad_norm': '20.375', 'counters/examples': 104960, 'counters/updates': 6560}
skipping logging after 104976 examples to avoid logging too frequently
skipping logging after 104992 examples to avoid logging too frequently
skipping logging after 105008 examples to avoid logging too frequently
train stats after 105024 examples: {'rewards_train/chosen': '-0.58732', 'rewards_train/rejected': '-0.59531', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.0081367', 'logps_train/rejected': '-163.28', 'logps_train/chosen': '-138.71', 'loss/train': '0.70892', 'examples_per_second': '4.4528', 'grad_norm': '20.125', 'counters/examples': 105024, 'counters/updates': 6564}
skipping logging after 105040 examples to avoid logging too frequently
skipping logging after 105056 examples to avoid logging too frequently
skipping logging after 105072 examples to avoid logging too frequently
train stats after 105088 examples: {'rewards_train/chosen': '-0.46245', 'rewards_train/rejected': '-0.64706', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.18447', 'logps_train/rejected': '-121.22', 'logps_train/chosen': '-107.02', 'loss/train': '0.62796', 'examples_per_second': '5.5092', 'grad_norm': '19.625', 'counters/examples': 105088, 'counters/updates': 6568}
skipping logging after 105104 examples to avoid logging too frequently
skipping logging after 105120 examples to avoid logging too frequently
skipping logging after 105136 examples to avoid logging too frequently
train stats after 105152 examples: {'rewards_train/chosen': '-0.53559', 'rewards_train/rejected': '-0.69655', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.16096', 'logps_train/rejected': '-129.72', 'logps_train/chosen': '-140.92', 'loss/train': '0.65469', 'examples_per_second': '4.1958', 'grad_norm': '23.75', 'counters/examples': 105152, 'counters/updates': 6572}
Running evaluation after 105152 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.53s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.46s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.53s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.25s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 105152: {'rewards_eval/chosen': '-0.5692', 'rewards_eval/rejected': '-0.67421', 'rewards_eval/accuracies': '0.54102', 'rewards_eval/margins': '0.10502', 'logps_eval/rejected': '-128.9', 'logps_eval/chosen': '-124.19', 'loss/eval': '0.6695'}
skipping logging after 105168 examples to avoid logging too frequently
skipping logging after 105184 examples to avoid logging too frequently
skipping logging after 105200 examples to avoid logging too frequently
train stats after 105216 examples: {'rewards_train/chosen': '-0.52366', 'rewards_train/rejected': '-0.62432', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.10063', 'logps_train/rejected': '-120.9', 'logps_train/chosen': '-116.01', 'loss/train': '0.66193', 'examples_per_second': '4.3888', 'grad_norm': '17.875', 'counters/examples': 105216, 'counters/updates': 6576}
skipping logging after 105232 examples to avoid logging too frequently
skipping logging after 105248 examples to avoid logging too frequently
skipping logging after 105264 examples to avoid logging too frequently
train stats after 105280 examples: {'rewards_train/chosen': '-0.5745', 'rewards_train/rejected': '-0.61983', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.045288', 'logps_train/rejected': '-118.38', 'logps_train/chosen': '-140.64', 'loss/train': '0.70285', 'examples_per_second': '5.4715', 'grad_norm': '21.5', 'counters/examples': 105280, 'counters/updates': 6580}
skipping logging after 105296 examples to avoid logging too frequently
skipping logging after 105312 examples to avoid logging too frequently
skipping logging after 105328 examples to avoid logging too frequently
train stats after 105344 examples: {'rewards_train/chosen': '-0.5753', 'rewards_train/rejected': '-0.64175', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.066437', 'logps_train/rejected': '-105.49', 'logps_train/chosen': '-127.06', 'loss/train': '0.68085', 'examples_per_second': '4.5484', 'grad_norm': '19.5', 'counters/examples': 105344, 'counters/updates': 6584}
skipping logging after 105360 examples to avoid logging too frequently
skipping logging after 105376 examples to avoid logging too frequently
skipping logging after 105392 examples to avoid logging too frequently
train stats after 105408 examples: {'rewards_train/chosen': '-0.54744', 'rewards_train/rejected': '-0.57709', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.029579', 'logps_train/rejected': '-105.58', 'logps_train/chosen': '-123.28', 'loss/train': '0.694', 'examples_per_second': '4.4744', 'grad_norm': '19', 'counters/examples': 105408, 'counters/updates': 6588}
skipping logging after 105424 examples to avoid logging too frequently
skipping logging after 105440 examples to avoid logging too frequently
skipping logging after 105456 examples to avoid logging too frequently
train stats after 105472 examples: {'rewards_train/chosen': '-0.49297', 'rewards_train/rejected': '-0.56786', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.074913', 'logps_train/rejected': '-131.82', 'logps_train/chosen': '-143.17', 'loss/train': '0.67899', 'examples_per_second': '5.8642', 'grad_norm': '17.75', 'counters/examples': 105472, 'counters/updates': 6592}
skipping logging after 105488 examples to avoid logging too frequently
skipping logging after 105504 examples to avoid logging too frequently
skipping logging after 105520 examples to avoid logging too frequently
train stats after 105536 examples: {'rewards_train/chosen': '-0.45371', 'rewards_train/rejected': '-0.5724', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.11855', 'logps_train/rejected': '-123.9', 'logps_train/chosen': '-112.02', 'loss/train': '0.64954', 'examples_per_second': '5.2916', 'grad_norm': '19.875', 'counters/examples': 105536, 'counters/updates': 6596}
skipping logging after 105552 examples to avoid logging too frequently
skipping logging after 105568 examples to avoid logging too frequently
skipping logging after 105584 examples to avoid logging too frequently
train stats after 105600 examples: {'rewards_train/chosen': '-0.48186', 'rewards_train/rejected': '-0.62939', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.14752', 'logps_train/rejected': '-112.5', 'logps_train/chosen': '-126.72', 'loss/train': '0.64363', 'examples_per_second': '5.1974', 'grad_norm': '18.375', 'counters/examples': 105600, 'counters/updates': 6600}
skipping logging after 105616 examples to avoid logging too frequently
skipping logging after 105632 examples to avoid logging too frequently
skipping logging after 105648 examples to avoid logging too frequently
train stats after 105664 examples: {'rewards_train/chosen': '-0.53123', 'rewards_train/rejected': '-0.66964', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.13836', 'logps_train/rejected': '-140.18', 'logps_train/chosen': '-146.03', 'loss/train': '0.65518', 'examples_per_second': '4.8281', 'grad_norm': '20.375', 'counters/examples': 105664, 'counters/updates': 6604}
skipping logging after 105680 examples to avoid logging too frequently
skipping logging after 105696 examples to avoid logging too frequently
skipping logging after 105712 examples to avoid logging too frequently
train stats after 105728 examples: {'rewards_train/chosen': '-0.50176', 'rewards_train/rejected': '-0.64145', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.13972', 'logps_train/rejected': '-95.689', 'logps_train/chosen': '-118.23', 'loss/train': '0.65936', 'examples_per_second': '5.4748', 'grad_norm': '16', 'counters/examples': 105728, 'counters/updates': 6608}
skipping logging after 105744 examples to avoid logging too frequently
skipping logging after 105760 examples to avoid logging too frequently
skipping logging after 105776 examples to avoid logging too frequently
train stats after 105792 examples: {'rewards_train/chosen': '-0.44782', 'rewards_train/rejected': '-0.48966', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.041827', 'logps_train/rejected': '-109.47', 'logps_train/chosen': '-116.35', 'loss/train': '0.69296', 'examples_per_second': '5.5624', 'grad_norm': '22.875', 'counters/examples': 105792, 'counters/updates': 6612}
skipping logging after 105808 examples to avoid logging too frequently
skipping logging after 105824 examples to avoid logging too frequently
skipping logging after 105840 examples to avoid logging too frequently
train stats after 105856 examples: {'rewards_train/chosen': '-0.47797', 'rewards_train/rejected': '-0.59579', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.11781', 'logps_train/rejected': '-116', 'logps_train/chosen': '-115.53', 'loss/train': '0.65762', 'examples_per_second': '4.8166', 'grad_norm': '19.25', 'counters/examples': 105856, 'counters/updates': 6616}
skipping logging after 105872 examples to avoid logging too frequently
skipping logging after 105888 examples to avoid logging too frequently
skipping logging after 105904 examples to avoid logging too frequently
train stats after 105920 examples: {'rewards_train/chosen': '-0.43887', 'rewards_train/rejected': '-0.57379', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.13485', 'logps_train/rejected': '-126.25', 'logps_train/chosen': '-133.39', 'loss/train': '0.65646', 'examples_per_second': '4.8402', 'grad_norm': '19.375', 'counters/examples': 105920, 'counters/updates': 6620}
skipping logging after 105936 examples to avoid logging too frequently
skipping logging after 105952 examples to avoid logging too frequently
skipping logging after 105968 examples to avoid logging too frequently
train stats after 105984 examples: {'rewards_train/chosen': '-0.44593', 'rewards_train/rejected': '-0.54404', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.09811', 'logps_train/rejected': '-116.72', 'logps_train/chosen': '-117.09', 'loss/train': '0.66507', 'examples_per_second': '4.4572', 'grad_norm': '19.125', 'counters/examples': 105984, 'counters/updates': 6624}
skipping logging after 106000 examples to avoid logging too frequently
skipping logging after 106016 examples to avoid logging too frequently
skipping logging after 106032 examples to avoid logging too frequently
train stats after 106048 examples: {'rewards_train/chosen': '-0.38568', 'rewards_train/rejected': '-0.52511', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.13948', 'logps_train/rejected': '-103.97', 'logps_train/chosen': '-118.02', 'loss/train': '0.64157', 'examples_per_second': '5.1166', 'grad_norm': '17.875', 'counters/examples': 106048, 'counters/updates': 6628}
skipping logging after 106064 examples to avoid logging too frequently
skipping logging after 106080 examples to avoid logging too frequently
skipping logging after 106096 examples to avoid logging too frequently
train stats after 106112 examples: {'rewards_train/chosen': '-0.47165', 'rewards_train/rejected': '-0.48057', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.0088997', 'logps_train/rejected': '-111.44', 'logps_train/chosen': '-132.6', 'loss/train': '0.70398', 'examples_per_second': '5.0134', 'grad_norm': '17.375', 'counters/examples': 106112, 'counters/updates': 6632}
skipping logging after 106128 examples to avoid logging too frequently
skipping logging after 106144 examples to avoid logging too frequently
Running evaluation after 106144 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:14,  2.39s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:05,  2.19s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:55,  1.93s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.90s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.55s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.65s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 106144: {'rewards_eval/chosen': '-0.44159', 'rewards_eval/rejected': '-0.55084', 'rewards_eval/accuracies': '0.56836', 'rewards_eval/margins': '0.10929', 'logps_eval/rejected': '-127.66', 'logps_eval/chosen': '-122.91', 'loss/eval': '0.66678'}
skipping logging after 106160 examples to avoid logging too frequently
train stats after 106176 examples: {'rewards_train/chosen': '-0.43151', 'rewards_train/rejected': '-0.55552', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.12393', 'logps_train/rejected': '-122.66', 'logps_train/chosen': '-107.89', 'loss/train': '0.65155', 'examples_per_second': '4.965', 'grad_norm': '20.125', 'counters/examples': 106176, 'counters/updates': 6636}
skipping logging after 106192 examples to avoid logging too frequently
skipping logging after 106208 examples to avoid logging too frequently
skipping logging after 106224 examples to avoid logging too frequently
train stats after 106240 examples: {'rewards_train/chosen': '-0.47123', 'rewards_train/rejected': '-0.64114', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.16989', 'logps_train/rejected': '-131.78', 'logps_train/chosen': '-117.39', 'loss/train': '0.63586', 'examples_per_second': '4.4412', 'grad_norm': '18.25', 'counters/examples': 106240, 'counters/updates': 6640}
skipping logging after 106256 examples to avoid logging too frequently
skipping logging after 106272 examples to avoid logging too frequently
skipping logging after 106288 examples to avoid logging too frequently
train stats after 106304 examples: {'rewards_train/chosen': '-0.45246', 'rewards_train/rejected': '-0.60154', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.14903', 'logps_train/rejected': '-112.39', 'logps_train/chosen': '-95.547', 'loss/train': '0.64139', 'examples_per_second': '5.6738', 'grad_norm': '16.75', 'counters/examples': 106304, 'counters/updates': 6644}
skipping logging after 106320 examples to avoid logging too frequently
skipping logging after 106336 examples to avoid logging too frequently
skipping logging after 106352 examples to avoid logging too frequently
train stats after 106368 examples: {'rewards_train/chosen': '-0.39284', 'rewards_train/rejected': '-0.56196', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.16904', 'logps_train/rejected': '-124.78', 'logps_train/chosen': '-110.6', 'loss/train': '0.63422', 'examples_per_second': '4.2696', 'grad_norm': '16.5', 'counters/examples': 106368, 'counters/updates': 6648}
skipping logging after 106384 examples to avoid logging too frequently
skipping logging after 106400 examples to avoid logging too frequently
skipping logging after 106416 examples to avoid logging too frequently
train stats after 106432 examples: {'rewards_train/chosen': '-0.45016', 'rewards_train/rejected': '-0.62071', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.17045', 'logps_train/rejected': '-136.6', 'logps_train/chosen': '-100.33', 'loss/train': '0.63036', 'examples_per_second': '5.5568', 'grad_norm': '16.625', 'counters/examples': 106432, 'counters/updates': 6652}
skipping logging after 106448 examples to avoid logging too frequently
skipping logging after 106464 examples to avoid logging too frequently
skipping logging after 106480 examples to avoid logging too frequently
train stats after 106496 examples: {'rewards_train/chosen': '-0.47781', 'rewards_train/rejected': '-0.51921', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.041637', 'logps_train/rejected': '-113.26', 'logps_train/chosen': '-129.1', 'loss/train': '0.69478', 'examples_per_second': '4.6627', 'grad_norm': '20.25', 'counters/examples': 106496, 'counters/updates': 6656}
skipping logging after 106512 examples to avoid logging too frequently
skipping logging after 106528 examples to avoid logging too frequently
skipping logging after 106544 examples to avoid logging too frequently
train stats after 106560 examples: {'rewards_train/chosen': '-0.56091', 'rewards_train/rejected': '-0.65625', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.095234', 'logps_train/rejected': '-126.22', 'logps_train/chosen': '-102.56', 'loss/train': '0.6657', 'examples_per_second': '5.4945', 'grad_norm': '19.125', 'counters/examples': 106560, 'counters/updates': 6660}
skipping logging after 106576 examples to avoid logging too frequently
skipping logging after 106592 examples to avoid logging too frequently
skipping logging after 106608 examples to avoid logging too frequently
train stats after 106624 examples: {'rewards_train/chosen': '-0.51146', 'rewards_train/rejected': '-0.60076', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.089138', 'logps_train/rejected': '-120.46', 'logps_train/chosen': '-100.86', 'loss/train': '0.67014', 'examples_per_second': '5.4952', 'grad_norm': '16.625', 'counters/examples': 106624, 'counters/updates': 6664}
skipping logging after 106640 examples to avoid logging too frequently
skipping logging after 106656 examples to avoid logging too frequently
skipping logging after 106672 examples to avoid logging too frequently
train stats after 106688 examples: {'rewards_train/chosen': '-0.45015', 'rewards_train/rejected': '-0.66209', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.212', 'logps_train/rejected': '-119.24', 'logps_train/chosen': '-161.61', 'loss/train': '0.62114', 'examples_per_second': '5.2221', 'grad_norm': '21.125', 'counters/examples': 106688, 'counters/updates': 6668}
skipping logging after 106704 examples to avoid logging too frequently
skipping logging after 106720 examples to avoid logging too frequently
skipping logging after 106736 examples to avoid logging too frequently
train stats after 106752 examples: {'rewards_train/chosen': '-0.49972', 'rewards_train/rejected': '-0.6371', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.13738', 'logps_train/rejected': '-118.44', 'logps_train/chosen': '-120.06', 'loss/train': '0.66188', 'examples_per_second': '6.1854', 'grad_norm': '21.625', 'counters/examples': 106752, 'counters/updates': 6672}
skipping logging after 106768 examples to avoid logging too frequently
skipping logging after 106784 examples to avoid logging too frequently
skipping logging after 106800 examples to avoid logging too frequently
train stats after 106816 examples: {'rewards_train/chosen': '-0.5405', 'rewards_train/rejected': '-0.73136', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.19099', 'logps_train/rejected': '-115.31', 'logps_train/chosen': '-111.8', 'loss/train': '0.62421', 'examples_per_second': '5.132', 'grad_norm': '16.125', 'counters/examples': 106816, 'counters/updates': 6676}
skipping logging after 106832 examples to avoid logging too frequently
skipping logging after 106848 examples to avoid logging too frequently
skipping logging after 106864 examples to avoid logging too frequently
train stats after 106880 examples: {'rewards_train/chosen': '-0.56506', 'rewards_train/rejected': '-0.72996', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.16485', 'logps_train/rejected': '-154.37', 'logps_train/chosen': '-110.43', 'loss/train': '0.6553', 'examples_per_second': '4.9533', 'grad_norm': '21.625', 'counters/examples': 106880, 'counters/updates': 6680}
skipping logging after 106896 examples to avoid logging too frequently
skipping logging after 106912 examples to avoid logging too frequently
skipping logging after 106928 examples to avoid logging too frequently
train stats after 106944 examples: {'rewards_train/chosen': '-0.53051', 'rewards_train/rejected': '-0.70245', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.17199', 'logps_train/rejected': '-118.32', 'logps_train/chosen': '-139.42', 'loss/train': '0.6472', 'examples_per_second': '5.1564', 'grad_norm': '21.875', 'counters/examples': 106944, 'counters/updates': 6684}
skipping logging after 106960 examples to avoid logging too frequently
skipping logging after 106976 examples to avoid logging too frequently
skipping logging after 106992 examples to avoid logging too frequently
train stats after 107008 examples: {'rewards_train/chosen': '-0.73859', 'rewards_train/rejected': '-0.86464', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.12605', 'logps_train/rejected': '-140.35', 'logps_train/chosen': '-112.23', 'loss/train': '0.66019', 'examples_per_second': '5.5258', 'grad_norm': '18.375', 'counters/examples': 107008, 'counters/updates': 6688}
skipping logging after 107024 examples to avoid logging too frequently
skipping logging after 107040 examples to avoid logging too frequently
skipping logging after 107056 examples to avoid logging too frequently
train stats after 107072 examples: {'rewards_train/chosen': '-0.72259', 'rewards_train/rejected': '-0.84423', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.12164', 'logps_train/rejected': '-96.491', 'logps_train/chosen': '-124.59', 'loss/train': '0.67108', 'examples_per_second': '5.6315', 'grad_norm': '24.25', 'counters/examples': 107072, 'counters/updates': 6692}
skipping logging after 107088 examples to avoid logging too frequently
skipping logging after 107104 examples to avoid logging too frequently
skipping logging after 107120 examples to avoid logging too frequently
train stats after 107136 examples: {'rewards_train/chosen': '-0.70899', 'rewards_train/rejected': '-0.85803', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.14897', 'logps_train/rejected': '-141.48', 'logps_train/chosen': '-124.4', 'loss/train': '0.651', 'examples_per_second': '4.4721', 'grad_norm': '20.25', 'counters/examples': 107136, 'counters/updates': 6696}
Running evaluation after 107136 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 107136: {'rewards_eval/chosen': '-0.61395', 'rewards_eval/rejected': '-0.73169', 'rewards_eval/accuracies': '0.55664', 'rewards_eval/margins': '0.11769', 'logps_eval/rejected': '-129.47', 'logps_eval/chosen': '-124.63', 'loss/eval': '0.66892'}
skipping logging after 107152 examples to avoid logging too frequently
skipping logging after 107168 examples to avoid logging too frequently
skipping logging after 107184 examples to avoid logging too frequently
train stats after 107200 examples: {'rewards_train/chosen': '-0.54093', 'rewards_train/rejected': '-0.69586', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.15503', 'logps_train/rejected': '-119.26', 'logps_train/chosen': '-126.94', 'loss/train': '0.66018', 'examples_per_second': '4.8519', 'grad_norm': '18.625', 'counters/examples': 107200, 'counters/updates': 6700}
skipping logging after 107216 examples to avoid logging too frequently
skipping logging after 107232 examples to avoid logging too frequently
skipping logging after 107248 examples to avoid logging too frequently
train stats after 107264 examples: {'rewards_train/chosen': '-0.58473', 'rewards_train/rejected': '-0.82514', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.24044', 'logps_train/rejected': '-127.53', 'logps_train/chosen': '-112.71', 'loss/train': '0.61359', 'examples_per_second': '5.9', 'grad_norm': '16', 'counters/examples': 107264, 'counters/updates': 6704}
skipping logging after 107280 examples to avoid logging too frequently
skipping logging after 107296 examples to avoid logging too frequently
skipping logging after 107312 examples to avoid logging too frequently
train stats after 107328 examples: {'rewards_train/chosen': '-0.58686', 'rewards_train/rejected': '-0.75526', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.16854', 'logps_train/rejected': '-140.57', 'logps_train/chosen': '-112.9', 'loss/train': '0.63737', 'examples_per_second': '4.6257', 'grad_norm': '21.25', 'counters/examples': 107328, 'counters/updates': 6708}
skipping logging after 107344 examples to avoid logging too frequently
skipping logging after 107360 examples to avoid logging too frequently
skipping logging after 107376 examples to avoid logging too frequently
train stats after 107392 examples: {'rewards_train/chosen': '-0.52863', 'rewards_train/rejected': '-0.66642', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.13779', 'logps_train/rejected': '-108.52', 'logps_train/chosen': '-117.13', 'loss/train': '0.65434', 'examples_per_second': '4.5146', 'grad_norm': '16.125', 'counters/examples': 107392, 'counters/updates': 6712}
skipping logging after 107408 examples to avoid logging too frequently
skipping logging after 107424 examples to avoid logging too frequently
skipping logging after 107440 examples to avoid logging too frequently
train stats after 107456 examples: {'rewards_train/chosen': '-0.64801', 'rewards_train/rejected': '-0.82267', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.17475', 'logps_train/rejected': '-136.87', 'logps_train/chosen': '-138.25', 'loss/train': '0.63107', 'examples_per_second': '4.5678', 'grad_norm': '21.875', 'counters/examples': 107456, 'counters/updates': 6716}
skipping logging after 107472 examples to avoid logging too frequently
skipping logging after 107488 examples to avoid logging too frequently
skipping logging after 107504 examples to avoid logging too frequently
train stats after 107520 examples: {'rewards_train/chosen': '-0.55994', 'rewards_train/rejected': '-0.73215', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.17236', 'logps_train/rejected': '-128.28', 'logps_train/chosen': '-130.56', 'loss/train': '0.63718', 'examples_per_second': '5.5561', 'grad_norm': '18.875', 'counters/examples': 107520, 'counters/updates': 6720}
skipping logging after 107536 examples to avoid logging too frequently
skipping logging after 107552 examples to avoid logging too frequently
skipping logging after 107568 examples to avoid logging too frequently
train stats after 107584 examples: {'rewards_train/chosen': '-0.40818', 'rewards_train/rejected': '-0.62033', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.21215', 'logps_train/rejected': '-125.02', 'logps_train/chosen': '-125.15', 'loss/train': '0.62384', 'examples_per_second': '5.7115', 'grad_norm': '17.75', 'counters/examples': 107584, 'counters/updates': 6724}
skipping logging after 107600 examples to avoid logging too frequently
skipping logging after 107616 examples to avoid logging too frequently
skipping logging after 107632 examples to avoid logging too frequently
train stats after 107648 examples: {'rewards_train/chosen': '-0.50793', 'rewards_train/rejected': '-0.72084', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.21287', 'logps_train/rejected': '-123.52', 'logps_train/chosen': '-125.86', 'loss/train': '0.61533', 'examples_per_second': '4.617', 'grad_norm': '18.5', 'counters/examples': 107648, 'counters/updates': 6728}
skipping logging after 107664 examples to avoid logging too frequently
skipping logging after 107680 examples to avoid logging too frequently
skipping logging after 107696 examples to avoid logging too frequently
train stats after 107712 examples: {'rewards_train/chosen': '-0.66242', 'rewards_train/rejected': '-0.69114', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.028767', 'logps_train/rejected': '-120.7', 'logps_train/chosen': '-147.69', 'loss/train': '0.70355', 'examples_per_second': '5.0546', 'grad_norm': '21.125', 'counters/examples': 107712, 'counters/updates': 6732}
skipping logging after 107728 examples to avoid logging too frequently
skipping logging after 107744 examples to avoid logging too frequently
skipping logging after 107760 examples to avoid logging too frequently
train stats after 107776 examples: {'rewards_train/chosen': '-0.50724', 'rewards_train/rejected': '-0.68121', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.1739', 'logps_train/rejected': '-142.31', 'logps_train/chosen': '-136.64', 'loss/train': '0.62421', 'examples_per_second': '5.3131', 'grad_norm': '21.75', 'counters/examples': 107776, 'counters/updates': 6736}
skipping logging after 107792 examples to avoid logging too frequently
skipping logging after 107808 examples to avoid logging too frequently
skipping logging after 107824 examples to avoid logging too frequently
train stats after 107840 examples: {'rewards_train/chosen': '-0.55542', 'rewards_train/rejected': '-0.70504', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.14963', 'logps_train/rejected': '-128.87', 'logps_train/chosen': '-109.04', 'loss/train': '0.63812', 'examples_per_second': '5.0186', 'grad_norm': '15.875', 'counters/examples': 107840, 'counters/updates': 6740}
skipping logging after 107856 examples to avoid logging too frequently
skipping logging after 107872 examples to avoid logging too frequently
skipping logging after 107888 examples to avoid logging too frequently
train stats after 107904 examples: {'rewards_train/chosen': '-0.58711', 'rewards_train/rejected': '-0.64481', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.057747', 'logps_train/rejected': '-130.18', 'logps_train/chosen': '-121.12', 'loss/train': '0.69687', 'examples_per_second': '5.5417', 'grad_norm': '20.625', 'counters/examples': 107904, 'counters/updates': 6744}
skipping logging after 107920 examples to avoid logging too frequently
skipping logging after 107936 examples to avoid logging too frequently
skipping logging after 107952 examples to avoid logging too frequently
train stats after 107968 examples: {'rewards_train/chosen': '-0.45733', 'rewards_train/rejected': '-0.63876', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.18164', 'logps_train/rejected': '-134.34', 'logps_train/chosen': '-107.44', 'loss/train': '0.6363', 'examples_per_second': '5.6778', 'grad_norm': '16.75', 'counters/examples': 107968, 'counters/updates': 6748}
skipping logging after 107984 examples to avoid logging too frequently
skipping logging after 108000 examples to avoid logging too frequently
skipping logging after 108016 examples to avoid logging too frequently
train stats after 108032 examples: {'rewards_train/chosen': '-0.61479', 'rewards_train/rejected': '-0.74243', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.12767', 'logps_train/rejected': '-133.29', 'logps_train/chosen': '-120.62', 'loss/train': '0.67714', 'examples_per_second': '5.8442', 'grad_norm': '21.625', 'counters/examples': 108032, 'counters/updates': 6752}
skipping logging after 108048 examples to avoid logging too frequently
skipping logging after 108064 examples to avoid logging too frequently
skipping logging after 108080 examples to avoid logging too frequently
train stats after 108096 examples: {'rewards_train/chosen': '-0.496', 'rewards_train/rejected': '-0.70092', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.20489', 'logps_train/rejected': '-117.41', 'logps_train/chosen': '-121.52', 'loss/train': '0.62018', 'examples_per_second': '4.328', 'grad_norm': '17.75', 'counters/examples': 108096, 'counters/updates': 6756}
skipping logging after 108112 examples to avoid logging too frequently
skipping logging after 108128 examples to avoid logging too frequently
Running evaluation after 108128 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:11,  2.31s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:04,  2.15s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:55,  1.90s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.88s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.37s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 108128: {'rewards_eval/chosen': '-0.51771', 'rewards_eval/rejected': '-0.63998', 'rewards_eval/accuracies': '0.55859', 'rewards_eval/margins': '0.12228', 'logps_eval/rejected': '-128.55', 'logps_eval/chosen': '-123.67', 'loss/eval': '0.66754'}
skipping logging after 108144 examples to avoid logging too frequently
train stats after 108160 examples: {'rewards_train/chosen': '-0.45127', 'rewards_train/rejected': '-0.79771', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.34652', 'logps_train/rejected': '-162.92', 'logps_train/chosen': '-132.5', 'loss/train': '0.59171', 'examples_per_second': '4.9661', 'grad_norm': '19.625', 'counters/examples': 108160, 'counters/updates': 6760}
skipping logging after 108176 examples to avoid logging too frequently
skipping logging after 108192 examples to avoid logging too frequently
skipping logging after 108208 examples to avoid logging too frequently
train stats after 108224 examples: {'rewards_train/chosen': '-0.57584', 'rewards_train/rejected': '-0.69826', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.12237', 'logps_train/rejected': '-127.86', 'logps_train/chosen': '-132.26', 'loss/train': '0.66357', 'examples_per_second': '5.2235', 'grad_norm': '22.25', 'counters/examples': 108224, 'counters/updates': 6764}
skipping logging after 108240 examples to avoid logging too frequently
skipping logging after 108256 examples to avoid logging too frequently
skipping logging after 108272 examples to avoid logging too frequently
train stats after 108288 examples: {'rewards_train/chosen': '-0.47806', 'rewards_train/rejected': '-0.71924', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.24115', 'logps_train/rejected': '-141.36', 'logps_train/chosen': '-131.46', 'loss/train': '0.60373', 'examples_per_second': '4.9401', 'grad_norm': '19.25', 'counters/examples': 108288, 'counters/updates': 6768}
skipping logging after 108304 examples to avoid logging too frequently
skipping logging after 108320 examples to avoid logging too frequently
skipping logging after 108336 examples to avoid logging too frequently
train stats after 108352 examples: {'rewards_train/chosen': '-0.54077', 'rewards_train/rejected': '-0.64264', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.10163', 'logps_train/rejected': '-127.39', 'logps_train/chosen': '-122.95', 'loss/train': '0.6819', 'examples_per_second': '4.2671', 'grad_norm': '23.75', 'counters/examples': 108352, 'counters/updates': 6772}
skipping logging after 108368 examples to avoid logging too frequently
skipping logging after 108384 examples to avoid logging too frequently
skipping logging after 108400 examples to avoid logging too frequently
train stats after 108416 examples: {'rewards_train/chosen': '-0.63868', 'rewards_train/rejected': '-0.6884', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.049694', 'logps_train/rejected': '-129.14', 'logps_train/chosen': '-122.99', 'loss/train': '0.69376', 'examples_per_second': '4.9009', 'grad_norm': '18.5', 'counters/examples': 108416, 'counters/updates': 6776}
skipping logging after 108432 examples to avoid logging too frequently
skipping logging after 108448 examples to avoid logging too frequently
skipping logging after 108464 examples to avoid logging too frequently
train stats after 108480 examples: {'rewards_train/chosen': '-0.47439', 'rewards_train/rejected': '-0.72863', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.25412', 'logps_train/rejected': '-110.43', 'logps_train/chosen': '-132.46', 'loss/train': '0.60796', 'examples_per_second': '6.0983', 'grad_norm': '17.375', 'counters/examples': 108480, 'counters/updates': 6780}
skipping logging after 108496 examples to avoid logging too frequently
skipping logging after 108512 examples to avoid logging too frequently
skipping logging after 108528 examples to avoid logging too frequently
train stats after 108544 examples: {'rewards_train/chosen': '-0.49404', 'rewards_train/rejected': '-0.60072', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.10655', 'logps_train/rejected': '-146.91', 'logps_train/chosen': '-144.74', 'loss/train': '0.68277', 'examples_per_second': '3.9952', 'grad_norm': '18.5', 'counters/examples': 108544, 'counters/updates': 6784}
skipping logging after 108560 examples to avoid logging too frequently
skipping logging after 108576 examples to avoid logging too frequently
skipping logging after 108592 examples to avoid logging too frequently
train stats after 108608 examples: {'rewards_train/chosen': '-0.49013', 'rewards_train/rejected': '-0.67826', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.1884', 'logps_train/rejected': '-150.14', 'logps_train/chosen': '-132.88', 'loss/train': '0.63168', 'examples_per_second': '4.0682', 'grad_norm': '18.375', 'counters/examples': 108608, 'counters/updates': 6788}
skipping logging after 108624 examples to avoid logging too frequently
skipping logging after 108640 examples to avoid logging too frequently
skipping logging after 108656 examples to avoid logging too frequently
train stats after 108672 examples: {'rewards_train/chosen': '-0.45156', 'rewards_train/rejected': '-0.61952', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.16792', 'logps_train/rejected': '-128.58', 'logps_train/chosen': '-140.87', 'loss/train': '0.65147', 'examples_per_second': '5.1272', 'grad_norm': '24.875', 'counters/examples': 108672, 'counters/updates': 6792}
skipping logging after 108688 examples to avoid logging too frequently
skipping logging after 108704 examples to avoid logging too frequently
skipping logging after 108720 examples to avoid logging too frequently
train stats after 108736 examples: {'rewards_train/chosen': '-0.60935', 'rewards_train/rejected': '-0.68048', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.070972', 'logps_train/rejected': '-131.88', 'logps_train/chosen': '-138.85', 'loss/train': '0.69567', 'examples_per_second': '5.3197', 'grad_norm': '22.875', 'counters/examples': 108736, 'counters/updates': 6796}
skipping logging after 108752 examples to avoid logging too frequently
skipping logging after 108768 examples to avoid logging too frequently
skipping logging after 108784 examples to avoid logging too frequently
train stats after 108800 examples: {'rewards_train/chosen': '-0.52469', 'rewards_train/rejected': '-0.64278', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.11806', 'logps_train/rejected': '-98.593', 'logps_train/chosen': '-121.2', 'loss/train': '0.66199', 'examples_per_second': '6.3595', 'grad_norm': '22.5', 'counters/examples': 108800, 'counters/updates': 6800}
skipping logging after 108816 examples to avoid logging too frequently
skipping logging after 108832 examples to avoid logging too frequently
skipping logging after 108848 examples to avoid logging too frequently
train stats after 108864 examples: {'rewards_train/chosen': '-0.54393', 'rewards_train/rejected': '-0.6502', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.1063', 'logps_train/rejected': '-120.84', 'logps_train/chosen': '-112.84', 'loss/train': '0.66638', 'examples_per_second': '4.8046', 'grad_norm': '17.625', 'counters/examples': 108864, 'counters/updates': 6804}
skipping logging after 108880 examples to avoid logging too frequently
skipping logging after 108896 examples to avoid logging too frequently
skipping logging after 108912 examples to avoid logging too frequently
train stats after 108928 examples: {'rewards_train/chosen': '-0.50758', 'rewards_train/rejected': '-0.71238', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.20478', 'logps_train/rejected': '-129.33', 'logps_train/chosen': '-133.35', 'loss/train': '0.6152', 'examples_per_second': '4.1828', 'grad_norm': '19.125', 'counters/examples': 108928, 'counters/updates': 6808}
skipping logging after 108944 examples to avoid logging too frequently
skipping logging after 108960 examples to avoid logging too frequently
skipping logging after 108976 examples to avoid logging too frequently
train stats after 108992 examples: {'rewards_train/chosen': '-0.51067', 'rewards_train/rejected': '-0.66702', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.1563', 'logps_train/rejected': '-124.85', 'logps_train/chosen': '-120.88', 'loss/train': '0.64093', 'examples_per_second': '4.3782', 'grad_norm': '17.25', 'counters/examples': 108992, 'counters/updates': 6812}
skipping logging after 109008 examples to avoid logging too frequently
skipping logging after 109024 examples to avoid logging too frequently
skipping logging after 109040 examples to avoid logging too frequently
train stats after 109056 examples: {'rewards_train/chosen': '-0.51416', 'rewards_train/rejected': '-0.77331', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.25926', 'logps_train/rejected': '-140.75', 'logps_train/chosen': '-142.67', 'loss/train': '0.61591', 'examples_per_second': '4.4898', 'grad_norm': '17.25', 'counters/examples': 109056, 'counters/updates': 6816}
skipping logging after 109072 examples to avoid logging too frequently
skipping logging after 109088 examples to avoid logging too frequently
skipping logging after 109104 examples to avoid logging too frequently
train stats after 109120 examples: {'rewards_train/chosen': '-0.48047', 'rewards_train/rejected': '-0.59787', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.1173', 'logps_train/rejected': '-84.151', 'logps_train/chosen': '-108.85', 'loss/train': '0.66711', 'examples_per_second': '4.8939', 'grad_norm': '19.75', 'counters/examples': 109120, 'counters/updates': 6820}
Running evaluation after 109120 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.12s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 109120: {'rewards_eval/chosen': '-0.50241', 'rewards_eval/rejected': '-0.62379', 'rewards_eval/accuracies': '0.5625', 'rewards_eval/margins': '0.12135', 'logps_eval/rejected': '-128.39', 'logps_eval/chosen': '-123.52', 'loss/eval': '0.66804'}
skipping logging after 109136 examples to avoid logging too frequently
skipping logging after 109152 examples to avoid logging too frequently
skipping logging after 109168 examples to avoid logging too frequently
train stats after 109184 examples: {'rewards_train/chosen': '-0.57387', 'rewards_train/rejected': '-0.57956', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.0057259', 'logps_train/rejected': '-136.5', 'logps_train/chosen': '-131.03', 'loss/train': '0.72633', 'examples_per_second': '4.2996', 'grad_norm': '21.75', 'counters/examples': 109184, 'counters/updates': 6824}
skipping logging after 109200 examples to avoid logging too frequently
skipping logging after 109216 examples to avoid logging too frequently
skipping logging after 109232 examples to avoid logging too frequently
train stats after 109248 examples: {'rewards_train/chosen': '-0.60346', 'rewards_train/rejected': '-0.73687', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.13327', 'logps_train/rejected': '-102.83', 'logps_train/chosen': '-131.39', 'loss/train': '0.65807', 'examples_per_second': '5.7746', 'grad_norm': '18.125', 'counters/examples': 109248, 'counters/updates': 6828}
skipping logging after 109264 examples to avoid logging too frequently
skipping logging after 109280 examples to avoid logging too frequently
skipping logging after 109296 examples to avoid logging too frequently
train stats after 109312 examples: {'rewards_train/chosen': '-0.46794', 'rewards_train/rejected': '-0.58985', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.12183', 'logps_train/rejected': '-124.05', 'logps_train/chosen': '-114.8', 'loss/train': '0.66093', 'examples_per_second': '5.8829', 'grad_norm': '18.125', 'counters/examples': 109312, 'counters/updates': 6832}
skipping logging after 109328 examples to avoid logging too frequently
skipping logging after 109344 examples to avoid logging too frequently
skipping logging after 109360 examples to avoid logging too frequently
train stats after 109376 examples: {'rewards_train/chosen': '-0.47531', 'rewards_train/rejected': '-0.57718', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.10176', 'logps_train/rejected': '-167.15', 'logps_train/chosen': '-136.71', 'loss/train': '0.66785', 'examples_per_second': '4.3695', 'grad_norm': '21.25', 'counters/examples': 109376, 'counters/updates': 6836}
skipping logging after 109392 examples to avoid logging too frequently
skipping logging after 109408 examples to avoid logging too frequently
skipping logging after 109424 examples to avoid logging too frequently
train stats after 109440 examples: {'rewards_train/chosen': '-0.41084', 'rewards_train/rejected': '-0.65799', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.24693', 'logps_train/rejected': '-143.75', 'logps_train/chosen': '-112.84', 'loss/train': '0.59891', 'examples_per_second': '5.7228', 'grad_norm': '17.5', 'counters/examples': 109440, 'counters/updates': 6840}
skipping logging after 109456 examples to avoid logging too frequently
skipping logging after 109472 examples to avoid logging too frequently
skipping logging after 109488 examples to avoid logging too frequently
train stats after 109504 examples: {'rewards_train/chosen': '-0.4007', 'rewards_train/rejected': '-0.49509', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.094276', 'logps_train/rejected': '-111.03', 'logps_train/chosen': '-121.82', 'loss/train': '0.66946', 'examples_per_second': '5.4563', 'grad_norm': '20.75', 'counters/examples': 109504, 'counters/updates': 6844}
skipping logging after 109520 examples to avoid logging too frequently
skipping logging after 109536 examples to avoid logging too frequently
skipping logging after 109552 examples to avoid logging too frequently
train stats after 109568 examples: {'rewards_train/chosen': '-0.35361', 'rewards_train/rejected': '-0.45563', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.10208', 'logps_train/rejected': '-117.88', 'logps_train/chosen': '-122.39', 'loss/train': '0.67863', 'examples_per_second': '5.185', 'grad_norm': '24.875', 'counters/examples': 109568, 'counters/updates': 6848}
skipping logging after 109584 examples to avoid logging too frequently
skipping logging after 109600 examples to avoid logging too frequently
skipping logging after 109616 examples to avoid logging too frequently
train stats after 109632 examples: {'rewards_train/chosen': '-0.28661', 'rewards_train/rejected': '-0.45824', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.1717', 'logps_train/rejected': '-119.19', 'logps_train/chosen': '-129.81', 'loss/train': '0.62677', 'examples_per_second': '6.6057', 'grad_norm': '22.125', 'counters/examples': 109632, 'counters/updates': 6852}
skipping logging after 109648 examples to avoid logging too frequently
skipping logging after 109664 examples to avoid logging too frequently
skipping logging after 109680 examples to avoid logging too frequently
train stats after 109696 examples: {'rewards_train/chosen': '-0.31022', 'rewards_train/rejected': '-0.51571', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.20557', 'logps_train/rejected': '-134.52', 'logps_train/chosen': '-135.98', 'loss/train': '0.62376', 'examples_per_second': '5.2223', 'grad_norm': '19.375', 'counters/examples': 109696, 'counters/updates': 6856}
skipping logging after 109712 examples to avoid logging too frequently
skipping logging after 109728 examples to avoid logging too frequently
skipping logging after 109744 examples to avoid logging too frequently
train stats after 109760 examples: {'rewards_train/chosen': '-0.45398', 'rewards_train/rejected': '-0.47211', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.01811', 'logps_train/rejected': '-101.9', 'logps_train/chosen': '-113.07', 'loss/train': '0.70526', 'examples_per_second': '5.7322', 'grad_norm': '20.5', 'counters/examples': 109760, 'counters/updates': 6860}
skipping logging after 109776 examples to avoid logging too frequently
skipping logging after 109792 examples to avoid logging too frequently
skipping logging after 109808 examples to avoid logging too frequently
train stats after 109824 examples: {'rewards_train/chosen': '-0.44033', 'rewards_train/rejected': '-0.62339', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.18318', 'logps_train/rejected': '-121.44', 'logps_train/chosen': '-131.37', 'loss/train': '0.6328', 'examples_per_second': '7.2657', 'grad_norm': '19', 'counters/examples': 109824, 'counters/updates': 6864}
skipping logging after 109840 examples to avoid logging too frequently
skipping logging after 109856 examples to avoid logging too frequently
skipping logging after 109872 examples to avoid logging too frequently
train stats after 109888 examples: {'rewards_train/chosen': '-0.4703', 'rewards_train/rejected': '-0.5325', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.062279', 'logps_train/rejected': '-138.13', 'logps_train/chosen': '-167.32', 'loss/train': '0.69022', 'examples_per_second': '4.9436', 'grad_norm': '25.375', 'counters/examples': 109888, 'counters/updates': 6868}
skipping logging after 109904 examples to avoid logging too frequently
skipping logging after 109920 examples to avoid logging too frequently
skipping logging after 109936 examples to avoid logging too frequently
train stats after 109952 examples: {'rewards_train/chosen': '-0.54649', 'rewards_train/rejected': '-0.61353', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.067101', 'logps_train/rejected': '-105.15', 'logps_train/chosen': '-118.19', 'loss/train': '0.68375', 'examples_per_second': '6.054', 'grad_norm': '18.25', 'counters/examples': 109952, 'counters/updates': 6872}
skipping logging after 109968 examples to avoid logging too frequently
skipping logging after 109984 examples to avoid logging too frequently
skipping logging after 110000 examples to avoid logging too frequently
train stats after 110016 examples: {'rewards_train/chosen': '-0.48278', 'rewards_train/rejected': '-0.61932', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.13649', 'logps_train/rejected': '-160.42', 'logps_train/chosen': '-137.06', 'loss/train': '0.64798', 'examples_per_second': '5.0631', 'grad_norm': '20.25', 'counters/examples': 110016, 'counters/updates': 6876}
skipping logging after 110032 examples to avoid logging too frequently
skipping logging after 110048 examples to avoid logging too frequently
skipping logging after 110064 examples to avoid logging too frequently
train stats after 110080 examples: {'rewards_train/chosen': '-0.52262', 'rewards_train/rejected': '-0.73761', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.21487', 'logps_train/rejected': '-125.36', 'logps_train/chosen': '-106.59', 'loss/train': '0.62286', 'examples_per_second': '6.3321', 'grad_norm': '17.875', 'counters/examples': 110080, 'counters/updates': 6880}
skipping logging after 110096 examples to avoid logging too frequently
skipping logging after 110112 examples to avoid logging too frequently
Running evaluation after 110112 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:13,  2.38s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:05,  2.18s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:55,  1.92s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.89s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.54s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 110112: {'rewards_eval/chosen': '-0.56929', 'rewards_eval/rejected': '-0.69008', 'rewards_eval/accuracies': '0.55664', 'rewards_eval/margins': '0.12075', 'logps_eval/rejected': '-129.06', 'logps_eval/chosen': '-124.19', 'loss/eval': '0.66815'}
skipping logging after 110128 examples to avoid logging too frequently
train stats after 110144 examples: {'rewards_train/chosen': '-0.57563', 'rewards_train/rejected': '-0.77663', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.20083', 'logps_train/rejected': '-145.37', 'logps_train/chosen': '-135.97', 'loss/train': '0.62445', 'examples_per_second': '5.3889', 'grad_norm': '22.75', 'counters/examples': 110144, 'counters/updates': 6884}
skipping logging after 110160 examples to avoid logging too frequently
skipping logging after 110176 examples to avoid logging too frequently
skipping logging after 110192 examples to avoid logging too frequently
train stats after 110208 examples: {'rewards_train/chosen': '-0.51625', 'rewards_train/rejected': '-0.69546', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.17918', 'logps_train/rejected': '-115.98', 'logps_train/chosen': '-105.55', 'loss/train': '0.63631', 'examples_per_second': '5.0373', 'grad_norm': '17.5', 'counters/examples': 110208, 'counters/updates': 6888}
skipping logging after 110224 examples to avoid logging too frequently
skipping logging after 110240 examples to avoid logging too frequently
skipping logging after 110256 examples to avoid logging too frequently
train stats after 110272 examples: {'rewards_train/chosen': '-0.56506', 'rewards_train/rejected': '-0.7252', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.16027', 'logps_train/rejected': '-117.34', 'logps_train/chosen': '-120.15', 'loss/train': '0.66116', 'examples_per_second': '5.6682', 'grad_norm': '18', 'counters/examples': 110272, 'counters/updates': 6892}
skipping logging after 110288 examples to avoid logging too frequently
skipping logging after 110304 examples to avoid logging too frequently
skipping logging after 110320 examples to avoid logging too frequently
train stats after 110336 examples: {'rewards_train/chosen': '-0.48658', 'rewards_train/rejected': '-0.62928', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.14276', 'logps_train/rejected': '-120.25', 'logps_train/chosen': '-125.21', 'loss/train': '0.64603', 'examples_per_second': '4.3857', 'grad_norm': '19.5', 'counters/examples': 110336, 'counters/updates': 6896}
skipping logging after 110352 examples to avoid logging too frequently
skipping logging after 110368 examples to avoid logging too frequently
skipping logging after 110384 examples to avoid logging too frequently
train stats after 110400 examples: {'rewards_train/chosen': '-0.5383', 'rewards_train/rejected': '-0.6435', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.10515', 'logps_train/rejected': '-115.89', 'logps_train/chosen': '-104.16', 'loss/train': '0.66397', 'examples_per_second': '5.4921', 'grad_norm': '16.375', 'counters/examples': 110400, 'counters/updates': 6900}
skipping logging after 110416 examples to avoid logging too frequently
skipping logging after 110432 examples to avoid logging too frequently
skipping logging after 110448 examples to avoid logging too frequently
train stats after 110464 examples: {'rewards_train/chosen': '-0.59631', 'rewards_train/rejected': '-0.83492', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.2386', 'logps_train/rejected': '-130.09', 'logps_train/chosen': '-127.62', 'loss/train': '0.61115', 'examples_per_second': '6.0176', 'grad_norm': '20.375', 'counters/examples': 110464, 'counters/updates': 6904}
skipping logging after 110480 examples to avoid logging too frequently
skipping logging after 110496 examples to avoid logging too frequently
skipping logging after 110512 examples to avoid logging too frequently
train stats after 110528 examples: {'rewards_train/chosen': '-0.59808', 'rewards_train/rejected': '-0.65701', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.05883', 'logps_train/rejected': '-128.23', 'logps_train/chosen': '-116.23', 'loss/train': '0.69354', 'examples_per_second': '4.998', 'grad_norm': '21.125', 'counters/examples': 110528, 'counters/updates': 6908}
skipping logging after 110544 examples to avoid logging too frequently
skipping logging after 110560 examples to avoid logging too frequently
skipping logging after 110576 examples to avoid logging too frequently
train stats after 110592 examples: {'rewards_train/chosen': '-0.71489', 'rewards_train/rejected': '-0.84637', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.13145', 'logps_train/rejected': '-127.93', 'logps_train/chosen': '-116.85', 'loss/train': '0.66621', 'examples_per_second': '5.6141', 'grad_norm': '18.25', 'counters/examples': 110592, 'counters/updates': 6912}
skipping logging after 110608 examples to avoid logging too frequently
skipping logging after 110624 examples to avoid logging too frequently
skipping logging after 110640 examples to avoid logging too frequently
train stats after 110656 examples: {'rewards_train/chosen': '-0.64462', 'rewards_train/rejected': '-0.77548', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.13083', 'logps_train/rejected': '-123.49', 'logps_train/chosen': '-106.01', 'loss/train': '0.65749', 'examples_per_second': '5.4529', 'grad_norm': '19.125', 'counters/examples': 110656, 'counters/updates': 6916}
skipping logging after 110672 examples to avoid logging too frequently
skipping logging after 110688 examples to avoid logging too frequently
skipping logging after 110704 examples to avoid logging too frequently
train stats after 110720 examples: {'rewards_train/chosen': '-0.67783', 'rewards_train/rejected': '-0.81063', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.13276', 'logps_train/rejected': '-115.51', 'logps_train/chosen': '-125.67', 'loss/train': '0.66492', 'examples_per_second': '5.3748', 'grad_norm': '20.375', 'counters/examples': 110720, 'counters/updates': 6920}
skipping logging after 110736 examples to avoid logging too frequently
skipping logging after 110752 examples to avoid logging too frequently
skipping logging after 110768 examples to avoid logging too frequently
train stats after 110784 examples: {'rewards_train/chosen': '-0.60224', 'rewards_train/rejected': '-0.76324', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.16099', 'logps_train/rejected': '-116.81', 'logps_train/chosen': '-108.94', 'loss/train': '0.64235', 'examples_per_second': '5.5011', 'grad_norm': '17.875', 'counters/examples': 110784, 'counters/updates': 6924}
skipping logging after 110800 examples to avoid logging too frequently
skipping logging after 110816 examples to avoid logging too frequently
skipping logging after 110832 examples to avoid logging too frequently
train stats after 110848 examples: {'rewards_train/chosen': '-0.45023', 'rewards_train/rejected': '-0.65704', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.20692', 'logps_train/rejected': '-129.68', 'logps_train/chosen': '-155.82', 'loss/train': '0.63068', 'examples_per_second': '4.2869', 'grad_norm': '19.25', 'counters/examples': 110848, 'counters/updates': 6928}
skipping logging after 110864 examples to avoid logging too frequently
skipping logging after 110880 examples to avoid logging too frequently
skipping logging after 110896 examples to avoid logging too frequently
train stats after 110912 examples: {'rewards_train/chosen': '-0.65648', 'rewards_train/rejected': '-0.78726', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.13087', 'logps_train/rejected': '-136.35', 'logps_train/chosen': '-149.62', 'loss/train': '0.67139', 'examples_per_second': '4.8614', 'grad_norm': '21.5', 'counters/examples': 110912, 'counters/updates': 6932}
skipping logging after 110928 examples to avoid logging too frequently
skipping logging after 110944 examples to avoid logging too frequently
skipping logging after 110960 examples to avoid logging too frequently
train stats after 110976 examples: {'rewards_train/chosen': '-0.46155', 'rewards_train/rejected': '-0.72002', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.25857', 'logps_train/rejected': '-136.07', 'logps_train/chosen': '-117.28', 'loss/train': '0.60444', 'examples_per_second': '4.5567', 'grad_norm': '17.5', 'counters/examples': 110976, 'counters/updates': 6936}
skipping logging after 110992 examples to avoid logging too frequently
skipping logging after 111008 examples to avoid logging too frequently
skipping logging after 111024 examples to avoid logging too frequently
train stats after 111040 examples: {'rewards_train/chosen': '-0.59714', 'rewards_train/rejected': '-0.6245', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.027435', 'logps_train/rejected': '-122.79', 'logps_train/chosen': '-110.53', 'loss/train': '0.703', 'examples_per_second': '5.4365', 'grad_norm': '18.625', 'counters/examples': 111040, 'counters/updates': 6940}
skipping logging after 111056 examples to avoid logging too frequently
skipping logging after 111072 examples to avoid logging too frequently
skipping logging after 111088 examples to avoid logging too frequently
train stats after 111104 examples: {'rewards_train/chosen': '-0.56283', 'rewards_train/rejected': '-0.71694', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.15403', 'logps_train/rejected': '-122.26', 'logps_train/chosen': '-115.93', 'loss/train': '0.64722', 'examples_per_second': '5.5699', 'grad_norm': '19.375', 'counters/examples': 111104, 'counters/updates': 6944}
Running evaluation after 111104 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 111104: {'rewards_eval/chosen': '-0.54157', 'rewards_eval/rejected': '-0.67175', 'rewards_eval/accuracies': '0.56445', 'rewards_eval/margins': '0.13014', 'logps_eval/rejected': '-128.87', 'logps_eval/chosen': '-123.91', 'loss/eval': '0.66635'}
skipping logging after 111120 examples to avoid logging too frequently
skipping logging after 111136 examples to avoid logging too frequently
skipping logging after 111152 examples to avoid logging too frequently
train stats after 111168 examples: {'rewards_train/chosen': '-0.59387', 'rewards_train/rejected': '-0.74454', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.15069', 'logps_train/rejected': '-108.65', 'logps_train/chosen': '-100.07', 'loss/train': '0.64249', 'examples_per_second': '5.5427', 'grad_norm': '19', 'counters/examples': 111168, 'counters/updates': 6948}
skipping logging after 111184 examples to avoid logging too frequently
skipping logging after 111200 examples to avoid logging too frequently
skipping logging after 111216 examples to avoid logging too frequently
train stats after 111232 examples: {'rewards_train/chosen': '-0.6181', 'rewards_train/rejected': '-0.62478', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.006794', 'logps_train/rejected': '-131.21', 'logps_train/chosen': '-123.68', 'loss/train': '0.71666', 'examples_per_second': '5.0423', 'grad_norm': '21.375', 'counters/examples': 111232, 'counters/updates': 6952}
skipping logging after 111248 examples to avoid logging too frequently
skipping logging after 111264 examples to avoid logging too frequently
skipping logging after 111280 examples to avoid logging too frequently
train stats after 111296 examples: {'rewards_train/chosen': '-0.66019', 'rewards_train/rejected': '-0.71292', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.052797', 'logps_train/rejected': '-124.88', 'logps_train/chosen': '-138.56', 'loss/train': '0.70361', 'examples_per_second': '5.2879', 'grad_norm': '22.125', 'counters/examples': 111296, 'counters/updates': 6956}
skipping logging after 111312 examples to avoid logging too frequently
skipping logging after 111328 examples to avoid logging too frequently
skipping logging after 111344 examples to avoid logging too frequently
train stats after 111360 examples: {'rewards_train/chosen': '-0.43689', 'rewards_train/rejected': '-0.5484', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.11144', 'logps_train/rejected': '-110.48', 'logps_train/chosen': '-99.689', 'loss/train': '0.66197', 'examples_per_second': '5.8651', 'grad_norm': '16.75', 'counters/examples': 111360, 'counters/updates': 6960}
skipping logging after 111376 examples to avoid logging too frequently
skipping logging after 111392 examples to avoid logging too frequently
skipping logging after 111408 examples to avoid logging too frequently
train stats after 111424 examples: {'rewards_train/chosen': '-0.57759', 'rewards_train/rejected': '-0.72721', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.14961', 'logps_train/rejected': '-110.58', 'logps_train/chosen': '-127.14', 'loss/train': '0.6582', 'examples_per_second': '5.157', 'grad_norm': '17', 'counters/examples': 111424, 'counters/updates': 6964}
skipping logging after 111440 examples to avoid logging too frequently
skipping logging after 111456 examples to avoid logging too frequently
skipping logging after 111472 examples to avoid logging too frequently
train stats after 111488 examples: {'rewards_train/chosen': '-0.40445', 'rewards_train/rejected': '-0.57547', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.1711', 'logps_train/rejected': '-124.41', 'logps_train/chosen': '-136.61', 'loss/train': '0.63319', 'examples_per_second': '5.2741', 'grad_norm': '18.375', 'counters/examples': 111488, 'counters/updates': 6968}
skipping logging after 111504 examples to avoid logging too frequently
skipping logging after 111520 examples to avoid logging too frequently
skipping logging after 111536 examples to avoid logging too frequently
train stats after 111552 examples: {'rewards_train/chosen': '-0.65941', 'rewards_train/rejected': '-0.66687', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.007412', 'logps_train/rejected': '-114.87', 'logps_train/chosen': '-107.07', 'loss/train': '0.71072', 'examples_per_second': '5.3758', 'grad_norm': '19.5', 'counters/examples': 111552, 'counters/updates': 6972}
skipping logging after 111568 examples to avoid logging too frequently
skipping logging after 111584 examples to avoid logging too frequently
skipping logging after 111600 examples to avoid logging too frequently
train stats after 111616 examples: {'rewards_train/chosen': '-0.54767', 'rewards_train/rejected': '-0.72879', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.18104', 'logps_train/rejected': '-154.08', 'logps_train/chosen': '-140.25', 'loss/train': '0.63541', 'examples_per_second': '4.2096', 'grad_norm': '21.5', 'counters/examples': 111616, 'counters/updates': 6976}
skipping logging after 111632 examples to avoid logging too frequently
skipping logging after 111648 examples to avoid logging too frequently
skipping logging after 111664 examples to avoid logging too frequently
train stats after 111680 examples: {'rewards_train/chosen': '-0.59647', 'rewards_train/rejected': '-0.74646', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.15', 'logps_train/rejected': '-116.14', 'logps_train/chosen': '-118.46', 'loss/train': '0.64224', 'examples_per_second': '6.0295', 'grad_norm': '17.75', 'counters/examples': 111680, 'counters/updates': 6980}
skipping logging after 111696 examples to avoid logging too frequently
skipping logging after 111712 examples to avoid logging too frequently
skipping logging after 111728 examples to avoid logging too frequently
train stats after 111744 examples: {'rewards_train/chosen': '-0.53409', 'rewards_train/rejected': '-0.70158', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.16751', 'logps_train/rejected': '-115.19', 'logps_train/chosen': '-123.82', 'loss/train': '0.63876', 'examples_per_second': '4.6162', 'grad_norm': '17', 'counters/examples': 111744, 'counters/updates': 6984}
skipping logging after 111760 examples to avoid logging too frequently
skipping logging after 111776 examples to avoid logging too frequently
skipping logging after 111792 examples to avoid logging too frequently
train stats after 111808 examples: {'rewards_train/chosen': '-0.60019', 'rewards_train/rejected': '-0.76401', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.1639', 'logps_train/rejected': '-130.15', 'logps_train/chosen': '-126.17', 'loss/train': '0.64352', 'examples_per_second': '5.0034', 'grad_norm': '20.375', 'counters/examples': 111808, 'counters/updates': 6988}
skipping logging after 111824 examples to avoid logging too frequently
skipping logging after 111840 examples to avoid logging too frequently
skipping logging after 111856 examples to avoid logging too frequently
train stats after 111872 examples: {'rewards_train/chosen': '-0.68313', 'rewards_train/rejected': '-0.69226', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.0090332', 'logps_train/rejected': '-123.39', 'logps_train/chosen': '-116.35', 'loss/train': '0.72432', 'examples_per_second': '5.6514', 'grad_norm': '20.875', 'counters/examples': 111872, 'counters/updates': 6992}
skipping logging after 111888 examples to avoid logging too frequently
skipping logging after 111904 examples to avoid logging too frequently
skipping logging after 111920 examples to avoid logging too frequently
train stats after 111936 examples: {'rewards_train/chosen': '-0.67407', 'rewards_train/rejected': '-0.80149', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.12726', 'logps_train/rejected': '-122.21', 'logps_train/chosen': '-119.1', 'loss/train': '0.64932', 'examples_per_second': '5.2948', 'grad_norm': '18.125', 'counters/examples': 111936, 'counters/updates': 6996}
skipping logging after 111952 examples to avoid logging too frequently
skipping logging after 111968 examples to avoid logging too frequently
skipping logging after 111984 examples to avoid logging too frequently
train stats after 112000 examples: {'rewards_train/chosen': '-0.52403', 'rewards_train/rejected': '-0.62109', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.096992', 'logps_train/rejected': '-134.17', 'logps_train/chosen': '-154.67', 'loss/train': '0.67729', 'examples_per_second': '4.7387', 'grad_norm': '20', 'counters/examples': 112000, 'counters/updates': 7000}
skipping logging after 112016 examples to avoid logging too frequently
skipping logging after 112032 examples to avoid logging too frequently
skipping logging after 112048 examples to avoid logging too frequently
train stats after 112064 examples: {'rewards_train/chosen': '-0.72766', 'rewards_train/rejected': '-0.78142', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.053772', 'logps_train/rejected': '-138.76', 'logps_train/chosen': '-128.66', 'loss/train': '0.68871', 'examples_per_second': '5.056', 'grad_norm': '20.125', 'counters/examples': 112064, 'counters/updates': 7004}
skipping logging after 112080 examples to avoid logging too frequently
skipping logging after 112096 examples to avoid logging too frequently
Running evaluation after 112096 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:06,  2.15s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:02,  2.09s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.87s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.86s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.52s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.63s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.30s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.12s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 112096: {'rewards_eval/chosen': '-0.52894', 'rewards_eval/rejected': '-0.6488', 'rewards_eval/accuracies': '0.54883', 'rewards_eval/margins': '0.11988', 'logps_eval/rejected': '-128.64', 'logps_eval/chosen': '-123.78', 'loss/eval': '0.66734'}
skipping logging after 112112 examples to avoid logging too frequently
train stats after 112128 examples: {'rewards_train/chosen': '-0.42825', 'rewards_train/rejected': '-0.58677', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.15861', 'logps_train/rejected': '-110.47', 'logps_train/chosen': '-101.03', 'loss/train': '0.64656', 'examples_per_second': '6.6516', 'grad_norm': '15.125', 'counters/examples': 112128, 'counters/updates': 7008}
skipping logging after 112144 examples to avoid logging too frequently
skipping logging after 112160 examples to avoid logging too frequently
skipping logging after 112176 examples to avoid logging too frequently
train stats after 112192 examples: {'rewards_train/chosen': '-0.53373', 'rewards_train/rejected': '-0.66866', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.13509', 'logps_train/rejected': '-143.44', 'logps_train/chosen': '-152.18', 'loss/train': '0.65668', 'examples_per_second': '4.8691', 'grad_norm': '18', 'counters/examples': 112192, 'counters/updates': 7012}
skipping logging after 112208 examples to avoid logging too frequently
skipping logging after 112224 examples to avoid logging too frequently
skipping logging after 112240 examples to avoid logging too frequently
train stats after 112256 examples: {'rewards_train/chosen': '-0.54597', 'rewards_train/rejected': '-0.71904', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.17323', 'logps_train/rejected': '-114.8', 'logps_train/chosen': '-133.04', 'loss/train': '0.64456', 'examples_per_second': '4.5649', 'grad_norm': '21.75', 'counters/examples': 112256, 'counters/updates': 7016}
skipping logging after 112272 examples to avoid logging too frequently
skipping logging after 112288 examples to avoid logging too frequently
skipping logging after 112304 examples to avoid logging too frequently
train stats after 112320 examples: {'rewards_train/chosen': '-0.54528', 'rewards_train/rejected': '-0.74863', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.20353', 'logps_train/rejected': '-116.55', 'logps_train/chosen': '-126.53', 'loss/train': '0.62036', 'examples_per_second': '5.0428', 'grad_norm': '20', 'counters/examples': 112320, 'counters/updates': 7020}
skipping logging after 112336 examples to avoid logging too frequently
skipping logging after 112352 examples to avoid logging too frequently
skipping logging after 112368 examples to avoid logging too frequently
train stats after 112384 examples: {'rewards_train/chosen': '-0.63297', 'rewards_train/rejected': '-0.78447', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.15141', 'logps_train/rejected': '-104.87', 'logps_train/chosen': '-122.85', 'loss/train': '0.64933', 'examples_per_second': '5.3321', 'grad_norm': '18', 'counters/examples': 112384, 'counters/updates': 7024}
skipping logging after 112400 examples to avoid logging too frequently
skipping logging after 112416 examples to avoid logging too frequently
skipping logging after 112432 examples to avoid logging too frequently
train stats after 112448 examples: {'rewards_train/chosen': '-0.57044', 'rewards_train/rejected': '-0.78502', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.21471', 'logps_train/rejected': '-127.71', 'logps_train/chosen': '-178.8', 'loss/train': '0.64452', 'examples_per_second': '3.8711', 'grad_norm': '20.375', 'counters/examples': 112448, 'counters/updates': 7028}
skipping logging after 112464 examples to avoid logging too frequently
skipping logging after 112480 examples to avoid logging too frequently
skipping logging after 112496 examples to avoid logging too frequently
train stats after 112512 examples: {'rewards_train/chosen': '-0.49228', 'rewards_train/rejected': '-0.56055', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.068333', 'logps_train/rejected': '-162.84', 'logps_train/chosen': '-138.09', 'loss/train': '0.69283', 'examples_per_second': '4.5084', 'grad_norm': '22', 'counters/examples': 112512, 'counters/updates': 7032}
skipping logging after 112528 examples to avoid logging too frequently
skipping logging after 112544 examples to avoid logging too frequently
skipping logging after 112560 examples to avoid logging too frequently
train stats after 112576 examples: {'rewards_train/chosen': '-0.60131', 'rewards_train/rejected': '-0.72389', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.12265', 'logps_train/rejected': '-164.34', 'logps_train/chosen': '-138.49', 'loss/train': '0.66856', 'examples_per_second': '4.8767', 'grad_norm': '22.375', 'counters/examples': 112576, 'counters/updates': 7036}
skipping logging after 112592 examples to avoid logging too frequently
skipping logging after 112608 examples to avoid logging too frequently
skipping logging after 112624 examples to avoid logging too frequently
train stats after 112640 examples: {'rewards_train/chosen': '-0.60973', 'rewards_train/rejected': '-0.7343', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.12478', 'logps_train/rejected': '-138.44', 'logps_train/chosen': '-125.74', 'loss/train': '0.65375', 'examples_per_second': '5.0157', 'grad_norm': '19', 'counters/examples': 112640, 'counters/updates': 7040}
skipping logging after 112656 examples to avoid logging too frequently
skipping logging after 112672 examples to avoid logging too frequently
skipping logging after 112688 examples to avoid logging too frequently
train stats after 112704 examples: {'rewards_train/chosen': '-0.51176', 'rewards_train/rejected': '-0.72373', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.21202', 'logps_train/rejected': '-100.7', 'logps_train/chosen': '-125.17', 'loss/train': '0.61855', 'examples_per_second': '5.7355', 'grad_norm': '17.875', 'counters/examples': 112704, 'counters/updates': 7044}
skipping logging after 112720 examples to avoid logging too frequently
skipping logging after 112736 examples to avoid logging too frequently
skipping logging after 112752 examples to avoid logging too frequently
train stats after 112768 examples: {'rewards_train/chosen': '-0.53689', 'rewards_train/rejected': '-0.74632', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.20941', 'logps_train/rejected': '-166.27', 'logps_train/chosen': '-187.19', 'loss/train': '0.63834', 'examples_per_second': '3.8575', 'grad_norm': '21.5', 'counters/examples': 112768, 'counters/updates': 7048}
skipping logging after 112784 examples to avoid logging too frequently
skipping logging after 112800 examples to avoid logging too frequently
skipping logging after 112816 examples to avoid logging too frequently
train stats after 112832 examples: {'rewards_train/chosen': '-0.63837', 'rewards_train/rejected': '-0.76276', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.12444', 'logps_train/rejected': '-131.6', 'logps_train/chosen': '-122.17', 'loss/train': '0.6723', 'examples_per_second': '5.1517', 'grad_norm': '25.125', 'counters/examples': 112832, 'counters/updates': 7052}
skipping logging after 112848 examples to avoid logging too frequently
skipping logging after 112864 examples to avoid logging too frequently
skipping logging after 112880 examples to avoid logging too frequently
train stats after 112896 examples: {'rewards_train/chosen': '-0.66257', 'rewards_train/rejected': '-0.70425', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.041634', 'logps_train/rejected': '-110.47', 'logps_train/chosen': '-120.95', 'loss/train': '0.70003', 'examples_per_second': '4.7286', 'grad_norm': '19.5', 'counters/examples': 112896, 'counters/updates': 7056}
skipping logging after 112912 examples to avoid logging too frequently
skipping logging after 112928 examples to avoid logging too frequently
skipping logging after 112944 examples to avoid logging too frequently
train stats after 112960 examples: {'rewards_train/chosen': '-0.55358', 'rewards_train/rejected': '-0.78537', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.2317', 'logps_train/rejected': '-98.271', 'logps_train/chosen': '-100.56', 'loss/train': '0.61183', 'examples_per_second': '5.6386', 'grad_norm': '18.875', 'counters/examples': 112960, 'counters/updates': 7060}
skipping logging after 112976 examples to avoid logging too frequently
skipping logging after 112992 examples to avoid logging too frequently
skipping logging after 113008 examples to avoid logging too frequently
train stats after 113024 examples: {'rewards_train/chosen': '-0.44286', 'rewards_train/rejected': '-0.63505', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.19235', 'logps_train/rejected': '-129.96', 'logps_train/chosen': '-145.08', 'loss/train': '0.62326', 'examples_per_second': '5.0025', 'grad_norm': '16.625', 'counters/examples': 113024, 'counters/updates': 7064}
skipping logging after 113040 examples to avoid logging too frequently
skipping logging after 113056 examples to avoid logging too frequently
skipping logging after 113072 examples to avoid logging too frequently
train stats after 113088 examples: {'rewards_train/chosen': '-0.58321', 'rewards_train/rejected': '-0.77086', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.18775', 'logps_train/rejected': '-110.3', 'logps_train/chosen': '-137.89', 'loss/train': '0.63544', 'examples_per_second': '6.3475', 'grad_norm': '19.625', 'counters/examples': 113088, 'counters/updates': 7068}
Running evaluation after 113088 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.53s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 113088: {'rewards_eval/chosen': '-0.58231', 'rewards_eval/rejected': '-0.70596', 'rewards_eval/accuracies': '0.55273', 'rewards_eval/margins': '0.12368', 'logps_eval/rejected': '-129.22', 'logps_eval/chosen': '-124.32', 'loss/eval': '0.67019'}
skipping logging after 113104 examples to avoid logging too frequently
skipping logging after 113120 examples to avoid logging too frequently
skipping logging after 113136 examples to avoid logging too frequently
train stats after 113152 examples: {'rewards_train/chosen': '-0.4622', 'rewards_train/rejected': '-0.63223', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.17009', 'logps_train/rejected': '-153.79', 'logps_train/chosen': '-147.02', 'loss/train': '0.6338', 'examples_per_second': '4.9823', 'grad_norm': '21.875', 'counters/examples': 113152, 'counters/updates': 7072}
skipping logging after 113168 examples to avoid logging too frequently
skipping logging after 113184 examples to avoid logging too frequently
skipping logging after 113200 examples to avoid logging too frequently
train stats after 113216 examples: {'rewards_train/chosen': '-0.56351', 'rewards_train/rejected': '-0.75153', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.1879', 'logps_train/rejected': '-121.63', 'logps_train/chosen': '-117.76', 'loss/train': '0.62604', 'examples_per_second': '4.5329', 'grad_norm': '18.25', 'counters/examples': 113216, 'counters/updates': 7076}
skipping logging after 113232 examples to avoid logging too frequently
skipping logging after 113248 examples to avoid logging too frequently
skipping logging after 113264 examples to avoid logging too frequently
train stats after 113280 examples: {'rewards_train/chosen': '-0.50983', 'rewards_train/rejected': '-0.66937', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.15956', 'logps_train/rejected': '-107.81', 'logps_train/chosen': '-107.22', 'loss/train': '0.64105', 'examples_per_second': '4.744', 'grad_norm': '17.875', 'counters/examples': 113280, 'counters/updates': 7080}
skipping logging after 113296 examples to avoid logging too frequently
skipping logging after 113312 examples to avoid logging too frequently
skipping logging after 113328 examples to avoid logging too frequently
train stats after 113344 examples: {'rewards_train/chosen': '-0.6098', 'rewards_train/rejected': '-0.66985', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.06007', 'logps_train/rejected': '-136.9', 'logps_train/chosen': '-140.89', 'loss/train': '0.71583', 'examples_per_second': '4.915', 'grad_norm': '23.5', 'counters/examples': 113344, 'counters/updates': 7084}
skipping logging after 113360 examples to avoid logging too frequently
skipping logging after 113376 examples to avoid logging too frequently
skipping logging after 113392 examples to avoid logging too frequently
train stats after 113408 examples: {'rewards_train/chosen': '-0.55646', 'rewards_train/rejected': '-0.59662', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.040283', 'logps_train/rejected': '-145.77', 'logps_train/chosen': '-123.1', 'loss/train': '0.69952', 'examples_per_second': '5.1143', 'grad_norm': '23.375', 'counters/examples': 113408, 'counters/updates': 7088}
skipping logging after 113424 examples to avoid logging too frequently
skipping logging after 113440 examples to avoid logging too frequently
skipping logging after 113456 examples to avoid logging too frequently
train stats after 113472 examples: {'rewards_train/chosen': '-0.37287', 'rewards_train/rejected': '-0.55999', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.18689', 'logps_train/rejected': '-111.09', 'logps_train/chosen': '-121.62', 'loss/train': '0.63586', 'examples_per_second': '5.1557', 'grad_norm': '19.125', 'counters/examples': 113472, 'counters/updates': 7092}
skipping logging after 113488 examples to avoid logging too frequently
skipping logging after 113504 examples to avoid logging too frequently
skipping logging after 113520 examples to avoid logging too frequently
train stats after 113536 examples: {'rewards_train/chosen': '-0.56968', 'rewards_train/rejected': '-0.68926', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.1196', 'logps_train/rejected': '-126.91', 'logps_train/chosen': '-136.72', 'loss/train': '0.66862', 'examples_per_second': '5.2512', 'grad_norm': '24.375', 'counters/examples': 113536, 'counters/updates': 7096}
skipping logging after 113552 examples to avoid logging too frequently
skipping logging after 113568 examples to avoid logging too frequently
skipping logging after 113584 examples to avoid logging too frequently
train stats after 113600 examples: {'rewards_train/chosen': '-0.481', 'rewards_train/rejected': '-0.65306', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.17204', 'logps_train/rejected': '-121.71', 'logps_train/chosen': '-114.73', 'loss/train': '0.65315', 'examples_per_second': '4.8662', 'grad_norm': '17.5', 'counters/examples': 113600, 'counters/updates': 7100}
skipping logging after 113616 examples to avoid logging too frequently
skipping logging after 113632 examples to avoid logging too frequently
skipping logging after 113648 examples to avoid logging too frequently
train stats after 113664 examples: {'rewards_train/chosen': '-0.54258', 'rewards_train/rejected': '-0.70924', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.16697', 'logps_train/rejected': '-118.17', 'logps_train/chosen': '-148.38', 'loss/train': '0.65747', 'examples_per_second': '4.2055', 'grad_norm': '19.875', 'counters/examples': 113664, 'counters/updates': 7104}
skipping logging after 113680 examples to avoid logging too frequently
skipping logging after 113696 examples to avoid logging too frequently
skipping logging after 113712 examples to avoid logging too frequently
train stats after 113728 examples: {'rewards_train/chosen': '-0.55616', 'rewards_train/rejected': '-0.65323', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.096985', 'logps_train/rejected': '-130.14', 'logps_train/chosen': '-165.35', 'loss/train': '0.675', 'examples_per_second': '4.4215', 'grad_norm': '19.125', 'counters/examples': 113728, 'counters/updates': 7108}
skipping logging after 113744 examples to avoid logging too frequently
skipping logging after 113760 examples to avoid logging too frequently
skipping logging after 113776 examples to avoid logging too frequently
train stats after 113792 examples: {'rewards_train/chosen': '-0.55156', 'rewards_train/rejected': '-0.64406', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.092428', 'logps_train/rejected': '-100.15', 'logps_train/chosen': '-95.343', 'loss/train': '0.67537', 'examples_per_second': '5.2699', 'grad_norm': '17.875', 'counters/examples': 113792, 'counters/updates': 7112}
skipping logging after 113808 examples to avoid logging too frequently
skipping logging after 113824 examples to avoid logging too frequently
skipping logging after 113840 examples to avoid logging too frequently
train stats after 113856 examples: {'rewards_train/chosen': '-0.47383', 'rewards_train/rejected': '-0.5877', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.11398', 'logps_train/rejected': '-109.41', 'logps_train/chosen': '-103.51', 'loss/train': '0.67342', 'examples_per_second': '4.5151', 'grad_norm': '20', 'counters/examples': 113856, 'counters/updates': 7116}
skipping logging after 113872 examples to avoid logging too frequently
skipping logging after 113888 examples to avoid logging too frequently
skipping logging after 113904 examples to avoid logging too frequently
train stats after 113920 examples: {'rewards_train/chosen': '-0.48671', 'rewards_train/rejected': '-0.64095', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.15423', 'logps_train/rejected': '-121.22', 'logps_train/chosen': '-106.85', 'loss/train': '0.64124', 'examples_per_second': '5.8151', 'grad_norm': '20.125', 'counters/examples': 113920, 'counters/updates': 7120}
skipping logging after 113936 examples to avoid logging too frequently
skipping logging after 113952 examples to avoid logging too frequently
skipping logging after 113968 examples to avoid logging too frequently
train stats after 113984 examples: {'rewards_train/chosen': '-0.40208', 'rewards_train/rejected': '-0.5913', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.1893', 'logps_train/rejected': '-140.17', 'logps_train/chosen': '-124.2', 'loss/train': '0.63162', 'examples_per_second': '4.2938', 'grad_norm': '17.375', 'counters/examples': 113984, 'counters/updates': 7124}
skipping logging after 114000 examples to avoid logging too frequently
skipping logging after 114016 examples to avoid logging too frequently
skipping logging after 114032 examples to avoid logging too frequently
train stats after 114048 examples: {'rewards_train/chosen': '-0.49547', 'rewards_train/rejected': '-0.63115', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.13577', 'logps_train/rejected': '-100.94', 'logps_train/chosen': '-109.34', 'loss/train': '0.65997', 'examples_per_second': '4.1061', 'grad_norm': '20.375', 'counters/examples': 114048, 'counters/updates': 7128}
skipping logging after 114064 examples to avoid logging too frequently
skipping logging after 114080 examples to avoid logging too frequently
Running evaluation after 114080 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:09,  2.23s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:03,  2.12s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.89s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.88s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 114080: {'rewards_eval/chosen': '-0.48862', 'rewards_eval/rejected': '-0.60824', 'rewards_eval/accuracies': '0.55273', 'rewards_eval/margins': '0.11964', 'logps_eval/rejected': '-128.24', 'logps_eval/chosen': '-123.38', 'loss/eval': '0.66807'}
skipping logging after 114096 examples to avoid logging too frequently
train stats after 114112 examples: {'rewards_train/chosen': '-0.42087', 'rewards_train/rejected': '-0.5836', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.16287', 'logps_train/rejected': '-137.17', 'logps_train/chosen': '-120.85', 'loss/train': '0.64268', 'examples_per_second': '5.5113', 'grad_norm': '19.375', 'counters/examples': 114112, 'counters/updates': 7132}
skipping logging after 114128 examples to avoid logging too frequently
skipping logging after 114144 examples to avoid logging too frequently
skipping logging after 114160 examples to avoid logging too frequently
train stats after 114176 examples: {'rewards_train/chosen': '-0.43556', 'rewards_train/rejected': '-0.6012', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.16571', 'logps_train/rejected': '-100.48', 'logps_train/chosen': '-115.22', 'loss/train': '0.63153', 'examples_per_second': '4.2825', 'grad_norm': '17.625', 'counters/examples': 114176, 'counters/updates': 7136}
skipping logging after 114192 examples to avoid logging too frequently
skipping logging after 114208 examples to avoid logging too frequently
skipping logging after 114224 examples to avoid logging too frequently
train stats after 114240 examples: {'rewards_train/chosen': '-0.50592', 'rewards_train/rejected': '-0.65561', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.1498', 'logps_train/rejected': '-130.28', 'logps_train/chosen': '-128.5', 'loss/train': '0.65163', 'examples_per_second': '6.2238', 'grad_norm': '19', 'counters/examples': 114240, 'counters/updates': 7140}
skipping logging after 114256 examples to avoid logging too frequently
skipping logging after 114272 examples to avoid logging too frequently
skipping logging after 114288 examples to avoid logging too frequently
train stats after 114304 examples: {'rewards_train/chosen': '-0.54553', 'rewards_train/rejected': '-0.63216', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.086639', 'logps_train/rejected': '-144.4', 'logps_train/chosen': '-125.22', 'loss/train': '0.68518', 'examples_per_second': '4.621', 'grad_norm': '19.125', 'counters/examples': 114304, 'counters/updates': 7144}
skipping logging after 114320 examples to avoid logging too frequently
skipping logging after 114336 examples to avoid logging too frequently
skipping logging after 114352 examples to avoid logging too frequently
train stats after 114368 examples: {'rewards_train/chosen': '-0.43018', 'rewards_train/rejected': '-0.60235', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.17221', 'logps_train/rejected': '-153.08', 'logps_train/chosen': '-160.72', 'loss/train': '0.63449', 'examples_per_second': '4.1708', 'grad_norm': '19.25', 'counters/examples': 114368, 'counters/updates': 7148}
skipping logging after 114384 examples to avoid logging too frequently
skipping logging after 114400 examples to avoid logging too frequently
skipping logging after 114416 examples to avoid logging too frequently
train stats after 114432 examples: {'rewards_train/chosen': '-0.45957', 'rewards_train/rejected': '-0.60755', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.1482', 'logps_train/rejected': '-134.62', 'logps_train/chosen': '-98.241', 'loss/train': '0.65163', 'examples_per_second': '5.0095', 'grad_norm': '20.625', 'counters/examples': 114432, 'counters/updates': 7152}
skipping logging after 114448 examples to avoid logging too frequently
skipping logging after 114464 examples to avoid logging too frequently
skipping logging after 114480 examples to avoid logging too frequently
train stats after 114496 examples: {'rewards_train/chosen': '-0.38625', 'rewards_train/rejected': '-0.65271', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.26664', 'logps_train/rejected': '-135.57', 'logps_train/chosen': '-124.37', 'loss/train': '0.599', 'examples_per_second': '6.5397', 'grad_norm': '18.125', 'counters/examples': 114496, 'counters/updates': 7156}
skipping logging after 114512 examples to avoid logging too frequently
skipping logging after 114528 examples to avoid logging too frequently
skipping logging after 114544 examples to avoid logging too frequently
train stats after 114560 examples: {'rewards_train/chosen': '-0.53431', 'rewards_train/rejected': '-0.63337', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.098999', 'logps_train/rejected': '-139.3', 'logps_train/chosen': '-139.36', 'loss/train': '0.673', 'examples_per_second': '4.6504', 'grad_norm': '22.875', 'counters/examples': 114560, 'counters/updates': 7160}
skipping logging after 114576 examples to avoid logging too frequently
skipping logging after 114592 examples to avoid logging too frequently
skipping logging after 114608 examples to avoid logging too frequently
train stats after 114624 examples: {'rewards_train/chosen': '-0.44972', 'rewards_train/rejected': '-0.72221', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.27248', 'logps_train/rejected': '-124.34', 'logps_train/chosen': '-128.71', 'loss/train': '0.59744', 'examples_per_second': '5.3635', 'grad_norm': '18.625', 'counters/examples': 114624, 'counters/updates': 7164}
skipping logging after 114640 examples to avoid logging too frequently
skipping logging after 114656 examples to avoid logging too frequently
skipping logging after 114672 examples to avoid logging too frequently
train stats after 114688 examples: {'rewards_train/chosen': '-0.46208', 'rewards_train/rejected': '-0.64684', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.18487', 'logps_train/rejected': '-144.58', 'logps_train/chosen': '-142.71', 'loss/train': '0.6445', 'examples_per_second': '4.2506', 'grad_norm': '20.375', 'counters/examples': 114688, 'counters/updates': 7168}
skipping logging after 114704 examples to avoid logging too frequently
skipping logging after 114720 examples to avoid logging too frequently
skipping logging after 114736 examples to avoid logging too frequently
train stats after 114752 examples: {'rewards_train/chosen': '-0.41043', 'rewards_train/rejected': '-0.56666', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.15623', 'logps_train/rejected': '-127.1', 'logps_train/chosen': '-102.05', 'loss/train': '0.6433', 'examples_per_second': '4.9082', 'grad_norm': '18.875', 'counters/examples': 114752, 'counters/updates': 7172}
skipping logging after 114768 examples to avoid logging too frequently
skipping logging after 114784 examples to avoid logging too frequently
skipping logging after 114800 examples to avoid logging too frequently
train stats after 114816 examples: {'rewards_train/chosen': '-0.55858', 'rewards_train/rejected': '-0.63846', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.079941', 'logps_train/rejected': '-95.406', 'logps_train/chosen': '-111.74', 'loss/train': '0.68027', 'examples_per_second': '5.9348', 'grad_norm': '18.875', 'counters/examples': 114816, 'counters/updates': 7176}
skipping logging after 114832 examples to avoid logging too frequently
skipping logging after 114848 examples to avoid logging too frequently
skipping logging after 114864 examples to avoid logging too frequently
train stats after 114880 examples: {'rewards_train/chosen': '-0.4292', 'rewards_train/rejected': '-0.53671', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.10763', 'logps_train/rejected': '-131.86', 'logps_train/chosen': '-117.89', 'loss/train': '0.6535', 'examples_per_second': '4.9522', 'grad_norm': '18.125', 'counters/examples': 114880, 'counters/updates': 7180}
skipping logging after 114896 examples to avoid logging too frequently
skipping logging after 114912 examples to avoid logging too frequently
skipping logging after 114928 examples to avoid logging too frequently
train stats after 114944 examples: {'rewards_train/chosen': '-0.42327', 'rewards_train/rejected': '-0.52759', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.10427', 'logps_train/rejected': '-105.47', 'logps_train/chosen': '-107.33', 'loss/train': '0.66016', 'examples_per_second': '4.6754', 'grad_norm': '19.25', 'counters/examples': 114944, 'counters/updates': 7184}
skipping logging after 114960 examples to avoid logging too frequently
skipping logging after 114976 examples to avoid logging too frequently
skipping logging after 114992 examples to avoid logging too frequently
train stats after 115008 examples: {'rewards_train/chosen': '-0.49682', 'rewards_train/rejected': '-0.53743', 'rewards_train/accuracies': '0.42188', 'rewards_train/margins': '0.040531', 'logps_train/rejected': '-119', 'logps_train/chosen': '-108.81', 'loss/train': '0.69305', 'examples_per_second': '5.4446', 'grad_norm': '18.75', 'counters/examples': 115008, 'counters/updates': 7188}
skipping logging after 115024 examples to avoid logging too frequently
skipping logging after 115040 examples to avoid logging too frequently
skipping logging after 115056 examples to avoid logging too frequently
train stats after 115072 examples: {'rewards_train/chosen': '-0.50221', 'rewards_train/rejected': '-0.66052', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.15838', 'logps_train/rejected': '-158.47', 'logps_train/chosen': '-126.15', 'loss/train': '0.65497', 'examples_per_second': '4.4779', 'grad_norm': '20.125', 'counters/examples': 115072, 'counters/updates': 7192}
Running evaluation after 115072 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 115072: {'rewards_eval/chosen': '-0.42229', 'rewards_eval/rejected': '-0.54348', 'rewards_eval/accuracies': '0.55664', 'rewards_eval/margins': '0.12122', 'logps_eval/rejected': '-127.59', 'logps_eval/chosen': '-122.72', 'loss/eval': '0.66327'}
skipping logging after 115088 examples to avoid logging too frequently
skipping logging after 115104 examples to avoid logging too frequently
skipping logging after 115120 examples to avoid logging too frequently
train stats after 115136 examples: {'rewards_train/chosen': '-0.43858', 'rewards_train/rejected': '-0.53873', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.10031', 'logps_train/rejected': '-136.2', 'logps_train/chosen': '-116.65', 'loss/train': '0.66594', 'examples_per_second': '4.2859', 'grad_norm': '18.5', 'counters/examples': 115136, 'counters/updates': 7196}
skipping logging after 115152 examples to avoid logging too frequently
skipping logging after 115168 examples to avoid logging too frequently
skipping logging after 115184 examples to avoid logging too frequently
train stats after 115200 examples: {'rewards_train/chosen': '-0.4585', 'rewards_train/rejected': '-0.56182', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.1034', 'logps_train/rejected': '-104.9', 'logps_train/chosen': '-120.02', 'loss/train': '0.6676', 'examples_per_second': '5.7458', 'grad_norm': '18.75', 'counters/examples': 115200, 'counters/updates': 7200}
skipping logging after 115216 examples to avoid logging too frequently
skipping logging after 115232 examples to avoid logging too frequently
skipping logging after 115248 examples to avoid logging too frequently
train stats after 115264 examples: {'rewards_train/chosen': '-0.50135', 'rewards_train/rejected': '-0.564', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.062675', 'logps_train/rejected': '-128.88', 'logps_train/chosen': '-127.72', 'loss/train': '0.68716', 'examples_per_second': '4.4756', 'grad_norm': '19.75', 'counters/examples': 115264, 'counters/updates': 7204}
skipping logging after 115280 examples to avoid logging too frequently
skipping logging after 115296 examples to avoid logging too frequently
skipping logging after 115312 examples to avoid logging too frequently
train stats after 115328 examples: {'rewards_train/chosen': '-0.38437', 'rewards_train/rejected': '-0.49063', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.10619', 'logps_train/rejected': '-119.21', 'logps_train/chosen': '-113.63', 'loss/train': '0.66325', 'examples_per_second': '4.9592', 'grad_norm': '18.875', 'counters/examples': 115328, 'counters/updates': 7208}
skipping logging after 115344 examples to avoid logging too frequently
skipping logging after 115360 examples to avoid logging too frequently
skipping logging after 115376 examples to avoid logging too frequently
train stats after 115392 examples: {'rewards_train/chosen': '-0.40046', 'rewards_train/rejected': '-0.53263', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.13219', 'logps_train/rejected': '-125.7', 'logps_train/chosen': '-134.7', 'loss/train': '0.65256', 'examples_per_second': '6.0271', 'grad_norm': '19.5', 'counters/examples': 115392, 'counters/updates': 7212}
skipping logging after 115408 examples to avoid logging too frequently
skipping logging after 115424 examples to avoid logging too frequently
skipping logging after 115440 examples to avoid logging too frequently
train stats after 115456 examples: {'rewards_train/chosen': '-0.4765', 'rewards_train/rejected': '-0.56777', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.091339', 'logps_train/rejected': '-151.02', 'logps_train/chosen': '-121.79', 'loss/train': '0.68134', 'examples_per_second': '5.8486', 'grad_norm': '19', 'counters/examples': 115456, 'counters/updates': 7216}
skipping logging after 115472 examples to avoid logging too frequently
skipping logging after 115488 examples to avoid logging too frequently
skipping logging after 115504 examples to avoid logging too frequently
train stats after 115520 examples: {'rewards_train/chosen': '-0.41152', 'rewards_train/rejected': '-0.56366', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.1522', 'logps_train/rejected': '-127.4', 'logps_train/chosen': '-121.84', 'loss/train': '0.66764', 'examples_per_second': '5.804', 'grad_norm': '21', 'counters/examples': 115520, 'counters/updates': 7220}
skipping logging after 115536 examples to avoid logging too frequently
skipping logging after 115552 examples to avoid logging too frequently
skipping logging after 115568 examples to avoid logging too frequently
train stats after 115584 examples: {'rewards_train/chosen': '-0.34416', 'rewards_train/rejected': '-0.50532', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.16121', 'logps_train/rejected': '-117.82', 'logps_train/chosen': '-131.02', 'loss/train': '0.63901', 'examples_per_second': '4.4364', 'grad_norm': '19', 'counters/examples': 115584, 'counters/updates': 7224}
skipping logging after 115600 examples to avoid logging too frequently
skipping logging after 115616 examples to avoid logging too frequently
skipping logging after 115632 examples to avoid logging too frequently
train stats after 115648 examples: {'rewards_train/chosen': '-0.37346', 'rewards_train/rejected': '-0.52159', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.14832', 'logps_train/rejected': '-129.88', 'logps_train/chosen': '-133.17', 'loss/train': '0.65906', 'examples_per_second': '5.3281', 'grad_norm': '17.375', 'counters/examples': 115648, 'counters/updates': 7228}
skipping logging after 115664 examples to avoid logging too frequently
skipping logging after 115680 examples to avoid logging too frequently
skipping logging after 115696 examples to avoid logging too frequently
train stats after 115712 examples: {'rewards_train/chosen': '-0.37265', 'rewards_train/rejected': '-0.53724', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.16465', 'logps_train/rejected': '-127.06', 'logps_train/chosen': '-144.7', 'loss/train': '0.63831', 'examples_per_second': '5.1588', 'grad_norm': '19', 'counters/examples': 115712, 'counters/updates': 7232}
skipping logging after 115728 examples to avoid logging too frequently
skipping logging after 115744 examples to avoid logging too frequently
skipping logging after 115760 examples to avoid logging too frequently
train stats after 115776 examples: {'rewards_train/chosen': '-0.44318', 'rewards_train/rejected': '-0.57096', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.12793', 'logps_train/rejected': '-136.17', 'logps_train/chosen': '-145.74', 'loss/train': '0.65189', 'examples_per_second': '4.4249', 'grad_norm': '18.625', 'counters/examples': 115776, 'counters/updates': 7236}
skipping logging after 115792 examples to avoid logging too frequently
skipping logging after 115808 examples to avoid logging too frequently
skipping logging after 115824 examples to avoid logging too frequently
train stats after 115840 examples: {'rewards_train/chosen': '-0.38782', 'rewards_train/rejected': '-0.50091', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.1132', 'logps_train/rejected': '-120.43', 'logps_train/chosen': '-133.68', 'loss/train': '0.67169', 'examples_per_second': '5.1976', 'grad_norm': '18', 'counters/examples': 115840, 'counters/updates': 7240}
skipping logging after 115856 examples to avoid logging too frequently
skipping logging after 115872 examples to avoid logging too frequently
skipping logging after 115888 examples to avoid logging too frequently
train stats after 115904 examples: {'rewards_train/chosen': '-0.41216', 'rewards_train/rejected': '-0.55976', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.14768', 'logps_train/rejected': '-130.41', 'logps_train/chosen': '-110.25', 'loss/train': '0.65096', 'examples_per_second': '4.926', 'grad_norm': '21.125', 'counters/examples': 115904, 'counters/updates': 7244}
skipping logging after 115920 examples to avoid logging too frequently
skipping logging after 115936 examples to avoid logging too frequently
skipping logging after 115952 examples to avoid logging too frequently
train stats after 115968 examples: {'rewards_train/chosen': '-0.45302', 'rewards_train/rejected': '-0.55304', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.099976', 'logps_train/rejected': '-130.47', 'logps_train/chosen': '-147.12', 'loss/train': '0.67642', 'examples_per_second': '4.2102', 'grad_norm': '18.625', 'counters/examples': 115968, 'counters/updates': 7248}
skipping logging after 115984 examples to avoid logging too frequently
skipping logging after 116000 examples to avoid logging too frequently
skipping logging after 116016 examples to avoid logging too frequently
train stats after 116032 examples: {'rewards_train/chosen': '-0.42765', 'rewards_train/rejected': '-0.53664', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.10884', 'logps_train/rejected': '-133.56', 'logps_train/chosen': '-134.51', 'loss/train': '0.66507', 'examples_per_second': '5.5301', 'grad_norm': '21.125', 'counters/examples': 116032, 'counters/updates': 7252}
skipping logging after 116048 examples to avoid logging too frequently
skipping logging after 116064 examples to avoid logging too frequently
Running evaluation after 116064 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:13,  2.38s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:05,  2.18s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:55,  1.92s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.89s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.54s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 116064: {'rewards_eval/chosen': '-0.42325', 'rewards_eval/rejected': '-0.53911', 'rewards_eval/accuracies': '0.54688', 'rewards_eval/margins': '0.11589', 'logps_eval/rejected': '-127.55', 'logps_eval/chosen': '-122.73', 'loss/eval': '0.66722'}
skipping logging after 116080 examples to avoid logging too frequently
train stats after 116096 examples: {'rewards_train/chosen': '-0.42085', 'rewards_train/rejected': '-0.49164', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.070801', 'logps_train/rejected': '-112.3', 'logps_train/chosen': '-121.98', 'loss/train': '0.69276', 'examples_per_second': '5.542', 'grad_norm': '19.625', 'counters/examples': 116096, 'counters/updates': 7256}
skipping logging after 116112 examples to avoid logging too frequently
skipping logging after 116128 examples to avoid logging too frequently
skipping logging after 116144 examples to avoid logging too frequently
train stats after 116160 examples: {'rewards_train/chosen': '-0.43177', 'rewards_train/rejected': '-0.64109', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.20924', 'logps_train/rejected': '-130.75', 'logps_train/chosen': '-138.13', 'loss/train': '0.61749', 'examples_per_second': '5.2744', 'grad_norm': '17.125', 'counters/examples': 116160, 'counters/updates': 7260}
skipping logging after 116176 examples to avoid logging too frequently
skipping logging after 116192 examples to avoid logging too frequently
skipping logging after 116208 examples to avoid logging too frequently
train stats after 116224 examples: {'rewards_train/chosen': '-0.39214', 'rewards_train/rejected': '-0.54947', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.15737', 'logps_train/rejected': '-124', 'logps_train/chosen': '-122.11', 'loss/train': '0.65717', 'examples_per_second': '4.7077', 'grad_norm': '17.75', 'counters/examples': 116224, 'counters/updates': 7264}
skipping logging after 116240 examples to avoid logging too frequently
skipping logging after 116256 examples to avoid logging too frequently
skipping logging after 116272 examples to avoid logging too frequently
train stats after 116288 examples: {'rewards_train/chosen': '-0.4942', 'rewards_train/rejected': '-0.65658', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.16238', 'logps_train/rejected': '-113.91', 'logps_train/chosen': '-114.88', 'loss/train': '0.63591', 'examples_per_second': '6.2347', 'grad_norm': '18', 'counters/examples': 116288, 'counters/updates': 7268}
skipping logging after 116304 examples to avoid logging too frequently
skipping logging after 116320 examples to avoid logging too frequently
skipping logging after 116336 examples to avoid logging too frequently
train stats after 116352 examples: {'rewards_train/chosen': '-0.48078', 'rewards_train/rejected': '-0.63222', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.15134', 'logps_train/rejected': '-105.13', 'logps_train/chosen': '-122.94', 'loss/train': '0.64162', 'examples_per_second': '5.7068', 'grad_norm': '18.875', 'counters/examples': 116352, 'counters/updates': 7272}
skipping logging after 116368 examples to avoid logging too frequently
skipping logging after 116384 examples to avoid logging too frequently
skipping logging after 116400 examples to avoid logging too frequently
train stats after 116416 examples: {'rewards_train/chosen': '-0.52667', 'rewards_train/rejected': '-0.56952', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.042885', 'logps_train/rejected': '-122.25', 'logps_train/chosen': '-126.43', 'loss/train': '0.71251', 'examples_per_second': '4.9019', 'grad_norm': '18.875', 'counters/examples': 116416, 'counters/updates': 7276}
skipping logging after 116432 examples to avoid logging too frequently
skipping logging after 116448 examples to avoid logging too frequently
skipping logging after 116464 examples to avoid logging too frequently
train stats after 116480 examples: {'rewards_train/chosen': '-0.55578', 'rewards_train/rejected': '-0.73298', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.17732', 'logps_train/rejected': '-108.82', 'logps_train/chosen': '-93.644', 'loss/train': '0.64404', 'examples_per_second': '5.8269', 'grad_norm': '17.875', 'counters/examples': 116480, 'counters/updates': 7280}
skipping logging after 116496 examples to avoid logging too frequently
skipping logging after 116512 examples to avoid logging too frequently
skipping logging after 116528 examples to avoid logging too frequently
train stats after 116544 examples: {'rewards_train/chosen': '-0.48126', 'rewards_train/rejected': '-0.51822', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.036999', 'logps_train/rejected': '-118.66', 'logps_train/chosen': '-126.19', 'loss/train': '0.69754', 'examples_per_second': '4.8961', 'grad_norm': '19.625', 'counters/examples': 116544, 'counters/updates': 7284}
skipping logging after 116560 examples to avoid logging too frequently
skipping logging after 116576 examples to avoid logging too frequently
skipping logging after 116592 examples to avoid logging too frequently
train stats after 116608 examples: {'rewards_train/chosen': '-0.4775', 'rewards_train/rejected': '-0.61236', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.13485', 'logps_train/rejected': '-130.09', 'logps_train/chosen': '-132.72', 'loss/train': '0.65372', 'examples_per_second': '4.6277', 'grad_norm': '18.375', 'counters/examples': 116608, 'counters/updates': 7288}
skipping logging after 116624 examples to avoid logging too frequently
skipping logging after 116640 examples to avoid logging too frequently
skipping logging after 116656 examples to avoid logging too frequently
train stats after 116672 examples: {'rewards_train/chosen': '-0.48026', 'rewards_train/rejected': '-0.5751', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.094835', 'logps_train/rejected': '-109.14', 'logps_train/chosen': '-118.64', 'loss/train': '0.6778', 'examples_per_second': '5.5478', 'grad_norm': '20.25', 'counters/examples': 116672, 'counters/updates': 7292}
skipping logging after 116688 examples to avoid logging too frequently
skipping logging after 116704 examples to avoid logging too frequently
skipping logging after 116720 examples to avoid logging too frequently
train stats after 116736 examples: {'rewards_train/chosen': '-0.50945', 'rewards_train/rejected': '-0.56659', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.057159', 'logps_train/rejected': '-118.95', 'logps_train/chosen': '-131', 'loss/train': '0.69095', 'examples_per_second': '4.6806', 'grad_norm': '20.25', 'counters/examples': 116736, 'counters/updates': 7296}
skipping logging after 116752 examples to avoid logging too frequently
skipping logging after 116768 examples to avoid logging too frequently
skipping logging after 116784 examples to avoid logging too frequently
train stats after 116800 examples: {'rewards_train/chosen': '-0.58593', 'rewards_train/rejected': '-0.68428', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.098343', 'logps_train/rejected': '-148.48', 'logps_train/chosen': '-136.13', 'loss/train': '0.66409', 'examples_per_second': '5.3203', 'grad_norm': '22.875', 'counters/examples': 116800, 'counters/updates': 7300}
skipping logging after 116816 examples to avoid logging too frequently
skipping logging after 116832 examples to avoid logging too frequently
skipping logging after 116848 examples to avoid logging too frequently
train stats after 116864 examples: {'rewards_train/chosen': '-0.49252', 'rewards_train/rejected': '-0.60866', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.11626', 'logps_train/rejected': '-124.45', 'logps_train/chosen': '-107.49', 'loss/train': '0.65906', 'examples_per_second': '5.2388', 'grad_norm': '19.375', 'counters/examples': 116864, 'counters/updates': 7304}
skipping logging after 116880 examples to avoid logging too frequently
skipping logging after 116896 examples to avoid logging too frequently
skipping logging after 116912 examples to avoid logging too frequently
train stats after 116928 examples: {'rewards_train/chosen': '-0.54222', 'rewards_train/rejected': '-0.63397', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.091827', 'logps_train/rejected': '-128.38', 'logps_train/chosen': '-116.68', 'loss/train': '0.67563', 'examples_per_second': '4.9156', 'grad_norm': '19.25', 'counters/examples': 116928, 'counters/updates': 7308}
skipping logging after 116944 examples to avoid logging too frequently
skipping logging after 116960 examples to avoid logging too frequently
skipping logging after 116976 examples to avoid logging too frequently
train stats after 116992 examples: {'rewards_train/chosen': '-0.56284', 'rewards_train/rejected': '-0.74787', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.18509', 'logps_train/rejected': '-151.29', 'logps_train/chosen': '-143.39', 'loss/train': '0.64169', 'examples_per_second': '4.852', 'grad_norm': '20.125', 'counters/examples': 116992, 'counters/updates': 7312}
skipping logging after 117008 examples to avoid logging too frequently
skipping logging after 117024 examples to avoid logging too frequently
skipping logging after 117040 examples to avoid logging too frequently
train stats after 117056 examples: {'rewards_train/chosen': '-0.54939', 'rewards_train/rejected': '-0.76339', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.21409', 'logps_train/rejected': '-136.02', 'logps_train/chosen': '-127.43', 'loss/train': '0.62233', 'examples_per_second': '5.9103', 'grad_norm': '17.875', 'counters/examples': 117056, 'counters/updates': 7316}
Running evaluation after 117056 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.45s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.46s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.53s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 117056: {'rewards_eval/chosen': '-0.55461', 'rewards_eval/rejected': '-0.67766', 'rewards_eval/accuracies': '0.55273', 'rewards_eval/margins': '0.12304', 'logps_eval/rejected': '-128.93', 'logps_eval/chosen': '-124.04', 'loss/eval': '0.66809'}
skipping logging after 117072 examples to avoid logging too frequently
skipping logging after 117088 examples to avoid logging too frequently
skipping logging after 117104 examples to avoid logging too frequently
train stats after 117120 examples: {'rewards_train/chosen': '-0.57511', 'rewards_train/rejected': '-0.67287', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.097763', 'logps_train/rejected': '-108.98', 'logps_train/chosen': '-108.14', 'loss/train': '0.67564', 'examples_per_second': '4.9312', 'grad_norm': '17.875', 'counters/examples': 117120, 'counters/updates': 7320}
skipping logging after 117136 examples to avoid logging too frequently
skipping logging after 117152 examples to avoid logging too frequently
skipping logging after 117168 examples to avoid logging too frequently
train stats after 117184 examples: {'rewards_train/chosen': '-0.55727', 'rewards_train/rejected': '-0.60608', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.048912', 'logps_train/rejected': '-118.3', 'logps_train/chosen': '-116.56', 'loss/train': '0.69711', 'examples_per_second': '5.1491', 'grad_norm': '20', 'counters/examples': 117184, 'counters/updates': 7324}
skipping logging after 117200 examples to avoid logging too frequently
skipping logging after 117216 examples to avoid logging too frequently
skipping logging after 117232 examples to avoid logging too frequently
train stats after 117248 examples: {'rewards_train/chosen': '-0.41385', 'rewards_train/rejected': '-0.54585', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.13204', 'logps_train/rejected': '-134.56', 'logps_train/chosen': '-120.09', 'loss/train': '0.65707', 'examples_per_second': '5.2278', 'grad_norm': '19.25', 'counters/examples': 117248, 'counters/updates': 7328}
skipping logging after 117264 examples to avoid logging too frequently
skipping logging after 117280 examples to avoid logging too frequently
skipping logging after 117296 examples to avoid logging too frequently
train stats after 117312 examples: {'rewards_train/chosen': '-0.53536', 'rewards_train/rejected': '-0.67421', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.13869', 'logps_train/rejected': '-130.18', 'logps_train/chosen': '-122.5', 'loss/train': '0.67078', 'examples_per_second': '5.2391', 'grad_norm': '17', 'counters/examples': 117312, 'counters/updates': 7332}
skipping logging after 117328 examples to avoid logging too frequently
skipping logging after 117344 examples to avoid logging too frequently
skipping logging after 117360 examples to avoid logging too frequently
train stats after 117376 examples: {'rewards_train/chosen': '-0.32363', 'rewards_train/rejected': '-0.46527', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.14172', 'logps_train/rejected': '-132.54', 'logps_train/chosen': '-129.29', 'loss/train': '0.64331', 'examples_per_second': '4.5586', 'grad_norm': '20.75', 'counters/examples': 117376, 'counters/updates': 7336}
skipping logging after 117392 examples to avoid logging too frequently
skipping logging after 117408 examples to avoid logging too frequently
skipping logging after 117424 examples to avoid logging too frequently
train stats after 117440 examples: {'rewards_train/chosen': '-0.53664', 'rewards_train/rejected': '-0.68883', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.15224', 'logps_train/rejected': '-143.04', 'logps_train/chosen': '-129.36', 'loss/train': '0.65694', 'examples_per_second': '5.6319', 'grad_norm': '19.25', 'counters/examples': 117440, 'counters/updates': 7340}
skipping logging after 117456 examples to avoid logging too frequently
skipping logging after 117472 examples to avoid logging too frequently
skipping logging after 117488 examples to avoid logging too frequently
train stats after 117504 examples: {'rewards_train/chosen': '-0.48619', 'rewards_train/rejected': '-0.66456', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.17845', 'logps_train/rejected': '-111.28', 'logps_train/chosen': '-93.826', 'loss/train': '0.64445', 'examples_per_second': '6.6654', 'grad_norm': '19.25', 'counters/examples': 117504, 'counters/updates': 7344}
skipping logging after 117520 examples to avoid logging too frequently
skipping logging after 117536 examples to avoid logging too frequently
skipping logging after 117552 examples to avoid logging too frequently
train stats after 117568 examples: {'rewards_train/chosen': '-0.34917', 'rewards_train/rejected': '-0.6007', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.25165', 'logps_train/rejected': '-129.91', 'logps_train/chosen': '-138.13', 'loss/train': '0.60674', 'examples_per_second': '5.186', 'grad_norm': '18.625', 'counters/examples': 117568, 'counters/updates': 7348}
skipping logging after 117584 examples to avoid logging too frequently
skipping logging after 117600 examples to avoid logging too frequently
skipping logging after 117616 examples to avoid logging too frequently
train stats after 117632 examples: {'rewards_train/chosen': '-0.4507', 'rewards_train/rejected': '-0.63768', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.18713', 'logps_train/rejected': '-111.42', 'logps_train/chosen': '-122.22', 'loss/train': '0.63313', 'examples_per_second': '4.6628', 'grad_norm': '17.75', 'counters/examples': 117632, 'counters/updates': 7352}
skipping logging after 117648 examples to avoid logging too frequently
skipping logging after 117664 examples to avoid logging too frequently
skipping logging after 117680 examples to avoid logging too frequently
train stats after 117696 examples: {'rewards_train/chosen': '-0.67258', 'rewards_train/rejected': '-0.76035', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.087784', 'logps_train/rejected': '-132.08', 'logps_train/chosen': '-119.73', 'loss/train': '0.68204', 'examples_per_second': '4.8461', 'grad_norm': '22.5', 'counters/examples': 117696, 'counters/updates': 7356}
skipping logging after 117712 examples to avoid logging too frequently
skipping logging after 117728 examples to avoid logging too frequently
skipping logging after 117744 examples to avoid logging too frequently
train stats after 117760 examples: {'rewards_train/chosen': '-0.56714', 'rewards_train/rejected': '-0.73284', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.16573', 'logps_train/rejected': '-131.94', 'logps_train/chosen': '-128.63', 'loss/train': '0.64853', 'examples_per_second': '5.0484', 'grad_norm': '22.75', 'counters/examples': 117760, 'counters/updates': 7360}
skipping logging after 117776 examples to avoid logging too frequently
skipping logging after 117792 examples to avoid logging too frequently
skipping logging after 117808 examples to avoid logging too frequently
train stats after 117824 examples: {'rewards_train/chosen': '-0.59522', 'rewards_train/rejected': '-0.68654', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.091148', 'logps_train/rejected': '-136.2', 'logps_train/chosen': '-121.47', 'loss/train': '0.68678', 'examples_per_second': '4.7593', 'grad_norm': '21.5', 'counters/examples': 117824, 'counters/updates': 7364}
skipping logging after 117840 examples to avoid logging too frequently
skipping logging after 117856 examples to avoid logging too frequently
skipping logging after 117872 examples to avoid logging too frequently
train stats after 117888 examples: {'rewards_train/chosen': '-0.49518', 'rewards_train/rejected': '-0.66118', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.16614', 'logps_train/rejected': '-118.46', 'logps_train/chosen': '-103.14', 'loss/train': '0.64108', 'examples_per_second': '4.8127', 'grad_norm': '16.25', 'counters/examples': 117888, 'counters/updates': 7368}
skipping logging after 117904 examples to avoid logging too frequently
skipping logging after 117920 examples to avoid logging too frequently
skipping logging after 117936 examples to avoid logging too frequently
train stats after 117952 examples: {'rewards_train/chosen': '-0.56508', 'rewards_train/rejected': '-0.72911', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.16386', 'logps_train/rejected': '-123.28', 'logps_train/chosen': '-123.12', 'loss/train': '0.65389', 'examples_per_second': '4.9612', 'grad_norm': '21.75', 'counters/examples': 117952, 'counters/updates': 7372}
skipping logging after 117968 examples to avoid logging too frequently
skipping logging after 117984 examples to avoid logging too frequently
skipping logging after 118000 examples to avoid logging too frequently
train stats after 118016 examples: {'rewards_train/chosen': '-0.63108', 'rewards_train/rejected': '-0.53515', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '-0.095978', 'logps_train/rejected': '-117.4', 'logps_train/chosen': '-115.09', 'loss/train': '0.78079', 'examples_per_second': '6.2884', 'grad_norm': '29.25', 'counters/examples': 118016, 'counters/updates': 7376}
skipping logging after 118032 examples to avoid logging too frequently
skipping logging after 118048 examples to avoid logging too frequently
Running evaluation after 118048 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:10,  2.26s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:03,  2.13s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.89s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.88s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 118048: {'rewards_eval/chosen': '-0.44239', 'rewards_eval/rejected': '-0.565', 'rewards_eval/accuracies': '0.55078', 'rewards_eval/margins': '0.12257', 'logps_eval/rejected': '-127.81', 'logps_eval/chosen': '-122.92', 'loss/eval': '0.66381'}
skipping logging after 118064 examples to avoid logging too frequently
train stats after 118080 examples: {'rewards_train/chosen': '-0.40887', 'rewards_train/rejected': '-0.53101', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.12213', 'logps_train/rejected': '-128.98', 'logps_train/chosen': '-116.52', 'loss/train': '0.6568', 'examples_per_second': '5.0566', 'grad_norm': '17.25', 'counters/examples': 118080, 'counters/updates': 7380}
skipping logging after 118096 examples to avoid logging too frequently
skipping logging after 118112 examples to avoid logging too frequently
skipping logging after 118128 examples to avoid logging too frequently
train stats after 118144 examples: {'rewards_train/chosen': '-0.37916', 'rewards_train/rejected': '-0.56492', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.18587', 'logps_train/rejected': '-118.17', 'logps_train/chosen': '-117.7', 'loss/train': '0.63025', 'examples_per_second': '5.5603', 'grad_norm': '17.875', 'counters/examples': 118144, 'counters/updates': 7384}
skipping logging after 118160 examples to avoid logging too frequently
skipping logging after 118176 examples to avoid logging too frequently
skipping logging after 118192 examples to avoid logging too frequently
train stats after 118208 examples: {'rewards_train/chosen': '-0.47927', 'rewards_train/rejected': '-0.68279', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.20355', 'logps_train/rejected': '-120.88', 'logps_train/chosen': '-107.79', 'loss/train': '0.63171', 'examples_per_second': '5.1465', 'grad_norm': '14.812', 'counters/examples': 118208, 'counters/updates': 7388}
skipping logging after 118224 examples to avoid logging too frequently
skipping logging after 118240 examples to avoid logging too frequently
skipping logging after 118256 examples to avoid logging too frequently
train stats after 118272 examples: {'rewards_train/chosen': '-0.48385', 'rewards_train/rejected': '-0.61626', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.13238', 'logps_train/rejected': '-134.6', 'logps_train/chosen': '-119.94', 'loss/train': '0.65881', 'examples_per_second': '4.693', 'grad_norm': '19.125', 'counters/examples': 118272, 'counters/updates': 7392}
skipping logging after 118288 examples to avoid logging too frequently
skipping logging after 118304 examples to avoid logging too frequently
skipping logging after 118320 examples to avoid logging too frequently
train stats after 118336 examples: {'rewards_train/chosen': '-0.38063', 'rewards_train/rejected': '-0.55015', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.16947', 'logps_train/rejected': '-123.54', 'logps_train/chosen': '-122.15', 'loss/train': '0.6402', 'examples_per_second': '6.0134', 'grad_norm': '16.125', 'counters/examples': 118336, 'counters/updates': 7396}
skipping logging after 118352 examples to avoid logging too frequently
skipping logging after 118368 examples to avoid logging too frequently
skipping logging after 118384 examples to avoid logging too frequently
train stats after 118400 examples: {'rewards_train/chosen': '-0.48199', 'rewards_train/rejected': '-0.60631', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.12407', 'logps_train/rejected': '-121.36', 'logps_train/chosen': '-127.32', 'loss/train': '0.66559', 'examples_per_second': '5.5261', 'grad_norm': '18.875', 'counters/examples': 118400, 'counters/updates': 7400}
skipping logging after 118416 examples to avoid logging too frequently
skipping logging after 118432 examples to avoid logging too frequently
skipping logging after 118448 examples to avoid logging too frequently
train stats after 118464 examples: {'rewards_train/chosen': '-0.39277', 'rewards_train/rejected': '-0.55126', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.15839', 'logps_train/rejected': '-128.25', 'logps_train/chosen': '-124.96', 'loss/train': '0.6373', 'examples_per_second': '5.916', 'grad_norm': '16.875', 'counters/examples': 118464, 'counters/updates': 7404}
skipping logging after 118480 examples to avoid logging too frequently
skipping logging after 118496 examples to avoid logging too frequently
skipping logging after 118512 examples to avoid logging too frequently
train stats after 118528 examples: {'rewards_train/chosen': '-0.4349', 'rewards_train/rejected': '-0.61544', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.18052', 'logps_train/rejected': '-107.84', 'logps_train/chosen': '-126.83', 'loss/train': '0.6272', 'examples_per_second': '5.0807', 'grad_norm': '20.875', 'counters/examples': 118528, 'counters/updates': 7408}
skipping logging after 118544 examples to avoid logging too frequently
skipping logging after 118560 examples to avoid logging too frequently
skipping logging after 118576 examples to avoid logging too frequently
train stats after 118592 examples: {'rewards_train/chosen': '-0.60785', 'rewards_train/rejected': '-0.76688', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.15918', 'logps_train/rejected': '-136.66', 'logps_train/chosen': '-113.2', 'loss/train': '0.63434', 'examples_per_second': '5.4703', 'grad_norm': '20', 'counters/examples': 118592, 'counters/updates': 7412}
skipping logging after 118608 examples to avoid logging too frequently
skipping logging after 118624 examples to avoid logging too frequently
skipping logging after 118640 examples to avoid logging too frequently
train stats after 118656 examples: {'rewards_train/chosen': '-0.61343', 'rewards_train/rejected': '-0.68263', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.069132', 'logps_train/rejected': '-133.38', 'logps_train/chosen': '-131.35', 'loss/train': '0.68648', 'examples_per_second': '5.3663', 'grad_norm': '20.625', 'counters/examples': 118656, 'counters/updates': 7416}
skipping logging after 118672 examples to avoid logging too frequently
skipping logging after 118688 examples to avoid logging too frequently
skipping logging after 118704 examples to avoid logging too frequently
train stats after 118720 examples: {'rewards_train/chosen': '-0.42352', 'rewards_train/rejected': '-0.64631', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.22286', 'logps_train/rejected': '-123.43', 'logps_train/chosen': '-128.79', 'loss/train': '0.62088', 'examples_per_second': '4.8925', 'grad_norm': '16.75', 'counters/examples': 118720, 'counters/updates': 7420}
skipping logging after 118736 examples to avoid logging too frequently
skipping logging after 118752 examples to avoid logging too frequently
skipping logging after 118768 examples to avoid logging too frequently
train stats after 118784 examples: {'rewards_train/chosen': '-0.33904', 'rewards_train/rejected': '-0.48261', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.1436', 'logps_train/rejected': '-127.62', 'logps_train/chosen': '-126.75', 'loss/train': '0.64819', 'examples_per_second': '4.6335', 'grad_norm': '18.25', 'counters/examples': 118784, 'counters/updates': 7424}
skipping logging after 118800 examples to avoid logging too frequently
skipping logging after 118816 examples to avoid logging too frequently
skipping logging after 118832 examples to avoid logging too frequently
train stats after 118848 examples: {'rewards_train/chosen': '-0.39155', 'rewards_train/rejected': '-0.64016', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.2486', 'logps_train/rejected': '-154.09', 'logps_train/chosen': '-107.07', 'loss/train': '0.60559', 'examples_per_second': '5.0013', 'grad_norm': '21.25', 'counters/examples': 118848, 'counters/updates': 7428}
skipping logging after 118864 examples to avoid logging too frequently
skipping logging after 118880 examples to avoid logging too frequently
skipping logging after 118896 examples to avoid logging too frequently
train stats after 118912 examples: {'rewards_train/chosen': '-0.51194', 'rewards_train/rejected': '-0.70744', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.19535', 'logps_train/rejected': '-116.51', 'logps_train/chosen': '-119.54', 'loss/train': '0.62933', 'examples_per_second': '5.2914', 'grad_norm': '17.75', 'counters/examples': 118912, 'counters/updates': 7432}
skipping logging after 118928 examples to avoid logging too frequently
skipping logging after 118944 examples to avoid logging too frequently
skipping logging after 118960 examples to avoid logging too frequently
train stats after 118976 examples: {'rewards_train/chosen': '-0.44868', 'rewards_train/rejected': '-0.63942', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.19082', 'logps_train/rejected': '-116.38', 'logps_train/chosen': '-121.34', 'loss/train': '0.6522', 'examples_per_second': '4.664', 'grad_norm': '20.125', 'counters/examples': 118976, 'counters/updates': 7436}
skipping logging after 118992 examples to avoid logging too frequently
skipping logging after 119008 examples to avoid logging too frequently
skipping logging after 119024 examples to avoid logging too frequently
train stats after 119040 examples: {'rewards_train/chosen': '-0.35339', 'rewards_train/rejected': '-0.59715', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.24377', 'logps_train/rejected': '-147.26', 'logps_train/chosen': '-139.1', 'loss/train': '0.6148', 'examples_per_second': '5.1628', 'grad_norm': '20.625', 'counters/examples': 119040, 'counters/updates': 7440}
Running evaluation after 119040 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.45s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.46s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.53s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 119040: {'rewards_eval/chosen': '-0.52323', 'rewards_eval/rejected': '-0.65346', 'rewards_eval/accuracies': '0.54688', 'rewards_eval/margins': '0.13021', 'logps_eval/rejected': '-128.69', 'logps_eval/chosen': '-123.73', 'loss/eval': '0.66843'}
skipping logging after 119056 examples to avoid logging too frequently
skipping logging after 119072 examples to avoid logging too frequently
skipping logging after 119088 examples to avoid logging too frequently
train stats after 119104 examples: {'rewards_train/chosen': '-0.52945', 'rewards_train/rejected': '-0.66024', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.1308', 'logps_train/rejected': '-104.15', 'logps_train/chosen': '-93.901', 'loss/train': '0.66539', 'examples_per_second': '4.7005', 'grad_norm': '18.5', 'counters/examples': 119104, 'counters/updates': 7444}
skipping logging after 119120 examples to avoid logging too frequently
skipping logging after 119136 examples to avoid logging too frequently
skipping logging after 119152 examples to avoid logging too frequently
train stats after 119168 examples: {'rewards_train/chosen': '-0.45621', 'rewards_train/rejected': '-0.75457', 'rewards_train/accuracies': '0.71875', 'rewards_train/margins': '0.29846', 'logps_train/rejected': '-117.59', 'logps_train/chosen': '-117.92', 'loss/train': '0.58264', 'examples_per_second': '6.0618', 'grad_norm': '21.125', 'counters/examples': 119168, 'counters/updates': 7448}
skipping logging after 119184 examples to avoid logging too frequently
skipping logging after 119200 examples to avoid logging too frequently
skipping logging after 119216 examples to avoid logging too frequently
train stats after 119232 examples: {'rewards_train/chosen': '-0.50526', 'rewards_train/rejected': '-0.68363', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.17852', 'logps_train/rejected': '-113.79', 'logps_train/chosen': '-105.6', 'loss/train': '0.63795', 'examples_per_second': '5.307', 'grad_norm': '20.625', 'counters/examples': 119232, 'counters/updates': 7452}
skipping logging after 119248 examples to avoid logging too frequently
skipping logging after 119264 examples to avoid logging too frequently
skipping logging after 119280 examples to avoid logging too frequently
train stats after 119296 examples: {'rewards_train/chosen': '-0.57288', 'rewards_train/rejected': '-0.73627', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.1633', 'logps_train/rejected': '-118.95', 'logps_train/chosen': '-116.06', 'loss/train': '0.65109', 'examples_per_second': '4.5657', 'grad_norm': '23.25', 'counters/examples': 119296, 'counters/updates': 7456}
skipping logging after 119312 examples to avoid logging too frequently
skipping logging after 119328 examples to avoid logging too frequently
skipping logging after 119344 examples to avoid logging too frequently
train stats after 119360 examples: {'rewards_train/chosen': '-0.76492', 'rewards_train/rejected': '-0.86064', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.095627', 'logps_train/rejected': '-118.23', 'logps_train/chosen': '-152.98', 'loss/train': '0.68913', 'examples_per_second': '5.1871', 'grad_norm': '24.5', 'counters/examples': 119360, 'counters/updates': 7460}
skipping logging after 119376 examples to avoid logging too frequently
skipping logging after 119392 examples to avoid logging too frequently
skipping logging after 119408 examples to avoid logging too frequently
train stats after 119424 examples: {'rewards_train/chosen': '-0.57357', 'rewards_train/rejected': '-0.81684', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.24329', 'logps_train/rejected': '-115.88', 'logps_train/chosen': '-122.92', 'loss/train': '0.6209', 'examples_per_second': '6.1091', 'grad_norm': '18.5', 'counters/examples': 119424, 'counters/updates': 7464}
skipping logging after 119440 examples to avoid logging too frequently
skipping logging after 119456 examples to avoid logging too frequently
skipping logging after 119472 examples to avoid logging too frequently
train stats after 119488 examples: {'rewards_train/chosen': '-0.6113', 'rewards_train/rejected': '-0.80563', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.19439', 'logps_train/rejected': '-132.71', 'logps_train/chosen': '-115.36', 'loss/train': '0.63766', 'examples_per_second': '5.5853', 'grad_norm': '19.375', 'counters/examples': 119488, 'counters/updates': 7468}
skipping logging after 119504 examples to avoid logging too frequently
skipping logging after 119520 examples to avoid logging too frequently
skipping logging after 119536 examples to avoid logging too frequently
train stats after 119552 examples: {'rewards_train/chosen': '-0.65997', 'rewards_train/rejected': '-0.87965', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.21973', 'logps_train/rejected': '-132.81', 'logps_train/chosen': '-125.92', 'loss/train': '0.6278', 'examples_per_second': '5.2538', 'grad_norm': '19.5', 'counters/examples': 119552, 'counters/updates': 7472}
skipping logging after 119568 examples to avoid logging too frequently
skipping logging after 119584 examples to avoid logging too frequently
skipping logging after 119600 examples to avoid logging too frequently
train stats after 119616 examples: {'rewards_train/chosen': '-0.66137', 'rewards_train/rejected': '-0.76607', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.10479', 'logps_train/rejected': '-106.45', 'logps_train/chosen': '-130.02', 'loss/train': '0.67184', 'examples_per_second': '6.2812', 'grad_norm': '19.375', 'counters/examples': 119616, 'counters/updates': 7476}
skipping logging after 119632 examples to avoid logging too frequently
skipping logging after 119648 examples to avoid logging too frequently
skipping logging after 119664 examples to avoid logging too frequently
train stats after 119680 examples: {'rewards_train/chosen': '-0.49739', 'rewards_train/rejected': '-0.74043', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.2432', 'logps_train/rejected': '-128.98', 'logps_train/chosen': '-125.22', 'loss/train': '0.6177', 'examples_per_second': '4.8624', 'grad_norm': '21.125', 'counters/examples': 119680, 'counters/updates': 7480}
skipping logging after 119696 examples to avoid logging too frequently
skipping logging after 119712 examples to avoid logging too frequently
skipping logging after 119728 examples to avoid logging too frequently
train stats after 119744 examples: {'rewards_train/chosen': '-0.4753', 'rewards_train/rejected': '-0.73813', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.26286', 'logps_train/rejected': '-126.07', 'logps_train/chosen': '-116.67', 'loss/train': '0.61797', 'examples_per_second': '5.0436', 'grad_norm': '19.625', 'counters/examples': 119744, 'counters/updates': 7484}
skipping logging after 119760 examples to avoid logging too frequently
skipping logging after 119776 examples to avoid logging too frequently
skipping logging after 119792 examples to avoid logging too frequently
train stats after 119808 examples: {'rewards_train/chosen': '-0.68359', 'rewards_train/rejected': '-0.90345', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.21984', 'logps_train/rejected': '-99.434', 'logps_train/chosen': '-124.65', 'loss/train': '0.62712', 'examples_per_second': '6.0819', 'grad_norm': '16.625', 'counters/examples': 119808, 'counters/updates': 7488}
skipping logging after 119824 examples to avoid logging too frequently
skipping logging after 119840 examples to avoid logging too frequently
skipping logging after 119856 examples to avoid logging too frequently
train stats after 119872 examples: {'rewards_train/chosen': '-0.70346', 'rewards_train/rejected': '-0.86494', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.16153', 'logps_train/rejected': '-113.94', 'logps_train/chosen': '-130.04', 'loss/train': '0.63994', 'examples_per_second': '4.2701', 'grad_norm': '20.25', 'counters/examples': 119872, 'counters/updates': 7492}
skipping logging after 119888 examples to avoid logging too frequently
skipping logging after 119904 examples to avoid logging too frequently
skipping logging after 119920 examples to avoid logging too frequently
train stats after 119936 examples: {'rewards_train/chosen': '-0.56578', 'rewards_train/rejected': '-0.78847', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.22285', 'logps_train/rejected': '-145.59', 'logps_train/chosen': '-124.87', 'loss/train': '0.61009', 'examples_per_second': '4.5087', 'grad_norm': '19.625', 'counters/examples': 119936, 'counters/updates': 7496}
skipping logging after 119952 examples to avoid logging too frequently
skipping logging after 119968 examples to avoid logging too frequently
skipping logging after 119984 examples to avoid logging too frequently
train stats after 120000 examples: {'rewards_train/chosen': '-0.60227', 'rewards_train/rejected': '-0.67684', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.074493', 'logps_train/rejected': '-108.81', 'logps_train/chosen': '-128.65', 'loss/train': '0.69411', 'examples_per_second': '4.5821', 'grad_norm': '23.5', 'counters/examples': 120000, 'counters/updates': 7500}
skipping logging after 120016 examples to avoid logging too frequently
skipping logging after 120032 examples to avoid logging too frequently
Running evaluation after 120032 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:14,  2.40s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:05,  2.19s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:55,  1.93s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.90s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.54s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.65s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 120032: {'rewards_eval/chosen': '-0.64714', 'rewards_eval/rejected': '-0.78781', 'rewards_eval/accuracies': '0.56055', 'rewards_eval/margins': '0.14067', 'logps_eval/rejected': '-130.03', 'logps_eval/chosen': '-124.97', 'loss/eval': '0.66615'}
skipping logging after 120048 examples to avoid logging too frequently
train stats after 120064 examples: {'rewards_train/chosen': '-0.69136', 'rewards_train/rejected': '-0.92901', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.23766', 'logps_train/rejected': '-132', 'logps_train/chosen': '-127.32', 'loss/train': '0.62256', 'examples_per_second': '4.4968', 'grad_norm': '22.25', 'counters/examples': 120064, 'counters/updates': 7504}
skipping logging after 120080 examples to avoid logging too frequently
skipping logging after 120096 examples to avoid logging too frequently
skipping logging after 120112 examples to avoid logging too frequently
train stats after 120128 examples: {'rewards_train/chosen': '-0.71011', 'rewards_train/rejected': '-0.87216', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.16206', 'logps_train/rejected': '-143.53', 'logps_train/chosen': '-140.55', 'loss/train': '0.65166', 'examples_per_second': '4.8753', 'grad_norm': '22.375', 'counters/examples': 120128, 'counters/updates': 7508}
skipping logging after 120144 examples to avoid logging too frequently
skipping logging after 120160 examples to avoid logging too frequently
skipping logging after 120176 examples to avoid logging too frequently
train stats after 120192 examples: {'rewards_train/chosen': '-0.6519', 'rewards_train/rejected': '-0.70263', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.050797', 'logps_train/rejected': '-145.12', 'logps_train/chosen': '-133.26', 'loss/train': '0.70603', 'examples_per_second': '4.5058', 'grad_norm': '28.25', 'counters/examples': 120192, 'counters/updates': 7512}
skipping logging after 120208 examples to avoid logging too frequently
skipping logging after 120224 examples to avoid logging too frequently
skipping logging after 120240 examples to avoid logging too frequently
train stats after 120256 examples: {'rewards_train/chosen': '-0.69452', 'rewards_train/rejected': '-0.76915', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.074593', 'logps_train/rejected': '-112.21', 'logps_train/chosen': '-114.73', 'loss/train': '0.70297', 'examples_per_second': '4.3951', 'grad_norm': '22.375', 'counters/examples': 120256, 'counters/updates': 7516}
skipping logging after 120272 examples to avoid logging too frequently
skipping logging after 120288 examples to avoid logging too frequently
skipping logging after 120304 examples to avoid logging too frequently
train stats after 120320 examples: {'rewards_train/chosen': '-0.69949', 'rewards_train/rejected': '-0.91284', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.2133', 'logps_train/rejected': '-111.87', 'logps_train/chosen': '-103.72', 'loss/train': '0.61165', 'examples_per_second': '4.2302', 'grad_norm': '15.625', 'counters/examples': 120320, 'counters/updates': 7520}
skipping logging after 120336 examples to avoid logging too frequently
skipping logging after 120352 examples to avoid logging too frequently
skipping logging after 120368 examples to avoid logging too frequently
train stats after 120384 examples: {'rewards_train/chosen': '-0.79661', 'rewards_train/rejected': '-1.0045', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.20798', 'logps_train/rejected': '-126.45', 'logps_train/chosen': '-131.11', 'loss/train': '0.63297', 'examples_per_second': '4.1582', 'grad_norm': '23.625', 'counters/examples': 120384, 'counters/updates': 7524}
skipping logging after 120400 examples to avoid logging too frequently
skipping logging after 120416 examples to avoid logging too frequently
skipping logging after 120432 examples to avoid logging too frequently
train stats after 120448 examples: {'rewards_train/chosen': '-0.70126', 'rewards_train/rejected': '-0.78029', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.079113', 'logps_train/rejected': '-122.3', 'logps_train/chosen': '-114.21', 'loss/train': '0.68436', 'examples_per_second': '5.8707', 'grad_norm': '18.25', 'counters/examples': 120448, 'counters/updates': 7528}
skipping logging after 120464 examples to avoid logging too frequently
skipping logging after 120480 examples to avoid logging too frequently
skipping logging after 120496 examples to avoid logging too frequently
train stats after 120512 examples: {'rewards_train/chosen': '-0.5973', 'rewards_train/rejected': '-0.73552', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.13818', 'logps_train/rejected': '-115.7', 'logps_train/chosen': '-131.81', 'loss/train': '0.65363', 'examples_per_second': '4.1799', 'grad_norm': '24.375', 'counters/examples': 120512, 'counters/updates': 7532}
skipping logging after 120528 examples to avoid logging too frequently
skipping logging after 120544 examples to avoid logging too frequently
skipping logging after 120560 examples to avoid logging too frequently
train stats after 120576 examples: {'rewards_train/chosen': '-0.46929', 'rewards_train/rejected': '-0.62436', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.15499', 'logps_train/rejected': '-120.88', 'logps_train/chosen': '-129.55', 'loss/train': '0.6391', 'examples_per_second': '5.3965', 'grad_norm': '24.125', 'counters/examples': 120576, 'counters/updates': 7536}
skipping logging after 120592 examples to avoid logging too frequently
skipping logging after 120608 examples to avoid logging too frequently
skipping logging after 120624 examples to avoid logging too frequently
train stats after 120640 examples: {'rewards_train/chosen': '-0.73499', 'rewards_train/rejected': '-0.82682', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.091892', 'logps_train/rejected': '-124.82', 'logps_train/chosen': '-120.05', 'loss/train': '0.68893', 'examples_per_second': '5.3468', 'grad_norm': '23.5', 'counters/examples': 120640, 'counters/updates': 7540}
skipping logging after 120656 examples to avoid logging too frequently
skipping logging after 120672 examples to avoid logging too frequently
skipping logging after 120688 examples to avoid logging too frequently
train stats after 120704 examples: {'rewards_train/chosen': '-0.61331', 'rewards_train/rejected': '-0.91186', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.29859', 'logps_train/rejected': '-120.79', 'logps_train/chosen': '-133.36', 'loss/train': '0.5952', 'examples_per_second': '5.1545', 'grad_norm': '17.125', 'counters/examples': 120704, 'counters/updates': 7544}
skipping logging after 120720 examples to avoid logging too frequently
skipping logging after 120736 examples to avoid logging too frequently
skipping logging after 120752 examples to avoid logging too frequently
train stats after 120768 examples: {'rewards_train/chosen': '-0.74577', 'rewards_train/rejected': '-0.7715', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.025772', 'logps_train/rejected': '-106.58', 'logps_train/chosen': '-136.76', 'loss/train': '0.7092', 'examples_per_second': '5.404', 'grad_norm': '20.875', 'counters/examples': 120768, 'counters/updates': 7548}
skipping logging after 120784 examples to avoid logging too frequently
skipping logging after 120800 examples to avoid logging too frequently
skipping logging after 120816 examples to avoid logging too frequently
train stats after 120832 examples: {'rewards_train/chosen': '-0.59306', 'rewards_train/rejected': '-0.83802', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.24496', 'logps_train/rejected': '-121.01', 'logps_train/chosen': '-118.13', 'loss/train': '0.60008', 'examples_per_second': '5.7888', 'grad_norm': '16.875', 'counters/examples': 120832, 'counters/updates': 7552}
skipping logging after 120848 examples to avoid logging too frequently
skipping logging after 120864 examples to avoid logging too frequently
skipping logging after 120880 examples to avoid logging too frequently
train stats after 120896 examples: {'rewards_train/chosen': '-0.6735', 'rewards_train/rejected': '-0.76541', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.091911', 'logps_train/rejected': '-158.82', 'logps_train/chosen': '-158.77', 'loss/train': '0.68407', 'examples_per_second': '4.8181', 'grad_norm': '23.625', 'counters/examples': 120896, 'counters/updates': 7556}
skipping logging after 120912 examples to avoid logging too frequently
skipping logging after 120928 examples to avoid logging too frequently
skipping logging after 120944 examples to avoid logging too frequently
train stats after 120960 examples: {'rewards_train/chosen': '-0.57491', 'rewards_train/rejected': '-0.6706', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.095657', 'logps_train/rejected': '-147.89', 'logps_train/chosen': '-159.72', 'loss/train': '0.67215', 'examples_per_second': '4.4612', 'grad_norm': '22.125', 'counters/examples': 120960, 'counters/updates': 7560}
skipping logging after 120976 examples to avoid logging too frequently
skipping logging after 120992 examples to avoid logging too frequently
skipping logging after 121008 examples to avoid logging too frequently
train stats after 121024 examples: {'rewards_train/chosen': '-0.76789', 'rewards_train/rejected': '-0.96219', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.1942', 'logps_train/rejected': '-107.39', 'logps_train/chosen': '-112', 'loss/train': '0.63287', 'examples_per_second': '4.8291', 'grad_norm': '22.625', 'counters/examples': 121024, 'counters/updates': 7564}
Running evaluation after 121024 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 121024: {'rewards_eval/chosen': '-0.59581', 'rewards_eval/rejected': '-0.71971', 'rewards_eval/accuracies': '0.55859', 'rewards_eval/margins': '0.12385', 'logps_eval/rejected': '-129.35', 'logps_eval/chosen': '-124.45', 'loss/eval': '0.66917'}
skipping logging after 121040 examples to avoid logging too frequently
skipping logging after 121056 examples to avoid logging too frequently
skipping logging after 121072 examples to avoid logging too frequently
train stats after 121088 examples: {'rewards_train/chosen': '-0.46287', 'rewards_train/rejected': '-0.67338', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.21054', 'logps_train/rejected': '-141.72', 'logps_train/chosen': '-149.34', 'loss/train': '0.61444', 'examples_per_second': '3.8759', 'grad_norm': '17.5', 'counters/examples': 121088, 'counters/updates': 7568}
skipping logging after 121104 examples to avoid logging too frequently
skipping logging after 121120 examples to avoid logging too frequently
skipping logging after 121136 examples to avoid logging too frequently
train stats after 121152 examples: {'rewards_train/chosen': '-0.58784', 'rewards_train/rejected': '-0.88484', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.29691', 'logps_train/rejected': '-167.97', 'logps_train/chosen': '-137.99', 'loss/train': '0.59383', 'examples_per_second': '5.6107', 'grad_norm': '27.5', 'counters/examples': 121152, 'counters/updates': 7572}
skipping logging after 121168 examples to avoid logging too frequently
skipping logging after 121184 examples to avoid logging too frequently
skipping logging after 121200 examples to avoid logging too frequently
train stats after 121216 examples: {'rewards_train/chosen': '-0.45848', 'rewards_train/rejected': '-0.65604', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.19768', 'logps_train/rejected': '-135.8', 'logps_train/chosen': '-139.68', 'loss/train': '0.62665', 'examples_per_second': '6.3654', 'grad_norm': '20.375', 'counters/examples': 121216, 'counters/updates': 7576}
skipping logging after 121232 examples to avoid logging too frequently
skipping logging after 121248 examples to avoid logging too frequently
skipping logging after 121264 examples to avoid logging too frequently
train stats after 121280 examples: {'rewards_train/chosen': '-0.5648', 'rewards_train/rejected': '-0.81691', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.25223', 'logps_train/rejected': '-128.59', 'logps_train/chosen': '-121.86', 'loss/train': '0.6149', 'examples_per_second': '5.4498', 'grad_norm': '19', 'counters/examples': 121280, 'counters/updates': 7580}
skipping logging after 121296 examples to avoid logging too frequently
skipping logging after 121312 examples to avoid logging too frequently
skipping logging after 121328 examples to avoid logging too frequently
train stats after 121344 examples: {'rewards_train/chosen': '-0.46679', 'rewards_train/rejected': '-0.6277', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.1611', 'logps_train/rejected': '-107.3', 'logps_train/chosen': '-148.25', 'loss/train': '0.65539', 'examples_per_second': '5.7004', 'grad_norm': '30.875', 'counters/examples': 121344, 'counters/updates': 7584}
skipping logging after 121360 examples to avoid logging too frequently
skipping logging after 121376 examples to avoid logging too frequently
skipping logging after 121392 examples to avoid logging too frequently
train stats after 121408 examples: {'rewards_train/chosen': '-0.62722', 'rewards_train/rejected': '-0.77872', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.1515', 'logps_train/rejected': '-154.07', 'logps_train/chosen': '-165.6', 'loss/train': '0.64891', 'examples_per_second': '3.9057', 'grad_norm': '21.625', 'counters/examples': 121408, 'counters/updates': 7588}
skipping logging after 121424 examples to avoid logging too frequently
skipping logging after 121440 examples to avoid logging too frequently
skipping logging after 121456 examples to avoid logging too frequently
train stats after 121472 examples: {'rewards_train/chosen': '-0.53732', 'rewards_train/rejected': '-0.77555', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.23834', 'logps_train/rejected': '-116.4', 'logps_train/chosen': '-141.25', 'loss/train': '0.61877', 'examples_per_second': '5.8037', 'grad_norm': '19.125', 'counters/examples': 121472, 'counters/updates': 7592}
skipping logging after 121488 examples to avoid logging too frequently
skipping logging after 121504 examples to avoid logging too frequently
skipping logging after 121520 examples to avoid logging too frequently
train stats after 121536 examples: {'rewards_train/chosen': '-0.60979', 'rewards_train/rejected': '-0.78987', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.17984', 'logps_train/rejected': '-129.94', 'logps_train/chosen': '-105.3', 'loss/train': '0.63643', 'examples_per_second': '5.8413', 'grad_norm': '18.625', 'counters/examples': 121536, 'counters/updates': 7596}
skipping logging after 121552 examples to avoid logging too frequently
skipping logging after 121568 examples to avoid logging too frequently
skipping logging after 121584 examples to avoid logging too frequently
train stats after 121600 examples: {'rewards_train/chosen': '-0.75282', 'rewards_train/rejected': '-0.81538', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.062561', 'logps_train/rejected': '-109.39', 'logps_train/chosen': '-127.12', 'loss/train': '0.6925', 'examples_per_second': '5.3918', 'grad_norm': '21.875', 'counters/examples': 121600, 'counters/updates': 7600}
skipping logging after 121616 examples to avoid logging too frequently
skipping logging after 121632 examples to avoid logging too frequently
skipping logging after 121648 examples to avoid logging too frequently
train stats after 121664 examples: {'rewards_train/chosen': '-0.58956', 'rewards_train/rejected': '-0.72383', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.1343', 'logps_train/rejected': '-113.52', 'logps_train/chosen': '-103.77', 'loss/train': '0.66859', 'examples_per_second': '5.8272', 'grad_norm': '22.25', 'counters/examples': 121664, 'counters/updates': 7604}
skipping logging after 121680 examples to avoid logging too frequently
skipping logging after 121696 examples to avoid logging too frequently
skipping logging after 121712 examples to avoid logging too frequently
train stats after 121728 examples: {'rewards_train/chosen': '-0.61775', 'rewards_train/rejected': '-0.69908', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.081192', 'logps_train/rejected': '-141.61', 'logps_train/chosen': '-125.64', 'loss/train': '0.69267', 'examples_per_second': '5.7836', 'grad_norm': '19.375', 'counters/examples': 121728, 'counters/updates': 7608}
skipping logging after 121744 examples to avoid logging too frequently
skipping logging after 121760 examples to avoid logging too frequently
skipping logging after 121776 examples to avoid logging too frequently
train stats after 121792 examples: {'rewards_train/chosen': '-0.57673', 'rewards_train/rejected': '-0.71515', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.13848', 'logps_train/rejected': '-130.19', 'logps_train/chosen': '-115.76', 'loss/train': '0.6619', 'examples_per_second': '5.3018', 'grad_norm': '18.25', 'counters/examples': 121792, 'counters/updates': 7612}
skipping logging after 121808 examples to avoid logging too frequently
skipping logging after 121824 examples to avoid logging too frequently
skipping logging after 121840 examples to avoid logging too frequently
train stats after 121856 examples: {'rewards_train/chosen': '-0.56888', 'rewards_train/rejected': '-0.62663', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.057785', 'logps_train/rejected': '-107.56', 'logps_train/chosen': '-119.16', 'loss/train': '0.68845', 'examples_per_second': '5.3839', 'grad_norm': '20.375', 'counters/examples': 121856, 'counters/updates': 7616}
skipping logging after 121872 examples to avoid logging too frequently
skipping logging after 121888 examples to avoid logging too frequently
skipping logging after 121904 examples to avoid logging too frequently
train stats after 121920 examples: {'rewards_train/chosen': '-0.58642', 'rewards_train/rejected': '-0.69629', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.10989', 'logps_train/rejected': '-96.727', 'logps_train/chosen': '-112.23', 'loss/train': '0.66101', 'examples_per_second': '5.3525', 'grad_norm': '19.75', 'counters/examples': 121920, 'counters/updates': 7620}
skipping logging after 121936 examples to avoid logging too frequently
skipping logging after 121952 examples to avoid logging too frequently
skipping logging after 121968 examples to avoid logging too frequently
train stats after 121984 examples: {'rewards_train/chosen': '-0.51255', 'rewards_train/rejected': '-0.63766', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.12517', 'logps_train/rejected': '-101.36', 'logps_train/chosen': '-108.51', 'loss/train': '0.6512', 'examples_per_second': '5.382', 'grad_norm': '15.375', 'counters/examples': 121984, 'counters/updates': 7624}
skipping logging after 122000 examples to avoid logging too frequently
skipping logging after 122016 examples to avoid logging too frequently
Running evaluation after 122016 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:10,  2.26s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:03,  2.13s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.89s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.88s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 122016: {'rewards_eval/chosen': '-0.47418', 'rewards_eval/rejected': '-0.60075', 'rewards_eval/accuracies': '0.55469', 'rewards_eval/margins': '0.12657', 'logps_eval/rejected': '-128.16', 'logps_eval/chosen': '-123.24', 'loss/eval': '0.66501'}
skipping logging after 122032 examples to avoid logging too frequently
train stats after 122048 examples: {'rewards_train/chosen': '-0.43297', 'rewards_train/rejected': '-0.55798', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.12496', 'logps_train/rejected': '-136.88', 'logps_train/chosen': '-115.18', 'loss/train': '0.6532', 'examples_per_second': '6.0554', 'grad_norm': '17', 'counters/examples': 122048, 'counters/updates': 7628}
skipping logging after 122064 examples to avoid logging too frequently
skipping logging after 122080 examples to avoid logging too frequently
skipping logging after 122096 examples to avoid logging too frequently
train stats after 122112 examples: {'rewards_train/chosen': '-0.50335', 'rewards_train/rejected': '-0.72658', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.22327', 'logps_train/rejected': '-111.66', 'logps_train/chosen': '-111.28', 'loss/train': '0.62878', 'examples_per_second': '4.9029', 'grad_norm': '18.875', 'counters/examples': 122112, 'counters/updates': 7632}
skipping logging after 122128 examples to avoid logging too frequently
skipping logging after 122144 examples to avoid logging too frequently
skipping logging after 122160 examples to avoid logging too frequently
train stats after 122176 examples: {'rewards_train/chosen': '-0.43131', 'rewards_train/rejected': '-0.65585', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.22461', 'logps_train/rejected': '-127.88', 'logps_train/chosen': '-108.43', 'loss/train': '0.60573', 'examples_per_second': '5.5248', 'grad_norm': '18', 'counters/examples': 122176, 'counters/updates': 7636}
skipping logging after 122192 examples to avoid logging too frequently
skipping logging after 122208 examples to avoid logging too frequently
skipping logging after 122224 examples to avoid logging too frequently
train stats after 122240 examples: {'rewards_train/chosen': '-0.39436', 'rewards_train/rejected': '-0.58193', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.18745', 'logps_train/rejected': '-121.77', 'logps_train/chosen': '-107.66', 'loss/train': '0.63162', 'examples_per_second': '5.9085', 'grad_norm': '20', 'counters/examples': 122240, 'counters/updates': 7640}
skipping logging after 122256 examples to avoid logging too frequently
skipping logging after 122272 examples to avoid logging too frequently
skipping logging after 122288 examples to avoid logging too frequently
train stats after 122304 examples: {'rewards_train/chosen': '-0.50283', 'rewards_train/rejected': '-0.59349', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.090504', 'logps_train/rejected': '-106.71', 'logps_train/chosen': '-109.51', 'loss/train': '0.6855', 'examples_per_second': '5.777', 'grad_norm': '24.625', 'counters/examples': 122304, 'counters/updates': 7644}
skipping logging after 122320 examples to avoid logging too frequently
skipping logging after 122336 examples to avoid logging too frequently
skipping logging after 122352 examples to avoid logging too frequently
train stats after 122368 examples: {'rewards_train/chosen': '-0.40462', 'rewards_train/rejected': '-0.61234', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.20773', 'logps_train/rejected': '-153.57', 'logps_train/chosen': '-122.61', 'loss/train': '0.61377', 'examples_per_second': '5.4872', 'grad_norm': '19.625', 'counters/examples': 122368, 'counters/updates': 7648}
skipping logging after 122384 examples to avoid logging too frequently
skipping logging after 122400 examples to avoid logging too frequently
skipping logging after 122416 examples to avoid logging too frequently
train stats after 122432 examples: {'rewards_train/chosen': '-0.41059', 'rewards_train/rejected': '-0.61995', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.20934', 'logps_train/rejected': '-147.8', 'logps_train/chosen': '-116.33', 'loss/train': '0.6214', 'examples_per_second': '5.2971', 'grad_norm': '17.625', 'counters/examples': 122432, 'counters/updates': 7652}
skipping logging after 122448 examples to avoid logging too frequently
skipping logging after 122464 examples to avoid logging too frequently
skipping logging after 122480 examples to avoid logging too frequently
train stats after 122496 examples: {'rewards_train/chosen': '-0.50033', 'rewards_train/rejected': '-0.6443', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.14401', 'logps_train/rejected': '-132.44', 'logps_train/chosen': '-127.09', 'loss/train': '0.65556', 'examples_per_second': '5.0359', 'grad_norm': '23.625', 'counters/examples': 122496, 'counters/updates': 7656}
skipping logging after 122512 examples to avoid logging too frequently
skipping logging after 122528 examples to avoid logging too frequently
skipping logging after 122544 examples to avoid logging too frequently
train stats after 122560 examples: {'rewards_train/chosen': '-0.45314', 'rewards_train/rejected': '-0.59291', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.13995', 'logps_train/rejected': '-155.39', 'logps_train/chosen': '-136.03', 'loss/train': '0.6499', 'examples_per_second': '4.6046', 'grad_norm': '19.875', 'counters/examples': 122560, 'counters/updates': 7660}
skipping logging after 122576 examples to avoid logging too frequently
skipping logging after 122592 examples to avoid logging too frequently
skipping logging after 122608 examples to avoid logging too frequently
train stats after 122624 examples: {'rewards_train/chosen': '-0.59199', 'rewards_train/rejected': '-0.71633', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.12434', 'logps_train/rejected': '-130.95', 'logps_train/chosen': '-120.96', 'loss/train': '0.67285', 'examples_per_second': '5.7637', 'grad_norm': '21', 'counters/examples': 122624, 'counters/updates': 7664}
skipping logging after 122640 examples to avoid logging too frequently
skipping logging after 122656 examples to avoid logging too frequently
skipping logging after 122672 examples to avoid logging too frequently
train stats after 122688 examples: {'rewards_train/chosen': '-0.55913', 'rewards_train/rejected': '-0.69286', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.1337', 'logps_train/rejected': '-148.34', 'logps_train/chosen': '-138.66', 'loss/train': '0.66238', 'examples_per_second': '4.9053', 'grad_norm': '17.375', 'counters/examples': 122688, 'counters/updates': 7668}
skipping logging after 122704 examples to avoid logging too frequently
skipping logging after 122720 examples to avoid logging too frequently
skipping logging after 122736 examples to avoid logging too frequently
train stats after 122752 examples: {'rewards_train/chosen': '-0.42867', 'rewards_train/rejected': '-0.62738', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.19876', 'logps_train/rejected': '-106.85', 'logps_train/chosen': '-117.08', 'loss/train': '0.62009', 'examples_per_second': '6.9336', 'grad_norm': '15.312', 'counters/examples': 122752, 'counters/updates': 7672}
skipping logging after 122768 examples to avoid logging too frequently
skipping logging after 122784 examples to avoid logging too frequently
skipping logging after 122800 examples to avoid logging too frequently
train stats after 122816 examples: {'rewards_train/chosen': '-0.4998', 'rewards_train/rejected': '-0.60388', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.1041', 'logps_train/rejected': '-109.55', 'logps_train/chosen': '-109.15', 'loss/train': '0.66498', 'examples_per_second': '4.8767', 'grad_norm': '17.25', 'counters/examples': 122816, 'counters/updates': 7676}
skipping logging after 122832 examples to avoid logging too frequently
skipping logging after 122848 examples to avoid logging too frequently
skipping logging after 122864 examples to avoid logging too frequently
train stats after 122880 examples: {'rewards_train/chosen': '-0.54443', 'rewards_train/rejected': '-0.68967', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.1452', 'logps_train/rejected': '-121.65', 'logps_train/chosen': '-120.13', 'loss/train': '0.66148', 'examples_per_second': '5.1561', 'grad_norm': '19.875', 'counters/examples': 122880, 'counters/updates': 7680}
skipping logging after 122896 examples to avoid logging too frequently
skipping logging after 122912 examples to avoid logging too frequently
skipping logging after 122928 examples to avoid logging too frequently
train stats after 122944 examples: {'rewards_train/chosen': '-0.41083', 'rewards_train/rejected': '-0.63875', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.22804', 'logps_train/rejected': '-165.8', 'logps_train/chosen': '-102.32', 'loss/train': '0.62257', 'examples_per_second': '5.5603', 'grad_norm': '21.875', 'counters/examples': 122944, 'counters/updates': 7684}
skipping logging after 122960 examples to avoid logging too frequently
skipping logging after 122976 examples to avoid logging too frequently
skipping logging after 122992 examples to avoid logging too frequently
train stats after 123008 examples: {'rewards_train/chosen': '-0.45337', 'rewards_train/rejected': '-0.6589', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.20565', 'logps_train/rejected': '-128.02', 'logps_train/chosen': '-134.56', 'loss/train': '0.62646', 'examples_per_second': '5.3013', 'grad_norm': '22.625', 'counters/examples': 123008, 'counters/updates': 7688}
Running evaluation after 123008 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 123008: {'rewards_eval/chosen': '-0.57592', 'rewards_eval/rejected': '-0.71427', 'rewards_eval/accuracies': '0.5625', 'rewards_eval/margins': '0.13838', 'logps_eval/rejected': '-129.3', 'logps_eval/chosen': '-124.25', 'loss/eval': '0.66856'}
skipping logging after 123024 examples to avoid logging too frequently
skipping logging after 123040 examples to avoid logging too frequently
skipping logging after 123056 examples to avoid logging too frequently
train stats after 123072 examples: {'rewards_train/chosen': '-0.54577', 'rewards_train/rejected': '-0.7965', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.25082', 'logps_train/rejected': '-117.64', 'logps_train/chosen': '-111.43', 'loss/train': '0.60164', 'examples_per_second': '5.2692', 'grad_norm': '18.375', 'counters/examples': 123072, 'counters/updates': 7692}
skipping logging after 123088 examples to avoid logging too frequently
skipping logging after 123104 examples to avoid logging too frequently
skipping logging after 123120 examples to avoid logging too frequently
train stats after 123136 examples: {'rewards_train/chosen': '-0.51553', 'rewards_train/rejected': '-0.5993', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.084068', 'logps_train/rejected': '-133.57', 'logps_train/chosen': '-138.03', 'loss/train': '0.70003', 'examples_per_second': '4.5285', 'grad_norm': '29', 'counters/examples': 123136, 'counters/updates': 7696}
skipping logging after 123152 examples to avoid logging too frequently
skipping logging after 123168 examples to avoid logging too frequently
skipping logging after 123184 examples to avoid logging too frequently
train stats after 123200 examples: {'rewards_train/chosen': '-0.59077', 'rewards_train/rejected': '-0.65112', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.060417', 'logps_train/rejected': '-130.37', 'logps_train/chosen': '-110.45', 'loss/train': '0.68246', 'examples_per_second': '5.8869', 'grad_norm': '23.125', 'counters/examples': 123200, 'counters/updates': 7700}
skipping logging after 123216 examples to avoid logging too frequently
skipping logging after 123232 examples to avoid logging too frequently
skipping logging after 123248 examples to avoid logging too frequently
train stats after 123264 examples: {'rewards_train/chosen': '-0.52579', 'rewards_train/rejected': '-0.80868', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.28263', 'logps_train/rejected': '-144.37', 'logps_train/chosen': '-137.46', 'loss/train': '0.62137', 'examples_per_second': '4.7381', 'grad_norm': '23.5', 'counters/examples': 123264, 'counters/updates': 7704}
skipping logging after 123280 examples to avoid logging too frequently
skipping logging after 123296 examples to avoid logging too frequently
skipping logging after 123312 examples to avoid logging too frequently
train stats after 123328 examples: {'rewards_train/chosen': '-0.58635', 'rewards_train/rejected': '-0.78314', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.19686', 'logps_train/rejected': '-125.92', 'logps_train/chosen': '-118.09', 'loss/train': '0.65086', 'examples_per_second': '5.6548', 'grad_norm': '20.625', 'counters/examples': 123328, 'counters/updates': 7708}
skipping logging after 123344 examples to avoid logging too frequently
skipping logging after 123360 examples to avoid logging too frequently
skipping logging after 123376 examples to avoid logging too frequently
train stats after 123392 examples: {'rewards_train/chosen': '-0.62356', 'rewards_train/rejected': '-0.83855', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.21497', 'logps_train/rejected': '-122.22', 'logps_train/chosen': '-103.05', 'loss/train': '0.64317', 'examples_per_second': '6.4989', 'grad_norm': '26.625', 'counters/examples': 123392, 'counters/updates': 7712}
skipping logging after 123408 examples to avoid logging too frequently
skipping logging after 123424 examples to avoid logging too frequently
skipping logging after 123440 examples to avoid logging too frequently
train stats after 123456 examples: {'rewards_train/chosen': '-0.54501', 'rewards_train/rejected': '-0.70796', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.16323', 'logps_train/rejected': '-112.07', 'logps_train/chosen': '-135.35', 'loss/train': '0.64447', 'examples_per_second': '4.4821', 'grad_norm': '21', 'counters/examples': 123456, 'counters/updates': 7716}
skipping logging after 123472 examples to avoid logging too frequently
skipping logging after 123488 examples to avoid logging too frequently
skipping logging after 123504 examples to avoid logging too frequently
train stats after 123520 examples: {'rewards_train/chosen': '-0.58159', 'rewards_train/rejected': '-0.70239', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.12097', 'logps_train/rejected': '-126.17', 'logps_train/chosen': '-126.67', 'loss/train': '0.67316', 'examples_per_second': '3.9835', 'grad_norm': '22.75', 'counters/examples': 123520, 'counters/updates': 7720}
skipping logging after 123536 examples to avoid logging too frequently
skipping logging after 123552 examples to avoid logging too frequently
skipping logging after 123568 examples to avoid logging too frequently
train stats after 123584 examples: {'rewards_train/chosen': '-0.40595', 'rewards_train/rejected': '-0.6901', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.28405', 'logps_train/rejected': '-118.62', 'logps_train/chosen': '-123.79', 'loss/train': '0.58189', 'examples_per_second': '5.3845', 'grad_norm': '23.5', 'counters/examples': 123584, 'counters/updates': 7724}
skipping logging after 123600 examples to avoid logging too frequently
skipping logging after 123616 examples to avoid logging too frequently
skipping logging after 123632 examples to avoid logging too frequently
train stats after 123648 examples: {'rewards_train/chosen': '-0.62549', 'rewards_train/rejected': '-0.91894', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.29354', 'logps_train/rejected': '-115.45', 'logps_train/chosen': '-130.63', 'loss/train': '0.59996', 'examples_per_second': '4.667', 'grad_norm': '22.625', 'counters/examples': 123648, 'counters/updates': 7728}
skipping logging after 123664 examples to avoid logging too frequently
skipping logging after 123680 examples to avoid logging too frequently
skipping logging after 123696 examples to avoid logging too frequently
train stats after 123712 examples: {'rewards_train/chosen': '-0.60279', 'rewards_train/rejected': '-0.78279', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.17999', 'logps_train/rejected': '-140.96', 'logps_train/chosen': '-120.91', 'loss/train': '0.65942', 'examples_per_second': '5.5173', 'grad_norm': '26.125', 'counters/examples': 123712, 'counters/updates': 7732}
skipping logging after 123728 examples to avoid logging too frequently
skipping logging after 123744 examples to avoid logging too frequently
skipping logging after 123760 examples to avoid logging too frequently
train stats after 123776 examples: {'rewards_train/chosen': '-0.36787', 'rewards_train/rejected': '-0.62167', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.25416', 'logps_train/rejected': '-119.61', 'logps_train/chosen': '-124.81', 'loss/train': '0.60552', 'examples_per_second': '5.8085', 'grad_norm': '18.375', 'counters/examples': 123776, 'counters/updates': 7736}
skipping logging after 123792 examples to avoid logging too frequently
skipping logging after 123808 examples to avoid logging too frequently
skipping logging after 123824 examples to avoid logging too frequently
train stats after 123840 examples: {'rewards_train/chosen': '-0.43368', 'rewards_train/rejected': '-0.66525', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.23169', 'logps_train/rejected': '-117.41', 'logps_train/chosen': '-121.64', 'loss/train': '0.6263', 'examples_per_second': '4.5', 'grad_norm': '22.125', 'counters/examples': 123840, 'counters/updates': 7740}
skipping logging after 123856 examples to avoid logging too frequently
skipping logging after 123872 examples to avoid logging too frequently
skipping logging after 123888 examples to avoid logging too frequently
train stats after 123904 examples: {'rewards_train/chosen': '-0.46883', 'rewards_train/rejected': '-0.63226', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.16339', 'logps_train/rejected': '-128.46', 'logps_train/chosen': '-122.74', 'loss/train': '0.64592', 'examples_per_second': '5.6483', 'grad_norm': '22.25', 'counters/examples': 123904, 'counters/updates': 7744}
skipping logging after 123920 examples to avoid logging too frequently
skipping logging after 123936 examples to avoid logging too frequently
skipping logging after 123952 examples to avoid logging too frequently
train stats after 123968 examples: {'rewards_train/chosen': '-0.59995', 'rewards_train/rejected': '-0.75301', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.15321', 'logps_train/rejected': '-115.6', 'logps_train/chosen': '-113.62', 'loss/train': '0.65695', 'examples_per_second': '5.4024', 'grad_norm': '19.25', 'counters/examples': 123968, 'counters/updates': 7748}
skipping logging after 123984 examples to avoid logging too frequently
skipping logging after 124000 examples to avoid logging too frequently
Running evaluation after 124000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:07,  2.17s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:02,  2.10s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.88s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.87s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 124000: {'rewards_eval/chosen': '-0.4723', 'rewards_eval/rejected': '-0.61007', 'rewards_eval/accuracies': '0.56055', 'rewards_eval/margins': '0.13778', 'logps_eval/rejected': '-128.26', 'logps_eval/chosen': '-123.22', 'loss/eval': '0.66481'}
skipping logging after 124016 examples to avoid logging too frequently
train stats after 124032 examples: {'rewards_train/chosen': '-0.43857', 'rewards_train/rejected': '-0.57223', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.13384', 'logps_train/rejected': '-113.33', 'logps_train/chosen': '-139.79', 'loss/train': '0.65475', 'examples_per_second': '5.008', 'grad_norm': '16.75', 'counters/examples': 124032, 'counters/updates': 7752}
skipping logging after 124048 examples to avoid logging too frequently
skipping logging after 124064 examples to avoid logging too frequently
skipping logging after 124080 examples to avoid logging too frequently
train stats after 124096 examples: {'rewards_train/chosen': '-0.36078', 'rewards_train/rejected': '-0.56107', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.20031', 'logps_train/rejected': '-123.12', 'logps_train/chosen': '-128.73', 'loss/train': '0.62509', 'examples_per_second': '4.0017', 'grad_norm': '18.75', 'counters/examples': 124096, 'counters/updates': 7756}
skipping logging after 124112 examples to avoid logging too frequently
skipping logging after 124128 examples to avoid logging too frequently
skipping logging after 124144 examples to avoid logging too frequently
train stats after 124160 examples: {'rewards_train/chosen': '-0.65331', 'rewards_train/rejected': '-0.71872', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.065525', 'logps_train/rejected': '-103.21', 'logps_train/chosen': '-111.82', 'loss/train': '0.70251', 'examples_per_second': '6.0493', 'grad_norm': '20.75', 'counters/examples': 124160, 'counters/updates': 7760}
skipping logging after 124176 examples to avoid logging too frequently
skipping logging after 124192 examples to avoid logging too frequently
skipping logging after 124208 examples to avoid logging too frequently
train stats after 124224 examples: {'rewards_train/chosen': '-0.44784', 'rewards_train/rejected': '-0.65845', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.2105', 'logps_train/rejected': '-151.67', 'logps_train/chosen': '-151.34', 'loss/train': '0.63074', 'examples_per_second': '4.9043', 'grad_norm': '22.5', 'counters/examples': 124224, 'counters/updates': 7764}
skipping logging after 124240 examples to avoid logging too frequently
skipping logging after 124256 examples to avoid logging too frequently
skipping logging after 124272 examples to avoid logging too frequently
train stats after 124288 examples: {'rewards_train/chosen': '-0.45005', 'rewards_train/rejected': '-0.73178', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.28162', 'logps_train/rejected': '-118.46', 'logps_train/chosen': '-116.3', 'loss/train': '0.59747', 'examples_per_second': '5.8094', 'grad_norm': '18.25', 'counters/examples': 124288, 'counters/updates': 7768}
skipping logging after 124304 examples to avoid logging too frequently
skipping logging after 124320 examples to avoid logging too frequently
skipping logging after 124336 examples to avoid logging too frequently
train stats after 124352 examples: {'rewards_train/chosen': '-0.42622', 'rewards_train/rejected': '-0.64106', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.21497', 'logps_train/rejected': '-121.24', 'logps_train/chosen': '-130.59', 'loss/train': '0.62488', 'examples_per_second': '4.4454', 'grad_norm': '22.375', 'counters/examples': 124352, 'counters/updates': 7772}
skipping logging after 124368 examples to avoid logging too frequently
skipping logging after 124384 examples to avoid logging too frequently
skipping logging after 124400 examples to avoid logging too frequently
train stats after 124416 examples: {'rewards_train/chosen': '-0.67389', 'rewards_train/rejected': '-0.72672', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '0.052673', 'logps_train/rejected': '-128.17', 'logps_train/chosen': '-113.17', 'loss/train': '0.70511', 'examples_per_second': '6.8694', 'grad_norm': '24.625', 'counters/examples': 124416, 'counters/updates': 7776}
skipping logging after 124432 examples to avoid logging too frequently
skipping logging after 124448 examples to avoid logging too frequently
skipping logging after 124464 examples to avoid logging too frequently
train stats after 124480 examples: {'rewards_train/chosen': '-0.5638', 'rewards_train/rejected': '-0.6958', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.13188', 'logps_train/rejected': '-119.84', 'logps_train/chosen': '-139.32', 'loss/train': '0.66507', 'examples_per_second': '5.3997', 'grad_norm': '19.375', 'counters/examples': 124480, 'counters/updates': 7780}
skipping logging after 124496 examples to avoid logging too frequently
skipping logging after 124512 examples to avoid logging too frequently
skipping logging after 124528 examples to avoid logging too frequently
train stats after 124544 examples: {'rewards_train/chosen': '-0.4689', 'rewards_train/rejected': '-0.61586', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.14689', 'logps_train/rejected': '-154.68', 'logps_train/chosen': '-133.38', 'loss/train': '0.65955', 'examples_per_second': '4.2149', 'grad_norm': '21', 'counters/examples': 124544, 'counters/updates': 7784}
skipping logging after 124560 examples to avoid logging too frequently
skipping logging after 124576 examples to avoid logging too frequently
skipping logging after 124592 examples to avoid logging too frequently
train stats after 124608 examples: {'rewards_train/chosen': '-0.5061', 'rewards_train/rejected': '-0.65779', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.15172', 'logps_train/rejected': '-123.66', 'logps_train/chosen': '-126.16', 'loss/train': '0.65521', 'examples_per_second': '4.887', 'grad_norm': '20.875', 'counters/examples': 124608, 'counters/updates': 7788}
skipping logging after 124624 examples to avoid logging too frequently
skipping logging after 124640 examples to avoid logging too frequently
skipping logging after 124656 examples to avoid logging too frequently
train stats after 124672 examples: {'rewards_train/chosen': '-0.57862', 'rewards_train/rejected': '-0.70442', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.12584', 'logps_train/rejected': '-124.46', 'logps_train/chosen': '-103.66', 'loss/train': '0.67172', 'examples_per_second': '5.031', 'grad_norm': '17.75', 'counters/examples': 124672, 'counters/updates': 7792}
skipping logging after 124688 examples to avoid logging too frequently
skipping logging after 124704 examples to avoid logging too frequently
skipping logging after 124720 examples to avoid logging too frequently
train stats after 124736 examples: {'rewards_train/chosen': '-0.56174', 'rewards_train/rejected': '-0.82728', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.2656', 'logps_train/rejected': '-122.86', 'logps_train/chosen': '-121.55', 'loss/train': '0.59366', 'examples_per_second': '5.6851', 'grad_norm': '17.875', 'counters/examples': 124736, 'counters/updates': 7796}
skipping logging after 124752 examples to avoid logging too frequently
skipping logging after 124768 examples to avoid logging too frequently
skipping logging after 124784 examples to avoid logging too frequently
train stats after 124800 examples: {'rewards_train/chosen': '-0.44711', 'rewards_train/rejected': '-0.61304', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.16586', 'logps_train/rejected': '-143.7', 'logps_train/chosen': '-126.08', 'loss/train': '0.64629', 'examples_per_second': '4.1926', 'grad_norm': '21.75', 'counters/examples': 124800, 'counters/updates': 7800}
skipping logging after 124816 examples to avoid logging too frequently
skipping logging after 124832 examples to avoid logging too frequently
skipping logging after 124848 examples to avoid logging too frequently
train stats after 124864 examples: {'rewards_train/chosen': '-0.51398', 'rewards_train/rejected': '-0.7659', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.25196', 'logps_train/rejected': '-137.15', 'logps_train/chosen': '-113.31', 'loss/train': '0.61409', 'examples_per_second': '4.3956', 'grad_norm': '23.375', 'counters/examples': 124864, 'counters/updates': 7804}
skipping logging after 124880 examples to avoid logging too frequently
skipping logging after 124896 examples to avoid logging too frequently
skipping logging after 124912 examples to avoid logging too frequently
train stats after 124928 examples: {'rewards_train/chosen': '-0.53651', 'rewards_train/rejected': '-0.61019', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.0737', 'logps_train/rejected': '-150.08', 'logps_train/chosen': '-141.44', 'loss/train': '0.67705', 'examples_per_second': '4.367', 'grad_norm': '21.5', 'counters/examples': 124928, 'counters/updates': 7808}
skipping logging after 124944 examples to avoid logging too frequently
skipping logging after 124960 examples to avoid logging too frequently
skipping logging after 124976 examples to avoid logging too frequently
train stats after 124992 examples: {'rewards_train/chosen': '-0.52973', 'rewards_train/rejected': '-0.61364', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.083702', 'logps_train/rejected': '-103.71', 'logps_train/chosen': '-152.71', 'loss/train': '0.70119', 'examples_per_second': '5.9176', 'grad_norm': '28', 'counters/examples': 124992, 'counters/updates': 7812}
Running evaluation after 124992 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 124992: {'rewards_eval/chosen': '-0.47972', 'rewards_eval/rejected': '-0.61154', 'rewards_eval/accuracies': '0.54883', 'rewards_eval/margins': '0.13178', 'logps_eval/rejected': '-128.27', 'logps_eval/chosen': '-123.29', 'loss/eval': '0.66638'}
skipping logging after 125008 examples to avoid logging too frequently
skipping logging after 125024 examples to avoid logging too frequently
skipping logging after 125040 examples to avoid logging too frequently
train stats after 125056 examples: {'rewards_train/chosen': '-0.46831', 'rewards_train/rejected': '-0.77318', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.3047', 'logps_train/rejected': '-127.39', 'logps_train/chosen': '-120.59', 'loss/train': '0.59054', 'examples_per_second': '4.8315', 'grad_norm': '19.5', 'counters/examples': 125056, 'counters/updates': 7816}
skipping logging after 125072 examples to avoid logging too frequently
skipping logging after 125088 examples to avoid logging too frequently
skipping logging after 125104 examples to avoid logging too frequently
train stats after 125120 examples: {'rewards_train/chosen': '-0.51851', 'rewards_train/rejected': '-0.71478', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.19601', 'logps_train/rejected': '-118.47', 'logps_train/chosen': '-113.29', 'loss/train': '0.65787', 'examples_per_second': '7.3581', 'grad_norm': '19.875', 'counters/examples': 125120, 'counters/updates': 7820}
skipping logging after 125136 examples to avoid logging too frequently
skipping logging after 125152 examples to avoid logging too frequently
skipping logging after 125168 examples to avoid logging too frequently
train stats after 125184 examples: {'rewards_train/chosen': '-0.36876', 'rewards_train/rejected': '-0.60431', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.23555', 'logps_train/rejected': '-120.27', 'logps_train/chosen': '-131.52', 'loss/train': '0.61011', 'examples_per_second': '4.8294', 'grad_norm': '20.5', 'counters/examples': 125184, 'counters/updates': 7824}
skipping logging after 125200 examples to avoid logging too frequently
skipping logging after 125216 examples to avoid logging too frequently
skipping logging after 125232 examples to avoid logging too frequently
train stats after 125248 examples: {'rewards_train/chosen': '-0.50009', 'rewards_train/rejected': '-0.70451', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.20444', 'logps_train/rejected': '-119.59', 'logps_train/chosen': '-130.03', 'loss/train': '0.62483', 'examples_per_second': '5.4414', 'grad_norm': '20.75', 'counters/examples': 125248, 'counters/updates': 7828}
skipping logging after 125264 examples to avoid logging too frequently
skipping logging after 125280 examples to avoid logging too frequently
skipping logging after 125296 examples to avoid logging too frequently
train stats after 125312 examples: {'rewards_train/chosen': '-0.48388', 'rewards_train/rejected': '-0.73379', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.24969', 'logps_train/rejected': '-114.37', 'logps_train/chosen': '-114.46', 'loss/train': '0.61656', 'examples_per_second': '4.6251', 'grad_norm': '19.125', 'counters/examples': 125312, 'counters/updates': 7832}
skipping logging after 125328 examples to avoid logging too frequently
skipping logging after 125344 examples to avoid logging too frequently
skipping logging after 125360 examples to avoid logging too frequently
train stats after 125376 examples: {'rewards_train/chosen': '-0.61237', 'rewards_train/rejected': '-0.73111', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.11876', 'logps_train/rejected': '-118', 'logps_train/chosen': '-135.15', 'loss/train': '0.6702', 'examples_per_second': '5.1787', 'grad_norm': '22.875', 'counters/examples': 125376, 'counters/updates': 7836}
skipping logging after 125392 examples to avoid logging too frequently
skipping logging after 125408 examples to avoid logging too frequently
skipping logging after 125424 examples to avoid logging too frequently
train stats after 125440 examples: {'rewards_train/chosen': '-0.51168', 'rewards_train/rejected': '-0.66856', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.15695', 'logps_train/rejected': '-144.17', 'logps_train/chosen': '-134.91', 'loss/train': '0.65095', 'examples_per_second': '5.2328', 'grad_norm': '19.625', 'counters/examples': 125440, 'counters/updates': 7840}
skipping logging after 125456 examples to avoid logging too frequently
skipping logging after 125472 examples to avoid logging too frequently
skipping logging after 125488 examples to avoid logging too frequently
train stats after 125504 examples: {'rewards_train/chosen': '-0.50251', 'rewards_train/rejected': '-0.7137', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.21122', 'logps_train/rejected': '-110.22', 'logps_train/chosen': '-126.56', 'loss/train': '0.6278', 'examples_per_second': '5.029', 'grad_norm': '17', 'counters/examples': 125504, 'counters/updates': 7844}
skipping logging after 125520 examples to avoid logging too frequently
skipping logging after 125536 examples to avoid logging too frequently
skipping logging after 125552 examples to avoid logging too frequently
train stats after 125568 examples: {'rewards_train/chosen': '-0.58845', 'rewards_train/rejected': '-0.64946', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.061089', 'logps_train/rejected': '-133.9', 'logps_train/chosen': '-149.8', 'loss/train': '0.69246', 'examples_per_second': '4.1731', 'grad_norm': '22.75', 'counters/examples': 125568, 'counters/updates': 7848}
skipping logging after 125584 examples to avoid logging too frequently
skipping logging after 125600 examples to avoid logging too frequently
skipping logging after 125616 examples to avoid logging too frequently
train stats after 125632 examples: {'rewards_train/chosen': '-0.61949', 'rewards_train/rejected': '-0.73217', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.11261', 'logps_train/rejected': '-119.42', 'logps_train/chosen': '-144.88', 'loss/train': '0.66629', 'examples_per_second': '4.429', 'grad_norm': '23.75', 'counters/examples': 125632, 'counters/updates': 7852}
skipping logging after 125648 examples to avoid logging too frequently
skipping logging after 125664 examples to avoid logging too frequently
skipping logging after 125680 examples to avoid logging too frequently
train stats after 125696 examples: {'rewards_train/chosen': '-0.55938', 'rewards_train/rejected': '-0.7625', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.20309', 'logps_train/rejected': '-142.16', 'logps_train/chosen': '-153.26', 'loss/train': '0.64201', 'examples_per_second': '4.409', 'grad_norm': '20.5', 'counters/examples': 125696, 'counters/updates': 7856}
skipping logging after 125712 examples to avoid logging too frequently
skipping logging after 125728 examples to avoid logging too frequently
skipping logging after 125744 examples to avoid logging too frequently
train stats after 125760 examples: {'rewards_train/chosen': '-0.49258', 'rewards_train/rejected': '-0.85511', 'rewards_train/accuracies': '0.78125', 'rewards_train/margins': '0.36238', 'logps_train/rejected': '-137.9', 'logps_train/chosen': '-141.47', 'loss/train': '0.5594', 'examples_per_second': '4.5335', 'grad_norm': '18.25', 'counters/examples': 125760, 'counters/updates': 7860}
skipping logging after 125776 examples to avoid logging too frequently
skipping logging after 125792 examples to avoid logging too frequently
skipping logging after 125808 examples to avoid logging too frequently
train stats after 125824 examples: {'rewards_train/chosen': '-0.5911', 'rewards_train/rejected': '-0.76795', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.17682', 'logps_train/rejected': '-105.59', 'logps_train/chosen': '-134.96', 'loss/train': '0.65104', 'examples_per_second': '5.6489', 'grad_norm': '18', 'counters/examples': 125824, 'counters/updates': 7864}
skipping logging after 125840 examples to avoid logging too frequently
skipping logging after 125856 examples to avoid logging too frequently
skipping logging after 125872 examples to avoid logging too frequently
train stats after 125888 examples: {'rewards_train/chosen': '-0.53747', 'rewards_train/rejected': '-0.67844', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.14079', 'logps_train/rejected': '-118.58', 'logps_train/chosen': '-140.15', 'loss/train': '0.65182', 'examples_per_second': '4.9314', 'grad_norm': '21', 'counters/examples': 125888, 'counters/updates': 7868}
skipping logging after 125904 examples to avoid logging too frequently
skipping logging after 125920 examples to avoid logging too frequently
skipping logging after 125936 examples to avoid logging too frequently
train stats after 125952 examples: {'rewards_train/chosen': '-0.59589', 'rewards_train/rejected': '-0.83282', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.23695', 'logps_train/rejected': '-98.121', 'logps_train/chosen': '-103.37', 'loss/train': '0.61644', 'examples_per_second': '6.1102', 'grad_norm': '15.25', 'counters/examples': 125952, 'counters/updates': 7872}
skipping logging after 125968 examples to avoid logging too frequently
skipping logging after 125984 examples to avoid logging too frequently
Running evaluation after 125984 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:14,  2.41s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:05,  2.19s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:55,  1.93s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.90s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.55s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.65s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 125984: {'rewards_eval/chosen': '-0.63047', 'rewards_eval/rejected': '-0.76913', 'rewards_eval/accuracies': '0.55664', 'rewards_eval/margins': '0.13862', 'logps_eval/rejected': '-129.85', 'logps_eval/chosen': '-124.8', 'loss/eval': '0.66914'}
skipping logging after 126000 examples to avoid logging too frequently
train stats after 126016 examples: {'rewards_train/chosen': '-0.5723', 'rewards_train/rejected': '-0.69787', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.12561', 'logps_train/rejected': '-135.2', 'logps_train/chosen': '-147.18', 'loss/train': '0.66847', 'examples_per_second': '4.2097', 'grad_norm': '20.375', 'counters/examples': 126016, 'counters/updates': 7876}
skipping logging after 126032 examples to avoid logging too frequently
skipping logging after 126048 examples to avoid logging too frequently
skipping logging after 126064 examples to avoid logging too frequently
train stats after 126080 examples: {'rewards_train/chosen': '-0.64566', 'rewards_train/rejected': '-0.75251', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.10691', 'logps_train/rejected': '-116.21', 'logps_train/chosen': '-123', 'loss/train': '0.66577', 'examples_per_second': '5.2447', 'grad_norm': '21.25', 'counters/examples': 126080, 'counters/updates': 7880}
skipping logging after 126096 examples to avoid logging too frequently
skipping logging after 126112 examples to avoid logging too frequently
skipping logging after 126128 examples to avoid logging too frequently
train stats after 126144 examples: {'rewards_train/chosen': '-0.45547', 'rewards_train/rejected': '-0.69677', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.24142', 'logps_train/rejected': '-117.2', 'logps_train/chosen': '-131.66', 'loss/train': '0.61507', 'examples_per_second': '5.5978', 'grad_norm': '19.875', 'counters/examples': 126144, 'counters/updates': 7884}
skipping logging after 126160 examples to avoid logging too frequently
skipping logging after 126176 examples to avoid logging too frequently
skipping logging after 126192 examples to avoid logging too frequently
train stats after 126208 examples: {'rewards_train/chosen': '-0.64434', 'rewards_train/rejected': '-1.0115', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.36713', 'logps_train/rejected': '-140.5', 'logps_train/chosen': '-146.12', 'loss/train': '0.57064', 'examples_per_second': '5.9571', 'grad_norm': '20.5', 'counters/examples': 126208, 'counters/updates': 7888}
skipping logging after 126224 examples to avoid logging too frequently
skipping logging after 126240 examples to avoid logging too frequently
skipping logging after 126256 examples to avoid logging too frequently
train stats after 126272 examples: {'rewards_train/chosen': '-0.53295', 'rewards_train/rejected': '-0.76302', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.22998', 'logps_train/rejected': '-129.75', 'logps_train/chosen': '-132.26', 'loss/train': '0.63458', 'examples_per_second': '4.9632', 'grad_norm': '19.75', 'counters/examples': 126272, 'counters/updates': 7892}
skipping logging after 126288 examples to avoid logging too frequently
skipping logging after 126304 examples to avoid logging too frequently
skipping logging after 126320 examples to avoid logging too frequently
train stats after 126336 examples: {'rewards_train/chosen': '-0.62066', 'rewards_train/rejected': '-0.84558', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.22504', 'logps_train/rejected': '-141.36', 'logps_train/chosen': '-118.73', 'loss/train': '0.62268', 'examples_per_second': '4.2508', 'grad_norm': '17.375', 'counters/examples': 126336, 'counters/updates': 7896}
skipping logging after 126352 examples to avoid logging too frequently
skipping logging after 126368 examples to avoid logging too frequently
skipping logging after 126384 examples to avoid logging too frequently
train stats after 126400 examples: {'rewards_train/chosen': '-0.57648', 'rewards_train/rejected': '-0.71414', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.1377', 'logps_train/rejected': '-128.78', 'logps_train/chosen': '-126.64', 'loss/train': '0.67451', 'examples_per_second': '4.4455', 'grad_norm': '19.125', 'counters/examples': 126400, 'counters/updates': 7900}
skipping logging after 126416 examples to avoid logging too frequently
skipping logging after 126432 examples to avoid logging too frequently
skipping logging after 126448 examples to avoid logging too frequently
train stats after 126464 examples: {'rewards_train/chosen': '-0.72268', 'rewards_train/rejected': '-0.73616', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.013607', 'logps_train/rejected': '-111.19', 'logps_train/chosen': '-114.34', 'loss/train': '0.72292', 'examples_per_second': '5.5769', 'grad_norm': '22.5', 'counters/examples': 126464, 'counters/updates': 7904}
skipping logging after 126480 examples to avoid logging too frequently
skipping logging after 126496 examples to avoid logging too frequently
skipping logging after 126512 examples to avoid logging too frequently
train stats after 126528 examples: {'rewards_train/chosen': '-0.57667', 'rewards_train/rejected': '-0.60192', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.025284', 'logps_train/rejected': '-112.66', 'logps_train/chosen': '-115.04', 'loss/train': '0.70895', 'examples_per_second': '5.7004', 'grad_norm': '22.375', 'counters/examples': 126528, 'counters/updates': 7908}
skipping logging after 126544 examples to avoid logging too frequently
skipping logging after 126560 examples to avoid logging too frequently
skipping logging after 126576 examples to avoid logging too frequently
train stats after 126592 examples: {'rewards_train/chosen': '-0.38329', 'rewards_train/rejected': '-0.58141', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.19808', 'logps_train/rejected': '-122.5', 'logps_train/chosen': '-112.09', 'loss/train': '0.64258', 'examples_per_second': '4.0459', 'grad_norm': '17.75', 'counters/examples': 126592, 'counters/updates': 7912}
skipping logging after 126608 examples to avoid logging too frequently
skipping logging after 126624 examples to avoid logging too frequently
skipping logging after 126640 examples to avoid logging too frequently
train stats after 126656 examples: {'rewards_train/chosen': '-0.65711', 'rewards_train/rejected': '-0.87703', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.21966', 'logps_train/rejected': '-138.64', 'logps_train/chosen': '-132.47', 'loss/train': '0.63478', 'examples_per_second': '4.074', 'grad_norm': '25', 'counters/examples': 126656, 'counters/updates': 7916}
skipping logging after 126672 examples to avoid logging too frequently
skipping logging after 126688 examples to avoid logging too frequently
skipping logging after 126704 examples to avoid logging too frequently
train stats after 126720 examples: {'rewards_train/chosen': '-0.52276', 'rewards_train/rejected': '-0.74696', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.22423', 'logps_train/rejected': '-114.95', 'logps_train/chosen': '-121.75', 'loss/train': '0.62777', 'examples_per_second': '4.553', 'grad_norm': '18.25', 'counters/examples': 126720, 'counters/updates': 7920}
skipping logging after 126736 examples to avoid logging too frequently
skipping logging after 126752 examples to avoid logging too frequently
skipping logging after 126768 examples to avoid logging too frequently
train stats after 126784 examples: {'rewards_train/chosen': '-0.57789', 'rewards_train/rejected': '-0.74534', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.16755', 'logps_train/rejected': '-131.9', 'logps_train/chosen': '-130.19', 'loss/train': '0.6367', 'examples_per_second': '4.0396', 'grad_norm': '18.25', 'counters/examples': 126784, 'counters/updates': 7924}
skipping logging after 126800 examples to avoid logging too frequently
skipping logging after 126816 examples to avoid logging too frequently
skipping logging after 126832 examples to avoid logging too frequently
train stats after 126848 examples: {'rewards_train/chosen': '-0.5317', 'rewards_train/rejected': '-0.6432', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.11134', 'logps_train/rejected': '-135.27', 'logps_train/chosen': '-127.13', 'loss/train': '0.66875', 'examples_per_second': '4.1498', 'grad_norm': '18.5', 'counters/examples': 126848, 'counters/updates': 7928}
skipping logging after 126864 examples to avoid logging too frequently
skipping logging after 126880 examples to avoid logging too frequently
skipping logging after 126896 examples to avoid logging too frequently
train stats after 126912 examples: {'rewards_train/chosen': '-0.43774', 'rewards_train/rejected': '-0.68426', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.24656', 'logps_train/rejected': '-160.02', 'logps_train/chosen': '-134.05', 'loss/train': '0.61542', 'examples_per_second': '4.3058', 'grad_norm': '18.875', 'counters/examples': 126912, 'counters/updates': 7932}
skipping logging after 126928 examples to avoid logging too frequently
skipping logging after 126944 examples to avoid logging too frequently
skipping logging after 126960 examples to avoid logging too frequently
train stats after 126976 examples: {'rewards_train/chosen': '-0.65406', 'rewards_train/rejected': '-0.79097', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.13688', 'logps_train/rejected': '-124.78', 'logps_train/chosen': '-134.16', 'loss/train': '0.66902', 'examples_per_second': '5.7802', 'grad_norm': '19.625', 'counters/examples': 126976, 'counters/updates': 7936}
Running evaluation after 126976 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.83s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.63s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.23s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.25s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.29s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 126976: {'rewards_eval/chosen': '-0.56988', 'rewards_eval/rejected': '-0.70687', 'rewards_eval/accuracies': '0.55078', 'rewards_eval/margins': '0.13695', 'logps_eval/rejected': '-129.22', 'logps_eval/chosen': '-124.19', 'loss/eval': '0.66487'}
skipping logging after 126992 examples to avoid logging too frequently
skipping logging after 127008 examples to avoid logging too frequently
skipping logging after 127024 examples to avoid logging too frequently
train stats after 127040 examples: {'rewards_train/chosen': '-0.62432', 'rewards_train/rejected': '-0.66639', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.042137', 'logps_train/rejected': '-153.4', 'logps_train/chosen': '-149', 'loss/train': '0.72615', 'examples_per_second': '5.1001', 'grad_norm': '25.375', 'counters/examples': 127040, 'counters/updates': 7940}
skipping logging after 127056 examples to avoid logging too frequently
skipping logging after 127072 examples to avoid logging too frequently
skipping logging after 127088 examples to avoid logging too frequently
train stats after 127104 examples: {'rewards_train/chosen': '-0.46617', 'rewards_train/rejected': '-0.62983', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.16357', 'logps_train/rejected': '-122.11', 'logps_train/chosen': '-111.05', 'loss/train': '0.64897', 'examples_per_second': '3.8298', 'grad_norm': '18.5', 'counters/examples': 127104, 'counters/updates': 7944}
skipping logging after 127120 examples to avoid logging too frequently
skipping logging after 127136 examples to avoid logging too frequently
skipping logging after 127152 examples to avoid logging too frequently
train stats after 127168 examples: {'rewards_train/chosen': '-0.44273', 'rewards_train/rejected': '-0.58656', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.14395', 'logps_train/rejected': '-131.27', 'logps_train/chosen': '-103.29', 'loss/train': '0.65639', 'examples_per_second': '5.8348', 'grad_norm': '17', 'counters/examples': 127168, 'counters/updates': 7948}
skipping logging after 127184 examples to avoid logging too frequently
skipping logging after 127200 examples to avoid logging too frequently
skipping logging after 127216 examples to avoid logging too frequently
train stats after 127232 examples: {'rewards_train/chosen': '-0.47602', 'rewards_train/rejected': '-0.71225', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.23635', 'logps_train/rejected': '-125.86', 'logps_train/chosen': '-128.15', 'loss/train': '0.63612', 'examples_per_second': '5.6508', 'grad_norm': '22.125', 'counters/examples': 127232, 'counters/updates': 7952}
skipping logging after 127248 examples to avoid logging too frequently
skipping logging after 127264 examples to avoid logging too frequently
skipping logging after 127280 examples to avoid logging too frequently
train stats after 127296 examples: {'rewards_train/chosen': '-0.51283', 'rewards_train/rejected': '-0.54574', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.033051', 'logps_train/rejected': '-119.74', 'logps_train/chosen': '-122', 'loss/train': '0.71387', 'examples_per_second': '5.855', 'grad_norm': '19.375', 'counters/examples': 127296, 'counters/updates': 7956}
skipping logging after 127312 examples to avoid logging too frequently
skipping logging after 127328 examples to avoid logging too frequently
skipping logging after 127344 examples to avoid logging too frequently
train stats after 127360 examples: {'rewards_train/chosen': '-0.47266', 'rewards_train/rejected': '-0.629', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.15634', 'logps_train/rejected': '-111.29', 'logps_train/chosen': '-123.55', 'loss/train': '0.65207', 'examples_per_second': '5.3826', 'grad_norm': '16.375', 'counters/examples': 127360, 'counters/updates': 7960}
skipping logging after 127376 examples to avoid logging too frequently
skipping logging after 127392 examples to avoid logging too frequently
skipping logging after 127408 examples to avoid logging too frequently
train stats after 127424 examples: {'rewards_train/chosen': '-0.48548', 'rewards_train/rejected': '-0.5564', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.070938', 'logps_train/rejected': '-117.82', 'logps_train/chosen': '-125.66', 'loss/train': '0.6842', 'examples_per_second': '5.2482', 'grad_norm': '21.25', 'counters/examples': 127424, 'counters/updates': 7964}
skipping logging after 127440 examples to avoid logging too frequently
skipping logging after 127456 examples to avoid logging too frequently
skipping logging after 127472 examples to avoid logging too frequently
train stats after 127488 examples: {'rewards_train/chosen': '-0.43214', 'rewards_train/rejected': '-0.50242', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.07021', 'logps_train/rejected': '-114.55', 'logps_train/chosen': '-113.48', 'loss/train': '0.67963', 'examples_per_second': '4.9447', 'grad_norm': '17.625', 'counters/examples': 127488, 'counters/updates': 7968}
skipping logging after 127504 examples to avoid logging too frequently
skipping logging after 127520 examples to avoid logging too frequently
skipping logging after 127536 examples to avoid logging too frequently
train stats after 127552 examples: {'rewards_train/chosen': '-0.41861', 'rewards_train/rejected': '-0.54302', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.12444', 'logps_train/rejected': '-119.76', 'logps_train/chosen': '-121.88', 'loss/train': '0.66264', 'examples_per_second': '4.8487', 'grad_norm': '19.875', 'counters/examples': 127552, 'counters/updates': 7972}
skipping logging after 127568 examples to avoid logging too frequently
skipping logging after 127584 examples to avoid logging too frequently
skipping logging after 127600 examples to avoid logging too frequently
train stats after 127616 examples: {'rewards_train/chosen': '-0.42015', 'rewards_train/rejected': '-0.71236', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.29217', 'logps_train/rejected': '-114.53', 'logps_train/chosen': '-115.04', 'loss/train': '0.59106', 'examples_per_second': '6.1284', 'grad_norm': '17.25', 'counters/examples': 127616, 'counters/updates': 7976}
skipping logging after 127632 examples to avoid logging too frequently
skipping logging after 127648 examples to avoid logging too frequently
skipping logging after 127664 examples to avoid logging too frequently
train stats after 127680 examples: {'rewards_train/chosen': '-0.46694', 'rewards_train/rejected': '-0.72803', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.26117', 'logps_train/rejected': '-168.79', 'logps_train/chosen': '-155.31', 'loss/train': '0.6159', 'examples_per_second': '4.31', 'grad_norm': '21.5', 'counters/examples': 127680, 'counters/updates': 7980}
skipping logging after 127696 examples to avoid logging too frequently
skipping logging after 127712 examples to avoid logging too frequently
skipping logging after 127728 examples to avoid logging too frequently
train stats after 127744 examples: {'rewards_train/chosen': '-0.38285', 'rewards_train/rejected': '-0.62938', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.24652', 'logps_train/rejected': '-114.97', 'logps_train/chosen': '-113.23', 'loss/train': '0.59544', 'examples_per_second': '4.8796', 'grad_norm': '16.125', 'counters/examples': 127744, 'counters/updates': 7984}
skipping logging after 127760 examples to avoid logging too frequently
skipping logging after 127776 examples to avoid logging too frequently
skipping logging after 127792 examples to avoid logging too frequently
train stats after 127808 examples: {'rewards_train/chosen': '-0.499', 'rewards_train/rejected': '-0.70839', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.20943', 'logps_train/rejected': '-130.46', 'logps_train/chosen': '-130.54', 'loss/train': '0.62764', 'examples_per_second': '4.2456', 'grad_norm': '17.875', 'counters/examples': 127808, 'counters/updates': 7988}
skipping logging after 127824 examples to avoid logging too frequently
skipping logging after 127840 examples to avoid logging too frequently
skipping logging after 127856 examples to avoid logging too frequently
train stats after 127872 examples: {'rewards_train/chosen': '-0.52708', 'rewards_train/rejected': '-0.61947', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.092339', 'logps_train/rejected': '-98.242', 'logps_train/chosen': '-108.7', 'loss/train': '0.67757', 'examples_per_second': '4.9246', 'grad_norm': '20', 'counters/examples': 127872, 'counters/updates': 7992}
skipping logging after 127888 examples to avoid logging too frequently
skipping logging after 127904 examples to avoid logging too frequently
skipping logging after 127920 examples to avoid logging too frequently
train stats after 127936 examples: {'rewards_train/chosen': '-0.47112', 'rewards_train/rejected': '-0.62506', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.15384', 'logps_train/rejected': '-129.36', 'logps_train/chosen': '-116.99', 'loss/train': '0.65195', 'examples_per_second': '4.3554', 'grad_norm': '17.75', 'counters/examples': 127936, 'counters/updates': 7996}
skipping logging after 127952 examples to avoid logging too frequently
skipping logging after 127968 examples to avoid logging too frequently
Running evaluation after 127968 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:08,  2.21s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:03,  2.11s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.88s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.87s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 127968: {'rewards_eval/chosen': '-0.51008', 'rewards_eval/rejected': '-0.64133', 'rewards_eval/accuracies': '0.55078', 'rewards_eval/margins': '0.13122', 'logps_eval/rejected': '-128.57', 'logps_eval/chosen': '-123.59', 'loss/eval': '0.66813'}
skipping logging after 127984 examples to avoid logging too frequently
train stats after 128000 examples: {'rewards_train/chosen': '-0.41624', 'rewards_train/rejected': '-0.74168', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.32549', 'logps_train/rejected': '-127.57', 'logps_train/chosen': '-115.08', 'loss/train': '0.5782', 'examples_per_second': '5.8053', 'grad_norm': '18.125', 'counters/examples': 128000, 'counters/updates': 8000}
skipping logging after 128016 examples to avoid logging too frequently
skipping logging after 128032 examples to avoid logging too frequently
skipping logging after 128048 examples to avoid logging too frequently
train stats after 128064 examples: {'rewards_train/chosen': '-0.6413', 'rewards_train/rejected': '-0.64827', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.0071373', 'logps_train/rejected': '-125.71', 'logps_train/chosen': '-122.77', 'loss/train': '0.73235', 'examples_per_second': '5.8082', 'grad_norm': '24.25', 'counters/examples': 128064, 'counters/updates': 8004}
skipping logging after 128080 examples to avoid logging too frequently
skipping logging after 128096 examples to avoid logging too frequently
skipping logging after 128112 examples to avoid logging too frequently
train stats after 128128 examples: {'rewards_train/chosen': '-0.479', 'rewards_train/rejected': '-0.63017', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.15101', 'logps_train/rejected': '-132.07', 'logps_train/chosen': '-158.97', 'loss/train': '0.64926', 'examples_per_second': '5.5228', 'grad_norm': '19.25', 'counters/examples': 128128, 'counters/updates': 8008}
skipping logging after 128144 examples to avoid logging too frequently
skipping logging after 128160 examples to avoid logging too frequently
skipping logging after 128176 examples to avoid logging too frequently
train stats after 128192 examples: {'rewards_train/chosen': '-0.443', 'rewards_train/rejected': '-0.70919', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.26622', 'logps_train/rejected': '-127.68', 'logps_train/chosen': '-137.47', 'loss/train': '0.62217', 'examples_per_second': '5.9723', 'grad_norm': '20', 'counters/examples': 128192, 'counters/updates': 8012}
skipping logging after 128208 examples to avoid logging too frequently
skipping logging after 128224 examples to avoid logging too frequently
skipping logging after 128240 examples to avoid logging too frequently
train stats after 128256 examples: {'rewards_train/chosen': '-0.59042', 'rewards_train/rejected': '-0.799', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.20869', 'logps_train/rejected': '-117', 'logps_train/chosen': '-106.72', 'loss/train': '0.64229', 'examples_per_second': '5.6279', 'grad_norm': '16.75', 'counters/examples': 128256, 'counters/updates': 8016}
skipping logging after 128272 examples to avoid logging too frequently
skipping logging after 128288 examples to avoid logging too frequently
skipping logging after 128304 examples to avoid logging too frequently
train stats after 128320 examples: {'rewards_train/chosen': '-0.55665', 'rewards_train/rejected': '-0.69556', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.13892', 'logps_train/rejected': '-112.12', 'logps_train/chosen': '-131.96', 'loss/train': '0.65582', 'examples_per_second': '4.8924', 'grad_norm': '22.75', 'counters/examples': 128320, 'counters/updates': 8020}
skipping logging after 128336 examples to avoid logging too frequently
skipping logging after 128352 examples to avoid logging too frequently
skipping logging after 128368 examples to avoid logging too frequently
train stats after 128384 examples: {'rewards_train/chosen': '-0.62257', 'rewards_train/rejected': '-0.85491', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.23212', 'logps_train/rejected': '-118.95', 'logps_train/chosen': '-140.51', 'loss/train': '0.63336', 'examples_per_second': '5.2316', 'grad_norm': '18.25', 'counters/examples': 128384, 'counters/updates': 8024}
skipping logging after 128400 examples to avoid logging too frequently
skipping logging after 128416 examples to avoid logging too frequently
skipping logging after 128432 examples to avoid logging too frequently
train stats after 128448 examples: {'rewards_train/chosen': '-0.48937', 'rewards_train/rejected': '-0.55974', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.070351', 'logps_train/rejected': '-140.69', 'logps_train/chosen': '-132.81', 'loss/train': '0.69423', 'examples_per_second': '4.9918', 'grad_norm': '20.625', 'counters/examples': 128448, 'counters/updates': 8028}
skipping logging after 128464 examples to avoid logging too frequently
skipping logging after 128480 examples to avoid logging too frequently
skipping logging after 128496 examples to avoid logging too frequently
train stats after 128512 examples: {'rewards_train/chosen': '-0.50112', 'rewards_train/rejected': '-0.56756', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.066559', 'logps_train/rejected': '-119.53', 'logps_train/chosen': '-156.14', 'loss/train': '0.68906', 'examples_per_second': '4.5682', 'grad_norm': '20.75', 'counters/examples': 128512, 'counters/updates': 8032}
skipping logging after 128528 examples to avoid logging too frequently
skipping logging after 128544 examples to avoid logging too frequently
skipping logging after 128560 examples to avoid logging too frequently
train stats after 128576 examples: {'rewards_train/chosen': '-0.48991', 'rewards_train/rejected': '-0.63803', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.14812', 'logps_train/rejected': '-125.31', 'logps_train/chosen': '-129.47', 'loss/train': '0.65146', 'examples_per_second': '4.2525', 'grad_norm': '18.625', 'counters/examples': 128576, 'counters/updates': 8036}
skipping logging after 128592 examples to avoid logging too frequently
skipping logging after 128608 examples to avoid logging too frequently
skipping logging after 128624 examples to avoid logging too frequently
train stats after 128640 examples: {'rewards_train/chosen': '-0.56797', 'rewards_train/rejected': '-0.71045', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.1426', 'logps_train/rejected': '-131.53', 'logps_train/chosen': '-132.66', 'loss/train': '0.65343', 'examples_per_second': '4.7654', 'grad_norm': '19', 'counters/examples': 128640, 'counters/updates': 8040}
skipping logging after 128656 examples to avoid logging too frequently
skipping logging after 128672 examples to avoid logging too frequently
skipping logging after 128688 examples to avoid logging too frequently
train stats after 128704 examples: {'rewards_train/chosen': '-0.4882', 'rewards_train/rejected': '-0.65044', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.1622', 'logps_train/rejected': '-135.66', 'logps_train/chosen': '-130.92', 'loss/train': '0.64459', 'examples_per_second': '5.6415', 'grad_norm': '21.375', 'counters/examples': 128704, 'counters/updates': 8044}
skipping logging after 128720 examples to avoid logging too frequently
skipping logging after 128736 examples to avoid logging too frequently
skipping logging after 128752 examples to avoid logging too frequently
train stats after 128768 examples: {'rewards_train/chosen': '-0.52027', 'rewards_train/rejected': '-0.69278', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.17253', 'logps_train/rejected': '-102.94', 'logps_train/chosen': '-106.66', 'loss/train': '0.64143', 'examples_per_second': '5.4266', 'grad_norm': '18.375', 'counters/examples': 128768, 'counters/updates': 8048}
skipping logging after 128784 examples to avoid logging too frequently
skipping logging after 128800 examples to avoid logging too frequently
skipping logging after 128816 examples to avoid logging too frequently
train stats after 128832 examples: {'rewards_train/chosen': '-0.58176', 'rewards_train/rejected': '-0.87726', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.29523', 'logps_train/rejected': '-147.21', 'logps_train/chosen': '-131.92', 'loss/train': '0.61469', 'examples_per_second': '5.541', 'grad_norm': '19.375', 'counters/examples': 128832, 'counters/updates': 8052}
skipping logging after 128848 examples to avoid logging too frequently
skipping logging after 128864 examples to avoid logging too frequently
skipping logging after 128880 examples to avoid logging too frequently
train stats after 128896 examples: {'rewards_train/chosen': '-0.51116', 'rewards_train/rejected': '-0.59159', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.080421', 'logps_train/rejected': '-117.94', 'logps_train/chosen': '-101.77', 'loss/train': '0.67755', 'examples_per_second': '4.2919', 'grad_norm': '18.125', 'counters/examples': 128896, 'counters/updates': 8056}
skipping logging after 128912 examples to avoid logging too frequently
skipping logging after 128928 examples to avoid logging too frequently
skipping logging after 128944 examples to avoid logging too frequently
train stats after 128960 examples: {'rewards_train/chosen': '-0.50449', 'rewards_train/rejected': '-0.64679', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.14221', 'logps_train/rejected': '-107.63', 'logps_train/chosen': '-124.23', 'loss/train': '0.65513', 'examples_per_second': '5.205', 'grad_norm': '20.5', 'counters/examples': 128960, 'counters/updates': 8060}
Running evaluation after 128960 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.53s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 128960: {'rewards_eval/chosen': '-0.53042', 'rewards_eval/rejected': '-0.66461', 'rewards_eval/accuracies': '0.55469', 'rewards_eval/margins': '0.13415', 'logps_eval/rejected': '-128.8', 'logps_eval/chosen': '-123.8', 'loss/eval': '0.66468'}
skipping logging after 128976 examples to avoid logging too frequently
skipping logging after 128992 examples to avoid logging too frequently
skipping logging after 129008 examples to avoid logging too frequently
train stats after 129024 examples: {'rewards_train/chosen': '-0.55766', 'rewards_train/rejected': '-0.61249', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.054672', 'logps_train/rejected': '-122.28', 'logps_train/chosen': '-99.179', 'loss/train': '0.69641', 'examples_per_second': '6.2293', 'grad_norm': '19', 'counters/examples': 129024, 'counters/updates': 8064}
skipping logging after 129040 examples to avoid logging too frequently
skipping logging after 129056 examples to avoid logging too frequently
skipping logging after 129072 examples to avoid logging too frequently
train stats after 129088 examples: {'rewards_train/chosen': '-0.44043', 'rewards_train/rejected': '-0.61992', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.17949', 'logps_train/rejected': '-130.04', 'logps_train/chosen': '-115.53', 'loss/train': '0.65167', 'examples_per_second': '4.3426', 'grad_norm': '16.875', 'counters/examples': 129088, 'counters/updates': 8068}
skipping logging after 129104 examples to avoid logging too frequently
skipping logging after 129120 examples to avoid logging too frequently
skipping logging after 129136 examples to avoid logging too frequently
train stats after 129152 examples: {'rewards_train/chosen': '-0.52771', 'rewards_train/rejected': '-0.64538', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.11752', 'logps_train/rejected': '-149.49', 'logps_train/chosen': '-126.36', 'loss/train': '0.66731', 'examples_per_second': '4.6454', 'grad_norm': '22.625', 'counters/examples': 129152, 'counters/updates': 8072}
skipping logging after 129168 examples to avoid logging too frequently
skipping logging after 129184 examples to avoid logging too frequently
skipping logging after 129200 examples to avoid logging too frequently
train stats after 129216 examples: {'rewards_train/chosen': '-0.51725', 'rewards_train/rejected': '-0.67636', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.15913', 'logps_train/rejected': '-101.17', 'logps_train/chosen': '-105.86', 'loss/train': '0.64444', 'examples_per_second': '5.8358', 'grad_norm': '21.625', 'counters/examples': 129216, 'counters/updates': 8076}
skipping logging after 129232 examples to avoid logging too frequently
skipping logging after 129248 examples to avoid logging too frequently
skipping logging after 129264 examples to avoid logging too frequently
train stats after 129280 examples: {'rewards_train/chosen': '-0.49821', 'rewards_train/rejected': '-0.70321', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.20509', 'logps_train/rejected': '-132.36', 'logps_train/chosen': '-134.62', 'loss/train': '0.62308', 'examples_per_second': '4.853', 'grad_norm': '17.75', 'counters/examples': 129280, 'counters/updates': 8080}
skipping logging after 129296 examples to avoid logging too frequently
skipping logging after 129312 examples to avoid logging too frequently
skipping logging after 129328 examples to avoid logging too frequently
train stats after 129344 examples: {'rewards_train/chosen': '-0.67669', 'rewards_train/rejected': '-0.83979', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.16324', 'logps_train/rejected': '-96.287', 'logps_train/chosen': '-120.47', 'loss/train': '0.65656', 'examples_per_second': '5.5653', 'grad_norm': '18.75', 'counters/examples': 129344, 'counters/updates': 8084}
skipping logging after 129360 examples to avoid logging too frequently
skipping logging after 129376 examples to avoid logging too frequently
skipping logging after 129392 examples to avoid logging too frequently
train stats after 129408 examples: {'rewards_train/chosen': '-0.58792', 'rewards_train/rejected': '-0.6826', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.094658', 'logps_train/rejected': '-108.78', 'logps_train/chosen': '-107.8', 'loss/train': '0.66904', 'examples_per_second': '5.8269', 'grad_norm': '19.75', 'counters/examples': 129408, 'counters/updates': 8088}
skipping logging after 129424 examples to avoid logging too frequently
skipping logging after 129440 examples to avoid logging too frequently
skipping logging after 129456 examples to avoid logging too frequently
train stats after 129472 examples: {'rewards_train/chosen': '-0.54505', 'rewards_train/rejected': '-0.75348', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.20836', 'logps_train/rejected': '-124.49', 'logps_train/chosen': '-104.47', 'loss/train': '0.62727', 'examples_per_second': '4.9813', 'grad_norm': '15.688', 'counters/examples': 129472, 'counters/updates': 8092}
skipping logging after 129488 examples to avoid logging too frequently
skipping logging after 129504 examples to avoid logging too frequently
skipping logging after 129520 examples to avoid logging too frequently
train stats after 129536 examples: {'rewards_train/chosen': '-0.59981', 'rewards_train/rejected': '-0.84956', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.24968', 'logps_train/rejected': '-138.02', 'logps_train/chosen': '-97.92', 'loss/train': '0.60056', 'examples_per_second': '4.6983', 'grad_norm': '17.125', 'counters/examples': 129536, 'counters/updates': 8096}
skipping logging after 129552 examples to avoid logging too frequently
skipping logging after 129568 examples to avoid logging too frequently
skipping logging after 129584 examples to avoid logging too frequently
train stats after 129600 examples: {'rewards_train/chosen': '-0.6217', 'rewards_train/rejected': '-0.73002', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.10834', 'logps_train/rejected': '-110.68', 'logps_train/chosen': '-127.7', 'loss/train': '0.69272', 'examples_per_second': '5.3234', 'grad_norm': '27.5', 'counters/examples': 129600, 'counters/updates': 8100}
skipping logging after 129616 examples to avoid logging too frequently
skipping logging after 129632 examples to avoid logging too frequently
skipping logging after 129648 examples to avoid logging too frequently
train stats after 129664 examples: {'rewards_train/chosen': '-0.59103', 'rewards_train/rejected': '-0.67422', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.083298', 'logps_train/rejected': '-116.15', 'logps_train/chosen': '-126.74', 'loss/train': '0.69012', 'examples_per_second': '5.9976', 'grad_norm': '19.375', 'counters/examples': 129664, 'counters/updates': 8104}
skipping logging after 129680 examples to avoid logging too frequently
skipping logging after 129696 examples to avoid logging too frequently
skipping logging after 129712 examples to avoid logging too frequently
train stats after 129728 examples: {'rewards_train/chosen': '-0.48487', 'rewards_train/rejected': '-0.53578', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.051144', 'logps_train/rejected': '-123.15', 'logps_train/chosen': '-140.68', 'loss/train': '0.69928', 'examples_per_second': '5.1941', 'grad_norm': '19', 'counters/examples': 129728, 'counters/updates': 8108}
skipping logging after 129744 examples to avoid logging too frequently
skipping logging after 129760 examples to avoid logging too frequently
skipping logging after 129776 examples to avoid logging too frequently
train stats after 129792 examples: {'rewards_train/chosen': '-0.43462', 'rewards_train/rejected': '-0.56017', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.12572', 'logps_train/rejected': '-118.1', 'logps_train/chosen': '-115.44', 'loss/train': '0.6561', 'examples_per_second': '4.6038', 'grad_norm': '17.5', 'counters/examples': 129792, 'counters/updates': 8112}
skipping logging after 129808 examples to avoid logging too frequently
skipping logging after 129824 examples to avoid logging too frequently
skipping logging after 129840 examples to avoid logging too frequently
train stats after 129856 examples: {'rewards_train/chosen': '-0.37518', 'rewards_train/rejected': '-0.51508', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.14016', 'logps_train/rejected': '-126.87', 'logps_train/chosen': '-132.96', 'loss/train': '0.65656', 'examples_per_second': '3.959', 'grad_norm': '17.125', 'counters/examples': 129856, 'counters/updates': 8116}
skipping logging after 129872 examples to avoid logging too frequently
skipping logging after 129888 examples to avoid logging too frequently
skipping logging after 129904 examples to avoid logging too frequently
train stats after 129920 examples: {'rewards_train/chosen': '-0.39153', 'rewards_train/rejected': '-0.50444', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.11301', 'logps_train/rejected': '-166.84', 'logps_train/chosen': '-146.89', 'loss/train': '0.65901', 'examples_per_second': '3.8064', 'grad_norm': '19.75', 'counters/examples': 129920, 'counters/updates': 8120}
skipping logging after 129936 examples to avoid logging too frequently
skipping logging after 129952 examples to avoid logging too frequently
Running evaluation after 129952 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:13,  2.38s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:05,  2.18s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:55,  1.92s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.90s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.54s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.65s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 129952: {'rewards_eval/chosen': '-0.52235', 'rewards_eval/rejected': '-0.65052', 'rewards_eval/accuracies': '0.55273', 'rewards_eval/margins': '0.12818', 'logps_eval/rejected': '-128.66', 'logps_eval/chosen': '-123.72', 'loss/eval': '0.66505'}
skipping logging after 129968 examples to avoid logging too frequently
train stats after 129984 examples: {'rewards_train/chosen': '-0.4388', 'rewards_train/rejected': '-0.58786', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.14896', 'logps_train/rejected': '-107.06', 'logps_train/chosen': '-116.98', 'loss/train': '0.6412', 'examples_per_second': '4.8896', 'grad_norm': '18.625', 'counters/examples': 129984, 'counters/updates': 8124}
skipping logging after 130000 examples to avoid logging too frequently
skipping logging after 130016 examples to avoid logging too frequently
skipping logging after 130032 examples to avoid logging too frequently
train stats after 130048 examples: {'rewards_train/chosen': '-0.55475', 'rewards_train/rejected': '-0.69223', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.13737', 'logps_train/rejected': '-120.76', 'logps_train/chosen': '-144.02', 'loss/train': '0.65067', 'examples_per_second': '4.5186', 'grad_norm': '21.625', 'counters/examples': 130048, 'counters/updates': 8128}
skipping logging after 130064 examples to avoid logging too frequently
skipping logging after 130080 examples to avoid logging too frequently
skipping logging after 130096 examples to avoid logging too frequently
train stats after 130112 examples: {'rewards_train/chosen': '-0.49681', 'rewards_train/rejected': '-0.64268', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.14583', 'logps_train/rejected': '-129.47', 'logps_train/chosen': '-124.83', 'loss/train': '0.65706', 'examples_per_second': '5.3294', 'grad_norm': '18.75', 'counters/examples': 130112, 'counters/updates': 8132}
skipping logging after 130128 examples to avoid logging too frequently
skipping logging after 130144 examples to avoid logging too frequently
skipping logging after 130160 examples to avoid logging too frequently
train stats after 130176 examples: {'rewards_train/chosen': '-0.52225', 'rewards_train/rejected': '-0.5763', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.05405', 'logps_train/rejected': '-122.64', 'logps_train/chosen': '-117.69', 'loss/train': '0.69458', 'examples_per_second': '3.9767', 'grad_norm': '19.375', 'counters/examples': 130176, 'counters/updates': 8136}
skipping logging after 130192 examples to avoid logging too frequently
skipping logging after 130208 examples to avoid logging too frequently
skipping logging after 130224 examples to avoid logging too frequently
train stats after 130240 examples: {'rewards_train/chosen': '-0.4566', 'rewards_train/rejected': '-0.64882', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.19216', 'logps_train/rejected': '-128.22', 'logps_train/chosen': '-135.01', 'loss/train': '0.6319', 'examples_per_second': '5.2523', 'grad_norm': '17', 'counters/examples': 130240, 'counters/updates': 8140}
skipping logging after 130256 examples to avoid logging too frequently
skipping logging after 130272 examples to avoid logging too frequently
skipping logging after 130288 examples to avoid logging too frequently
train stats after 130304 examples: {'rewards_train/chosen': '-0.41972', 'rewards_train/rejected': '-0.64721', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.2274', 'logps_train/rejected': '-127.58', 'logps_train/chosen': '-145.05', 'loss/train': '0.62376', 'examples_per_second': '5.6525', 'grad_norm': '18.5', 'counters/examples': 130304, 'counters/updates': 8144}
skipping logging after 130320 examples to avoid logging too frequently
skipping logging after 130336 examples to avoid logging too frequently
skipping logging after 130352 examples to avoid logging too frequently
train stats after 130368 examples: {'rewards_train/chosen': '-0.54522', 'rewards_train/rejected': '-0.77175', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.22656', 'logps_train/rejected': '-121.78', 'logps_train/chosen': '-135.4', 'loss/train': '0.61171', 'examples_per_second': '5.5347', 'grad_norm': '18.875', 'counters/examples': 130368, 'counters/updates': 8148}
skipping logging after 130384 examples to avoid logging too frequently
skipping logging after 130400 examples to avoid logging too frequently
skipping logging after 130416 examples to avoid logging too frequently
train stats after 130432 examples: {'rewards_train/chosen': '-0.35622', 'rewards_train/rejected': '-0.51806', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.16188', 'logps_train/rejected': '-121.07', 'logps_train/chosen': '-121.06', 'loss/train': '0.63651', 'examples_per_second': '4.72', 'grad_norm': '19.25', 'counters/examples': 130432, 'counters/updates': 8152}
skipping logging after 130448 examples to avoid logging too frequently
skipping logging after 130464 examples to avoid logging too frequently
skipping logging after 130480 examples to avoid logging too frequently
train stats after 130496 examples: {'rewards_train/chosen': '-0.43444', 'rewards_train/rejected': '-0.56635', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.13197', 'logps_train/rejected': '-104.04', 'logps_train/chosen': '-111.51', 'loss/train': '0.65097', 'examples_per_second': '4.6884', 'grad_norm': '16.75', 'counters/examples': 130496, 'counters/updates': 8156}
skipping logging after 130512 examples to avoid logging too frequently
skipping logging after 130528 examples to avoid logging too frequently
skipping logging after 130544 examples to avoid logging too frequently
train stats after 130560 examples: {'rewards_train/chosen': '-0.48228', 'rewards_train/rejected': '-0.57686', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.094566', 'logps_train/rejected': '-115', 'logps_train/chosen': '-127.49', 'loss/train': '0.6745', 'examples_per_second': '5.0648', 'grad_norm': '18', 'counters/examples': 130560, 'counters/updates': 8160}
skipping logging after 130576 examples to avoid logging too frequently
skipping logging after 130592 examples to avoid logging too frequently
skipping logging after 130608 examples to avoid logging too frequently
train stats after 130624 examples: {'rewards_train/chosen': '-0.55457', 'rewards_train/rejected': '-0.80427', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.24961', 'logps_train/rejected': '-127.55', 'logps_train/chosen': '-97.234', 'loss/train': '0.60475', 'examples_per_second': '5.5285', 'grad_norm': '19.875', 'counters/examples': 130624, 'counters/updates': 8164}
skipping logging after 130640 examples to avoid logging too frequently
skipping logging after 130656 examples to avoid logging too frequently
skipping logging after 130672 examples to avoid logging too frequently
train stats after 130688 examples: {'rewards_train/chosen': '-0.61146', 'rewards_train/rejected': '-0.67982', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.06834', 'logps_train/rejected': '-106.58', 'logps_train/chosen': '-134.17', 'loss/train': '0.68694', 'examples_per_second': '5.2356', 'grad_norm': '18.625', 'counters/examples': 130688, 'counters/updates': 8168}
skipping logging after 130704 examples to avoid logging too frequently
skipping logging after 130720 examples to avoid logging too frequently
skipping logging after 130736 examples to avoid logging too frequently
train stats after 130752 examples: {'rewards_train/chosen': '-0.60308', 'rewards_train/rejected': '-0.69082', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.087616', 'logps_train/rejected': '-122.86', 'logps_train/chosen': '-130.57', 'loss/train': '0.68643', 'examples_per_second': '6.0557', 'grad_norm': '22.75', 'counters/examples': 130752, 'counters/updates': 8172}
skipping logging after 130768 examples to avoid logging too frequently
skipping logging after 130784 examples to avoid logging too frequently
skipping logging after 130800 examples to avoid logging too frequently
train stats after 130816 examples: {'rewards_train/chosen': '-0.57561', 'rewards_train/rejected': '-0.6944', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.11882', 'logps_train/rejected': '-120.6', 'logps_train/chosen': '-117.05', 'loss/train': '0.67058', 'examples_per_second': '5.6434', 'grad_norm': '18.75', 'counters/examples': 130816, 'counters/updates': 8176}
skipping logging after 130832 examples to avoid logging too frequently
skipping logging after 130848 examples to avoid logging too frequently
skipping logging after 130864 examples to avoid logging too frequently
train stats after 130880 examples: {'rewards_train/chosen': '-0.48448', 'rewards_train/rejected': '-0.73196', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.24752', 'logps_train/rejected': '-136.67', 'logps_train/chosen': '-150.47', 'loss/train': '0.60114', 'examples_per_second': '4.7659', 'grad_norm': '22.875', 'counters/examples': 130880, 'counters/updates': 8180}
skipping logging after 130896 examples to avoid logging too frequently
skipping logging after 130912 examples to avoid logging too frequently
skipping logging after 130928 examples to avoid logging too frequently
train stats after 130944 examples: {'rewards_train/chosen': '-0.59912', 'rewards_train/rejected': '-0.73788', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.13881', 'logps_train/rejected': '-117.86', 'logps_train/chosen': '-108.14', 'loss/train': '0.6554', 'examples_per_second': '5.6762', 'grad_norm': '20.75', 'counters/examples': 130944, 'counters/updates': 8184}
Running evaluation after 130944 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<01:00,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.83s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.63s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 130944: {'rewards_eval/chosen': '-0.59106', 'rewards_eval/rejected': '-0.73097', 'rewards_eval/accuracies': '0.54492', 'rewards_eval/margins': '0.13988', 'logps_eval/rejected': '-129.47', 'logps_eval/chosen': '-124.4', 'loss/eval': '0.66198'}
skipping logging after 130960 examples to avoid logging too frequently
skipping logging after 130976 examples to avoid logging too frequently
skipping logging after 130992 examples to avoid logging too frequently
train stats after 131008 examples: {'rewards_train/chosen': '-0.59277', 'rewards_train/rejected': '-0.65659', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.063797', 'logps_train/rejected': '-119.91', 'logps_train/chosen': '-132.12', 'loss/train': '0.68814', 'examples_per_second': '5.0545', 'grad_norm': '17.125', 'counters/examples': 131008, 'counters/updates': 8188}
skipping logging after 131024 examples to avoid logging too frequently
skipping logging after 131040 examples to avoid logging too frequently
skipping logging after 131056 examples to avoid logging too frequently
train stats after 131072 examples: {'rewards_train/chosen': '-0.53215', 'rewards_train/rejected': '-0.6507', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.11847', 'logps_train/rejected': '-139.53', 'logps_train/chosen': '-123.04', 'loss/train': '0.66547', 'examples_per_second': '4.4006', 'grad_norm': '20.875', 'counters/examples': 131072, 'counters/updates': 8192}
skipping logging after 131088 examples to avoid logging too frequently
skipping logging after 131104 examples to avoid logging too frequently
skipping logging after 131120 examples to avoid logging too frequently
train stats after 131136 examples: {'rewards_train/chosen': '-0.52803', 'rewards_train/rejected': '-0.70178', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.17396', 'logps_train/rejected': '-107.09', 'logps_train/chosen': '-134.64', 'loss/train': '0.64079', 'examples_per_second': '5.0176', 'grad_norm': '17.25', 'counters/examples': 131136, 'counters/updates': 8196}
skipping logging after 131152 examples to avoid logging too frequently
skipping logging after 131168 examples to avoid logging too frequently
skipping logging after 131184 examples to avoid logging too frequently
train stats after 131200 examples: {'rewards_train/chosen': '-0.51641', 'rewards_train/rejected': '-0.61957', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.10307', 'logps_train/rejected': '-119.75', 'logps_train/chosen': '-115.78', 'loss/train': '0.68249', 'examples_per_second': '5.5363', 'grad_norm': '19.25', 'counters/examples': 131200, 'counters/updates': 8200}
skipping logging after 131216 examples to avoid logging too frequently
skipping logging after 131232 examples to avoid logging too frequently
skipping logging after 131248 examples to avoid logging too frequently
train stats after 131264 examples: {'rewards_train/chosen': '-0.67814', 'rewards_train/rejected': '-0.72082', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.042831', 'logps_train/rejected': '-150', 'logps_train/chosen': '-133.69', 'loss/train': '0.70465', 'examples_per_second': '5.8129', 'grad_norm': '21.875', 'counters/examples': 131264, 'counters/updates': 8204}
skipping logging after 131280 examples to avoid logging too frequently
skipping logging after 131296 examples to avoid logging too frequently
skipping logging after 131312 examples to avoid logging too frequently
train stats after 131328 examples: {'rewards_train/chosen': '-0.53331', 'rewards_train/rejected': '-0.76355', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.23025', 'logps_train/rejected': '-140.97', 'logps_train/chosen': '-126.47', 'loss/train': '0.61699', 'examples_per_second': '4.7409', 'grad_norm': '20.125', 'counters/examples': 131328, 'counters/updates': 8208}
skipping logging after 131344 examples to avoid logging too frequently
skipping logging after 131360 examples to avoid logging too frequently
skipping logging after 131376 examples to avoid logging too frequently
train stats after 131392 examples: {'rewards_train/chosen': '-0.5972', 'rewards_train/rejected': '-0.82158', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.2244', 'logps_train/rejected': '-144.42', 'logps_train/chosen': '-130.42', 'loss/train': '0.61675', 'examples_per_second': '5.0312', 'grad_norm': '24.25', 'counters/examples': 131392, 'counters/updates': 8212}
skipping logging after 131408 examples to avoid logging too frequently
skipping logging after 131424 examples to avoid logging too frequently
skipping logging after 131440 examples to avoid logging too frequently
train stats after 131456 examples: {'rewards_train/chosen': '-0.45013', 'rewards_train/rejected': '-0.78959', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.33943', 'logps_train/rejected': '-153.87', 'logps_train/chosen': '-134.91', 'loss/train': '0.58467', 'examples_per_second': '5.3712', 'grad_norm': '20.25', 'counters/examples': 131456, 'counters/updates': 8216}
skipping logging after 131472 examples to avoid logging too frequently
skipping logging after 131488 examples to avoid logging too frequently
skipping logging after 131504 examples to avoid logging too frequently
train stats after 131520 examples: {'rewards_train/chosen': '-0.62909', 'rewards_train/rejected': '-0.69973', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.070576', 'logps_train/rejected': '-127.41', 'logps_train/chosen': '-124.58', 'loss/train': '0.69554', 'examples_per_second': '4.2686', 'grad_norm': '22.125', 'counters/examples': 131520, 'counters/updates': 8220}
skipping logging after 131536 examples to avoid logging too frequently
skipping logging after 131552 examples to avoid logging too frequently
skipping logging after 131568 examples to avoid logging too frequently
train stats after 131584 examples: {'rewards_train/chosen': '-0.44503', 'rewards_train/rejected': '-0.68788', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.24284', 'logps_train/rejected': '-108.52', 'logps_train/chosen': '-111.88', 'loss/train': '0.60934', 'examples_per_second': '4.6032', 'grad_norm': '16.875', 'counters/examples': 131584, 'counters/updates': 8224}
skipping logging after 131600 examples to avoid logging too frequently
skipping logging after 131616 examples to avoid logging too frequently
skipping logging after 131632 examples to avoid logging too frequently
train stats after 131648 examples: {'rewards_train/chosen': '-0.55799', 'rewards_train/rejected': '-0.73181', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.17387', 'logps_train/rejected': '-125.38', 'logps_train/chosen': '-121.01', 'loss/train': '0.65654', 'examples_per_second': '5.622', 'grad_norm': '18.875', 'counters/examples': 131648, 'counters/updates': 8228}
skipping logging after 131664 examples to avoid logging too frequently
skipping logging after 131680 examples to avoid logging too frequently
skipping logging after 131696 examples to avoid logging too frequently
train stats after 131712 examples: {'rewards_train/chosen': '-0.64819', 'rewards_train/rejected': '-0.86946', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.22115', 'logps_train/rejected': '-104.48', 'logps_train/chosen': '-104.87', 'loss/train': '0.6142', 'examples_per_second': '6.8735', 'grad_norm': '22.125', 'counters/examples': 131712, 'counters/updates': 8232}
skipping logging after 131728 examples to avoid logging too frequently
skipping logging after 131744 examples to avoid logging too frequently
skipping logging after 131760 examples to avoid logging too frequently
train stats after 131776 examples: {'rewards_train/chosen': '-0.46158', 'rewards_train/rejected': '-0.72176', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.26018', 'logps_train/rejected': '-134.79', 'logps_train/chosen': '-115.78', 'loss/train': '0.61299', 'examples_per_second': '4.4818', 'grad_norm': '17.5', 'counters/examples': 131776, 'counters/updates': 8236}
skipping logging after 131792 examples to avoid logging too frequently
skipping logging after 131808 examples to avoid logging too frequently
skipping logging after 131824 examples to avoid logging too frequently
train stats after 131840 examples: {'rewards_train/chosen': '-0.51044', 'rewards_train/rejected': '-0.71809', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.20764', 'logps_train/rejected': '-113.46', 'logps_train/chosen': '-127.75', 'loss/train': '0.63203', 'examples_per_second': '4.6379', 'grad_norm': '20.5', 'counters/examples': 131840, 'counters/updates': 8240}
skipping logging after 131856 examples to avoid logging too frequently
skipping logging after 131872 examples to avoid logging too frequently
skipping logging after 131888 examples to avoid logging too frequently
train stats after 131904 examples: {'rewards_train/chosen': '-0.67814', 'rewards_train/rejected': '-0.7577', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.079531', 'logps_train/rejected': '-105.6', 'logps_train/chosen': '-100.82', 'loss/train': '0.6763', 'examples_per_second': '5.6583', 'grad_norm': '20.25', 'counters/examples': 131904, 'counters/updates': 8244}
skipping logging after 131920 examples to avoid logging too frequently
skipping logging after 131936 examples to avoid logging too frequently
Running evaluation after 131936 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:10,  2.27s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:04,  2.13s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.89s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.88s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 131936: {'rewards_eval/chosen': '-0.65226', 'rewards_eval/rejected': '-0.79974', 'rewards_eval/accuracies': '0.55078', 'rewards_eval/margins': '0.14754', 'logps_eval/rejected': '-130.15', 'logps_eval/chosen': '-125.02', 'loss/eval': '0.6655'}
skipping logging after 131952 examples to avoid logging too frequently
train stats after 131968 examples: {'rewards_train/chosen': '-0.6507', 'rewards_train/rejected': '-0.84474', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.19409', 'logps_train/rejected': '-121.29', 'logps_train/chosen': '-117.13', 'loss/train': '0.63811', 'examples_per_second': '5.3473', 'grad_norm': '19.75', 'counters/examples': 131968, 'counters/updates': 8248}
skipping logging after 131984 examples to avoid logging too frequently
skipping logging after 132000 examples to avoid logging too frequently
skipping logging after 132016 examples to avoid logging too frequently
train stats after 132032 examples: {'rewards_train/chosen': '-0.70253', 'rewards_train/rejected': '-0.82249', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.11996', 'logps_train/rejected': '-144.6', 'logps_train/chosen': '-127.2', 'loss/train': '0.67388', 'examples_per_second': '4.5902', 'grad_norm': '19', 'counters/examples': 132032, 'counters/updates': 8252}
skipping logging after 132048 examples to avoid logging too frequently
skipping logging after 132064 examples to avoid logging too frequently
skipping logging after 132080 examples to avoid logging too frequently
train stats after 132096 examples: {'rewards_train/chosen': '-0.659', 'rewards_train/rejected': '-0.86595', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.20679', 'logps_train/rejected': '-144.27', 'logps_train/chosen': '-124.95', 'loss/train': '0.64516', 'examples_per_second': '4.2215', 'grad_norm': '22.625', 'counters/examples': 132096, 'counters/updates': 8256}
skipping logging after 132112 examples to avoid logging too frequently
skipping logging after 132128 examples to avoid logging too frequently
skipping logging after 132144 examples to avoid logging too frequently
train stats after 132160 examples: {'rewards_train/chosen': '-0.62611', 'rewards_train/rejected': '-0.70983', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '0.083622', 'logps_train/rejected': '-134.19', 'logps_train/chosen': '-125.24', 'loss/train': '0.69781', 'examples_per_second': '4.8526', 'grad_norm': '18.5', 'counters/examples': 132160, 'counters/updates': 8260}
skipping logging after 132176 examples to avoid logging too frequently
skipping logging after 132192 examples to avoid logging too frequently
skipping logging after 132208 examples to avoid logging too frequently
train stats after 132224 examples: {'rewards_train/chosen': '-0.5924', 'rewards_train/rejected': '-0.89396', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.30166', 'logps_train/rejected': '-155.71', 'logps_train/chosen': '-125.49', 'loss/train': '0.58592', 'examples_per_second': '4.8577', 'grad_norm': '21.5', 'counters/examples': 132224, 'counters/updates': 8264}
skipping logging after 132240 examples to avoid logging too frequently
skipping logging after 132256 examples to avoid logging too frequently
skipping logging after 132272 examples to avoid logging too frequently
train stats after 132288 examples: {'rewards_train/chosen': '-0.396', 'rewards_train/rejected': '-0.63229', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.23637', 'logps_train/rejected': '-133.82', 'logps_train/chosen': '-120.67', 'loss/train': '0.60492', 'examples_per_second': '5.2666', 'grad_norm': '19.125', 'counters/examples': 132288, 'counters/updates': 8268}
skipping logging after 132304 examples to avoid logging too frequently
skipping logging after 132320 examples to avoid logging too frequently
skipping logging after 132336 examples to avoid logging too frequently
train stats after 132352 examples: {'rewards_train/chosen': '-0.57821', 'rewards_train/rejected': '-0.74556', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.16748', 'logps_train/rejected': '-125.05', 'logps_train/chosen': '-127.97', 'loss/train': '0.65413', 'examples_per_second': '4.3923', 'grad_norm': '19.625', 'counters/examples': 132352, 'counters/updates': 8272}
skipping logging after 132368 examples to avoid logging too frequently
skipping logging after 132384 examples to avoid logging too frequently
skipping logging after 132400 examples to avoid logging too frequently
train stats after 132416 examples: {'rewards_train/chosen': '-0.67132', 'rewards_train/rejected': '-0.82143', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.15017', 'logps_train/rejected': '-119.48', 'logps_train/chosen': '-118.99', 'loss/train': '0.65829', 'examples_per_second': '4.9452', 'grad_norm': '23.25', 'counters/examples': 132416, 'counters/updates': 8276}
skipping logging after 132432 examples to avoid logging too frequently
skipping logging after 132448 examples to avoid logging too frequently
skipping logging after 132464 examples to avoid logging too frequently
train stats after 132480 examples: {'rewards_train/chosen': '-0.52596', 'rewards_train/rejected': '-0.64956', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.12379', 'logps_train/rejected': '-146.46', 'logps_train/chosen': '-137.52', 'loss/train': '0.66116', 'examples_per_second': '4.4008', 'grad_norm': '18.25', 'counters/examples': 132480, 'counters/updates': 8280}
skipping logging after 132496 examples to avoid logging too frequently
skipping logging after 132512 examples to avoid logging too frequently
skipping logging after 132528 examples to avoid logging too frequently
train stats after 132544 examples: {'rewards_train/chosen': '-0.51341', 'rewards_train/rejected': '-0.68902', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.17568', 'logps_train/rejected': '-135.58', 'logps_train/chosen': '-126.13', 'loss/train': '0.63681', 'examples_per_second': '4.7323', 'grad_norm': '17.75', 'counters/examples': 132544, 'counters/updates': 8284}
skipping logging after 132560 examples to avoid logging too frequently
skipping logging after 132576 examples to avoid logging too frequently
skipping logging after 132592 examples to avoid logging too frequently
train stats after 132608 examples: {'rewards_train/chosen': '-0.57716', 'rewards_train/rejected': '-0.6358', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.058723', 'logps_train/rejected': '-134.15', 'logps_train/chosen': '-122.15', 'loss/train': '0.70596', 'examples_per_second': '5.3844', 'grad_norm': '20', 'counters/examples': 132608, 'counters/updates': 8288}
skipping logging after 132624 examples to avoid logging too frequently
skipping logging after 132640 examples to avoid logging too frequently
skipping logging after 132656 examples to avoid logging too frequently
train stats after 132672 examples: {'rewards_train/chosen': '-0.6597', 'rewards_train/rejected': '-0.68714', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.027527', 'logps_train/rejected': '-100.86', 'logps_train/chosen': '-115.24', 'loss/train': '0.70743', 'examples_per_second': '5.234', 'grad_norm': '25.75', 'counters/examples': 132672, 'counters/updates': 8292}
skipping logging after 132688 examples to avoid logging too frequently
skipping logging after 132704 examples to avoid logging too frequently
skipping logging after 132720 examples to avoid logging too frequently
train stats after 132736 examples: {'rewards_train/chosen': '-0.43064', 'rewards_train/rejected': '-0.56414', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.13364', 'logps_train/rejected': '-110.02', 'logps_train/chosen': '-125.64', 'loss/train': '0.64813', 'examples_per_second': '4.3238', 'grad_norm': '21.375', 'counters/examples': 132736, 'counters/updates': 8296}
skipping logging after 132752 examples to avoid logging too frequently
skipping logging after 132768 examples to avoid logging too frequently
skipping logging after 132784 examples to avoid logging too frequently
train stats after 132800 examples: {'rewards_train/chosen': '-0.49942', 'rewards_train/rejected': '-0.66753', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.16814', 'logps_train/rejected': '-136.89', 'logps_train/chosen': '-129.24', 'loss/train': '0.6526', 'examples_per_second': '4.6538', 'grad_norm': '18.875', 'counters/examples': 132800, 'counters/updates': 8300}
skipping logging after 132816 examples to avoid logging too frequently
skipping logging after 132832 examples to avoid logging too frequently
skipping logging after 132848 examples to avoid logging too frequently
train stats after 132864 examples: {'rewards_train/chosen': '-0.57794', 'rewards_train/rejected': '-0.60843', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.030609', 'logps_train/rejected': '-172.83', 'logps_train/chosen': '-144.04', 'loss/train': '0.70496', 'examples_per_second': '5.2275', 'grad_norm': '25.375', 'counters/examples': 132864, 'counters/updates': 8304}
skipping logging after 132880 examples to avoid logging too frequently
skipping logging after 132896 examples to avoid logging too frequently
skipping logging after 132912 examples to avoid logging too frequently
train stats after 132928 examples: {'rewards_train/chosen': '-0.44298', 'rewards_train/rejected': '-0.57167', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.12862', 'logps_train/rejected': '-143.58', 'logps_train/chosen': '-135.88', 'loss/train': '0.6631', 'examples_per_second': '4.6064', 'grad_norm': '21.25', 'counters/examples': 132928, 'counters/updates': 8308}
Running evaluation after 132928 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 132928: {'rewards_eval/chosen': '-0.46477', 'rewards_eval/rejected': '-0.60365', 'rewards_eval/accuracies': '0.56055', 'rewards_eval/margins': '0.1389', 'logps_eval/rejected': '-128.19', 'logps_eval/chosen': '-123.14', 'loss/eval': '0.66064'}
skipping logging after 132944 examples to avoid logging too frequently
skipping logging after 132960 examples to avoid logging too frequently
skipping logging after 132976 examples to avoid logging too frequently
train stats after 132992 examples: {'rewards_train/chosen': '-0.49646', 'rewards_train/rejected': '-0.6572', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.16072', 'logps_train/rejected': '-112.49', 'logps_train/chosen': '-126.19', 'loss/train': '0.65651', 'examples_per_second': '4.6414', 'grad_norm': '21.125', 'counters/examples': 132992, 'counters/updates': 8312}
skipping logging after 133008 examples to avoid logging too frequently
skipping logging after 133024 examples to avoid logging too frequently
skipping logging after 133040 examples to avoid logging too frequently
train stats after 133056 examples: {'rewards_train/chosen': '-0.46651', 'rewards_train/rejected': '-0.60633', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.13966', 'logps_train/rejected': '-110.51', 'logps_train/chosen': '-121.65', 'loss/train': '0.66501', 'examples_per_second': '4.9941', 'grad_norm': '18.625', 'counters/examples': 133056, 'counters/updates': 8316}
skipping logging after 133072 examples to avoid logging too frequently
skipping logging after 133088 examples to avoid logging too frequently
skipping logging after 133104 examples to avoid logging too frequently
train stats after 133120 examples: {'rewards_train/chosen': '-0.47602', 'rewards_train/rejected': '-0.63269', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.15653', 'logps_train/rejected': '-121.73', 'logps_train/chosen': '-144.29', 'loss/train': '0.65753', 'examples_per_second': '4.4929', 'grad_norm': '21.375', 'counters/examples': 133120, 'counters/updates': 8320}
skipping logging after 133136 examples to avoid logging too frequently
skipping logging after 133152 examples to avoid logging too frequently
skipping logging after 133168 examples to avoid logging too frequently
train stats after 133184 examples: {'rewards_train/chosen': '-0.46852', 'rewards_train/rejected': '-0.60347', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.13498', 'logps_train/rejected': '-119.04', 'logps_train/chosen': '-111.36', 'loss/train': '0.66487', 'examples_per_second': '4.4675', 'grad_norm': '17.625', 'counters/examples': 133184, 'counters/updates': 8324}
skipping logging after 133200 examples to avoid logging too frequently
skipping logging after 133216 examples to avoid logging too frequently
skipping logging after 133232 examples to avoid logging too frequently
train stats after 133248 examples: {'rewards_train/chosen': '-0.4482', 'rewards_train/rejected': '-0.56457', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.11629', 'logps_train/rejected': '-128.59', 'logps_train/chosen': '-106.47', 'loss/train': '0.6635', 'examples_per_second': '5.3183', 'grad_norm': '18', 'counters/examples': 133248, 'counters/updates': 8328}
skipping logging after 133264 examples to avoid logging too frequently
skipping logging after 133280 examples to avoid logging too frequently
skipping logging after 133296 examples to avoid logging too frequently
train stats after 133312 examples: {'rewards_train/chosen': '-0.44668', 'rewards_train/rejected': '-0.55621', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.10951', 'logps_train/rejected': '-123.95', 'logps_train/chosen': '-103.29', 'loss/train': '0.66513', 'examples_per_second': '5.6244', 'grad_norm': '18.25', 'counters/examples': 133312, 'counters/updates': 8332}
skipping logging after 133328 examples to avoid logging too frequently
skipping logging after 133344 examples to avoid logging too frequently
skipping logging after 133360 examples to avoid logging too frequently
train stats after 133376 examples: {'rewards_train/chosen': '-0.33917', 'rewards_train/rejected': '-0.50518', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.16603', 'logps_train/rejected': '-108.6', 'logps_train/chosen': '-149.12', 'loss/train': '0.64391', 'examples_per_second': '4.6078', 'grad_norm': '21.5', 'counters/examples': 133376, 'counters/updates': 8336}
skipping logging after 133392 examples to avoid logging too frequently
skipping logging after 133408 examples to avoid logging too frequently
skipping logging after 133424 examples to avoid logging too frequently
train stats after 133440 examples: {'rewards_train/chosen': '-0.47926', 'rewards_train/rejected': '-0.64212', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.16293', 'logps_train/rejected': '-116.99', 'logps_train/chosen': '-116.68', 'loss/train': '0.66164', 'examples_per_second': '5.9667', 'grad_norm': '18.875', 'counters/examples': 133440, 'counters/updates': 8340}
skipping logging after 133456 examples to avoid logging too frequently
skipping logging after 133472 examples to avoid logging too frequently
skipping logging after 133488 examples to avoid logging too frequently
train stats after 133504 examples: {'rewards_train/chosen': '-0.56421', 'rewards_train/rejected': '-0.69551', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.13145', 'logps_train/rejected': '-150.32', 'logps_train/chosen': '-143.89', 'loss/train': '0.66995', 'examples_per_second': '4.1797', 'grad_norm': '21', 'counters/examples': 133504, 'counters/updates': 8344}
skipping logging after 133520 examples to avoid logging too frequently
skipping logging after 133536 examples to avoid logging too frequently
skipping logging after 133552 examples to avoid logging too frequently
train stats after 133568 examples: {'rewards_train/chosen': '-0.39047', 'rewards_train/rejected': '-0.47976', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.08942', 'logps_train/rejected': '-119.34', 'logps_train/chosen': '-113.71', 'loss/train': '0.67886', 'examples_per_second': '5.2179', 'grad_norm': '17.125', 'counters/examples': 133568, 'counters/updates': 8348}
skipping logging after 133584 examples to avoid logging too frequently
skipping logging after 133600 examples to avoid logging too frequently
skipping logging after 133616 examples to avoid logging too frequently
train stats after 133632 examples: {'rewards_train/chosen': '-0.58238', 'rewards_train/rejected': '-0.72666', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.14431', 'logps_train/rejected': '-112.67', 'logps_train/chosen': '-130.45', 'loss/train': '0.64923', 'examples_per_second': '4.9619', 'grad_norm': '17.875', 'counters/examples': 133632, 'counters/updates': 8352}
skipping logging after 133648 examples to avoid logging too frequently
skipping logging after 133664 examples to avoid logging too frequently
skipping logging after 133680 examples to avoid logging too frequently
train stats after 133696 examples: {'rewards_train/chosen': '-0.42986', 'rewards_train/rejected': '-0.63227', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.20253', 'logps_train/rejected': '-115.59', 'logps_train/chosen': '-127.3', 'loss/train': '0.62471', 'examples_per_second': '5.7425', 'grad_norm': '17.25', 'counters/examples': 133696, 'counters/updates': 8356}
skipping logging after 133712 examples to avoid logging too frequently
skipping logging after 133728 examples to avoid logging too frequently
skipping logging after 133744 examples to avoid logging too frequently
train stats after 133760 examples: {'rewards_train/chosen': '-0.36794', 'rewards_train/rejected': '-0.58691', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.2189', 'logps_train/rejected': '-132.01', 'logps_train/chosen': '-132.5', 'loss/train': '0.61613', 'examples_per_second': '4.6312', 'grad_norm': '18', 'counters/examples': 133760, 'counters/updates': 8360}
skipping logging after 133776 examples to avoid logging too frequently
skipping logging after 133792 examples to avoid logging too frequently
skipping logging after 133808 examples to avoid logging too frequently
train stats after 133824 examples: {'rewards_train/chosen': '-0.50793', 'rewards_train/rejected': '-0.62807', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.12009', 'logps_train/rejected': '-128.48', 'logps_train/chosen': '-129.65', 'loss/train': '0.68873', 'examples_per_second': '5.6633', 'grad_norm': '21.5', 'counters/examples': 133824, 'counters/updates': 8364}
skipping logging after 133840 examples to avoid logging too frequently
skipping logging after 133856 examples to avoid logging too frequently
skipping logging after 133872 examples to avoid logging too frequently
train stats after 133888 examples: {'rewards_train/chosen': '-0.37667', 'rewards_train/rejected': '-0.54591', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.16933', 'logps_train/rejected': '-131.27', 'logps_train/chosen': '-101.78', 'loss/train': '0.64055', 'examples_per_second': '5.3911', 'grad_norm': '21', 'counters/examples': 133888, 'counters/updates': 8368}
skipping logging after 133904 examples to avoid logging too frequently
skipping logging after 133920 examples to avoid logging too frequently
Running evaluation after 133920 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:14,  2.40s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:05,  2.19s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:55,  1.93s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.90s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.55s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.65s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 133920: {'rewards_eval/chosen': '-0.44353', 'rewards_eval/rejected': '-0.57758', 'rewards_eval/accuracies': '0.56055', 'rewards_eval/margins': '0.134', 'logps_eval/rejected': '-127.93', 'logps_eval/chosen': '-122.93', 'loss/eval': '0.66119'}
skipping logging after 133936 examples to avoid logging too frequently
train stats after 133952 examples: {'rewards_train/chosen': '-0.47489', 'rewards_train/rejected': '-0.61541', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.14052', 'logps_train/rejected': '-113.1', 'logps_train/chosen': '-114.02', 'loss/train': '0.65189', 'examples_per_second': '5.7923', 'grad_norm': '23.25', 'counters/examples': 133952, 'counters/updates': 8372}
skipping logging after 133968 examples to avoid logging too frequently
skipping logging after 133984 examples to avoid logging too frequently
skipping logging after 134000 examples to avoid logging too frequently
train stats after 134016 examples: {'rewards_train/chosen': '-0.47635', 'rewards_train/rejected': '-0.60899', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.13248', 'logps_train/rejected': '-118.72', 'logps_train/chosen': '-123.97', 'loss/train': '0.66104', 'examples_per_second': '5.2206', 'grad_norm': '18.625', 'counters/examples': 134016, 'counters/updates': 8376}
skipping logging after 134032 examples to avoid logging too frequently
skipping logging after 134048 examples to avoid logging too frequently
skipping logging after 134064 examples to avoid logging too frequently
train stats after 134080 examples: {'rewards_train/chosen': '-0.44283', 'rewards_train/rejected': '-0.64543', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.20267', 'logps_train/rejected': '-135', 'logps_train/chosen': '-118.3', 'loss/train': '0.63847', 'examples_per_second': '4.3178', 'grad_norm': '18.25', 'counters/examples': 134080, 'counters/updates': 8380}
skipping logging after 134096 examples to avoid logging too frequently
skipping logging after 134112 examples to avoid logging too frequently
skipping logging after 134128 examples to avoid logging too frequently
train stats after 134144 examples: {'rewards_train/chosen': '-0.40099', 'rewards_train/rejected': '-0.52428', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.12337', 'logps_train/rejected': '-132.8', 'logps_train/chosen': '-124.61', 'loss/train': '0.66232', 'examples_per_second': '3.9877', 'grad_norm': '19.375', 'counters/examples': 134144, 'counters/updates': 8384}
skipping logging after 134160 examples to avoid logging too frequently
skipping logging after 134176 examples to avoid logging too frequently
skipping logging after 134192 examples to avoid logging too frequently
train stats after 134208 examples: {'rewards_train/chosen': '-0.47567', 'rewards_train/rejected': '-0.63113', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.15557', 'logps_train/rejected': '-120.21', 'logps_train/chosen': '-101.96', 'loss/train': '0.6484', 'examples_per_second': '5.8121', 'grad_norm': '16.75', 'counters/examples': 134208, 'counters/updates': 8388}
skipping logging after 134224 examples to avoid logging too frequently
skipping logging after 134240 examples to avoid logging too frequently
skipping logging after 134256 examples to avoid logging too frequently
train stats after 134272 examples: {'rewards_train/chosen': '-0.40878', 'rewards_train/rejected': '-0.54653', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.13786', 'logps_train/rejected': '-111.3', 'logps_train/chosen': '-120.21', 'loss/train': '0.65988', 'examples_per_second': '5.4802', 'grad_norm': '17.875', 'counters/examples': 134272, 'counters/updates': 8392}
skipping logging after 134288 examples to avoid logging too frequently
skipping logging after 134304 examples to avoid logging too frequently
skipping logging after 134320 examples to avoid logging too frequently
train stats after 134336 examples: {'rewards_train/chosen': '-0.36504', 'rewards_train/rejected': '-0.5888', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.22406', 'logps_train/rejected': '-123.17', 'logps_train/chosen': '-115.14', 'loss/train': '0.61444', 'examples_per_second': '4.7947', 'grad_norm': '18', 'counters/examples': 134336, 'counters/updates': 8396}
skipping logging after 134352 examples to avoid logging too frequently
skipping logging after 134368 examples to avoid logging too frequently
skipping logging after 134384 examples to avoid logging too frequently
train stats after 134400 examples: {'rewards_train/chosen': '-0.45281', 'rewards_train/rejected': '-0.51847', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.065556', 'logps_train/rejected': '-128.11', 'logps_train/chosen': '-119.24', 'loss/train': '0.68869', 'examples_per_second': '5.7066', 'grad_norm': '19.5', 'counters/examples': 134400, 'counters/updates': 8400}
skipping logging after 134416 examples to avoid logging too frequently
skipping logging after 134432 examples to avoid logging too frequently
skipping logging after 134448 examples to avoid logging too frequently
train stats after 134464 examples: {'rewards_train/chosen': '-0.46988', 'rewards_train/rejected': '-0.71245', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.24256', 'logps_train/rejected': '-113.71', 'logps_train/chosen': '-134.93', 'loss/train': '0.61369', 'examples_per_second': '5.6908', 'grad_norm': '17.625', 'counters/examples': 134464, 'counters/updates': 8404}
skipping logging after 134480 examples to avoid logging too frequently
skipping logging after 134496 examples to avoid logging too frequently
skipping logging after 134512 examples to avoid logging too frequently
train stats after 134528 examples: {'rewards_train/chosen': '-0.48275', 'rewards_train/rejected': '-0.64302', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.16026', 'logps_train/rejected': '-137.39', 'logps_train/chosen': '-111.44', 'loss/train': '0.64397', 'examples_per_second': '4.7508', 'grad_norm': '18', 'counters/examples': 134528, 'counters/updates': 8408}
skipping logging after 134544 examples to avoid logging too frequently
skipping logging after 134560 examples to avoid logging too frequently
skipping logging after 134576 examples to avoid logging too frequently
train stats after 134592 examples: {'rewards_train/chosen': '-0.44748', 'rewards_train/rejected': '-0.61254', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.16502', 'logps_train/rejected': '-120.26', 'logps_train/chosen': '-102.02', 'loss/train': '0.6434', 'examples_per_second': '6.2079', 'grad_norm': '16.5', 'counters/examples': 134592, 'counters/updates': 8412}
skipping logging after 134608 examples to avoid logging too frequently
skipping logging after 134624 examples to avoid logging too frequently
skipping logging after 134640 examples to avoid logging too frequently
train stats after 134656 examples: {'rewards_train/chosen': '-0.4465', 'rewards_train/rejected': '-0.60676', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.16036', 'logps_train/rejected': '-136.96', 'logps_train/chosen': '-141.33', 'loss/train': '0.65178', 'examples_per_second': '5.8371', 'grad_norm': '19.25', 'counters/examples': 134656, 'counters/updates': 8416}
skipping logging after 134672 examples to avoid logging too frequently
skipping logging after 134688 examples to avoid logging too frequently
skipping logging after 134704 examples to avoid logging too frequently
train stats after 134720 examples: {'rewards_train/chosen': '-0.44979', 'rewards_train/rejected': '-0.57458', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.12476', 'logps_train/rejected': '-122.28', 'logps_train/chosen': '-133.97', 'loss/train': '0.6629', 'examples_per_second': '5.3144', 'grad_norm': '19.875', 'counters/examples': 134720, 'counters/updates': 8420}
skipping logging after 134736 examples to avoid logging too frequently
skipping logging after 134752 examples to avoid logging too frequently
skipping logging after 134768 examples to avoid logging too frequently
train stats after 134784 examples: {'rewards_train/chosen': '-0.48724', 'rewards_train/rejected': '-0.65434', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.16695', 'logps_train/rejected': '-147.57', 'logps_train/chosen': '-144.61', 'loss/train': '0.64626', 'examples_per_second': '4.6276', 'grad_norm': '21.5', 'counters/examples': 134784, 'counters/updates': 8424}
skipping logging after 134800 examples to avoid logging too frequently
skipping logging after 134816 examples to avoid logging too frequently
skipping logging after 134832 examples to avoid logging too frequently
train stats after 134848 examples: {'rewards_train/chosen': '-0.52567', 'rewards_train/rejected': '-0.79636', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.27081', 'logps_train/rejected': '-110.65', 'logps_train/chosen': '-131.12', 'loss/train': '0.6069', 'examples_per_second': '4.8986', 'grad_norm': '18', 'counters/examples': 134848, 'counters/updates': 8428}
skipping logging after 134864 examples to avoid logging too frequently
skipping logging after 134880 examples to avoid logging too frequently
skipping logging after 134896 examples to avoid logging too frequently
train stats after 134912 examples: {'rewards_train/chosen': '-0.38097', 'rewards_train/rejected': '-0.54253', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.16153', 'logps_train/rejected': '-153.26', 'logps_train/chosen': '-137.78', 'loss/train': '0.65611', 'examples_per_second': '4.5125', 'grad_norm': '19.5', 'counters/examples': 134912, 'counters/updates': 8432}
Running evaluation after 134912 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 134912: {'rewards_eval/chosen': '-0.52764', 'rewards_eval/rejected': '-0.66776', 'rewards_eval/accuracies': '0.57617', 'rewards_eval/margins': '0.14011', 'logps_eval/rejected': '-128.83', 'logps_eval/chosen': '-123.77', 'loss/eval': '0.66371'}
skipping logging after 134928 examples to avoid logging too frequently
skipping logging after 134944 examples to avoid logging too frequently
skipping logging after 134960 examples to avoid logging too frequently
train stats after 134976 examples: {'rewards_train/chosen': '-0.66515', 'rewards_train/rejected': '-0.84593', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.18092', 'logps_train/rejected': '-126.7', 'logps_train/chosen': '-133.97', 'loss/train': '0.65782', 'examples_per_second': '4.7492', 'grad_norm': '21.875', 'counters/examples': 134976, 'counters/updates': 8436}
skipping logging after 134992 examples to avoid logging too frequently
skipping logging after 135008 examples to avoid logging too frequently
skipping logging after 135024 examples to avoid logging too frequently
train stats after 135040 examples: {'rewards_train/chosen': '-0.45062', 'rewards_train/rejected': '-0.76327', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.31252', 'logps_train/rejected': '-122.85', 'logps_train/chosen': '-136.72', 'loss/train': '0.59666', 'examples_per_second': '5.1938', 'grad_norm': '17.75', 'counters/examples': 135040, 'counters/updates': 8440}
skipping logging after 135056 examples to avoid logging too frequently
skipping logging after 135072 examples to avoid logging too frequently
skipping logging after 135088 examples to avoid logging too frequently
train stats after 135104 examples: {'rewards_train/chosen': '-0.55991', 'rewards_train/rejected': '-0.72867', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.16888', 'logps_train/rejected': '-138.77', 'logps_train/chosen': '-137.57', 'loss/train': '0.65522', 'examples_per_second': '4.4027', 'grad_norm': '22.75', 'counters/examples': 135104, 'counters/updates': 8444}
skipping logging after 135120 examples to avoid logging too frequently
skipping logging after 135136 examples to avoid logging too frequently
skipping logging after 135152 examples to avoid logging too frequently
train stats after 135168 examples: {'rewards_train/chosen': '-0.59048', 'rewards_train/rejected': '-0.85432', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.26379', 'logps_train/rejected': '-149.43', 'logps_train/chosen': '-128.34', 'loss/train': '0.61642', 'examples_per_second': '5.008', 'grad_norm': '21.75', 'counters/examples': 135168, 'counters/updates': 8448}
skipping logging after 135184 examples to avoid logging too frequently
skipping logging after 135200 examples to avoid logging too frequently
skipping logging after 135216 examples to avoid logging too frequently
train stats after 135232 examples: {'rewards_train/chosen': '-0.46918', 'rewards_train/rejected': '-0.70549', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.23629', 'logps_train/rejected': '-125.05', 'logps_train/chosen': '-114.72', 'loss/train': '0.60092', 'examples_per_second': '5.253', 'grad_norm': '19.875', 'counters/examples': 135232, 'counters/updates': 8452}
skipping logging after 135248 examples to avoid logging too frequently
skipping logging after 135264 examples to avoid logging too frequently
skipping logging after 135280 examples to avoid logging too frequently
train stats after 135296 examples: {'rewards_train/chosen': '-0.62317', 'rewards_train/rejected': '-0.74341', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.12025', 'logps_train/rejected': '-115.9', 'logps_train/chosen': '-129.72', 'loss/train': '0.66188', 'examples_per_second': '6.1805', 'grad_norm': '19.75', 'counters/examples': 135296, 'counters/updates': 8456}
skipping logging after 135312 examples to avoid logging too frequently
skipping logging after 135328 examples to avoid logging too frequently
skipping logging after 135344 examples to avoid logging too frequently
train stats after 135360 examples: {'rewards_train/chosen': '-0.52048', 'rewards_train/rejected': '-0.82645', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.30598', 'logps_train/rejected': '-126.12', 'logps_train/chosen': '-133.45', 'loss/train': '0.59198', 'examples_per_second': '5.0081', 'grad_norm': '20.375', 'counters/examples': 135360, 'counters/updates': 8460}
skipping logging after 135376 examples to avoid logging too frequently
skipping logging after 135392 examples to avoid logging too frequently
skipping logging after 135408 examples to avoid logging too frequently
train stats after 135424 examples: {'rewards_train/chosen': '-0.61826', 'rewards_train/rejected': '-0.78216', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.16386', 'logps_train/rejected': '-111.78', 'logps_train/chosen': '-128.47', 'loss/train': '0.65341', 'examples_per_second': '4.6236', 'grad_norm': '32.75', 'counters/examples': 135424, 'counters/updates': 8464}
skipping logging after 135440 examples to avoid logging too frequently
skipping logging after 135456 examples to avoid logging too frequently
skipping logging after 135472 examples to avoid logging too frequently
train stats after 135488 examples: {'rewards_train/chosen': '-0.61274', 'rewards_train/rejected': '-0.82289', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.21019', 'logps_train/rejected': '-122.18', 'logps_train/chosen': '-141.55', 'loss/train': '0.63155', 'examples_per_second': '4.6018', 'grad_norm': '18.375', 'counters/examples': 135488, 'counters/updates': 8468}
skipping logging after 135504 examples to avoid logging too frequently
skipping logging after 135520 examples to avoid logging too frequently
skipping logging after 135536 examples to avoid logging too frequently
train stats after 135552 examples: {'rewards_train/chosen': '-0.55814', 'rewards_train/rejected': '-0.78562', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.2275', 'logps_train/rejected': '-112.96', 'logps_train/chosen': '-110.25', 'loss/train': '0.62408', 'examples_per_second': '5.4311', 'grad_norm': '17', 'counters/examples': 135552, 'counters/updates': 8472}
skipping logging after 135568 examples to avoid logging too frequently
skipping logging after 135584 examples to avoid logging too frequently
skipping logging after 135600 examples to avoid logging too frequently
train stats after 135616 examples: {'rewards_train/chosen': '-0.66448', 'rewards_train/rejected': '-0.7804', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.116', 'logps_train/rejected': '-116.84', 'logps_train/chosen': '-124.8', 'loss/train': '0.67982', 'examples_per_second': '5.2571', 'grad_norm': '21.125', 'counters/examples': 135616, 'counters/updates': 8476}
skipping logging after 135632 examples to avoid logging too frequently
skipping logging after 135648 examples to avoid logging too frequently
skipping logging after 135664 examples to avoid logging too frequently
train stats after 135680 examples: {'rewards_train/chosen': '-0.51851', 'rewards_train/rejected': '-0.58942', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.071063', 'logps_train/rejected': '-98.366', 'logps_train/chosen': '-105.08', 'loss/train': '0.69963', 'examples_per_second': '3.9328', 'grad_norm': '18.875', 'counters/examples': 135680, 'counters/updates': 8480}
skipping logging after 135696 examples to avoid logging too frequently
skipping logging after 135712 examples to avoid logging too frequently
skipping logging after 135728 examples to avoid logging too frequently
train stats after 135744 examples: {'rewards_train/chosen': '-0.52887', 'rewards_train/rejected': '-0.692', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.16331', 'logps_train/rejected': '-119.99', 'logps_train/chosen': '-116.14', 'loss/train': '0.65286', 'examples_per_second': '5.886', 'grad_norm': '21.75', 'counters/examples': 135744, 'counters/updates': 8484}
skipping logging after 135760 examples to avoid logging too frequently
skipping logging after 135776 examples to avoid logging too frequently
skipping logging after 135792 examples to avoid logging too frequently
train stats after 135808 examples: {'rewards_train/chosen': '-0.51623', 'rewards_train/rejected': '-0.7124', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.19621', 'logps_train/rejected': '-109.85', 'logps_train/chosen': '-117.88', 'loss/train': '0.63443', 'examples_per_second': '5.3675', 'grad_norm': '18', 'counters/examples': 135808, 'counters/updates': 8488}
skipping logging after 135824 examples to avoid logging too frequently
skipping logging after 135840 examples to avoid logging too frequently
skipping logging after 135856 examples to avoid logging too frequently
train stats after 135872 examples: {'rewards_train/chosen': '-0.55621', 'rewards_train/rejected': '-0.73995', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.18368', 'logps_train/rejected': '-125.75', 'logps_train/chosen': '-111.12', 'loss/train': '0.63611', 'examples_per_second': '6.314', 'grad_norm': '18.75', 'counters/examples': 135872, 'counters/updates': 8492}
skipping logging after 135888 examples to avoid logging too frequently
skipping logging after 135904 examples to avoid logging too frequently
Running evaluation after 135904 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:15,  2.43s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:06,  2.20s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:56,  1.93s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.90s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.55s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.65s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 135904: {'rewards_eval/chosen': '-0.52939', 'rewards_eval/rejected': '-0.67208', 'rewards_eval/accuracies': '0.56055', 'rewards_eval/margins': '0.14267', 'logps_eval/rejected': '-128.88', 'logps_eval/chosen': '-123.79', 'loss/eval': '0.66426'}
skipping logging after 135920 examples to avoid logging too frequently
train stats after 135936 examples: {'rewards_train/chosen': '-0.5621', 'rewards_train/rejected': '-0.7115', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.14967', 'logps_train/rejected': '-117.07', 'logps_train/chosen': '-156.86', 'loss/train': '0.65776', 'examples_per_second': '4.9608', 'grad_norm': '25.375', 'counters/examples': 135936, 'counters/updates': 8496}
skipping logging after 135952 examples to avoid logging too frequently
skipping logging after 135968 examples to avoid logging too frequently
skipping logging after 135984 examples to avoid logging too frequently
train stats after 136000 examples: {'rewards_train/chosen': '-0.54239', 'rewards_train/rejected': '-0.76245', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.22006', 'logps_train/rejected': '-132.29', 'logps_train/chosen': '-129.76', 'loss/train': '0.62242', 'examples_per_second': '3.9599', 'grad_norm': '18', 'counters/examples': 136000, 'counters/updates': 8500}
skipping logging after 136016 examples to avoid logging too frequently
skipping logging after 136032 examples to avoid logging too frequently
skipping logging after 136048 examples to avoid logging too frequently
train stats after 136064 examples: {'rewards_train/chosen': '-0.49475', 'rewards_train/rejected': '-0.55324', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.058571', 'logps_train/rejected': '-133.55', 'logps_train/chosen': '-135.67', 'loss/train': '0.70183', 'examples_per_second': '4.165', 'grad_norm': '25.75', 'counters/examples': 136064, 'counters/updates': 8504}
skipping logging after 136080 examples to avoid logging too frequently
skipping logging after 136096 examples to avoid logging too frequently
skipping logging after 136112 examples to avoid logging too frequently
train stats after 136128 examples: {'rewards_train/chosen': '-0.46716', 'rewards_train/rejected': '-0.75127', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.28403', 'logps_train/rejected': '-118.47', 'logps_train/chosen': '-144.23', 'loss/train': '0.60089', 'examples_per_second': '4.9095', 'grad_norm': '18', 'counters/examples': 136128, 'counters/updates': 8508}
skipping logging after 136144 examples to avoid logging too frequently
skipping logging after 136160 examples to avoid logging too frequently
skipping logging after 136176 examples to avoid logging too frequently
train stats after 136192 examples: {'rewards_train/chosen': '-0.45924', 'rewards_train/rejected': '-0.67313', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.21384', 'logps_train/rejected': '-108.67', 'logps_train/chosen': '-106.85', 'loss/train': '0.62055', 'examples_per_second': '4.7662', 'grad_norm': '16.875', 'counters/examples': 136192, 'counters/updates': 8512}
skipping logging after 136208 examples to avoid logging too frequently
skipping logging after 136224 examples to avoid logging too frequently
skipping logging after 136240 examples to avoid logging too frequently
train stats after 136256 examples: {'rewards_train/chosen': '-0.55611', 'rewards_train/rejected': '-0.62054', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.064423', 'logps_train/rejected': '-104.85', 'logps_train/chosen': '-130.57', 'loss/train': '0.69449', 'examples_per_second': '4.6143', 'grad_norm': '21.875', 'counters/examples': 136256, 'counters/updates': 8516}
skipping logging after 136272 examples to avoid logging too frequently
skipping logging after 136288 examples to avoid logging too frequently
skipping logging after 136304 examples to avoid logging too frequently
train stats after 136320 examples: {'rewards_train/chosen': '-0.51412', 'rewards_train/rejected': '-0.57694', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.062808', 'logps_train/rejected': '-120.89', 'logps_train/chosen': '-118.1', 'loss/train': '0.69875', 'examples_per_second': '5.2204', 'grad_norm': '23.375', 'counters/examples': 136320, 'counters/updates': 8520}
skipping logging after 136336 examples to avoid logging too frequently
skipping logging after 136352 examples to avoid logging too frequently
skipping logging after 136368 examples to avoid logging too frequently
train stats after 136384 examples: {'rewards_train/chosen': '-0.55553', 'rewards_train/rejected': '-0.51817', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '-0.037529', 'logps_train/rejected': '-118.02', 'logps_train/chosen': '-143.43', 'loss/train': '0.73575', 'examples_per_second': '4.7121', 'grad_norm': '24.875', 'counters/examples': 136384, 'counters/updates': 8524}
skipping logging after 136400 examples to avoid logging too frequently
skipping logging after 136416 examples to avoid logging too frequently
skipping logging after 136432 examples to avoid logging too frequently
train stats after 136448 examples: {'rewards_train/chosen': '-0.46074', 'rewards_train/rejected': '-0.63332', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.17269', 'logps_train/rejected': '-111.72', 'logps_train/chosen': '-107.75', 'loss/train': '0.64931', 'examples_per_second': '4.639', 'grad_norm': '17.875', 'counters/examples': 136448, 'counters/updates': 8528}
skipping logging after 136464 examples to avoid logging too frequently
skipping logging after 136480 examples to avoid logging too frequently
skipping logging after 136496 examples to avoid logging too frequently
train stats after 136512 examples: {'rewards_train/chosen': '-0.49619', 'rewards_train/rejected': '-0.78674', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.29057', 'logps_train/rejected': '-154.68', 'logps_train/chosen': '-110.06', 'loss/train': '0.58395', 'examples_per_second': '5.3152', 'grad_norm': '18.5', 'counters/examples': 136512, 'counters/updates': 8532}
skipping logging after 136528 examples to avoid logging too frequently
skipping logging after 136544 examples to avoid logging too frequently
skipping logging after 136560 examples to avoid logging too frequently
train stats after 136576 examples: {'rewards_train/chosen': '-0.58518', 'rewards_train/rejected': '-0.65658', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.071472', 'logps_train/rejected': '-137.1', 'logps_train/chosen': '-132.53', 'loss/train': '0.6821', 'examples_per_second': '4.7527', 'grad_norm': '19.125', 'counters/examples': 136576, 'counters/updates': 8536}
skipping logging after 136592 examples to avoid logging too frequently
skipping logging after 136608 examples to avoid logging too frequently
skipping logging after 136624 examples to avoid logging too frequently
train stats after 136640 examples: {'rewards_train/chosen': '-0.46051', 'rewards_train/rejected': '-0.68316', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.22259', 'logps_train/rejected': '-113.86', 'logps_train/chosen': '-120.01', 'loss/train': '0.61853', 'examples_per_second': '4.8839', 'grad_norm': '19.5', 'counters/examples': 136640, 'counters/updates': 8540}
skipping logging after 136656 examples to avoid logging too frequently
skipping logging after 136672 examples to avoid logging too frequently
skipping logging after 136688 examples to avoid logging too frequently
train stats after 136704 examples: {'rewards_train/chosen': '-0.58414', 'rewards_train/rejected': '-0.70533', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.12125', 'logps_train/rejected': '-99.369', 'logps_train/chosen': '-107.6', 'loss/train': '0.66743', 'examples_per_second': '6.0203', 'grad_norm': '21.25', 'counters/examples': 136704, 'counters/updates': 8544}
skipping logging after 136720 examples to avoid logging too frequently
skipping logging after 136736 examples to avoid logging too frequently
skipping logging after 136752 examples to avoid logging too frequently
train stats after 136768 examples: {'rewards_train/chosen': '-0.53137', 'rewards_train/rejected': '-0.70921', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.1781', 'logps_train/rejected': '-110.93', 'logps_train/chosen': '-114.66', 'loss/train': '0.64215', 'examples_per_second': '5.7559', 'grad_norm': '16.375', 'counters/examples': 136768, 'counters/updates': 8548}
skipping logging after 136784 examples to avoid logging too frequently
skipping logging after 136800 examples to avoid logging too frequently
skipping logging after 136816 examples to avoid logging too frequently
train stats after 136832 examples: {'rewards_train/chosen': '-0.52503', 'rewards_train/rejected': '-0.80886', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.28379', 'logps_train/rejected': '-129.64', 'logps_train/chosen': '-127.95', 'loss/train': '0.5968', 'examples_per_second': '5.2709', 'grad_norm': '18', 'counters/examples': 136832, 'counters/updates': 8552}
skipping logging after 136848 examples to avoid logging too frequently
skipping logging after 136864 examples to avoid logging too frequently
skipping logging after 136880 examples to avoid logging too frequently
train stats after 136896 examples: {'rewards_train/chosen': '-0.61386', 'rewards_train/rejected': '-0.71663', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.10286', 'logps_train/rejected': '-133.48', 'logps_train/chosen': '-124.75', 'loss/train': '0.69202', 'examples_per_second': '5.122', 'grad_norm': '26.5', 'counters/examples': 136896, 'counters/updates': 8556}
Running evaluation after 136896 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.63s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.32s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 136896: {'rewards_eval/chosen': '-0.44934', 'rewards_eval/rejected': '-0.58556', 'rewards_eval/accuracies': '0.56445', 'rewards_eval/margins': '0.13621', 'logps_eval/rejected': '-128.01', 'logps_eval/chosen': '-122.99', 'loss/eval': '0.66245'}
skipping logging after 136912 examples to avoid logging too frequently
skipping logging after 136928 examples to avoid logging too frequently
skipping logging after 136944 examples to avoid logging too frequently
train stats after 136960 examples: {'rewards_train/chosen': '-0.35254', 'rewards_train/rejected': '-0.57018', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.21761', 'logps_train/rejected': '-127.78', 'logps_train/chosen': '-141.07', 'loss/train': '0.62268', 'examples_per_second': '4.4145', 'grad_norm': '20.25', 'counters/examples': 136960, 'counters/updates': 8560}
skipping logging after 136976 examples to avoid logging too frequently
skipping logging after 136992 examples to avoid logging too frequently
skipping logging after 137008 examples to avoid logging too frequently
train stats after 137024 examples: {'rewards_train/chosen': '-0.43024', 'rewards_train/rejected': '-0.5615', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.1313', 'logps_train/rejected': '-130.34', 'logps_train/chosen': '-119.13', 'loss/train': '0.66731', 'examples_per_second': '6.0903', 'grad_norm': '22.625', 'counters/examples': 137024, 'counters/updates': 8564}
skipping logging after 137040 examples to avoid logging too frequently
skipping logging after 137056 examples to avoid logging too frequently
skipping logging after 137072 examples to avoid logging too frequently
train stats after 137088 examples: {'rewards_train/chosen': '-0.46381', 'rewards_train/rejected': '-0.51932', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.055462', 'logps_train/rejected': '-132.94', 'logps_train/chosen': '-118.58', 'loss/train': '0.69057', 'examples_per_second': '5.5945', 'grad_norm': '19.875', 'counters/examples': 137088, 'counters/updates': 8568}
skipping logging after 137104 examples to avoid logging too frequently
skipping logging after 137120 examples to avoid logging too frequently
skipping logging after 137136 examples to avoid logging too frequently
train stats after 137152 examples: {'rewards_train/chosen': '-0.4237', 'rewards_train/rejected': '-0.60787', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.18406', 'logps_train/rejected': '-107.15', 'logps_train/chosen': '-119.72', 'loss/train': '0.63409', 'examples_per_second': '5.2672', 'grad_norm': '23.25', 'counters/examples': 137152, 'counters/updates': 8572}
skipping logging after 137168 examples to avoid logging too frequently
skipping logging after 137184 examples to avoid logging too frequently
skipping logging after 137200 examples to avoid logging too frequently
train stats after 137216 examples: {'rewards_train/chosen': '-0.33681', 'rewards_train/rejected': '-0.51842', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.18171', 'logps_train/rejected': '-108.11', 'logps_train/chosen': '-125.63', 'loss/train': '0.62808', 'examples_per_second': '4.3206', 'grad_norm': '18.125', 'counters/examples': 137216, 'counters/updates': 8576}
skipping logging after 137232 examples to avoid logging too frequently
skipping logging after 137248 examples to avoid logging too frequently
skipping logging after 137264 examples to avoid logging too frequently
train stats after 137280 examples: {'rewards_train/chosen': '-0.55659', 'rewards_train/rejected': '-0.59925', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.042603', 'logps_train/rejected': '-137.52', 'logps_train/chosen': '-140.5', 'loss/train': '0.70386', 'examples_per_second': '4.405', 'grad_norm': '19.75', 'counters/examples': 137280, 'counters/updates': 8580}
skipping logging after 137296 examples to avoid logging too frequently
skipping logging after 137312 examples to avoid logging too frequently
skipping logging after 137328 examples to avoid logging too frequently
train stats after 137344 examples: {'rewards_train/chosen': '-0.54855', 'rewards_train/rejected': '-0.67748', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.129', 'logps_train/rejected': '-121.52', 'logps_train/chosen': '-117.5', 'loss/train': '0.66223', 'examples_per_second': '5.6525', 'grad_norm': '22.875', 'counters/examples': 137344, 'counters/updates': 8584}
skipping logging after 137360 examples to avoid logging too frequently
skipping logging after 137376 examples to avoid logging too frequently
skipping logging after 137392 examples to avoid logging too frequently
train stats after 137408 examples: {'rewards_train/chosen': '-0.42559', 'rewards_train/rejected': '-0.589', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.16349', 'logps_train/rejected': '-131.07', 'logps_train/chosen': '-137.58', 'loss/train': '0.6403', 'examples_per_second': '4.4027', 'grad_norm': '17.875', 'counters/examples': 137408, 'counters/updates': 8588}
skipping logging after 137424 examples to avoid logging too frequently
skipping logging after 137440 examples to avoid logging too frequently
skipping logging after 137456 examples to avoid logging too frequently
train stats after 137472 examples: {'rewards_train/chosen': '-0.5442', 'rewards_train/rejected': '-0.7225', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.17847', 'logps_train/rejected': '-117.44', 'logps_train/chosen': '-109.7', 'loss/train': '0.64758', 'examples_per_second': '5.6836', 'grad_norm': '18', 'counters/examples': 137472, 'counters/updates': 8592}
skipping logging after 137488 examples to avoid logging too frequently
skipping logging after 137504 examples to avoid logging too frequently
skipping logging after 137520 examples to avoid logging too frequently
train stats after 137536 examples: {'rewards_train/chosen': '-0.52766', 'rewards_train/rejected': '-0.65252', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.12501', 'logps_train/rejected': '-155.45', 'logps_train/chosen': '-134.35', 'loss/train': '0.66145', 'examples_per_second': '4.6913', 'grad_norm': '19.625', 'counters/examples': 137536, 'counters/updates': 8596}
skipping logging after 137552 examples to avoid logging too frequently
skipping logging after 137568 examples to avoid logging too frequently
skipping logging after 137584 examples to avoid logging too frequently
train stats after 137600 examples: {'rewards_train/chosen': '-0.55674', 'rewards_train/rejected': '-0.72557', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.16884', 'logps_train/rejected': '-147.28', 'logps_train/chosen': '-134.59', 'loss/train': '0.65237', 'examples_per_second': '5.1744', 'grad_norm': '21.75', 'counters/examples': 137600, 'counters/updates': 8600}
skipping logging after 137616 examples to avoid logging too frequently
skipping logging after 137632 examples to avoid logging too frequently
skipping logging after 137648 examples to avoid logging too frequently
train stats after 137664 examples: {'rewards_train/chosen': '-0.43209', 'rewards_train/rejected': '-0.58629', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.15425', 'logps_train/rejected': '-113.9', 'logps_train/chosen': '-144.44', 'loss/train': '0.65309', 'examples_per_second': '4.2986', 'grad_norm': '17.75', 'counters/examples': 137664, 'counters/updates': 8604}
skipping logging after 137680 examples to avoid logging too frequently
skipping logging after 137696 examples to avoid logging too frequently
skipping logging after 137712 examples to avoid logging too frequently
train stats after 137728 examples: {'rewards_train/chosen': '-0.51187', 'rewards_train/rejected': '-0.73048', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.21853', 'logps_train/rejected': '-113.62', 'logps_train/chosen': '-123.8', 'loss/train': '0.62627', 'examples_per_second': '6.6555', 'grad_norm': '20.875', 'counters/examples': 137728, 'counters/updates': 8608}
skipping logging after 137744 examples to avoid logging too frequently
skipping logging after 137760 examples to avoid logging too frequently
skipping logging after 137776 examples to avoid logging too frequently
train stats after 137792 examples: {'rewards_train/chosen': '-0.58861', 'rewards_train/rejected': '-0.86506', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.27651', 'logps_train/rejected': '-126.89', 'logps_train/chosen': '-148.88', 'loss/train': '0.59811', 'examples_per_second': '5.9183', 'grad_norm': '20', 'counters/examples': 137792, 'counters/updates': 8612}
skipping logging after 137808 examples to avoid logging too frequently
skipping logging after 137824 examples to avoid logging too frequently
skipping logging after 137840 examples to avoid logging too frequently
train stats after 137856 examples: {'rewards_train/chosen': '-0.61584', 'rewards_train/rejected': '-0.70726', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.091419', 'logps_train/rejected': '-130.56', 'logps_train/chosen': '-118.47', 'loss/train': '0.6825', 'examples_per_second': '5.5846', 'grad_norm': '19.125', 'counters/examples': 137856, 'counters/updates': 8616}
skipping logging after 137872 examples to avoid logging too frequently
skipping logging after 137888 examples to avoid logging too frequently
Running evaluation after 137888 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:16,  2.46s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:06,  2.21s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:56,  1.94s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.91s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.55s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.65s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 137888: {'rewards_eval/chosen': '-0.52896', 'rewards_eval/rejected': '-0.66671', 'rewards_eval/accuracies': '0.56055', 'rewards_eval/margins': '0.13771', 'logps_eval/rejected': '-128.82', 'logps_eval/chosen': '-123.78', 'loss/eval': '0.66718'}
skipping logging after 137904 examples to avoid logging too frequently
train stats after 137920 examples: {'rewards_train/chosen': '-0.43594', 'rewards_train/rejected': '-0.80868', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.37265', 'logps_train/rejected': '-132.16', 'logps_train/chosen': '-125.76', 'loss/train': '0.57757', 'examples_per_second': '5.2823', 'grad_norm': '19.375', 'counters/examples': 137920, 'counters/updates': 8620}
skipping logging after 137936 examples to avoid logging too frequently
skipping logging after 137952 examples to avoid logging too frequently
skipping logging after 137968 examples to avoid logging too frequently
train stats after 137984 examples: {'rewards_train/chosen': '-0.60708', 'rewards_train/rejected': '-0.85318', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.24639', 'logps_train/rejected': '-125.07', 'logps_train/chosen': '-138.1', 'loss/train': '0.63286', 'examples_per_second': '4.5988', 'grad_norm': '18.875', 'counters/examples': 137984, 'counters/updates': 8624}
skipping logging after 138000 examples to avoid logging too frequently
skipping logging after 138016 examples to avoid logging too frequently
skipping logging after 138032 examples to avoid logging too frequently
train stats after 138048 examples: {'rewards_train/chosen': '-0.5281', 'rewards_train/rejected': '-0.80464', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.27636', 'logps_train/rejected': '-141.39', 'logps_train/chosen': '-125.16', 'loss/train': '0.60719', 'examples_per_second': '4.5838', 'grad_norm': '16.625', 'counters/examples': 138048, 'counters/updates': 8628}
skipping logging after 138064 examples to avoid logging too frequently
skipping logging after 138080 examples to avoid logging too frequently
skipping logging after 138096 examples to avoid logging too frequently
train stats after 138112 examples: {'rewards_train/chosen': '-0.62702', 'rewards_train/rejected': '-0.77433', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.14743', 'logps_train/rejected': '-138.8', 'logps_train/chosen': '-127.28', 'loss/train': '0.65845', 'examples_per_second': '4.2035', 'grad_norm': '18.75', 'counters/examples': 138112, 'counters/updates': 8632}
skipping logging after 138128 examples to avoid logging too frequently
skipping logging after 138144 examples to avoid logging too frequently
skipping logging after 138160 examples to avoid logging too frequently
train stats after 138176 examples: {'rewards_train/chosen': '-0.46725', 'rewards_train/rejected': '-0.60918', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.14217', 'logps_train/rejected': '-114.45', 'logps_train/chosen': '-120.02', 'loss/train': '0.65771', 'examples_per_second': '4.6363', 'grad_norm': '16.375', 'counters/examples': 138176, 'counters/updates': 8636}
skipping logging after 138192 examples to avoid logging too frequently
skipping logging after 138208 examples to avoid logging too frequently
skipping logging after 138224 examples to avoid logging too frequently
train stats after 138240 examples: {'rewards_train/chosen': '-0.57877', 'rewards_train/rejected': '-0.67747', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.098658', 'logps_train/rejected': '-131.55', 'logps_train/chosen': '-133.63', 'loss/train': '0.68597', 'examples_per_second': '4.9149', 'grad_norm': '19.125', 'counters/examples': 138240, 'counters/updates': 8640}
skipping logging after 138256 examples to avoid logging too frequently
skipping logging after 138272 examples to avoid logging too frequently
skipping logging after 138288 examples to avoid logging too frequently
train stats after 138304 examples: {'rewards_train/chosen': '-0.51342', 'rewards_train/rejected': '-0.71163', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.19831', 'logps_train/rejected': '-134.31', 'logps_train/chosen': '-113.78', 'loss/train': '0.63847', 'examples_per_second': '4.4326', 'grad_norm': '18.5', 'counters/examples': 138304, 'counters/updates': 8644}
skipping logging after 138320 examples to avoid logging too frequently
skipping logging after 138336 examples to avoid logging too frequently
skipping logging after 138352 examples to avoid logging too frequently
train stats after 138368 examples: {'rewards_train/chosen': '-0.60603', 'rewards_train/rejected': '-0.76994', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.16376', 'logps_train/rejected': '-138.94', 'logps_train/chosen': '-133.33', 'loss/train': '0.67246', 'examples_per_second': '4.2527', 'grad_norm': '20.25', 'counters/examples': 138368, 'counters/updates': 8648}
skipping logging after 138384 examples to avoid logging too frequently
skipping logging after 138400 examples to avoid logging too frequently
skipping logging after 138416 examples to avoid logging too frequently
train stats after 138432 examples: {'rewards_train/chosen': '-0.53544', 'rewards_train/rejected': '-0.78389', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.24864', 'logps_train/rejected': '-133.87', 'logps_train/chosen': '-126.57', 'loss/train': '0.6115', 'examples_per_second': '4.8395', 'grad_norm': '19.375', 'counters/examples': 138432, 'counters/updates': 8652}
skipping logging after 138448 examples to avoid logging too frequently
skipping logging after 138464 examples to avoid logging too frequently
skipping logging after 138480 examples to avoid logging too frequently
train stats after 138496 examples: {'rewards_train/chosen': '-0.46284', 'rewards_train/rejected': '-0.67896', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.21602', 'logps_train/rejected': '-163.16', 'logps_train/chosen': '-134.54', 'loss/train': '0.63115', 'examples_per_second': '3.9471', 'grad_norm': '19.375', 'counters/examples': 138496, 'counters/updates': 8656}
skipping logging after 138512 examples to avoid logging too frequently
skipping logging after 138528 examples to avoid logging too frequently
skipping logging after 138544 examples to avoid logging too frequently
train stats after 138560 examples: {'rewards_train/chosen': '-0.49728', 'rewards_train/rejected': '-0.63611', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.13889', 'logps_train/rejected': '-140.33', 'logps_train/chosen': '-146.36', 'loss/train': '0.65079', 'examples_per_second': '4.7199', 'grad_norm': '18.875', 'counters/examples': 138560, 'counters/updates': 8660}
skipping logging after 138576 examples to avoid logging too frequently
skipping logging after 138592 examples to avoid logging too frequently
skipping logging after 138608 examples to avoid logging too frequently
train stats after 138624 examples: {'rewards_train/chosen': '-0.45791', 'rewards_train/rejected': '-0.69613', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.23809', 'logps_train/rejected': '-145.08', 'logps_train/chosen': '-139.72', 'loss/train': '0.60475', 'examples_per_second': '4.6412', 'grad_norm': '17.375', 'counters/examples': 138624, 'counters/updates': 8664}
skipping logging after 138640 examples to avoid logging too frequently
skipping logging after 138656 examples to avoid logging too frequently
skipping logging after 138672 examples to avoid logging too frequently
train stats after 138688 examples: {'rewards_train/chosen': '-0.51908', 'rewards_train/rejected': '-0.60818', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.089397', 'logps_train/rejected': '-108.89', 'logps_train/chosen': '-128.42', 'loss/train': '0.68491', 'examples_per_second': '5.2092', 'grad_norm': '22', 'counters/examples': 138688, 'counters/updates': 8668}
skipping logging after 138704 examples to avoid logging too frequently
skipping logging after 138720 examples to avoid logging too frequently
skipping logging after 138736 examples to avoid logging too frequently
train stats after 138752 examples: {'rewards_train/chosen': '-0.54763', 'rewards_train/rejected': '-0.65954', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.11203', 'logps_train/rejected': '-133.18', 'logps_train/chosen': '-133.98', 'loss/train': '0.671', 'examples_per_second': '5.1601', 'grad_norm': '17.875', 'counters/examples': 138752, 'counters/updates': 8672}
skipping logging after 138768 examples to avoid logging too frequently
skipping logging after 138784 examples to avoid logging too frequently
skipping logging after 138800 examples to avoid logging too frequently
train stats after 138816 examples: {'rewards_train/chosen': '-0.62562', 'rewards_train/rejected': '-0.81035', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.18466', 'logps_train/rejected': '-91.203', 'logps_train/chosen': '-85.245', 'loss/train': '0.63943', 'examples_per_second': '6.0168', 'grad_norm': '17.25', 'counters/examples': 138816, 'counters/updates': 8676}
skipping logging after 138832 examples to avoid logging too frequently
skipping logging after 138848 examples to avoid logging too frequently
skipping logging after 138864 examples to avoid logging too frequently
train stats after 138880 examples: {'rewards_train/chosen': '-0.65677', 'rewards_train/rejected': '-0.71786', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.061127', 'logps_train/rejected': '-138.54', 'logps_train/chosen': '-106.44', 'loss/train': '0.68085', 'examples_per_second': '4.9565', 'grad_norm': '25.25', 'counters/examples': 138880, 'counters/updates': 8680}
Running evaluation after 138880 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.46s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.53s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 138880: {'rewards_eval/chosen': '-0.53852', 'rewards_eval/rejected': '-0.68079', 'rewards_eval/accuracies': '0.56055', 'rewards_eval/margins': '0.14227', 'logps_eval/rejected': '-128.96', 'logps_eval/chosen': '-123.88', 'loss/eval': '0.66414'}
skipping logging after 138896 examples to avoid logging too frequently
skipping logging after 138912 examples to avoid logging too frequently
skipping logging after 138928 examples to avoid logging too frequently
train stats after 138944 examples: {'rewards_train/chosen': '-0.43517', 'rewards_train/rejected': '-0.53578', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.10072', 'logps_train/rejected': '-130.11', 'logps_train/chosen': '-128.59', 'loss/train': '0.67068', 'examples_per_second': '5.0885', 'grad_norm': '19.25', 'counters/examples': 138944, 'counters/updates': 8684}
skipping logging after 138960 examples to avoid logging too frequently
skipping logging after 138976 examples to avoid logging too frequently
skipping logging after 138992 examples to avoid logging too frequently
train stats after 139008 examples: {'rewards_train/chosen': '-0.51147', 'rewards_train/rejected': '-0.76408', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.25267', 'logps_train/rejected': '-141.73', 'logps_train/chosen': '-125.87', 'loss/train': '0.59967', 'examples_per_second': '5.4085', 'grad_norm': '19.375', 'counters/examples': 139008, 'counters/updates': 8688}
skipping logging after 139024 examples to avoid logging too frequently
skipping logging after 139040 examples to avoid logging too frequently
skipping logging after 139056 examples to avoid logging too frequently
train stats after 139072 examples: {'rewards_train/chosen': '-0.62546', 'rewards_train/rejected': '-0.75418', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.12864', 'logps_train/rejected': '-88.344', 'logps_train/chosen': '-89.197', 'loss/train': '0.66899', 'examples_per_second': '5.9012', 'grad_norm': '15.688', 'counters/examples': 139072, 'counters/updates': 8692}
skipping logging after 139088 examples to avoid logging too frequently
skipping logging after 139104 examples to avoid logging too frequently
skipping logging after 139120 examples to avoid logging too frequently
train stats after 139136 examples: {'rewards_train/chosen': '-0.54161', 'rewards_train/rejected': '-0.7197', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.17813', 'logps_train/rejected': '-124.93', 'logps_train/chosen': '-125.56', 'loss/train': '0.63776', 'examples_per_second': '5.454', 'grad_norm': '23.5', 'counters/examples': 139136, 'counters/updates': 8696}
skipping logging after 139152 examples to avoid logging too frequently
skipping logging after 139168 examples to avoid logging too frequently
skipping logging after 139184 examples to avoid logging too frequently
train stats after 139200 examples: {'rewards_train/chosen': '-0.64318', 'rewards_train/rejected': '-0.79765', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.15438', 'logps_train/rejected': '-133.6', 'logps_train/chosen': '-156.63', 'loss/train': '0.66301', 'examples_per_second': '4.7581', 'grad_norm': '23.125', 'counters/examples': 139200, 'counters/updates': 8700}
skipping logging after 139216 examples to avoid logging too frequently
skipping logging after 139232 examples to avoid logging too frequently
skipping logging after 139248 examples to avoid logging too frequently
train stats after 139264 examples: {'rewards_train/chosen': '-0.55082', 'rewards_train/rejected': '-0.71405', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.16348', 'logps_train/rejected': '-121.74', 'logps_train/chosen': '-139.16', 'loss/train': '0.64975', 'examples_per_second': '5.5993', 'grad_norm': '21', 'counters/examples': 139264, 'counters/updates': 8704}
skipping logging after 139280 examples to avoid logging too frequently
skipping logging after 139296 examples to avoid logging too frequently
skipping logging after 139312 examples to avoid logging too frequently
train stats after 139328 examples: {'rewards_train/chosen': '-0.54418', 'rewards_train/rejected': '-0.79374', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.24961', 'logps_train/rejected': '-117.93', 'logps_train/chosen': '-115.99', 'loss/train': '0.60046', 'examples_per_second': '4.5908', 'grad_norm': '17.25', 'counters/examples': 139328, 'counters/updates': 8708}
skipping logging after 139344 examples to avoid logging too frequently
skipping logging after 139360 examples to avoid logging too frequently
skipping logging after 139376 examples to avoid logging too frequently
train stats after 139392 examples: {'rewards_train/chosen': '-0.52503', 'rewards_train/rejected': '-0.62218', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.097237', 'logps_train/rejected': '-136.23', 'logps_train/chosen': '-116.85', 'loss/train': '0.68346', 'examples_per_second': '4.7078', 'grad_norm': '20.25', 'counters/examples': 139392, 'counters/updates': 8712}
skipping logging after 139408 examples to avoid logging too frequently
skipping logging after 139424 examples to avoid logging too frequently
skipping logging after 139440 examples to avoid logging too frequently
train stats after 139456 examples: {'rewards_train/chosen': '-0.43277', 'rewards_train/rejected': '-0.58033', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.14745', 'logps_train/rejected': '-128.5', 'logps_train/chosen': '-107.27', 'loss/train': '0.6563', 'examples_per_second': '6.2756', 'grad_norm': '18.75', 'counters/examples': 139456, 'counters/updates': 8716}
skipping logging after 139472 examples to avoid logging too frequently
skipping logging after 139488 examples to avoid logging too frequently
skipping logging after 139504 examples to avoid logging too frequently
train stats after 139520 examples: {'rewards_train/chosen': '-0.40117', 'rewards_train/rejected': '-0.63759', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.23655', 'logps_train/rejected': '-135.02', 'logps_train/chosen': '-135.22', 'loss/train': '0.6055', 'examples_per_second': '4.5501', 'grad_norm': '22', 'counters/examples': 139520, 'counters/updates': 8720}
skipping logging after 139536 examples to avoid logging too frequently
skipping logging after 139552 examples to avoid logging too frequently
skipping logging after 139568 examples to avoid logging too frequently
train stats after 139584 examples: {'rewards_train/chosen': '-0.53261', 'rewards_train/rejected': '-0.67351', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.14094', 'logps_train/rejected': '-128.18', 'logps_train/chosen': '-118.14', 'loss/train': '0.67265', 'examples_per_second': '5.5761', 'grad_norm': '20.75', 'counters/examples': 139584, 'counters/updates': 8724}
skipping logging after 139600 examples to avoid logging too frequently
skipping logging after 139616 examples to avoid logging too frequently
skipping logging after 139632 examples to avoid logging too frequently
train stats after 139648 examples: {'rewards_train/chosen': '-0.54833', 'rewards_train/rejected': '-0.66032', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.11177', 'logps_train/rejected': '-157.41', 'logps_train/chosen': '-131.96', 'loss/train': '0.68649', 'examples_per_second': '4.9145', 'grad_norm': '21.375', 'counters/examples': 139648, 'counters/updates': 8728}
skipping logging after 139664 examples to avoid logging too frequently
skipping logging after 139680 examples to avoid logging too frequently
skipping logging after 139696 examples to avoid logging too frequently
train stats after 139712 examples: {'rewards_train/chosen': '-0.60004', 'rewards_train/rejected': '-0.85085', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.25093', 'logps_train/rejected': '-120.06', 'logps_train/chosen': '-130.9', 'loss/train': '0.62251', 'examples_per_second': '4.9228', 'grad_norm': '19.375', 'counters/examples': 139712, 'counters/updates': 8732}
skipping logging after 139728 examples to avoid logging too frequently
skipping logging after 139744 examples to avoid logging too frequently
skipping logging after 139760 examples to avoid logging too frequently
train stats after 139776 examples: {'rewards_train/chosen': '-0.60817', 'rewards_train/rejected': '-0.67898', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.070877', 'logps_train/rejected': '-91.072', 'logps_train/chosen': '-95.92', 'loss/train': '0.69241', 'examples_per_second': '5.4738', 'grad_norm': '18.375', 'counters/examples': 139776, 'counters/updates': 8736}
skipping logging after 139792 examples to avoid logging too frequently
skipping logging after 139808 examples to avoid logging too frequently
skipping logging after 139824 examples to avoid logging too frequently
train stats after 139840 examples: {'rewards_train/chosen': '-0.47703', 'rewards_train/rejected': '-0.67373', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.19691', 'logps_train/rejected': '-121.19', 'logps_train/chosen': '-110.82', 'loss/train': '0.64041', 'examples_per_second': '5.8697', 'grad_norm': '18.5', 'counters/examples': 139840, 'counters/updates': 8740}
skipping logging after 139856 examples to avoid logging too frequently
skipping logging after 139872 examples to avoid logging too frequently
Running evaluation after 139872 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:10,  2.27s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:04,  2.13s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.90s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.88s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 139872: {'rewards_eval/chosen': '-0.53528', 'rewards_eval/rejected': '-0.68477', 'rewards_eval/accuracies': '0.57617', 'rewards_eval/margins': '0.1495', 'logps_eval/rejected': '-129', 'logps_eval/chosen': '-123.85', 'loss/eval': '0.66257'}
skipping logging after 139888 examples to avoid logging too frequently
train stats after 139904 examples: {'rewards_train/chosen': '-0.5915', 'rewards_train/rejected': '-0.68352', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.092049', 'logps_train/rejected': '-113.31', 'logps_train/chosen': '-112.22', 'loss/train': '0.68775', 'examples_per_second': '5.894', 'grad_norm': '22.125', 'counters/examples': 139904, 'counters/updates': 8744}
skipping logging after 139920 examples to avoid logging too frequently
skipping logging after 139936 examples to avoid logging too frequently
skipping logging after 139952 examples to avoid logging too frequently
train stats after 139968 examples: {'rewards_train/chosen': '-0.50438', 'rewards_train/rejected': '-0.74959', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.24539', 'logps_train/rejected': '-134.27', 'logps_train/chosen': '-121.14', 'loss/train': '0.61082', 'examples_per_second': '4.0211', 'grad_norm': '20.5', 'counters/examples': 139968, 'counters/updates': 8748}
skipping logging after 139984 examples to avoid logging too frequently
skipping logging after 140000 examples to avoid logging too frequently
skipping logging after 140016 examples to avoid logging too frequently
train stats after 140032 examples: {'rewards_train/chosen': '-0.45405', 'rewards_train/rejected': '-0.63518', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.18112', 'logps_train/rejected': '-138.53', 'logps_train/chosen': '-129.26', 'loss/train': '0.63525', 'examples_per_second': '5.3832', 'grad_norm': '21.125', 'counters/examples': 140032, 'counters/updates': 8752}
skipping logging after 140048 examples to avoid logging too frequently
skipping logging after 140064 examples to avoid logging too frequently
skipping logging after 140080 examples to avoid logging too frequently
train stats after 140096 examples: {'rewards_train/chosen': '-0.50727', 'rewards_train/rejected': '-0.77303', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.26561', 'logps_train/rejected': '-113.67', 'logps_train/chosen': '-104.53', 'loss/train': '0.60757', 'examples_per_second': '6.1741', 'grad_norm': '18.375', 'counters/examples': 140096, 'counters/updates': 8756}
skipping logging after 140112 examples to avoid logging too frequently
skipping logging after 140128 examples to avoid logging too frequently
skipping logging after 140144 examples to avoid logging too frequently
train stats after 140160 examples: {'rewards_train/chosen': '-0.51631', 'rewards_train/rejected': '-0.62955', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.11333', 'logps_train/rejected': '-125.64', 'logps_train/chosen': '-133.26', 'loss/train': '0.68176', 'examples_per_second': '4.6858', 'grad_norm': '21', 'counters/examples': 140160, 'counters/updates': 8760}
skipping logging after 140176 examples to avoid logging too frequently
skipping logging after 140192 examples to avoid logging too frequently
skipping logging after 140208 examples to avoid logging too frequently
train stats after 140224 examples: {'rewards_train/chosen': '-0.51453', 'rewards_train/rejected': '-0.68491', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.17027', 'logps_train/rejected': '-109.09', 'logps_train/chosen': '-115.17', 'loss/train': '0.63425', 'examples_per_second': '5.9183', 'grad_norm': '18.875', 'counters/examples': 140224, 'counters/updates': 8764}
skipping logging after 140240 examples to avoid logging too frequently
skipping logging after 140256 examples to avoid logging too frequently
skipping logging after 140272 examples to avoid logging too frequently
train stats after 140288 examples: {'rewards_train/chosen': '-0.52314', 'rewards_train/rejected': '-0.66781', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.14482', 'logps_train/rejected': '-134.57', 'logps_train/chosen': '-140.86', 'loss/train': '0.66939', 'examples_per_second': '4.1203', 'grad_norm': '24.375', 'counters/examples': 140288, 'counters/updates': 8768}
skipping logging after 140304 examples to avoid logging too frequently
skipping logging after 140320 examples to avoid logging too frequently
skipping logging after 140336 examples to avoid logging too frequently
train stats after 140352 examples: {'rewards_train/chosen': '-0.42312', 'rewards_train/rejected': '-0.64395', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.22067', 'logps_train/rejected': '-137.59', 'logps_train/chosen': '-113.58', 'loss/train': '0.61929', 'examples_per_second': '5.819', 'grad_norm': '18.625', 'counters/examples': 140352, 'counters/updates': 8772}
skipping logging after 140368 examples to avoid logging too frequently
skipping logging after 140384 examples to avoid logging too frequently
skipping logging after 140400 examples to avoid logging too frequently
train stats after 140416 examples: {'rewards_train/chosen': '-0.48299', 'rewards_train/rejected': '-0.63275', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.14992', 'logps_train/rejected': '-132.84', 'logps_train/chosen': '-149.22', 'loss/train': '0.65897', 'examples_per_second': '4.7751', 'grad_norm': '19.125', 'counters/examples': 140416, 'counters/updates': 8776}
skipping logging after 140432 examples to avoid logging too frequently
skipping logging after 140448 examples to avoid logging too frequently
skipping logging after 140464 examples to avoid logging too frequently
train stats after 140480 examples: {'rewards_train/chosen': '-0.42439', 'rewards_train/rejected': '-0.68184', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.2575', 'logps_train/rejected': '-103.24', 'logps_train/chosen': '-121.94', 'loss/train': '0.60992', 'examples_per_second': '5.2027', 'grad_norm': '18', 'counters/examples': 140480, 'counters/updates': 8780}
skipping logging after 140496 examples to avoid logging too frequently
skipping logging after 140512 examples to avoid logging too frequently
skipping logging after 140528 examples to avoid logging too frequently
train stats after 140544 examples: {'rewards_train/chosen': '-0.52854', 'rewards_train/rejected': '-0.62487', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.09631', 'logps_train/rejected': '-125.72', 'logps_train/chosen': '-115.14', 'loss/train': '0.68521', 'examples_per_second': '4.8918', 'grad_norm': '23.125', 'counters/examples': 140544, 'counters/updates': 8784}
skipping logging after 140560 examples to avoid logging too frequently
skipping logging after 140576 examples to avoid logging too frequently
skipping logging after 140592 examples to avoid logging too frequently
train stats after 140608 examples: {'rewards_train/chosen': '-0.46976', 'rewards_train/rejected': '-0.69581', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.22619', 'logps_train/rejected': '-123.67', 'logps_train/chosen': '-134.39', 'loss/train': '0.62292', 'examples_per_second': '4.7793', 'grad_norm': '20.125', 'counters/examples': 140608, 'counters/updates': 8788}
skipping logging after 140624 examples to avoid logging too frequently
skipping logging after 140640 examples to avoid logging too frequently
skipping logging after 140656 examples to avoid logging too frequently
train stats after 140672 examples: {'rewards_train/chosen': '-0.56704', 'rewards_train/rejected': '-0.82634', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.25942', 'logps_train/rejected': '-137.66', 'logps_train/chosen': '-123.27', 'loss/train': '0.6106', 'examples_per_second': '4.472', 'grad_norm': '19.5', 'counters/examples': 140672, 'counters/updates': 8792}
skipping logging after 140688 examples to avoid logging too frequently
skipping logging after 140704 examples to avoid logging too frequently
skipping logging after 140720 examples to avoid logging too frequently
train stats after 140736 examples: {'rewards_train/chosen': '-0.62681', 'rewards_train/rejected': '-0.83215', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.20532', 'logps_train/rejected': '-99.944', 'logps_train/chosen': '-101.55', 'loss/train': '0.63564', 'examples_per_second': '5.2729', 'grad_norm': '17.5', 'counters/examples': 140736, 'counters/updates': 8796}
skipping logging after 140752 examples to avoid logging too frequently
skipping logging after 140768 examples to avoid logging too frequently
skipping logging after 140784 examples to avoid logging too frequently
train stats after 140800 examples: {'rewards_train/chosen': '-0.62993', 'rewards_train/rejected': '-0.68508', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.055183', 'logps_train/rejected': '-132.29', 'logps_train/chosen': '-127.1', 'loss/train': '0.70085', 'examples_per_second': '4.8898', 'grad_norm': '23.5', 'counters/examples': 140800, 'counters/updates': 8800}
skipping logging after 140816 examples to avoid logging too frequently
skipping logging after 140832 examples to avoid logging too frequently
skipping logging after 140848 examples to avoid logging too frequently
train stats after 140864 examples: {'rewards_train/chosen': '-0.59131', 'rewards_train/rejected': '-0.80241', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.21111', 'logps_train/rejected': '-106.23', 'logps_train/chosen': '-91.705', 'loss/train': '0.63766', 'examples_per_second': '5.0685', 'grad_norm': '18.375', 'counters/examples': 140864, 'counters/updates': 8804}
Running evaluation after 140864 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 140864: {'rewards_eval/chosen': '-0.57361', 'rewards_eval/rejected': '-0.72119', 'rewards_eval/accuracies': '0.56836', 'rewards_eval/margins': '0.14761', 'logps_eval/rejected': '-129.37', 'logps_eval/chosen': '-124.23', 'loss/eval': '0.66588'}
skipping logging after 140880 examples to avoid logging too frequently
skipping logging after 140896 examples to avoid logging too frequently
skipping logging after 140912 examples to avoid logging too frequently
train stats after 140928 examples: {'rewards_train/chosen': '-0.5919', 'rewards_train/rejected': '-0.93332', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.34131', 'logps_train/rejected': '-128.5', 'logps_train/chosen': '-112.24', 'loss/train': '0.58395', 'examples_per_second': '4.7986', 'grad_norm': '19', 'counters/examples': 140928, 'counters/updates': 8808}
skipping logging after 140944 examples to avoid logging too frequently
skipping logging after 140960 examples to avoid logging too frequently
skipping logging after 140976 examples to avoid logging too frequently
train stats after 140992 examples: {'rewards_train/chosen': '-0.59068', 'rewards_train/rejected': '-0.81896', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.22834', 'logps_train/rejected': '-130.93', 'logps_train/chosen': '-126.32', 'loss/train': '0.61925', 'examples_per_second': '6.6028', 'grad_norm': '17.375', 'counters/examples': 140992, 'counters/updates': 8812}
skipping logging after 141008 examples to avoid logging too frequently
skipping logging after 141024 examples to avoid logging too frequently
skipping logging after 141040 examples to avoid logging too frequently
train stats after 141056 examples: {'rewards_train/chosen': '-0.49437', 'rewards_train/rejected': '-0.68744', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.19303', 'logps_train/rejected': '-120.92', 'logps_train/chosen': '-127.44', 'loss/train': '0.63824', 'examples_per_second': '5.4608', 'grad_norm': '20', 'counters/examples': 141056, 'counters/updates': 8816}
skipping logging after 141072 examples to avoid logging too frequently
skipping logging after 141088 examples to avoid logging too frequently
skipping logging after 141104 examples to avoid logging too frequently
train stats after 141120 examples: {'rewards_train/chosen': '-0.50365', 'rewards_train/rejected': '-0.71127', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.20774', 'logps_train/rejected': '-130.37', 'logps_train/chosen': '-125.37', 'loss/train': '0.63222', 'examples_per_second': '4.5565', 'grad_norm': '20.5', 'counters/examples': 141120, 'counters/updates': 8820}
skipping logging after 141136 examples to avoid logging too frequently
skipping logging after 141152 examples to avoid logging too frequently
skipping logging after 141168 examples to avoid logging too frequently
train stats after 141184 examples: {'rewards_train/chosen': '-0.57502', 'rewards_train/rejected': '-0.6995', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.12456', 'logps_train/rejected': '-110.34', 'logps_train/chosen': '-115.82', 'loss/train': '0.66939', 'examples_per_second': '4.4001', 'grad_norm': '26', 'counters/examples': 141184, 'counters/updates': 8824}
skipping logging after 141200 examples to avoid logging too frequently
skipping logging after 141216 examples to avoid logging too frequently
skipping logging after 141232 examples to avoid logging too frequently
train stats after 141248 examples: {'rewards_train/chosen': '-0.57709', 'rewards_train/rejected': '-0.71489', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.13768', 'logps_train/rejected': '-140.87', 'logps_train/chosen': '-136.51', 'loss/train': '0.66071', 'examples_per_second': '4.5151', 'grad_norm': '18.625', 'counters/examples': 141248, 'counters/updates': 8828}
skipping logging after 141264 examples to avoid logging too frequently
skipping logging after 141280 examples to avoid logging too frequently
skipping logging after 141296 examples to avoid logging too frequently
train stats after 141312 examples: {'rewards_train/chosen': '-0.73765', 'rewards_train/rejected': '-0.88883', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.15146', 'logps_train/rejected': '-149.92', 'logps_train/chosen': '-151.53', 'loss/train': '0.67836', 'examples_per_second': '4.3264', 'grad_norm': '26', 'counters/examples': 141312, 'counters/updates': 8832}
skipping logging after 141328 examples to avoid logging too frequently
skipping logging after 141344 examples to avoid logging too frequently
skipping logging after 141360 examples to avoid logging too frequently
train stats after 141376 examples: {'rewards_train/chosen': '-0.72827', 'rewards_train/rejected': '-0.96649', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.23838', 'logps_train/rejected': '-127.21', 'logps_train/chosen': '-115.14', 'loss/train': '0.64349', 'examples_per_second': '5.5974', 'grad_norm': '20.125', 'counters/examples': 141376, 'counters/updates': 8836}
skipping logging after 141392 examples to avoid logging too frequently
skipping logging after 141408 examples to avoid logging too frequently
skipping logging after 141424 examples to avoid logging too frequently
train stats after 141440 examples: {'rewards_train/chosen': '-0.49035', 'rewards_train/rejected': '-0.79244', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.30224', 'logps_train/rejected': '-115.75', 'logps_train/chosen': '-107.88', 'loss/train': '0.58318', 'examples_per_second': '5.5152', 'grad_norm': '15.875', 'counters/examples': 141440, 'counters/updates': 8840}
skipping logging after 141456 examples to avoid logging too frequently
skipping logging after 141472 examples to avoid logging too frequently
skipping logging after 141488 examples to avoid logging too frequently
train stats after 141504 examples: {'rewards_train/chosen': '-0.66851', 'rewards_train/rejected': '-0.8865', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.21813', 'logps_train/rejected': '-124.67', 'logps_train/chosen': '-138.48', 'loss/train': '0.63388', 'examples_per_second': '4.7817', 'grad_norm': '21.625', 'counters/examples': 141504, 'counters/updates': 8844}
skipping logging after 141520 examples to avoid logging too frequently
skipping logging after 141536 examples to avoid logging too frequently
skipping logging after 141552 examples to avoid logging too frequently
train stats after 141568 examples: {'rewards_train/chosen': '-0.61174', 'rewards_train/rejected': '-0.91981', 'rewards_train/accuracies': '0.71875', 'rewards_train/margins': '0.30821', 'logps_train/rejected': '-125.55', 'logps_train/chosen': '-93.208', 'loss/train': '0.58387', 'examples_per_second': '4.6927', 'grad_norm': '16', 'counters/examples': 141568, 'counters/updates': 8848}
skipping logging after 141584 examples to avoid logging too frequently
skipping logging after 141600 examples to avoid logging too frequently
skipping logging after 141616 examples to avoid logging too frequently
train stats after 141632 examples: {'rewards_train/chosen': '-0.68171', 'rewards_train/rejected': '-0.89677', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.21513', 'logps_train/rejected': '-103.61', 'logps_train/chosen': '-104.92', 'loss/train': '0.62584', 'examples_per_second': '5.5198', 'grad_norm': '21.5', 'counters/examples': 141632, 'counters/updates': 8852}
skipping logging after 141648 examples to avoid logging too frequently
skipping logging after 141664 examples to avoid logging too frequently
skipping logging after 141680 examples to avoid logging too frequently
train stats after 141696 examples: {'rewards_train/chosen': '-0.58749', 'rewards_train/rejected': '-0.90859', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.32094', 'logps_train/rejected': '-141.73', 'logps_train/chosen': '-129.5', 'loss/train': '0.60044', 'examples_per_second': '4.7459', 'grad_norm': '20.375', 'counters/examples': 141696, 'counters/updates': 8856}
skipping logging after 141712 examples to avoid logging too frequently
skipping logging after 141728 examples to avoid logging too frequently
skipping logging after 141744 examples to avoid logging too frequently
train stats after 141760 examples: {'rewards_train/chosen': '-0.67446', 'rewards_train/rejected': '-0.82036', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.14579', 'logps_train/rejected': '-143.98', 'logps_train/chosen': '-130.92', 'loss/train': '0.65388', 'examples_per_second': '4.5356', 'grad_norm': '18.375', 'counters/examples': 141760, 'counters/updates': 8860}
skipping logging after 141776 examples to avoid logging too frequently
skipping logging after 141792 examples to avoid logging too frequently
skipping logging after 141808 examples to avoid logging too frequently
train stats after 141824 examples: {'rewards_train/chosen': '-0.7893', 'rewards_train/rejected': '-0.91037', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.12091', 'logps_train/rejected': '-121.42', 'logps_train/chosen': '-103', 'loss/train': '0.66257', 'examples_per_second': '5.4301', 'grad_norm': '25', 'counters/examples': 141824, 'counters/updates': 8864}
skipping logging after 141840 examples to avoid logging too frequently
skipping logging after 141856 examples to avoid logging too frequently
Running evaluation after 141856 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:12,  2.35s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:05,  2.17s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:55,  1.91s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.89s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.54s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.12s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 141856: {'rewards_eval/chosen': '-0.66733', 'rewards_eval/rejected': '-0.83298', 'rewards_eval/accuracies': '0.5625', 'rewards_eval/margins': '0.16569', 'logps_eval/rejected': '-130.49', 'logps_eval/chosen': '-125.17', 'loss/eval': '0.66564'}
skipping logging after 141872 examples to avoid logging too frequently
train stats after 141888 examples: {'rewards_train/chosen': '-0.68983', 'rewards_train/rejected': '-0.89968', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.20986', 'logps_train/rejected': '-105.38', 'logps_train/chosen': '-133.81', 'loss/train': '0.63916', 'examples_per_second': '4.8929', 'grad_norm': '18.75', 'counters/examples': 141888, 'counters/updates': 8868}
skipping logging after 141904 examples to avoid logging too frequently
skipping logging after 141920 examples to avoid logging too frequently
skipping logging after 141936 examples to avoid logging too frequently
train stats after 141952 examples: {'rewards_train/chosen': '-0.57281', 'rewards_train/rejected': '-0.88992', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.31693', 'logps_train/rejected': '-126.02', 'logps_train/chosen': '-111.06', 'loss/train': '0.59686', 'examples_per_second': '6.1333', 'grad_norm': '21.5', 'counters/examples': 141952, 'counters/updates': 8872}
skipping logging after 141968 examples to avoid logging too frequently
skipping logging after 141984 examples to avoid logging too frequently
skipping logging after 142000 examples to avoid logging too frequently
train stats after 142016 examples: {'rewards_train/chosen': '-0.60527', 'rewards_train/rejected': '-0.81354', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.20833', 'logps_train/rejected': '-132.23', 'logps_train/chosen': '-125.75', 'loss/train': '0.62796', 'examples_per_second': '4.5207', 'grad_norm': '23', 'counters/examples': 142016, 'counters/updates': 8876}
skipping logging after 142032 examples to avoid logging too frequently
skipping logging after 142048 examples to avoid logging too frequently
skipping logging after 142064 examples to avoid logging too frequently
train stats after 142080 examples: {'rewards_train/chosen': '-0.56461', 'rewards_train/rejected': '-0.82228', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.25753', 'logps_train/rejected': '-155.53', 'logps_train/chosen': '-142.63', 'loss/train': '0.62402', 'examples_per_second': '4.9165', 'grad_norm': '24.375', 'counters/examples': 142080, 'counters/updates': 8880}
skipping logging after 142096 examples to avoid logging too frequently
skipping logging after 142112 examples to avoid logging too frequently
skipping logging after 142128 examples to avoid logging too frequently
train stats after 142144 examples: {'rewards_train/chosen': '-0.55689', 'rewards_train/rejected': '-0.66491', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.10814', 'logps_train/rejected': '-118.28', 'logps_train/chosen': '-109.46', 'loss/train': '0.66901', 'examples_per_second': '5.5878', 'grad_norm': '22.25', 'counters/examples': 142144, 'counters/updates': 8884}
skipping logging after 142160 examples to avoid logging too frequently
skipping logging after 142176 examples to avoid logging too frequently
skipping logging after 142192 examples to avoid logging too frequently
train stats after 142208 examples: {'rewards_train/chosen': '-0.52041', 'rewards_train/rejected': '-0.65734', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.13694', 'logps_train/rejected': '-115.22', 'logps_train/chosen': '-124.65', 'loss/train': '0.66983', 'examples_per_second': '4.0255', 'grad_norm': '21.125', 'counters/examples': 142208, 'counters/updates': 8888}
skipping logging after 142224 examples to avoid logging too frequently
skipping logging after 142240 examples to avoid logging too frequently
skipping logging after 142256 examples to avoid logging too frequently
train stats after 142272 examples: {'rewards_train/chosen': '-0.45048', 'rewards_train/rejected': '-0.7276', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.27692', 'logps_train/rejected': '-114.73', 'logps_train/chosen': '-133.81', 'loss/train': '0.61249', 'examples_per_second': '5.1945', 'grad_norm': '20.75', 'counters/examples': 142272, 'counters/updates': 8892}
skipping logging after 142288 examples to avoid logging too frequently
skipping logging after 142304 examples to avoid logging too frequently
skipping logging after 142320 examples to avoid logging too frequently
train stats after 142336 examples: {'rewards_train/chosen': '-0.5505', 'rewards_train/rejected': '-0.72746', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.17702', 'logps_train/rejected': '-146.87', 'logps_train/chosen': '-117.21', 'loss/train': '0.64265', 'examples_per_second': '5.2992', 'grad_norm': '23.125', 'counters/examples': 142336, 'counters/updates': 8896}
skipping logging after 142352 examples to avoid logging too frequently
skipping logging after 142368 examples to avoid logging too frequently
skipping logging after 142384 examples to avoid logging too frequently
train stats after 142400 examples: {'rewards_train/chosen': '-0.53464', 'rewards_train/rejected': '-0.79105', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.25655', 'logps_train/rejected': '-122.89', 'logps_train/chosen': '-115.92', 'loss/train': '0.62121', 'examples_per_second': '5.0691', 'grad_norm': '20.875', 'counters/examples': 142400, 'counters/updates': 8900}
skipping logging after 142416 examples to avoid logging too frequently
skipping logging after 142432 examples to avoid logging too frequently
skipping logging after 142448 examples to avoid logging too frequently
train stats after 142464 examples: {'rewards_train/chosen': '-0.53268', 'rewards_train/rejected': '-0.68827', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.15577', 'logps_train/rejected': '-131.93', 'logps_train/chosen': '-139.88', 'loss/train': '0.6525', 'examples_per_second': '3.973', 'grad_norm': '21.125', 'counters/examples': 142464, 'counters/updates': 8904}
skipping logging after 142480 examples to avoid logging too frequently
skipping logging after 142496 examples to avoid logging too frequently
skipping logging after 142512 examples to avoid logging too frequently
train stats after 142528 examples: {'rewards_train/chosen': '-0.55976', 'rewards_train/rejected': '-0.86911', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.30922', 'logps_train/rejected': '-130.75', 'logps_train/chosen': '-130.94', 'loss/train': '0.59596', 'examples_per_second': '5.6321', 'grad_norm': '22', 'counters/examples': 142528, 'counters/updates': 8908}
skipping logging after 142544 examples to avoid logging too frequently
skipping logging after 142560 examples to avoid logging too frequently
skipping logging after 142576 examples to avoid logging too frequently
train stats after 142592 examples: {'rewards_train/chosen': '-0.55015', 'rewards_train/rejected': '-0.72568', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.17559', 'logps_train/rejected': '-133.57', 'logps_train/chosen': '-125.19', 'loss/train': '0.64009', 'examples_per_second': '5.8902', 'grad_norm': '21.875', 'counters/examples': 142592, 'counters/updates': 8912}
skipping logging after 142608 examples to avoid logging too frequently
skipping logging after 142624 examples to avoid logging too frequently
skipping logging after 142640 examples to avoid logging too frequently
train stats after 142656 examples: {'rewards_train/chosen': '-0.65469', 'rewards_train/rejected': '-0.89059', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.23569', 'logps_train/rejected': '-115.08', 'logps_train/chosen': '-123.5', 'loss/train': '0.63542', 'examples_per_second': '5.4388', 'grad_norm': '18.5', 'counters/examples': 142656, 'counters/updates': 8916}
skipping logging after 142672 examples to avoid logging too frequently
skipping logging after 142688 examples to avoid logging too frequently
skipping logging after 142704 examples to avoid logging too frequently
train stats after 142720 examples: {'rewards_train/chosen': '-0.61944', 'rewards_train/rejected': '-0.76898', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.14951', 'logps_train/rejected': '-114.73', 'logps_train/chosen': '-114.84', 'loss/train': '0.65585', 'examples_per_second': '5.5567', 'grad_norm': '21.625', 'counters/examples': 142720, 'counters/updates': 8920}
skipping logging after 142736 examples to avoid logging too frequently
skipping logging after 142752 examples to avoid logging too frequently
skipping logging after 142768 examples to avoid logging too frequently
train stats after 142784 examples: {'rewards_train/chosen': '-0.60843', 'rewards_train/rejected': '-0.77414', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.16558', 'logps_train/rejected': '-121.2', 'logps_train/chosen': '-132.09', 'loss/train': '0.64128', 'examples_per_second': '5.6942', 'grad_norm': '22.125', 'counters/examples': 142784, 'counters/updates': 8924}
skipping logging after 142800 examples to avoid logging too frequently
skipping logging after 142816 examples to avoid logging too frequently
skipping logging after 142832 examples to avoid logging too frequently
train stats after 142848 examples: {'rewards_train/chosen': '-0.5312', 'rewards_train/rejected': '-0.63804', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.107', 'logps_train/rejected': '-113.26', 'logps_train/chosen': '-126.45', 'loss/train': '0.68112', 'examples_per_second': '4.9629', 'grad_norm': '22', 'counters/examples': 142848, 'counters/updates': 8928}
Running evaluation after 142848 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.46s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.53s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 142848: {'rewards_eval/chosen': '-0.5593', 'rewards_eval/rejected': '-0.69996', 'rewards_eval/accuracies': '0.55664', 'rewards_eval/margins': '0.14061', 'logps_eval/rejected': '-129.16', 'logps_eval/chosen': '-124.09', 'loss/eval': '0.66897'}
skipping logging after 142864 examples to avoid logging too frequently
skipping logging after 142880 examples to avoid logging too frequently
skipping logging after 142896 examples to avoid logging too frequently
train stats after 142912 examples: {'rewards_train/chosen': '-0.543', 'rewards_train/rejected': '-0.7622', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.21926', 'logps_train/rejected': '-134.48', 'logps_train/chosen': '-135.31', 'loss/train': '0.64211', 'examples_per_second': '6.0114', 'grad_norm': '24.625', 'counters/examples': 142912, 'counters/updates': 8932}
skipping logging after 142928 examples to avoid logging too frequently
skipping logging after 142944 examples to avoid logging too frequently
skipping logging after 142960 examples to avoid logging too frequently
train stats after 142976 examples: {'rewards_train/chosen': '-0.45533', 'rewards_train/rejected': '-0.58793', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.1326', 'logps_train/rejected': '-110.6', 'logps_train/chosen': '-114.49', 'loss/train': '0.65179', 'examples_per_second': '5.4098', 'grad_norm': '21.125', 'counters/examples': 142976, 'counters/updates': 8936}
skipping logging after 142992 examples to avoid logging too frequently
skipping logging after 143008 examples to avoid logging too frequently
skipping logging after 143024 examples to avoid logging too frequently
train stats after 143040 examples: {'rewards_train/chosen': '-0.50496', 'rewards_train/rejected': '-0.70312', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.19799', 'logps_train/rejected': '-130.45', 'logps_train/chosen': '-126.33', 'loss/train': '0.62689', 'examples_per_second': '4.7096', 'grad_norm': '22.25', 'counters/examples': 143040, 'counters/updates': 8940}
skipping logging after 143056 examples to avoid logging too frequently
skipping logging after 143072 examples to avoid logging too frequently
skipping logging after 143088 examples to avoid logging too frequently
train stats after 143104 examples: {'rewards_train/chosen': '-0.48701', 'rewards_train/rejected': '-0.58732', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.10034', 'logps_train/rejected': '-116.22', 'logps_train/chosen': '-112.05', 'loss/train': '0.67258', 'examples_per_second': '5.5501', 'grad_norm': '23', 'counters/examples': 143104, 'counters/updates': 8944}
skipping logging after 143120 examples to avoid logging too frequently
skipping logging after 143136 examples to avoid logging too frequently
skipping logging after 143152 examples to avoid logging too frequently
train stats after 143168 examples: {'rewards_train/chosen': '-0.56919', 'rewards_train/rejected': '-0.66184', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.092758', 'logps_train/rejected': '-114.98', 'logps_train/chosen': '-142.23', 'loss/train': '0.69713', 'examples_per_second': '4.559', 'grad_norm': '23', 'counters/examples': 143168, 'counters/updates': 8948}
skipping logging after 143184 examples to avoid logging too frequently
skipping logging after 143200 examples to avoid logging too frequently
skipping logging after 143216 examples to avoid logging too frequently
train stats after 143232 examples: {'rewards_train/chosen': '-0.52586', 'rewards_train/rejected': '-0.71403', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.18825', 'logps_train/rejected': '-143.41', 'logps_train/chosen': '-101.34', 'loss/train': '0.62778', 'examples_per_second': '4.3644', 'grad_norm': '20.125', 'counters/examples': 143232, 'counters/updates': 8952}
skipping logging after 143248 examples to avoid logging too frequently
skipping logging after 143264 examples to avoid logging too frequently
skipping logging after 143280 examples to avoid logging too frequently
train stats after 143296 examples: {'rewards_train/chosen': '-0.44209', 'rewards_train/rejected': '-0.74033', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.29852', 'logps_train/rejected': '-130.27', 'logps_train/chosen': '-132.52', 'loss/train': '0.60526', 'examples_per_second': '5.2398', 'grad_norm': '18.25', 'counters/examples': 143296, 'counters/updates': 8956}
skipping logging after 143312 examples to avoid logging too frequently
skipping logging after 143328 examples to avoid logging too frequently
skipping logging after 143344 examples to avoid logging too frequently
train stats after 143360 examples: {'rewards_train/chosen': '-0.71097', 'rewards_train/rejected': '-0.79516', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.084145', 'logps_train/rejected': '-109.71', 'logps_train/chosen': '-93.786', 'loss/train': '0.68666', 'examples_per_second': '5.6183', 'grad_norm': '22.75', 'counters/examples': 143360, 'counters/updates': 8960}
skipping logging after 143376 examples to avoid logging too frequently
skipping logging after 143392 examples to avoid logging too frequently
skipping logging after 143408 examples to avoid logging too frequently
train stats after 143424 examples: {'rewards_train/chosen': '-0.68409', 'rewards_train/rejected': '-0.74547', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.061565', 'logps_train/rejected': '-116.98', 'logps_train/chosen': '-134.81', 'loss/train': '0.6944', 'examples_per_second': '5.6134', 'grad_norm': '22.25', 'counters/examples': 143424, 'counters/updates': 8964}
skipping logging after 143440 examples to avoid logging too frequently
skipping logging after 143456 examples to avoid logging too frequently
skipping logging after 143472 examples to avoid logging too frequently
train stats after 143488 examples: {'rewards_train/chosen': '-0.74073', 'rewards_train/rejected': '-0.82345', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.082928', 'logps_train/rejected': '-132.98', 'logps_train/chosen': '-104.26', 'loss/train': '0.68922', 'examples_per_second': '3.7672', 'grad_norm': '21.125', 'counters/examples': 143488, 'counters/updates': 8968}
skipping logging after 143504 examples to avoid logging too frequently
skipping logging after 143520 examples to avoid logging too frequently
skipping logging after 143536 examples to avoid logging too frequently
train stats after 143552 examples: {'rewards_train/chosen': '-0.62051', 'rewards_train/rejected': '-0.68713', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.066757', 'logps_train/rejected': '-102.02', 'logps_train/chosen': '-115.72', 'loss/train': '0.68845', 'examples_per_second': '4.7792', 'grad_norm': '22.25', 'counters/examples': 143552, 'counters/updates': 8972}
skipping logging after 143568 examples to avoid logging too frequently
skipping logging after 143584 examples to avoid logging too frequently
skipping logging after 143600 examples to avoid logging too frequently
train stats after 143616 examples: {'rewards_train/chosen': '-0.61588', 'rewards_train/rejected': '-0.70109', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.08527', 'logps_train/rejected': '-131.76', 'logps_train/chosen': '-120.34', 'loss/train': '0.67679', 'examples_per_second': '4.7119', 'grad_norm': '22.625', 'counters/examples': 143616, 'counters/updates': 8976}
skipping logging after 143632 examples to avoid logging too frequently
skipping logging after 143648 examples to avoid logging too frequently
skipping logging after 143664 examples to avoid logging too frequently
train stats after 143680 examples: {'rewards_train/chosen': '-0.72117', 'rewards_train/rejected': '-0.74739', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.026222', 'logps_train/rejected': '-107.52', 'logps_train/chosen': '-117.58', 'loss/train': '0.7122', 'examples_per_second': '4.9959', 'grad_norm': '26.875', 'counters/examples': 143680, 'counters/updates': 8980}
skipping logging after 143696 examples to avoid logging too frequently
skipping logging after 143712 examples to avoid logging too frequently
skipping logging after 143728 examples to avoid logging too frequently
train stats after 143744 examples: {'rewards_train/chosen': '-0.49139', 'rewards_train/rejected': '-0.5911', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.0998', 'logps_train/rejected': '-122.28', 'logps_train/chosen': '-114.54', 'loss/train': '0.67609', 'examples_per_second': '5.64', 'grad_norm': '19.375', 'counters/examples': 143744, 'counters/updates': 8984}
skipping logging after 143760 examples to avoid logging too frequently
skipping logging after 143776 examples to avoid logging too frequently
skipping logging after 143792 examples to avoid logging too frequently
train stats after 143808 examples: {'rewards_train/chosen': '-0.49438', 'rewards_train/rejected': '-0.55499', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.060547', 'logps_train/rejected': '-124.27', 'logps_train/chosen': '-107.9', 'loss/train': '0.68571', 'examples_per_second': '4.5117', 'grad_norm': '18.875', 'counters/examples': 143808, 'counters/updates': 8988}
skipping logging after 143824 examples to avoid logging too frequently
skipping logging after 143840 examples to avoid logging too frequently
Running evaluation after 143840 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:05,  2.12s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:02,  2.08s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.87s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.86s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.52s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.63s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 143840: {'rewards_eval/chosen': '-0.55199', 'rewards_eval/rejected': '-0.69534', 'rewards_eval/accuracies': '0.57812', 'rewards_eval/margins': '0.14339', 'logps_eval/rejected': '-129.11', 'logps_eval/chosen': '-124.01', 'loss/eval': '0.6642'}
skipping logging after 143856 examples to avoid logging too frequently
train stats after 143872 examples: {'rewards_train/chosen': '-0.48646', 'rewards_train/rejected': '-0.6783', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.19166', 'logps_train/rejected': '-139.7', 'logps_train/chosen': '-126.05', 'loss/train': '0.64067', 'examples_per_second': '5.8747', 'grad_norm': '20.5', 'counters/examples': 143872, 'counters/updates': 8992}
skipping logging after 143888 examples to avoid logging too frequently
skipping logging after 143904 examples to avoid logging too frequently
skipping logging after 143920 examples to avoid logging too frequently
train stats after 143936 examples: {'rewards_train/chosen': '-0.50558', 'rewards_train/rejected': '-0.69119', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.18579', 'logps_train/rejected': '-137.17', 'logps_train/chosen': '-133.82', 'loss/train': '0.6458', 'examples_per_second': '4.3804', 'grad_norm': '21.625', 'counters/examples': 143936, 'counters/updates': 8996}
skipping logging after 143952 examples to avoid logging too frequently
skipping logging after 143968 examples to avoid logging too frequently
skipping logging after 143984 examples to avoid logging too frequently
train stats after 144000 examples: {'rewards_train/chosen': '-0.50302', 'rewards_train/rejected': '-0.70241', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.19943', 'logps_train/rejected': '-122.11', 'logps_train/chosen': '-118.64', 'loss/train': '0.63611', 'examples_per_second': '4.9285', 'grad_norm': '20.375', 'counters/examples': 144000, 'counters/updates': 9000}
skipping logging after 144016 examples to avoid logging too frequently
skipping logging after 144032 examples to avoid logging too frequently
skipping logging after 144048 examples to avoid logging too frequently
train stats after 144064 examples: {'rewards_train/chosen': '-0.55521', 'rewards_train/rejected': '-0.67527', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.12012', 'logps_train/rejected': '-133.26', 'logps_train/chosen': '-121.09', 'loss/train': '0.65714', 'examples_per_second': '4.3498', 'grad_norm': '21.25', 'counters/examples': 144064, 'counters/updates': 9004}
skipping logging after 144080 examples to avoid logging too frequently
skipping logging after 144096 examples to avoid logging too frequently
skipping logging after 144112 examples to avoid logging too frequently
train stats after 144128 examples: {'rewards_train/chosen': '-0.402', 'rewards_train/rejected': '-0.52642', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.12448', 'logps_train/rejected': '-125.37', 'logps_train/chosen': '-126.84', 'loss/train': '0.65912', 'examples_per_second': '4.6946', 'grad_norm': '17.625', 'counters/examples': 144128, 'counters/updates': 9008}
skipping logging after 144144 examples to avoid logging too frequently
skipping logging after 144160 examples to avoid logging too frequently
skipping logging after 144176 examples to avoid logging too frequently
train stats after 144192 examples: {'rewards_train/chosen': '-0.499', 'rewards_train/rejected': '-0.71476', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.21596', 'logps_train/rejected': '-109.75', 'logps_train/chosen': '-114.59', 'loss/train': '0.62193', 'examples_per_second': '5.1875', 'grad_norm': '20.25', 'counters/examples': 144192, 'counters/updates': 9012}
skipping logging after 144208 examples to avoid logging too frequently
skipping logging after 144224 examples to avoid logging too frequently
skipping logging after 144240 examples to avoid logging too frequently
train stats after 144256 examples: {'rewards_train/chosen': '-0.53424', 'rewards_train/rejected': '-0.6139', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.079563', 'logps_train/rejected': '-112.7', 'logps_train/chosen': '-110.88', 'loss/train': '0.70009', 'examples_per_second': '5.5285', 'grad_norm': '22', 'counters/examples': 144256, 'counters/updates': 9016}
skipping logging after 144272 examples to avoid logging too frequently
skipping logging after 144288 examples to avoid logging too frequently
skipping logging after 144304 examples to avoid logging too frequently
train stats after 144320 examples: {'rewards_train/chosen': '-0.55449', 'rewards_train/rejected': '-0.77832', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.22378', 'logps_train/rejected': '-136.99', 'logps_train/chosen': '-122.81', 'loss/train': '0.6245', 'examples_per_second': '4.5254', 'grad_norm': '22', 'counters/examples': 144320, 'counters/updates': 9020}
skipping logging after 144336 examples to avoid logging too frequently
skipping logging after 144352 examples to avoid logging too frequently
skipping logging after 144368 examples to avoid logging too frequently
train stats after 144384 examples: {'rewards_train/chosen': '-0.47305', 'rewards_train/rejected': '-0.69974', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.2268', 'logps_train/rejected': '-138.84', 'logps_train/chosen': '-124.16', 'loss/train': '0.61797', 'examples_per_second': '5.8957', 'grad_norm': '18.125', 'counters/examples': 144384, 'counters/updates': 9024}
skipping logging after 144400 examples to avoid logging too frequently
skipping logging after 144416 examples to avoid logging too frequently
skipping logging after 144432 examples to avoid logging too frequently
train stats after 144448 examples: {'rewards_train/chosen': '-0.58245', 'rewards_train/rejected': '-0.86637', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.28412', 'logps_train/rejected': '-159.15', 'logps_train/chosen': '-142.48', 'loss/train': '0.59809', 'examples_per_second': '5.3308', 'grad_norm': '24.5', 'counters/examples': 144448, 'counters/updates': 9028}
skipping logging after 144464 examples to avoid logging too frequently
skipping logging after 144480 examples to avoid logging too frequently
skipping logging after 144496 examples to avoid logging too frequently
train stats after 144512 examples: {'rewards_train/chosen': '-0.63729', 'rewards_train/rejected': '-0.84853', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.21111', 'logps_train/rejected': '-150.44', 'logps_train/chosen': '-146.67', 'loss/train': '0.63914', 'examples_per_second': '6.0418', 'grad_norm': '23.375', 'counters/examples': 144512, 'counters/updates': 9032}
skipping logging after 144528 examples to avoid logging too frequently
skipping logging after 144544 examples to avoid logging too frequently
skipping logging after 144560 examples to avoid logging too frequently
train stats after 144576 examples: {'rewards_train/chosen': '-0.46735', 'rewards_train/rejected': '-0.7671', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.2996', 'logps_train/rejected': '-112.39', 'logps_train/chosen': '-94.743', 'loss/train': '0.5901', 'examples_per_second': '6.5899', 'grad_norm': '21.75', 'counters/examples': 144576, 'counters/updates': 9036}
skipping logging after 144592 examples to avoid logging too frequently
skipping logging after 144608 examples to avoid logging too frequently
skipping logging after 144624 examples to avoid logging too frequently
train stats after 144640 examples: {'rewards_train/chosen': '-0.57787', 'rewards_train/rejected': '-0.63983', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.06216', 'logps_train/rejected': '-128.9', 'logps_train/chosen': '-108.69', 'loss/train': '0.69446', 'examples_per_second': '4.409', 'grad_norm': '18.25', 'counters/examples': 144640, 'counters/updates': 9040}
skipping logging after 144656 examples to avoid logging too frequently
skipping logging after 144672 examples to avoid logging too frequently
skipping logging after 144688 examples to avoid logging too frequently
train stats after 144704 examples: {'rewards_train/chosen': '-0.44557', 'rewards_train/rejected': '-0.61154', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.16579', 'logps_train/rejected': '-120.96', 'logps_train/chosen': '-117.86', 'loss/train': '0.65047', 'examples_per_second': '4.8867', 'grad_norm': '21.125', 'counters/examples': 144704, 'counters/updates': 9044}
skipping logging after 144720 examples to avoid logging too frequently
skipping logging after 144736 examples to avoid logging too frequently
skipping logging after 144752 examples to avoid logging too frequently
train stats after 144768 examples: {'rewards_train/chosen': '-0.49373', 'rewards_train/rejected': '-0.66034', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.16678', 'logps_train/rejected': '-90.598', 'logps_train/chosen': '-117.97', 'loss/train': '0.63858', 'examples_per_second': '6.0836', 'grad_norm': '26.125', 'counters/examples': 144768, 'counters/updates': 9048}
skipping logging after 144784 examples to avoid logging too frequently
skipping logging after 144800 examples to avoid logging too frequently
skipping logging after 144816 examples to avoid logging too frequently
train stats after 144832 examples: {'rewards_train/chosen': '-0.52341', 'rewards_train/rejected': '-0.61278', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.089272', 'logps_train/rejected': '-129.19', 'logps_train/chosen': '-111.82', 'loss/train': '0.67134', 'examples_per_second': '4.2888', 'grad_norm': '21.25', 'counters/examples': 144832, 'counters/updates': 9052}
Running evaluation after 144832 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 144832: {'rewards_eval/chosen': '-0.61167', 'rewards_eval/rejected': '-0.74756', 'rewards_eval/accuracies': '0.55469', 'rewards_eval/margins': '0.13596', 'logps_eval/rejected': '-129.63', 'logps_eval/chosen': '-124.61', 'loss/eval': '0.6694'}
skipping logging after 144848 examples to avoid logging too frequently
skipping logging after 144864 examples to avoid logging too frequently
skipping logging after 144880 examples to avoid logging too frequently
train stats after 144896 examples: {'rewards_train/chosen': '-0.65303', 'rewards_train/rejected': '-0.80117', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.14825', 'logps_train/rejected': '-131.33', 'logps_train/chosen': '-135.14', 'loss/train': '0.65456', 'examples_per_second': '4.5236', 'grad_norm': '21', 'counters/examples': 144896, 'counters/updates': 9056}
skipping logging after 144912 examples to avoid logging too frequently
skipping logging after 144928 examples to avoid logging too frequently
skipping logging after 144944 examples to avoid logging too frequently
train stats after 144960 examples: {'rewards_train/chosen': '-0.64942', 'rewards_train/rejected': '-0.884', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.23461', 'logps_train/rejected': '-141.6', 'logps_train/chosen': '-117.55', 'loss/train': '0.6321', 'examples_per_second': '4.8918', 'grad_norm': '24.625', 'counters/examples': 144960, 'counters/updates': 9060}
skipping logging after 144976 examples to avoid logging too frequently
skipping logging after 144992 examples to avoid logging too frequently
skipping logging after 145008 examples to avoid logging too frequently
train stats after 145024 examples: {'rewards_train/chosen': '-0.53185', 'rewards_train/rejected': '-0.77376', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.24181', 'logps_train/rejected': '-143.57', 'logps_train/chosen': '-139.95', 'loss/train': '0.62134', 'examples_per_second': '4.6959', 'grad_norm': '20.25', 'counters/examples': 145024, 'counters/updates': 9064}
skipping logging after 145040 examples to avoid logging too frequently
skipping logging after 145056 examples to avoid logging too frequently
skipping logging after 145072 examples to avoid logging too frequently
train stats after 145088 examples: {'rewards_train/chosen': '-0.59133', 'rewards_train/rejected': '-0.69831', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.10709', 'logps_train/rejected': '-129.69', 'logps_train/chosen': '-147.19', 'loss/train': '0.67165', 'examples_per_second': '4.8107', 'grad_norm': '21.625', 'counters/examples': 145088, 'counters/updates': 9068}
skipping logging after 145104 examples to avoid logging too frequently
skipping logging after 145120 examples to avoid logging too frequently
skipping logging after 145136 examples to avoid logging too frequently
train stats after 145152 examples: {'rewards_train/chosen': '-0.62197', 'rewards_train/rejected': '-0.90239', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.28029', 'logps_train/rejected': '-138.39', 'logps_train/chosen': '-128.64', 'loss/train': '0.60324', 'examples_per_second': '6.1535', 'grad_norm': '19', 'counters/examples': 145152, 'counters/updates': 9072}
skipping logging after 145168 examples to avoid logging too frequently
skipping logging after 145184 examples to avoid logging too frequently
skipping logging after 145200 examples to avoid logging too frequently
train stats after 145216 examples: {'rewards_train/chosen': '-0.65651', 'rewards_train/rejected': '-0.6913', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.034683', 'logps_train/rejected': '-115.88', 'logps_train/chosen': '-116.05', 'loss/train': '0.70956', 'examples_per_second': '4.4864', 'grad_norm': '22.5', 'counters/examples': 145216, 'counters/updates': 9076}
skipping logging after 145232 examples to avoid logging too frequently
skipping logging after 145248 examples to avoid logging too frequently
skipping logging after 145264 examples to avoid logging too frequently
train stats after 145280 examples: {'rewards_train/chosen': '-0.39355', 'rewards_train/rejected': '-0.75724', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.36355', 'logps_train/rejected': '-110.02', 'logps_train/chosen': '-114.09', 'loss/train': '0.57024', 'examples_per_second': '5.1601', 'grad_norm': '17.5', 'counters/examples': 145280, 'counters/updates': 9080}
skipping logging after 145296 examples to avoid logging too frequently
skipping logging after 145312 examples to avoid logging too frequently
skipping logging after 145328 examples to avoid logging too frequently
train stats after 145344 examples: {'rewards_train/chosen': '-0.55872', 'rewards_train/rejected': '-0.79429', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.23563', 'logps_train/rejected': '-118.68', 'logps_train/chosen': '-117.21', 'loss/train': '0.62947', 'examples_per_second': '4.7901', 'grad_norm': '18.25', 'counters/examples': 145344, 'counters/updates': 9084}
skipping logging after 145360 examples to avoid logging too frequently
skipping logging after 145376 examples to avoid logging too frequently
skipping logging after 145392 examples to avoid logging too frequently
train stats after 145408 examples: {'rewards_train/chosen': '-0.46344', 'rewards_train/rejected': '-0.58853', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.12509', 'logps_train/rejected': '-137.53', 'logps_train/chosen': '-137.03', 'loss/train': '0.66714', 'examples_per_second': '4.973', 'grad_norm': '18.375', 'counters/examples': 145408, 'counters/updates': 9088}
skipping logging after 145424 examples to avoid logging too frequently
skipping logging after 145440 examples to avoid logging too frequently
skipping logging after 145456 examples to avoid logging too frequently
train stats after 145472 examples: {'rewards_train/chosen': '-0.65183', 'rewards_train/rejected': '-0.80589', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.15411', 'logps_train/rejected': '-103.69', 'logps_train/chosen': '-117.24', 'loss/train': '0.65266', 'examples_per_second': '6.7559', 'grad_norm': '19.875', 'counters/examples': 145472, 'counters/updates': 9092}
skipping logging after 145488 examples to avoid logging too frequently
skipping logging after 145504 examples to avoid logging too frequently
skipping logging after 145520 examples to avoid logging too frequently
train stats after 145536 examples: {'rewards_train/chosen': '-0.54879', 'rewards_train/rejected': '-0.66374', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.11494', 'logps_train/rejected': '-135.48', 'logps_train/chosen': '-131.66', 'loss/train': '0.66693', 'examples_per_second': '5.4727', 'grad_norm': '22.25', 'counters/examples': 145536, 'counters/updates': 9096}
skipping logging after 145552 examples to avoid logging too frequently
skipping logging after 145568 examples to avoid logging too frequently
skipping logging after 145584 examples to avoid logging too frequently
train stats after 145600 examples: {'rewards_train/chosen': '-0.54431', 'rewards_train/rejected': '-0.79489', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.25045', 'logps_train/rejected': '-114.07', 'logps_train/chosen': '-126.63', 'loss/train': '0.60776', 'examples_per_second': '5.2788', 'grad_norm': '20.5', 'counters/examples': 145600, 'counters/updates': 9100}
skipping logging after 145616 examples to avoid logging too frequently
skipping logging after 145632 examples to avoid logging too frequently
skipping logging after 145648 examples to avoid logging too frequently
train stats after 145664 examples: {'rewards_train/chosen': '-0.46002', 'rewards_train/rejected': '-0.71298', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.25314', 'logps_train/rejected': '-134.4', 'logps_train/chosen': '-121.42', 'loss/train': '0.62162', 'examples_per_second': '4.7824', 'grad_norm': '20.875', 'counters/examples': 145664, 'counters/updates': 9104}
skipping logging after 145680 examples to avoid logging too frequently
skipping logging after 145696 examples to avoid logging too frequently
skipping logging after 145712 examples to avoid logging too frequently
train stats after 145728 examples: {'rewards_train/chosen': '-0.55229', 'rewards_train/rejected': '-0.67247', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.12012', 'logps_train/rejected': '-134.64', 'logps_train/chosen': '-132.51', 'loss/train': '0.67887', 'examples_per_second': '6.8441', 'grad_norm': '21', 'counters/examples': 145728, 'counters/updates': 9108}
skipping logging after 145744 examples to avoid logging too frequently
skipping logging after 145760 examples to avoid logging too frequently
skipping logging after 145776 examples to avoid logging too frequently
train stats after 145792 examples: {'rewards_train/chosen': '-0.56778', 'rewards_train/rejected': '-0.62928', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.061409', 'logps_train/rejected': '-143.13', 'logps_train/chosen': '-133.54', 'loss/train': '0.69812', 'examples_per_second': '5.8825', 'grad_norm': '22.125', 'counters/examples': 145792, 'counters/updates': 9112}
skipping logging after 145808 examples to avoid logging too frequently
skipping logging after 145824 examples to avoid logging too frequently
Running evaluation after 145824 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:08,  2.20s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:03,  2.10s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.88s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.87s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 145824: {'rewards_eval/chosen': '-0.57139', 'rewards_eval/rejected': '-0.71291', 'rewards_eval/accuracies': '0.55078', 'rewards_eval/margins': '0.14152', 'logps_eval/rejected': '-129.28', 'logps_eval/chosen': '-124.21', 'loss/eval': '0.66341'}
skipping logging after 145840 examples to avoid logging too frequently
train stats after 145856 examples: {'rewards_train/chosen': '-0.52359', 'rewards_train/rejected': '-0.72168', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.19794', 'logps_train/rejected': '-114.47', 'logps_train/chosen': '-120.08', 'loss/train': '0.63196', 'examples_per_second': '5.9563', 'grad_norm': '20.25', 'counters/examples': 145856, 'counters/updates': 9116}
skipping logging after 145872 examples to avoid logging too frequently
skipping logging after 145888 examples to avoid logging too frequently
skipping logging after 145904 examples to avoid logging too frequently
train stats after 145920 examples: {'rewards_train/chosen': '-0.53104', 'rewards_train/rejected': '-0.76237', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.23137', 'logps_train/rejected': '-125.42', 'logps_train/chosen': '-124.53', 'loss/train': '0.62556', 'examples_per_second': '5.345', 'grad_norm': '21.875', 'counters/examples': 145920, 'counters/updates': 9120}
skipping logging after 145936 examples to avoid logging too frequently
skipping logging after 145952 examples to avoid logging too frequently
skipping logging after 145968 examples to avoid logging too frequently
train stats after 145984 examples: {'rewards_train/chosen': '-0.61248', 'rewards_train/rejected': '-0.64444', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.031918', 'logps_train/rejected': '-101.35', 'logps_train/chosen': '-124.61', 'loss/train': '0.69545', 'examples_per_second': '5.4267', 'grad_norm': '21.5', 'counters/examples': 145984, 'counters/updates': 9124}
skipping logging after 146000 examples to avoid logging too frequently
skipping logging after 146016 examples to avoid logging too frequently
skipping logging after 146032 examples to avoid logging too frequently
train stats after 146048 examples: {'rewards_train/chosen': '-0.59199', 'rewards_train/rejected': '-0.82072', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.22881', 'logps_train/rejected': '-98.273', 'logps_train/chosen': '-120.68', 'loss/train': '0.61682', 'examples_per_second': '5.9006', 'grad_norm': '18.375', 'counters/examples': 146048, 'counters/updates': 9128}
skipping logging after 146064 examples to avoid logging too frequently
skipping logging after 146080 examples to avoid logging too frequently
skipping logging after 146096 examples to avoid logging too frequently
train stats after 146112 examples: {'rewards_train/chosen': '-0.4939', 'rewards_train/rejected': '-0.73379', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.23998', 'logps_train/rejected': '-138.13', 'logps_train/chosen': '-126.73', 'loss/train': '0.625', 'examples_per_second': '4.9406', 'grad_norm': '20.375', 'counters/examples': 146112, 'counters/updates': 9132}
skipping logging after 146128 examples to avoid logging too frequently
skipping logging after 146144 examples to avoid logging too frequently
skipping logging after 146160 examples to avoid logging too frequently
train stats after 146176 examples: {'rewards_train/chosen': '-0.55399', 'rewards_train/rejected': '-0.64746', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.093447', 'logps_train/rejected': '-127.4', 'logps_train/chosen': '-131.55', 'loss/train': '0.68159', 'examples_per_second': '4.7473', 'grad_norm': '21.5', 'counters/examples': 146176, 'counters/updates': 9136}
skipping logging after 146192 examples to avoid logging too frequently
skipping logging after 146208 examples to avoid logging too frequently
skipping logging after 146224 examples to avoid logging too frequently
train stats after 146240 examples: {'rewards_train/chosen': '-0.46693', 'rewards_train/rejected': '-0.70296', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.23596', 'logps_train/rejected': '-124.06', 'logps_train/chosen': '-112.87', 'loss/train': '0.61044', 'examples_per_second': '4.7759', 'grad_norm': '21.25', 'counters/examples': 146240, 'counters/updates': 9140}
skipping logging after 146256 examples to avoid logging too frequently
skipping logging after 146272 examples to avoid logging too frequently
skipping logging after 146288 examples to avoid logging too frequently
train stats after 146304 examples: {'rewards_train/chosen': '-0.50074', 'rewards_train/rejected': '-0.65425', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.15355', 'logps_train/rejected': '-135.81', 'logps_train/chosen': '-121.96', 'loss/train': '0.64864', 'examples_per_second': '5.568', 'grad_norm': '25.5', 'counters/examples': 146304, 'counters/updates': 9144}
skipping logging after 146320 examples to avoid logging too frequently
skipping logging after 146336 examples to avoid logging too frequently
skipping logging after 146352 examples to avoid logging too frequently
train stats after 146368 examples: {'rewards_train/chosen': '-0.57511', 'rewards_train/rejected': '-0.65015', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.074883', 'logps_train/rejected': '-156.67', 'logps_train/chosen': '-151.5', 'loss/train': '0.69243', 'examples_per_second': '4.9467', 'grad_norm': '24.875', 'counters/examples': 146368, 'counters/updates': 9148}
skipping logging after 146384 examples to avoid logging too frequently
skipping logging after 146400 examples to avoid logging too frequently
skipping logging after 146416 examples to avoid logging too frequently
train stats after 146432 examples: {'rewards_train/chosen': '-0.51888', 'rewards_train/rejected': '-0.68353', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.16448', 'logps_train/rejected': '-106.98', 'logps_train/chosen': '-126.72', 'loss/train': '0.64607', 'examples_per_second': '5.0304', 'grad_norm': '17.875', 'counters/examples': 146432, 'counters/updates': 9152}
skipping logging after 146448 examples to avoid logging too frequently
skipping logging after 146464 examples to avoid logging too frequently
skipping logging after 146480 examples to avoid logging too frequently
train stats after 146496 examples: {'rewards_train/chosen': '-0.38461', 'rewards_train/rejected': '-0.65044', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.2657', 'logps_train/rejected': '-131.64', 'logps_train/chosen': '-117.55', 'loss/train': '0.61206', 'examples_per_second': '4.9359', 'grad_norm': '17', 'counters/examples': 146496, 'counters/updates': 9156}
skipping logging after 146512 examples to avoid logging too frequently
skipping logging after 146528 examples to avoid logging too frequently
skipping logging after 146544 examples to avoid logging too frequently
train stats after 146560 examples: {'rewards_train/chosen': '-0.50565', 'rewards_train/rejected': '-0.62389', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.11824', 'logps_train/rejected': '-111.52', 'logps_train/chosen': '-128.85', 'loss/train': '0.66388', 'examples_per_second': '4.0044', 'grad_norm': '18.125', 'counters/examples': 146560, 'counters/updates': 9160}
skipping logging after 146576 examples to avoid logging too frequently
skipping logging after 146592 examples to avoid logging too frequently
skipping logging after 146608 examples to avoid logging too frequently
train stats after 146624 examples: {'rewards_train/chosen': '-0.4715', 'rewards_train/rejected': '-0.62725', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.15586', 'logps_train/rejected': '-149.81', 'logps_train/chosen': '-147.41', 'loss/train': '0.65829', 'examples_per_second': '4.4274', 'grad_norm': '18.75', 'counters/examples': 146624, 'counters/updates': 9164}
skipping logging after 146640 examples to avoid logging too frequently
skipping logging after 146656 examples to avoid logging too frequently
skipping logging after 146672 examples to avoid logging too frequently
train stats after 146688 examples: {'rewards_train/chosen': '-0.53844', 'rewards_train/rejected': '-0.59581', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.057449', 'logps_train/rejected': '-137.12', 'logps_train/chosen': '-103.74', 'loss/train': '0.68292', 'examples_per_second': '4.2696', 'grad_norm': '17.125', 'counters/examples': 146688, 'counters/updates': 9168}
skipping logging after 146704 examples to avoid logging too frequently
skipping logging after 146720 examples to avoid logging too frequently
skipping logging after 146736 examples to avoid logging too frequently
train stats after 146752 examples: {'rewards_train/chosen': '-0.49052', 'rewards_train/rejected': '-0.74982', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.25925', 'logps_train/rejected': '-114.21', 'logps_train/chosen': '-105.93', 'loss/train': '0.60889', 'examples_per_second': '4.9794', 'grad_norm': '17.125', 'counters/examples': 146752, 'counters/updates': 9172}
skipping logging after 146768 examples to avoid logging too frequently
skipping logging after 146784 examples to avoid logging too frequently
skipping logging after 146800 examples to avoid logging too frequently
train stats after 146816 examples: {'rewards_train/chosen': '-0.48555', 'rewards_train/rejected': '-0.70531', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.21982', 'logps_train/rejected': '-140.49', 'logps_train/chosen': '-134.37', 'loss/train': '0.62686', 'examples_per_second': '4.4031', 'grad_norm': '19.375', 'counters/examples': 146816, 'counters/updates': 9176}
Running evaluation after 146816 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 146816: {'rewards_eval/chosen': '-0.51896', 'rewards_eval/rejected': '-0.66411', 'rewards_eval/accuracies': '0.56445', 'rewards_eval/margins': '0.1451', 'logps_eval/rejected': '-128.8', 'logps_eval/chosen': '-123.68', 'loss/eval': '0.66202'}
skipping logging after 146832 examples to avoid logging too frequently
skipping logging after 146848 examples to avoid logging too frequently
skipping logging after 146864 examples to avoid logging too frequently
train stats after 146880 examples: {'rewards_train/chosen': '-0.55807', 'rewards_train/rejected': '-0.8111', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.25323', 'logps_train/rejected': '-145.67', 'logps_train/chosen': '-114.64', 'loss/train': '0.61389', 'examples_per_second': '4.8108', 'grad_norm': '19.5', 'counters/examples': 146880, 'counters/updates': 9180}
skipping logging after 146896 examples to avoid logging too frequently
skipping logging after 146912 examples to avoid logging too frequently
skipping logging after 146928 examples to avoid logging too frequently
train stats after 146944 examples: {'rewards_train/chosen': '-0.59127', 'rewards_train/rejected': '-0.6859', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.094589', 'logps_train/rejected': '-145', 'logps_train/chosen': '-161.11', 'loss/train': '0.68044', 'examples_per_second': '4.8375', 'grad_norm': '25.125', 'counters/examples': 146944, 'counters/updates': 9184}
skipping logging after 146960 examples to avoid logging too frequently
skipping logging after 146976 examples to avoid logging too frequently
skipping logging after 146992 examples to avoid logging too frequently
train stats after 147008 examples: {'rewards_train/chosen': '-0.47737', 'rewards_train/rejected': '-0.68654', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.20906', 'logps_train/rejected': '-93.196', 'logps_train/chosen': '-88.284', 'loss/train': '0.62683', 'examples_per_second': '4.8618', 'grad_norm': '17', 'counters/examples': 147008, 'counters/updates': 9188}
skipping logging after 147024 examples to avoid logging too frequently
skipping logging after 147040 examples to avoid logging too frequently
skipping logging after 147056 examples to avoid logging too frequently
train stats after 147072 examples: {'rewards_train/chosen': '-0.4309', 'rewards_train/rejected': '-0.70427', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.27345', 'logps_train/rejected': '-121.54', 'logps_train/chosen': '-112.59', 'loss/train': '0.59702', 'examples_per_second': '5.4543', 'grad_norm': '18.875', 'counters/examples': 147072, 'counters/updates': 9192}
skipping logging after 147088 examples to avoid logging too frequently
skipping logging after 147104 examples to avoid logging too frequently
skipping logging after 147120 examples to avoid logging too frequently
train stats after 147136 examples: {'rewards_train/chosen': '-0.47013', 'rewards_train/rejected': '-0.6666', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.1965', 'logps_train/rejected': '-137.1', 'logps_train/chosen': '-112.48', 'loss/train': '0.62796', 'examples_per_second': '5.4173', 'grad_norm': '17.625', 'counters/examples': 147136, 'counters/updates': 9196}
skipping logging after 147152 examples to avoid logging too frequently
skipping logging after 147168 examples to avoid logging too frequently
skipping logging after 147184 examples to avoid logging too frequently
train stats after 147200 examples: {'rewards_train/chosen': '-0.55155', 'rewards_train/rejected': '-0.65759', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.106', 'logps_train/rejected': '-124.13', 'logps_train/chosen': '-129.7', 'loss/train': '0.66425', 'examples_per_second': '4.6067', 'grad_norm': '17.5', 'counters/examples': 147200, 'counters/updates': 9200}
skipping logging after 147216 examples to avoid logging too frequently
skipping logging after 147232 examples to avoid logging too frequently
skipping logging after 147248 examples to avoid logging too frequently
train stats after 147264 examples: {'rewards_train/chosen': '-0.46508', 'rewards_train/rejected': '-0.68164', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.21648', 'logps_train/rejected': '-127.58', 'logps_train/chosen': '-123.51', 'loss/train': '0.61888', 'examples_per_second': '4.9279', 'grad_norm': '19.125', 'counters/examples': 147264, 'counters/updates': 9204}
skipping logging after 147280 examples to avoid logging too frequently
skipping logging after 147296 examples to avoid logging too frequently
skipping logging after 147312 examples to avoid logging too frequently
train stats after 147328 examples: {'rewards_train/chosen': '-0.51308', 'rewards_train/rejected': '-0.76011', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.24716', 'logps_train/rejected': '-124.42', 'logps_train/chosen': '-126.1', 'loss/train': '0.60745', 'examples_per_second': '4.8841', 'grad_norm': '27', 'counters/examples': 147328, 'counters/updates': 9208}
skipping logging after 147344 examples to avoid logging too frequently
skipping logging after 147360 examples to avoid logging too frequently
skipping logging after 147376 examples to avoid logging too frequently
train stats after 147392 examples: {'rewards_train/chosen': '-0.49999', 'rewards_train/rejected': '-0.73245', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.23252', 'logps_train/rejected': '-132.21', 'logps_train/chosen': '-132.39', 'loss/train': '0.61238', 'examples_per_second': '4.2455', 'grad_norm': '19.125', 'counters/examples': 147392, 'counters/updates': 9212}
skipping logging after 147408 examples to avoid logging too frequently
skipping logging after 147424 examples to avoid logging too frequently
skipping logging after 147440 examples to avoid logging too frequently
train stats after 147456 examples: {'rewards_train/chosen': '-0.63118', 'rewards_train/rejected': '-0.75096', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.11972', 'logps_train/rejected': '-141.44', 'logps_train/chosen': '-137.5', 'loss/train': '0.67186', 'examples_per_second': '4.4517', 'grad_norm': '19.75', 'counters/examples': 147456, 'counters/updates': 9216}
skipping logging after 147472 examples to avoid logging too frequently
skipping logging after 147488 examples to avoid logging too frequently
skipping logging after 147504 examples to avoid logging too frequently
train stats after 147520 examples: {'rewards_train/chosen': '-0.56656', 'rewards_train/rejected': '-0.76365', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.19701', 'logps_train/rejected': '-116.33', 'logps_train/chosen': '-104.46', 'loss/train': '0.66137', 'examples_per_second': '4.5446', 'grad_norm': '17', 'counters/examples': 147520, 'counters/updates': 9220}
skipping logging after 147536 examples to avoid logging too frequently
skipping logging after 147552 examples to avoid logging too frequently
skipping logging after 147568 examples to avoid logging too frequently
train stats after 147584 examples: {'rewards_train/chosen': '-0.40769', 'rewards_train/rejected': '-0.65926', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.25146', 'logps_train/rejected': '-111.1', 'logps_train/chosen': '-119.74', 'loss/train': '0.60448', 'examples_per_second': '5.5278', 'grad_norm': '18.625', 'counters/examples': 147584, 'counters/updates': 9224}
skipping logging after 147600 examples to avoid logging too frequently
skipping logging after 147616 examples to avoid logging too frequently
skipping logging after 147632 examples to avoid logging too frequently
train stats after 147648 examples: {'rewards_train/chosen': '-0.54598', 'rewards_train/rejected': '-0.67014', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.12435', 'logps_train/rejected': '-170.51', 'logps_train/chosen': '-156.76', 'loss/train': '0.66502', 'examples_per_second': '4.2983', 'grad_norm': '22.125', 'counters/examples': 147648, 'counters/updates': 9228}
skipping logging after 147664 examples to avoid logging too frequently
skipping logging after 147680 examples to avoid logging too frequently
skipping logging after 147696 examples to avoid logging too frequently
train stats after 147712 examples: {'rewards_train/chosen': '-0.65627', 'rewards_train/rejected': '-0.84542', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.18935', 'logps_train/rejected': '-96.369', 'logps_train/chosen': '-112.78', 'loss/train': '0.64778', 'examples_per_second': '6.1596', 'grad_norm': '18.25', 'counters/examples': 147712, 'counters/updates': 9232}
skipping logging after 147728 examples to avoid logging too frequently
skipping logging after 147744 examples to avoid logging too frequently
skipping logging after 147760 examples to avoid logging too frequently
train stats after 147776 examples: {'rewards_train/chosen': '-0.48632', 'rewards_train/rejected': '-0.66835', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.18198', 'logps_train/rejected': '-116.63', 'logps_train/chosen': '-114.13', 'loss/train': '0.63937', 'examples_per_second': '4.7105', 'grad_norm': '17.5', 'counters/examples': 147776, 'counters/updates': 9236}
skipping logging after 147792 examples to avoid logging too frequently
skipping logging after 147808 examples to avoid logging too frequently
Running evaluation after 147808 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:10,  2.27s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:04,  2.14s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.90s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.88s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.48s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.55s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.25s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.29s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.41s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 147808: {'rewards_eval/chosen': '-0.58718', 'rewards_eval/rejected': '-0.73652', 'rewards_eval/accuracies': '0.56641', 'rewards_eval/margins': '0.14932', 'logps_eval/rejected': '-129.52', 'logps_eval/chosen': '-124.36', 'loss/eval': '0.66259'}
skipping logging after 147824 examples to avoid logging too frequently
train stats after 147840 examples: {'rewards_train/chosen': '-0.60987', 'rewards_train/rejected': '-0.75828', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.14839', 'logps_train/rejected': '-156.57', 'logps_train/chosen': '-128.34', 'loss/train': '0.66772', 'examples_per_second': '5.1303', 'grad_norm': '22.625', 'counters/examples': 147840, 'counters/updates': 9240}
skipping logging after 147856 examples to avoid logging too frequently
skipping logging after 147872 examples to avoid logging too frequently
skipping logging after 147888 examples to avoid logging too frequently
train stats after 147904 examples: {'rewards_train/chosen': '-0.68652', 'rewards_train/rejected': '-0.76178', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.07522', 'logps_train/rejected': '-107.6', 'logps_train/chosen': '-108.76', 'loss/train': '0.69183', 'examples_per_second': '5.7039', 'grad_norm': '21.25', 'counters/examples': 147904, 'counters/updates': 9244}
skipping logging after 147920 examples to avoid logging too frequently
skipping logging after 147936 examples to avoid logging too frequently
skipping logging after 147952 examples to avoid logging too frequently
train stats after 147968 examples: {'rewards_train/chosen': '-0.52292', 'rewards_train/rejected': '-0.69386', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.17106', 'logps_train/rejected': '-110.95', 'logps_train/chosen': '-122.34', 'loss/train': '0.65115', 'examples_per_second': '5.2581', 'grad_norm': '17.625', 'counters/examples': 147968, 'counters/updates': 9248}
skipping logging after 147984 examples to avoid logging too frequently
skipping logging after 148000 examples to avoid logging too frequently
skipping logging after 148016 examples to avoid logging too frequently
train stats after 148032 examples: {'rewards_train/chosen': '-0.49167', 'rewards_train/rejected': '-0.74583', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.25425', 'logps_train/rejected': '-139.65', 'logps_train/chosen': '-148.74', 'loss/train': '0.61266', 'examples_per_second': '4.4882', 'grad_norm': '21.75', 'counters/examples': 148032, 'counters/updates': 9252}
skipping logging after 148048 examples to avoid logging too frequently
skipping logging after 148064 examples to avoid logging too frequently
skipping logging after 148080 examples to avoid logging too frequently
train stats after 148096 examples: {'rewards_train/chosen': '-0.61862', 'rewards_train/rejected': '-0.8157', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.197', 'logps_train/rejected': '-99.825', 'logps_train/chosen': '-117.94', 'loss/train': '0.62904', 'examples_per_second': '5.4246', 'grad_norm': '17.75', 'counters/examples': 148096, 'counters/updates': 9256}
skipping logging after 148112 examples to avoid logging too frequently
skipping logging after 148128 examples to avoid logging too frequently
skipping logging after 148144 examples to avoid logging too frequently
train stats after 148160 examples: {'rewards_train/chosen': '-0.55389', 'rewards_train/rejected': '-0.74383', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.18973', 'logps_train/rejected': '-107.8', 'logps_train/chosen': '-125.66', 'loss/train': '0.63466', 'examples_per_second': '4.375', 'grad_norm': '18.125', 'counters/examples': 148160, 'counters/updates': 9260}
skipping logging after 148176 examples to avoid logging too frequently
skipping logging after 148192 examples to avoid logging too frequently
skipping logging after 148208 examples to avoid logging too frequently
train stats after 148224 examples: {'rewards_train/chosen': '-0.4568', 'rewards_train/rejected': '-0.67489', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.21793', 'logps_train/rejected': '-143.76', 'logps_train/chosen': '-121.11', 'loss/train': '0.61923', 'examples_per_second': '5.6486', 'grad_norm': '18', 'counters/examples': 148224, 'counters/updates': 9264}
skipping logging after 148240 examples to avoid logging too frequently
skipping logging after 148256 examples to avoid logging too frequently
skipping logging after 148272 examples to avoid logging too frequently
train stats after 148288 examples: {'rewards_train/chosen': '-0.54451', 'rewards_train/rejected': '-0.74219', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.19747', 'logps_train/rejected': '-131.01', 'logps_train/chosen': '-111.25', 'loss/train': '0.62965', 'examples_per_second': '4.6806', 'grad_norm': '18.125', 'counters/examples': 148288, 'counters/updates': 9268}
skipping logging after 148304 examples to avoid logging too frequently
skipping logging after 148320 examples to avoid logging too frequently
skipping logging after 148336 examples to avoid logging too frequently
train stats after 148352 examples: {'rewards_train/chosen': '-0.52094', 'rewards_train/rejected': '-0.72707', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.20596', 'logps_train/rejected': '-138.01', 'logps_train/chosen': '-155.93', 'loss/train': '0.63675', 'examples_per_second': '4.4434', 'grad_norm': '21.625', 'counters/examples': 148352, 'counters/updates': 9272}
skipping logging after 148368 examples to avoid logging too frequently
skipping logging after 148384 examples to avoid logging too frequently
skipping logging after 148400 examples to avoid logging too frequently
train stats after 148416 examples: {'rewards_train/chosen': '-0.50527', 'rewards_train/rejected': '-0.74157', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.23615', 'logps_train/rejected': '-132.28', 'logps_train/chosen': '-114.13', 'loss/train': '0.62403', 'examples_per_second': '5.5768', 'grad_norm': '21.125', 'counters/examples': 148416, 'counters/updates': 9276}
skipping logging after 148432 examples to avoid logging too frequently
skipping logging after 148448 examples to avoid logging too frequently
skipping logging after 148464 examples to avoid logging too frequently
train stats after 148480 examples: {'rewards_train/chosen': '-0.65984', 'rewards_train/rejected': '-0.73273', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.072945', 'logps_train/rejected': '-127.64', 'logps_train/chosen': '-151.38', 'loss/train': '0.69769', 'examples_per_second': '6.3182', 'grad_norm': '22.5', 'counters/examples': 148480, 'counters/updates': 9280}
skipping logging after 148496 examples to avoid logging too frequently
skipping logging after 148512 examples to avoid logging too frequently
skipping logging after 148528 examples to avoid logging too frequently
train stats after 148544 examples: {'rewards_train/chosen': '-0.41479', 'rewards_train/rejected': '-0.76452', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.3494', 'logps_train/rejected': '-132.88', 'logps_train/chosen': '-108.26', 'loss/train': '0.56989', 'examples_per_second': '4.6899', 'grad_norm': '21', 'counters/examples': 148544, 'counters/updates': 9284}
skipping logging after 148560 examples to avoid logging too frequently
skipping logging after 148576 examples to avoid logging too frequently
skipping logging after 148592 examples to avoid logging too frequently
train stats after 148608 examples: {'rewards_train/chosen': '-0.56138', 'rewards_train/rejected': '-0.76362', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.20222', 'logps_train/rejected': '-110.62', 'logps_train/chosen': '-118.76', 'loss/train': '0.6557', 'examples_per_second': '4.6353', 'grad_norm': '21.625', 'counters/examples': 148608, 'counters/updates': 9288}
skipping logging after 148624 examples to avoid logging too frequently
skipping logging after 148640 examples to avoid logging too frequently
skipping logging after 148656 examples to avoid logging too frequently
train stats after 148672 examples: {'rewards_train/chosen': '-0.52286', 'rewards_train/rejected': '-0.69134', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.16852', 'logps_train/rejected': '-125.89', 'logps_train/chosen': '-109.8', 'loss/train': '0.64003', 'examples_per_second': '5.3258', 'grad_norm': '18', 'counters/examples': 148672, 'counters/updates': 9292}
skipping logging after 148688 examples to avoid logging too frequently
skipping logging after 148704 examples to avoid logging too frequently
skipping logging after 148720 examples to avoid logging too frequently
train stats after 148736 examples: {'rewards_train/chosen': '-0.57017', 'rewards_train/rejected': '-0.80348', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.23329', 'logps_train/rejected': '-93.229', 'logps_train/chosen': '-123.37', 'loss/train': '0.62047', 'examples_per_second': '5.3592', 'grad_norm': '19.75', 'counters/examples': 148736, 'counters/updates': 9296}
skipping logging after 148752 examples to avoid logging too frequently
skipping logging after 148768 examples to avoid logging too frequently
skipping logging after 148784 examples to avoid logging too frequently
train stats after 148800 examples: {'rewards_train/chosen': '-0.54712', 'rewards_train/rejected': '-0.71541', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.16832', 'logps_train/rejected': '-123.17', 'logps_train/chosen': '-104.68', 'loss/train': '0.64796', 'examples_per_second': '5.2868', 'grad_norm': '18.625', 'counters/examples': 148800, 'counters/updates': 9300}
Running evaluation after 148800 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<01:00,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.83s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.63s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 148800: {'rewards_eval/chosen': '-0.58207', 'rewards_eval/rejected': '-0.74546', 'rewards_eval/accuracies': '0.55273', 'rewards_eval/margins': '0.16342', 'logps_eval/rejected': '-129.61', 'logps_eval/chosen': '-124.32', 'loss/eval': '0.65943'}
skipping logging after 148816 examples to avoid logging too frequently
skipping logging after 148832 examples to avoid logging too frequently
skipping logging after 148848 examples to avoid logging too frequently
train stats after 148864 examples: {'rewards_train/chosen': '-0.5954', 'rewards_train/rejected': '-0.69735', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.10185', 'logps_train/rejected': '-113.73', 'logps_train/chosen': '-138.9', 'loss/train': '0.68301', 'examples_per_second': '5.5092', 'grad_norm': '21.5', 'counters/examples': 148864, 'counters/updates': 9304}
skipping logging after 148880 examples to avoid logging too frequently
skipping logging after 148896 examples to avoid logging too frequently
skipping logging after 148912 examples to avoid logging too frequently
train stats after 148928 examples: {'rewards_train/chosen': '-0.42572', 'rewards_train/rejected': '-0.68918', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.26352', 'logps_train/rejected': '-132.01', 'logps_train/chosen': '-112.54', 'loss/train': '0.61539', 'examples_per_second': '5.3152', 'grad_norm': '18.625', 'counters/examples': 148928, 'counters/updates': 9308}
skipping logging after 148944 examples to avoid logging too frequently
skipping logging after 148960 examples to avoid logging too frequently
skipping logging after 148976 examples to avoid logging too frequently
train stats after 148992 examples: {'rewards_train/chosen': '-0.63364', 'rewards_train/rejected': '-0.72931', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.095467', 'logps_train/rejected': '-149.32', 'logps_train/chosen': '-119.29', 'loss/train': '0.6828', 'examples_per_second': '4.6303', 'grad_norm': '21.75', 'counters/examples': 148992, 'counters/updates': 9312}
skipping logging after 149008 examples to avoid logging too frequently
skipping logging after 149024 examples to avoid logging too frequently
skipping logging after 149040 examples to avoid logging too frequently
train stats after 149056 examples: {'rewards_train/chosen': '-0.5215', 'rewards_train/rejected': '-0.76514', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.24367', 'logps_train/rejected': '-142.49', 'logps_train/chosen': '-108.86', 'loss/train': '0.61639', 'examples_per_second': '3.8228', 'grad_norm': '17.25', 'counters/examples': 149056, 'counters/updates': 9316}
skipping logging after 149072 examples to avoid logging too frequently
skipping logging after 149088 examples to avoid logging too frequently
skipping logging after 149104 examples to avoid logging too frequently
train stats after 149120 examples: {'rewards_train/chosen': '-0.67658', 'rewards_train/rejected': '-0.74335', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.066673', 'logps_train/rejected': '-121.61', 'logps_train/chosen': '-134.02', 'loss/train': '0.69539', 'examples_per_second': '5.0174', 'grad_norm': '22.125', 'counters/examples': 149120, 'counters/updates': 9320}
skipping logging after 149136 examples to avoid logging too frequently
skipping logging after 149152 examples to avoid logging too frequently
skipping logging after 149168 examples to avoid logging too frequently
train stats after 149184 examples: {'rewards_train/chosen': '-0.60404', 'rewards_train/rejected': '-0.74652', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.14242', 'logps_train/rejected': '-116.93', 'logps_train/chosen': '-110.83', 'loss/train': '0.65204', 'examples_per_second': '5.7277', 'grad_norm': '18.875', 'counters/examples': 149184, 'counters/updates': 9324}
skipping logging after 149200 examples to avoid logging too frequently
skipping logging after 149216 examples to avoid logging too frequently
skipping logging after 149232 examples to avoid logging too frequently
train stats after 149248 examples: {'rewards_train/chosen': '-0.47588', 'rewards_train/rejected': '-0.66115', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.18526', 'logps_train/rejected': '-123.36', 'logps_train/chosen': '-110.97', 'loss/train': '0.633', 'examples_per_second': '4.4358', 'grad_norm': '18', 'counters/examples': 149248, 'counters/updates': 9328}
skipping logging after 149264 examples to avoid logging too frequently
skipping logging after 149280 examples to avoid logging too frequently
skipping logging after 149296 examples to avoid logging too frequently
train stats after 149312 examples: {'rewards_train/chosen': '-0.69762', 'rewards_train/rejected': '-0.82581', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.12838', 'logps_train/rejected': '-120.06', 'logps_train/chosen': '-97.77', 'loss/train': '0.67615', 'examples_per_second': '4.7629', 'grad_norm': '20.875', 'counters/examples': 149312, 'counters/updates': 9332}
skipping logging after 149328 examples to avoid logging too frequently
skipping logging after 149344 examples to avoid logging too frequently
skipping logging after 149360 examples to avoid logging too frequently
train stats after 149376 examples: {'rewards_train/chosen': '-0.56088', 'rewards_train/rejected': '-0.66423', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.10332', 'logps_train/rejected': '-122.28', 'logps_train/chosen': '-128.56', 'loss/train': '0.679', 'examples_per_second': '5.6004', 'grad_norm': '21.875', 'counters/examples': 149376, 'counters/updates': 9336}
skipping logging after 149392 examples to avoid logging too frequently
skipping logging after 149408 examples to avoid logging too frequently
skipping logging after 149424 examples to avoid logging too frequently
train stats after 149440 examples: {'rewards_train/chosen': '-0.67087', 'rewards_train/rejected': '-0.76833', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.097404', 'logps_train/rejected': '-123.56', 'logps_train/chosen': '-121.71', 'loss/train': '0.70306', 'examples_per_second': '4.4218', 'grad_norm': '21.875', 'counters/examples': 149440, 'counters/updates': 9340}
skipping logging after 149456 examples to avoid logging too frequently
skipping logging after 149472 examples to avoid logging too frequently
skipping logging after 149488 examples to avoid logging too frequently
train stats after 149504 examples: {'rewards_train/chosen': '-0.48605', 'rewards_train/rejected': '-0.67161', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.18549', 'logps_train/rejected': '-142', 'logps_train/chosen': '-146.7', 'loss/train': '0.64102', 'examples_per_second': '4.6725', 'grad_norm': '23.5', 'counters/examples': 149504, 'counters/updates': 9344}
skipping logging after 149520 examples to avoid logging too frequently
skipping logging after 149536 examples to avoid logging too frequently
skipping logging after 149552 examples to avoid logging too frequently
train stats after 149568 examples: {'rewards_train/chosen': '-0.62776', 'rewards_train/rejected': '-0.81043', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.18279', 'logps_train/rejected': '-140.37', 'logps_train/chosen': '-126.61', 'loss/train': '0.63867', 'examples_per_second': '5.3829', 'grad_norm': '20', 'counters/examples': 149568, 'counters/updates': 9348}
skipping logging after 149584 examples to avoid logging too frequently
skipping logging after 149600 examples to avoid logging too frequently
skipping logging after 149616 examples to avoid logging too frequently
train stats after 149632 examples: {'rewards_train/chosen': '-0.6613', 'rewards_train/rejected': '-0.71969', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.058258', 'logps_train/rejected': '-148.32', 'logps_train/chosen': '-140.88', 'loss/train': '0.70072', 'examples_per_second': '5.773', 'grad_norm': '21', 'counters/examples': 149632, 'counters/updates': 9352}
skipping logging after 149648 examples to avoid logging too frequently
skipping logging after 149664 examples to avoid logging too frequently
skipping logging after 149680 examples to avoid logging too frequently
train stats after 149696 examples: {'rewards_train/chosen': '-0.65343', 'rewards_train/rejected': '-0.75723', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.10369', 'logps_train/rejected': '-116.36', 'logps_train/chosen': '-140.7', 'loss/train': '0.67531', 'examples_per_second': '6.1007', 'grad_norm': '23.75', 'counters/examples': 149696, 'counters/updates': 9356}
skipping logging after 149712 examples to avoid logging too frequently
skipping logging after 149728 examples to avoid logging too frequently
skipping logging after 149744 examples to avoid logging too frequently
train stats after 149760 examples: {'rewards_train/chosen': '-0.58876', 'rewards_train/rejected': '-0.80396', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.21495', 'logps_train/rejected': '-112.11', 'logps_train/chosen': '-129.1', 'loss/train': '0.64616', 'examples_per_second': '5.134', 'grad_norm': '17', 'counters/examples': 149760, 'counters/updates': 9360}
skipping logging after 149776 examples to avoid logging too frequently
skipping logging after 149792 examples to avoid logging too frequently
Running evaluation after 149792 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:11,  2.31s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:04,  2.15s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:55,  1.90s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.88s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.12s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 149792: {'rewards_eval/chosen': '-0.58106', 'rewards_eval/rejected': '-0.73557', 'rewards_eval/accuracies': '0.55664', 'rewards_eval/margins': '0.15444', 'logps_eval/rejected': '-129.51', 'logps_eval/chosen': '-124.3', 'loss/eval': '0.66117'}
skipping logging after 149808 examples to avoid logging too frequently
train stats after 149824 examples: {'rewards_train/chosen': '-0.54015', 'rewards_train/rejected': '-0.66174', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.12136', 'logps_train/rejected': '-130.19', 'logps_train/chosen': '-133.65', 'loss/train': '0.68056', 'examples_per_second': '5.6401', 'grad_norm': '21.375', 'counters/examples': 149824, 'counters/updates': 9364}
skipping logging after 149840 examples to avoid logging too frequently
skipping logging after 149856 examples to avoid logging too frequently
skipping logging after 149872 examples to avoid logging too frequently
train stats after 149888 examples: {'rewards_train/chosen': '-0.47244', 'rewards_train/rejected': '-0.74178', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.26947', 'logps_train/rejected': '-134.74', 'logps_train/chosen': '-93.917', 'loss/train': '0.60934', 'examples_per_second': '4.7528', 'grad_norm': '22', 'counters/examples': 149888, 'counters/updates': 9368}
skipping logging after 149904 examples to avoid logging too frequently
skipping logging after 149920 examples to avoid logging too frequently
skipping logging after 149936 examples to avoid logging too frequently
train stats after 149952 examples: {'rewards_train/chosen': '-0.68097', 'rewards_train/rejected': '-0.80235', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.12128', 'logps_train/rejected': '-103.16', 'logps_train/chosen': '-109.83', 'loss/train': '0.66899', 'examples_per_second': '5.9572', 'grad_norm': '19.75', 'counters/examples': 149952, 'counters/updates': 9372}
skipping logging after 149968 examples to avoid logging too frequently
skipping logging after 149984 examples to avoid logging too frequently
skipping logging after 150000 examples to avoid logging too frequently
train stats after 150016 examples: {'rewards_train/chosen': '-0.53186', 'rewards_train/rejected': '-0.74339', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.21148', 'logps_train/rejected': '-122.48', 'logps_train/chosen': '-112.82', 'loss/train': '0.63444', 'examples_per_second': '5.1833', 'grad_norm': '18.375', 'counters/examples': 150016, 'counters/updates': 9376}
skipping logging after 150032 examples to avoid logging too frequently
skipping logging after 150048 examples to avoid logging too frequently
skipping logging after 150064 examples to avoid logging too frequently
train stats after 150080 examples: {'rewards_train/chosen': '-0.45322', 'rewards_train/rejected': '-0.70919', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.25609', 'logps_train/rejected': '-133.05', 'logps_train/chosen': '-135.79', 'loss/train': '0.60972', 'examples_per_second': '5.0589', 'grad_norm': '17.75', 'counters/examples': 150080, 'counters/updates': 9380}
skipping logging after 150096 examples to avoid logging too frequently
skipping logging after 150112 examples to avoid logging too frequently
skipping logging after 150128 examples to avoid logging too frequently
train stats after 150144 examples: {'rewards_train/chosen': '-0.45576', 'rewards_train/rejected': '-0.61402', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.15836', 'logps_train/rejected': '-135.52', 'logps_train/chosen': '-120.83', 'loss/train': '0.65131', 'examples_per_second': '4.34', 'grad_norm': '20.125', 'counters/examples': 150144, 'counters/updates': 9384}
skipping logging after 150160 examples to avoid logging too frequently
skipping logging after 150176 examples to avoid logging too frequently
skipping logging after 150192 examples to avoid logging too frequently
train stats after 150208 examples: {'rewards_train/chosen': '-0.50082', 'rewards_train/rejected': '-0.57036', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.069389', 'logps_train/rejected': '-141.06', 'logps_train/chosen': '-121.4', 'loss/train': '0.68729', 'examples_per_second': '4.6762', 'grad_norm': '18.875', 'counters/examples': 150208, 'counters/updates': 9388}
skipping logging after 150224 examples to avoid logging too frequently
skipping logging after 150240 examples to avoid logging too frequently
skipping logging after 150256 examples to avoid logging too frequently
train stats after 150272 examples: {'rewards_train/chosen': '-0.48959', 'rewards_train/rejected': '-0.75217', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.2626', 'logps_train/rejected': '-134.87', 'logps_train/chosen': '-113.73', 'loss/train': '0.60435', 'examples_per_second': '4.6362', 'grad_norm': '17', 'counters/examples': 150272, 'counters/updates': 9392}
skipping logging after 150288 examples to avoid logging too frequently
skipping logging after 150304 examples to avoid logging too frequently
skipping logging after 150320 examples to avoid logging too frequently
train stats after 150336 examples: {'rewards_train/chosen': '-0.56025', 'rewards_train/rejected': '-0.71984', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.15963', 'logps_train/rejected': '-133.66', 'logps_train/chosen': '-117.56', 'loss/train': '0.65176', 'examples_per_second': '5.0335', 'grad_norm': '19.5', 'counters/examples': 150336, 'counters/updates': 9396}
skipping logging after 150352 examples to avoid logging too frequently
skipping logging after 150368 examples to avoid logging too frequently
skipping logging after 150384 examples to avoid logging too frequently
train stats after 150400 examples: {'rewards_train/chosen': '-0.6049', 'rewards_train/rejected': '-0.74592', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.14105', 'logps_train/rejected': '-131.79', 'logps_train/chosen': '-158.03', 'loss/train': '0.66393', 'examples_per_second': '4.7674', 'grad_norm': '22.875', 'counters/examples': 150400, 'counters/updates': 9400}
skipping logging after 150416 examples to avoid logging too frequently
skipping logging after 150432 examples to avoid logging too frequently
skipping logging after 150448 examples to avoid logging too frequently
train stats after 150464 examples: {'rewards_train/chosen': '-0.59411', 'rewards_train/rejected': '-0.75638', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.16232', 'logps_train/rejected': '-105.66', 'logps_train/chosen': '-125.74', 'loss/train': '0.64948', 'examples_per_second': '5.3576', 'grad_norm': '24.625', 'counters/examples': 150464, 'counters/updates': 9404}
skipping logging after 150480 examples to avoid logging too frequently
skipping logging after 150496 examples to avoid logging too frequently
skipping logging after 150512 examples to avoid logging too frequently
train stats after 150528 examples: {'rewards_train/chosen': '-0.5467', 'rewards_train/rejected': '-0.79149', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.24479', 'logps_train/rejected': '-124.21', 'logps_train/chosen': '-139.09', 'loss/train': '0.61585', 'examples_per_second': '4.9348', 'grad_norm': '19.875', 'counters/examples': 150528, 'counters/updates': 9408}
skipping logging after 150544 examples to avoid logging too frequently
skipping logging after 150560 examples to avoid logging too frequently
skipping logging after 150576 examples to avoid logging too frequently
train stats after 150592 examples: {'rewards_train/chosen': '-0.49681', 'rewards_train/rejected': '-0.78589', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.28915', 'logps_train/rejected': '-146.92', 'logps_train/chosen': '-122.62', 'loss/train': '0.59489', 'examples_per_second': '5.3389', 'grad_norm': '18.75', 'counters/examples': 150592, 'counters/updates': 9412}
skipping logging after 150608 examples to avoid logging too frequently
skipping logging after 150624 examples to avoid logging too frequently
skipping logging after 150640 examples to avoid logging too frequently
train stats after 150656 examples: {'rewards_train/chosen': '-0.53467', 'rewards_train/rejected': '-0.7152', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.18059', 'logps_train/rejected': '-109.65', 'logps_train/chosen': '-141.38', 'loss/train': '0.63704', 'examples_per_second': '4.5342', 'grad_norm': '17.75', 'counters/examples': 150656, 'counters/updates': 9416}
skipping logging after 150672 examples to avoid logging too frequently
skipping logging after 150688 examples to avoid logging too frequently
skipping logging after 150704 examples to avoid logging too frequently
train stats after 150720 examples: {'rewards_train/chosen': '-0.54376', 'rewards_train/rejected': '-0.67894', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.13521', 'logps_train/rejected': '-99.952', 'logps_train/chosen': '-136.55', 'loss/train': '0.6656', 'examples_per_second': '5.0391', 'grad_norm': '23.125', 'counters/examples': 150720, 'counters/updates': 9420}
skipping logging after 150736 examples to avoid logging too frequently
skipping logging after 150752 examples to avoid logging too frequently
skipping logging after 150768 examples to avoid logging too frequently
train stats after 150784 examples: {'rewards_train/chosen': '-0.64698', 'rewards_train/rejected': '-0.75054', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.1036', 'logps_train/rejected': '-117.25', 'logps_train/chosen': '-122.02', 'loss/train': '0.66629', 'examples_per_second': '4.764', 'grad_norm': '20.125', 'counters/examples': 150784, 'counters/updates': 9424}
Running evaluation after 150784 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<01:00,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.83s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.63s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 150784: {'rewards_eval/chosen': '-0.51487', 'rewards_eval/rejected': '-0.66601', 'rewards_eval/accuracies': '0.54883', 'rewards_eval/margins': '0.15114', 'logps_eval/rejected': '-128.82', 'logps_eval/chosen': '-123.64', 'loss/eval': '0.65878'}
skipping logging after 150800 examples to avoid logging too frequently
skipping logging after 150816 examples to avoid logging too frequently
skipping logging after 150832 examples to avoid logging too frequently
train stats after 150848 examples: {'rewards_train/chosen': '-0.55495', 'rewards_train/rejected': '-0.76836', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.21354', 'logps_train/rejected': '-128.87', 'logps_train/chosen': '-125.1', 'loss/train': '0.62241', 'examples_per_second': '4.4835', 'grad_norm': '20', 'counters/examples': 150848, 'counters/updates': 9428}
skipping logging after 150864 examples to avoid logging too frequently
skipping logging after 150880 examples to avoid logging too frequently
skipping logging after 150896 examples to avoid logging too frequently
train stats after 150912 examples: {'rewards_train/chosen': '-0.50146', 'rewards_train/rejected': '-0.7559', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.25453', 'logps_train/rejected': '-135.02', 'logps_train/chosen': '-127.7', 'loss/train': '0.60847', 'examples_per_second': '4.366', 'grad_norm': '19.125', 'counters/examples': 150912, 'counters/updates': 9432}
skipping logging after 150928 examples to avoid logging too frequently
skipping logging after 150944 examples to avoid logging too frequently
skipping logging after 150960 examples to avoid logging too frequently
train stats after 150976 examples: {'rewards_train/chosen': '-0.43452', 'rewards_train/rejected': '-0.64814', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.21356', 'logps_train/rejected': '-148.65', 'logps_train/chosen': '-156.81', 'loss/train': '0.64299', 'examples_per_second': '3.7224', 'grad_norm': '23.25', 'counters/examples': 150976, 'counters/updates': 9436}
skipping logging after 150992 examples to avoid logging too frequently
skipping logging after 151008 examples to avoid logging too frequently
skipping logging after 151024 examples to avoid logging too frequently
train stats after 151040 examples: {'rewards_train/chosen': '-0.57544', 'rewards_train/rejected': '-0.82837', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.25293', 'logps_train/rejected': '-94.301', 'logps_train/chosen': '-124.64', 'loss/train': '0.63322', 'examples_per_second': '4.9125', 'grad_norm': '16.375', 'counters/examples': 151040, 'counters/updates': 9440}
skipping logging after 151056 examples to avoid logging too frequently
skipping logging after 151072 examples to avoid logging too frequently
skipping logging after 151088 examples to avoid logging too frequently
train stats after 151104 examples: {'rewards_train/chosen': '-0.51892', 'rewards_train/rejected': '-0.73062', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.21184', 'logps_train/rejected': '-131.6', 'logps_train/chosen': '-112.82', 'loss/train': '0.6328', 'examples_per_second': '5.1217', 'grad_norm': '17.875', 'counters/examples': 151104, 'counters/updates': 9444}
skipping logging after 151120 examples to avoid logging too frequently
skipping logging after 151136 examples to avoid logging too frequently
skipping logging after 151152 examples to avoid logging too frequently
train stats after 151168 examples: {'rewards_train/chosen': '-0.42732', 'rewards_train/rejected': '-0.71716', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.28977', 'logps_train/rejected': '-126.66', 'logps_train/chosen': '-120.09', 'loss/train': '0.5944', 'examples_per_second': '5.2855', 'grad_norm': '17', 'counters/examples': 151168, 'counters/updates': 9448}
skipping logging after 151184 examples to avoid logging too frequently
skipping logging after 151200 examples to avoid logging too frequently
skipping logging after 151216 examples to avoid logging too frequently
train stats after 151232 examples: {'rewards_train/chosen': '-0.47408', 'rewards_train/rejected': '-0.71731', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.24313', 'logps_train/rejected': '-122.6', 'logps_train/chosen': '-151.73', 'loss/train': '0.62949', 'examples_per_second': '5.5692', 'grad_norm': '21', 'counters/examples': 151232, 'counters/updates': 9452}
skipping logging after 151248 examples to avoid logging too frequently
skipping logging after 151264 examples to avoid logging too frequently
skipping logging after 151280 examples to avoid logging too frequently
train stats after 151296 examples: {'rewards_train/chosen': '-0.536', 'rewards_train/rejected': '-0.62403', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.088039', 'logps_train/rejected': '-109.04', 'logps_train/chosen': '-123.64', 'loss/train': '0.6761', 'examples_per_second': '5.3082', 'grad_norm': '21.625', 'counters/examples': 151296, 'counters/updates': 9456}
skipping logging after 151312 examples to avoid logging too frequently
skipping logging after 151328 examples to avoid logging too frequently
skipping logging after 151344 examples to avoid logging too frequently
train stats after 151360 examples: {'rewards_train/chosen': '-0.55202', 'rewards_train/rejected': '-0.73539', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.18343', 'logps_train/rejected': '-127.27', 'logps_train/chosen': '-125.53', 'loss/train': '0.63205', 'examples_per_second': '6.0363', 'grad_norm': '17.25', 'counters/examples': 151360, 'counters/updates': 9460}
skipping logging after 151376 examples to avoid logging too frequently
skipping logging after 151392 examples to avoid logging too frequently
skipping logging after 151408 examples to avoid logging too frequently
train stats after 151424 examples: {'rewards_train/chosen': '-0.44283', 'rewards_train/rejected': '-0.5598', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.11711', 'logps_train/rejected': '-121.45', 'logps_train/chosen': '-125.63', 'loss/train': '0.66919', 'examples_per_second': '4.7281', 'grad_norm': '18.625', 'counters/examples': 151424, 'counters/updates': 9464}
skipping logging after 151440 examples to avoid logging too frequently
skipping logging after 151456 examples to avoid logging too frequently
skipping logging after 151472 examples to avoid logging too frequently
train stats after 151488 examples: {'rewards_train/chosen': '-0.4975', 'rewards_train/rejected': '-0.61524', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.11783', 'logps_train/rejected': '-113.13', 'logps_train/chosen': '-91.304', 'loss/train': '0.67096', 'examples_per_second': '5.7647', 'grad_norm': '21', 'counters/examples': 151488, 'counters/updates': 9468}
skipping logging after 151504 examples to avoid logging too frequently
skipping logging after 151520 examples to avoid logging too frequently
skipping logging after 151536 examples to avoid logging too frequently
train stats after 151552 examples: {'rewards_train/chosen': '-0.59074', 'rewards_train/rejected': '-0.75167', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.16087', 'logps_train/rejected': '-162.9', 'logps_train/chosen': '-111.57', 'loss/train': '0.65189', 'examples_per_second': '5.6436', 'grad_norm': '19.75', 'counters/examples': 151552, 'counters/updates': 9472}
skipping logging after 151568 examples to avoid logging too frequently
skipping logging after 151584 examples to avoid logging too frequently
skipping logging after 151600 examples to avoid logging too frequently
train stats after 151616 examples: {'rewards_train/chosen': '-0.47443', 'rewards_train/rejected': '-0.72248', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.2481', 'logps_train/rejected': '-113.17', 'logps_train/chosen': '-107.07', 'loss/train': '0.60873', 'examples_per_second': '4.5122', 'grad_norm': '18', 'counters/examples': 151616, 'counters/updates': 9476}
skipping logging after 151632 examples to avoid logging too frequently
skipping logging after 151648 examples to avoid logging too frequently
skipping logging after 151664 examples to avoid logging too frequently
train stats after 151680 examples: {'rewards_train/chosen': '-0.45502', 'rewards_train/rejected': '-0.63354', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.1787', 'logps_train/rejected': '-109.43', 'logps_train/chosen': '-128.03', 'loss/train': '0.64476', 'examples_per_second': '5.3541', 'grad_norm': '19.5', 'counters/examples': 151680, 'counters/updates': 9480}
skipping logging after 151696 examples to avoid logging too frequently
skipping logging after 151712 examples to avoid logging too frequently
skipping logging after 151728 examples to avoid logging too frequently
train stats after 151744 examples: {'rewards_train/chosen': '-0.56307', 'rewards_train/rejected': '-0.74732', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.1844', 'logps_train/rejected': '-146.21', 'logps_train/chosen': '-123.22', 'loss/train': '0.64078', 'examples_per_second': '5.3765', 'grad_norm': '18.375', 'counters/examples': 151744, 'counters/updates': 9484}
skipping logging after 151760 examples to avoid logging too frequently
skipping logging after 151776 examples to avoid logging too frequently
Running evaluation after 151776 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:08,  2.21s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:03,  2.11s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.89s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.87s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 151776: {'rewards_eval/chosen': '-0.56317', 'rewards_eval/rejected': '-0.71644', 'rewards_eval/accuracies': '0.54688', 'rewards_eval/margins': '0.15329', 'logps_eval/rejected': '-129.32', 'logps_eval/chosen': '-124.13', 'loss/eval': '0.66034'}
skipping logging after 151792 examples to avoid logging too frequently
train stats after 151808 examples: {'rewards_train/chosen': '-0.391', 'rewards_train/rejected': '-0.50354', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.11259', 'logps_train/rejected': '-136.49', 'logps_train/chosen': '-128.01', 'loss/train': '0.67096', 'examples_per_second': '4.2716', 'grad_norm': '19', 'counters/examples': 151808, 'counters/updates': 9488}
skipping logging after 151824 examples to avoid logging too frequently
skipping logging after 151840 examples to avoid logging too frequently
skipping logging after 151856 examples to avoid logging too frequently
train stats after 151872 examples: {'rewards_train/chosen': '-0.44567', 'rewards_train/rejected': '-0.79887', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.35353', 'logps_train/rejected': '-150.38', 'logps_train/chosen': '-133', 'loss/train': '0.60376', 'examples_per_second': '5.2024', 'grad_norm': '19.5', 'counters/examples': 151872, 'counters/updates': 9492}
skipping logging after 151888 examples to avoid logging too frequently
skipping logging after 151904 examples to avoid logging too frequently
skipping logging after 151920 examples to avoid logging too frequently
train stats after 151936 examples: {'rewards_train/chosen': '-0.64993', 'rewards_train/rejected': '-0.91629', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.26645', 'logps_train/rejected': '-160.18', 'logps_train/chosen': '-144.38', 'loss/train': '0.61569', 'examples_per_second': '4.531', 'grad_norm': '19.375', 'counters/examples': 151936, 'counters/updates': 9496}
skipping logging after 151952 examples to avoid logging too frequently
skipping logging after 151968 examples to avoid logging too frequently
skipping logging after 151984 examples to avoid logging too frequently
train stats after 152000 examples: {'rewards_train/chosen': '-0.62918', 'rewards_train/rejected': '-0.82142', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.19222', 'logps_train/rejected': '-99.408', 'logps_train/chosen': '-107.27', 'loss/train': '0.6358', 'examples_per_second': '5.7087', 'grad_norm': '18', 'counters/examples': 152000, 'counters/updates': 9500}
skipping logging after 152016 examples to avoid logging too frequently
skipping logging after 152032 examples to avoid logging too frequently
skipping logging after 152048 examples to avoid logging too frequently
train stats after 152064 examples: {'rewards_train/chosen': '-0.55973', 'rewards_train/rejected': '-0.91624', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.35633', 'logps_train/rejected': '-136.3', 'logps_train/chosen': '-122.24', 'loss/train': '0.57434', 'examples_per_second': '5.7389', 'grad_norm': '17.375', 'counters/examples': 152064, 'counters/updates': 9504}
skipping logging after 152080 examples to avoid logging too frequently
skipping logging after 152096 examples to avoid logging too frequently
skipping logging after 152112 examples to avoid logging too frequently
train stats after 152128 examples: {'rewards_train/chosen': '-0.59947', 'rewards_train/rejected': '-0.80349', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.20402', 'logps_train/rejected': '-141.06', 'logps_train/chosen': '-148.05', 'loss/train': '0.64038', 'examples_per_second': '5.0659', 'grad_norm': '20.125', 'counters/examples': 152128, 'counters/updates': 9508}
skipping logging after 152144 examples to avoid logging too frequently
skipping logging after 152160 examples to avoid logging too frequently
skipping logging after 152176 examples to avoid logging too frequently
train stats after 152192 examples: {'rewards_train/chosen': '-0.7452', 'rewards_train/rejected': '-0.80828', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.063202', 'logps_train/rejected': '-120.75', 'logps_train/chosen': '-165.95', 'loss/train': '0.71188', 'examples_per_second': '4.1438', 'grad_norm': '23.125', 'counters/examples': 152192, 'counters/updates': 9512}
skipping logging after 152208 examples to avoid logging too frequently
skipping logging after 152224 examples to avoid logging too frequently
skipping logging after 152240 examples to avoid logging too frequently
train stats after 152256 examples: {'rewards_train/chosen': '-0.57907', 'rewards_train/rejected': '-0.73367', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.15472', 'logps_train/rejected': '-129.85', 'logps_train/chosen': '-130', 'loss/train': '0.64114', 'examples_per_second': '4.267', 'grad_norm': '17.5', 'counters/examples': 152256, 'counters/updates': 9516}
skipping logging after 152272 examples to avoid logging too frequently
skipping logging after 152288 examples to avoid logging too frequently
skipping logging after 152304 examples to avoid logging too frequently
train stats after 152320 examples: {'rewards_train/chosen': '-0.55009', 'rewards_train/rejected': '-0.76879', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.21869', 'logps_train/rejected': '-147.27', 'logps_train/chosen': '-111.14', 'loss/train': '0.62569', 'examples_per_second': '4.983', 'grad_norm': '19.75', 'counters/examples': 152320, 'counters/updates': 9520}
skipping logging after 152336 examples to avoid logging too frequently
skipping logging after 152352 examples to avoid logging too frequently
skipping logging after 152368 examples to avoid logging too frequently
train stats after 152384 examples: {'rewards_train/chosen': '-0.60055', 'rewards_train/rejected': '-0.88308', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.28259', 'logps_train/rejected': '-113.97', 'logps_train/chosen': '-122.35', 'loss/train': '0.60663', 'examples_per_second': '5.1844', 'grad_norm': '17.75', 'counters/examples': 152384, 'counters/updates': 9524}
skipping logging after 152400 examples to avoid logging too frequently
skipping logging after 152416 examples to avoid logging too frequently
skipping logging after 152432 examples to avoid logging too frequently
train stats after 152448 examples: {'rewards_train/chosen': '-0.53704', 'rewards_train/rejected': '-0.8587', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.32135', 'logps_train/rejected': '-116.74', 'logps_train/chosen': '-110.63', 'loss/train': '0.59628', 'examples_per_second': '5.3363', 'grad_norm': '16', 'counters/examples': 152448, 'counters/updates': 9528}
skipping logging after 152464 examples to avoid logging too frequently
skipping logging after 152480 examples to avoid logging too frequently
skipping logging after 152496 examples to avoid logging too frequently
train stats after 152512 examples: {'rewards_train/chosen': '-0.62938', 'rewards_train/rejected': '-0.93554', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.30596', 'logps_train/rejected': '-137.14', 'logps_train/chosen': '-150.41', 'loss/train': '0.5835', 'examples_per_second': '4.325', 'grad_norm': '21.5', 'counters/examples': 152512, 'counters/updates': 9532}
skipping logging after 152528 examples to avoid logging too frequently
skipping logging after 152544 examples to avoid logging too frequently
skipping logging after 152560 examples to avoid logging too frequently
train stats after 152576 examples: {'rewards_train/chosen': '-0.61876', 'rewards_train/rejected': '-0.83809', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.21944', 'logps_train/rejected': '-131.8', 'logps_train/chosen': '-111.72', 'loss/train': '0.6272', 'examples_per_second': '5.9985', 'grad_norm': '18.375', 'counters/examples': 152576, 'counters/updates': 9536}
skipping logging after 152592 examples to avoid logging too frequently
skipping logging after 152608 examples to avoid logging too frequently
skipping logging after 152624 examples to avoid logging too frequently
train stats after 152640 examples: {'rewards_train/chosen': '-0.70604', 'rewards_train/rejected': '-0.82021', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.1144', 'logps_train/rejected': '-132.11', 'logps_train/chosen': '-132.54', 'loss/train': '0.6821', 'examples_per_second': '4.436', 'grad_norm': '20.875', 'counters/examples': 152640, 'counters/updates': 9540}
skipping logging after 152656 examples to avoid logging too frequently
skipping logging after 152672 examples to avoid logging too frequently
skipping logging after 152688 examples to avoid logging too frequently
train stats after 152704 examples: {'rewards_train/chosen': '-0.66956', 'rewards_train/rejected': '-0.79625', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.12668', 'logps_train/rejected': '-112.49', 'logps_train/chosen': '-130.41', 'loss/train': '0.67513', 'examples_per_second': '6.1509', 'grad_norm': '21', 'counters/examples': 152704, 'counters/updates': 9544}
skipping logging after 152720 examples to avoid logging too frequently
skipping logging after 152736 examples to avoid logging too frequently
skipping logging after 152752 examples to avoid logging too frequently
train stats after 152768 examples: {'rewards_train/chosen': '-0.73858', 'rewards_train/rejected': '-0.80261', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.064102', 'logps_train/rejected': '-135.02', 'logps_train/chosen': '-127.02', 'loss/train': '0.69437', 'examples_per_second': '5.1522', 'grad_norm': '24.125', 'counters/examples': 152768, 'counters/updates': 9548}
Running evaluation after 152768 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 152768: {'rewards_eval/chosen': '-0.74053', 'rewards_eval/rejected': '-0.8871', 'rewards_eval/accuracies': '0.55078', 'rewards_eval/margins': '0.14657', 'logps_eval/rejected': '-131.03', 'logps_eval/chosen': '-125.9', 'loss/eval': '0.66814'}
skipping logging after 152784 examples to avoid logging too frequently
skipping logging after 152800 examples to avoid logging too frequently
skipping logging after 152816 examples to avoid logging too frequently
train stats after 152832 examples: {'rewards_train/chosen': '-0.82374', 'rewards_train/rejected': '-1.0424', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.21873', 'logps_train/rejected': '-107.14', 'logps_train/chosen': '-138.12', 'loss/train': '0.64702', 'examples_per_second': '4.2966', 'grad_norm': '25.375', 'counters/examples': 152832, 'counters/updates': 9552}
skipping logging after 152848 examples to avoid logging too frequently
skipping logging after 152864 examples to avoid logging too frequently
skipping logging after 152880 examples to avoid logging too frequently
train stats after 152896 examples: {'rewards_train/chosen': '-0.73231', 'rewards_train/rejected': '-0.96483', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.2325', 'logps_train/rejected': '-133.71', 'logps_train/chosen': '-108.98', 'loss/train': '0.61125', 'examples_per_second': '4.3036', 'grad_norm': '22', 'counters/examples': 152896, 'counters/updates': 9556}
skipping logging after 152912 examples to avoid logging too frequently
skipping logging after 152928 examples to avoid logging too frequently
skipping logging after 152944 examples to avoid logging too frequently
train stats after 152960 examples: {'rewards_train/chosen': '-0.51073', 'rewards_train/rejected': '-0.68024', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.16948', 'logps_train/rejected': '-154.28', 'logps_train/chosen': '-133.1', 'loss/train': '0.6497', 'examples_per_second': '4.1207', 'grad_norm': '18.75', 'counters/examples': 152960, 'counters/updates': 9560}
skipping logging after 152976 examples to avoid logging too frequently
skipping logging after 152992 examples to avoid logging too frequently
skipping logging after 153008 examples to avoid logging too frequently
train stats after 153024 examples: {'rewards_train/chosen': '-0.64971', 'rewards_train/rejected': '-0.85012', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.20058', 'logps_train/rejected': '-136.55', 'logps_train/chosen': '-122.57', 'loss/train': '0.65005', 'examples_per_second': '4.8086', 'grad_norm': '17.375', 'counters/examples': 153024, 'counters/updates': 9564}
skipping logging after 153040 examples to avoid logging too frequently
skipping logging after 153056 examples to avoid logging too frequently
skipping logging after 153072 examples to avoid logging too frequently
train stats after 153088 examples: {'rewards_train/chosen': '-0.63713', 'rewards_train/rejected': '-0.94478', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.30763', 'logps_train/rejected': '-133.36', 'logps_train/chosen': '-120.35', 'loss/train': '0.60084', 'examples_per_second': '5.3585', 'grad_norm': '19.875', 'counters/examples': 153088, 'counters/updates': 9568}
skipping logging after 153104 examples to avoid logging too frequently
skipping logging after 153120 examples to avoid logging too frequently
skipping logging after 153136 examples to avoid logging too frequently
train stats after 153152 examples: {'rewards_train/chosen': '-0.62019', 'rewards_train/rejected': '-0.86627', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.24609', 'logps_train/rejected': '-129.54', 'logps_train/chosen': '-125.59', 'loss/train': '0.60446', 'examples_per_second': '5.7721', 'grad_norm': '23.875', 'counters/examples': 153152, 'counters/updates': 9572}
skipping logging after 153168 examples to avoid logging too frequently
skipping logging after 153184 examples to avoid logging too frequently
skipping logging after 153200 examples to avoid logging too frequently
train stats after 153216 examples: {'rewards_train/chosen': '-0.59906', 'rewards_train/rejected': '-0.89111', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.29206', 'logps_train/rejected': '-133.79', 'logps_train/chosen': '-137.88', 'loss/train': '0.59587', 'examples_per_second': '4.7043', 'grad_norm': '22', 'counters/examples': 153216, 'counters/updates': 9576}
skipping logging after 153232 examples to avoid logging too frequently
skipping logging after 153248 examples to avoid logging too frequently
skipping logging after 153264 examples to avoid logging too frequently
train stats after 153280 examples: {'rewards_train/chosen': '-0.64761', 'rewards_train/rejected': '-0.81069', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.16311', 'logps_train/rejected': '-122.59', 'logps_train/chosen': '-109.83', 'loss/train': '0.65862', 'examples_per_second': '5.6493', 'grad_norm': '21.25', 'counters/examples': 153280, 'counters/updates': 9580}
skipping logging after 153296 examples to avoid logging too frequently
skipping logging after 153312 examples to avoid logging too frequently
skipping logging after 153328 examples to avoid logging too frequently
train stats after 153344 examples: {'rewards_train/chosen': '-0.60364', 'rewards_train/rejected': '-0.79958', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.19593', 'logps_train/rejected': '-108.14', 'logps_train/chosen': '-129.79', 'loss/train': '0.64317', 'examples_per_second': '5.3867', 'grad_norm': '21.125', 'counters/examples': 153344, 'counters/updates': 9584}
skipping logging after 153360 examples to avoid logging too frequently
skipping logging after 153376 examples to avoid logging too frequently
skipping logging after 153392 examples to avoid logging too frequently
train stats after 153408 examples: {'rewards_train/chosen': '-0.54039', 'rewards_train/rejected': '-0.87091', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.3305', 'logps_train/rejected': '-132.35', 'logps_train/chosen': '-122.11', 'loss/train': '0.58911', 'examples_per_second': '4.8492', 'grad_norm': '20', 'counters/examples': 153408, 'counters/updates': 9588}
skipping logging after 153424 examples to avoid logging too frequently
skipping logging after 153440 examples to avoid logging too frequently
skipping logging after 153456 examples to avoid logging too frequently
train stats after 153472 examples: {'rewards_train/chosen': '-0.61391', 'rewards_train/rejected': '-0.94854', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.3346', 'logps_train/rejected': '-129.86', 'logps_train/chosen': '-135.51', 'loss/train': '0.6011', 'examples_per_second': '4.5532', 'grad_norm': '17.875', 'counters/examples': 153472, 'counters/updates': 9592}
skipping logging after 153488 examples to avoid logging too frequently
skipping logging after 153504 examples to avoid logging too frequently
skipping logging after 153520 examples to avoid logging too frequently
train stats after 153536 examples: {'rewards_train/chosen': '-0.56481', 'rewards_train/rejected': '-0.81023', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.2454', 'logps_train/rejected': '-137.98', 'logps_train/chosen': '-135.17', 'loss/train': '0.61588', 'examples_per_second': '4.2116', 'grad_norm': '20.25', 'counters/examples': 153536, 'counters/updates': 9596}
skipping logging after 153552 examples to avoid logging too frequently
skipping logging after 153568 examples to avoid logging too frequently
skipping logging after 153584 examples to avoid logging too frequently
train stats after 153600 examples: {'rewards_train/chosen': '-0.69623', 'rewards_train/rejected': '-0.91468', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.21852', 'logps_train/rejected': '-103.27', 'logps_train/chosen': '-119.03', 'loss/train': '0.63987', 'examples_per_second': '5.7923', 'grad_norm': '17.5', 'counters/examples': 153600, 'counters/updates': 9600}
skipping logging after 153616 examples to avoid logging too frequently
skipping logging after 153632 examples to avoid logging too frequently
skipping logging after 153648 examples to avoid logging too frequently
train stats after 153664 examples: {'rewards_train/chosen': '-0.61609', 'rewards_train/rejected': '-1.0005', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.38435', 'logps_train/rejected': '-103.09', 'logps_train/chosen': '-127.03', 'loss/train': '0.56659', 'examples_per_second': '6.2458', 'grad_norm': '17.625', 'counters/examples': 153664, 'counters/updates': 9604}
skipping logging after 153680 examples to avoid logging too frequently
skipping logging after 153696 examples to avoid logging too frequently
skipping logging after 153712 examples to avoid logging too frequently
train stats after 153728 examples: {'rewards_train/chosen': '-0.52856', 'rewards_train/rejected': '-0.71769', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.1891', 'logps_train/rejected': '-113.43', 'logps_train/chosen': '-131.89', 'loss/train': '0.63583', 'examples_per_second': '5.7508', 'grad_norm': '20.875', 'counters/examples': 153728, 'counters/updates': 9608}
skipping logging after 153744 examples to avoid logging too frequently
skipping logging after 153760 examples to avoid logging too frequently
Running evaluation after 153760 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:13,  2.36s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:05,  2.17s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:55,  1.92s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.89s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.54s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 153760: {'rewards_eval/chosen': '-0.66605', 'rewards_eval/rejected': '-0.83118', 'rewards_eval/accuracies': '0.54883', 'rewards_eval/margins': '0.16512', 'logps_eval/rejected': '-130.47', 'logps_eval/chosen': '-125.15', 'loss/eval': '0.66482'}
skipping logging after 153776 examples to avoid logging too frequently
train stats after 153792 examples: {'rewards_train/chosen': '-0.64011', 'rewards_train/rejected': '-0.85331', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.21326', 'logps_train/rejected': '-145.51', 'logps_train/chosen': '-142.48', 'loss/train': '0.63129', 'examples_per_second': '5.176', 'grad_norm': '19.125', 'counters/examples': 153792, 'counters/updates': 9612}
skipping logging after 153808 examples to avoid logging too frequently
skipping logging after 153824 examples to avoid logging too frequently
skipping logging after 153840 examples to avoid logging too frequently
train stats after 153856 examples: {'rewards_train/chosen': '-0.68215', 'rewards_train/rejected': '-0.75786', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.075714', 'logps_train/rejected': '-156.2', 'logps_train/chosen': '-149.51', 'loss/train': '0.69435', 'examples_per_second': '4.6254', 'grad_norm': '25.5', 'counters/examples': 153856, 'counters/updates': 9616}
skipping logging after 153872 examples to avoid logging too frequently
skipping logging after 153888 examples to avoid logging too frequently
skipping logging after 153904 examples to avoid logging too frequently
train stats after 153920 examples: {'rewards_train/chosen': '-0.65486', 'rewards_train/rejected': '-0.79279', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.13804', 'logps_train/rejected': '-124.75', 'logps_train/chosen': '-136.12', 'loss/train': '0.66951', 'examples_per_second': '4.3173', 'grad_norm': '21.625', 'counters/examples': 153920, 'counters/updates': 9620}
skipping logging after 153936 examples to avoid logging too frequently
skipping logging after 153952 examples to avoid logging too frequently
skipping logging after 153968 examples to avoid logging too frequently
train stats after 153984 examples: {'rewards_train/chosen': '-0.51306', 'rewards_train/rejected': '-0.72981', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.2168', 'logps_train/rejected': '-131.09', 'logps_train/chosen': '-146.39', 'loss/train': '0.62779', 'examples_per_second': '4.9137', 'grad_norm': '21.25', 'counters/examples': 153984, 'counters/updates': 9624}
skipping logging after 154000 examples to avoid logging too frequently
skipping logging after 154016 examples to avoid logging too frequently
skipping logging after 154032 examples to avoid logging too frequently
train stats after 154048 examples: {'rewards_train/chosen': '-0.53114', 'rewards_train/rejected': '-0.76143', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.2303', 'logps_train/rejected': '-119.36', 'logps_train/chosen': '-124.05', 'loss/train': '0.6201', 'examples_per_second': '5.7374', 'grad_norm': '17.375', 'counters/examples': 154048, 'counters/updates': 9628}
skipping logging after 154064 examples to avoid logging too frequently
skipping logging after 154080 examples to avoid logging too frequently
skipping logging after 154096 examples to avoid logging too frequently
train stats after 154112 examples: {'rewards_train/chosen': '-0.60525', 'rewards_train/rejected': '-0.86256', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.25738', 'logps_train/rejected': '-133.56', 'logps_train/chosen': '-143.39', 'loss/train': '0.6201', 'examples_per_second': '4.4617', 'grad_norm': '22.375', 'counters/examples': 154112, 'counters/updates': 9632}
skipping logging after 154128 examples to avoid logging too frequently
skipping logging after 154144 examples to avoid logging too frequently
skipping logging after 154160 examples to avoid logging too frequently
train stats after 154176 examples: {'rewards_train/chosen': '-0.74861', 'rewards_train/rejected': '-0.94061', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.19178', 'logps_train/rejected': '-122.28', 'logps_train/chosen': '-134.2', 'loss/train': '0.63739', 'examples_per_second': '4.481', 'grad_norm': '20.625', 'counters/examples': 154176, 'counters/updates': 9636}
skipping logging after 154192 examples to avoid logging too frequently
skipping logging after 154208 examples to avoid logging too frequently
skipping logging after 154224 examples to avoid logging too frequently
train stats after 154240 examples: {'rewards_train/chosen': '-0.64356', 'rewards_train/rejected': '-0.82969', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.18629', 'logps_train/rejected': '-124.31', 'logps_train/chosen': '-120.85', 'loss/train': '0.64317', 'examples_per_second': '4.9446', 'grad_norm': '19.125', 'counters/examples': 154240, 'counters/updates': 9640}
skipping logging after 154256 examples to avoid logging too frequently
skipping logging after 154272 examples to avoid logging too frequently
skipping logging after 154288 examples to avoid logging too frequently
train stats after 154304 examples: {'rewards_train/chosen': '-0.60277', 'rewards_train/rejected': '-0.87471', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.27214', 'logps_train/rejected': '-150.81', 'logps_train/chosen': '-163.17', 'loss/train': '0.62304', 'examples_per_second': '5.2016', 'grad_norm': '19.75', 'counters/examples': 154304, 'counters/updates': 9644}
skipping logging after 154320 examples to avoid logging too frequently
skipping logging after 154336 examples to avoid logging too frequently
skipping logging after 154352 examples to avoid logging too frequently
train stats after 154368 examples: {'rewards_train/chosen': '-0.76404', 'rewards_train/rejected': '-0.88838', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.12421', 'logps_train/rejected': '-106.3', 'logps_train/chosen': '-112.81', 'loss/train': '0.66702', 'examples_per_second': '5.2113', 'grad_norm': '20.875', 'counters/examples': 154368, 'counters/updates': 9648}
skipping logging after 154384 examples to avoid logging too frequently
skipping logging after 154400 examples to avoid logging too frequently
skipping logging after 154416 examples to avoid logging too frequently
train stats after 154432 examples: {'rewards_train/chosen': '-0.76684', 'rewards_train/rejected': '-1.0868', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.31992', 'logps_train/rejected': '-114.52', 'logps_train/chosen': '-117.23', 'loss/train': '0.60431', 'examples_per_second': '4.8178', 'grad_norm': '20.125', 'counters/examples': 154432, 'counters/updates': 9652}
skipping logging after 154448 examples to avoid logging too frequently
skipping logging after 154464 examples to avoid logging too frequently
skipping logging after 154480 examples to avoid logging too frequently
train stats after 154496 examples: {'rewards_train/chosen': '-0.61205', 'rewards_train/rejected': '-0.87637', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.26417', 'logps_train/rejected': '-118.76', 'logps_train/chosen': '-148.18', 'loss/train': '0.61707', 'examples_per_second': '4.5054', 'grad_norm': '19.75', 'counters/examples': 154496, 'counters/updates': 9656}
skipping logging after 154512 examples to avoid logging too frequently
skipping logging after 154528 examples to avoid logging too frequently
skipping logging after 154544 examples to avoid logging too frequently
train stats after 154560 examples: {'rewards_train/chosen': '-0.84443', 'rewards_train/rejected': '-1.06', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.21546', 'logps_train/rejected': '-116.58', 'logps_train/chosen': '-109.36', 'loss/train': '0.63087', 'examples_per_second': '6.4775', 'grad_norm': '17.875', 'counters/examples': 154560, 'counters/updates': 9660}
skipping logging after 154576 examples to avoid logging too frequently
skipping logging after 154592 examples to avoid logging too frequently
skipping logging after 154608 examples to avoid logging too frequently
train stats after 154624 examples: {'rewards_train/chosen': '-0.51291', 'rewards_train/rejected': '-0.73792', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.22483', 'logps_train/rejected': '-136.42', 'logps_train/chosen': '-118.44', 'loss/train': '0.63654', 'examples_per_second': '5.2883', 'grad_norm': '21.375', 'counters/examples': 154624, 'counters/updates': 9664}
skipping logging after 154640 examples to avoid logging too frequently
skipping logging after 154656 examples to avoid logging too frequently
skipping logging after 154672 examples to avoid logging too frequently
train stats after 154688 examples: {'rewards_train/chosen': '-0.66437', 'rewards_train/rejected': '-0.77335', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.10907', 'logps_train/rejected': '-108.95', 'logps_train/chosen': '-132.28', 'loss/train': '0.69937', 'examples_per_second': '4.6895', 'grad_norm': '24.5', 'counters/examples': 154688, 'counters/updates': 9668}
skipping logging after 154704 examples to avoid logging too frequently
skipping logging after 154720 examples to avoid logging too frequently
skipping logging after 154736 examples to avoid logging too frequently
train stats after 154752 examples: {'rewards_train/chosen': '-0.66992', 'rewards_train/rejected': '-0.84607', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.17613', 'logps_train/rejected': '-120.68', 'logps_train/chosen': '-139.6', 'loss/train': '0.64647', 'examples_per_second': '5.2644', 'grad_norm': '18.5', 'counters/examples': 154752, 'counters/updates': 9672}
Running evaluation after 154752 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 154752: {'rewards_eval/chosen': '-0.62768', 'rewards_eval/rejected': '-0.78566', 'rewards_eval/accuracies': '0.5625', 'rewards_eval/margins': '0.15811', 'logps_eval/rejected': '-130.01', 'logps_eval/chosen': '-124.77', 'loss/eval': '0.66194'}
skipping logging after 154768 examples to avoid logging too frequently
skipping logging after 154784 examples to avoid logging too frequently
skipping logging after 154800 examples to avoid logging too frequently
train stats after 154816 examples: {'rewards_train/chosen': '-0.63837', 'rewards_train/rejected': '-0.76543', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.12709', 'logps_train/rejected': '-132.89', 'logps_train/chosen': '-118.84', 'loss/train': '0.66119', 'examples_per_second': '4.6223', 'grad_norm': '21.125', 'counters/examples': 154816, 'counters/updates': 9676}
skipping logging after 154832 examples to avoid logging too frequently
skipping logging after 154848 examples to avoid logging too frequently
skipping logging after 154864 examples to avoid logging too frequently
train stats after 154880 examples: {'rewards_train/chosen': '-0.65635', 'rewards_train/rejected': '-0.94949', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.29316', 'logps_train/rejected': '-116.08', 'logps_train/chosen': '-116.05', 'loss/train': '0.5912', 'examples_per_second': '4.967', 'grad_norm': '19.25', 'counters/examples': 154880, 'counters/updates': 9680}
skipping logging after 154896 examples to avoid logging too frequently
skipping logging after 154912 examples to avoid logging too frequently
skipping logging after 154928 examples to avoid logging too frequently
train stats after 154944 examples: {'rewards_train/chosen': '-0.50945', 'rewards_train/rejected': '-0.90196', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.39276', 'logps_train/rejected': '-155.21', 'logps_train/chosen': '-134.96', 'loss/train': '0.56101', 'examples_per_second': '4.0494', 'grad_norm': '18.875', 'counters/examples': 154944, 'counters/updates': 9684}
skipping logging after 154960 examples to avoid logging too frequently
skipping logging after 154976 examples to avoid logging too frequently
skipping logging after 154992 examples to avoid logging too frequently
train stats after 155008 examples: {'rewards_train/chosen': '-0.55677', 'rewards_train/rejected': '-0.67041', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.11364', 'logps_train/rejected': '-131.71', 'logps_train/chosen': '-134.64', 'loss/train': '0.67577', 'examples_per_second': '4.6792', 'grad_norm': '20.375', 'counters/examples': 155008, 'counters/updates': 9688}
skipping logging after 155024 examples to avoid logging too frequently
skipping logging after 155040 examples to avoid logging too frequently
skipping logging after 155056 examples to avoid logging too frequently
train stats after 155072 examples: {'rewards_train/chosen': '-0.61243', 'rewards_train/rejected': '-0.83241', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.22009', 'logps_train/rejected': '-152.65', 'logps_train/chosen': '-131.85', 'loss/train': '0.64119', 'examples_per_second': '4.8178', 'grad_norm': '23', 'counters/examples': 155072, 'counters/updates': 9692}
skipping logging after 155088 examples to avoid logging too frequently
skipping logging after 155104 examples to avoid logging too frequently
skipping logging after 155120 examples to avoid logging too frequently
train stats after 155136 examples: {'rewards_train/chosen': '-0.71773', 'rewards_train/rejected': '-0.86709', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.14939', 'logps_train/rejected': '-113.76', 'logps_train/chosen': '-123.68', 'loss/train': '0.65659', 'examples_per_second': '5.8773', 'grad_norm': '21.25', 'counters/examples': 155136, 'counters/updates': 9696}
skipping logging after 155152 examples to avoid logging too frequently
skipping logging after 155168 examples to avoid logging too frequently
skipping logging after 155184 examples to avoid logging too frequently
train stats after 155200 examples: {'rewards_train/chosen': '-0.5879', 'rewards_train/rejected': '-0.67953', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.09137', 'logps_train/rejected': '-114.78', 'logps_train/chosen': '-128.15', 'loss/train': '0.69765', 'examples_per_second': '5.0433', 'grad_norm': '20.5', 'counters/examples': 155200, 'counters/updates': 9700}
skipping logging after 155216 examples to avoid logging too frequently
skipping logging after 155232 examples to avoid logging too frequently
skipping logging after 155248 examples to avoid logging too frequently
train stats after 155264 examples: {'rewards_train/chosen': '-0.46314', 'rewards_train/rejected': '-0.68918', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.22592', 'logps_train/rejected': '-126.44', 'logps_train/chosen': '-127.9', 'loss/train': '0.61786', 'examples_per_second': '5.4994', 'grad_norm': '17.75', 'counters/examples': 155264, 'counters/updates': 9704}
skipping logging after 155280 examples to avoid logging too frequently
skipping logging after 155296 examples to avoid logging too frequently
skipping logging after 155312 examples to avoid logging too frequently
train stats after 155328 examples: {'rewards_train/chosen': '-0.45876', 'rewards_train/rejected': '-0.6664', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.20762', 'logps_train/rejected': '-131.18', 'logps_train/chosen': '-121.57', 'loss/train': '0.63235', 'examples_per_second': '5.7189', 'grad_norm': '26.25', 'counters/examples': 155328, 'counters/updates': 9708}
skipping logging after 155344 examples to avoid logging too frequently
skipping logging after 155360 examples to avoid logging too frequently
skipping logging after 155376 examples to avoid logging too frequently
train stats after 155392 examples: {'rewards_train/chosen': '-0.58257', 'rewards_train/rejected': '-0.76327', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.18076', 'logps_train/rejected': '-131.22', 'logps_train/chosen': '-108.23', 'loss/train': '0.6375', 'examples_per_second': '5.4316', 'grad_norm': '17.875', 'counters/examples': 155392, 'counters/updates': 9712}
skipping logging after 155408 examples to avoid logging too frequently
skipping logging after 155424 examples to avoid logging too frequently
skipping logging after 155440 examples to avoid logging too frequently
train stats after 155456 examples: {'rewards_train/chosen': '-0.46529', 'rewards_train/rejected': '-0.62771', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.16248', 'logps_train/rejected': '-120.19', 'logps_train/chosen': '-142.41', 'loss/train': '0.64907', 'examples_per_second': '5.8722', 'grad_norm': '21.625', 'counters/examples': 155456, 'counters/updates': 9716}
skipping logging after 155472 examples to avoid logging too frequently
skipping logging after 155488 examples to avoid logging too frequently
skipping logging after 155504 examples to avoid logging too frequently
train stats after 155520 examples: {'rewards_train/chosen': '-0.55024', 'rewards_train/rejected': '-0.71509', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.16499', 'logps_train/rejected': '-121.25', 'logps_train/chosen': '-124.2', 'loss/train': '0.65902', 'examples_per_second': '4.8551', 'grad_norm': '18.75', 'counters/examples': 155520, 'counters/updates': 9720}
skipping logging after 155536 examples to avoid logging too frequently
skipping logging after 155552 examples to avoid logging too frequently
skipping logging after 155568 examples to avoid logging too frequently
train stats after 155584 examples: {'rewards_train/chosen': '-0.49686', 'rewards_train/rejected': '-0.81149', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.31447', 'logps_train/rejected': '-117.49', 'logps_train/chosen': '-146.48', 'loss/train': '0.57914', 'examples_per_second': '4.8781', 'grad_norm': '18.75', 'counters/examples': 155584, 'counters/updates': 9724}
skipping logging after 155600 examples to avoid logging too frequently
skipping logging after 155616 examples to avoid logging too frequently
skipping logging after 155632 examples to avoid logging too frequently
train stats after 155648 examples: {'rewards_train/chosen': '-0.48127', 'rewards_train/rejected': '-0.682', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.20078', 'logps_train/rejected': '-128.32', 'logps_train/chosen': '-141.23', 'loss/train': '0.62607', 'examples_per_second': '5.3967', 'grad_norm': '19.25', 'counters/examples': 155648, 'counters/updates': 9728}
skipping logging after 155664 examples to avoid logging too frequently
skipping logging after 155680 examples to avoid logging too frequently
skipping logging after 155696 examples to avoid logging too frequently
train stats after 155712 examples: {'rewards_train/chosen': '-0.67243', 'rewards_train/rejected': '-0.77955', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.10709', 'logps_train/rejected': '-139.38', 'logps_train/chosen': '-132.06', 'loss/train': '0.68878', 'examples_per_second': '5.79', 'grad_norm': '25.125', 'counters/examples': 155712, 'counters/updates': 9732}
skipping logging after 155728 examples to avoid logging too frequently
skipping logging after 155744 examples to avoid logging too frequently
Running evaluation after 155744 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:10,  2.29s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:04,  2.14s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:55,  1.90s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.88s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 155744: {'rewards_eval/chosen': '-0.64293', 'rewards_eval/rejected': '-0.79969', 'rewards_eval/accuracies': '0.55273', 'rewards_eval/margins': '0.1568', 'logps_eval/rejected': '-130.15', 'logps_eval/chosen': '-124.92', 'loss/eval': '0.66153'}
skipping logging after 155760 examples to avoid logging too frequently
train stats after 155776 examples: {'rewards_train/chosen': '-0.58514', 'rewards_train/rejected': '-0.72241', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.13729', 'logps_train/rejected': '-133.2', 'logps_train/chosen': '-126.41', 'loss/train': '0.65887', 'examples_per_second': '4.7499', 'grad_norm': '22.75', 'counters/examples': 155776, 'counters/updates': 9736}
skipping logging after 155792 examples to avoid logging too frequently
skipping logging after 155808 examples to avoid logging too frequently
skipping logging after 155824 examples to avoid logging too frequently
train stats after 155840 examples: {'rewards_train/chosen': '-0.61184', 'rewards_train/rejected': '-0.86435', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.25224', 'logps_train/rejected': '-153.99', 'logps_train/chosen': '-130.28', 'loss/train': '0.612', 'examples_per_second': '3.9359', 'grad_norm': '21.375', 'counters/examples': 155840, 'counters/updates': 9740}
skipping logging after 155856 examples to avoid logging too frequently
skipping logging after 155872 examples to avoid logging too frequently
skipping logging after 155888 examples to avoid logging too frequently
train stats after 155904 examples: {'rewards_train/chosen': '-0.85322', 'rewards_train/rejected': '-1.0851', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.23201', 'logps_train/rejected': '-116.48', 'logps_train/chosen': '-126.59', 'loss/train': '0.62473', 'examples_per_second': '5.0912', 'grad_norm': '18.125', 'counters/examples': 155904, 'counters/updates': 9744}
skipping logging after 155920 examples to avoid logging too frequently
skipping logging after 155936 examples to avoid logging too frequently
skipping logging after 155952 examples to avoid logging too frequently
train stats after 155968 examples: {'rewards_train/chosen': '-0.76067', 'rewards_train/rejected': '-0.98524', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.22475', 'logps_train/rejected': '-109.09', 'logps_train/chosen': '-107.81', 'loss/train': '0.62498', 'examples_per_second': '5.5164', 'grad_norm': '19.875', 'counters/examples': 155968, 'counters/updates': 9748}
skipping logging after 155984 examples to avoid logging too frequently
skipping logging after 156000 examples to avoid logging too frequently
skipping logging after 156016 examples to avoid logging too frequently
train stats after 156032 examples: {'rewards_train/chosen': '-0.65397', 'rewards_train/rejected': '-0.85676', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '0.20295', 'logps_train/rejected': '-117.58', 'logps_train/chosen': '-149.8', 'loss/train': '0.65372', 'examples_per_second': '4.3935', 'grad_norm': '21.375', 'counters/examples': 156032, 'counters/updates': 9752}
skipping logging after 156048 examples to avoid logging too frequently
skipping logging after 156064 examples to avoid logging too frequently
skipping logging after 156080 examples to avoid logging too frequently
train stats after 156096 examples: {'rewards_train/chosen': '-0.68371', 'rewards_train/rejected': '-0.86546', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.18181', 'logps_train/rejected': '-131.24', 'logps_train/chosen': '-118.26', 'loss/train': '0.64134', 'examples_per_second': '5.6528', 'grad_norm': '18.625', 'counters/examples': 156096, 'counters/updates': 9756}
skipping logging after 156112 examples to avoid logging too frequently
skipping logging after 156128 examples to avoid logging too frequently
skipping logging after 156144 examples to avoid logging too frequently
train stats after 156160 examples: {'rewards_train/chosen': '-0.75806', 'rewards_train/rejected': '-0.95081', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.19295', 'logps_train/rejected': '-120.72', 'logps_train/chosen': '-134.63', 'loss/train': '0.64802', 'examples_per_second': '5.1166', 'grad_norm': '19.375', 'counters/examples': 156160, 'counters/updates': 9760}
skipping logging after 156176 examples to avoid logging too frequently
skipping logging after 156192 examples to avoid logging too frequently
skipping logging after 156208 examples to avoid logging too frequently
train stats after 156224 examples: {'rewards_train/chosen': '-0.76515', 'rewards_train/rejected': '-0.94753', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.18234', 'logps_train/rejected': '-103.76', 'logps_train/chosen': '-111.29', 'loss/train': '0.64001', 'examples_per_second': '5.978', 'grad_norm': '16.875', 'counters/examples': 156224, 'counters/updates': 9764}
skipping logging after 156240 examples to avoid logging too frequently
skipping logging after 156256 examples to avoid logging too frequently
skipping logging after 156272 examples to avoid logging too frequently
train stats after 156288 examples: {'rewards_train/chosen': '-0.66117', 'rewards_train/rejected': '-0.8012', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.13998', 'logps_train/rejected': '-106.84', 'logps_train/chosen': '-103.52', 'loss/train': '0.65056', 'examples_per_second': '5.4352', 'grad_norm': '19', 'counters/examples': 156288, 'counters/updates': 9768}
skipping logging after 156304 examples to avoid logging too frequently
skipping logging after 156320 examples to avoid logging too frequently
skipping logging after 156336 examples to avoid logging too frequently
train stats after 156352 examples: {'rewards_train/chosen': '-0.67725', 'rewards_train/rejected': '-0.96358', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.28642', 'logps_train/rejected': '-117.05', 'logps_train/chosen': '-128.93', 'loss/train': '0.62212', 'examples_per_second': '4.6482', 'grad_norm': '19.375', 'counters/examples': 156352, 'counters/updates': 9772}
skipping logging after 156368 examples to avoid logging too frequently
skipping logging after 156384 examples to avoid logging too frequently
skipping logging after 156400 examples to avoid logging too frequently
train stats after 156416 examples: {'rewards_train/chosen': '-0.69596', 'rewards_train/rejected': '-0.89088', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.19506', 'logps_train/rejected': '-144.92', 'logps_train/chosen': '-127.62', 'loss/train': '0.6505', 'examples_per_second': '4.7031', 'grad_norm': '21.375', 'counters/examples': 156416, 'counters/updates': 9776}
skipping logging after 156432 examples to avoid logging too frequently
skipping logging after 156448 examples to avoid logging too frequently
skipping logging after 156464 examples to avoid logging too frequently
train stats after 156480 examples: {'rewards_train/chosen': '-0.69671', 'rewards_train/rejected': '-0.86629', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.16946', 'logps_train/rejected': '-120.28', 'logps_train/chosen': '-119.49', 'loss/train': '0.646', 'examples_per_second': '5.2087', 'grad_norm': '20.5', 'counters/examples': 156480, 'counters/updates': 9780}
skipping logging after 156496 examples to avoid logging too frequently
skipping logging after 156512 examples to avoid logging too frequently
skipping logging after 156528 examples to avoid logging too frequently
train stats after 156544 examples: {'rewards_train/chosen': '-0.77186', 'rewards_train/rejected': '-0.95503', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.18318', 'logps_train/rejected': '-148.82', 'logps_train/chosen': '-114.2', 'loss/train': '0.64578', 'examples_per_second': '5.9947', 'grad_norm': '23.875', 'counters/examples': 156544, 'counters/updates': 9784}
skipping logging after 156560 examples to avoid logging too frequently
skipping logging after 156576 examples to avoid logging too frequently
skipping logging after 156592 examples to avoid logging too frequently
train stats after 156608 examples: {'rewards_train/chosen': '-0.72615', 'rewards_train/rejected': '-0.91038', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.18421', 'logps_train/rejected': '-129.47', 'logps_train/chosen': '-144.98', 'loss/train': '0.6315', 'examples_per_second': '5.37', 'grad_norm': '19', 'counters/examples': 156608, 'counters/updates': 9788}
skipping logging after 156624 examples to avoid logging too frequently
skipping logging after 156640 examples to avoid logging too frequently
skipping logging after 156656 examples to avoid logging too frequently
train stats after 156672 examples: {'rewards_train/chosen': '-0.69258', 'rewards_train/rejected': '-0.90166', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.20915', 'logps_train/rejected': '-96.316', 'logps_train/chosen': '-119', 'loss/train': '0.63243', 'examples_per_second': '5.2471', 'grad_norm': '18.125', 'counters/examples': 156672, 'counters/updates': 9792}
skipping logging after 156688 examples to avoid logging too frequently
skipping logging after 156704 examples to avoid logging too frequently
skipping logging after 156720 examples to avoid logging too frequently
train stats after 156736 examples: {'rewards_train/chosen': '-0.67953', 'rewards_train/rejected': '-0.91623', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.23666', 'logps_train/rejected': '-104.26', 'logps_train/chosen': '-132.01', 'loss/train': '0.62596', 'examples_per_second': '5.6213', 'grad_norm': '17.75', 'counters/examples': 156736, 'counters/updates': 9796}
Running evaluation after 156736 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.91s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.98s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.45s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:12<00:36,  1.53s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.46s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.53s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.12s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 156736: {'rewards_eval/chosen': '-0.76067', 'rewards_eval/rejected': '-0.9163', 'rewards_eval/accuracies': '0.55273', 'rewards_eval/margins': '0.15566', 'logps_eval/rejected': '-131.32', 'logps_eval/chosen': '-126.1', 'loss/eval': '0.66637'}
skipping logging after 156752 examples to avoid logging too frequently
skipping logging after 156768 examples to avoid logging too frequently
skipping logging after 156784 examples to avoid logging too frequently
train stats after 156800 examples: {'rewards_train/chosen': '-0.87586', 'rewards_train/rejected': '-1.033', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.15703', 'logps_train/rejected': '-122.84', 'logps_train/chosen': '-118.14', 'loss/train': '0.66946', 'examples_per_second': '6.0166', 'grad_norm': '19', 'counters/examples': 156800, 'counters/updates': 9800}
skipping logging after 156816 examples to avoid logging too frequently
skipping logging after 156832 examples to avoid logging too frequently
skipping logging after 156848 examples to avoid logging too frequently
train stats after 156864 examples: {'rewards_train/chosen': '-0.51655', 'rewards_train/rejected': '-0.80137', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.285', 'logps_train/rejected': '-136.92', 'logps_train/chosen': '-137.61', 'loss/train': '0.59545', 'examples_per_second': '4.5377', 'grad_norm': '19', 'counters/examples': 156864, 'counters/updates': 9804}
skipping logging after 156880 examples to avoid logging too frequently
skipping logging after 156896 examples to avoid logging too frequently
skipping logging after 156912 examples to avoid logging too frequently
train stats after 156928 examples: {'rewards_train/chosen': '-0.68818', 'rewards_train/rejected': '-0.81949', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.13143', 'logps_train/rejected': '-158.85', 'logps_train/chosen': '-156.02', 'loss/train': '0.66837', 'examples_per_second': '5.4393', 'grad_norm': '22', 'counters/examples': 156928, 'counters/updates': 9808}
skipping logging after 156944 examples to avoid logging too frequently
skipping logging after 156960 examples to avoid logging too frequently
skipping logging after 156976 examples to avoid logging too frequently
train stats after 156992 examples: {'rewards_train/chosen': '-0.78606', 'rewards_train/rejected': '-0.97741', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.19139', 'logps_train/rejected': '-116.57', 'logps_train/chosen': '-119.41', 'loss/train': '0.6404', 'examples_per_second': '6.1584', 'grad_norm': '18.5', 'counters/examples': 156992, 'counters/updates': 9812}
skipping logging after 157008 examples to avoid logging too frequently
skipping logging after 157024 examples to avoid logging too frequently
skipping logging after 157040 examples to avoid logging too frequently
train stats after 157056 examples: {'rewards_train/chosen': '-0.64975', 'rewards_train/rejected': '-0.94159', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.29181', 'logps_train/rejected': '-138.95', 'logps_train/chosen': '-144.98', 'loss/train': '0.59192', 'examples_per_second': '5.1277', 'grad_norm': '18.625', 'counters/examples': 157056, 'counters/updates': 9816}
skipping logging after 157072 examples to avoid logging too frequently
skipping logging after 157088 examples to avoid logging too frequently
skipping logging after 157104 examples to avoid logging too frequently
train stats after 157120 examples: {'rewards_train/chosen': '-0.50132', 'rewards_train/rejected': '-0.65801', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.15681', 'logps_train/rejected': '-133.01', 'logps_train/chosen': '-127.81', 'loss/train': '0.64771', 'examples_per_second': '4.9051', 'grad_norm': '19.5', 'counters/examples': 157120, 'counters/updates': 9820}
skipping logging after 157136 examples to avoid logging too frequently
skipping logging after 157152 examples to avoid logging too frequently
skipping logging after 157168 examples to avoid logging too frequently
train stats after 157184 examples: {'rewards_train/chosen': '-0.67675', 'rewards_train/rejected': '-0.8511', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.17432', 'logps_train/rejected': '-130.92', 'logps_train/chosen': '-116.71', 'loss/train': '0.66942', 'examples_per_second': '4.2602', 'grad_norm': '19.875', 'counters/examples': 157184, 'counters/updates': 9824}
skipping logging after 157200 examples to avoid logging too frequently
skipping logging after 157216 examples to avoid logging too frequently
skipping logging after 157232 examples to avoid logging too frequently
train stats after 157248 examples: {'rewards_train/chosen': '-0.64022', 'rewards_train/rejected': '-0.88811', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.24786', 'logps_train/rejected': '-143.01', 'logps_train/chosen': '-141.42', 'loss/train': '0.61153', 'examples_per_second': '4.5219', 'grad_norm': '20.375', 'counters/examples': 157248, 'counters/updates': 9828}
skipping logging after 157264 examples to avoid logging too frequently
skipping logging after 157280 examples to avoid logging too frequently
skipping logging after 157296 examples to avoid logging too frequently
train stats after 157312 examples: {'rewards_train/chosen': '-0.55819', 'rewards_train/rejected': '-0.89343', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.33543', 'logps_train/rejected': '-112.17', 'logps_train/chosen': '-111.08', 'loss/train': '0.571', 'examples_per_second': '4.5145', 'grad_norm': '18', 'counters/examples': 157312, 'counters/updates': 9832}
skipping logging after 157328 examples to avoid logging too frequently
skipping logging after 157344 examples to avoid logging too frequently
skipping logging after 157360 examples to avoid logging too frequently
train stats after 157376 examples: {'rewards_train/chosen': '-0.72768', 'rewards_train/rejected': '-0.95248', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.22477', 'logps_train/rejected': '-136.57', 'logps_train/chosen': '-128.12', 'loss/train': '0.62512', 'examples_per_second': '4.7087', 'grad_norm': '20', 'counters/examples': 157376, 'counters/updates': 9836}
skipping logging after 157392 examples to avoid logging too frequently
skipping logging after 157408 examples to avoid logging too frequently
skipping logging after 157424 examples to avoid logging too frequently
train stats after 157440 examples: {'rewards_train/chosen': '-0.62408', 'rewards_train/rejected': '-0.8577', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.23355', 'logps_train/rejected': '-138.52', 'logps_train/chosen': '-116.91', 'loss/train': '0.62444', 'examples_per_second': '5.5851', 'grad_norm': '19.5', 'counters/examples': 157440, 'counters/updates': 9840}
skipping logging after 157456 examples to avoid logging too frequently
skipping logging after 157472 examples to avoid logging too frequently
skipping logging after 157488 examples to avoid logging too frequently
train stats after 157504 examples: {'rewards_train/chosen': '-0.74043', 'rewards_train/rejected': '-0.86376', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.12351', 'logps_train/rejected': '-92.591', 'logps_train/chosen': '-113.92', 'loss/train': '0.6666', 'examples_per_second': '5.9849', 'grad_norm': '19.375', 'counters/examples': 157504, 'counters/updates': 9844}
skipping logging after 157520 examples to avoid logging too frequently
skipping logging after 157536 examples to avoid logging too frequently
skipping logging after 157552 examples to avoid logging too frequently
train stats after 157568 examples: {'rewards_train/chosen': '-0.64138', 'rewards_train/rejected': '-0.79255', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.15116', 'logps_train/rejected': '-134.98', 'logps_train/chosen': '-117.1', 'loss/train': '0.66125', 'examples_per_second': '4.4518', 'grad_norm': '21', 'counters/examples': 157568, 'counters/updates': 9848}
skipping logging after 157584 examples to avoid logging too frequently
skipping logging after 157600 examples to avoid logging too frequently
skipping logging after 157616 examples to avoid logging too frequently
train stats after 157632 examples: {'rewards_train/chosen': '-0.83041', 'rewards_train/rejected': '-0.91122', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.08083', 'logps_train/rejected': '-108.57', 'logps_train/chosen': '-129.81', 'loss/train': '0.69829', 'examples_per_second': '5.1802', 'grad_norm': '23.75', 'counters/examples': 157632, 'counters/updates': 9852}
skipping logging after 157648 examples to avoid logging too frequently
skipping logging after 157664 examples to avoid logging too frequently
skipping logging after 157680 examples to avoid logging too frequently
train stats after 157696 examples: {'rewards_train/chosen': '-0.66296', 'rewards_train/rejected': '-0.84528', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.18234', 'logps_train/rejected': '-115.77', 'logps_train/chosen': '-124.58', 'loss/train': '0.6416', 'examples_per_second': '5.926', 'grad_norm': '21.5', 'counters/examples': 157696, 'counters/updates': 9856}
skipping logging after 157712 examples to avoid logging too frequently
skipping logging after 157728 examples to avoid logging too frequently
Running evaluation after 157728 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:12,  2.32s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:04,  2.16s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:55,  1.91s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.89s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.54s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.25s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 157728: {'rewards_eval/chosen': '-0.69935', 'rewards_eval/rejected': '-0.85511', 'rewards_eval/accuracies': '0.53906', 'rewards_eval/margins': '0.15571', 'logps_eval/rejected': '-130.71', 'logps_eval/chosen': '-125.49', 'loss/eval': '0.66607'}
skipping logging after 157744 examples to avoid logging too frequently
train stats after 157760 examples: {'rewards_train/chosen': '-0.63481', 'rewards_train/rejected': '-0.68726', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.052353', 'logps_train/rejected': '-112.47', 'logps_train/chosen': '-120.29', 'loss/train': '0.70552', 'examples_per_second': '5.5488', 'grad_norm': '20.875', 'counters/examples': 157760, 'counters/updates': 9860}
skipping logging after 157776 examples to avoid logging too frequently
skipping logging after 157792 examples to avoid logging too frequently
skipping logging after 157808 examples to avoid logging too frequently
train stats after 157824 examples: {'rewards_train/chosen': '-0.52413', 'rewards_train/rejected': '-0.84645', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.32238', 'logps_train/rejected': '-103.91', 'logps_train/chosen': '-114.44', 'loss/train': '0.58781', 'examples_per_second': '4.5986', 'grad_norm': '18.625', 'counters/examples': 157824, 'counters/updates': 9864}
skipping logging after 157840 examples to avoid logging too frequently
skipping logging after 157856 examples to avoid logging too frequently
skipping logging after 157872 examples to avoid logging too frequently
train stats after 157888 examples: {'rewards_train/chosen': '-0.71842', 'rewards_train/rejected': '-0.87067', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.15212', 'logps_train/rejected': '-130.62', 'logps_train/chosen': '-153.84', 'loss/train': '0.66397', 'examples_per_second': '5.173', 'grad_norm': '21.375', 'counters/examples': 157888, 'counters/updates': 9868}
skipping logging after 157904 examples to avoid logging too frequently
skipping logging after 157920 examples to avoid logging too frequently
skipping logging after 157936 examples to avoid logging too frequently
train stats after 157952 examples: {'rewards_train/chosen': '-0.73098', 'rewards_train/rejected': '-0.82536', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '0.094124', 'logps_train/rejected': '-143.97', 'logps_train/chosen': '-165.49', 'loss/train': '0.69924', 'examples_per_second': '4.7293', 'grad_norm': '23.5', 'counters/examples': 157952, 'counters/updates': 9872}
skipping logging after 157968 examples to avoid logging too frequently
skipping logging after 157984 examples to avoid logging too frequently
skipping logging after 158000 examples to avoid logging too frequently
train stats after 158016 examples: {'rewards_train/chosen': '-0.55627', 'rewards_train/rejected': '-0.7765', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.22036', 'logps_train/rejected': '-134.34', 'logps_train/chosen': '-138.95', 'loss/train': '0.62611', 'examples_per_second': '5.0864', 'grad_norm': '21.25', 'counters/examples': 158016, 'counters/updates': 9876}
skipping logging after 158032 examples to avoid logging too frequently
skipping logging after 158048 examples to avoid logging too frequently
skipping logging after 158064 examples to avoid logging too frequently
train stats after 158080 examples: {'rewards_train/chosen': '-0.70204', 'rewards_train/rejected': '-0.92353', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.22132', 'logps_train/rejected': '-143.35', 'logps_train/chosen': '-134.6', 'loss/train': '0.62537', 'examples_per_second': '4.8302', 'grad_norm': '20', 'counters/examples': 158080, 'counters/updates': 9880}
skipping logging after 158096 examples to avoid logging too frequently
skipping logging after 158112 examples to avoid logging too frequently
skipping logging after 158128 examples to avoid logging too frequently
train stats after 158144 examples: {'rewards_train/chosen': '-0.69303', 'rewards_train/rejected': '-0.8411', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.14813', 'logps_train/rejected': '-124.18', 'logps_train/chosen': '-110.69', 'loss/train': '0.66997', 'examples_per_second': '4.7098', 'grad_norm': '20.25', 'counters/examples': 158144, 'counters/updates': 9884}
skipping logging after 158160 examples to avoid logging too frequently
skipping logging after 158176 examples to avoid logging too frequently
skipping logging after 158192 examples to avoid logging too frequently
train stats after 158208 examples: {'rewards_train/chosen': '-0.66291', 'rewards_train/rejected': '-0.81362', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.15075', 'logps_train/rejected': '-134.79', 'logps_train/chosen': '-124.41', 'loss/train': '0.66286', 'examples_per_second': '5.0717', 'grad_norm': '20', 'counters/examples': 158208, 'counters/updates': 9888}
skipping logging after 158224 examples to avoid logging too frequently
skipping logging after 158240 examples to avoid logging too frequently
skipping logging after 158256 examples to avoid logging too frequently
train stats after 158272 examples: {'rewards_train/chosen': '-0.48308', 'rewards_train/rejected': '-0.69197', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.20881', 'logps_train/rejected': '-109.03', 'logps_train/chosen': '-143.09', 'loss/train': '0.62906', 'examples_per_second': '5.7176', 'grad_norm': '20.625', 'counters/examples': 158272, 'counters/updates': 9892}
skipping logging after 158288 examples to avoid logging too frequently
skipping logging after 158304 examples to avoid logging too frequently
skipping logging after 158320 examples to avoid logging too frequently
train stats after 158336 examples: {'rewards_train/chosen': '-0.59664', 'rewards_train/rejected': '-0.74393', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.14711', 'logps_train/rejected': '-149.2', 'logps_train/chosen': '-124.61', 'loss/train': '0.6601', 'examples_per_second': '4.9105', 'grad_norm': '24.125', 'counters/examples': 158336, 'counters/updates': 9896}
skipping logging after 158352 examples to avoid logging too frequently
skipping logging after 158368 examples to avoid logging too frequently
skipping logging after 158384 examples to avoid logging too frequently
train stats after 158400 examples: {'rewards_train/chosen': '-0.73251', 'rewards_train/rejected': '-0.89382', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.16129', 'logps_train/rejected': '-152.2', 'logps_train/chosen': '-128.99', 'loss/train': '0.65355', 'examples_per_second': '4.372', 'grad_norm': '21.125', 'counters/examples': 158400, 'counters/updates': 9900}
skipping logging after 158416 examples to avoid logging too frequently
skipping logging after 158432 examples to avoid logging too frequently
skipping logging after 158448 examples to avoid logging too frequently
train stats after 158464 examples: {'rewards_train/chosen': '-0.59769', 'rewards_train/rejected': '-0.64996', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.052141', 'logps_train/rejected': '-130.79', 'logps_train/chosen': '-145.39', 'loss/train': '0.69565', 'examples_per_second': '4.1635', 'grad_norm': '21.125', 'counters/examples': 158464, 'counters/updates': 9904}
skipping logging after 158480 examples to avoid logging too frequently
skipping logging after 158496 examples to avoid logging too frequently
skipping logging after 158512 examples to avoid logging too frequently
train stats after 158528 examples: {'rewards_train/chosen': '-0.58941', 'rewards_train/rejected': '-0.759', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.16953', 'logps_train/rejected': '-126.48', 'logps_train/chosen': '-117.37', 'loss/train': '0.65622', 'examples_per_second': '4.8773', 'grad_norm': '18.25', 'counters/examples': 158528, 'counters/updates': 9908}
skipping logging after 158544 examples to avoid logging too frequently
skipping logging after 158560 examples to avoid logging too frequently
skipping logging after 158576 examples to avoid logging too frequently
train stats after 158592 examples: {'rewards_train/chosen': '-0.40577', 'rewards_train/rejected': '-0.69871', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.29276', 'logps_train/rejected': '-116.13', 'logps_train/chosen': '-107.63', 'loss/train': '0.60159', 'examples_per_second': '5.6684', 'grad_norm': '17.375', 'counters/examples': 158592, 'counters/updates': 9912}
skipping logging after 158608 examples to avoid logging too frequently
skipping logging after 158624 examples to avoid logging too frequently
skipping logging after 158640 examples to avoid logging too frequently
train stats after 158656 examples: {'rewards_train/chosen': '-0.54581', 'rewards_train/rejected': '-0.67938', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.13369', 'logps_train/rejected': '-116.73', 'logps_train/chosen': '-123.74', 'loss/train': '0.67545', 'examples_per_second': '5.7661', 'grad_norm': '22.125', 'counters/examples': 158656, 'counters/updates': 9916}
skipping logging after 158672 examples to avoid logging too frequently
skipping logging after 158688 examples to avoid logging too frequently
skipping logging after 158704 examples to avoid logging too frequently
train stats after 158720 examples: {'rewards_train/chosen': '-0.5114', 'rewards_train/rejected': '-0.70338', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.19186', 'logps_train/rejected': '-121.91', 'logps_train/chosen': '-127.25', 'loss/train': '0.63641', 'examples_per_second': '5.0632', 'grad_norm': '18.875', 'counters/examples': 158720, 'counters/updates': 9920}
Running evaluation after 158720 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.50s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.53s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.46s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.53s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.42s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 158720: {'rewards_eval/chosen': '-0.523', 'rewards_eval/rejected': '-0.66604', 'rewards_eval/accuracies': '0.55469', 'rewards_eval/margins': '0.14305', 'logps_eval/rejected': '-128.82', 'logps_eval/chosen': '-123.72', 'loss/eval': '0.66401'}
skipping logging after 158736 examples to avoid logging too frequently
skipping logging after 158752 examples to avoid logging too frequently
skipping logging after 158768 examples to avoid logging too frequently
train stats after 158784 examples: {'rewards_train/chosen': '-0.65092', 'rewards_train/rejected': '-0.8186', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.16757', 'logps_train/rejected': '-108.84', 'logps_train/chosen': '-105.22', 'loss/train': '0.6438', 'examples_per_second': '4.8197', 'grad_norm': '19.875', 'counters/examples': 158784, 'counters/updates': 9924}
skipping logging after 158800 examples to avoid logging too frequently
skipping logging after 158816 examples to avoid logging too frequently
skipping logging after 158832 examples to avoid logging too frequently
train stats after 158848 examples: {'rewards_train/chosen': '-0.40898', 'rewards_train/rejected': '-0.69842', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.28949', 'logps_train/rejected': '-119.09', 'logps_train/chosen': '-121.94', 'loss/train': '0.58318', 'examples_per_second': '4.8978', 'grad_norm': '17.375', 'counters/examples': 158848, 'counters/updates': 9928}
skipping logging after 158864 examples to avoid logging too frequently
skipping logging after 158880 examples to avoid logging too frequently
skipping logging after 158896 examples to avoid logging too frequently
train stats after 158912 examples: {'rewards_train/chosen': '-0.40615', 'rewards_train/rejected': '-0.60951', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.2033', 'logps_train/rejected': '-110.73', 'logps_train/chosen': '-130.61', 'loss/train': '0.65051', 'examples_per_second': '4.0435', 'grad_norm': '19.5', 'counters/examples': 158912, 'counters/updates': 9932}
skipping logging after 158928 examples to avoid logging too frequently
skipping logging after 158944 examples to avoid logging too frequently
skipping logging after 158960 examples to avoid logging too frequently
train stats after 158976 examples: {'rewards_train/chosen': '-0.42894', 'rewards_train/rejected': '-0.62228', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.19334', 'logps_train/rejected': '-142.88', 'logps_train/chosen': '-148.77', 'loss/train': '0.62949', 'examples_per_second': '5.5692', 'grad_norm': '21.5', 'counters/examples': 158976, 'counters/updates': 9936}
skipping logging after 158992 examples to avoid logging too frequently
skipping logging after 159008 examples to avoid logging too frequently
skipping logging after 159024 examples to avoid logging too frequently
train stats after 159040 examples: {'rewards_train/chosen': '-0.47383', 'rewards_train/rejected': '-0.72376', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.25003', 'logps_train/rejected': '-112.26', 'logps_train/chosen': '-125.06', 'loss/train': '0.60057', 'examples_per_second': '4.1478', 'grad_norm': '17.375', 'counters/examples': 159040, 'counters/updates': 9940}
skipping logging after 159056 examples to avoid logging too frequently
skipping logging after 159072 examples to avoid logging too frequently
skipping logging after 159088 examples to avoid logging too frequently
train stats after 159104 examples: {'rewards_train/chosen': '-0.53941', 'rewards_train/rejected': '-0.78135', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.24209', 'logps_train/rejected': '-130.98', 'logps_train/chosen': '-105.41', 'loss/train': '0.60992', 'examples_per_second': '4.2955', 'grad_norm': '17.625', 'counters/examples': 159104, 'counters/updates': 9944}
skipping logging after 159120 examples to avoid logging too frequently
skipping logging after 159136 examples to avoid logging too frequently
skipping logging after 159152 examples to avoid logging too frequently
train stats after 159168 examples: {'rewards_train/chosen': '-0.653', 'rewards_train/rejected': '-0.88636', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.23345', 'logps_train/rejected': '-120.28', 'logps_train/chosen': '-124.63', 'loss/train': '0.61272', 'examples_per_second': '4.0649', 'grad_norm': '20.5', 'counters/examples': 159168, 'counters/updates': 9948}
skipping logging after 159184 examples to avoid logging too frequently
skipping logging after 159200 examples to avoid logging too frequently
skipping logging after 159216 examples to avoid logging too frequently
train stats after 159232 examples: {'rewards_train/chosen': '-0.69947', 'rewards_train/rejected': '-0.94775', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.24828', 'logps_train/rejected': '-120.95', 'logps_train/chosen': '-136.16', 'loss/train': '0.631', 'examples_per_second': '5.4684', 'grad_norm': '24.875', 'counters/examples': 159232, 'counters/updates': 9952}
skipping logging after 159248 examples to avoid logging too frequently
skipping logging after 159264 examples to avoid logging too frequently
skipping logging after 159280 examples to avoid logging too frequently
train stats after 159296 examples: {'rewards_train/chosen': '-0.48767', 'rewards_train/rejected': '-0.85022', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.36287', 'logps_train/rejected': '-138.66', 'logps_train/chosen': '-140.35', 'loss/train': '0.58028', 'examples_per_second': '5.4961', 'grad_norm': '23.125', 'counters/examples': 159296, 'counters/updates': 9956}
skipping logging after 159312 examples to avoid logging too frequently
skipping logging after 159328 examples to avoid logging too frequently
skipping logging after 159344 examples to avoid logging too frequently
train stats after 159360 examples: {'rewards_train/chosen': '-0.77337', 'rewards_train/rejected': '-0.94958', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.17633', 'logps_train/rejected': '-122.77', 'logps_train/chosen': '-121.85', 'loss/train': '0.64738', 'examples_per_second': '6.6943', 'grad_norm': '21.5', 'counters/examples': 159360, 'counters/updates': 9960}
skipping logging after 159376 examples to avoid logging too frequently
skipping logging after 159392 examples to avoid logging too frequently
skipping logging after 159408 examples to avoid logging too frequently
train stats after 159424 examples: {'rewards_train/chosen': '-0.67041', 'rewards_train/rejected': '-0.79217', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.12177', 'logps_train/rejected': '-146.31', 'logps_train/chosen': '-152.9', 'loss/train': '0.68312', 'examples_per_second': '5.1082', 'grad_norm': '23.25', 'counters/examples': 159424, 'counters/updates': 9964}
skipping logging after 159440 examples to avoid logging too frequently
skipping logging after 159456 examples to avoid logging too frequently
skipping logging after 159472 examples to avoid logging too frequently
train stats after 159488 examples: {'rewards_train/chosen': '-0.77377', 'rewards_train/rejected': '-0.98967', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.21592', 'logps_train/rejected': '-140.27', 'logps_train/chosen': '-130.68', 'loss/train': '0.64497', 'examples_per_second': '4.2053', 'grad_norm': '21.25', 'counters/examples': 159488, 'counters/updates': 9968}
skipping logging after 159504 examples to avoid logging too frequently
skipping logging after 159520 examples to avoid logging too frequently
skipping logging after 159536 examples to avoid logging too frequently
train stats after 159552 examples: {'rewards_train/chosen': '-0.62417', 'rewards_train/rejected': '-0.81496', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.19093', 'logps_train/rejected': '-155.92', 'logps_train/chosen': '-141.69', 'loss/train': '0.64703', 'examples_per_second': '6.0666', 'grad_norm': '20.125', 'counters/examples': 159552, 'counters/updates': 9972}
skipping logging after 159568 examples to avoid logging too frequently
skipping logging after 159584 examples to avoid logging too frequently
skipping logging after 159600 examples to avoid logging too frequently
train stats after 159616 examples: {'rewards_train/chosen': '-0.79663', 'rewards_train/rejected': '-0.86242', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.065773', 'logps_train/rejected': '-94.909', 'logps_train/chosen': '-120.57', 'loss/train': '0.70239', 'examples_per_second': '4.6475', 'grad_norm': '21.875', 'counters/examples': 159616, 'counters/updates': 9976}
skipping logging after 159632 examples to avoid logging too frequently
skipping logging after 159648 examples to avoid logging too frequently
skipping logging after 159664 examples to avoid logging too frequently
train stats after 159680 examples: {'rewards_train/chosen': '-0.66919', 'rewards_train/rejected': '-0.86286', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.19354', 'logps_train/rejected': '-121.02', 'logps_train/chosen': '-112.68', 'loss/train': '0.62956', 'examples_per_second': '5.1565', 'grad_norm': '17.875', 'counters/examples': 159680, 'counters/updates': 9980}
skipping logging after 159696 examples to avoid logging too frequently
skipping logging after 159712 examples to avoid logging too frequently
Running evaluation after 159712 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:07,  2.18s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:02,  2.09s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.88s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.87s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.63s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.30s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 159712: {'rewards_eval/chosen': '-0.6914', 'rewards_eval/rejected': '-0.8491', 'rewards_eval/accuracies': '0.55469', 'rewards_eval/margins': '0.15773', 'logps_eval/rejected': '-130.65', 'logps_eval/chosen': '-125.41', 'loss/eval': '0.665'}
skipping logging after 159728 examples to avoid logging too frequently
train stats after 159744 examples: {'rewards_train/chosen': '-0.41272', 'rewards_train/rejected': '-0.67495', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.26202', 'logps_train/rejected': '-125.92', 'logps_train/chosen': '-140.9', 'loss/train': '0.61812', 'examples_per_second': '5.603', 'grad_norm': '20.875', 'counters/examples': 159744, 'counters/updates': 9984}
skipping logging after 159760 examples to avoid logging too frequently
skipping logging after 159776 examples to avoid logging too frequently
skipping logging after 159792 examples to avoid logging too frequently
train stats after 159808 examples: {'rewards_train/chosen': '-0.66559', 'rewards_train/rejected': '-1.0425', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.37698', 'logps_train/rejected': '-104.25', 'logps_train/chosen': '-108.65', 'loss/train': '0.57835', 'examples_per_second': '5.4004', 'grad_norm': '17', 'counters/examples': 159808, 'counters/updates': 9988}
skipping logging after 159824 examples to avoid logging too frequently
skipping logging after 159840 examples to avoid logging too frequently
skipping logging after 159856 examples to avoid logging too frequently
train stats after 159872 examples: {'rewards_train/chosen': '-0.83913', 'rewards_train/rejected': '-1.0111', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.17199', 'logps_train/rejected': '-147.76', 'logps_train/chosen': '-125.49', 'loss/train': '0.66248', 'examples_per_second': '5.6201', 'grad_norm': '29.25', 'counters/examples': 159872, 'counters/updates': 9992}
skipping logging after 159888 examples to avoid logging too frequently
skipping logging after 159904 examples to avoid logging too frequently
skipping logging after 159920 examples to avoid logging too frequently
train stats after 159936 examples: {'rewards_train/chosen': '-0.48049', 'rewards_train/rejected': '-0.63216', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.15169', 'logps_train/rejected': '-143.55', 'logps_train/chosen': '-118.6', 'loss/train': '0.66316', 'examples_per_second': '5.0984', 'grad_norm': '19.75', 'counters/examples': 159936, 'counters/updates': 9996}
skipping logging after 159952 examples to avoid logging too frequently
skipping logging after 159968 examples to avoid logging too frequently
skipping logging after 159984 examples to avoid logging too frequently
train stats after 160000 examples: {'rewards_train/chosen': '-0.69097', 'rewards_train/rejected': '-0.87233', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.18154', 'logps_train/rejected': '-154.6', 'logps_train/chosen': '-121.43', 'loss/train': '0.66103', 'examples_per_second': '4.8705', 'grad_norm': '33.75', 'counters/examples': 160000, 'counters/updates': 10000}
skipping logging after 160016 examples to avoid logging too frequently
skipping logging after 160032 examples to avoid logging too frequently
skipping logging after 160048 examples to avoid logging too frequently
train stats after 160064 examples: {'rewards_train/chosen': '-0.57408', 'rewards_train/rejected': '-0.82442', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.25045', 'logps_train/rejected': '-114.24', 'logps_train/chosen': '-106.9', 'loss/train': '0.61247', 'examples_per_second': '5.0159', 'grad_norm': '17.375', 'counters/examples': 160064, 'counters/updates': 10004}
skipping logging after 160080 examples to avoid logging too frequently
skipping logging after 160096 examples to avoid logging too frequently
skipping logging after 160112 examples to avoid logging too frequently
train stats after 160128 examples: {'rewards_train/chosen': '-0.57142', 'rewards_train/rejected': '-0.72971', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.15842', 'logps_train/rejected': '-117.61', 'logps_train/chosen': '-131.94', 'loss/train': '0.67102', 'examples_per_second': '4.8426', 'grad_norm': '22.125', 'counters/examples': 160128, 'counters/updates': 10008}
skipping logging after 160144 examples to avoid logging too frequently
skipping logging after 160160 examples to avoid logging too frequently
skipping logging after 160176 examples to avoid logging too frequently
train stats after 160192 examples: {'rewards_train/chosen': '-0.58127', 'rewards_train/rejected': '-0.8786', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.29746', 'logps_train/rejected': '-119.65', 'logps_train/chosen': '-123.07', 'loss/train': '0.60693', 'examples_per_second': '5.103', 'grad_norm': '20.875', 'counters/examples': 160192, 'counters/updates': 10012}
skipping logging after 160208 examples to avoid logging too frequently
skipping logging after 160224 examples to avoid logging too frequently
skipping logging after 160240 examples to avoid logging too frequently
train stats after 160256 examples: {'rewards_train/chosen': '-0.81471', 'rewards_train/rejected': '-0.94188', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.12731', 'logps_train/rejected': '-128.19', 'logps_train/chosen': '-120.02', 'loss/train': '0.67258', 'examples_per_second': '4.5169', 'grad_norm': '19.125', 'counters/examples': 160256, 'counters/updates': 10016}
skipping logging after 160272 examples to avoid logging too frequently
skipping logging after 160288 examples to avoid logging too frequently
skipping logging after 160304 examples to avoid logging too frequently
train stats after 160320 examples: {'rewards_train/chosen': '-0.72787', 'rewards_train/rejected': '-0.85546', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '0.12753', 'logps_train/rejected': '-117.69', 'logps_train/chosen': '-127.64', 'loss/train': '0.66505', 'examples_per_second': '5.2872', 'grad_norm': '19.75', 'counters/examples': 160320, 'counters/updates': 10020}
skipping logging after 160336 examples to avoid logging too frequently
skipping logging after 160352 examples to avoid logging too frequently
skipping logging after 160368 examples to avoid logging too frequently
train stats after 160384 examples: {'rewards_train/chosen': '-0.64445', 'rewards_train/rejected': '-0.73185', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.087553', 'logps_train/rejected': '-127.19', 'logps_train/chosen': '-145.1', 'loss/train': '0.68842', 'examples_per_second': '4.76', 'grad_norm': '23.375', 'counters/examples': 160384, 'counters/updates': 10024}
skipping logging after 160400 examples to avoid logging too frequently
skipping logging after 160416 examples to avoid logging too frequently
skipping logging after 160432 examples to avoid logging too frequently
train stats after 160448 examples: {'rewards_train/chosen': '-0.7575', 'rewards_train/rejected': '-0.82474', 'rewards_train/accuracies': '0.5', 'rewards_train/margins': '0.067154', 'logps_train/rejected': '-110.79', 'logps_train/chosen': '-106.72', 'loss/train': '0.68106', 'examples_per_second': '5.5107', 'grad_norm': '20.5', 'counters/examples': 160448, 'counters/updates': 10028}
skipping logging after 160464 examples to avoid logging too frequently
skipping logging after 160480 examples to avoid logging too frequently
skipping logging after 160496 examples to avoid logging too frequently
train stats after 160512 examples: {'rewards_train/chosen': '-0.54819', 'rewards_train/rejected': '-0.74405', 'rewards_train/accuracies': '0.625', 'rewards_train/margins': '0.1958', 'logps_train/rejected': '-114.96', 'logps_train/chosen': '-109.87', 'loss/train': '0.65056', 'examples_per_second': '5.5443', 'grad_norm': '18.125', 'counters/examples': 160512, 'counters/updates': 10032}
skipping logging after 160528 examples to avoid logging too frequently
skipping logging after 160544 examples to avoid logging too frequently
skipping logging after 160560 examples to avoid logging too frequently
train stats after 160576 examples: {'rewards_train/chosen': '-0.6427', 'rewards_train/rejected': '-0.90771', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.26492', 'logps_train/rejected': '-133.49', 'logps_train/chosen': '-139.65', 'loss/train': '0.61569', 'examples_per_second': '5.6906', 'grad_norm': '21.875', 'counters/examples': 160576, 'counters/updates': 10036}
skipping logging after 160592 examples to avoid logging too frequently
skipping logging after 160608 examples to avoid logging too frequently
skipping logging after 160624 examples to avoid logging too frequently
train stats after 160640 examples: {'rewards_train/chosen': '-0.51586', 'rewards_train/rejected': '-0.77287', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.25729', 'logps_train/rejected': '-139.15', 'logps_train/chosen': '-131.75', 'loss/train': '0.6241', 'examples_per_second': '4.9169', 'grad_norm': '19.375', 'counters/examples': 160640, 'counters/updates': 10040}
skipping logging after 160656 examples to avoid logging too frequently
skipping logging after 160672 examples to avoid logging too frequently
skipping logging after 160688 examples to avoid logging too frequently
train stats after 160704 examples: {'rewards_train/chosen': '-0.71047', 'rewards_train/rejected': '-0.99576', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.28509', 'logps_train/rejected': '-111.02', 'logps_train/chosen': '-111.62', 'loss/train': '0.61827', 'examples_per_second': '5.3786', 'grad_norm': '17.25', 'counters/examples': 160704, 'counters/updates': 10044}
Running evaluation after 160704 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.92s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:59,  1.99s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:52,  1.82s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.83s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.54s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.46s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.53s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.47s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.42s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.41s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
4
2 initializing distributed
Creating trainer on process 2 with world size 4
Loaded model on rank 2
4
3 initializing distributed
Creating trainer on process 3 with world size 4
Loaded model on rank 3
4
1 initializing distributed
Creating trainer on process 1 with world size 4
Loaded model on rank 1
eval after 160704: {'rewards_eval/chosen': '-0.66991', 'rewards_eval/rejected': '-0.82848', 'rewards_eval/accuracies': '0.54297', 'rewards_eval/margins': '0.15857', 'logps_eval/rejected': '-130.44', 'logps_eval/chosen': '-125.19', 'loss/eval': '0.66292'}
skipping logging after 160720 examples to avoid logging too frequently
skipping logging after 160736 examples to avoid logging too frequently
skipping logging after 160752 examples to avoid logging too frequently
train stats after 160768 examples: {'rewards_train/chosen': '-0.61771', 'rewards_train/rejected': '-0.77219', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.15457', 'logps_train/rejected': '-136.74', 'logps_train/chosen': '-138.43', 'loss/train': '0.65614', 'examples_per_second': '5.3266', 'grad_norm': '26.25', 'counters/examples': 160768, 'counters/updates': 10048}
skipping logging after 160784 examples to avoid logging too frequently
skipping logging after 160800 examples to avoid logging too frequently
writing checkpoint to /home/wxt/.cache/huggingface/hub/llama2_7b_dpo_halos/LATEST/policy.pt...
