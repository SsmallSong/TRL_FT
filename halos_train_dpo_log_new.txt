4
/home/wxt/.conda/envs/halos3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Making experiment directory /home/wxt/.cache/huggingface/hub/llama2_7b_dpo_halos_2
WARNING: eval_every must be divisible by batch_size
Setting eval_every to 992
no FSDP port specified; using open port for FSDP: 50975
seed: 1
exp_name: llama2_7b_dpo_halos_2
datasets:
- hh
mode: train
debug: false
use_fsdp: true
fsdp_port: 50975
wandb:
  enabled: true
  entity: null
  project: archangel
cache_dir: /home/wxt/.cache/huggingface/hub
local_run_dir: /home/wxt/.cache/huggingface/hub/llama2_7b_dpo_halos_2
do_first_eval: true
minimum_log_interval_secs: 1.0
intermediate_checkpoints: false
trainer: DPOTrainer
lr: 2.0e-05
n_epochs: 1
n_examples: null
optimizer: RMSprop
warmup_steps: 150
eval_every: 992
n_samples: 128
samples_dir: samples/
n_eval_examples: 512
saved_policy: /home/wxt/.cache/huggingface/hub/llama2_7b_dpo_halos_2/LATEST/policy.pt
top_p: 0.95
human_prefix: '

  <|user|>

  '
assistant_prefix: '

  <|assistant|>

  '
human_suffix: ''
assistant_suffix: ''
frac_unique_desirable: 1.0
frac_unique_undesirable: 1.0
model:
  name_or_path: daryl149/llama-2-7b-hf
  tokenizer_name_or_path: null
  load_from: /home/wxt/.cache/huggingface/hub/llama2_7b_sft_halos_2/LATEST/policy.pt
  block_name: LlamaDecoderLayer
  policy_dtype: bfloat16
  fsdp_policy_mp: null
  reference_dtype: bfloat16
  max_grad_norm: 10.0
  v_head_max_grad_norm: 0.1
  max_length: 1024
  max_prompt_length: 512
  activation_checkpointing: true
  batch_size: 32
  gradient_accumulation_steps: 4
  eval_batch_size: 16
  use_flash_attention: false
loss:
  name: dpo
  beta: 0.1
  trainer: DPOTrainer
  dataloader: PairedPreferenceDataLoader
  use_reference_model: true

================================================================================
Writing to design-agent-09:/home/wxt/.cache/huggingface/hub/llama2_7b_dpo_halos_2
================================================================================
building policy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]
building reference model
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]
loading pre-trained weights at step 159968 from /home/wxt/.cache/huggingface/hub/llama2_7b_sft_halos_2/LATEST/policy.pt with metrics {}
loaded pre-trained weights
Loading tokenizer daryl149/llama-2-7b-hf
0 special tokens added
Loading HH dataset (train split) from Huggingface...
Processing HH:   0%|          | 0/160800 [00:00<?, ?it/s]Processing HH:   1%|          | 1517/160800 [00:00<00:10, 15162.28it/s]Processing HH:   2%|▏         | 3034/160800 [00:00<00:10, 15146.06it/s]Processing HH:   3%|▎         | 4549/160800 [00:00<00:10, 15083.66it/s]Processing HH:   4%|▍         | 6065/160800 [00:00<00:10, 15105.29it/s]Processing HH:   5%|▍         | 7576/160800 [00:00<00:10, 14965.49it/s]Processing HH:   6%|▌         | 9073/160800 [00:00<00:10, 14841.22it/s]Processing HH:   7%|▋         | 10558/160800 [00:00<00:10, 14742.49it/s]Processing HH:   7%|▋         | 12033/160800 [00:00<00:10, 14553.45it/s]Processing HH:   8%|▊         | 13559/160800 [00:00<00:09, 14769.60it/s]Processing HH:   9%|▉         | 15037/160800 [00:01<00:13, 10936.34it/s]Processing HH:  10%|█         | 16609/160800 [00:01<00:11, 12102.72it/s]Processing HH:  11%|█▏        | 18171/160800 [00:01<00:10, 13011.26it/s]Processing HH:  12%|█▏        | 19695/160800 [00:01<00:10, 13610.27it/s]Processing HH:  13%|█▎        | 21185/160800 [00:01<00:09, 13965.61it/s]Processing HH:  14%|█▍        | 22720/160800 [00:01<00:09, 14357.54it/s]Processing HH:  15%|█▌        | 24226/160800 [00:01<00:09, 14555.90it/s]Processing HH:  16%|█▌        | 25713/160800 [00:01<00:09, 14531.01it/s]Processing HH:  17%|█▋        | 27225/160800 [00:01<00:09, 14699.57it/s]Processing HH:  18%|█▊        | 28736/160800 [00:02<00:08, 14819.54it/s]Processing HH:  19%|█▉        | 30230/160800 [00:02<00:08, 14756.69it/s]Processing HH:  20%|█▉        | 31746/160800 [00:02<00:08, 14875.07it/s]Processing HH:  21%|██        | 33256/160800 [00:02<00:08, 14937.13it/s]Processing HH:  22%|██▏       | 34754/160800 [00:02<00:12, 10477.94it/s]Processing HH:  23%|██▎       | 36256/160800 [00:02<00:10, 11521.51it/s]Processing HH:  23%|██▎       | 37669/160800 [00:02<00:10, 12164.71it/s]Processing HH:  24%|██▍       | 39162/160800 [00:02<00:09, 12885.20it/s]Processing HH:  25%|██▌       | 40675/160800 [00:02<00:08, 13493.20it/s]Processing HH:  26%|██▌       | 42205/160800 [00:03<00:08, 13996.53it/s]Processing HH:  27%|██▋       | 43662/160800 [00:03<00:08, 14106.99it/s]Processing HH:  28%|██▊       | 45114/160800 [00:03<00:08, 14199.19it/s]Processing HH:  29%|██▉       | 46563/160800 [00:03<00:08, 14190.06it/s]Processing HH:  30%|██▉       | 48002/160800 [00:03<00:07, 14178.28it/s]Processing HH:  31%|███       | 49434/160800 [00:03<00:07, 14188.59it/s]Processing HH:  32%|███▏      | 50863/160800 [00:03<00:07, 14125.30it/s]Processing HH:  33%|███▎      | 52283/160800 [00:03<00:07, 13919.94it/s]Processing HH:  33%|███▎      | 53709/160800 [00:03<00:07, 14018.15it/s]Processing HH:  34%|███▍      | 55121/160800 [00:03<00:07, 14047.23it/s]Processing HH:  35%|███▌      | 56529/160800 [00:04<00:07, 14011.77it/s]Processing HH:  36%|███▌      | 57933/160800 [00:04<00:11, 8873.01it/s] Processing HH:  37%|███▋      | 59340/160800 [00:04<00:10, 9969.57it/s]Processing HH:  38%|███▊      | 60731/160800 [00:04<00:09, 10882.51it/s]Processing HH:  39%|███▊      | 62140/160800 [00:04<00:08, 11676.15it/s]Processing HH:  39%|███▉      | 63488/160800 [00:04<00:08, 12147.39it/s]Processing HH:  40%|████      | 64893/160800 [00:04<00:07, 12664.16it/s]Processing HH:  41%|████      | 66325/160800 [00:04<00:07, 13128.00it/s]Processing HH:  42%|████▏     | 67727/160800 [00:05<00:06, 13381.35it/s]Processing HH:  43%|████▎     | 69131/160800 [00:05<00:06, 13570.68it/s]Processing HH:  44%|████▍     | 70526/160800 [00:05<00:06, 13681.54it/s]Processing HH:  45%|████▍     | 71977/160800 [00:05<00:06, 13920.11it/s]Processing HH:  46%|████▌     | 73429/160800 [00:05<00:06, 14096.40it/s]Processing HH:  47%|████▋     | 74864/160800 [00:05<00:06, 14171.70it/s]Processing HH:  47%|████▋     | 76289/160800 [00:05<00:05, 14173.57it/s]Processing HH:  48%|████▊     | 77712/160800 [00:05<00:05, 13985.33it/s]Processing HH:  49%|████▉     | 79117/160800 [00:05<00:05, 14004.00it/s]Processing HH:  50%|█████     | 80557/160800 [00:05<00:05, 14120.17it/s]Processing HH:  51%|█████     | 81997/160800 [00:06<00:05, 14203.16it/s]Processing HH:  52%|█████▏    | 83424/160800 [00:06<00:05, 14221.87it/s]Processing HH:  53%|█████▎    | 84867/160800 [00:06<00:05, 14280.50it/s]Processing HH:  54%|█████▎    | 86296/160800 [00:06<00:05, 14177.90it/s]Processing HH:  55%|█████▍    | 87715/160800 [00:06<00:08, 8487.56it/s] Processing HH:  55%|█████▌    | 88839/160800 [00:06<00:08, 8415.55it/s]Processing HH:  56%|█████▌    | 89872/160800 [00:06<00:08, 8456.89it/s]Processing HH:  57%|█████▋    | 90853/160800 [00:07<00:08, 8386.71it/s]Processing HH:  57%|█████▋    | 91785/160800 [00:07<00:08, 8424.04it/s]Processing HH:  58%|█████▊    | 92694/160800 [00:07<00:08, 8466.59it/s]Processing HH:  58%|█████▊    | 93588/160800 [00:07<00:08, 8354.99it/s]Processing HH:  59%|█████▊    | 94456/160800 [00:07<00:07, 8399.82it/s]Processing HH:  59%|█████▉    | 95319/160800 [00:07<00:07, 8405.45it/s]Processing HH:  60%|█████▉    | 96176/160800 [00:07<00:07, 8349.34it/s]Processing HH:  60%|██████    | 97022/160800 [00:07<00:07, 8348.94it/s]Processing HH:  61%|██████    | 97885/160800 [00:07<00:07, 8421.64it/s]Processing HH:  61%|██████▏   | 98733/160800 [00:08<00:07, 8377.57it/s]Processing HH:  62%|██████▏   | 99575/160800 [00:08<00:07, 8358.52it/s]Processing HH:  62%|██████▏   | 100414/160800 [00:08<00:07, 8298.16it/s]Processing HH:  63%|██████▎   | 101270/160800 [00:08<00:07, 8372.77it/s]Processing HH:  64%|██████▎   | 102109/160800 [00:08<00:07, 8340.47it/s]Processing HH:  64%|██████▍   | 102982/160800 [00:08<00:06, 8453.36it/s]Processing HH:  65%|██████▍   | 103841/160800 [00:08<00:06, 8492.80it/s]Processing HH:  65%|██████▌   | 104691/160800 [00:08<00:06, 8432.99it/s]Processing HH:  66%|██████▌   | 105535/160800 [00:08<00:06, 8425.93it/s]Processing HH:  66%|██████▌   | 106378/160800 [00:08<00:06, 8321.13it/s]Processing HH:  67%|██████▋   | 107226/160800 [00:09<00:06, 8367.43it/s]Processing HH:  67%|██████▋   | 108064/160800 [00:09<00:06, 8281.18it/s]Processing HH:  68%|██████▊   | 109163/160800 [00:09<00:05, 9081.72it/s]Processing HH:  69%|██████▊   | 110408/160800 [00:09<00:04, 10081.58it/s]Processing HH:  69%|██████▉   | 111640/160800 [00:09<00:04, 10747.54it/s]Processing HH:  70%|███████   | 112861/160800 [00:09<00:04, 11181.07it/s]Processing HH:  71%|███████   | 114082/160800 [00:09<00:04, 11488.43it/s]Processing HH:  72%|███████▏  | 115318/160800 [00:09<00:03, 11748.82it/s]Processing HH:  72%|███████▏  | 116541/160800 [00:09<00:03, 11892.81it/s]Processing HH:  73%|███████▎  | 117796/160800 [00:09<00:03, 12089.07it/s]Processing HH:  74%|███████▍  | 119011/160800 [00:10<00:03, 12104.81it/s]Processing HH:  75%|███████▍  | 120281/160800 [00:10<00:03, 12280.28it/s]Processing HH:  76%|███████▌  | 121557/160800 [00:10<00:03, 12423.02it/s]Processing HH:  76%|███████▋  | 122800/160800 [00:10<00:04, 8085.11it/s] Processing HH:  77%|███████▋  | 124032/160800 [00:10<00:04, 9008.08it/s]Processing HH:  78%|███████▊  | 125258/160800 [00:10<00:03, 9779.07it/s]Processing HH:  79%|███████▊  | 126463/160800 [00:10<00:03, 10351.20it/s]Processing HH:  79%|███████▉  | 127725/160800 [00:10<00:03, 10952.73it/s]Processing HH:  80%|████████  | 129012/160800 [00:11<00:02, 11477.37it/s]Processing HH:  81%|████████  | 130259/160800 [00:11<00:02, 11755.95it/s]Processing HH:  82%|████████▏ | 131509/160800 [00:11<00:02, 11969.49it/s]Processing HH:  83%|████████▎ | 132740/160800 [00:11<00:02, 12039.13it/s]Processing HH:  83%|████████▎ | 133982/160800 [00:11<00:02, 12150.55it/s]Processing HH:  84%|████████▍ | 135222/160800 [00:11<00:02, 12221.32it/s]Processing HH:  85%|████████▍ | 136476/160800 [00:11<00:01, 12314.89it/s]Processing HH:  86%|████████▌ | 137716/160800 [00:11<00:01, 12304.54it/s]Processing HH:  86%|████████▋ | 138953/160800 [00:11<00:01, 12192.72it/s]Processing HH:  87%|████████▋ | 140207/160800 [00:11<00:01, 12292.82it/s]Processing HH:  88%|████████▊ | 141440/160800 [00:12<00:01, 12214.21it/s]Processing HH:  89%|████████▊ | 142697/160800 [00:12<00:01, 12319.45it/s]Processing HH:  90%|████████▉ | 143965/160800 [00:12<00:01, 12423.19it/s]Processing HH:  90%|█████████ | 145216/160800 [00:12<00:01, 12447.49it/s]Processing HH:  91%|█████████ | 146464/160800 [00:12<00:01, 12454.66it/s]Processing HH:  92%|█████████▏| 147713/160800 [00:12<00:01, 12464.74it/s]Processing HH:  93%|█████████▎| 148973/160800 [00:12<00:00, 12503.46it/s]Processing HH:  93%|█████████▎| 150224/160800 [00:12<00:00, 12344.19it/s]Processing HH:  94%|█████████▍| 151460/160800 [00:12<00:00, 12300.46it/s]Processing HH:  95%|█████████▍| 152720/160800 [00:12<00:00, 12382.74it/s]Processing HH:  96%|█████████▌| 153959/160800 [00:13<00:00, 12313.74it/s]Processing HH:  97%|█████████▋| 155206/160800 [00:13<00:00, 12359.96it/s]Processing HH:  97%|█████████▋| 156484/160800 [00:13<00:00, 12482.27it/s]Processing HH:  98%|█████████▊| 157733/160800 [00:13<00:00, 12437.29it/s]Processing HH:  99%|█████████▉| 158977/160800 [00:13<00:00, 12361.90it/s]Processing HH: 100%|█████████▉| 160226/160800 [00:13<00:00, 12398.17it/s]Processing HH: 100%|██████████| 160800/160800 [00:13<00:00, 11823.35it/s]
Loading HH dataset (test split) from Huggingface...
Processing HH:   0%|          | 0/8552 [00:00<?, ?it/s]Processing HH:  16%|█▋        | 1408/8552 [00:00<00:00, 14078.17it/s]Processing HH:  33%|███▎      | 2843/8552 [00:00<00:00, 14235.63it/s]Processing HH:  50%|████▉     | 4267/8552 [00:00<00:00, 14066.45it/s]Processing HH:  66%|██████▋   | 5674/8552 [00:00<00:00, 11806.28it/s]Processing HH:  81%|████████  | 6899/8552 [00:00<00:00, 11703.70it/s]Processing HH:  95%|█████████▍| 8097/8552 [00:01<00:00, 5223.01it/s] Processing HH: 100%|██████████| 8552/8552 [00:01<00:00, 7762.53it/s]
starting 4 processes for FSDP training
setting RLIMIT_NOFILE soft limit to 1048576 from 1024
4
0 initializing distributed
Creating trainer on process 0 with world size 4
Finished 512 examples on test split
Loaded 32 eval batches of size 16
Sharding models...
Attempting to enable activation checkpointing...
Applying activation checkpointing wrapper to policy...
FSDP activation checkpointing enabled!
Loaded model on rank 0
Using RMSprop optimizer with learning rate 2e-05
Running evaluation after 0 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]/home/wxt/.conda/envs/halos3/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/wxt/.conda/envs/halos3/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/wxt/.conda/envs/halos3/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/wxt/.conda/envs/halos3/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Computing eval metrics:   3%|▎         | 1/32 [00:02<01:16,  2.48s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:05,  2.19s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:55,  1.91s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.87s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.52s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:41,  1.61s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.45s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.51s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:34,  1.52s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:31,  1.44s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:31,  1.51s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:28,  1.44s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:26,  1.40s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:24,  1.39s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.25s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.20s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.28s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.29s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.24s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.19s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.23s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:30<00:11,  1.11s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.18s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.25s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:08,  1.22s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.26s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:37<00:07,  1.43s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.37s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.56s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.38s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.37s/it]Computing eval metrics: 100%|██████████| 32/32 [00:44<00:00,  1.36s/it]Computing eval metrics: 100%|██████████| 32/32 [00:44<00:00,  1.40s/it]
eval after 0: {'rewards_eval/chosen': '0', 'rewards_eval/rejected': '0', 'rewards_eval/accuracies': '0', 'rewards_eval/margins': '0', 'logps_eval/rejected': '-122.57', 'logps_eval/chosen': '-119.35', 'loss/eval': '0.69141'}
skipping logging after 32 examples to avoid logging too frequently
skipping logging after 64 examples to avoid logging too frequently
skipping logging after 96 examples to avoid logging too frequently
train stats after 128 examples: {'rewards_train/chosen': '0', 'rewards_train/rejected': '0', 'rewards_train/accuracies': '0', 'rewards_train/margins': '0', 'logps_train/rejected': '-110.31', 'logps_train/chosen': '-104.67', 'loss/train': '0.69141', 'examples_per_second': '5.4288', 'grad_norm': '7.5', 'counters/examples': 128, 'counters/updates': 4}
skipping logging after 160 examples to avoid logging too frequently
skipping logging after 192 examples to avoid logging too frequently
skipping logging after 224 examples to avoid logging too frequently
train stats after 256 examples: {'rewards_train/chosen': '0.0025787', 'rewards_train/rejected': '0.0023', 'rewards_train/accuracies': '0.33594', 'rewards_train/margins': '0.00027376', 'logps_train/rejected': '-118.32', 'logps_train/chosen': '-99.306', 'loss/train': '0.69324', 'examples_per_second': '4.8324', 'grad_norm': '7.1562', 'counters/examples': 256, 'counters/updates': 8}
skipping logging after 288 examples to avoid logging too frequently
skipping logging after 320 examples to avoid logging too frequently
skipping logging after 352 examples to avoid logging too frequently
train stats after 384 examples: {'rewards_train/chosen': '0.0036669', 'rewards_train/rejected': '0.0056696', 'rewards_train/accuracies': '0.27344', 'rewards_train/margins': '-0.0020031', 'logps_train/rejected': '-123.54', 'logps_train/chosen': '-86.7', 'loss/train': '0.69415', 'examples_per_second': '5.7612', 'grad_norm': '7.0625', 'counters/examples': 384, 'counters/updates': 12}
skipping logging after 416 examples to avoid logging too frequently
skipping logging after 448 examples to avoid logging too frequently
skipping logging after 480 examples to avoid logging too frequently
train stats after 512 examples: {'rewards_train/chosen': '0.0033339', 'rewards_train/rejected': '-0.0019137', 'rewards_train/accuracies': '0.40625', 'rewards_train/margins': '0.0052454', 'logps_train/rejected': '-93.112', 'logps_train/chosen': '-72.748', 'loss/train': '0.68979', 'examples_per_second': '5.4647', 'grad_norm': '6.1562', 'counters/examples': 512, 'counters/updates': 16}
skipping logging after 544 examples to avoid logging too frequently
skipping logging after 576 examples to avoid logging too frequently
skipping logging after 608 examples to avoid logging too frequently
train stats after 640 examples: {'rewards_train/chosen': '0.010288', 'rewards_train/rejected': '-0.0043132', 'rewards_train/accuracies': '0.42188', 'rewards_train/margins': '0.014614', 'logps_train/rejected': '-108.01', 'logps_train/chosen': '-93.097', 'loss/train': '0.68445', 'examples_per_second': '4.5751', 'grad_norm': '6.6875', 'counters/examples': 640, 'counters/updates': 20}
skipping logging after 672 examples to avoid logging too frequently
skipping logging after 704 examples to avoid logging too frequently
skipping logging after 736 examples to avoid logging too frequently
train stats after 768 examples: {'rewards_train/chosen': '0.025348', 'rewards_train/rejected': '-0.0071843', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.032528', 'logps_train/rejected': '-111.35', 'logps_train/chosen': '-109.41', 'loss/train': '0.67706', 'examples_per_second': '4.9464', 'grad_norm': '7.5625', 'counters/examples': 768, 'counters/updates': 24}
skipping logging after 800 examples to avoid logging too frequently
skipping logging after 832 examples to avoid logging too frequently
skipping logging after 864 examples to avoid logging too frequently
train stats after 896 examples: {'rewards_train/chosen': '0.026631', 'rewards_train/rejected': '0.0048876', 'rewards_train/accuracies': '0.52344', 'rewards_train/margins': '0.021742', 'logps_train/rejected': '-102.18', 'logps_train/chosen': '-92.842', 'loss/train': '0.68307', 'examples_per_second': '5.1808', 'grad_norm': '6.6562', 'counters/examples': 896, 'counters/updates': 28}
skipping logging after 928 examples to avoid logging too frequently
skipping logging after 960 examples to avoid logging too frequently
skipping logging after 992 examples to avoid logging too frequently
Running evaluation after 992 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:18,  2.54s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:07,  2.25s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:57,  1.97s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:08<00:54,  1.93s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:09<00:42,  1.57s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.67s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:12<00:37,  1.49s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.57s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:36,  1.57s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.50s/it]Computing eval metrics:  41%|████      | 13/32 [00:21<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.43s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.29s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.23s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.32s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.33s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.28s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.26s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.14s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:33<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.25s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:37<00:07,  1.29s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:39<00:07,  1.47s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.41s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.44s/it]
eval after 992: {'rewards_eval/chosen': '-0.00021276', 'rewards_eval/rejected': '-0.0010802', 'rewards_eval/accuracies': '0.37305', 'rewards_eval/margins': '0.00086385', 'logps_eval/rejected': '-122.58', 'logps_eval/chosen': '-119.35', 'loss/eval': '0.69347'}
train stats after 1024 examples: {'rewards_train/chosen': '0.028988', 'rewards_train/rejected': '-0.00086141', 'rewards_train/accuracies': '0.54688', 'rewards_train/margins': '0.029845', 'logps_train/rejected': '-112.39', 'logps_train/chosen': '-96.443', 'loss/train': '0.67816', 'examples_per_second': '4.9707', 'grad_norm': '6.8125', 'counters/examples': 1024, 'counters/updates': 32}
skipping logging after 1056 examples to avoid logging too frequently
skipping logging after 1088 examples to avoid logging too frequently
skipping logging after 1120 examples to avoid logging too frequently
train stats after 1152 examples: {'rewards_train/chosen': '0.036145', 'rewards_train/rejected': '-0.0085051', 'rewards_train/accuracies': '0.65625', 'rewards_train/margins': '0.044664', 'logps_train/rejected': '-97.318', 'logps_train/chosen': '-89.999', 'loss/train': '0.67154', 'examples_per_second': '5.1991', 'grad_norm': '6.375', 'counters/examples': 1152, 'counters/updates': 36}
skipping logging after 1184 examples to avoid logging too frequently
skipping logging after 1216 examples to avoid logging too frequently
skipping logging after 1248 examples to avoid logging too frequently
train stats after 1280 examples: {'rewards_train/chosen': '0.05312', 'rewards_train/rejected': '-0.0021745', 'rewards_train/accuracies': '0.64844', 'rewards_train/margins': '0.055313', 'logps_train/rejected': '-120.92', 'logps_train/chosen': '-99.042', 'loss/train': '0.66809', 'examples_per_second': '4.2981', 'grad_norm': '6.7812', 'counters/examples': 1280, 'counters/updates': 40}
skipping logging after 1312 examples to avoid logging too frequently
skipping logging after 1344 examples to avoid logging too frequently
skipping logging after 1376 examples to avoid logging too frequently
train stats after 1408 examples: {'rewards_train/chosen': '0.062734', 'rewards_train/rejected': '-0.004474', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.067218', 'logps_train/rejected': '-125.86', 'logps_train/chosen': '-89.81', 'loss/train': '0.66145', 'examples_per_second': '5.1543', 'grad_norm': '6.8125', 'counters/examples': 1408, 'counters/updates': 44}
skipping logging after 1440 examples to avoid logging too frequently
skipping logging after 1472 examples to avoid logging too frequently
skipping logging after 1504 examples to avoid logging too frequently
train stats after 1536 examples: {'rewards_train/chosen': '0.072374', 'rewards_train/rejected': '-0.015622', 'rewards_train/accuracies': '0.75', 'rewards_train/margins': '0.088012', 'logps_train/rejected': '-119.58', 'logps_train/chosen': '-86.961', 'loss/train': '0.64964', 'examples_per_second': '4.0833', 'grad_norm': '6.7188', 'counters/examples': 1536, 'counters/updates': 48}
skipping logging after 1568 examples to avoid logging too frequently
skipping logging after 1600 examples to avoid logging too frequently
skipping logging after 1632 examples to avoid logging too frequently
train stats after 1664 examples: {'rewards_train/chosen': '0.094401', 'rewards_train/rejected': '-0.018748', 'rewards_train/accuracies': '0.77344', 'rewards_train/margins': '0.11316', 'logps_train/rejected': '-122.13', 'logps_train/chosen': '-100.17', 'loss/train': '0.64038', 'examples_per_second': '5.6091', 'grad_norm': '6.5938', 'counters/examples': 1664, 'counters/updates': 52}
skipping logging after 1696 examples to avoid logging too frequently
skipping logging after 1728 examples to avoid logging too frequently
skipping logging after 1760 examples to avoid logging too frequently
train stats after 1792 examples: {'rewards_train/chosen': '0.096991', 'rewards_train/rejected': '-0.026672', 'rewards_train/accuracies': '0.8125', 'rewards_train/margins': '0.12369', 'logps_train/rejected': '-125.18', 'logps_train/chosen': '-91.07', 'loss/train': '0.6366', 'examples_per_second': '6.2506', 'grad_norm': '6.625', 'counters/examples': 1792, 'counters/updates': 56}
skipping logging after 1824 examples to avoid logging too frequently
skipping logging after 1856 examples to avoid logging too frequently
skipping logging after 1888 examples to avoid logging too frequently
train stats after 1920 examples: {'rewards_train/chosen': '0.11305', 'rewards_train/rejected': '-0.032148', 'rewards_train/accuracies': '0.82812', 'rewards_train/margins': '0.14522', 'logps_train/rejected': '-88.796', 'logps_train/chosen': '-87.399', 'loss/train': '0.62704', 'examples_per_second': '4.6523', 'grad_norm': '6', 'counters/examples': 1920, 'counters/updates': 60}
skipping logging after 1952 examples to avoid logging too frequently
skipping logging after 1984 examples to avoid logging too frequently
Running evaluation after 1984 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:21,  2.64s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:08,  2.29s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:57,  1.98s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:08<00:54,  1.94s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:09<00:42,  1.57s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.67s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:12<00:37,  1.49s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.48s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.55s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:21<00:27,  1.44s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.23s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.32s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:33<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.25s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:37<00:07,  1.29s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.44s/it]
eval after 1984: {'rewards_eval/chosen': '-0.029579', 'rewards_eval/rejected': '-0.044154', 'rewards_eval/accuracies': '0.49023', 'rewards_eval/margins': '0.014576', 'logps_eval/rejected': '-123.01', 'logps_eval/chosen': '-119.65', 'loss/eval': '0.68951'}
skipping logging after 2016 examples to avoid logging too frequently
train stats after 2048 examples: {'rewards_train/chosen': '0.13467', 'rewards_train/rejected': '-0.023412', 'rewards_train/accuracies': '0.78906', 'rewards_train/margins': '0.15812', 'logps_train/rejected': '-118.32', 'logps_train/chosen': '-94.419', 'loss/train': '0.62177', 'examples_per_second': '5.0847', 'grad_norm': '6.7812', 'counters/examples': 2048, 'counters/updates': 64}
skipping logging after 2080 examples to avoid logging too frequently
skipping logging after 2112 examples to avoid logging too frequently
skipping logging after 2144 examples to avoid logging too frequently
train stats after 2176 examples: {'rewards_train/chosen': '0.13737', 'rewards_train/rejected': '-0.061769', 'rewards_train/accuracies': '0.8125', 'rewards_train/margins': '0.19916', 'logps_train/rejected': '-103.29', 'logps_train/chosen': '-92.247', 'loss/train': '0.60989', 'examples_per_second': '5.5757', 'grad_norm': '6', 'counters/examples': 2176, 'counters/updates': 68}
skipping logging after 2208 examples to avoid logging too frequently
skipping logging after 2240 examples to avoid logging too frequently
skipping logging after 2272 examples to avoid logging too frequently
train stats after 2304 examples: {'rewards_train/chosen': '0.14903', 'rewards_train/rejected': '-0.10629', 'rewards_train/accuracies': '0.84375', 'rewards_train/margins': '0.25538', 'logps_train/rejected': '-119.1', 'logps_train/chosen': '-94.775', 'loss/train': '0.58531', 'examples_per_second': '5.2748', 'grad_norm': '6.4688', 'counters/examples': 2304, 'counters/updates': 72}
skipping logging after 2336 examples to avoid logging too frequently
skipping logging after 2368 examples to avoid logging too frequently
skipping logging after 2400 examples to avoid logging too frequently
train stats after 2432 examples: {'rewards_train/chosen': '0.15525', 'rewards_train/rejected': '-0.068068', 'rewards_train/accuracies': '0.84375', 'rewards_train/margins': '0.22323', 'logps_train/rejected': '-102.49', 'logps_train/chosen': '-88.791', 'loss/train': '0.5952', 'examples_per_second': '5.7316', 'grad_norm': '6.0312', 'counters/examples': 2432, 'counters/updates': 76}
skipping logging after 2464 examples to avoid logging too frequently
skipping logging after 2496 examples to avoid logging too frequently
skipping logging after 2528 examples to avoid logging too frequently
train stats after 2560 examples: {'rewards_train/chosen': '0.16749', 'rewards_train/rejected': '-0.091583', 'rewards_train/accuracies': '0.82031', 'rewards_train/margins': '0.25912', 'logps_train/rejected': '-122.55', 'logps_train/chosen': '-92.277', 'loss/train': '0.58793', 'examples_per_second': '6.2495', 'grad_norm': '6.2188', 'counters/examples': 2560, 'counters/updates': 80}
skipping logging after 2592 examples to avoid logging too frequently
skipping logging after 2624 examples to avoid logging too frequently
skipping logging after 2656 examples to avoid logging too frequently
train stats after 2688 examples: {'rewards_train/chosen': '0.17709', 'rewards_train/rejected': '-0.08008', 'rewards_train/accuracies': '0.80469', 'rewards_train/margins': '0.25717', 'logps_train/rejected': '-108.43', 'logps_train/chosen': '-95.337', 'loss/train': '0.58383', 'examples_per_second': '5.183', 'grad_norm': '5.8125', 'counters/examples': 2688, 'counters/updates': 84}
skipping logging after 2720 examples to avoid logging too frequently
skipping logging after 2752 examples to avoid logging too frequently
skipping logging after 2784 examples to avoid logging too frequently
train stats after 2816 examples: {'rewards_train/chosen': '0.13856', 'rewards_train/rejected': '-0.081913', 'rewards_train/accuracies': '0.82031', 'rewards_train/margins': '0.2204', 'logps_train/rejected': '-96.058', 'logps_train/chosen': '-69.636', 'loss/train': '0.59996', 'examples_per_second': '5.3686', 'grad_norm': '5.375', 'counters/examples': 2816, 'counters/updates': 88}
skipping logging after 2848 examples to avoid logging too frequently
skipping logging after 2880 examples to avoid logging too frequently
skipping logging after 2912 examples to avoid logging too frequently
train stats after 2944 examples: {'rewards_train/chosen': '0.14968', 'rewards_train/rejected': '-0.12179', 'rewards_train/accuracies': '0.83594', 'rewards_train/margins': '0.27158', 'logps_train/rejected': '-104.31', 'logps_train/chosen': '-87.517', 'loss/train': '0.58056', 'examples_per_second': '5.5584', 'grad_norm': '5.6875', 'counters/examples': 2944, 'counters/updates': 92}
skipping logging after 2976 examples to avoid logging too frequently
Running evaluation after 2976 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:27,  2.81s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:10,  2.36s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:58,  2.02s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:08<00:54,  1.96s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:09<00:42,  1.58s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:11<00:43,  1.68s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:12<00:37,  1.50s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.48s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.55s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.49s/it]Computing eval metrics:  41%|████      | 13/32 [00:21<00:27,  1.44s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.23s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:26<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.33s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:31<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:33<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.25s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:37<00:07,  1.29s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:39<00:07,  1.47s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.41s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.44s/it]
eval after 2976: {'rewards_eval/chosen': '-0.13803', 'rewards_eval/rejected': '-0.16609', 'rewards_eval/accuracies': '0.51367', 'rewards_eval/margins': '0.028082', 'logps_eval/rejected': '-124.23', 'logps_eval/chosen': '-120.73', 'loss/eval': '0.69233'}
skipping logging after 3008 examples to avoid logging too frequently
skipping logging after 3040 examples to avoid logging too frequently
train stats after 3072 examples: {'rewards_train/chosen': '0.20063', 'rewards_train/rejected': '-0.15076', 'rewards_train/accuracies': '0.83594', 'rewards_train/margins': '0.35145', 'logps_train/rejected': '-118.03', 'logps_train/chosen': '-92.853', 'loss/train': '0.55614', 'examples_per_second': '4.7453', 'grad_norm': '5.8438', 'counters/examples': 3072, 'counters/updates': 96}
skipping logging after 3104 examples to avoid logging too frequently
skipping logging after 3136 examples to avoid logging too frequently
skipping logging after 3168 examples to avoid logging too frequently
train stats after 3200 examples: {'rewards_train/chosen': '0.2508', 'rewards_train/rejected': '-0.19447', 'rewards_train/accuracies': '0.875', 'rewards_train/margins': '0.44516', 'logps_train/rejected': '-141.72', 'logps_train/chosen': '-104.42', 'loss/train': '0.52203', 'examples_per_second': '4.8594', 'grad_norm': '5.9375', 'counters/examples': 3200, 'counters/updates': 100}
skipping logging after 3232 examples to avoid logging too frequently
skipping logging after 3264 examples to avoid logging too frequently
skipping logging after 3296 examples to avoid logging too frequently
train stats after 3328 examples: {'rewards_train/chosen': '0.23069', 'rewards_train/rejected': '-0.17724', 'rewards_train/accuracies': '0.84375', 'rewards_train/margins': '0.40795', 'logps_train/rejected': '-126.24', 'logps_train/chosen': '-93.443', 'loss/train': '0.53779', 'examples_per_second': '5.2449', 'grad_norm': '5.625', 'counters/examples': 3328, 'counters/updates': 104}
skipping logging after 3360 examples to avoid logging too frequently
skipping logging after 3392 examples to avoid logging too frequently
skipping logging after 3424 examples to avoid logging too frequently
train stats after 3456 examples: {'rewards_train/chosen': '0.17331', 'rewards_train/rejected': '-0.19913', 'rewards_train/accuracies': '0.79688', 'rewards_train/margins': '0.37245', 'logps_train/rejected': '-109.78', 'logps_train/chosen': '-92.721', 'loss/train': '0.55099', 'examples_per_second': '5.0093', 'grad_norm': '5.3125', 'counters/examples': 3456, 'counters/updates': 108}
skipping logging after 3488 examples to avoid logging too frequently
skipping logging after 3520 examples to avoid logging too frequently
skipping logging after 3552 examples to avoid logging too frequently
train stats after 3584 examples: {'rewards_train/chosen': '0.17141', 'rewards_train/rejected': '-0.33257', 'rewards_train/accuracies': '0.84375', 'rewards_train/margins': '0.50397', 'logps_train/rejected': '-130.54', 'logps_train/chosen': '-93.669', 'loss/train': '0.51251', 'examples_per_second': '4.8647', 'grad_norm': '5.4375', 'counters/examples': 3584, 'counters/updates': 112}
skipping logging after 3616 examples to avoid logging too frequently
skipping logging after 3648 examples to avoid logging too frequently
skipping logging after 3680 examples to avoid logging too frequently
train stats after 3712 examples: {'rewards_train/chosen': '0.17235', 'rewards_train/rejected': '-0.30352', 'rewards_train/accuracies': '0.82812', 'rewards_train/margins': '0.47588', 'logps_train/rejected': '-106.6', 'logps_train/chosen': '-102.83', 'loss/train': '0.51475', 'examples_per_second': '5.9028', 'grad_norm': '5.5312', 'counters/examples': 3712, 'counters/updates': 116}
skipping logging after 3744 examples to avoid logging too frequently
skipping logging after 3776 examples to avoid logging too frequently
skipping logging after 3808 examples to avoid logging too frequently
train stats after 3840 examples: {'rewards_train/chosen': '0.16133', 'rewards_train/rejected': '-0.32929', 'rewards_train/accuracies': '0.84375', 'rewards_train/margins': '0.49064', 'logps_train/rejected': '-113.3', 'logps_train/chosen': '-94.58', 'loss/train': '0.51239', 'examples_per_second': '5.2808', 'grad_norm': '5.5', 'counters/examples': 3840, 'counters/updates': 120}
skipping logging after 3872 examples to avoid logging too frequently
skipping logging after 3904 examples to avoid logging too frequently
skipping logging after 3936 examples to avoid logging too frequently
train stats after 3968 examples: {'rewards_train/chosen': '0.24241', 'rewards_train/rejected': '-0.40086', 'rewards_train/accuracies': '0.92969', 'rewards_train/margins': '0.64328', 'logps_train/rejected': '-113.01', 'logps_train/chosen': '-94.726', 'loss/train': '0.47175', 'examples_per_second': '5.2248', 'grad_norm': '5.3438', 'counters/examples': 3968, 'counters/updates': 124}
Running evaluation after 3968 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<01:00,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:53,  1.83s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.85s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.63s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.48s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.55s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.44s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.43s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.29s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.23s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.32s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.33s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.28s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.23s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.26s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.14s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.25s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.29s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.47s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.61s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.41s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.41s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 3968: {'rewards_eval/chosen': '-0.46489', 'rewards_eval/rejected': '-0.5181', 'rewards_eval/accuracies': '0.54102', 'rewards_eval/margins': '0.053095', 'logps_eval/rejected': '-127.75', 'logps_eval/chosen': '-124', 'loss/eval': '0.72567'}
skipping logging after 4000 examples to avoid logging too frequently
skipping logging after 4032 examples to avoid logging too frequently
skipping logging after 4064 examples to avoid logging too frequently
train stats after 4096 examples: {'rewards_train/chosen': '0.16077', 'rewards_train/rejected': '-0.43871', 'rewards_train/accuracies': '0.83594', 'rewards_train/margins': '0.59924', 'logps_train/rejected': '-117.59', 'logps_train/chosen': '-92.908', 'loss/train': '0.50116', 'examples_per_second': '4.2059', 'grad_norm': '5.75', 'counters/examples': 4096, 'counters/updates': 128}
skipping logging after 4128 examples to avoid logging too frequently
skipping logging after 4160 examples to avoid logging too frequently
skipping logging after 4192 examples to avoid logging too frequently
train stats after 4224 examples: {'rewards_train/chosen': '0.13628', 'rewards_train/rejected': '-0.53143', 'rewards_train/accuracies': '0.8125', 'rewards_train/margins': '0.66777', 'logps_train/rejected': '-113.64', 'logps_train/chosen': '-93.407', 'loss/train': '0.48423', 'examples_per_second': '4.8967', 'grad_norm': '5.1875', 'counters/examples': 4224, 'counters/updates': 132}
skipping logging after 4256 examples to avoid logging too frequently
skipping logging after 4288 examples to avoid logging too frequently
skipping logging after 4320 examples to avoid logging too frequently
train stats after 4352 examples: {'rewards_train/chosen': '0.15835', 'rewards_train/rejected': '-0.5857', 'rewards_train/accuracies': '0.89062', 'rewards_train/margins': '0.74439', 'logps_train/rejected': '-120.44', 'logps_train/chosen': '-102.04', 'loss/train': '0.45582', 'examples_per_second': '5.8012', 'grad_norm': '5.3125', 'counters/examples': 4352, 'counters/updates': 136}
skipping logging after 4384 examples to avoid logging too frequently
skipping logging after 4416 examples to avoid logging too frequently
skipping logging after 4448 examples to avoid logging too frequently
train stats after 4480 examples: {'rewards_train/chosen': '0.12501', 'rewards_train/rejected': '-0.58727', 'rewards_train/accuracies': '0.86719', 'rewards_train/margins': '0.71235', 'logps_train/rejected': '-119.05', 'logps_train/chosen': '-104.8', 'loss/train': '0.46692', 'examples_per_second': '4.9986', 'grad_norm': '5.4062', 'counters/examples': 4480, 'counters/updates': 140}
skipping logging after 4512 examples to avoid logging too frequently
skipping logging after 4544 examples to avoid logging too frequently
skipping logging after 4576 examples to avoid logging too frequently
train stats after 4608 examples: {'rewards_train/chosen': '0.14255', 'rewards_train/rejected': '-0.55559', 'rewards_train/accuracies': '0.85938', 'rewards_train/margins': '0.6981', 'logps_train/rejected': '-110.65', 'logps_train/chosen': '-89.626', 'loss/train': '0.46903', 'examples_per_second': '4.9959', 'grad_norm': '5.1875', 'counters/examples': 4608, 'counters/updates': 144}
skipping logging after 4640 examples to avoid logging too frequently
skipping logging after 4672 examples to avoid logging too frequently
skipping logging after 4704 examples to avoid logging too frequently
train stats after 4736 examples: {'rewards_train/chosen': '0.11995', 'rewards_train/rejected': '-0.63472', 'rewards_train/accuracies': '0.83594', 'rewards_train/margins': '0.75488', 'logps_train/rejected': '-126.14', 'logps_train/chosen': '-111.53', 'loss/train': '0.46069', 'examples_per_second': '4.3777', 'grad_norm': '5.5312', 'counters/examples': 4736, 'counters/updates': 148}
skipping logging after 4768 examples to avoid logging too frequently
skipping logging after 4800 examples to avoid logging too frequently
skipping logging after 4832 examples to avoid logging too frequently
train stats after 4864 examples: {'rewards_train/chosen': '0.15069', 'rewards_train/rejected': '-0.75292', 'rewards_train/accuracies': '0.85156', 'rewards_train/margins': '0.90321', 'logps_train/rejected': '-122.2', 'logps_train/chosen': '-104.84', 'loss/train': '0.41404', 'examples_per_second': '4.9472', 'grad_norm': '5.125', 'counters/examples': 4864, 'counters/updates': 152}
skipping logging after 4896 examples to avoid logging too frequently
skipping logging after 4928 examples to avoid logging too frequently
skipping logging after 4960 examples to avoid logging too frequently
Running evaluation after 4960 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:20,  2.59s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:08,  2.28s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:57,  1.98s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:08<00:54,  1.94s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:09<00:42,  1.57s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.67s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:12<00:37,  1.50s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.57s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:36,  1.57s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.49s/it]Computing eval metrics:  41%|████      | 13/32 [00:21<00:27,  1.44s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.43s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.29s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.23s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:26<00:19,  1.32s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.33s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.23s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.26s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.14s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:33<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.25s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:37<00:07,  1.29s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:39<00:07,  1.47s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.61s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.41s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.41s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.44s/it]
eval after 4960: {'rewards_eval/chosen': '-0.79853', 'rewards_eval/rejected': '-0.87149', 'rewards_eval/accuracies': '0.52344', 'rewards_eval/margins': '0.072973', 'logps_eval/rejected': '-131.28', 'logps_eval/chosen': '-127.34', 'loss/eval': '0.77073'}
train stats after 4992 examples: {'rewards_train/chosen': '0.087427', 'rewards_train/rejected': '-0.79511', 'rewards_train/accuracies': '0.83594', 'rewards_train/margins': '0.88239', 'logps_train/rejected': '-118.38', 'logps_train/chosen': '-100.39', 'loss/train': '0.43983', 'examples_per_second': '5.048', 'grad_norm': '5.25', 'counters/examples': 4992, 'counters/updates': 156}
skipping logging after 5024 examples to avoid logging too frequently
skipping logging after 5056 examples to avoid logging too frequently
skipping logging after 5088 examples to avoid logging too frequently
train stats after 5120 examples: {'rewards_train/chosen': '0.14703', 'rewards_train/rejected': '-0.7804', 'rewards_train/accuracies': '0.85156', 'rewards_train/margins': '0.92732', 'logps_train/rejected': '-124.06', 'logps_train/chosen': '-97.975', 'loss/train': '0.42365', 'examples_per_second': '4.9572', 'grad_norm': '5.125', 'counters/examples': 5120, 'counters/updates': 160}
skipping logging after 5152 examples to avoid logging too frequently
skipping logging after 5184 examples to avoid logging too frequently
skipping logging after 5216 examples to avoid logging too frequently
train stats after 5248 examples: {'rewards_train/chosen': '0.043969', 'rewards_train/rejected': '-0.7233', 'rewards_train/accuracies': '0.83594', 'rewards_train/margins': '0.76711', 'logps_train/rejected': '-108.21', 'logps_train/chosen': '-94.64', 'loss/train': '0.45002', 'examples_per_second': '6.4886', 'grad_norm': '5.375', 'counters/examples': 5248, 'counters/updates': 164}
skipping logging after 5280 examples to avoid logging too frequently
skipping logging after 5312 examples to avoid logging too frequently
skipping logging after 5344 examples to avoid logging too frequently
train stats after 5376 examples: {'rewards_train/chosen': '0.055729', 'rewards_train/rejected': '-0.8085', 'rewards_train/accuracies': '0.83594', 'rewards_train/margins': '0.8643', 'logps_train/rejected': '-116.9', 'logps_train/chosen': '-104.9', 'loss/train': '0.44343', 'examples_per_second': '5.3865', 'grad_norm': '5.2812', 'counters/examples': 5376, 'counters/updates': 168}
skipping logging after 5408 examples to avoid logging too frequently
skipping logging after 5440 examples to avoid logging too frequently
skipping logging after 5472 examples to avoid logging too frequently
train stats after 5504 examples: {'rewards_train/chosen': '0.021455', 'rewards_train/rejected': '-0.89861', 'rewards_train/accuracies': '0.85938', 'rewards_train/margins': '0.92013', 'logps_train/rejected': '-110.27', 'logps_train/chosen': '-91.956', 'loss/train': '0.44062', 'examples_per_second': '4.1538', 'grad_norm': '5.2188', 'counters/examples': 5504, 'counters/updates': 172}
skipping logging after 5536 examples to avoid logging too frequently
skipping logging after 5568 examples to avoid logging too frequently
skipping logging after 5600 examples to avoid logging too frequently
train stats after 5632 examples: {'rewards_train/chosen': '-0.053766', 'rewards_train/rejected': '-0.91956', 'rewards_train/accuracies': '0.76562', 'rewards_train/margins': '0.8654', 'logps_train/rejected': '-111.1', 'logps_train/chosen': '-99.758', 'loss/train': '0.43909', 'examples_per_second': '5.2569', 'grad_norm': '5.1875', 'counters/examples': 5632, 'counters/updates': 176}
skipping logging after 5664 examples to avoid logging too frequently
skipping logging after 5696 examples to avoid logging too frequently
skipping logging after 5728 examples to avoid logging too frequently
train stats after 5760 examples: {'rewards_train/chosen': '0.019152', 'rewards_train/rejected': '-1.2244', 'rewards_train/accuracies': '0.80469', 'rewards_train/margins': '1.2437', 'logps_train/rejected': '-139.65', 'logps_train/chosen': '-105.8', 'loss/train': '0.37358', 'examples_per_second': '5.1422', 'grad_norm': '4.75', 'counters/examples': 5760, 'counters/updates': 180}
skipping logging after 5792 examples to avoid logging too frequently
skipping logging after 5824 examples to avoid logging too frequently
skipping logging after 5856 examples to avoid logging too frequently
train stats after 5888 examples: {'rewards_train/chosen': '-0.093975', 'rewards_train/rejected': '-1.1156', 'rewards_train/accuracies': '0.84375', 'rewards_train/margins': '1.0219', 'logps_train/rejected': '-122.43', 'logps_train/chosen': '-83.648', 'loss/train': '0.41602', 'examples_per_second': '5.2597', 'grad_norm': '6.0312', 'counters/examples': 5888, 'counters/updates': 184}
skipping logging after 5920 examples to avoid logging too frequently
skipping logging after 5952 examples to avoid logging too frequently
Running evaluation after 5952 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:25,  2.76s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:10,  2.34s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:58,  2.02s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:08<00:54,  1.96s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:09<00:42,  1.59s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:11<00:43,  1.68s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:12<00:37,  1.50s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.57s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:36,  1.57s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.49s/it]Computing eval metrics:  41%|████      | 13/32 [00:21<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.43s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.29s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.23s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:26<00:19,  1.32s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.33s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:31<00:13,  1.26s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:32<00:11,  1.14s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:33<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.29s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:36<00:08,  1.25s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:37<00:07,  1.29s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:39<00:07,  1.47s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.41s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.41s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.45s/it]
eval after 5952: {'rewards_eval/chosen': '-1.346', 'rewards_eval/rejected': '-1.4466', 'rewards_eval/accuracies': '0.54688', 'rewards_eval/margins': '0.10047', 'logps_eval/rejected': '-137.03', 'logps_eval/chosen': '-132.81', 'loss/eval': '0.85715'}
skipping logging after 5984 examples to avoid logging too frequently
train stats after 6016 examples: {'rewards_train/chosen': '-0.28604', 'rewards_train/rejected': '-1.5923', 'rewards_train/accuracies': '0.82031', 'rewards_train/margins': '1.3062', 'logps_train/rejected': '-143.23', 'logps_train/chosen': '-113', 'loss/train': '0.40072', 'examples_per_second': '5.315', 'grad_norm': '6.0938', 'counters/examples': 6016, 'counters/updates': 188}
skipping logging after 6048 examples to avoid logging too frequently
skipping logging after 6080 examples to avoid logging too frequently
skipping logging after 6112 examples to avoid logging too frequently
train stats after 6144 examples: {'rewards_train/chosen': '-0.064535', 'rewards_train/rejected': '-1.079', 'rewards_train/accuracies': '0.85156', 'rewards_train/margins': '1.0145', 'logps_train/rejected': '-115.76', 'logps_train/chosen': '-86.262', 'loss/train': '0.40664', 'examples_per_second': '6.2692', 'grad_norm': '5.4375', 'counters/examples': 6144, 'counters/updates': 192}
skipping logging after 6176 examples to avoid logging too frequently
skipping logging after 6208 examples to avoid logging too frequently
skipping logging after 6240 examples to avoid logging too frequently
train stats after 6272 examples: {'rewards_train/chosen': '-0.20807', 'rewards_train/rejected': '-1.334', 'rewards_train/accuracies': '0.80469', 'rewards_train/margins': '1.1265', 'logps_train/rejected': '-116.47', 'logps_train/chosen': '-114.85', 'loss/train': '0.42753', 'examples_per_second': '4.6429', 'grad_norm': '7.4375', 'counters/examples': 6272, 'counters/updates': 196}
skipping logging after 6304 examples to avoid logging too frequently
skipping logging after 6336 examples to avoid logging too frequently
skipping logging after 6368 examples to avoid logging too frequently
train stats after 6400 examples: {'rewards_train/chosen': '0.0012674', 'rewards_train/rejected': '-0.96536', 'rewards_train/accuracies': '0.82031', 'rewards_train/margins': '0.96652', 'logps_train/rejected': '-120.08', 'logps_train/chosen': '-86.842', 'loss/train': '0.42585', 'examples_per_second': '4.7553', 'grad_norm': '5.4688', 'counters/examples': 6400, 'counters/updates': 200}
skipping logging after 6432 examples to avoid logging too frequently
skipping logging after 6464 examples to avoid logging too frequently
skipping logging after 6496 examples to avoid logging too frequently
train stats after 6528 examples: {'rewards_train/chosen': '-0.034914', 'rewards_train/rejected': '-1.1236', 'rewards_train/accuracies': '0.89062', 'rewards_train/margins': '1.0889', 'logps_train/rejected': '-119.72', 'logps_train/chosen': '-91.417', 'loss/train': '0.38782', 'examples_per_second': '4.5894', 'grad_norm': '4.9688', 'counters/examples': 6528, 'counters/updates': 204}
skipping logging after 6560 examples to avoid logging too frequently
skipping logging after 6592 examples to avoid logging too frequently
skipping logging after 6624 examples to avoid logging too frequently
train stats after 6656 examples: {'rewards_train/chosen': '-0.065865', 'rewards_train/rejected': '-1.1812', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '1.1151', 'logps_train/rejected': '-124.59', 'logps_train/chosen': '-108.31', 'loss/train': '0.36981', 'examples_per_second': '5.3442', 'grad_norm': '5.0625', 'counters/examples': 6656, 'counters/updates': 208}
skipping logging after 6688 examples to avoid logging too frequently
skipping logging after 6720 examples to avoid logging too frequently
skipping logging after 6752 examples to avoid logging too frequently
train stats after 6784 examples: {'rewards_train/chosen': '-0.11731', 'rewards_train/rejected': '-1.6139', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '1.497', 'logps_train/rejected': '-143.45', 'logps_train/chosen': '-119.84', 'loss/train': '0.33416', 'examples_per_second': '4.6367', 'grad_norm': '5', 'counters/examples': 6784, 'counters/updates': 212}
skipping logging after 6816 examples to avoid logging too frequently
skipping logging after 6848 examples to avoid logging too frequently
skipping logging after 6880 examples to avoid logging too frequently
train stats after 6912 examples: {'rewards_train/chosen': '-0.18638', 'rewards_train/rejected': '-1.7739', 'rewards_train/accuracies': '0.89844', 'rewards_train/margins': '1.5871', 'logps_train/rejected': '-139.29', 'logps_train/chosen': '-98.558', 'loss/train': '0.36243', 'examples_per_second': '5.4048', 'grad_norm': '5.4375', 'counters/examples': 6912, 'counters/updates': 216}
skipping logging after 6944 examples to avoid logging too frequently
Running evaluation after 6944 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:15,  2.44s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:06,  2.21s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:56,  1.93s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.90s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.55s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.65s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.48s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.55s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.44s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.43s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.23s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.32s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.33s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.26s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.25s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.29s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 6944: {'rewards_eval/chosen': '-1.6104', 'rewards_eval/rejected': '-1.7804', 'rewards_eval/accuracies': '0.54102', 'rewards_eval/margins': '0.17013', 'logps_eval/rejected': '-140.37', 'logps_eval/chosen': '-135.46', 'loss/eval': '0.8428'}
skipping logging after 6976 examples to avoid logging too frequently
skipping logging after 7008 examples to avoid logging too frequently
train stats after 7040 examples: {'rewards_train/chosen': '-0.28421', 'rewards_train/rejected': '-1.4642', 'rewards_train/accuracies': '0.84375', 'rewards_train/margins': '1.18', 'logps_train/rejected': '-115.15', 'logps_train/chosen': '-89.314', 'loss/train': '0.41836', 'examples_per_second': '5.401', 'grad_norm': '5.6875', 'counters/examples': 7040, 'counters/updates': 220}
skipping logging after 7072 examples to avoid logging too frequently
skipping logging after 7104 examples to avoid logging too frequently
skipping logging after 7136 examples to avoid logging too frequently
train stats after 7168 examples: {'rewards_train/chosen': '-0.47141', 'rewards_train/rejected': '-1.6208', 'rewards_train/accuracies': '0.82031', 'rewards_train/margins': '1.1493', 'logps_train/rejected': '-114.52', 'logps_train/chosen': '-83.949', 'loss/train': '0.41342', 'examples_per_second': '5.3865', 'grad_norm': '6.2188', 'counters/examples': 7168, 'counters/updates': 224}
skipping logging after 7200 examples to avoid logging too frequently
skipping logging after 7232 examples to avoid logging too frequently
skipping logging after 7264 examples to avoid logging too frequently
train stats after 7296 examples: {'rewards_train/chosen': '-0.77618', 'rewards_train/rejected': '-2.4212', 'rewards_train/accuracies': '0.78125', 'rewards_train/margins': '1.6448', 'logps_train/rejected': '-160.54', 'logps_train/chosen': '-119.14', 'loss/train': '0.39841', 'examples_per_second': '4.9901', 'grad_norm': '7.0938', 'counters/examples': 7296, 'counters/updates': 228}
skipping logging after 7328 examples to avoid logging too frequently
skipping logging after 7360 examples to avoid logging too frequently
skipping logging after 7392 examples to avoid logging too frequently
train stats after 7424 examples: {'rewards_train/chosen': '-0.13367', 'rewards_train/rejected': '-1.388', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '1.254', 'logps_train/rejected': '-124.64', 'logps_train/chosen': '-94.094', 'loss/train': '0.35303', 'examples_per_second': '5.2068', 'grad_norm': '4.9375', 'counters/examples': 7424, 'counters/updates': 232}
skipping logging after 7456 examples to avoid logging too frequently
skipping logging after 7488 examples to avoid logging too frequently
skipping logging after 7520 examples to avoid logging too frequently
train stats after 7552 examples: {'rewards_train/chosen': '-0.22032', 'rewards_train/rejected': '-1.4965', 'rewards_train/accuracies': '0.875', 'rewards_train/margins': '1.2764', 'logps_train/rejected': '-118.02', 'logps_train/chosen': '-95.287', 'loss/train': '0.3519', 'examples_per_second': '5.2475', 'grad_norm': '4.9375', 'counters/examples': 7552, 'counters/updates': 236}
skipping logging after 7584 examples to avoid logging too frequently
skipping logging after 7616 examples to avoid logging too frequently
skipping logging after 7648 examples to avoid logging too frequently
train stats after 7680 examples: {'rewards_train/chosen': '-0.24612', 'rewards_train/rejected': '-1.8089', 'rewards_train/accuracies': '0.85938', 'rewards_train/margins': '1.563', 'logps_train/rejected': '-141.75', 'logps_train/chosen': '-100.81', 'loss/train': '0.31363', 'examples_per_second': '4.4326', 'grad_norm': '4.6562', 'counters/examples': 7680, 'counters/updates': 240}
skipping logging after 7712 examples to avoid logging too frequently
skipping logging after 7744 examples to avoid logging too frequently
skipping logging after 7776 examples to avoid logging too frequently
train stats after 7808 examples: {'rewards_train/chosen': '-0.41987', 'rewards_train/rejected': '-2.0238', 'rewards_train/accuracies': '0.86719', 'rewards_train/margins': '1.6046', 'logps_train/rejected': '-133.88', 'logps_train/chosen': '-88.882', 'loss/train': '0.30723', 'examples_per_second': '4.412', 'grad_norm': '4.9375', 'counters/examples': 7808, 'counters/updates': 244}
skipping logging after 7840 examples to avoid logging too frequently
skipping logging after 7872 examples to avoid logging too frequently
skipping logging after 7904 examples to avoid logging too frequently
train stats after 7936 examples: {'rewards_train/chosen': '-0.58163', 'rewards_train/rejected': '-2.1879', 'rewards_train/accuracies': '0.84375', 'rewards_train/margins': '1.6065', 'logps_train/rejected': '-132.29', 'logps_train/chosen': '-98.765', 'loss/train': '0.35224', 'examples_per_second': '5.5052', 'grad_norm': '6.1562', 'counters/examples': 7936, 'counters/updates': 248}
Running evaluation after 7936 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<01:00,  1.94s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<01:00,  2.01s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:53,  1.83s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.84s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.51s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.55s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:15<00:32,  1.47s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.54s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:18<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.22s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.31s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.25s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.29s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.41s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
eval after 7936: {'rewards_eval/chosen': '-2.0654', 'rewards_eval/rejected': '-2.3029', 'rewards_eval/accuracies': '0.5625', 'rewards_eval/margins': '0.23753', 'logps_eval/rejected': '-145.6', 'logps_eval/chosen': '-140.01', 'loss/eval': '0.88144'}
skipping logging after 7968 examples to avoid logging too frequently
skipping logging after 8000 examples to avoid logging too frequently
skipping logging after 8032 examples to avoid logging too frequently
train stats after 8064 examples: {'rewards_train/chosen': '-0.56224', 'rewards_train/rejected': '-2.3714', 'rewards_train/accuracies': '0.89844', 'rewards_train/margins': '1.8085', 'logps_train/rejected': '-139.64', 'logps_train/chosen': '-104.47', 'loss/train': '0.30813', 'examples_per_second': '4.3768', 'grad_norm': '5.3438', 'counters/examples': 8064, 'counters/updates': 252}
skipping logging after 8096 examples to avoid logging too frequently
skipping logging after 8128 examples to avoid logging too frequently
skipping logging after 8160 examples to avoid logging too frequently
train stats after 8192 examples: {'rewards_train/chosen': '-0.56973', 'rewards_train/rejected': '-2.2616', 'rewards_train/accuracies': '0.82812', 'rewards_train/margins': '1.6923', 'logps_train/rejected': '-139.31', 'logps_train/chosen': '-99.614', 'loss/train': '0.32832', 'examples_per_second': '5.597', 'grad_norm': '6.4375', 'counters/examples': 8192, 'counters/updates': 256}
skipping logging after 8224 examples to avoid logging too frequently
skipping logging after 8256 examples to avoid logging too frequently
skipping logging after 8288 examples to avoid logging too frequently
train stats after 8320 examples: {'rewards_train/chosen': '-0.88511', 'rewards_train/rejected': '-2.5829', 'rewards_train/accuracies': '0.82812', 'rewards_train/margins': '1.6974', 'logps_train/rejected': '-143.77', 'logps_train/chosen': '-115.74', 'loss/train': '0.34384', 'examples_per_second': '4.4887', 'grad_norm': '6.4062', 'counters/examples': 8320, 'counters/updates': 260}
skipping logging after 8352 examples to avoid logging too frequently
skipping logging after 8384 examples to avoid logging too frequently
skipping logging after 8416 examples to avoid logging too frequently
train stats after 8448 examples: {'rewards_train/chosen': '-0.76612', 'rewards_train/rejected': '-2.2376', 'rewards_train/accuracies': '0.8125', 'rewards_train/margins': '1.4721', 'logps_train/rejected': '-137.51', 'logps_train/chosen': '-102.67', 'loss/train': '0.36987', 'examples_per_second': '5.3362', 'grad_norm': '6.9688', 'counters/examples': 8448, 'counters/updates': 264}
skipping logging after 8480 examples to avoid logging too frequently
skipping logging after 8512 examples to avoid logging too frequently
skipping logging after 8544 examples to avoid logging too frequently
train stats after 8576 examples: {'rewards_train/chosen': '-0.78825', 'rewards_train/rejected': '-2.5282', 'rewards_train/accuracies': '0.85938', 'rewards_train/margins': '1.7391', 'logps_train/rejected': '-147.31', 'logps_train/chosen': '-105.53', 'loss/train': '0.30399', 'examples_per_second': '5.4822', 'grad_norm': '5.2812', 'counters/examples': 8576, 'counters/updates': 268}
skipping logging after 8608 examples to avoid logging too frequently
skipping logging after 8640 examples to avoid logging too frequently
skipping logging after 8672 examples to avoid logging too frequently
train stats after 8704 examples: {'rewards_train/chosen': '-0.86253', 'rewards_train/rejected': '-2.5237', 'rewards_train/accuracies': '0.86719', 'rewards_train/margins': '1.6614', 'logps_train/rejected': '-129.41', 'logps_train/chosen': '-105.38', 'loss/train': '0.31207', 'examples_per_second': '5.0022', 'grad_norm': '5.9375', 'counters/examples': 8704, 'counters/updates': 272}
skipping logging after 8736 examples to avoid logging too frequently
skipping logging after 8768 examples to avoid logging too frequently
skipping logging after 8800 examples to avoid logging too frequently
train stats after 8832 examples: {'rewards_train/chosen': '-0.73839', 'rewards_train/rejected': '-2.6945', 'rewards_train/accuracies': '0.875', 'rewards_train/margins': '1.9562', 'logps_train/rejected': '-161.57', 'logps_train/chosen': '-112.52', 'loss/train': '0.31514', 'examples_per_second': '4.4099', 'grad_norm': '6.0625', 'counters/examples': 8832, 'counters/updates': 276}
skipping logging after 8864 examples to avoid logging too frequently
skipping logging after 8896 examples to avoid logging too frequently
skipping logging after 8928 examples to avoid logging too frequently
Running evaluation after 8928 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:24,  2.73s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:09,  2.33s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:58,  2.00s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:08<00:54,  1.95s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:09<00:42,  1.58s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:11<00:43,  1.67s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:12<00:37,  1.49s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.48s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.55s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.48s/it]Computing eval metrics:  41%|████      | 13/32 [00:21<00:27,  1.43s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.42s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.28s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.23s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:26<00:19,  1.32s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.32s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.25s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:33<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.25s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:37<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:39<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.44s/it]
eval after 8928: {'rewards_eval/chosen': '-2.321', 'rewards_eval/rejected': '-2.5942', 'rewards_eval/accuracies': '0.56055', 'rewards_eval/margins': '0.27319', 'logps_eval/rejected': '-148.51', 'logps_eval/chosen': '-142.56', 'loss/eval': '0.85471'}
train stats after 8960 examples: {'rewards_train/chosen': '-0.89864', 'rewards_train/rejected': '-2.5457', 'rewards_train/accuracies': '0.82031', 'rewards_train/margins': '1.647', 'logps_train/rejected': '-135.85', 'logps_train/chosen': '-96.546', 'loss/train': '0.36218', 'examples_per_second': '4.9532', 'grad_norm': '5.6875', 'counters/examples': 8960, 'counters/updates': 280}
skipping logging after 8992 examples to avoid logging too frequently
skipping logging after 9024 examples to avoid logging too frequently
skipping logging after 9056 examples to avoid logging too frequently
train stats after 9088 examples: {'rewards_train/chosen': '-0.51167', 'rewards_train/rejected': '-2.2418', 'rewards_train/accuracies': '0.85156', 'rewards_train/margins': '1.7299', 'logps_train/rejected': '-125.08', 'logps_train/chosen': '-97.634', 'loss/train': '0.30298', 'examples_per_second': '5.1639', 'grad_norm': '5.2188', 'counters/examples': 9088, 'counters/updates': 284}
skipping logging after 9120 examples to avoid logging too frequently
skipping logging after 9152 examples to avoid logging too frequently
skipping logging after 9184 examples to avoid logging too frequently
train stats after 9216 examples: {'rewards_train/chosen': '-0.84424', 'rewards_train/rejected': '-2.6193', 'rewards_train/accuracies': '0.82812', 'rewards_train/margins': '1.775', 'logps_train/rejected': '-150.87', 'logps_train/chosen': '-113.42', 'loss/train': '0.30777', 'examples_per_second': '5.4142', 'grad_norm': '6.5938', 'counters/examples': 9216, 'counters/updates': 288}
skipping logging after 9248 examples to avoid logging too frequently
skipping logging after 9280 examples to avoid logging too frequently
skipping logging after 9312 examples to avoid logging too frequently
train stats after 9344 examples: {'rewards_train/chosen': '-0.68702', 'rewards_train/rejected': '-2.6688', 'rewards_train/accuracies': '0.875', 'rewards_train/margins': '1.9824', 'logps_train/rejected': '-142.06', 'logps_train/chosen': '-100.5', 'loss/train': '0.29944', 'examples_per_second': '5.4475', 'grad_norm': '5.875', 'counters/examples': 9344, 'counters/updates': 292}
skipping logging after 9376 examples to avoid logging too frequently
skipping logging after 9408 examples to avoid logging too frequently
skipping logging after 9440 examples to avoid logging too frequently
train stats after 9472 examples: {'rewards_train/chosen': '-1.3882', 'rewards_train/rejected': '-3.264', 'rewards_train/accuracies': '0.80469', 'rewards_train/margins': '1.8761', 'logps_train/rejected': '-136.93', 'logps_train/chosen': '-97.777', 'loss/train': '0.33609', 'examples_per_second': '5.6708', 'grad_norm': '6.3438', 'counters/examples': 9472, 'counters/updates': 296}
skipping logging after 9504 examples to avoid logging too frequently
skipping logging after 9536 examples to avoid logging too frequently
skipping logging after 9568 examples to avoid logging too frequently
train stats after 9600 examples: {'rewards_train/chosen': '-0.94005', 'rewards_train/rejected': '-2.8888', 'rewards_train/accuracies': '0.85156', 'rewards_train/margins': '1.9497', 'logps_train/rejected': '-147.8', 'logps_train/chosen': '-114.73', 'loss/train': '0.32584', 'examples_per_second': '4.4477', 'grad_norm': '6.4375', 'counters/examples': 9600, 'counters/updates': 300}
skipping logging after 9632 examples to avoid logging too frequently
skipping logging after 9664 examples to avoid logging too frequently
skipping logging after 9696 examples to avoid logging too frequently
train stats after 9728 examples: {'rewards_train/chosen': '-0.98802', 'rewards_train/rejected': '-2.8113', 'rewards_train/accuracies': '0.82031', 'rewards_train/margins': '1.8235', 'logps_train/rejected': '-150.06', 'logps_train/chosen': '-112', 'loss/train': '0.30818', 'examples_per_second': '5.6967', 'grad_norm': '6.25', 'counters/examples': 9728, 'counters/updates': 304}
skipping logging after 9760 examples to avoid logging too frequently
skipping logging after 9792 examples to avoid logging too frequently
skipping logging after 9824 examples to avoid logging too frequently
train stats after 9856 examples: {'rewards_train/chosen': '-0.88366', 'rewards_train/rejected': '-2.6013', 'rewards_train/accuracies': '0.84375', 'rewards_train/margins': '1.7178', 'logps_train/rejected': '-134.84', 'logps_train/chosen': '-116.36', 'loss/train': '0.35878', 'examples_per_second': '4.863', 'grad_norm': '7', 'counters/examples': 9856, 'counters/updates': 308}
skipping logging after 9888 examples to avoid logging too frequently
skipping logging after 9920 examples to avoid logging too frequently
Running evaluation after 9920 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:17,  2.49s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:06,  2.23s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:56,  1.96s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:08<00:53,  1.92s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:42,  1.56s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.66s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.49s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.48s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.55s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.49s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.44s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.43s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.29s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.23s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.32s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.33s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.26s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:33<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.25s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:37<00:07,  1.29s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.41s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.44s/it]
eval after 9920: {'rewards_eval/chosen': '-2.1073', 'rewards_eval/rejected': '-2.3439', 'rewards_eval/accuracies': '0.56055', 'rewards_eval/margins': '0.2365', 'logps_eval/rejected': '-146.01', 'logps_eval/chosen': '-140.43', 'loss/eval': '0.84112'}
skipping logging after 9952 examples to avoid logging too frequently
train stats after 9984 examples: {'rewards_train/chosen': '-0.73008', 'rewards_train/rejected': '-2.2789', 'rewards_train/accuracies': '0.85156', 'rewards_train/margins': '1.5485', 'logps_train/rejected': '-132.51', 'logps_train/chosen': '-101.24', 'loss/train': '0.35183', 'examples_per_second': '5.6475', 'grad_norm': '6.2188', 'counters/examples': 9984, 'counters/updates': 312}
skipping logging after 10016 examples to avoid logging too frequently
skipping logging after 10048 examples to avoid logging too frequently
skipping logging after 10080 examples to avoid logging too frequently
train stats after 10112 examples: {'rewards_train/chosen': '-0.68455', 'rewards_train/rejected': '-2.3355', 'rewards_train/accuracies': '0.89844', 'rewards_train/margins': '1.6513', 'logps_train/rejected': '-131.85', 'logps_train/chosen': '-98.313', 'loss/train': '0.33282', 'examples_per_second': '5.1188', 'grad_norm': '5.75', 'counters/examples': 10112, 'counters/updates': 316}
skipping logging after 10144 examples to avoid logging too frequently
skipping logging after 10176 examples to avoid logging too frequently
skipping logging after 10208 examples to avoid logging too frequently
train stats after 10240 examples: {'rewards_train/chosen': '-0.74774', 'rewards_train/rejected': '-2.3671', 'rewards_train/accuracies': '0.80469', 'rewards_train/margins': '1.6186', 'logps_train/rejected': '-138.8', 'logps_train/chosen': '-120.37', 'loss/train': '0.35237', 'examples_per_second': '6.0556', 'grad_norm': '6.75', 'counters/examples': 10240, 'counters/updates': 320}
skipping logging after 10272 examples to avoid logging too frequently
skipping logging after 10304 examples to avoid logging too frequently
skipping logging after 10336 examples to avoid logging too frequently
train stats after 10368 examples: {'rewards_train/chosen': '-0.85831', 'rewards_train/rejected': '-2.5834', 'rewards_train/accuracies': '0.85156', 'rewards_train/margins': '1.7255', 'logps_train/rejected': '-135.96', 'logps_train/chosen': '-100.57', 'loss/train': '0.34828', 'examples_per_second': '5.1877', 'grad_norm': '6.6875', 'counters/examples': 10368, 'counters/updates': 324}
skipping logging after 10400 examples to avoid logging too frequently
skipping logging after 10432 examples to avoid logging too frequently
skipping logging after 10464 examples to avoid logging too frequently
train stats after 10496 examples: {'rewards_train/chosen': '-0.59068', 'rewards_train/rejected': '-2.6527', 'rewards_train/accuracies': '0.89062', 'rewards_train/margins': '2.0623', 'logps_train/rejected': '-143.88', 'logps_train/chosen': '-107.8', 'loss/train': '0.26507', 'examples_per_second': '4.6913', 'grad_norm': '5.25', 'counters/examples': 10496, 'counters/updates': 328}
skipping logging after 10528 examples to avoid logging too frequently
skipping logging after 10560 examples to avoid logging too frequently
skipping logging after 10592 examples to avoid logging too frequently
train stats after 10624 examples: {'rewards_train/chosen': '-1.0934', 'rewards_train/rejected': '-2.7785', 'rewards_train/accuracies': '0.80469', 'rewards_train/margins': '1.685', 'logps_train/rejected': '-131.59', 'logps_train/chosen': '-106.7', 'loss/train': '0.37497', 'examples_per_second': '5.5055', 'grad_norm': '7.2188', 'counters/examples': 10624, 'counters/updates': 332}
skipping logging after 10656 examples to avoid logging too frequently
skipping logging after 10688 examples to avoid logging too frequently
skipping logging after 10720 examples to avoid logging too frequently
train stats after 10752 examples: {'rewards_train/chosen': '-0.43438', 'rewards_train/rejected': '-2.2886', 'rewards_train/accuracies': '0.89844', 'rewards_train/margins': '1.8537', 'logps_train/rejected': '-144.29', 'logps_train/chosen': '-103.03', 'loss/train': '0.27566', 'examples_per_second': '4.9517', 'grad_norm': '5', 'counters/examples': 10752, 'counters/updates': 336}
skipping logging after 10784 examples to avoid logging too frequently
skipping logging after 10816 examples to avoid logging too frequently
skipping logging after 10848 examples to avoid logging too frequently
train stats after 10880 examples: {'rewards_train/chosen': '-0.86746', 'rewards_train/rejected': '-2.8091', 'rewards_train/accuracies': '0.875', 'rewards_train/margins': '1.9414', 'logps_train/rejected': '-143.24', 'logps_train/chosen': '-106.25', 'loss/train': '0.29254', 'examples_per_second': '4.9457', 'grad_norm': '6', 'counters/examples': 10880, 'counters/updates': 340}
skipping logging after 10912 examples to avoid logging too frequently
Running evaluation after 10912 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:29,  2.88s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:11,  2.39s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:59,  2.04s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:08<00:55,  1.97s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:09<00:43,  1.60s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:11<00:43,  1.69s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:12<00:37,  1.51s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:14<00:37,  1.57s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:36,  1.58s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.49s/it]Computing eval metrics:  41%|████      | 13/32 [00:21<00:27,  1.44s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.43s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:21,  1.29s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.23s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:26<00:19,  1.32s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.33s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.28s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:31<00:13,  1.26s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:32<00:11,  1.14s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:33<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:36<00:08,  1.25s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:37<00:07,  1.29s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:39<00:07,  1.46s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.41s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:45<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.45s/it]
eval after 10912: {'rewards_eval/chosen': '-2.7775', 'rewards_eval/rejected': '-3.0952', 'rewards_eval/accuracies': '0.56445', 'rewards_eval/margins': '0.31751', 'logps_eval/rejected': '-153.52', 'logps_eval/chosen': '-147.13', 'loss/eval': '0.94455'}
skipping logging after 10944 examples to avoid logging too frequently
skipping logging after 10976 examples to avoid logging too frequently
train stats after 11008 examples: {'rewards_train/chosen': '-0.93578', 'rewards_train/rejected': '-3.0742', 'rewards_train/accuracies': '0.85938', 'rewards_train/margins': '2.1385', 'logps_train/rejected': '-162.49', 'logps_train/chosen': '-112.51', 'loss/train': '0.26414', 'examples_per_second': '4.2392', 'grad_norm': '4.9375', 'counters/examples': 11008, 'counters/updates': 344}
skipping logging after 11040 examples to avoid logging too frequently
skipping logging after 11072 examples to avoid logging too frequently
skipping logging after 11104 examples to avoid logging too frequently
train stats after 11136 examples: {'rewards_train/chosen': '-1.0644', 'rewards_train/rejected': '-3.3196', 'rewards_train/accuracies': '0.85938', 'rewards_train/margins': '2.2551', 'logps_train/rejected': '-153.25', 'logps_train/chosen': '-110.44', 'loss/train': '0.28974', 'examples_per_second': '4.5122', 'grad_norm': '6.5', 'counters/examples': 11136, 'counters/updates': 348}
skipping logging after 11168 examples to avoid logging too frequently
skipping logging after 11200 examples to avoid logging too frequently
skipping logging after 11232 examples to avoid logging too frequently
train stats after 11264 examples: {'rewards_train/chosen': '-0.91113', 'rewards_train/rejected': '-2.7414', 'rewards_train/accuracies': '0.83594', 'rewards_train/margins': '1.8296', 'logps_train/rejected': '-127.41', 'logps_train/chosen': '-83.659', 'loss/train': '0.30204', 'examples_per_second': '5.6722', 'grad_norm': '5.6562', 'counters/examples': 11264, 'counters/updates': 352}
skipping logging after 11296 examples to avoid logging too frequently
skipping logging after 11328 examples to avoid logging too frequently
skipping logging after 11360 examples to avoid logging too frequently
train stats after 11392 examples: {'rewards_train/chosen': '-1.6563', 'rewards_train/rejected': '-3.4524', 'rewards_train/accuracies': '0.76562', 'rewards_train/margins': '1.7963', 'logps_train/rejected': '-164.37', 'logps_train/chosen': '-127.9', 'loss/train': '0.3877', 'examples_per_second': '4.7408', 'grad_norm': '11.125', 'counters/examples': 11392, 'counters/updates': 356}
skipping logging after 11424 examples to avoid logging too frequently
skipping logging after 11456 examples to avoid logging too frequently
skipping logging after 11488 examples to avoid logging too frequently
train stats after 11520 examples: {'rewards_train/chosen': '-0.42054', 'rewards_train/rejected': '-1.8197', 'rewards_train/accuracies': '0.83594', 'rewards_train/margins': '1.399', 'logps_train/rejected': '-130.74', 'logps_train/chosen': '-95.218', 'loss/train': '0.35038', 'examples_per_second': '5.0622', 'grad_norm': '5.5312', 'counters/examples': 11520, 'counters/updates': 360}
skipping logging after 11552 examples to avoid logging too frequently
skipping logging after 11584 examples to avoid logging too frequently
skipping logging after 11616 examples to avoid logging too frequently
train stats after 11648 examples: {'rewards_train/chosen': '-0.92581', 'rewards_train/rejected': '-2.4152', 'rewards_train/accuracies': '0.82812', 'rewards_train/margins': '1.489', 'logps_train/rejected': '-140.46', 'logps_train/chosen': '-100.57', 'loss/train': '0.35088', 'examples_per_second': '4.4095', 'grad_norm': '6.25', 'counters/examples': 11648, 'counters/updates': 364}
skipping logging after 11680 examples to avoid logging too frequently
skipping logging after 11712 examples to avoid logging too frequently
skipping logging after 11744 examples to avoid logging too frequently
train stats after 11776 examples: {'rewards_train/chosen': '-1.1416', 'rewards_train/rejected': '-2.8983', 'rewards_train/accuracies': '0.80469', 'rewards_train/margins': '1.7563', 'logps_train/rejected': '-149.04', 'logps_train/chosen': '-103.9', 'loss/train': '0.35643', 'examples_per_second': '5.1777', 'grad_norm': '6.5938', 'counters/examples': 11776, 'counters/updates': 368}
skipping logging after 11808 examples to avoid logging too frequently
skipping logging after 11840 examples to avoid logging too frequently
skipping logging after 11872 examples to avoid logging too frequently
train stats after 11904 examples: {'rewards_train/chosen': '-1.063', 'rewards_train/rejected': '-3.2841', 'rewards_train/accuracies': '0.875', 'rewards_train/margins': '2.2211', 'logps_train/rejected': '-167.81', 'logps_train/chosen': '-123.8', 'loss/train': '0.28707', 'examples_per_second': '4.8204', 'grad_norm': '7.5', 'counters/examples': 11904, 'counters/updates': 372}
Running evaluation after 11904 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:59,  1.93s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<01:00,  2.00s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:53,  1.83s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.85s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:40,  1.52s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.63s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.47s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.48s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.55s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.49s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.44s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.43s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.29s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.23s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.32s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.33s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.27s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.22s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.26s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.14s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.20s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.28s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.25s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.29s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.47s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.40s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.60s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.41s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.42s/it]
