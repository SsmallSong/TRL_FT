4
/home/wxt/.conda/envs/halos3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Making experiment directory /home/wxt/.cache/huggingface/hub/llama2_7b_dpo_halos_2
no FSDP port specified; using open port for FSDP: 52167
seed: 1
exp_name: llama2_7b_dpo_halos_2
datasets:
- hh
mode: train
debug: false
use_fsdp: true
fsdp_port: 52167
wandb:
  enabled: true
  entity: null
  project: archangel
cache_dir: /home/wxt/.cache/huggingface/hub
local_run_dir: /home/wxt/.cache/huggingface/hub/llama2_7b_dpo_halos_2
do_first_eval: true
minimum_log_interval_secs: 1.0
intermediate_checkpoints: false
trainer: DPOTrainer
lr: 1.0e-05
n_epochs: 1
n_examples: null
optimizer: RMSprop
warmup_steps: 150
eval_every: 4000
n_samples: 128
samples_dir: samples/
n_eval_examples: 512
saved_policy: /home/wxt/.cache/huggingface/hub/llama2_7b_dpo_halos_2/LATEST/policy.pt
top_p: 0.95
human_prefix: '

  <|user|>

  '
assistant_prefix: '

  <|assistant|>

  '
human_suffix: ''
assistant_suffix: ''
frac_unique_desirable: 1.0
frac_unique_undesirable: 1.0
model:
  name_or_path: daryl149/llama-2-7b-hf
  tokenizer_name_or_path: null
  load_from: /home/wxt/.cache/huggingface/hub/llama2_7b_sft_halos_2_3/LATEST/policy.pt
  block_name: LlamaDecoderLayer
  policy_dtype: bfloat16
  fsdp_policy_mp: null
  reference_dtype: bfloat16
  max_grad_norm: 10.0
  v_head_max_grad_norm: 0.1
  max_length: 1024
  max_prompt_length: 512
  activation_checkpointing: true
  batch_size: 16
  gradient_accumulation_steps: 4
  eval_batch_size: 16
  use_flash_attention: false
loss:
  name: dpo
  beta: 0.1
  trainer: DPOTrainer
  dataloader: PairedPreferenceDataLoader
  use_reference_model: true

================================================================================
Writing to design-agent-09:/home/wxt/.cache/huggingface/hub/llama2_7b_dpo_halos_2
================================================================================
building policy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.68s/it]
building reference model
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]
loading pre-trained weights at step 159968 from /home/wxt/.cache/huggingface/hub/llama2_7b_sft_halos_2_3/LATEST/policy.pt with metrics {}
loaded pre-trained weights
Loading tokenizer daryl149/llama-2-7b-hf
0 special tokens added
Loading HH dataset (train split) from Huggingface...
Processing HH:   0%|          | 0/160800 [00:00<?, ?it/s]Processing HH:   1%|          | 1484/160800 [00:00<00:10, 14836.76it/s]Processing HH:   2%|▏         | 2968/160800 [00:00<00:10, 14432.00it/s]Processing HH:   3%|▎         | 4506/160800 [00:00<00:10, 14857.33it/s]Processing HH:   4%|▎         | 6025/160800 [00:00<00:10, 14982.36it/s]Processing HH:   5%|▍         | 7524/160800 [00:00<00:10, 14962.71it/s]Processing HH:   6%|▌         | 9021/160800 [00:00<00:10, 14940.31it/s]Processing HH:   7%|▋         | 10530/160800 [00:00<00:10, 14988.66it/s]Processing HH:   7%|▋         | 12034/160800 [00:00<00:09, 15004.42it/s]Processing HH:   8%|▊         | 13567/160800 [00:00<00:09, 15105.82it/s]Processing HH:   9%|▉         | 15078/160800 [00:01<00:14, 9755.95it/s] Processing HH:  10%|█         | 16616/160800 [00:01<00:13, 10999.60it/s]Processing HH:  11%|█▏        | 18116/160800 [00:01<00:11, 11959.52it/s]Processing HH:  12%|█▏        | 19558/160800 [00:01<00:11, 12586.76it/s]Processing HH:  13%|█▎        | 21064/160800 [00:01<00:10, 13246.64it/s]Processing HH:  14%|█▍        | 22546/160800 [00:01<00:10, 13679.77it/s]Processing HH:  15%|█▍        | 24036/160800 [00:01<00:09, 14024.08it/s]Processing HH:  16%|█▌        | 25498/160800 [00:01<00:09, 14194.28it/s]Processing HH:  17%|█▋        | 27022/160800 [00:01<00:09, 14497.02it/s]Processing HH:  18%|█▊        | 28500/160800 [00:02<00:09, 14558.63it/s]Processing HH:  19%|█▊        | 29976/160800 [00:02<00:09, 14414.01it/s]Processing HH:  20%|█▉        | 31448/160800 [00:02<00:08, 14503.08it/s]Processing HH:  20%|██        | 32944/160800 [00:02<00:08, 14635.37it/s]Processing HH:  21%|██▏       | 34415/160800 [00:02<00:13, 9208.35it/s] Processing HH:  22%|██▏       | 35920/160800 [00:02<00:11, 10436.16it/s]Processing HH:  23%|██▎       | 37340/160800 [00:02<00:10, 11303.15it/s]Processing HH:  24%|██▍       | 38710/160800 [00:02<00:10, 11896.81it/s]Processing HH:  25%|██▍       | 40188/160800 [00:03<00:09, 12650.14it/s]Processing HH:  26%|██▌       | 41588/160800 [00:03<00:09, 13015.54it/s]Processing HH:  27%|██▋       | 43047/160800 [00:03<00:08, 13454.84it/s]Processing HH:  28%|██▊       | 44453/160800 [00:03<00:08, 13596.55it/s]Processing HH:  29%|██▊       | 45864/160800 [00:03<00:08, 13743.59it/s]Processing HH:  29%|██▉       | 47269/160800 [00:03<00:08, 13733.17it/s]Processing HH:  30%|███       | 48664/160800 [00:03<00:08, 13779.85it/s]Processing HH:  31%|███       | 50058/160800 [00:03<00:08, 13709.28it/s]Processing HH:  32%|███▏      | 51443/160800 [00:03<00:07, 13750.30it/s]Processing HH:  33%|███▎      | 52857/160800 [00:03<00:07, 13861.89it/s]Processing HH:  34%|███▍      | 54276/160800 [00:04<00:07, 13956.47it/s]Processing HH:  35%|███▍      | 55676/160800 [00:04<00:07, 13752.89it/s]Processing HH:  35%|███▌      | 57069/160800 [00:04<00:07, 13800.94it/s]Processing HH:  36%|███▋      | 58452/160800 [00:04<00:13, 7325.23it/s] Processing HH:  37%|███▋      | 59849/160800 [00:04<00:11, 8544.02it/s]Processing HH:  38%|███▊      | 61203/160800 [00:04<00:10, 9581.25it/s]Processing HH:  39%|███▉      | 62585/160800 [00:04<00:09, 10550.25it/s]Processing HH:  40%|███▉      | 63952/160800 [00:05<00:08, 11317.68it/s]Processing HH:  41%|████      | 65253/160800 [00:05<00:08, 11748.76it/s]Processing HH:  41%|████▏     | 66666/160800 [00:05<00:07, 12391.80it/s]Processing HH:  42%|████▏     | 68042/160800 [00:05<00:07, 12773.11it/s]Processing HH:  43%|████▎     | 69420/160800 [00:05<00:06, 13057.13it/s]Processing HH:  44%|████▍     | 70796/160800 [00:05<00:06, 13260.08it/s]Processing HH:  45%|████▍     | 72210/160800 [00:05<00:06, 13515.90it/s]Processing HH:  46%|████▌     | 73615/160800 [00:05<00:06, 13668.43it/s]Processing HH:  47%|████▋     | 75000/160800 [00:05<00:06, 13613.83it/s]Processing HH:  47%|████▋     | 76375/160800 [00:06<00:06, 13615.38it/s]Processing HH:  48%|████▊     | 77773/160800 [00:06<00:06, 13722.34it/s]Processing HH:  49%|████▉     | 79152/160800 [00:06<00:06, 13340.41it/s]Processing HH:  50%|█████     | 80545/160800 [00:06<00:05, 13510.30it/s]Processing HH:  51%|█████     | 81943/160800 [00:06<00:05, 13647.59it/s]Processing HH:  52%|█████▏    | 83347/160800 [00:06<00:05, 13762.88it/s]Processing HH:  53%|█████▎    | 84738/160800 [00:06<00:05, 13804.55it/s]Processing HH:  54%|█████▎    | 86139/160800 [00:06<00:05, 13863.77it/s]Processing HH:  54%|█████▍    | 87527/160800 [00:07<00:08, 8351.05it/s] Processing HH:  55%|█████▌    | 88629/160800 [00:07<00:08, 8249.82it/s]Processing HH:  56%|█████▌    | 89639/160800 [00:07<00:08, 8273.75it/s]Processing HH:  56%|█████▋    | 90597/160800 [00:07<00:08, 8258.80it/s]Processing HH:  57%|█████▋    | 91514/160800 [00:07<00:08, 8264.04it/s]Processing HH:  57%|█████▋    | 92404/160800 [00:07<00:08, 8360.82it/s]Processing HH:  58%|█████▊    | 93287/160800 [00:07<00:08, 8325.79it/s]Processing HH:  59%|█████▊    | 94152/160800 [00:07<00:07, 8334.19it/s]Processing HH:  59%|█████▉    | 95008/160800 [00:07<00:07, 8330.41it/s]Processing HH:  60%|█████▉    | 95857/160800 [00:08<00:07, 8253.38it/s]Processing HH:  60%|██████    | 96694/160800 [00:08<00:07, 8285.39it/s]Processing HH:  61%|██████    | 97531/160800 [00:08<00:07, 8295.34it/s]Processing HH:  61%|██████    | 98366/160800 [00:08<00:07, 8243.72it/s]Processing HH:  62%|██████▏   | 99195/160800 [00:08<00:07, 8178.33it/s]Processing HH:  62%|██████▏   | 100016/160800 [00:08<00:07, 8147.75it/s]Processing HH:  63%|██████▎   | 100833/160800 [00:08<00:07, 8124.75it/s]Processing HH:  63%|██████▎   | 101652/160800 [00:08<00:07, 8142.66it/s]Processing HH:  64%|██████▍   | 102518/160800 [00:08<00:07, 8293.73it/s]Processing HH:  64%|██████▍   | 103357/160800 [00:08<00:06, 8321.27it/s]Processing HH:  65%|██████▍   | 104196/160800 [00:09<00:06, 8340.35it/s]Processing HH:  65%|██████▌   | 105031/160800 [00:09<00:06, 8125.93it/s]Processing HH:  66%|██████▌   | 105887/160800 [00:09<00:06, 8249.38it/s]Processing HH:  66%|██████▋   | 106714/160800 [00:09<00:06, 8188.25it/s]Processing HH:  67%|██████▋   | 107534/160800 [00:09<00:06, 8155.54it/s]Processing HH:  67%|██████▋   | 108358/160800 [00:09<00:06, 8176.51it/s]Processing HH:  68%|██████▊   | 109584/160800 [00:09<00:05, 9388.21it/s]Processing HH:  69%|██████▉   | 110815/160800 [00:09<00:04, 10256.66it/s]Processing HH:  70%|██████▉   | 112035/160800 [00:09<00:04, 10830.41it/s]Processing HH:  70%|███████   | 113225/160800 [00:09<00:04, 11148.76it/s]Processing HH:  71%|███████   | 114409/160800 [00:10<00:04, 11351.56it/s]Processing HH:  72%|███████▏  | 115617/160800 [00:10<00:03, 11567.21it/s]Processing HH:  73%|███████▎  | 116836/160800 [00:10<00:03, 11751.18it/s]Processing HH:  73%|███████▎  | 118081/160800 [00:10<00:03, 11958.18it/s]Processing HH:  74%|███████▍  | 119295/160800 [00:10<00:03, 12007.27it/s]Processing HH:  75%|███████▍  | 120538/160800 [00:10<00:03, 12133.25it/s]Processing HH:  76%|███████▌  | 121770/160800 [00:10<00:03, 12188.16it/s]Processing HH:  76%|███████▋  | 122989/160800 [00:10<00:04, 7769.43it/s] Processing HH:  77%|███████▋  | 124184/160800 [00:11<00:04, 8662.72it/s]Processing HH:  78%|███████▊  | 125366/160800 [00:11<00:03, 9400.44it/s]Processing HH:  79%|███████▊  | 126558/160800 [00:11<00:03, 10031.62it/s]Processing HH:  79%|███████▉  | 127782/160800 [00:11<00:03, 10613.54it/s]Processing HH:  80%|████████  | 129038/160800 [00:11<00:02, 11141.69it/s]Processing HH:  81%|████████  | 130274/160800 [00:11<00:02, 11483.91it/s]Processing HH:  82%|████████▏ | 131515/160800 [00:11<00:02, 11748.44it/s]Processing HH:  83%|████████▎ | 132731/160800 [00:11<00:02, 11864.63it/s]Processing HH:  83%|████████▎ | 133959/160800 [00:11<00:02, 11984.32it/s]Processing HH:  84%|████████▍ | 135188/160800 [00:11<00:02, 12071.51it/s]Processing HH:  85%|████████▍ | 136408/160800 [00:12<00:02, 12102.47it/s]Processing HH:  86%|████████▌ | 137628/160800 [00:12<00:01, 12049.43it/s]Processing HH:  86%|████████▋ | 138840/160800 [00:12<00:01, 11917.92it/s]Processing HH:  87%|████████▋ | 140043/160800 [00:12<00:01, 11950.45it/s]Processing HH:  88%|████████▊ | 141242/160800 [00:12<00:01, 11946.93it/s]Processing HH:  89%|████████▊ | 142464/160800 [00:12<00:01, 12026.57it/s]Processing HH:  89%|████████▉ | 143701/160800 [00:12<00:01, 12126.68it/s]Processing HH:  90%|█████████ | 144915/160800 [00:12<00:01, 12115.98it/s]Processing HH:  91%|█████████ | 146139/160800 [00:12<00:01, 12152.90it/s]Processing HH:  92%|█████████▏| 147355/160800 [00:12<00:01, 12000.95it/s]Processing HH:  92%|█████████▏| 148579/160800 [00:13<00:01, 12070.42it/s]Processing HH:  93%|█████████▎| 149787/160800 [00:13<00:00, 11923.43it/s]Processing HH:  94%|█████████▍| 150981/160800 [00:13<00:00, 11870.82it/s]Processing HH:  95%|█████████▍| 152184/160800 [00:13<00:00, 11916.73it/s]Processing HH:  95%|█████████▌| 153377/160800 [00:13<00:00, 11875.48it/s]Processing HH:  96%|█████████▌| 154593/160800 [00:13<00:00, 11957.04it/s]Processing HH:  97%|█████████▋| 155794/160800 [00:13<00:00, 11968.72it/s]Processing HH:  98%|█████████▊| 157020/160800 [00:13<00:00, 12055.37it/s]Processing HH:  98%|█████████▊| 158226/160800 [00:13<00:00, 12016.18it/s]Processing HH:  99%|█████████▉| 159465/160800 [00:13<00:00, 12126.59it/s]Processing HH: 100%|█████████▉| 160680/160800 [00:14<00:00, 12129.81it/s]Processing HH: 100%|██████████| 160800/160800 [00:14<00:00, 11411.68it/s]
Loading HH dataset (test split) from Huggingface...
Processing HH:   0%|          | 0/8552 [00:00<?, ?it/s]Processing HH:  17%|█▋        | 1436/8552 [00:00<00:00, 14355.36it/s]Processing HH:  34%|███▎      | 2872/8552 [00:00<00:00, 14329.70it/s]Processing HH:  50%|█████     | 4305/8552 [00:00<00:00, 14108.82it/s]Processing HH:  67%|██████▋   | 5717/8552 [00:00<00:00, 11655.19it/s]Processing HH:  81%|████████  | 6934/8552 [00:00<00:00, 11568.15it/s]Processing HH:  95%|█████████▍| 8123/8552 [00:01<00:00, 4749.55it/s] Processing HH: 100%|██████████| 8552/8552 [00:01<00:00, 7262.63it/s]
starting 4 processes for FSDP training
setting RLIMIT_NOFILE soft limit to 1048576 from 1024
4
0 initializing distributed
Creating trainer on process 0 with world size 4
Finished 512 examples on test split
Loaded 32 eval batches of size 16
Sharding models...
Attempting to enable activation checkpointing...
Applying activation checkpointing wrapper to policy...
FSDP activation checkpointing enabled!
Loaded model on rank 0
Using RMSprop optimizer with learning rate 1e-05
Running evaluation after 0 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]/home/wxt/.conda/envs/halos3/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/wxt/.conda/envs/halos3/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/wxt/.conda/envs/halos3/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/wxt/.conda/envs/halos3/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Computing eval metrics:   3%|▎         | 1/32 [00:02<01:13,  2.36s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:04,  2.14s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.89s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.86s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.52s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.53s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:31,  1.45s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:31,  1.52s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.46s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:26,  1.41s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.40s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.21s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.30s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.31s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.24s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 0: {'rewards_eval/chosen': '0', 'rewards_eval/rejected': '0', 'rewards_eval/accuracies': '0', 'rewards_eval/margins': '0', 'logps_eval/rejected': '-147.66', 'logps_eval/chosen': '-144.92', 'loss/eval': '0.69141'}
skipping logging after 16 examples to avoid logging too frequently
skipping logging after 32 examples to avoid logging too frequently
skipping logging after 48 examples to avoid logging too frequently
train stats after 64 examples: {'rewards_train/chosen': '0', 'rewards_train/rejected': '0', 'rewards_train/accuracies': '0', 'rewards_train/margins': '0', 'logps_train/rejected': '-139.07', 'logps_train/chosen': '-44.217', 'loss/train': '0.69141', 'examples_per_second': '6.1593', 'grad_norm': '30', 'counters/examples': 64, 'counters/updates': 4}
skipping logging after 80 examples to avoid logging too frequently
skipping logging after 96 examples to avoid logging too frequently
skipping logging after 112 examples to avoid logging too frequently
train stats after 128 examples: {'rewards_train/chosen': '-0.0042536', 'rewards_train/rejected': '-0.0052786', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.001018', 'logps_train/rejected': '-128.19', 'logps_train/chosen': '-45.8', 'loss/train': '0.69446', 'examples_per_second': '4.7602', 'grad_norm': '30.875', 'counters/examples': 128, 'counters/updates': 8}
skipping logging after 144 examples to avoid logging too frequently
skipping logging after 160 examples to avoid logging too frequently
skipping logging after 176 examples to avoid logging too frequently
train stats after 192 examples: {'rewards_train/chosen': '0.0074526', 'rewards_train/rejected': '-0.015763', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.023227', 'logps_train/rejected': '-156.14', 'logps_train/chosen': '-43.075', 'loss/train': '0.68134', 'examples_per_second': '3.7196', 'grad_norm': '33', 'counters/examples': 192, 'counters/updates': 12}
skipping logging after 208 examples to avoid logging too frequently
skipping logging after 224 examples to avoid logging too frequently
skipping logging after 240 examples to avoid logging too frequently
train stats after 256 examples: {'rewards_train/chosen': '0.0053277', 'rewards_train/rejected': '0.0058496', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '-0.00052238', 'logps_train/rejected': '-131.87', 'logps_train/chosen': '-39.911', 'loss/train': '0.69263', 'examples_per_second': '5.9965', 'grad_norm': '30.75', 'counters/examples': 256, 'counters/updates': 16}
skipping logging after 272 examples to avoid logging too frequently
skipping logging after 288 examples to avoid logging too frequently
skipping logging after 304 examples to avoid logging too frequently
train stats after 320 examples: {'rewards_train/chosen': '0.0058386', 'rewards_train/rejected': '-0.011779', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.0176', 'logps_train/rejected': '-149.92', 'logps_train/chosen': '-34.727', 'loss/train': '0.68719', 'examples_per_second': '5.2752', 'grad_norm': '31.75', 'counters/examples': 320, 'counters/updates': 20}
skipping logging after 336 examples to avoid logging too frequently
skipping logging after 352 examples to avoid logging too frequently
skipping logging after 368 examples to avoid logging too frequently
train stats after 384 examples: {'rewards_train/chosen': '0.017979', 'rewards_train/rejected': '-0.022092', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.040102', 'logps_train/rejected': '-146.41', 'logps_train/chosen': '-34.571', 'loss/train': '0.67242', 'examples_per_second': '6.2627', 'grad_norm': '31', 'counters/examples': 384, 'counters/updates': 24}
skipping logging after 400 examples to avoid logging too frequently
skipping logging after 416 examples to avoid logging too frequently
skipping logging after 432 examples to avoid logging too frequently
train stats after 448 examples: {'rewards_train/chosen': '0.0094156', 'rewards_train/rejected': '-0.017982', 'rewards_train/accuracies': '0.73438', 'rewards_train/margins': '0.027415', 'logps_train/rejected': '-114.86', 'logps_train/chosen': '-26.756', 'loss/train': '0.68121', 'examples_per_second': '5.3898', 'grad_norm': '25.625', 'counters/examples': 448, 'counters/updates': 28}
skipping logging after 464 examples to avoid logging too frequently
skipping logging after 480 examples to avoid logging too frequently
skipping logging after 496 examples to avoid logging too frequently
train stats after 512 examples: {'rewards_train/chosen': '0.0082018', 'rewards_train/rejected': '-0.035342', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.043544', 'logps_train/rejected': '-109.55', 'logps_train/chosen': '-35.459', 'loss/train': '0.67444', 'examples_per_second': '5.7896', 'grad_norm': '24.375', 'counters/examples': 512, 'counters/updates': 32}
skipping logging after 528 examples to avoid logging too frequently
skipping logging after 544 examples to avoid logging too frequently
skipping logging after 560 examples to avoid logging too frequently
train stats after 576 examples: {'rewards_train/chosen': '0.030716', 'rewards_train/rejected': '-0.055039', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '0.085735', 'logps_train/rejected': '-120.31', 'logps_train/chosen': '-40.451', 'loss/train': '0.65253', 'examples_per_second': '4.9132', 'grad_norm': '27.125', 'counters/examples': 576, 'counters/updates': 36}
skipping logging after 592 examples to avoid logging too frequently
skipping logging after 608 examples to avoid logging too frequently
skipping logging after 624 examples to avoid logging too frequently
train stats after 640 examples: {'rewards_train/chosen': '0.021042', 'rewards_train/rejected': '-0.079561', 'rewards_train/accuracies': '0.8125', 'rewards_train/margins': '0.10063', 'logps_train/rejected': '-140.75', 'logps_train/chosen': '-37.561', 'loss/train': '0.6438', 'examples_per_second': '4.7458', 'grad_norm': '26.625', 'counters/examples': 640, 'counters/updates': 40}
skipping logging after 656 examples to avoid logging too frequently
skipping logging after 672 examples to avoid logging too frequently
skipping logging after 688 examples to avoid logging too frequently
train stats after 704 examples: {'rewards_train/chosen': '0.052602', 'rewards_train/rejected': '-0.099818', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '0.15242', 'logps_train/rejected': '-148.52', 'logps_train/chosen': '-47.873', 'loss/train': '0.62073', 'examples_per_second': '4.941', 'grad_norm': '29.625', 'counters/examples': 704, 'counters/updates': 44}
skipping logging after 720 examples to avoid logging too frequently
skipping logging after 736 examples to avoid logging too frequently
skipping logging after 752 examples to avoid logging too frequently
train stats after 768 examples: {'rewards_train/chosen': '0.052826', 'rewards_train/rejected': '-0.11997', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '0.17275', 'logps_train/rejected': '-122.23', 'logps_train/chosen': '-43.385', 'loss/train': '0.61145', 'examples_per_second': '5.3574', 'grad_norm': '25.25', 'counters/examples': 768, 'counters/updates': 48}
skipping logging after 784 examples to avoid logging too frequently
skipping logging after 800 examples to avoid logging too frequently
skipping logging after 816 examples to avoid logging too frequently
train stats after 832 examples: {'rewards_train/chosen': '0.052069', 'rewards_train/rejected': '-0.12616', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '0.17833', 'logps_train/rejected': '-114.33', 'logps_train/chosen': '-42.113', 'loss/train': '0.61548', 'examples_per_second': '6.4415', 'grad_norm': '24.375', 'counters/examples': 832, 'counters/updates': 52}
skipping logging after 848 examples to avoid logging too frequently
skipping logging after 864 examples to avoid logging too frequently
skipping logging after 880 examples to avoid logging too frequently
train stats after 896 examples: {'rewards_train/chosen': '0.057083', 'rewards_train/rejected': '-0.15545', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '0.21253', 'logps_train/rejected': '-137.91', 'logps_train/chosen': '-33.467', 'loss/train': '0.59717', 'examples_per_second': '3.6778', 'grad_norm': '25.375', 'counters/examples': 896, 'counters/updates': 56}
skipping logging after 912 examples to avoid logging too frequently
skipping logging after 928 examples to avoid logging too frequently
skipping logging after 944 examples to avoid logging too frequently
train stats after 960 examples: {'rewards_train/chosen': '0.064645', 'rewards_train/rejected': '-0.20045', 'rewards_train/accuracies': '1', 'rewards_train/margins': '0.26509', 'logps_train/rejected': '-152.47', 'logps_train/chosen': '-38.572', 'loss/train': '0.57941', 'examples_per_second': '5.8172', 'grad_norm': '25.625', 'counters/examples': 960, 'counters/updates': 60}
skipping logging after 976 examples to avoid logging too frequently
skipping logging after 992 examples to avoid logging too frequently
skipping logging after 1008 examples to avoid logging too frequently
train stats after 1024 examples: {'rewards_train/chosen': '0.08511', 'rewards_train/rejected': '-0.18772', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '0.27268', 'logps_train/rejected': '-122.25', 'logps_train/chosen': '-43.985', 'loss/train': '0.57114', 'examples_per_second': '4.8444', 'grad_norm': '21.5', 'counters/examples': 1024, 'counters/updates': 64}
skipping logging after 1040 examples to avoid logging too frequently
skipping logging after 1056 examples to avoid logging too frequently
skipping logging after 1072 examples to avoid logging too frequently
train stats after 1088 examples: {'rewards_train/chosen': '0.081467', 'rewards_train/rejected': '-0.20914', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '0.29062', 'logps_train/rejected': '-114', 'logps_train/chosen': '-37.088', 'loss/train': '0.565', 'examples_per_second': '5.8952', 'grad_norm': '20.125', 'counters/examples': 1088, 'counters/updates': 68}
skipping logging after 1104 examples to avoid logging too frequently
skipping logging after 1120 examples to avoid logging too frequently
skipping logging after 1136 examples to avoid logging too frequently
train stats after 1152 examples: {'rewards_train/chosen': '0.10909', 'rewards_train/rejected': '-0.26365', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '0.37254', 'logps_train/rejected': '-122.12', 'logps_train/chosen': '-39.639', 'loss/train': '0.53955', 'examples_per_second': '5.9215', 'grad_norm': '19.5', 'counters/examples': 1152, 'counters/updates': 72}
skipping logging after 1168 examples to avoid logging too frequently
skipping logging after 1184 examples to avoid logging too frequently
skipping logging after 1200 examples to avoid logging too frequently
train stats after 1216 examples: {'rewards_train/chosen': '0.11325', 'rewards_train/rejected': '-0.31848', 'rewards_train/accuracies': '1', 'rewards_train/margins': '0.43175', 'logps_train/rejected': '-143.84', 'logps_train/chosen': '-37.472', 'loss/train': '0.51547', 'examples_per_second': '4.5074', 'grad_norm': '21', 'counters/examples': 1216, 'counters/updates': 76}
skipping logging after 1232 examples to avoid logging too frequently
skipping logging after 1248 examples to avoid logging too frequently
skipping logging after 1264 examples to avoid logging too frequently
train stats after 1280 examples: {'rewards_train/chosen': '0.14504', 'rewards_train/rejected': '-0.39376', 'rewards_train/accuracies': '1', 'rewards_train/margins': '0.53873', 'logps_train/rejected': '-152.82', 'logps_train/chosen': '-39.885', 'loss/train': '0.48047', 'examples_per_second': '4.4434', 'grad_norm': '20.125', 'counters/examples': 1280, 'counters/updates': 80}
skipping logging after 1296 examples to avoid logging too frequently
skipping logging after 1312 examples to avoid logging too frequently
skipping logging after 1328 examples to avoid logging too frequently
train stats after 1344 examples: {'rewards_train/chosen': '0.13726', 'rewards_train/rejected': '-0.41318', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '0.55042', 'logps_train/rejected': '-145.74', 'logps_train/chosen': '-37.414', 'loss/train': '0.47894', 'examples_per_second': '6.0491', 'grad_norm': '20.25', 'counters/examples': 1344, 'counters/updates': 84}
skipping logging after 1360 examples to avoid logging too frequently
skipping logging after 1376 examples to avoid logging too frequently
skipping logging after 1392 examples to avoid logging too frequently
train stats after 1408 examples: {'rewards_train/chosen': '0.14689', 'rewards_train/rejected': '-0.50485', 'rewards_train/accuracies': '1', 'rewards_train/margins': '0.65145', 'logps_train/rejected': '-168.57', 'logps_train/chosen': '-37.949', 'loss/train': '0.45234', 'examples_per_second': '4.6295', 'grad_norm': '20', 'counters/examples': 1408, 'counters/updates': 88}
skipping logging after 1424 examples to avoid logging too frequently
skipping logging after 1440 examples to avoid logging too frequently
skipping logging after 1456 examples to avoid logging too frequently
train stats after 1472 examples: {'rewards_train/chosen': '0.16626', 'rewards_train/rejected': '-0.53938', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '0.70582', 'logps_train/rejected': '-143', 'logps_train/chosen': '-35.948', 'loss/train': '0.43353', 'examples_per_second': '3.9217', 'grad_norm': '17.625', 'counters/examples': 1472, 'counters/updates': 92}
skipping logging after 1488 examples to avoid logging too frequently
skipping logging after 1504 examples to avoid logging too frequently
skipping logging after 1520 examples to avoid logging too frequently
train stats after 1536 examples: {'rewards_train/chosen': '0.16135', 'rewards_train/rejected': '-0.5937', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '0.7553', 'logps_train/rejected': '-159.05', 'logps_train/chosen': '-35.421', 'loss/train': '0.42294', 'examples_per_second': '4.8955', 'grad_norm': '18.375', 'counters/examples': 1536, 'counters/updates': 96}
skipping logging after 1552 examples to avoid logging too frequently
skipping logging after 1568 examples to avoid logging too frequently
skipping logging after 1584 examples to avoid logging too frequently
train stats after 1600 examples: {'rewards_train/chosen': '0.21023', 'rewards_train/rejected': '-0.60562', 'rewards_train/accuracies': '1', 'rewards_train/margins': '0.81515', 'logps_train/rejected': '-139.27', 'logps_train/chosen': '-32.406', 'loss/train': '0.40936', 'examples_per_second': '5.4467', 'grad_norm': '15.25', 'counters/examples': 1600, 'counters/updates': 100}
skipping logging after 1616 examples to avoid logging too frequently
skipping logging after 1632 examples to avoid logging too frequently
skipping logging after 1648 examples to avoid logging too frequently
train stats after 1664 examples: {'rewards_train/chosen': '0.23613', 'rewards_train/rejected': '-0.78855', 'rewards_train/accuracies': '1', 'rewards_train/margins': '1.0246', 'logps_train/rejected': '-166.51', 'logps_train/chosen': '-39.989', 'loss/train': '0.36551', 'examples_per_second': '5.723', 'grad_norm': '15.438', 'counters/examples': 1664, 'counters/updates': 104}
skipping logging after 1680 examples to avoid logging too frequently
skipping logging after 1696 examples to avoid logging too frequently
skipping logging after 1712 examples to avoid logging too frequently
train stats after 1728 examples: {'rewards_train/chosen': '0.22556', 'rewards_train/rejected': '-0.85432', 'rewards_train/accuracies': '1', 'rewards_train/margins': '1.0798', 'logps_train/rejected': '-177.37', 'logps_train/chosen': '-37.766', 'loss/train': '0.35152', 'examples_per_second': '6.5795', 'grad_norm': '16', 'counters/examples': 1728, 'counters/updates': 108}
skipping logging after 1744 examples to avoid logging too frequently
skipping logging after 1760 examples to avoid logging too frequently
skipping logging after 1776 examples to avoid logging too frequently
train stats after 1792 examples: {'rewards_train/chosen': '0.18338', 'rewards_train/rejected': '-0.74494', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '0.92832', 'logps_train/rejected': '-139.57', 'logps_train/chosen': '-33.863', 'loss/train': '0.41227', 'examples_per_second': '4.3565', 'grad_norm': '13', 'counters/examples': 1792, 'counters/updates': 112}
skipping logging after 1808 examples to avoid logging too frequently
skipping logging after 1824 examples to avoid logging too frequently
skipping logging after 1840 examples to avoid logging too frequently
train stats after 1856 examples: {'rewards_train/chosen': '0.27229', 'rewards_train/rejected': '-0.75456', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '1.027', 'logps_train/rejected': '-114.91', 'logps_train/chosen': '-36.968', 'loss/train': '0.36606', 'examples_per_second': '4.9643', 'grad_norm': '13.25', 'counters/examples': 1856, 'counters/updates': 116}
skipping logging after 1872 examples to avoid logging too frequently
skipping logging after 1888 examples to avoid logging too frequently
skipping logging after 1904 examples to avoid logging too frequently
train stats after 1920 examples: {'rewards_train/chosen': '0.21878', 'rewards_train/rejected': '-0.77257', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '0.99109', 'logps_train/rejected': '-117.5', 'logps_train/chosen': '-30.199', 'loss/train': '0.37163', 'examples_per_second': '4.9984', 'grad_norm': '12.938', 'counters/examples': 1920, 'counters/updates': 120}
skipping logging after 1936 examples to avoid logging too frequently
skipping logging after 1952 examples to avoid logging too frequently
skipping logging after 1968 examples to avoid logging too frequently
train stats after 1984 examples: {'rewards_train/chosen': '0.29107', 'rewards_train/rejected': '-1.1802', 'rewards_train/accuracies': '1', 'rewards_train/margins': '1.4708', 'logps_train/rejected': '-170.67', 'logps_train/chosen': '-35.73', 'loss/train': '0.3014', 'examples_per_second': '4.9956', 'grad_norm': '11.375', 'counters/examples': 1984, 'counters/updates': 124}
skipping logging after 2000 examples to avoid logging too frequently
skipping logging after 2016 examples to avoid logging too frequently
skipping logging after 2032 examples to avoid logging too frequently
train stats after 2048 examples: {'rewards_train/chosen': '0.25902', 'rewards_train/rejected': '-0.96529', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '1.2243', 'logps_train/rejected': '-138.18', 'logps_train/chosen': '-35.499', 'loss/train': '0.33237', 'examples_per_second': '5.04', 'grad_norm': '12.125', 'counters/examples': 2048, 'counters/updates': 128}
skipping logging after 2064 examples to avoid logging too frequently
skipping logging after 2080 examples to avoid logging too frequently
skipping logging after 2096 examples to avoid logging too frequently
train stats after 2112 examples: {'rewards_train/chosen': '0.34972', 'rewards_train/rejected': '-1.1443', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '1.4939', 'logps_train/rejected': '-143.75', 'logps_train/chosen': '-43.353', 'loss/train': '0.29067', 'examples_per_second': '5.0509', 'grad_norm': '10.875', 'counters/examples': 2112, 'counters/updates': 132}
skipping logging after 2128 examples to avoid logging too frequently
skipping logging after 2144 examples to avoid logging too frequently
skipping logging after 2160 examples to avoid logging too frequently
train stats after 2176 examples: {'rewards_train/chosen': '0.23955', 'rewards_train/rejected': '-1.1419', 'rewards_train/accuracies': '1', 'rewards_train/margins': '1.3819', 'logps_train/rejected': '-131.26', 'logps_train/chosen': '-28.773', 'loss/train': '0.34721', 'examples_per_second': '5.8711', 'grad_norm': '10.188', 'counters/examples': 2176, 'counters/updates': 136}
skipping logging after 2192 examples to avoid logging too frequently
skipping logging after 2208 examples to avoid logging too frequently
skipping logging after 2224 examples to avoid logging too frequently
train stats after 2240 examples: {'rewards_train/chosen': '0.32823', 'rewards_train/rejected': '-1.2927', 'rewards_train/accuracies': '1', 'rewards_train/margins': '1.6213', 'logps_train/rejected': '-145.85', 'logps_train/chosen': '-33.442', 'loss/train': '0.26501', 'examples_per_second': '5.9711', 'grad_norm': '11.062', 'counters/examples': 2240, 'counters/updates': 140}
skipping logging after 2256 examples to avoid logging too frequently
skipping logging after 2272 examples to avoid logging too frequently
skipping logging after 2288 examples to avoid logging too frequently
train stats after 2304 examples: {'rewards_train/chosen': '0.34989', 'rewards_train/rejected': '-1.6493', 'rewards_train/accuracies': '1', 'rewards_train/margins': '1.999', 'logps_train/rejected': '-173.72', 'logps_train/chosen': '-31.734', 'loss/train': '0.2453', 'examples_per_second': '4.3971', 'grad_norm': '9.4375', 'counters/examples': 2304, 'counters/updates': 144}
skipping logging after 2320 examples to avoid logging too frequently
skipping logging after 2336 examples to avoid logging too frequently
skipping logging after 2352 examples to avoid logging too frequently
train stats after 2368 examples: {'rewards_train/chosen': '0.33212', 'rewards_train/rejected': '-1.3073', 'rewards_train/accuracies': '1', 'rewards_train/margins': '1.6391', 'logps_train/rejected': '-125.95', 'logps_train/chosen': '-32.641', 'loss/train': '0.27018', 'examples_per_second': '5.6643', 'grad_norm': '10.25', 'counters/examples': 2368, 'counters/updates': 148}
skipping logging after 2384 examples to avoid logging too frequently
skipping logging after 2400 examples to avoid logging too frequently
skipping logging after 2416 examples to avoid logging too frequently
train stats after 2432 examples: {'rewards_train/chosen': '0.37399', 'rewards_train/rejected': '-1.581', 'rewards_train/accuracies': '1', 'rewards_train/margins': '1.9543', 'logps_train/rejected': '-147.62', 'logps_train/chosen': '-35.096', 'loss/train': '0.21855', 'examples_per_second': '5.3836', 'grad_norm': '9.25', 'counters/examples': 2432, 'counters/updates': 152}
skipping logging after 2448 examples to avoid logging too frequently
skipping logging after 2464 examples to avoid logging too frequently
skipping logging after 2480 examples to avoid logging too frequently
train stats after 2496 examples: {'rewards_train/chosen': '0.29948', 'rewards_train/rejected': '-1.7204', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '2.0203', 'logps_train/rejected': '-158.36', 'logps_train/chosen': '-37.555', 'loss/train': '0.2354', 'examples_per_second': '6.8376', 'grad_norm': '9.125', 'counters/examples': 2496, 'counters/updates': 156}
skipping logging after 2512 examples to avoid logging too frequently
skipping logging after 2528 examples to avoid logging too frequently
skipping logging after 2544 examples to avoid logging too frequently
train stats after 2560 examples: {'rewards_train/chosen': '0.37893', 'rewards_train/rejected': '-2.1202', 'rewards_train/accuracies': '1', 'rewards_train/margins': '2.4996', 'logps_train/rejected': '-175.48', 'logps_train/chosen': '-31.269', 'loss/train': '0.20633', 'examples_per_second': '4.8576', 'grad_norm': '7.6562', 'counters/examples': 2560, 'counters/updates': 160}
skipping logging after 2576 examples to avoid logging too frequently
skipping logging after 2592 examples to avoid logging too frequently
skipping logging after 2608 examples to avoid logging too frequently
train stats after 2624 examples: {'rewards_train/chosen': '0.46689', 'rewards_train/rejected': '-1.9815', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '2.4497', 'logps_train/rejected': '-163.59', 'logps_train/chosen': '-41.178', 'loss/train': '0.21424', 'examples_per_second': '4.5052', 'grad_norm': '9', 'counters/examples': 2624, 'counters/updates': 164}
skipping logging after 2640 examples to avoid logging too frequently
skipping logging after 2656 examples to avoid logging too frequently
skipping logging after 2672 examples to avoid logging too frequently
train stats after 2688 examples: {'rewards_train/chosen': '0.35334', 'rewards_train/rejected': '-1.7136', 'rewards_train/accuracies': '1', 'rewards_train/margins': '2.067', 'logps_train/rejected': '-133.75', 'logps_train/chosen': '-37.673', 'loss/train': '0.24341', 'examples_per_second': '5.6617', 'grad_norm': '8.0625', 'counters/examples': 2688, 'counters/updates': 168}
skipping logging after 2704 examples to avoid logging too frequently
skipping logging after 2720 examples to avoid logging too frequently
skipping logging after 2736 examples to avoid logging too frequently
train stats after 2752 examples: {'rewards_train/chosen': '0.10791', 'rewards_train/rejected': '-1.7203', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '1.8284', 'logps_train/rejected': '-121.28', 'logps_train/chosen': '-30.546', 'loss/train': '0.27646', 'examples_per_second': '5.5835', 'grad_norm': '15.75', 'counters/examples': 2752, 'counters/updates': 172}
skipping logging after 2768 examples to avoid logging too frequently
skipping logging after 2784 examples to avoid logging too frequently
skipping logging after 2800 examples to avoid logging too frequently
train stats after 2816 examples: {'rewards_train/chosen': '0.25561', 'rewards_train/rejected': '-2.0792', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '2.335', 'logps_train/rejected': '-148.69', 'logps_train/chosen': '-28.146', 'loss/train': '0.23127', 'examples_per_second': '5.5966', 'grad_norm': '7.625', 'counters/examples': 2816, 'counters/updates': 176}
skipping logging after 2832 examples to avoid logging too frequently
skipping logging after 2848 examples to avoid logging too frequently
skipping logging after 2864 examples to avoid logging too frequently
train stats after 2880 examples: {'rewards_train/chosen': '0.3496', 'rewards_train/rejected': '-1.9054', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '2.2553', 'logps_train/rejected': '-139.25', 'logps_train/chosen': '-35.928', 'loss/train': '0.21493', 'examples_per_second': '4.9995', 'grad_norm': '8.1875', 'counters/examples': 2880, 'counters/updates': 180}
skipping logging after 2896 examples to avoid logging too frequently
skipping logging after 2912 examples to avoid logging too frequently
skipping logging after 2928 examples to avoid logging too frequently
train stats after 2944 examples: {'rewards_train/chosen': '0.3322', 'rewards_train/rejected': '-2.1652', 'rewards_train/accuracies': '1', 'rewards_train/margins': '2.497', 'logps_train/rejected': '-148.62', 'logps_train/chosen': '-33.374', 'loss/train': '0.21721', 'examples_per_second': '5.8435', 'grad_norm': '7.0938', 'counters/examples': 2944, 'counters/updates': 184}
skipping logging after 2960 examples to avoid logging too frequently
skipping logging after 2976 examples to avoid logging too frequently
skipping logging after 2992 examples to avoid logging too frequently
train stats after 3008 examples: {'rewards_train/chosen': '0.3094', 'rewards_train/rejected': '-2.0145', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '2.3244', 'logps_train/rejected': '-129.85', 'logps_train/chosen': '-29.428', 'loss/train': '0.22725', 'examples_per_second': '4.68', 'grad_norm': '8.125', 'counters/examples': 3008, 'counters/updates': 188}
skipping logging after 3024 examples to avoid logging too frequently
skipping logging after 3040 examples to avoid logging too frequently
skipping logging after 3056 examples to avoid logging too frequently
train stats after 3072 examples: {'rewards_train/chosen': '0.42778', 'rewards_train/rejected': '-2.8661', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '3.2932', 'logps_train/rejected': '-201.03', 'logps_train/chosen': '-41.686', 'loss/train': '0.13855', 'examples_per_second': '5.172', 'grad_norm': '6.25', 'counters/examples': 3072, 'counters/updates': 192}
skipping logging after 3088 examples to avoid logging too frequently
skipping logging after 3104 examples to avoid logging too frequently
skipping logging after 3120 examples to avoid logging too frequently
train stats after 3136 examples: {'rewards_train/chosen': '0.48455', 'rewards_train/rejected': '-2.6647', 'rewards_train/accuracies': '1', 'rewards_train/margins': '3.1498', 'logps_train/rejected': '-180.29', 'logps_train/chosen': '-39.123', 'loss/train': '0.16762', 'examples_per_second': '5.1757', 'grad_norm': '6.4375', 'counters/examples': 3136, 'counters/updates': 196}
skipping logging after 3152 examples to avoid logging too frequently
skipping logging after 3168 examples to avoid logging too frequently
skipping logging after 3184 examples to avoid logging too frequently
train stats after 3200 examples: {'rewards_train/chosen': '0.44407', 'rewards_train/rejected': '-3.0699', 'rewards_train/accuracies': '1', 'rewards_train/margins': '3.5143', 'logps_train/rejected': '-211.04', 'logps_train/chosen': '-38.997', 'loss/train': '0.12984', 'examples_per_second': '4.6834', 'grad_norm': '6.6562', 'counters/examples': 3200, 'counters/updates': 200}
skipping logging after 3216 examples to avoid logging too frequently
skipping logging after 3232 examples to avoid logging too frequently
skipping logging after 3248 examples to avoid logging too frequently
train stats after 3264 examples: {'rewards_train/chosen': '0.36774', 'rewards_train/rejected': '-2.3716', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '2.7404', 'logps_train/rejected': '-147.82', 'logps_train/chosen': '-39.577', 'loss/train': '0.19198', 'examples_per_second': '5.6022', 'grad_norm': '8.25', 'counters/examples': 3264, 'counters/updates': 204}
skipping logging after 3280 examples to avoid logging too frequently
skipping logging after 3296 examples to avoid logging too frequently
skipping logging after 3312 examples to avoid logging too frequently
train stats after 3328 examples: {'rewards_train/chosen': '0.21314', 'rewards_train/rejected': '-3.5173', 'rewards_train/accuracies': '1', 'rewards_train/margins': '3.7306', 'logps_train/rejected': '-208.92', 'logps_train/chosen': '-36.058', 'loss/train': '0.16955', 'examples_per_second': '5.226', 'grad_norm': '9.5', 'counters/examples': 3328, 'counters/updates': 208}
skipping logging after 3344 examples to avoid logging too frequently
skipping logging after 3360 examples to avoid logging too frequently
skipping logging after 3376 examples to avoid logging too frequently
train stats after 3392 examples: {'rewards_train/chosen': '0.35324', 'rewards_train/rejected': '-2.6507', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '3.0043', 'logps_train/rejected': '-150.93', 'logps_train/chosen': '-43.749', 'loss/train': '0.20007', 'examples_per_second': '4.9361', 'grad_norm': '9.125', 'counters/examples': 3392, 'counters/updates': 212}
skipping logging after 3408 examples to avoid logging too frequently
skipping logging after 3424 examples to avoid logging too frequently
skipping logging after 3440 examples to avoid logging too frequently
train stats after 3456 examples: {'rewards_train/chosen': '0.25379', 'rewards_train/rejected': '-2.6866', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '2.9409', 'logps_train/rejected': '-152.94', 'logps_train/chosen': '-32.335', 'loss/train': '0.19515', 'examples_per_second': '4.7792', 'grad_norm': '7.2188', 'counters/examples': 3456, 'counters/updates': 216}
skipping logging after 3472 examples to avoid logging too frequently
skipping logging after 3488 examples to avoid logging too frequently
skipping logging after 3504 examples to avoid logging too frequently
train stats after 3520 examples: {'rewards_train/chosen': '0.14599', 'rewards_train/rejected': '-3.2357', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '3.3814', 'logps_train/rejected': '-178.78', 'logps_train/chosen': '-41.474', 'loss/train': '0.20113', 'examples_per_second': '5.3875', 'grad_norm': '9.375', 'counters/examples': 3520, 'counters/updates': 220}
skipping logging after 3536 examples to avoid logging too frequently
skipping logging after 3552 examples to avoid logging too frequently
skipping logging after 3568 examples to avoid logging too frequently
train stats after 3584 examples: {'rewards_train/chosen': '0.42216', 'rewards_train/rejected': '-3.5775', 'rewards_train/accuracies': '1', 'rewards_train/margins': '3.9997', 'logps_train/rejected': '-198.94', 'logps_train/chosen': '-36.347', 'loss/train': '0.12865', 'examples_per_second': '4.6272', 'grad_norm': '5.9688', 'counters/examples': 3584, 'counters/updates': 224}
skipping logging after 3600 examples to avoid logging too frequently
skipping logging after 3616 examples to avoid logging too frequently
skipping logging after 3632 examples to avoid logging too frequently
train stats after 3648 examples: {'rewards_train/chosen': '0.44294', 'rewards_train/rejected': '-3.0738', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '3.5165', 'logps_train/rejected': '-154.33', 'logps_train/chosen': '-42.189', 'loss/train': '0.14108', 'examples_per_second': '6.2975', 'grad_norm': '5.9062', 'counters/examples': 3648, 'counters/updates': 228}
skipping logging after 3664 examples to avoid logging too frequently
skipping logging after 3680 examples to avoid logging too frequently
skipping logging after 3696 examples to avoid logging too frequently
train stats after 3712 examples: {'rewards_train/chosen': '0.45728', 'rewards_train/rejected': '-3.1792', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '3.6354', 'logps_train/rejected': '-158.92', 'logps_train/chosen': '-33.958', 'loss/train': '0.12423', 'examples_per_second': '5.2318', 'grad_norm': '5.875', 'counters/examples': 3712, 'counters/updates': 232}
skipping logging after 3728 examples to avoid logging too frequently
skipping logging after 3744 examples to avoid logging too frequently
skipping logging after 3760 examples to avoid logging too frequently
train stats after 3776 examples: {'rewards_train/chosen': '0.36168', 'rewards_train/rejected': '-3.4434', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '3.8036', 'logps_train/rejected': '-176.84', 'logps_train/chosen': '-34.776', 'loss/train': '0.15707', 'examples_per_second': '4.8975', 'grad_norm': '5.9688', 'counters/examples': 3776, 'counters/updates': 236}
skipping logging after 3792 examples to avoid logging too frequently
skipping logging after 3808 examples to avoid logging too frequently
skipping logging after 3824 examples to avoid logging too frequently
train stats after 3840 examples: {'rewards_train/chosen': '0.28629', 'rewards_train/rejected': '-3.361', 'rewards_train/accuracies': '1', 'rewards_train/margins': '3.6467', 'logps_train/rejected': '-157.86', 'logps_train/chosen': '-39.799', 'loss/train': '0.13803', 'examples_per_second': '5.5555', 'grad_norm': '6.5938', 'counters/examples': 3840, 'counters/updates': 240}
skipping logging after 3856 examples to avoid logging too frequently
skipping logging after 3872 examples to avoid logging too frequently
skipping logging after 3888 examples to avoid logging too frequently
train stats after 3904 examples: {'rewards_train/chosen': '0.34319', 'rewards_train/rejected': '-3.4996', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '3.8431', 'logps_train/rejected': '-167.93', 'logps_train/chosen': '-40.073', 'loss/train': '0.11975', 'examples_per_second': '5.8151', 'grad_norm': '4.8125', 'counters/examples': 3904, 'counters/updates': 244}
skipping logging after 3920 examples to avoid logging too frequently
skipping logging after 3936 examples to avoid logging too frequently
skipping logging after 3952 examples to avoid logging too frequently
train stats after 3968 examples: {'rewards_train/chosen': '0.26325', 'rewards_train/rejected': '-3.8285', 'rewards_train/accuracies': '1', 'rewards_train/margins': '4.0909', 'logps_train/rejected': '-170.88', 'logps_train/chosen': '-34.616', 'loss/train': '0.10568', 'examples_per_second': '4.6083', 'grad_norm': '5.4688', 'counters/examples': 3968, 'counters/updates': 248}
skipping logging after 3984 examples to avoid logging too frequently
skipping logging after 4000 examples to avoid logging too frequently
Running evaluation after 4000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:10,  2.26s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:04,  2.15s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:55,  1.91s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.90s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.55s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.66s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.50s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.57s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:36,  1.57s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.50s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.57s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:30,  1.51s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.46s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:26,  1.45s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:22,  1.31s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:20,  1.25s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:20,  1.34s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.35s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:14,  1.28s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:33<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.30s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.27s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:37<00:07,  1.31s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:39<00:07,  1.49s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.42s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.62s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.43s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.42s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.41s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.45s/it]
eval after 4000: {'rewards_eval/chosen': '-3.912', 'rewards_eval/rejected': '-3.9723', 'rewards_eval/accuracies': '0.50977', 'rewards_eval/margins': '0.060241', 'logps_eval/rejected': '-187.39', 'logps_eval/chosen': '-184.03', 'loss/eval': '1.5485'}
skipping logging after 4016 examples to avoid logging too frequently
train stats after 4032 examples: {'rewards_train/chosen': '0.28424', 'rewards_train/rejected': '-3.5873', 'rewards_train/accuracies': '1', 'rewards_train/margins': '3.8719', 'logps_train/rejected': '-171.88', 'logps_train/chosen': '-43.423', 'loss/train': '0.14239', 'examples_per_second': '4.6854', 'grad_norm': '7.9688', 'counters/examples': 4032, 'counters/updates': 252}
skipping logging after 4048 examples to avoid logging too frequently
skipping logging after 4064 examples to avoid logging too frequently
skipping logging after 4080 examples to avoid logging too frequently
train stats after 4096 examples: {'rewards_train/chosen': '0.24419', 'rewards_train/rejected': '-3.7622', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '4.0053', 'logps_train/rejected': '-174.13', 'logps_train/chosen': '-34.535', 'loss/train': '0.15039', 'examples_per_second': '4.5078', 'grad_norm': '5.8125', 'counters/examples': 4096, 'counters/updates': 256}
skipping logging after 4112 examples to avoid logging too frequently
skipping logging after 4128 examples to avoid logging too frequently
skipping logging after 4144 examples to avoid logging too frequently
train stats after 4160 examples: {'rewards_train/chosen': '0.22711', 'rewards_train/rejected': '-3.6728', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '3.9018', 'logps_train/rejected': '-168.41', 'logps_train/chosen': '-37.133', 'loss/train': '0.15056', 'examples_per_second': '5.0641', 'grad_norm': '6.0312', 'counters/examples': 4160, 'counters/updates': 260}
skipping logging after 4176 examples to avoid logging too frequently
skipping logging after 4192 examples to avoid logging too frequently
skipping logging after 4208 examples to avoid logging too frequently
train stats after 4224 examples: {'rewards_train/chosen': '0.14789', 'rewards_train/rejected': '-3.9585', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '4.1066', 'logps_train/rejected': '-167.82', 'logps_train/chosen': '-40.303', 'loss/train': '0.16028', 'examples_per_second': '4.9192', 'grad_norm': '9.3125', 'counters/examples': 4224, 'counters/updates': 264}
skipping logging after 4240 examples to avoid logging too frequently
skipping logging after 4256 examples to avoid logging too frequently
skipping logging after 4272 examples to avoid logging too frequently
train stats after 4288 examples: {'rewards_train/chosen': '0.40104', 'rewards_train/rejected': '-4.1429', 'rewards_train/accuracies': '1', 'rewards_train/margins': '4.5418', 'logps_train/rejected': '-197.29', 'logps_train/chosen': '-46.818', 'loss/train': '0.10954', 'examples_per_second': '5.6691', 'grad_norm': '6.0312', 'counters/examples': 4288, 'counters/updates': 268}
skipping logging after 4304 examples to avoid logging too frequently
skipping logging after 4320 examples to avoid logging too frequently
skipping logging after 4336 examples to avoid logging too frequently
train stats after 4352 examples: {'rewards_train/chosen': '0.31034', 'rewards_train/rejected': '-3.4073', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '3.7164', 'logps_train/rejected': '-152.14', 'logps_train/chosen': '-33.931', 'loss/train': '0.14873', 'examples_per_second': '5.644', 'grad_norm': '5.4062', 'counters/examples': 4352, 'counters/updates': 272}
skipping logging after 4368 examples to avoid logging too frequently
skipping logging after 4384 examples to avoid logging too frequently
skipping logging after 4400 examples to avoid logging too frequently
train stats after 4416 examples: {'rewards_train/chosen': '0.36105', 'rewards_train/rejected': '-3.9017', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '4.2634', 'logps_train/rejected': '-181.36', 'logps_train/chosen': '-39.404', 'loss/train': '0.12656', 'examples_per_second': '4.8461', 'grad_norm': '6.0938', 'counters/examples': 4416, 'counters/updates': 276}
skipping logging after 4432 examples to avoid logging too frequently
skipping logging after 4448 examples to avoid logging too frequently
skipping logging after 4464 examples to avoid logging too frequently
train stats after 4480 examples: {'rewards_train/chosen': '0.25246', 'rewards_train/rejected': '-4.599', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '4.8515', 'logps_train/rejected': '-178.78', 'logps_train/chosen': '-43.473', 'loss/train': '0.117', 'examples_per_second': '5.5842', 'grad_norm': '6.5938', 'counters/examples': 4480, 'counters/updates': 280}
skipping logging after 4496 examples to avoid logging too frequently
skipping logging after 4512 examples to avoid logging too frequently
skipping logging after 4528 examples to avoid logging too frequently
train stats after 4544 examples: {'rewards_train/chosen': '0.20508', 'rewards_train/rejected': '-4.3539', 'rewards_train/accuracies': '1', 'rewards_train/margins': '4.5604', 'logps_train/rejected': '-169.71', 'logps_train/chosen': '-36.376', 'loss/train': '0.14739', 'examples_per_second': '5.4997', 'grad_norm': '8.0625', 'counters/examples': 4544, 'counters/updates': 284}
skipping logging after 4560 examples to avoid logging too frequently
skipping logging after 4576 examples to avoid logging too frequently
skipping logging after 4592 examples to avoid logging too frequently
train stats after 4608 examples: {'rewards_train/chosen': '0.17557', 'rewards_train/rejected': '-4.1005', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '4.2761', 'logps_train/rejected': '-168.76', 'logps_train/chosen': '-32.309', 'loss/train': '0.14256', 'examples_per_second': '5.789', 'grad_norm': '6.4375', 'counters/examples': 4608, 'counters/updates': 288}
skipping logging after 4624 examples to avoid logging too frequently
skipping logging after 4640 examples to avoid logging too frequently
skipping logging after 4656 examples to avoid logging too frequently
train stats after 4672 examples: {'rewards_train/chosen': '0.27451', 'rewards_train/rejected': '-4.2602', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '4.536', 'logps_train/rejected': '-168.45', 'logps_train/chosen': '-43.321', 'loss/train': '0.11616', 'examples_per_second': '3.7818', 'grad_norm': '5.2812', 'counters/examples': 4672, 'counters/updates': 292}
skipping logging after 4688 examples to avoid logging too frequently
skipping logging after 4704 examples to avoid logging too frequently
skipping logging after 4720 examples to avoid logging too frequently
train stats after 4736 examples: {'rewards_train/chosen': '0.27241', 'rewards_train/rejected': '-4.8047', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '5.0753', 'logps_train/rejected': '-196.57', 'logps_train/chosen': '-41.893', 'loss/train': '0.11794', 'examples_per_second': '4.8663', 'grad_norm': '7.1562', 'counters/examples': 4736, 'counters/updates': 296}
skipping logging after 4752 examples to avoid logging too frequently
skipping logging after 4768 examples to avoid logging too frequently
skipping logging after 4784 examples to avoid logging too frequently
train stats after 4800 examples: {'rewards_train/chosen': '0.14929', 'rewards_train/rejected': '-4.3173', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '4.4682', 'logps_train/rejected': '-170.44', 'logps_train/chosen': '-39.179', 'loss/train': '0.18277', 'examples_per_second': '4.6956', 'grad_norm': '15', 'counters/examples': 4800, 'counters/updates': 300}
skipping logging after 4816 examples to avoid logging too frequently
skipping logging after 4832 examples to avoid logging too frequently
skipping logging after 4848 examples to avoid logging too frequently
train stats after 4864 examples: {'rewards_train/chosen': '0.21153', 'rewards_train/rejected': '-4.8398', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '5.0533', 'logps_train/rejected': '-190.77', 'logps_train/chosen': '-43.866', 'loss/train': '0.11182', 'examples_per_second': '5.408', 'grad_norm': '6.5938', 'counters/examples': 4864, 'counters/updates': 304}
skipping logging after 4880 examples to avoid logging too frequently
skipping logging after 4896 examples to avoid logging too frequently
skipping logging after 4912 examples to avoid logging too frequently
train stats after 4928 examples: {'rewards_train/chosen': '0.072138', 'rewards_train/rejected': '-4.6151', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '4.6872', 'logps_train/rejected': '-182.85', 'logps_train/chosen': '-40.96', 'loss/train': '0.11191', 'examples_per_second': '5.3129', 'grad_norm': '8.0625', 'counters/examples': 4928, 'counters/updates': 308}
skipping logging after 4944 examples to avoid logging too frequently
skipping logging after 4960 examples to avoid logging too frequently
skipping logging after 4976 examples to avoid logging too frequently
train stats after 4992 examples: {'rewards_train/chosen': '0.10041', 'rewards_train/rejected': '-4.7687', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '4.8673', 'logps_train/rejected': '-177.85', 'logps_train/chosen': '-39.321', 'loss/train': '0.13061', 'examples_per_second': '4.8696', 'grad_norm': '10.688', 'counters/examples': 4992, 'counters/updates': 312}
skipping logging after 5008 examples to avoid logging too frequently
skipping logging after 5024 examples to avoid logging too frequently
skipping logging after 5040 examples to avoid logging too frequently
train stats after 5056 examples: {'rewards_train/chosen': '0.10634', 'rewards_train/rejected': '-4.8327', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '4.9392', 'logps_train/rejected': '-183.57', 'logps_train/chosen': '-33.643', 'loss/train': '0.10578', 'examples_per_second': '4.8588', 'grad_norm': '6.25', 'counters/examples': 5056, 'counters/updates': 316}
skipping logging after 5072 examples to avoid logging too frequently
skipping logging after 5088 examples to avoid logging too frequently
skipping logging after 5104 examples to avoid logging too frequently
train stats after 5120 examples: {'rewards_train/chosen': '0.21666', 'rewards_train/rejected': '-4.9035', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '5.1211', 'logps_train/rejected': '-197.03', 'logps_train/chosen': '-43.915', 'loss/train': '0.11681', 'examples_per_second': '5.1502', 'grad_norm': '9.1875', 'counters/examples': 5120, 'counters/updates': 320}
skipping logging after 5136 examples to avoid logging too frequently
skipping logging after 5152 examples to avoid logging too frequently
skipping logging after 5168 examples to avoid logging too frequently
train stats after 5184 examples: {'rewards_train/chosen': '0.03977', 'rewards_train/rejected': '-4.8622', 'rewards_train/accuracies': '1', 'rewards_train/margins': '4.9019', 'logps_train/rejected': '-184.05', 'logps_train/chosen': '-43.57', 'loss/train': '0.1601', 'examples_per_second': '5.3177', 'grad_norm': '11.75', 'counters/examples': 5184, 'counters/updates': 324}
skipping logging after 5200 examples to avoid logging too frequently
skipping logging after 5216 examples to avoid logging too frequently
skipping logging after 5232 examples to avoid logging too frequently
train stats after 5248 examples: {'rewards_train/chosen': '0.083802', 'rewards_train/rejected': '-4.5182', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '4.6014', 'logps_train/rejected': '-152.68', 'logps_train/chosen': '-41.674', 'loss/train': '0.10212', 'examples_per_second': '6.9838', 'grad_norm': '5.75', 'counters/examples': 5248, 'counters/updates': 328}
skipping logging after 5264 examples to avoid logging too frequently
skipping logging after 5280 examples to avoid logging too frequently
skipping logging after 5296 examples to avoid logging too frequently
train stats after 5312 examples: {'rewards_train/chosen': '0.086168', 'rewards_train/rejected': '-4.037', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '4.1232', 'logps_train/rejected': '-149.56', 'logps_train/chosen': '-45.217', 'loss/train': '0.15152', 'examples_per_second': '5.6219', 'grad_norm': '10.938', 'counters/examples': 5312, 'counters/updates': 332}
skipping logging after 5328 examples to avoid logging too frequently
skipping logging after 5344 examples to avoid logging too frequently
skipping logging after 5360 examples to avoid logging too frequently
train stats after 5376 examples: {'rewards_train/chosen': '0.17299', 'rewards_train/rejected': '-5.4266', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '5.601', 'logps_train/rejected': '-204.28', 'logps_train/chosen': '-44.191', 'loss/train': '0.073163', 'examples_per_second': '5.4765', 'grad_norm': '5.3125', 'counters/examples': 5376, 'counters/updates': 336}
skipping logging after 5392 examples to avoid logging too frequently
skipping logging after 5408 examples to avoid logging too frequently
skipping logging after 5424 examples to avoid logging too frequently
train stats after 5440 examples: {'rewards_train/chosen': '-0.07645', 'rewards_train/rejected': '-5.0635', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '4.9869', 'logps_train/rejected': '-178.95', 'logps_train/chosen': '-39.832', 'loss/train': '0.12009', 'examples_per_second': '4.2022', 'grad_norm': '6.4375', 'counters/examples': 5440, 'counters/updates': 340}
skipping logging after 5456 examples to avoid logging too frequently
skipping logging after 5472 examples to avoid logging too frequently
skipping logging after 5488 examples to avoid logging too frequently
train stats after 5504 examples: {'rewards_train/chosen': '-0.23896', 'rewards_train/rejected': '-4.941', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '4.7006', 'logps_train/rejected': '-165.99', 'logps_train/chosen': '-40.744', 'loss/train': '0.10612', 'examples_per_second': '5.3021', 'grad_norm': '8.5', 'counters/examples': 5504, 'counters/updates': 344}
skipping logging after 5520 examples to avoid logging too frequently
skipping logging after 5536 examples to avoid logging too frequently
skipping logging after 5552 examples to avoid logging too frequently
train stats after 5568 examples: {'rewards_train/chosen': '-0.046161', 'rewards_train/rejected': '-5.0182', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '4.9706', 'logps_train/rejected': '-160.84', 'logps_train/chosen': '-46.004', 'loss/train': '0.12935', 'examples_per_second': '4.7529', 'grad_norm': '11.25', 'counters/examples': 5568, 'counters/updates': 348}
skipping logging after 5584 examples to avoid logging too frequently
skipping logging after 5600 examples to avoid logging too frequently
skipping logging after 5616 examples to avoid logging too frequently
train stats after 5632 examples: {'rewards_train/chosen': '-0.27693', 'rewards_train/rejected': '-5.7205', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '5.4442', 'logps_train/rejected': '-190.99', 'logps_train/chosen': '-39.794', 'loss/train': '0.12392', 'examples_per_second': '5.6486', 'grad_norm': '7.9688', 'counters/examples': 5632, 'counters/updates': 352}
skipping logging after 5648 examples to avoid logging too frequently
skipping logging after 5664 examples to avoid logging too frequently
skipping logging after 5680 examples to avoid logging too frequently
train stats after 5696 examples: {'rewards_train/chosen': '-0.038074', 'rewards_train/rejected': '-5.684', 'rewards_train/accuracies': '1', 'rewards_train/margins': '5.6458', 'logps_train/rejected': '-200.7', 'logps_train/chosen': '-46.015', 'loss/train': '0.085242', 'examples_per_second': '5.3498', 'grad_norm': '5', 'counters/examples': 5696, 'counters/updates': 356}
skipping logging after 5712 examples to avoid logging too frequently
skipping logging after 5728 examples to avoid logging too frequently
skipping logging after 5744 examples to avoid logging too frequently
train stats after 5760 examples: {'rewards_train/chosen': '-0.27868', 'rewards_train/rejected': '-6.6365', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.3578', 'logps_train/rejected': '-234.65', 'logps_train/chosen': '-45.367', 'loss/train': '0.15686', 'examples_per_second': '5.0946', 'grad_norm': '11.938', 'counters/examples': 5760, 'counters/updates': 360}
skipping logging after 5776 examples to avoid logging too frequently
skipping logging after 5792 examples to avoid logging too frequently
skipping logging after 5808 examples to avoid logging too frequently
train stats after 5824 examples: {'rewards_train/chosen': '-0.060495', 'rewards_train/rejected': '-5.4743', 'rewards_train/accuracies': '1', 'rewards_train/margins': '5.4156', 'logps_train/rejected': '-189.72', 'logps_train/chosen': '-35.623', 'loss/train': '0.070773', 'examples_per_second': '5.1922', 'grad_norm': '4.75', 'counters/examples': 5824, 'counters/updates': 364}
skipping logging after 5840 examples to avoid logging too frequently
skipping logging after 5856 examples to avoid logging too frequently
skipping logging after 5872 examples to avoid logging too frequently
train stats after 5888 examples: {'rewards_train/chosen': '-0.26619', 'rewards_train/rejected': '-5.3335', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '5.0657', 'logps_train/rejected': '-188.93', 'logps_train/chosen': '-36.231', 'loss/train': '0.090544', 'examples_per_second': '5.7397', 'grad_norm': '6.4688', 'counters/examples': 5888, 'counters/updates': 368}
skipping logging after 5904 examples to avoid logging too frequently
skipping logging after 5920 examples to avoid logging too frequently
skipping logging after 5936 examples to avoid logging too frequently
train stats after 5952 examples: {'rewards_train/chosen': '0.092615', 'rewards_train/rejected': '-6.2231', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.3151', 'logps_train/rejected': '-212.43', 'logps_train/chosen': '-45.375', 'loss/train': '0.09968', 'examples_per_second': '4.9352', 'grad_norm': '8.25', 'counters/examples': 5952, 'counters/updates': 372}
skipping logging after 5968 examples to avoid logging too frequently
skipping logging after 5984 examples to avoid logging too frequently
skipping logging after 6000 examples to avoid logging too frequently
train stats after 6016 examples: {'rewards_train/chosen': '-0.087413', 'rewards_train/rejected': '-6.0782', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '5.9924', 'logps_train/rejected': '-218.16', 'logps_train/chosen': '-44.422', 'loss/train': '0.082403', 'examples_per_second': '4.9665', 'grad_norm': '6.4688', 'counters/examples': 6016, 'counters/updates': 376}
skipping logging after 6032 examples to avoid logging too frequently
skipping logging after 6048 examples to avoid logging too frequently
skipping logging after 6064 examples to avoid logging too frequently
train stats after 6080 examples: {'rewards_train/chosen': '-0.51575', 'rewards_train/rejected': '-4.9618', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '4.4452', 'logps_train/rejected': '-154.64', 'logps_train/chosen': '-41.835', 'loss/train': '0.22409', 'examples_per_second': '6.9244', 'grad_norm': '16.875', 'counters/examples': 6080, 'counters/updates': 380}
skipping logging after 6096 examples to avoid logging too frequently
skipping logging after 6112 examples to avoid logging too frequently
skipping logging after 6128 examples to avoid logging too frequently
train stats after 6144 examples: {'rewards_train/chosen': '-0.16876', 'rewards_train/rejected': '-5.7353', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '5.5665', 'logps_train/rejected': '-205.28', 'logps_train/chosen': '-45.597', 'loss/train': '0.1243', 'examples_per_second': '4.5729', 'grad_norm': '8.8125', 'counters/examples': 6144, 'counters/updates': 384}
skipping logging after 6160 examples to avoid logging too frequently
skipping logging after 6176 examples to avoid logging too frequently
skipping logging after 6192 examples to avoid logging too frequently
train stats after 6208 examples: {'rewards_train/chosen': '-0.1773', 'rewards_train/rejected': '-5.6403', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '5.4617', 'logps_train/rejected': '-195.18', 'logps_train/chosen': '-47.846', 'loss/train': '0.099391', 'examples_per_second': '5.3842', 'grad_norm': '5.5625', 'counters/examples': 6208, 'counters/updates': 388}
skipping logging after 6224 examples to avoid logging too frequently
skipping logging after 6240 examples to avoid logging too frequently
skipping logging after 6256 examples to avoid logging too frequently
train stats after 6272 examples: {'rewards_train/chosen': '-0.097704', 'rewards_train/rejected': '-5.1681', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '5.0712', 'logps_train/rejected': '-159.71', 'logps_train/chosen': '-49.327', 'loss/train': '0.11388', 'examples_per_second': '5.342', 'grad_norm': '8.6875', 'counters/examples': 6272, 'counters/updates': 392}
skipping logging after 6288 examples to avoid logging too frequently
skipping logging after 6304 examples to avoid logging too frequently
skipping logging after 6320 examples to avoid logging too frequently
train stats after 6336 examples: {'rewards_train/chosen': '-0.35936', 'rewards_train/rejected': '-6.2449', 'rewards_train/accuracies': '1', 'rewards_train/margins': '5.8871', 'logps_train/rejected': '-200.74', 'logps_train/chosen': '-41.005', 'loss/train': '0.062202', 'examples_per_second': '4.7886', 'grad_norm': '5.2812', 'counters/examples': 6336, 'counters/updates': 396}
skipping logging after 6352 examples to avoid logging too frequently
skipping logging after 6368 examples to avoid logging too frequently
skipping logging after 6384 examples to avoid logging too frequently
train stats after 6400 examples: {'rewards_train/chosen': '-0.44247', 'rewards_train/rejected': '-5.8337', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '5.3906', 'logps_train/rejected': '-183.67', 'logps_train/chosen': '-39.875', 'loss/train': '0.12035', 'examples_per_second': '5.3118', 'grad_norm': '6.9688', 'counters/examples': 6400, 'counters/updates': 400}
skipping logging after 6416 examples to avoid logging too frequently
skipping logging after 6432 examples to avoid logging too frequently
skipping logging after 6448 examples to avoid logging too frequently
train stats after 6464 examples: {'rewards_train/chosen': '-0.5513', 'rewards_train/rejected': '-5.3566', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '4.8066', 'logps_train/rejected': '-162.25', 'logps_train/chosen': '-39.925', 'loss/train': '0.13146', 'examples_per_second': '5.3801', 'grad_norm': '11', 'counters/examples': 6464, 'counters/updates': 404}
skipping logging after 6480 examples to avoid logging too frequently
skipping logging after 6496 examples to avoid logging too frequently
skipping logging after 6512 examples to avoid logging too frequently
train stats after 6528 examples: {'rewards_train/chosen': '-0.3197', 'rewards_train/rejected': '-7.0417', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.7207', 'logps_train/rejected': '-227.35', 'logps_train/chosen': '-48.296', 'loss/train': '0.063393', 'examples_per_second': '4.9578', 'grad_norm': '5.8125', 'counters/examples': 6528, 'counters/updates': 408}
skipping logging after 6544 examples to avoid logging too frequently
skipping logging after 6560 examples to avoid logging too frequently
skipping logging after 6576 examples to avoid logging too frequently
train stats after 6592 examples: {'rewards_train/chosen': '-0.34748', 'rewards_train/rejected': '-5.9966', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '5.6494', 'logps_train/rejected': '-186.89', 'logps_train/chosen': '-39.704', 'loss/train': '0.067492', 'examples_per_second': '5.117', 'grad_norm': '5.875', 'counters/examples': 6592, 'counters/updates': 412}
skipping logging after 6608 examples to avoid logging too frequently
skipping logging after 6624 examples to avoid logging too frequently
skipping logging after 6640 examples to avoid logging too frequently
train stats after 6656 examples: {'rewards_train/chosen': '-0.45848', 'rewards_train/rejected': '-6.8866', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.4285', 'logps_train/rejected': '-212.76', 'logps_train/chosen': '-61.661', 'loss/train': '0.099318', 'examples_per_second': '5.3984', 'grad_norm': '8.75', 'counters/examples': 6656, 'counters/updates': 416}
skipping logging after 6672 examples to avoid logging too frequently
skipping logging after 6688 examples to avoid logging too frequently
skipping logging after 6704 examples to avoid logging too frequently
train stats after 6720 examples: {'rewards_train/chosen': '-0.29233', 'rewards_train/rejected': '-6.7937', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.5024', 'logps_train/rejected': '-199.34', 'logps_train/chosen': '-49.894', 'loss/train': '0.038236', 'examples_per_second': '5.499', 'grad_norm': '4.3438', 'counters/examples': 6720, 'counters/updates': 420}
skipping logging after 6736 examples to avoid logging too frequently
skipping logging after 6752 examples to avoid logging too frequently
skipping logging after 6768 examples to avoid logging too frequently
train stats after 6784 examples: {'rewards_train/chosen': '-0.40501', 'rewards_train/rejected': '-8.4058', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.0016', 'logps_train/rejected': '-260.19', 'logps_train/chosen': '-51.893', 'loss/train': '0.049052', 'examples_per_second': '3.5234', 'grad_norm': '4.5625', 'counters/examples': 6784, 'counters/updates': 424}
skipping logging after 6800 examples to avoid logging too frequently
skipping logging after 6816 examples to avoid logging too frequently
skipping logging after 6832 examples to avoid logging too frequently
train stats after 6848 examples: {'rewards_train/chosen': '-0.52729', 'rewards_train/rejected': '-7.5293', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.0004', 'logps_train/rejected': '-224.52', 'logps_train/chosen': '-47.223', 'loss/train': '0.055841', 'examples_per_second': '5.7201', 'grad_norm': '6.375', 'counters/examples': 6848, 'counters/updates': 428}
skipping logging after 6864 examples to avoid logging too frequently
skipping logging after 6880 examples to avoid logging too frequently
skipping logging after 6896 examples to avoid logging too frequently
train stats after 6912 examples: {'rewards_train/chosen': '-0.74722', 'rewards_train/rejected': '-7.2834', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.5367', 'logps_train/rejected': '-219.8', 'logps_train/chosen': '-44.511', 'loss/train': '0.11542', 'examples_per_second': '4.5372', 'grad_norm': '12.875', 'counters/examples': 6912, 'counters/updates': 432}
skipping logging after 6928 examples to avoid logging too frequently
skipping logging after 6944 examples to avoid logging too frequently
skipping logging after 6960 examples to avoid logging too frequently
train stats after 6976 examples: {'rewards_train/chosen': '-0.6035', 'rewards_train/rejected': '-6.4082', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '5.8049', 'logps_train/rejected': '-202.92', 'logps_train/chosen': '-44.327', 'loss/train': '0.15885', 'examples_per_second': '5.4841', 'grad_norm': '15.312', 'counters/examples': 6976, 'counters/updates': 436}
skipping logging after 6992 examples to avoid logging too frequently
skipping logging after 7008 examples to avoid logging too frequently
skipping logging after 7024 examples to avoid logging too frequently
train stats after 7040 examples: {'rewards_train/chosen': '-0.83582', 'rewards_train/rejected': '-6.0092', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '5.1741', 'logps_train/rejected': '-167.05', 'logps_train/chosen': '-44.252', 'loss/train': '0.14258', 'examples_per_second': '4.5851', 'grad_norm': '13.938', 'counters/examples': 7040, 'counters/updates': 440}
skipping logging after 7056 examples to avoid logging too frequently
skipping logging after 7072 examples to avoid logging too frequently
skipping logging after 7088 examples to avoid logging too frequently
train stats after 7104 examples: {'rewards_train/chosen': '-0.80292', 'rewards_train/rejected': '-6.1676', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '5.3669', 'logps_train/rejected': '-180.13', 'logps_train/chosen': '-37.891', 'loss/train': '0.1363', 'examples_per_second': '5.5544', 'grad_norm': '15.375', 'counters/examples': 7104, 'counters/updates': 444}
skipping logging after 7120 examples to avoid logging too frequently
skipping logging after 7136 examples to avoid logging too frequently
skipping logging after 7152 examples to avoid logging too frequently
train stats after 7168 examples: {'rewards_train/chosen': '-0.58759', 'rewards_train/rejected': '-6.1368', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '5.5533', 'logps_train/rejected': '-179.16', 'logps_train/chosen': '-45.083', 'loss/train': '0.089145', 'examples_per_second': '5.3805', 'grad_norm': '7.5', 'counters/examples': 7168, 'counters/updates': 448}
skipping logging after 7184 examples to avoid logging too frequently
skipping logging after 7200 examples to avoid logging too frequently
skipping logging after 7216 examples to avoid logging too frequently
train stats after 7232 examples: {'rewards_train/chosen': '-0.85706', 'rewards_train/rejected': '-6.9598', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.1033', 'logps_train/rejected': '-213.56', 'logps_train/chosen': '-54.464', 'loss/train': '0.17622', 'examples_per_second': '5.3904', 'grad_norm': '14.375', 'counters/examples': 7232, 'counters/updates': 452}
skipping logging after 7248 examples to avoid logging too frequently
skipping logging after 7264 examples to avoid logging too frequently
skipping logging after 7280 examples to avoid logging too frequently
train stats after 7296 examples: {'rewards_train/chosen': '-0.57523', 'rewards_train/rejected': '-7.8826', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.3091', 'logps_train/rejected': '-260.96', 'logps_train/chosen': '-55.465', 'loss/train': '0.068053', 'examples_per_second': '4.6774', 'grad_norm': '6.4375', 'counters/examples': 7296, 'counters/updates': 456}
skipping logging after 7312 examples to avoid logging too frequently
skipping logging after 7328 examples to avoid logging too frequently
skipping logging after 7344 examples to avoid logging too frequently
train stats after 7360 examples: {'rewards_train/chosen': '-0.27014', 'rewards_train/rejected': '-6.3096', 'rewards_train/accuracies': '1', 'rewards_train/margins': '6.0398', 'logps_train/rejected': '-199.44', 'logps_train/chosen': '-40.318', 'loss/train': '0.08459', 'examples_per_second': '5.4513', 'grad_norm': '6.6875', 'counters/examples': 7360, 'counters/updates': 460}
skipping logging after 7376 examples to avoid logging too frequently
skipping logging after 7392 examples to avoid logging too frequently
skipping logging after 7408 examples to avoid logging too frequently
train stats after 7424 examples: {'rewards_train/chosen': '-0.7637', 'rewards_train/rejected': '-6.9939', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.2299', 'logps_train/rejected': '-203.05', 'logps_train/chosen': '-48.223', 'loss/train': '0.091144', 'examples_per_second': '5.1953', 'grad_norm': '7.4688', 'counters/examples': 7424, 'counters/updates': 464}
skipping logging after 7440 examples to avoid logging too frequently
skipping logging after 7456 examples to avoid logging too frequently
skipping logging after 7472 examples to avoid logging too frequently
train stats after 7488 examples: {'rewards_train/chosen': '-0.091644', 'rewards_train/rejected': '-6.3419', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.2487', 'logps_train/rejected': '-193.14', 'logps_train/chosen': '-45.396', 'loss/train': '0.053938', 'examples_per_second': '4.7341', 'grad_norm': '4.0938', 'counters/examples': 7488, 'counters/updates': 468}
skipping logging after 7504 examples to avoid logging too frequently
skipping logging after 7520 examples to avoid logging too frequently
skipping logging after 7536 examples to avoid logging too frequently
train stats after 7552 examples: {'rewards_train/chosen': '-0.72753', 'rewards_train/rejected': '-5.9826', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '5.254', 'logps_train/rejected': '-176.35', 'logps_train/chosen': '-45.824', 'loss/train': '0.16583', 'examples_per_second': '5.978', 'grad_norm': '15', 'counters/examples': 7552, 'counters/updates': 472}
skipping logging after 7568 examples to avoid logging too frequently
skipping logging after 7584 examples to avoid logging too frequently
skipping logging after 7600 examples to avoid logging too frequently
train stats after 7616 examples: {'rewards_train/chosen': '-0.29013', 'rewards_train/rejected': '-6.5764', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.2842', 'logps_train/rejected': '-209.12', 'logps_train/chosen': '-45.779', 'loss/train': '0.10115', 'examples_per_second': '4.5064', 'grad_norm': '8.125', 'counters/examples': 7616, 'counters/updates': 476}
skipping logging after 7632 examples to avoid logging too frequently
skipping logging after 7648 examples to avoid logging too frequently
skipping logging after 7664 examples to avoid logging too frequently
train stats after 7680 examples: {'rewards_train/chosen': '-0.36066', 'rewards_train/rejected': '-6.6178', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.2562', 'logps_train/rejected': '-222.79', 'logps_train/chosen': '-46.204', 'loss/train': '0.08604', 'examples_per_second': '4.2287', 'grad_norm': '8.1875', 'counters/examples': 7680, 'counters/updates': 480}
skipping logging after 7696 examples to avoid logging too frequently
skipping logging after 7712 examples to avoid logging too frequently
skipping logging after 7728 examples to avoid logging too frequently
train stats after 7744 examples: {'rewards_train/chosen': '-0.62817', 'rewards_train/rejected': '-6.8499', 'rewards_train/accuracies': '1', 'rewards_train/margins': '6.2225', 'logps_train/rejected': '-209.21', 'logps_train/chosen': '-44.794', 'loss/train': '0.08142', 'examples_per_second': '4.8954', 'grad_norm': '7.0312', 'counters/examples': 7744, 'counters/updates': 484}
skipping logging after 7760 examples to avoid logging too frequently
skipping logging after 7776 examples to avoid logging too frequently
skipping logging after 7792 examples to avoid logging too frequently
train stats after 7808 examples: {'rewards_train/chosen': '-0.56283', 'rewards_train/rejected': '-6.7037', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.1403', 'logps_train/rejected': '-202.87', 'logps_train/chosen': '-40.561', 'loss/train': '0.12251', 'examples_per_second': '4.9582', 'grad_norm': '9.4375', 'counters/examples': 7808, 'counters/updates': 488}
skipping logging after 7824 examples to avoid logging too frequently
skipping logging after 7840 examples to avoid logging too frequently
skipping logging after 7856 examples to avoid logging too frequently
train stats after 7872 examples: {'rewards_train/chosen': '-0.45443', 'rewards_train/rejected': '-7.4472', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.995', 'logps_train/rejected': '-225.03', 'logps_train/chosen': '-54.06', 'loss/train': '0.19631', 'examples_per_second': '5.4327', 'grad_norm': '16.75', 'counters/examples': 7872, 'counters/updates': 492}
skipping logging after 7888 examples to avoid logging too frequently
skipping logging after 7904 examples to avoid logging too frequently
skipping logging after 7920 examples to avoid logging too frequently
train stats after 7936 examples: {'rewards_train/chosen': '-0.3566', 'rewards_train/rejected': '-5.5671', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '5.2096', 'logps_train/rejected': '-170.99', 'logps_train/chosen': '-38.203', 'loss/train': '0.13604', 'examples_per_second': '5.2039', 'grad_norm': '8.5625', 'counters/examples': 7936, 'counters/updates': 496}
skipping logging after 7952 examples to avoid logging too frequently
skipping logging after 7968 examples to avoid logging too frequently
skipping logging after 7984 examples to avoid logging too frequently
train stats after 8000 examples: {'rewards_train/chosen': '-0.55137', 'rewards_train/rejected': '-6.031', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '5.4789', 'logps_train/rejected': '-190.8', 'logps_train/chosen': '-51.55', 'loss/train': '0.16812', 'examples_per_second': '4.5119', 'grad_norm': '20.875', 'counters/examples': 8000, 'counters/updates': 500}
Running evaluation after 8000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<01:00,  1.95s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:00,  2.02s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:53,  1.84s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.86s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.65s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:36,  1.57s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.50s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:22,  1.30s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.25s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:20,  1.34s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.35s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:14,  1.28s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.30s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.27s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.31s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.49s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.42s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.62s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.43s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.42s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.44s/it]
eval after 8000: {'rewards_eval/chosen': '-6.1533', 'rewards_eval/rejected': '-6.2915', 'rewards_eval/accuracies': '0.50195', 'rewards_eval/margins': '0.13869', 'logps_eval/rejected': '-210.58', 'logps_eval/chosen': '-206.45', 'loss/eval': '1.8877'}
skipping logging after 8016 examples to avoid logging too frequently
skipping logging after 8032 examples to avoid logging too frequently
skipping logging after 8048 examples to avoid logging too frequently
train stats after 8064 examples: {'rewards_train/chosen': '-0.30292', 'rewards_train/rejected': '-6.2753', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '5.9736', 'logps_train/rejected': '-209.14', 'logps_train/chosen': '-40.72', 'loss/train': '0.063348', 'examples_per_second': '4.9834', 'grad_norm': '4.7188', 'counters/examples': 8064, 'counters/updates': 504}
skipping logging after 8080 examples to avoid logging too frequently
skipping logging after 8096 examples to avoid logging too frequently
skipping logging after 8112 examples to avoid logging too frequently
train stats after 8128 examples: {'rewards_train/chosen': '-0.3334', 'rewards_train/rejected': '-5.6655', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '5.3324', 'logps_train/rejected': '-178.77', 'logps_train/chosen': '-45.543', 'loss/train': '0.08651', 'examples_per_second': '5.4691', 'grad_norm': '9.875', 'counters/examples': 8128, 'counters/updates': 508}
skipping logging after 8144 examples to avoid logging too frequently
skipping logging after 8160 examples to avoid logging too frequently
skipping logging after 8176 examples to avoid logging too frequently
train stats after 8192 examples: {'rewards_train/chosen': '-0.63203', 'rewards_train/rejected': '-7.6465', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.0151', 'logps_train/rejected': '-235.75', 'logps_train/chosen': '-43.981', 'loss/train': '0.082874', 'examples_per_second': '5.2042', 'grad_norm': '11.25', 'counters/examples': 8192, 'counters/updates': 512}
skipping logging after 8208 examples to avoid logging too frequently
skipping logging after 8224 examples to avoid logging too frequently
skipping logging after 8240 examples to avoid logging too frequently
train stats after 8256 examples: {'rewards_train/chosen': '-0.43615', 'rewards_train/rejected': '-5.8104', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '5.3749', 'logps_train/rejected': '-183.99', 'logps_train/chosen': '-46.428', 'loss/train': '0.092558', 'examples_per_second': '5.7779', 'grad_norm': '7.0625', 'counters/examples': 8256, 'counters/updates': 516}
skipping logging after 8272 examples to avoid logging too frequently
skipping logging after 8288 examples to avoid logging too frequently
skipping logging after 8304 examples to avoid logging too frequently
train stats after 8320 examples: {'rewards_train/chosen': '-0.16696', 'rewards_train/rejected': '-7.1653', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.9979', 'logps_train/rejected': '-229.49', 'logps_train/chosen': '-50.568', 'loss/train': '0.090579', 'examples_per_second': '4.4781', 'grad_norm': '11.562', 'counters/examples': 8320, 'counters/updates': 520}
skipping logging after 8336 examples to avoid logging too frequently
skipping logging after 8352 examples to avoid logging too frequently
skipping logging after 8368 examples to avoid logging too frequently
train stats after 8384 examples: {'rewards_train/chosen': '-0.41594', 'rewards_train/rejected': '-7.0507', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.6342', 'logps_train/rejected': '-209.88', 'logps_train/chosen': '-43.706', 'loss/train': '0.061046', 'examples_per_second': '5.9217', 'grad_norm': '5.0625', 'counters/examples': 8384, 'counters/updates': 524}
skipping logging after 8400 examples to avoid logging too frequently
skipping logging after 8416 examples to avoid logging too frequently
skipping logging after 8432 examples to avoid logging too frequently
train stats after 8448 examples: {'rewards_train/chosen': '-0.5446', 'rewards_train/rejected': '-6.5913', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.0496', 'logps_train/rejected': '-205.54', 'logps_train/chosen': '-47.55', 'loss/train': '0.13224', 'examples_per_second': '4.3599', 'grad_norm': '9.5', 'counters/examples': 8448, 'counters/updates': 528}
skipping logging after 8464 examples to avoid logging too frequently
skipping logging after 8480 examples to avoid logging too frequently
skipping logging after 8496 examples to avoid logging too frequently
train stats after 8512 examples: {'rewards_train/chosen': '-0.4375', 'rewards_train/rejected': '-6.9506', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.5132', 'logps_train/rejected': '-209.47', 'logps_train/chosen': '-44.826', 'loss/train': '0.073084', 'examples_per_second': '5.034', 'grad_norm': '8.3125', 'counters/examples': 8512, 'counters/updates': 532}
skipping logging after 8528 examples to avoid logging too frequently
skipping logging after 8544 examples to avoid logging too frequently
skipping logging after 8560 examples to avoid logging too frequently
train stats after 8576 examples: {'rewards_train/chosen': '-0.64372', 'rewards_train/rejected': '-7.1122', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.4651', 'logps_train/rejected': '-225.94', 'logps_train/chosen': '-48.037', 'loss/train': '0.070862', 'examples_per_second': '5.2405', 'grad_norm': '7.0312', 'counters/examples': 8576, 'counters/updates': 536}
skipping logging after 8592 examples to avoid logging too frequently
skipping logging after 8608 examples to avoid logging too frequently
skipping logging after 8624 examples to avoid logging too frequently
train stats after 8640 examples: {'rewards_train/chosen': '-0.48564', 'rewards_train/rejected': '-5.957', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '5.4685', 'logps_train/rejected': '-166.02', 'logps_train/chosen': '-47.451', 'loss/train': '0.071874', 'examples_per_second': '4.798', 'grad_norm': '5.8125', 'counters/examples': 8640, 'counters/updates': 540}
skipping logging after 8656 examples to avoid logging too frequently
skipping logging after 8672 examples to avoid logging too frequently
skipping logging after 8688 examples to avoid logging too frequently
train stats after 8704 examples: {'rewards_train/chosen': '-0.65767', 'rewards_train/rejected': '-8.0349', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.3792', 'logps_train/rejected': '-230.03', 'logps_train/chosen': '-45.793', 'loss/train': '0.062267', 'examples_per_second': '5.8233', 'grad_norm': '5.875', 'counters/examples': 8704, 'counters/updates': 544}
skipping logging after 8720 examples to avoid logging too frequently
skipping logging after 8736 examples to avoid logging too frequently
skipping logging after 8752 examples to avoid logging too frequently
train stats after 8768 examples: {'rewards_train/chosen': '-0.398', 'rewards_train/rejected': '-8.4069', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.0094', 'logps_train/rejected': '-274.66', 'logps_train/chosen': '-47.19', 'loss/train': '0.040561', 'examples_per_second': '4.3384', 'grad_norm': '3.3906', 'counters/examples': 8768, 'counters/updates': 548}
skipping logging after 8784 examples to avoid logging too frequently
skipping logging after 8800 examples to avoid logging too frequently
skipping logging after 8816 examples to avoid logging too frequently
train stats after 8832 examples: {'rewards_train/chosen': '-0.80182', 'rewards_train/rejected': '-7.5014', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '6.7003', 'logps_train/rejected': '-213.38', 'logps_train/chosen': '-50.945', 'loss/train': '0.11144', 'examples_per_second': '4.9749', 'grad_norm': '8.875', 'counters/examples': 8832, 'counters/updates': 552}
skipping logging after 8848 examples to avoid logging too frequently
skipping logging after 8864 examples to avoid logging too frequently
skipping logging after 8880 examples to avoid logging too frequently
train stats after 8896 examples: {'rewards_train/chosen': '-0.83987', 'rewards_train/rejected': '-6.7512', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '5.9099', 'logps_train/rejected': '-182.94', 'logps_train/chosen': '-43.714', 'loss/train': '0.10786', 'examples_per_second': '4.4816', 'grad_norm': '13.688', 'counters/examples': 8896, 'counters/updates': 556}
skipping logging after 8912 examples to avoid logging too frequently
skipping logging after 8928 examples to avoid logging too frequently
skipping logging after 8944 examples to avoid logging too frequently
train stats after 8960 examples: {'rewards_train/chosen': '-0.34686', 'rewards_train/rejected': '-7.1681', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.8205', 'logps_train/rejected': '-223.57', 'logps_train/chosen': '-40.531', 'loss/train': '0.075977', 'examples_per_second': '5.0695', 'grad_norm': '5.9688', 'counters/examples': 8960, 'counters/updates': 560}
skipping logging after 8976 examples to avoid logging too frequently
skipping logging after 8992 examples to avoid logging too frequently
skipping logging after 9008 examples to avoid logging too frequently
train stats after 9024 examples: {'rewards_train/chosen': '-0.50386', 'rewards_train/rejected': '-7.2524', 'rewards_train/accuracies': '1', 'rewards_train/margins': '6.7462', 'logps_train/rejected': '-202.92', 'logps_train/chosen': '-53.91', 'loss/train': '0.043217', 'examples_per_second': '5.8025', 'grad_norm': '4.7812', 'counters/examples': 9024, 'counters/updates': 564}
skipping logging after 9040 examples to avoid logging too frequently
skipping logging after 9056 examples to avoid logging too frequently
skipping logging after 9072 examples to avoid logging too frequently
train stats after 9088 examples: {'rewards_train/chosen': '-0.65037', 'rewards_train/rejected': '-7.0125', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.363', 'logps_train/rejected': '-186.61', 'logps_train/chosen': '-37.611', 'loss/train': '0.10391', 'examples_per_second': '4.9183', 'grad_norm': '8.9375', 'counters/examples': 9088, 'counters/updates': 568}
skipping logging after 9104 examples to avoid logging too frequently
skipping logging after 9120 examples to avoid logging too frequently
skipping logging after 9136 examples to avoid logging too frequently
train stats after 9152 examples: {'rewards_train/chosen': '-0.73116', 'rewards_train/rejected': '-8.0501', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.3224', 'logps_train/rejected': '-238.26', 'logps_train/chosen': '-54.887', 'loss/train': '0.095492', 'examples_per_second': '5.3832', 'grad_norm': '10.312', 'counters/examples': 9152, 'counters/updates': 572}
skipping logging after 9168 examples to avoid logging too frequently
skipping logging after 9184 examples to avoid logging too frequently
skipping logging after 9200 examples to avoid logging too frequently
train stats after 9216 examples: {'rewards_train/chosen': '-0.66252', 'rewards_train/rejected': '-7.2383', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.5776', 'logps_train/rejected': '-214.15', 'logps_train/chosen': '-44.379', 'loss/train': '0.059447', 'examples_per_second': '5.0567', 'grad_norm': '7.25', 'counters/examples': 9216, 'counters/updates': 576}
skipping logging after 9232 examples to avoid logging too frequently
skipping logging after 9248 examples to avoid logging too frequently
skipping logging after 9264 examples to avoid logging too frequently
train stats after 9280 examples: {'rewards_train/chosen': '-1.007', 'rewards_train/rejected': '-7.4316', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.4255', 'logps_train/rejected': '-201.35', 'logps_train/chosen': '-53.642', 'loss/train': '0.097357', 'examples_per_second': '6.4789', 'grad_norm': '9.5625', 'counters/examples': 9280, 'counters/updates': 580}
skipping logging after 9296 examples to avoid logging too frequently
skipping logging after 9312 examples to avoid logging too frequently
skipping logging after 9328 examples to avoid logging too frequently
train stats after 9344 examples: {'rewards_train/chosen': '-0.67945', 'rewards_train/rejected': '-8.9383', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.2597', 'logps_train/rejected': '-242.54', 'logps_train/chosen': '-40.757', 'loss/train': '0.079626', 'examples_per_second': '4.152', 'grad_norm': '5.75', 'counters/examples': 9344, 'counters/updates': 584}
skipping logging after 9360 examples to avoid logging too frequently
skipping logging after 9376 examples to avoid logging too frequently
skipping logging after 9392 examples to avoid logging too frequently
train stats after 9408 examples: {'rewards_train/chosen': '-0.80255', 'rewards_train/rejected': '-7.6973', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.8944', 'logps_train/rejected': '-181.65', 'logps_train/chosen': '-37.669', 'loss/train': '0.098939', 'examples_per_second': '5.9249', 'grad_norm': '9.125', 'counters/examples': 9408, 'counters/updates': 588}
skipping logging after 9424 examples to avoid logging too frequently
skipping logging after 9440 examples to avoid logging too frequently
skipping logging after 9456 examples to avoid logging too frequently
train stats after 9472 examples: {'rewards_train/chosen': '-0.62519', 'rewards_train/rejected': '-8.2885', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.6619', 'logps_train/rejected': '-232.72', 'logps_train/chosen': '-45.626', 'loss/train': '0.081708', 'examples_per_second': '4.4803', 'grad_norm': '7.4375', 'counters/examples': 9472, 'counters/updates': 592}
skipping logging after 9488 examples to avoid logging too frequently
skipping logging after 9504 examples to avoid logging too frequently
skipping logging after 9520 examples to avoid logging too frequently
train stats after 9536 examples: {'rewards_train/chosen': '-0.64766', 'rewards_train/rejected': '-8.9755', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.3264', 'logps_train/rejected': '-242.4', 'logps_train/chosen': '-53.313', 'loss/train': '0.042702', 'examples_per_second': '4.7718', 'grad_norm': '4.125', 'counters/examples': 9536, 'counters/updates': 596}
skipping logging after 9552 examples to avoid logging too frequently
skipping logging after 9568 examples to avoid logging too frequently
skipping logging after 9584 examples to avoid logging too frequently
train stats after 9600 examples: {'rewards_train/chosen': '-0.73855', 'rewards_train/rejected': '-8.1458', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.4062', 'logps_train/rejected': '-216.58', 'logps_train/chosen': '-47.911', 'loss/train': '0.1464', 'examples_per_second': '5.0259', 'grad_norm': '11.75', 'counters/examples': 9600, 'counters/updates': 600}
skipping logging after 9616 examples to avoid logging too frequently
skipping logging after 9632 examples to avoid logging too frequently
skipping logging after 9648 examples to avoid logging too frequently
train stats after 9664 examples: {'rewards_train/chosen': '-0.32817', 'rewards_train/rejected': '-6.9007', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.5763', 'logps_train/rejected': '-206.25', 'logps_train/chosen': '-38.728', 'loss/train': '0.13703', 'examples_per_second': '6.0278', 'grad_norm': '13.688', 'counters/examples': 9664, 'counters/updates': 604}
skipping logging after 9680 examples to avoid logging too frequently
skipping logging after 9696 examples to avoid logging too frequently
skipping logging after 9712 examples to avoid logging too frequently
train stats after 9728 examples: {'rewards_train/chosen': '-0.17727', 'rewards_train/rejected': '-6.9005', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.7252', 'logps_train/rejected': '-225.36', 'logps_train/chosen': '-47.113', 'loss/train': '0.093448', 'examples_per_second': '4.8401', 'grad_norm': '8.625', 'counters/examples': 9728, 'counters/updates': 608}
skipping logging after 9744 examples to avoid logging too frequently
skipping logging after 9760 examples to avoid logging too frequently
skipping logging after 9776 examples to avoid logging too frequently
train stats after 9792 examples: {'rewards_train/chosen': '-0.21872', 'rewards_train/rejected': '-6.4092', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.1915', 'logps_train/rejected': '-200.29', 'logps_train/chosen': '-52.28', 'loss/train': '0.11256', 'examples_per_second': '5.2566', 'grad_norm': '12.562', 'counters/examples': 9792, 'counters/updates': 612}
skipping logging after 9808 examples to avoid logging too frequently
skipping logging after 9824 examples to avoid logging too frequently
skipping logging after 9840 examples to avoid logging too frequently
train stats after 9856 examples: {'rewards_train/chosen': '-0.18763', 'rewards_train/rejected': '-6.7428', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.5571', 'logps_train/rejected': '-192.72', 'logps_train/chosen': '-39.57', 'loss/train': '0.063167', 'examples_per_second': '4.5307', 'grad_norm': '5.6562', 'counters/examples': 9856, 'counters/updates': 616}
skipping logging after 9872 examples to avoid logging too frequently
skipping logging after 9888 examples to avoid logging too frequently
skipping logging after 9904 examples to avoid logging too frequently
train stats after 9920 examples: {'rewards_train/chosen': '-0.37027', 'rewards_train/rejected': '-6.4085', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.0376', 'logps_train/rejected': '-190.37', 'logps_train/chosen': '-53.34', 'loss/train': '0.072284', 'examples_per_second': '5.5871', 'grad_norm': '6.875', 'counters/examples': 9920, 'counters/updates': 620}
skipping logging after 9936 examples to avoid logging too frequently
skipping logging after 9952 examples to avoid logging too frequently
skipping logging after 9968 examples to avoid logging too frequently
train stats after 9984 examples: {'rewards_train/chosen': '-0.77597', 'rewards_train/rejected': '-7.2821', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '6.5055', 'logps_train/rejected': '-210.74', 'logps_train/chosen': '-46.163', 'loss/train': '0.36013', 'examples_per_second': '6.2465', 'grad_norm': '22.625', 'counters/examples': 9984, 'counters/updates': 624}
skipping logging after 10000 examples to avoid logging too frequently
skipping logging after 10016 examples to avoid logging too frequently
skipping logging after 10032 examples to avoid logging too frequently
train stats after 10048 examples: {'rewards_train/chosen': '-0.16842', 'rewards_train/rejected': '-5.9144', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '5.7433', 'logps_train/rejected': '-183.93', 'logps_train/chosen': '-36.356', 'loss/train': '0.057511', 'examples_per_second': '5.2105', 'grad_norm': '3.7969', 'counters/examples': 10048, 'counters/updates': 628}
skipping logging after 10064 examples to avoid logging too frequently
skipping logging after 10080 examples to avoid logging too frequently
skipping logging after 10096 examples to avoid logging too frequently
train stats after 10112 examples: {'rewards_train/chosen': '-0.26908', 'rewards_train/rejected': '-6.751', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.4827', 'logps_train/rejected': '-207.17', 'logps_train/chosen': '-44.792', 'loss/train': '0.059447', 'examples_per_second': '5.215', 'grad_norm': '7', 'counters/examples': 10112, 'counters/updates': 632}
skipping logging after 10128 examples to avoid logging too frequently
skipping logging after 10144 examples to avoid logging too frequently
skipping logging after 10160 examples to avoid logging too frequently
train stats after 10176 examples: {'rewards_train/chosen': '-0.10558', 'rewards_train/rejected': '-6.1027', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '5.998', 'logps_train/rejected': '-194.99', 'logps_train/chosen': '-46.535', 'loss/train': '0.069052', 'examples_per_second': '5.2277', 'grad_norm': '6.3438', 'counters/examples': 10176, 'counters/updates': 636}
skipping logging after 10192 examples to avoid logging too frequently
skipping logging after 10208 examples to avoid logging too frequently
skipping logging after 10224 examples to avoid logging too frequently
train stats after 10240 examples: {'rewards_train/chosen': '-0.34597', 'rewards_train/rejected': '-6.3411', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '5.9925', 'logps_train/rejected': '-202.29', 'logps_train/chosen': '-51.205', 'loss/train': '0.12927', 'examples_per_second': '5.9163', 'grad_norm': '8.875', 'counters/examples': 10240, 'counters/updates': 640}
skipping logging after 10256 examples to avoid logging too frequently
skipping logging after 10272 examples to avoid logging too frequently
skipping logging after 10288 examples to avoid logging too frequently
train stats after 10304 examples: {'rewards_train/chosen': '-0.49851', 'rewards_train/rejected': '-6.2932', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '5.7958', 'logps_train/rejected': '-195.5', 'logps_train/chosen': '-47.431', 'loss/train': '0.10095', 'examples_per_second': '4.8995', 'grad_norm': '12.375', 'counters/examples': 10304, 'counters/updates': 644}
skipping logging after 10320 examples to avoid logging too frequently
skipping logging after 10336 examples to avoid logging too frequently
skipping logging after 10352 examples to avoid logging too frequently
train stats after 10368 examples: {'rewards_train/chosen': '-0.26949', 'rewards_train/rejected': '-6.2388', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '5.9708', 'logps_train/rejected': '-192.32', 'logps_train/chosen': '-39.839', 'loss/train': '0.070463', 'examples_per_second': '5.3194', 'grad_norm': '5.3125', 'counters/examples': 10368, 'counters/updates': 648}
skipping logging after 10384 examples to avoid logging too frequently
skipping logging after 10400 examples to avoid logging too frequently
skipping logging after 10416 examples to avoid logging too frequently
train stats after 10432 examples: {'rewards_train/chosen': '-0.45518', 'rewards_train/rejected': '-7.2977', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.8413', 'logps_train/rejected': '-212.89', 'logps_train/chosen': '-46.479', 'loss/train': '0.15836', 'examples_per_second': '5.0439', 'grad_norm': '14.25', 'counters/examples': 10432, 'counters/updates': 652}
skipping logging after 10448 examples to avoid logging too frequently
skipping logging after 10464 examples to avoid logging too frequently
skipping logging after 10480 examples to avoid logging too frequently
train stats after 10496 examples: {'rewards_train/chosen': '-0.54725', 'rewards_train/rejected': '-7.8091', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.2624', 'logps_train/rejected': '-226.19', 'logps_train/chosen': '-54.137', 'loss/train': '0.086205', 'examples_per_second': '4.5647', 'grad_norm': '10.062', 'counters/examples': 10496, 'counters/updates': 656}
skipping logging after 10512 examples to avoid logging too frequently
skipping logging after 10528 examples to avoid logging too frequently
skipping logging after 10544 examples to avoid logging too frequently
train stats after 10560 examples: {'rewards_train/chosen': '-0.43156', 'rewards_train/rejected': '-6.4186', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '5.9865', 'logps_train/rejected': '-193.28', 'logps_train/chosen': '-45.983', 'loss/train': '0.068225', 'examples_per_second': '5.6103', 'grad_norm': '4.6562', 'counters/examples': 10560, 'counters/updates': 660}
skipping logging after 10576 examples to avoid logging too frequently
skipping logging after 10592 examples to avoid logging too frequently
skipping logging after 10608 examples to avoid logging too frequently
train stats after 10624 examples: {'rewards_train/chosen': '-0.51376', 'rewards_train/rejected': '-6.0005', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '5.4858', 'logps_train/rejected': '-181.46', 'logps_train/chosen': '-45.58', 'loss/train': '0.12594', 'examples_per_second': '4.8199', 'grad_norm': '9.1875', 'counters/examples': 10624, 'counters/updates': 664}
skipping logging after 10640 examples to avoid logging too frequently
skipping logging after 10656 examples to avoid logging too frequently
skipping logging after 10672 examples to avoid logging too frequently
train stats after 10688 examples: {'rewards_train/chosen': '-0.71955', 'rewards_train/rejected': '-7.8875', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.1692', 'logps_train/rejected': '-229.23', 'logps_train/chosen': '-48.443', 'loss/train': '0.041615', 'examples_per_second': '5.2435', 'grad_norm': '4.0312', 'counters/examples': 10688, 'counters/updates': 668}
skipping logging after 10704 examples to avoid logging too frequently
skipping logging after 10720 examples to avoid logging too frequently
skipping logging after 10736 examples to avoid logging too frequently
train stats after 10752 examples: {'rewards_train/chosen': '-1.004', 'rewards_train/rejected': '-7.2372', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.2339', 'logps_train/rejected': '-212.31', 'logps_train/chosen': '-53.226', 'loss/train': '0.068717', 'examples_per_second': '4.5147', 'grad_norm': '7.4688', 'counters/examples': 10752, 'counters/updates': 672}
skipping logging after 10768 examples to avoid logging too frequently
skipping logging after 10784 examples to avoid logging too frequently
skipping logging after 10800 examples to avoid logging too frequently
train stats after 10816 examples: {'rewards_train/chosen': '-1.0534', 'rewards_train/rejected': '-8.6642', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.611', 'logps_train/rejected': '-221.23', 'logps_train/chosen': '-53.155', 'loss/train': '0.051131', 'examples_per_second': '4.8644', 'grad_norm': '8.25', 'counters/examples': 10816, 'counters/updates': 676}
skipping logging after 10832 examples to avoid logging too frequently
skipping logging after 10848 examples to avoid logging too frequently
skipping logging after 10864 examples to avoid logging too frequently
train stats after 10880 examples: {'rewards_train/chosen': '-0.92469', 'rewards_train/rejected': '-7.8556', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.9283', 'logps_train/rejected': '-222.53', 'logps_train/chosen': '-52.08', 'loss/train': '0.084879', 'examples_per_second': '4.3492', 'grad_norm': '10.438', 'counters/examples': 10880, 'counters/updates': 680}
skipping logging after 10896 examples to avoid logging too frequently
skipping logging after 10912 examples to avoid logging too frequently
skipping logging after 10928 examples to avoid logging too frequently
train stats after 10944 examples: {'rewards_train/chosen': '-0.73059', 'rewards_train/rejected': '-6.4688', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '5.7389', 'logps_train/rejected': '-184.82', 'logps_train/chosen': '-47.996', 'loss/train': '0.11725', 'examples_per_second': '4.2547', 'grad_norm': '12', 'counters/examples': 10944, 'counters/updates': 684}
skipping logging after 10960 examples to avoid logging too frequently
skipping logging after 10976 examples to avoid logging too frequently
skipping logging after 10992 examples to avoid logging too frequently
train stats after 11008 examples: {'rewards_train/chosen': '-0.53265', 'rewards_train/rejected': '-7.5867', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.0547', 'logps_train/rejected': '-260.88', 'logps_train/chosen': '-53.926', 'loss/train': '0.053374', 'examples_per_second': '4.7074', 'grad_norm': '6.8125', 'counters/examples': 11008, 'counters/updates': 688}
skipping logging after 11024 examples to avoid logging too frequently
skipping logging after 11040 examples to avoid logging too frequently
skipping logging after 11056 examples to avoid logging too frequently
train stats after 11072 examples: {'rewards_train/chosen': '-0.68154', 'rewards_train/rejected': '-7.4461', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.767', 'logps_train/rejected': '-230.73', 'logps_train/chosen': '-48.592', 'loss/train': '0.059968', 'examples_per_second': '4.6301', 'grad_norm': '6.4375', 'counters/examples': 11072, 'counters/updates': 692}
skipping logging after 11088 examples to avoid logging too frequently
skipping logging after 11104 examples to avoid logging too frequently
skipping logging after 11120 examples to avoid logging too frequently
train stats after 11136 examples: {'rewards_train/chosen': '-0.86107', 'rewards_train/rejected': '-7.2557', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.3948', 'logps_train/rejected': '-207.57', 'logps_train/chosen': '-50.102', 'loss/train': '0.082717', 'examples_per_second': '4.6474', 'grad_norm': '9.875', 'counters/examples': 11136, 'counters/updates': 696}
skipping logging after 11152 examples to avoid logging too frequently
skipping logging after 11168 examples to avoid logging too frequently
skipping logging after 11184 examples to avoid logging too frequently
train stats after 11200 examples: {'rewards_train/chosen': '-0.94955', 'rewards_train/rejected': '-6.7515', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '5.8005', 'logps_train/rejected': '-179.15', 'logps_train/chosen': '-37.795', 'loss/train': '0.098115', 'examples_per_second': '5.919', 'grad_norm': '7.625', 'counters/examples': 11200, 'counters/updates': 700}
skipping logging after 11216 examples to avoid logging too frequently
skipping logging after 11232 examples to avoid logging too frequently
skipping logging after 11248 examples to avoid logging too frequently
train stats after 11264 examples: {'rewards_train/chosen': '-0.85816', 'rewards_train/rejected': '-7.7038', 'rewards_train/accuracies': '1', 'rewards_train/margins': '6.847', 'logps_train/rejected': '-208.4', 'logps_train/chosen': '-43.11', 'loss/train': '0.047267', 'examples_per_second': '5.1691', 'grad_norm': '4.0938', 'counters/examples': 11264, 'counters/updates': 704}
skipping logging after 11280 examples to avoid logging too frequently
skipping logging after 11296 examples to avoid logging too frequently
skipping logging after 11312 examples to avoid logging too frequently
train stats after 11328 examples: {'rewards_train/chosen': '-0.80951', 'rewards_train/rejected': '-8.7003', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.8899', 'logps_train/rejected': '-260.89', 'logps_train/chosen': '-59.561', 'loss/train': '0.043345', 'examples_per_second': '4.6243', 'grad_norm': '4.7812', 'counters/examples': 11328, 'counters/updates': 708}
skipping logging after 11344 examples to avoid logging too frequently
skipping logging after 11360 examples to avoid logging too frequently
skipping logging after 11376 examples to avoid logging too frequently
train stats after 11392 examples: {'rewards_train/chosen': '-0.71279', 'rewards_train/rejected': '-7.977', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.2626', 'logps_train/rejected': '-214.98', 'logps_train/chosen': '-49.486', 'loss/train': '0.038628', 'examples_per_second': '6.0296', 'grad_norm': '4.5938', 'counters/examples': 11392, 'counters/updates': 712}
skipping logging after 11408 examples to avoid logging too frequently
skipping logging after 11424 examples to avoid logging too frequently
skipping logging after 11440 examples to avoid logging too frequently
train stats after 11456 examples: {'rewards_train/chosen': '-1.1474', 'rewards_train/rejected': '-8.9763', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.8303', 'logps_train/rejected': '-239.16', 'logps_train/chosen': '-51.738', 'loss/train': '0.082175', 'examples_per_second': '4.4086', 'grad_norm': '11.75', 'counters/examples': 11456, 'counters/updates': 716}
skipping logging after 11472 examples to avoid logging too frequently
skipping logging after 11488 examples to avoid logging too frequently
skipping logging after 11504 examples to avoid logging too frequently
train stats after 11520 examples: {'rewards_train/chosen': '-1.0171', 'rewards_train/rejected': '-7.7559', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.7369', 'logps_train/rejected': '-200.58', 'logps_train/chosen': '-44.186', 'loss/train': '0.067733', 'examples_per_second': '6.3686', 'grad_norm': '7.5625', 'counters/examples': 11520, 'counters/updates': 720}
skipping logging after 11536 examples to avoid logging too frequently
skipping logging after 11552 examples to avoid logging too frequently
skipping logging after 11568 examples to avoid logging too frequently
train stats after 11584 examples: {'rewards_train/chosen': '-1.1662', 'rewards_train/rejected': '-8.8549', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.6881', 'logps_train/rejected': '-230.33', 'logps_train/chosen': '-53.269', 'loss/train': '0.052346', 'examples_per_second': '4.6802', 'grad_norm': '11.625', 'counters/examples': 11584, 'counters/updates': 724}
skipping logging after 11600 examples to avoid logging too frequently
skipping logging after 11616 examples to avoid logging too frequently
skipping logging after 11632 examples to avoid logging too frequently
train stats after 11648 examples: {'rewards_train/chosen': '-1.3777', 'rewards_train/rejected': '-8.2541', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.8737', 'logps_train/rejected': '-220.77', 'logps_train/chosen': '-51.606', 'loss/train': '0.1077', 'examples_per_second': '4.6642', 'grad_norm': '10.125', 'counters/examples': 11648, 'counters/updates': 728}
skipping logging after 11664 examples to avoid logging too frequently
skipping logging after 11680 examples to avoid logging too frequently
skipping logging after 11696 examples to avoid logging too frequently
train stats after 11712 examples: {'rewards_train/chosen': '-0.89998', 'rewards_train/rejected': '-8.2886', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.3856', 'logps_train/rejected': '-248.05', 'logps_train/chosen': '-54.119', 'loss/train': '0.11627', 'examples_per_second': '5.3873', 'grad_norm': '9', 'counters/examples': 11712, 'counters/updates': 732}
skipping logging after 11728 examples to avoid logging too frequently
skipping logging after 11744 examples to avoid logging too frequently
skipping logging after 11760 examples to avoid logging too frequently
train stats after 11776 examples: {'rewards_train/chosen': '-1.2576', 'rewards_train/rejected': '-7.3633', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.1052', 'logps_train/rejected': '-196.85', 'logps_train/chosen': '-47.507', 'loss/train': '0.11863', 'examples_per_second': '5.6199', 'grad_norm': '12.312', 'counters/examples': 11776, 'counters/updates': 736}
skipping logging after 11792 examples to avoid logging too frequently
skipping logging after 11808 examples to avoid logging too frequently
skipping logging after 11824 examples to avoid logging too frequently
train stats after 11840 examples: {'rewards_train/chosen': '-1.0284', 'rewards_train/rejected': '-9.4799', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.4508', 'logps_train/rejected': '-259.43', 'logps_train/chosen': '-51.992', 'loss/train': '0.024961', 'examples_per_second': '4.8452', 'grad_norm': '3.75', 'counters/examples': 11840, 'counters/updates': 740}
skipping logging after 11856 examples to avoid logging too frequently
skipping logging after 11872 examples to avoid logging too frequently
skipping logging after 11888 examples to avoid logging too frequently
train stats after 11904 examples: {'rewards_train/chosen': '-1.1318', 'rewards_train/rejected': '-9.1458', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.0131', 'logps_train/rejected': '-245.08', 'logps_train/chosen': '-58.322', 'loss/train': '0.05308', 'examples_per_second': '4.8448', 'grad_norm': '6.9375', 'counters/examples': 11904, 'counters/updates': 744}
skipping logging after 11920 examples to avoid logging too frequently
skipping logging after 11936 examples to avoid logging too frequently
skipping logging after 11952 examples to avoid logging too frequently
train stats after 11968 examples: {'rewards_train/chosen': '-1.228', 'rewards_train/rejected': '-8.7149', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.4872', 'logps_train/rejected': '-216.29', 'logps_train/chosen': '-60.032', 'loss/train': '0.076343', 'examples_per_second': '4.9642', 'grad_norm': '7.4062', 'counters/examples': 11968, 'counters/updates': 748}
skipping logging after 11984 examples to avoid logging too frequently
skipping logging after 12000 examples to avoid logging too frequently
Running evaluation after 12000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:14,  2.41s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:06,  2.21s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:56,  1.95s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.92s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:42,  1.56s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.67s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.49s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.57s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:36,  1.57s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.50s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.43s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:22,  1.29s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.24s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.33s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.34s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.27s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:33<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.29s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.26s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:37<00:07,  1.30s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:39<00:07,  1.48s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.41s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.62s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.42s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.42s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.45s/it]
eval after 12000: {'rewards_eval/chosen': '-9.4794', 'rewards_eval/rejected': '-9.6485', 'rewards_eval/accuracies': '0.50195', 'rewards_eval/margins': '0.16978', 'logps_eval/rejected': '-244.14', 'logps_eval/chosen': '-239.71', 'loss/eval': '2.4611'}
skipping logging after 12016 examples to avoid logging too frequently
train stats after 12032 examples: {'rewards_train/chosen': '-1.542', 'rewards_train/rejected': '-10.203', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.6624', 'logps_train/rejected': '-262.31', 'logps_train/chosen': '-71.29', 'loss/train': '0.10635', 'examples_per_second': '5.2292', 'grad_norm': '15.625', 'counters/examples': 12032, 'counters/updates': 752}
skipping logging after 12048 examples to avoid logging too frequently
skipping logging after 12064 examples to avoid logging too frequently
skipping logging after 12080 examples to avoid logging too frequently
train stats after 12096 examples: {'rewards_train/chosen': '-1.1834', 'rewards_train/rejected': '-8.002', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.8192', 'logps_train/rejected': '-217.57', 'logps_train/chosen': '-50.603', 'loss/train': '0.065201', 'examples_per_second': '5.5592', 'grad_norm': '7.875', 'counters/examples': 12096, 'counters/updates': 756}
skipping logging after 12112 examples to avoid logging too frequently
skipping logging after 12128 examples to avoid logging too frequently
skipping logging after 12144 examples to avoid logging too frequently
train stats after 12160 examples: {'rewards_train/chosen': '-1.1406', 'rewards_train/rejected': '-7.9364', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.7957', 'logps_train/rejected': '-215.53', 'logps_train/chosen': '-57.614', 'loss/train': '0.070071', 'examples_per_second': '4.9514', 'grad_norm': '5.0938', 'counters/examples': 12160, 'counters/updates': 760}
skipping logging after 12176 examples to avoid logging too frequently
skipping logging after 12192 examples to avoid logging too frequently
skipping logging after 12208 examples to avoid logging too frequently
train stats after 12224 examples: {'rewards_train/chosen': '-1.589', 'rewards_train/rejected': '-9.9316', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.3401', 'logps_train/rejected': '-242.43', 'logps_train/chosen': '-49.322', 'loss/train': '0.073936', 'examples_per_second': '5.5951', 'grad_norm': '13.875', 'counters/examples': 12224, 'counters/updates': 764}
skipping logging after 12240 examples to avoid logging too frequently
skipping logging after 12256 examples to avoid logging too frequently
skipping logging after 12272 examples to avoid logging too frequently
train stats after 12288 examples: {'rewards_train/chosen': '-1.1707', 'rewards_train/rejected': '-9.0887', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.9188', 'logps_train/rejected': '-228.43', 'logps_train/chosen': '-52.195', 'loss/train': '0.065997', 'examples_per_second': '5.1632', 'grad_norm': '7.9375', 'counters/examples': 12288, 'counters/updates': 768}
skipping logging after 12304 examples to avoid logging too frequently
skipping logging after 12320 examples to avoid logging too frequently
skipping logging after 12336 examples to avoid logging too frequently
train stats after 12352 examples: {'rewards_train/chosen': '-1.1609', 'rewards_train/rejected': '-9.3237', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.1636', 'logps_train/rejected': '-277.54', 'logps_train/chosen': '-61.436', 'loss/train': '0.06467', 'examples_per_second': '4.4312', 'grad_norm': '6.0938', 'counters/examples': 12352, 'counters/updates': 772}
skipping logging after 12368 examples to avoid logging too frequently
skipping logging after 12384 examples to avoid logging too frequently
skipping logging after 12400 examples to avoid logging too frequently
train stats after 12416 examples: {'rewards_train/chosen': '-1.6433', 'rewards_train/rejected': '-9.4058', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.7614', 'logps_train/rejected': '-235.96', 'logps_train/chosen': '-64.147', 'loss/train': '0.1548', 'examples_per_second': '4.2153', 'grad_norm': '16.25', 'counters/examples': 12416, 'counters/updates': 776}
skipping logging after 12432 examples to avoid logging too frequently
skipping logging after 12448 examples to avoid logging too frequently
skipping logging after 12464 examples to avoid logging too frequently
train stats after 12480 examples: {'rewards_train/chosen': '-1.1171', 'rewards_train/rejected': '-7.3126', 'rewards_train/accuracies': '1', 'rewards_train/margins': '6.198', 'logps_train/rejected': '-220.1', 'logps_train/chosen': '-53.111', 'loss/train': '0.083392', 'examples_per_second': '4.1044', 'grad_norm': '10.625', 'counters/examples': 12480, 'counters/updates': 780}
skipping logging after 12496 examples to avoid logging too frequently
skipping logging after 12512 examples to avoid logging too frequently
skipping logging after 12528 examples to avoid logging too frequently
train stats after 12544 examples: {'rewards_train/chosen': '-1.2047', 'rewards_train/rejected': '-9.6674', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.4648', 'logps_train/rejected': '-262.16', 'logps_train/chosen': '-48.065', 'loss/train': '0.03347', 'examples_per_second': '4.6351', 'grad_norm': '4.25', 'counters/examples': 12544, 'counters/updates': 784}
skipping logging after 12560 examples to avoid logging too frequently
skipping logging after 12576 examples to avoid logging too frequently
skipping logging after 12592 examples to avoid logging too frequently
train stats after 12608 examples: {'rewards_train/chosen': '-1.5156', 'rewards_train/rejected': '-9.7939', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.2806', 'logps_train/rejected': '-255.27', 'logps_train/chosen': '-52.542', 'loss/train': '0.1224', 'examples_per_second': '4.7701', 'grad_norm': '14.625', 'counters/examples': 12608, 'counters/updates': 788}
skipping logging after 12624 examples to avoid logging too frequently
skipping logging after 12640 examples to avoid logging too frequently
skipping logging after 12656 examples to avoid logging too frequently
train stats after 12672 examples: {'rewards_train/chosen': '-1.6', 'rewards_train/rejected': '-9.9152', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.3168', 'logps_train/rejected': '-254.87', 'logps_train/chosen': '-58.328', 'loss/train': '0.04213', 'examples_per_second': '4.5013', 'grad_norm': '9', 'counters/examples': 12672, 'counters/updates': 792}
skipping logging after 12688 examples to avoid logging too frequently
skipping logging after 12704 examples to avoid logging too frequently
skipping logging after 12720 examples to avoid logging too frequently
train stats after 12736 examples: {'rewards_train/chosen': '-1.6186', 'rewards_train/rejected': '-8.6679', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.0472', 'logps_train/rejected': '-218.38', 'logps_train/chosen': '-62.1', 'loss/train': '0.067422', 'examples_per_second': '4.5604', 'grad_norm': '5.9688', 'counters/examples': 12736, 'counters/updates': 796}
skipping logging after 12752 examples to avoid logging too frequently
skipping logging after 12768 examples to avoid logging too frequently
skipping logging after 12784 examples to avoid logging too frequently
train stats after 12800 examples: {'rewards_train/chosen': '-1.575', 'rewards_train/rejected': '-9.6445', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.0696', 'logps_train/rejected': '-239.21', 'logps_train/chosen': '-59.618', 'loss/train': '0.10956', 'examples_per_second': '5.3991', 'grad_norm': '15.125', 'counters/examples': 12800, 'counters/updates': 800}
skipping logging after 12816 examples to avoid logging too frequently
skipping logging after 12832 examples to avoid logging too frequently
skipping logging after 12848 examples to avoid logging too frequently
train stats after 12864 examples: {'rewards_train/chosen': '-0.88692', 'rewards_train/rejected': '-7.8827', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.9964', 'logps_train/rejected': '-214.66', 'logps_train/chosen': '-53.055', 'loss/train': '0.086754', 'examples_per_second': '4.4816', 'grad_norm': '9', 'counters/examples': 12864, 'counters/updates': 804}
skipping logging after 12880 examples to avoid logging too frequently
skipping logging after 12896 examples to avoid logging too frequently
skipping logging after 12912 examples to avoid logging too frequently
train stats after 12928 examples: {'rewards_train/chosen': '-0.89689', 'rewards_train/rejected': '-7.0227', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.125', 'logps_train/rejected': '-204.74', 'logps_train/chosen': '-51.438', 'loss/train': '0.079005', 'examples_per_second': '5.1717', 'grad_norm': '7', 'counters/examples': 12928, 'counters/updates': 808}
skipping logging after 12944 examples to avoid logging too frequently
skipping logging after 12960 examples to avoid logging too frequently
skipping logging after 12976 examples to avoid logging too frequently
train stats after 12992 examples: {'rewards_train/chosen': '-1.3772', 'rewards_train/rejected': '-7.2238', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '5.8463', 'logps_train/rejected': '-195.24', 'logps_train/chosen': '-55.323', 'loss/train': '0.087743', 'examples_per_second': '5.0685', 'grad_norm': '12', 'counters/examples': 12992, 'counters/updates': 812}
skipping logging after 13008 examples to avoid logging too frequently
skipping logging after 13024 examples to avoid logging too frequently
skipping logging after 13040 examples to avoid logging too frequently
train stats after 13056 examples: {'rewards_train/chosen': '-1.1139', 'rewards_train/rejected': '-6.5752', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '5.46', 'logps_train/rejected': '-184.49', 'logps_train/chosen': '-48.684', 'loss/train': '0.12122', 'examples_per_second': '5.6416', 'grad_norm': '8.5', 'counters/examples': 13056, 'counters/updates': 816}
skipping logging after 13072 examples to avoid logging too frequently
skipping logging after 13088 examples to avoid logging too frequently
skipping logging after 13104 examples to avoid logging too frequently
train stats after 13120 examples: {'rewards_train/chosen': '-1.0386', 'rewards_train/rejected': '-7.2155', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.1747', 'logps_train/rejected': '-202.48', 'logps_train/chosen': '-48.088', 'loss/train': '0.10099', 'examples_per_second': '4.8444', 'grad_norm': '12.812', 'counters/examples': 13120, 'counters/updates': 820}
skipping logging after 13136 examples to avoid logging too frequently
skipping logging after 13152 examples to avoid logging too frequently
skipping logging after 13168 examples to avoid logging too frequently
train stats after 13184 examples: {'rewards_train/chosen': '-0.88922', 'rewards_train/rejected': '-7.6302', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.7395', 'logps_train/rejected': '-225.98', 'logps_train/chosen': '-43.796', 'loss/train': '0.075516', 'examples_per_second': '4.4635', 'grad_norm': '7.8438', 'counters/examples': 13184, 'counters/updates': 824}
skipping logging after 13200 examples to avoid logging too frequently
skipping logging after 13216 examples to avoid logging too frequently
skipping logging after 13232 examples to avoid logging too frequently
train stats after 13248 examples: {'rewards_train/chosen': '-0.89369', 'rewards_train/rejected': '-7.6792', 'rewards_train/accuracies': '1', 'rewards_train/margins': '6.7867', 'logps_train/rejected': '-212.49', 'logps_train/chosen': '-49.407', 'loss/train': '0.069917', 'examples_per_second': '4.8677', 'grad_norm': '8.1875', 'counters/examples': 13248, 'counters/updates': 828}
skipping logging after 13264 examples to avoid logging too frequently
skipping logging after 13280 examples to avoid logging too frequently
skipping logging after 13296 examples to avoid logging too frequently
train stats after 13312 examples: {'rewards_train/chosen': '-0.95146', 'rewards_train/rejected': '-8.2456', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.2927', 'logps_train/rejected': '-230.11', 'logps_train/chosen': '-46.433', 'loss/train': '0.097898', 'examples_per_second': '5.8087', 'grad_norm': '9.9375', 'counters/examples': 13312, 'counters/updates': 832}
skipping logging after 13328 examples to avoid logging too frequently
skipping logging after 13344 examples to avoid logging too frequently
skipping logging after 13360 examples to avoid logging too frequently
train stats after 13376 examples: {'rewards_train/chosen': '-1.0844', 'rewards_train/rejected': '-7.3078', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.2213', 'logps_train/rejected': '-192.24', 'logps_train/chosen': '-48.853', 'loss/train': '0.11057', 'examples_per_second': '5.9338', 'grad_norm': '11.625', 'counters/examples': 13376, 'counters/updates': 836}
skipping logging after 13392 examples to avoid logging too frequently
skipping logging after 13408 examples to avoid logging too frequently
skipping logging after 13424 examples to avoid logging too frequently
train stats after 13440 examples: {'rewards_train/chosen': '-0.91305', 'rewards_train/rejected': '-8.3156', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.3975', 'logps_train/rejected': '-257.39', 'logps_train/chosen': '-55.924', 'loss/train': '0.094197', 'examples_per_second': '4.3596', 'grad_norm': '10.375', 'counters/examples': 13440, 'counters/updates': 840}
skipping logging after 13456 examples to avoid logging too frequently
skipping logging after 13472 examples to avoid logging too frequently
skipping logging after 13488 examples to avoid logging too frequently
train stats after 13504 examples: {'rewards_train/chosen': '-1.2861', 'rewards_train/rejected': '-8.1409', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.8534', 'logps_train/rejected': '-220.34', 'logps_train/chosen': '-58.293', 'loss/train': '0.10471', 'examples_per_second': '4.5041', 'grad_norm': '10.438', 'counters/examples': 13504, 'counters/updates': 844}
skipping logging after 13520 examples to avoid logging too frequently
skipping logging after 13536 examples to avoid logging too frequently
skipping logging after 13552 examples to avoid logging too frequently
train stats after 13568 examples: {'rewards_train/chosen': '-1.4909', 'rewards_train/rejected': '-10.111', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.6187', 'logps_train/rejected': '-273.16', 'logps_train/chosen': '-56.29', 'loss/train': '0.049853', 'examples_per_second': '5.4693', 'grad_norm': '8.875', 'counters/examples': 13568, 'counters/updates': 848}
skipping logging after 13584 examples to avoid logging too frequently
skipping logging after 13600 examples to avoid logging too frequently
skipping logging after 13616 examples to avoid logging too frequently
train stats after 13632 examples: {'rewards_train/chosen': '-1.4298', 'rewards_train/rejected': '-9.0102', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.5817', 'logps_train/rejected': '-222.37', 'logps_train/chosen': '-47.748', 'loss/train': '0.10231', 'examples_per_second': '4.816', 'grad_norm': '9.875', 'counters/examples': 13632, 'counters/updates': 852}
skipping logging after 13648 examples to avoid logging too frequently
skipping logging after 13664 examples to avoid logging too frequently
skipping logging after 13680 examples to avoid logging too frequently
train stats after 13696 examples: {'rewards_train/chosen': '-1.4235', 'rewards_train/rejected': '-10.479', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.0536', 'logps_train/rejected': '-277.15', 'logps_train/chosen': '-63.812', 'loss/train': '0.067864', 'examples_per_second': '4.5837', 'grad_norm': '16.25', 'counters/examples': 13696, 'counters/updates': 856}
skipping logging after 13712 examples to avoid logging too frequently
skipping logging after 13728 examples to avoid logging too frequently
skipping logging after 13744 examples to avoid logging too frequently
train stats after 13760 examples: {'rewards_train/chosen': '-1.4505', 'rewards_train/rejected': '-9.4746', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.0207', 'logps_train/rejected': '-237.54', 'logps_train/chosen': '-67.531', 'loss/train': '0.19999', 'examples_per_second': '4.9916', 'grad_norm': '25.125', 'counters/examples': 13760, 'counters/updates': 860}
skipping logging after 13776 examples to avoid logging too frequently
skipping logging after 13792 examples to avoid logging too frequently
skipping logging after 13808 examples to avoid logging too frequently
train stats after 13824 examples: {'rewards_train/chosen': '-1.4042', 'rewards_train/rejected': '-7.8446', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '6.4389', 'logps_train/rejected': '-208.01', 'logps_train/chosen': '-56.14', 'loss/train': '0.14805', 'examples_per_second': '5.4713', 'grad_norm': '15.438', 'counters/examples': 13824, 'counters/updates': 864}
skipping logging after 13840 examples to avoid logging too frequently
skipping logging after 13856 examples to avoid logging too frequently
skipping logging after 13872 examples to avoid logging too frequently
train stats after 13888 examples: {'rewards_train/chosen': '-0.9889', 'rewards_train/rejected': '-8.6388', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.6503', 'logps_train/rejected': '-247.13', 'logps_train/chosen': '-53.71', 'loss/train': '0.066232', 'examples_per_second': '5.866', 'grad_norm': '7.8438', 'counters/examples': 13888, 'counters/updates': 868}
skipping logging after 13904 examples to avoid logging too frequently
skipping logging after 13920 examples to avoid logging too frequently
skipping logging after 13936 examples to avoid logging too frequently
train stats after 13952 examples: {'rewards_train/chosen': '-1.2048', 'rewards_train/rejected': '-7.6829', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.4775', 'logps_train/rejected': '-203.37', 'logps_train/chosen': '-47.175', 'loss/train': '0.13614', 'examples_per_second': '5.0463', 'grad_norm': '10.062', 'counters/examples': 13952, 'counters/updates': 872}
skipping logging after 13968 examples to avoid logging too frequently
skipping logging after 13984 examples to avoid logging too frequently
skipping logging after 14000 examples to avoid logging too frequently
train stats after 14016 examples: {'rewards_train/chosen': '-1.1069', 'rewards_train/rejected': '-8.5586', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.4521', 'logps_train/rejected': '-253.58', 'logps_train/chosen': '-61.646', 'loss/train': '0.087946', 'examples_per_second': '4.6591', 'grad_norm': '4.75', 'counters/examples': 14016, 'counters/updates': 876}
skipping logging after 14032 examples to avoid logging too frequently
skipping logging after 14048 examples to avoid logging too frequently
skipping logging after 14064 examples to avoid logging too frequently
train stats after 14080 examples: {'rewards_train/chosen': '-1.286', 'rewards_train/rejected': '-7.9399', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.6512', 'logps_train/rejected': '-208.38', 'logps_train/chosen': '-54.692', 'loss/train': '0.16762', 'examples_per_second': '4.8843', 'grad_norm': '15.375', 'counters/examples': 14080, 'counters/updates': 880}
skipping logging after 14096 examples to avoid logging too frequently
skipping logging after 14112 examples to avoid logging too frequently
skipping logging after 14128 examples to avoid logging too frequently
train stats after 14144 examples: {'rewards_train/chosen': '-1.1107', 'rewards_train/rejected': '-7.9487', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.8376', 'logps_train/rejected': '-209.38', 'logps_train/chosen': '-52.011', 'loss/train': '0.084236', 'examples_per_second': '4.6058', 'grad_norm': '9.5625', 'counters/examples': 14144, 'counters/updates': 884}
skipping logging after 14160 examples to avoid logging too frequently
skipping logging after 14176 examples to avoid logging too frequently
skipping logging after 14192 examples to avoid logging too frequently
train stats after 14208 examples: {'rewards_train/chosen': '-1.1711', 'rewards_train/rejected': '-7.3841', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.2144', 'logps_train/rejected': '-200.48', 'logps_train/chosen': '-49.984', 'loss/train': '0.21876', 'examples_per_second': '4.9654', 'grad_norm': '11.375', 'counters/examples': 14208, 'counters/updates': 888}
skipping logging after 14224 examples to avoid logging too frequently
skipping logging after 14240 examples to avoid logging too frequently
skipping logging after 14256 examples to avoid logging too frequently
train stats after 14272 examples: {'rewards_train/chosen': '-0.88418', 'rewards_train/rejected': '-7.3037', 'rewards_train/accuracies': '1', 'rewards_train/margins': '6.4192', 'logps_train/rejected': '-214.98', 'logps_train/chosen': '-46.125', 'loss/train': '0.056456', 'examples_per_second': '5.1805', 'grad_norm': '7.0312', 'counters/examples': 14272, 'counters/updates': 892}
skipping logging after 14288 examples to avoid logging too frequently
skipping logging after 14304 examples to avoid logging too frequently
skipping logging after 14320 examples to avoid logging too frequently
train stats after 14336 examples: {'rewards_train/chosen': '-1.4166', 'rewards_train/rejected': '-7.3326', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '5.9142', 'logps_train/rejected': '-187.45', 'logps_train/chosen': '-46.997', 'loss/train': '0.11548', 'examples_per_second': '5.3983', 'grad_norm': '9.5', 'counters/examples': 14336, 'counters/updates': 896}
skipping logging after 14352 examples to avoid logging too frequently
skipping logging after 14368 examples to avoid logging too frequently
skipping logging after 14384 examples to avoid logging too frequently
train stats after 14400 examples: {'rewards_train/chosen': '-0.93419', 'rewards_train/rejected': '-7.1672', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.2341', 'logps_train/rejected': '-209.02', 'logps_train/chosen': '-46.283', 'loss/train': '0.08053', 'examples_per_second': '4.4434', 'grad_norm': '6.7188', 'counters/examples': 14400, 'counters/updates': 900}
skipping logging after 14416 examples to avoid logging too frequently
skipping logging after 14432 examples to avoid logging too frequently
skipping logging after 14448 examples to avoid logging too frequently
train stats after 14464 examples: {'rewards_train/chosen': '-0.9972', 'rewards_train/rejected': '-7.1704', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.1726', 'logps_train/rejected': '-190.69', 'logps_train/chosen': '-52.293', 'loss/train': '0.11756', 'examples_per_second': '5.0063', 'grad_norm': '7.0625', 'counters/examples': 14464, 'counters/updates': 904}
skipping logging after 14480 examples to avoid logging too frequently
skipping logging after 14496 examples to avoid logging too frequently
skipping logging after 14512 examples to avoid logging too frequently
train stats after 14528 examples: {'rewards_train/chosen': '-0.83742', 'rewards_train/rejected': '-8.7544', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.9155', 'logps_train/rejected': '-256.59', 'logps_train/chosen': '-57.346', 'loss/train': '0.077235', 'examples_per_second': '5.463', 'grad_norm': '13.062', 'counters/examples': 14528, 'counters/updates': 908}
skipping logging after 14544 examples to avoid logging too frequently
skipping logging after 14560 examples to avoid logging too frequently
skipping logging after 14576 examples to avoid logging too frequently
train stats after 14592 examples: {'rewards_train/chosen': '-1.0935', 'rewards_train/rejected': '-6.9357', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '5.8414', 'logps_train/rejected': '-218.42', 'logps_train/chosen': '-51.171', 'loss/train': '0.1238', 'examples_per_second': '4.9823', 'grad_norm': '7.625', 'counters/examples': 14592, 'counters/updates': 912}
skipping logging after 14608 examples to avoid logging too frequently
skipping logging after 14624 examples to avoid logging too frequently
skipping logging after 14640 examples to avoid logging too frequently
train stats after 14656 examples: {'rewards_train/chosen': '-0.8165', 'rewards_train/rejected': '-7.1289', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.314', 'logps_train/rejected': '-213.93', 'logps_train/chosen': '-55.805', 'loss/train': '0.099455', 'examples_per_second': '4.7757', 'grad_norm': '9.9375', 'counters/examples': 14656, 'counters/updates': 916}
skipping logging after 14672 examples to avoid logging too frequently
skipping logging after 14688 examples to avoid logging too frequently
skipping logging after 14704 examples to avoid logging too frequently
train stats after 14720 examples: {'rewards_train/chosen': '-0.90276', 'rewards_train/rejected': '-6.9288', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.0253', 'logps_train/rejected': '-208.53', 'logps_train/chosen': '-51.856', 'loss/train': '0.064225', 'examples_per_second': '5.3825', 'grad_norm': '6.375', 'counters/examples': 14720, 'counters/updates': 920}
skipping logging after 14736 examples to avoid logging too frequently
skipping logging after 14752 examples to avoid logging too frequently
skipping logging after 14768 examples to avoid logging too frequently
train stats after 14784 examples: {'rewards_train/chosen': '-1.1366', 'rewards_train/rejected': '-7.2355', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.0977', 'logps_train/rejected': '-206.78', 'logps_train/chosen': '-59.222', 'loss/train': '0.15548', 'examples_per_second': '5.2714', 'grad_norm': '18', 'counters/examples': 14784, 'counters/updates': 924}
skipping logging after 14800 examples to avoid logging too frequently
skipping logging after 14816 examples to avoid logging too frequently
skipping logging after 14832 examples to avoid logging too frequently
train stats after 14848 examples: {'rewards_train/chosen': '-0.8844', 'rewards_train/rejected': '-7.0256', 'rewards_train/accuracies': '1', 'rewards_train/margins': '6.1434', 'logps_train/rejected': '-195.25', 'logps_train/chosen': '-51.308', 'loss/train': '0.056495', 'examples_per_second': '4.6979', 'grad_norm': '5.9375', 'counters/examples': 14848, 'counters/updates': 928}
skipping logging after 14864 examples to avoid logging too frequently
skipping logging after 14880 examples to avoid logging too frequently
skipping logging after 14896 examples to avoid logging too frequently
train stats after 14912 examples: {'rewards_train/chosen': '-1.0876', 'rewards_train/rejected': '-7.2583', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.1708', 'logps_train/rejected': '-222.26', 'logps_train/chosen': '-51.416', 'loss/train': '0.1078', 'examples_per_second': '5.0915', 'grad_norm': '8.3125', 'counters/examples': 14912, 'counters/updates': 932}
skipping logging after 14928 examples to avoid logging too frequently
skipping logging after 14944 examples to avoid logging too frequently
skipping logging after 14960 examples to avoid logging too frequently
train stats after 14976 examples: {'rewards_train/chosen': '-1.2289', 'rewards_train/rejected': '-7.4726', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '6.2428', 'logps_train/rejected': '-222.07', 'logps_train/chosen': '-55.795', 'loss/train': '0.14808', 'examples_per_second': '4.3857', 'grad_norm': '12.5', 'counters/examples': 14976, 'counters/updates': 936}
skipping logging after 14992 examples to avoid logging too frequently
skipping logging after 15008 examples to avoid logging too frequently
skipping logging after 15024 examples to avoid logging too frequently
train stats after 15040 examples: {'rewards_train/chosen': '-1.2927', 'rewards_train/rejected': '-8.1326', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.8384', 'logps_train/rejected': '-218.93', 'logps_train/chosen': '-59.63', 'loss/train': '0.046184', 'examples_per_second': '5.9332', 'grad_norm': '7.8438', 'counters/examples': 15040, 'counters/updates': 940}
skipping logging after 15056 examples to avoid logging too frequently
skipping logging after 15072 examples to avoid logging too frequently
skipping logging after 15088 examples to avoid logging too frequently
train stats after 15104 examples: {'rewards_train/chosen': '-1.5632', 'rewards_train/rejected': '-7.9182', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.3535', 'logps_train/rejected': '-210.97', 'logps_train/chosen': '-54.076', 'loss/train': '0.24457', 'examples_per_second': '6.1942', 'grad_norm': '23.25', 'counters/examples': 15104, 'counters/updates': 944}
skipping logging after 15120 examples to avoid logging too frequently
skipping logging after 15136 examples to avoid logging too frequently
skipping logging after 15152 examples to avoid logging too frequently
train stats after 15168 examples: {'rewards_train/chosen': '-1.1828', 'rewards_train/rejected': '-7.8049', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.6232', 'logps_train/rejected': '-195.21', 'logps_train/chosen': '-54.013', 'loss/train': '0.085924', 'examples_per_second': '4.7695', 'grad_norm': '7.7812', 'counters/examples': 15168, 'counters/updates': 948}
skipping logging after 15184 examples to avoid logging too frequently
skipping logging after 15200 examples to avoid logging too frequently
skipping logging after 15216 examples to avoid logging too frequently
train stats after 15232 examples: {'rewards_train/chosen': '-1.182', 'rewards_train/rejected': '-8.265', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.0828', 'logps_train/rejected': '-249.33', 'logps_train/chosen': '-52.256', 'loss/train': '0.042714', 'examples_per_second': '4.7804', 'grad_norm': '4.375', 'counters/examples': 15232, 'counters/updates': 952}
skipping logging after 15248 examples to avoid logging too frequently
skipping logging after 15264 examples to avoid logging too frequently
skipping logging after 15280 examples to avoid logging too frequently
train stats after 15296 examples: {'rewards_train/chosen': '-1.217', 'rewards_train/rejected': '-7.7264', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.5106', 'logps_train/rejected': '-194.87', 'logps_train/chosen': '-51.699', 'loss/train': '0.10972', 'examples_per_second': '4.9792', 'grad_norm': '11.875', 'counters/examples': 15296, 'counters/updates': 956}
skipping logging after 15312 examples to avoid logging too frequently
skipping logging after 15328 examples to avoid logging too frequently
skipping logging after 15344 examples to avoid logging too frequently
train stats after 15360 examples: {'rewards_train/chosen': '-0.88973', 'rewards_train/rejected': '-6.9731', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.0811', 'logps_train/rejected': '-203.11', 'logps_train/chosen': '-51.775', 'loss/train': '0.1052', 'examples_per_second': '5.2254', 'grad_norm': '12.688', 'counters/examples': 15360, 'counters/updates': 960}
skipping logging after 15376 examples to avoid logging too frequently
skipping logging after 15392 examples to avoid logging too frequently
skipping logging after 15408 examples to avoid logging too frequently
train stats after 15424 examples: {'rewards_train/chosen': '-1.0397', 'rewards_train/rejected': '-7.2053', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.1654', 'logps_train/rejected': '-196.18', 'logps_train/chosen': '-49.133', 'loss/train': '0.088868', 'examples_per_second': '4.5068', 'grad_norm': '6.8438', 'counters/examples': 15424, 'counters/updates': 964}
skipping logging after 15440 examples to avoid logging too frequently
skipping logging after 15456 examples to avoid logging too frequently
skipping logging after 15472 examples to avoid logging too frequently
train stats after 15488 examples: {'rewards_train/chosen': '-1.3737', 'rewards_train/rejected': '-8.1792', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.8033', 'logps_train/rejected': '-231.2', 'logps_train/chosen': '-60.231', 'loss/train': '0.075975', 'examples_per_second': '4.5694', 'grad_norm': '13.25', 'counters/examples': 15488, 'counters/updates': 968}
skipping logging after 15504 examples to avoid logging too frequently
skipping logging after 15520 examples to avoid logging too frequently
skipping logging after 15536 examples to avoid logging too frequently
train stats after 15552 examples: {'rewards_train/chosen': '-0.7989', 'rewards_train/rejected': '-8.1888', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.3917', 'logps_train/rejected': '-250.32', 'logps_train/chosen': '-49.004', 'loss/train': '0.057879', 'examples_per_second': '5.9525', 'grad_norm': '7.0938', 'counters/examples': 15552, 'counters/updates': 972}
skipping logging after 15568 examples to avoid logging too frequently
skipping logging after 15584 examples to avoid logging too frequently
skipping logging after 15600 examples to avoid logging too frequently
train stats after 15616 examples: {'rewards_train/chosen': '-1.241', 'rewards_train/rejected': '-7.7212', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.4819', 'logps_train/rejected': '-219.04', 'logps_train/chosen': '-49.863', 'loss/train': '0.095656', 'examples_per_second': '5.1465', 'grad_norm': '10.625', 'counters/examples': 15616, 'counters/updates': 976}
skipping logging after 15632 examples to avoid logging too frequently
skipping logging after 15648 examples to avoid logging too frequently
skipping logging after 15664 examples to avoid logging too frequently
train stats after 15680 examples: {'rewards_train/chosen': '-0.98194', 'rewards_train/rejected': '-7.4803', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.498', 'logps_train/rejected': '-215.7', 'logps_train/chosen': '-44.93', 'loss/train': '0.084981', 'examples_per_second': '5.3836', 'grad_norm': '6.375', 'counters/examples': 15680, 'counters/updates': 980}
skipping logging after 15696 examples to avoid logging too frequently
skipping logging after 15712 examples to avoid logging too frequently
skipping logging after 15728 examples to avoid logging too frequently
train stats after 15744 examples: {'rewards_train/chosen': '-1.5137', 'rewards_train/rejected': '-8.1738', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.6594', 'logps_train/rejected': '-213.28', 'logps_train/chosen': '-68.706', 'loss/train': '0.26542', 'examples_per_second': '4.9594', 'grad_norm': '22.5', 'counters/examples': 15744, 'counters/updates': 984}
skipping logging after 15760 examples to avoid logging too frequently
skipping logging after 15776 examples to avoid logging too frequently
skipping logging after 15792 examples to avoid logging too frequently
train stats after 15808 examples: {'rewards_train/chosen': '-1.3851', 'rewards_train/rejected': '-6.4719', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '5.0876', 'logps_train/rejected': '-180.67', 'logps_train/chosen': '-45.763', 'loss/train': '0.11506', 'examples_per_second': '6.2614', 'grad_norm': '15.125', 'counters/examples': 15808, 'counters/updates': 988}
skipping logging after 15824 examples to avoid logging too frequently
skipping logging after 15840 examples to avoid logging too frequently
skipping logging after 15856 examples to avoid logging too frequently
train stats after 15872 examples: {'rewards_train/chosen': '-1.169', 'rewards_train/rejected': '-8.2776', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.1089', 'logps_train/rejected': '-262.4', 'logps_train/chosen': '-51.646', 'loss/train': '0.046969', 'examples_per_second': '4.7511', 'grad_norm': '5.9688', 'counters/examples': 15872, 'counters/updates': 992}
skipping logging after 15888 examples to avoid logging too frequently
skipping logging after 15904 examples to avoid logging too frequently
skipping logging after 15920 examples to avoid logging too frequently
train stats after 15936 examples: {'rewards_train/chosen': '-1.4961', 'rewards_train/rejected': '-8.9987', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.5049', 'logps_train/rejected': '-272.04', 'logps_train/chosen': '-56.6', 'loss/train': '0.062946', 'examples_per_second': '3.9635', 'grad_norm': '9.8125', 'counters/examples': 15936, 'counters/updates': 996}
skipping logging after 15952 examples to avoid logging too frequently
skipping logging after 15968 examples to avoid logging too frequently
skipping logging after 15984 examples to avoid logging too frequently
train stats after 16000 examples: {'rewards_train/chosen': '-1.7404', 'rewards_train/rejected': '-8.0249', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.2845', 'logps_train/rejected': '-214.53', 'logps_train/chosen': '-67.592', 'loss/train': '0.16597', 'examples_per_second': '5.3487', 'grad_norm': '8.3125', 'counters/examples': 16000, 'counters/updates': 1000}
Running evaluation after 16000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<01:00,  1.95s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:00,  2.02s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:53,  1.84s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.86s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.52s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.50s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.29s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.24s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.33s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.34s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.27s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.29s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.26s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.30s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.48s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.41s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.61s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.42s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.41s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 16000: {'rewards_eval/chosen': '-7.6078', 'rewards_eval/rejected': '-7.8576', 'rewards_eval/accuracies': '0.50586', 'rewards_eval/margins': '0.25', 'logps_eval/rejected': '-226.23', 'logps_eval/chosen': '-221', 'loss/eval': '1.8149'}
skipping logging after 16016 examples to avoid logging too frequently
skipping logging after 16032 examples to avoid logging too frequently
skipping logging after 16048 examples to avoid logging too frequently
train stats after 16064 examples: {'rewards_train/chosen': '-1.193', 'rewards_train/rejected': '-7.1941', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '5.9997', 'logps_train/rejected': '-189.85', 'logps_train/chosen': '-50.445', 'loss/train': '0.083782', 'examples_per_second': '5.4981', 'grad_norm': '5.1875', 'counters/examples': 16064, 'counters/updates': 1004}
skipping logging after 16080 examples to avoid logging too frequently
skipping logging after 16096 examples to avoid logging too frequently
skipping logging after 16112 examples to avoid logging too frequently
train stats after 16128 examples: {'rewards_train/chosen': '-1.3425', 'rewards_train/rejected': '-6.7875', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '5.4474', 'logps_train/rejected': '-183.21', 'logps_train/chosen': '-56.058', 'loss/train': '0.084847', 'examples_per_second': '5.0775', 'grad_norm': '6.4688', 'counters/examples': 16128, 'counters/updates': 1008}
skipping logging after 16144 examples to avoid logging too frequently
skipping logging after 16160 examples to avoid logging too frequently
skipping logging after 16176 examples to avoid logging too frequently
train stats after 16192 examples: {'rewards_train/chosen': '-1.5483', 'rewards_train/rejected': '-8.8903', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.3419', 'logps_train/rejected': '-226.38', 'logps_train/chosen': '-54.023', 'loss/train': '0.082095', 'examples_per_second': '4.2099', 'grad_norm': '8.25', 'counters/examples': 16192, 'counters/updates': 1012}
skipping logging after 16208 examples to avoid logging too frequently
skipping logging after 16224 examples to avoid logging too frequently
skipping logging after 16240 examples to avoid logging too frequently
train stats after 16256 examples: {'rewards_train/chosen': '-1.4217', 'rewards_train/rejected': '-9.2066', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.7841', 'logps_train/rejected': '-256.16', 'logps_train/chosen': '-56.373', 'loss/train': '0.11015', 'examples_per_second': '4.1373', 'grad_norm': '15.812', 'counters/examples': 16256, 'counters/updates': 1016}
skipping logging after 16272 examples to avoid logging too frequently
skipping logging after 16288 examples to avoid logging too frequently
skipping logging after 16304 examples to avoid logging too frequently
train stats after 16320 examples: {'rewards_train/chosen': '-1.2428', 'rewards_train/rejected': '-7.1084', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '5.8657', 'logps_train/rejected': '-192.13', 'logps_train/chosen': '-51.092', 'loss/train': '0.11726', 'examples_per_second': '5.987', 'grad_norm': '10.062', 'counters/examples': 16320, 'counters/updates': 1020}
skipping logging after 16336 examples to avoid logging too frequently
skipping logging after 16352 examples to avoid logging too frequently
skipping logging after 16368 examples to avoid logging too frequently
train stats after 16384 examples: {'rewards_train/chosen': '-1.3619', 'rewards_train/rejected': '-7.0587', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '5.6973', 'logps_train/rejected': '-198.25', 'logps_train/chosen': '-47.391', 'loss/train': '0.14356', 'examples_per_second': '5.518', 'grad_norm': '9.25', 'counters/examples': 16384, 'counters/updates': 1024}
skipping logging after 16400 examples to avoid logging too frequently
skipping logging after 16416 examples to avoid logging too frequently
skipping logging after 16432 examples to avoid logging too frequently
train stats after 16448 examples: {'rewards_train/chosen': '-1.1184', 'rewards_train/rejected': '-7.6067', 'rewards_train/accuracies': '1', 'rewards_train/margins': '6.488', 'logps_train/rejected': '-210.94', 'logps_train/chosen': '-59.241', 'loss/train': '0.033413', 'examples_per_second': '6.3139', 'grad_norm': '4.5312', 'counters/examples': 16448, 'counters/updates': 1028}
skipping logging after 16464 examples to avoid logging too frequently
skipping logging after 16480 examples to avoid logging too frequently
skipping logging after 16496 examples to avoid logging too frequently
train stats after 16512 examples: {'rewards_train/chosen': '-1.257', 'rewards_train/rejected': '-8.5808', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.3254', 'logps_train/rejected': '-237.8', 'logps_train/chosen': '-52.528', 'loss/train': '0.035329', 'examples_per_second': '4.7331', 'grad_norm': '4.4062', 'counters/examples': 16512, 'counters/updates': 1032}
skipping logging after 16528 examples to avoid logging too frequently
skipping logging after 16544 examples to avoid logging too frequently
skipping logging after 16560 examples to avoid logging too frequently
train stats after 16576 examples: {'rewards_train/chosen': '-1.2914', 'rewards_train/rejected': '-8.8886', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.5992', 'logps_train/rejected': '-232.25', 'logps_train/chosen': '-54.719', 'loss/train': '0.099143', 'examples_per_second': '4.7693', 'grad_norm': '8.625', 'counters/examples': 16576, 'counters/updates': 1036}
skipping logging after 16592 examples to avoid logging too frequently
skipping logging after 16608 examples to avoid logging too frequently
skipping logging after 16624 examples to avoid logging too frequently
train stats after 16640 examples: {'rewards_train/chosen': '-1.6465', 'rewards_train/rejected': '-7.7039', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.0574', 'logps_train/rejected': '-202.84', 'logps_train/chosen': '-56.33', 'loss/train': '0.077747', 'examples_per_second': '5.9666', 'grad_norm': '8.875', 'counters/examples': 16640, 'counters/updates': 1040}
skipping logging after 16656 examples to avoid logging too frequently
skipping logging after 16672 examples to avoid logging too frequently
skipping logging after 16688 examples to avoid logging too frequently
train stats after 16704 examples: {'rewards_train/chosen': '-1.4354', 'rewards_train/rejected': '-10.302', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.8665', 'logps_train/rejected': '-248.83', 'logps_train/chosen': '-55.178', 'loss/train': '0.070494', 'examples_per_second': '4.6784', 'grad_norm': '12.188', 'counters/examples': 16704, 'counters/updates': 1044}
skipping logging after 16720 examples to avoid logging too frequently
skipping logging after 16736 examples to avoid logging too frequently
skipping logging after 16752 examples to avoid logging too frequently
train stats after 16768 examples: {'rewards_train/chosen': '-1.8848', 'rewards_train/rejected': '-8.7456', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '6.8595', 'logps_train/rejected': '-221.68', 'logps_train/chosen': '-60.06', 'loss/train': '0.23786', 'examples_per_second': '5.4781', 'grad_norm': '20.125', 'counters/examples': 16768, 'counters/updates': 1048}
skipping logging after 16784 examples to avoid logging too frequently
skipping logging after 16800 examples to avoid logging too frequently
skipping logging after 16816 examples to avoid logging too frequently
train stats after 16832 examples: {'rewards_train/chosen': '-1.3433', 'rewards_train/rejected': '-7.3041', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '5.9606', 'logps_train/rejected': '-189.58', 'logps_train/chosen': '-52.081', 'loss/train': '0.13165', 'examples_per_second': '5.4484', 'grad_norm': '13.562', 'counters/examples': 16832, 'counters/updates': 1052}
skipping logging after 16848 examples to avoid logging too frequently
skipping logging after 16864 examples to avoid logging too frequently
skipping logging after 16880 examples to avoid logging too frequently
train stats after 16896 examples: {'rewards_train/chosen': '-0.93797', 'rewards_train/rejected': '-8.4445', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.5073', 'logps_train/rejected': '-268.01', 'logps_train/chosen': '-46.72', 'loss/train': '0.030497', 'examples_per_second': '4.4222', 'grad_norm': '2.8906', 'counters/examples': 16896, 'counters/updates': 1056}
skipping logging after 16912 examples to avoid logging too frequently
skipping logging after 16928 examples to avoid logging too frequently
skipping logging after 16944 examples to avoid logging too frequently
train stats after 16960 examples: {'rewards_train/chosen': '-1.2911', 'rewards_train/rejected': '-8.4264', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.1348', 'logps_train/rejected': '-224.96', 'logps_train/chosen': '-47.506', 'loss/train': '0.049937', 'examples_per_second': '6.0048', 'grad_norm': '3.9375', 'counters/examples': 16960, 'counters/updates': 1060}
skipping logging after 16976 examples to avoid logging too frequently
skipping logging after 16992 examples to avoid logging too frequently
skipping logging after 17008 examples to avoid logging too frequently
train stats after 17024 examples: {'rewards_train/chosen': '-1.2831', 'rewards_train/rejected': '-8.6709', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.3882', 'logps_train/rejected': '-253.83', 'logps_train/chosen': '-51.189', 'loss/train': '0.033981', 'examples_per_second': '5.3408', 'grad_norm': '4.0312', 'counters/examples': 17024, 'counters/updates': 1064}
skipping logging after 17040 examples to avoid logging too frequently
skipping logging after 17056 examples to avoid logging too frequently
skipping logging after 17072 examples to avoid logging too frequently
train stats after 17088 examples: {'rewards_train/chosen': '-1.4925', 'rewards_train/rejected': '-7.8435', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.3489', 'logps_train/rejected': '-219.15', 'logps_train/chosen': '-61.553', 'loss/train': '0.19025', 'examples_per_second': '4.1193', 'grad_norm': '22.625', 'counters/examples': 17088, 'counters/updates': 1068}
skipping logging after 17104 examples to avoid logging too frequently
skipping logging after 17120 examples to avoid logging too frequently
skipping logging after 17136 examples to avoid logging too frequently
train stats after 17152 examples: {'rewards_train/chosen': '-1.6883', 'rewards_train/rejected': '-7.9625', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.2766', 'logps_train/rejected': '-188.73', 'logps_train/chosen': '-54.33', 'loss/train': '0.13898', 'examples_per_second': '5.9029', 'grad_norm': '12.75', 'counters/examples': 17152, 'counters/updates': 1072}
skipping logging after 17168 examples to avoid logging too frequently
skipping logging after 17184 examples to avoid logging too frequently
skipping logging after 17200 examples to avoid logging too frequently
train stats after 17216 examples: {'rewards_train/chosen': '-1.5565', 'rewards_train/rejected': '-9.6036', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.0491', 'logps_train/rejected': '-249.46', 'logps_train/chosen': '-46.998', 'loss/train': '0.054399', 'examples_per_second': '5.5809', 'grad_norm': '6.125', 'counters/examples': 17216, 'counters/updates': 1076}
skipping logging after 17232 examples to avoid logging too frequently
skipping logging after 17248 examples to avoid logging too frequently
skipping logging after 17264 examples to avoid logging too frequently
train stats after 17280 examples: {'rewards_train/chosen': '-1.3248', 'rewards_train/rejected': '-9.8143', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.4874', 'logps_train/rejected': '-251', 'logps_train/chosen': '-52.342', 'loss/train': '0.061225', 'examples_per_second': '4.9712', 'grad_norm': '8.0625', 'counters/examples': 17280, 'counters/updates': 1080}
skipping logging after 17296 examples to avoid logging too frequently
skipping logging after 17312 examples to avoid logging too frequently
skipping logging after 17328 examples to avoid logging too frequently
train stats after 17344 examples: {'rewards_train/chosen': '-1.5099', 'rewards_train/rejected': '-8.7637', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.2518', 'logps_train/rejected': '-204.91', 'logps_train/chosen': '-53.142', 'loss/train': '0.12123', 'examples_per_second': '6.0136', 'grad_norm': '13.812', 'counters/examples': 17344, 'counters/updates': 1084}
skipping logging after 17360 examples to avoid logging too frequently
skipping logging after 17376 examples to avoid logging too frequently
skipping logging after 17392 examples to avoid logging too frequently
train stats after 17408 examples: {'rewards_train/chosen': '-1.3211', 'rewards_train/rejected': '-8.9635', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.642', 'logps_train/rejected': '-236.07', 'logps_train/chosen': '-55.326', 'loss/train': '0.066109', 'examples_per_second': '5.2784', 'grad_norm': '7.75', 'counters/examples': 17408, 'counters/updates': 1088}
skipping logging after 17424 examples to avoid logging too frequently
skipping logging after 17440 examples to avoid logging too frequently
skipping logging after 17456 examples to avoid logging too frequently
train stats after 17472 examples: {'rewards_train/chosen': '-1.3923', 'rewards_train/rejected': '-7.8638', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.4714', 'logps_train/rejected': '-195.85', 'logps_train/chosen': '-57.134', 'loss/train': '0.076321', 'examples_per_second': '5.2656', 'grad_norm': '7.8438', 'counters/examples': 17472, 'counters/updates': 1092}
skipping logging after 17488 examples to avoid logging too frequently
skipping logging after 17504 examples to avoid logging too frequently
skipping logging after 17520 examples to avoid logging too frequently
train stats after 17536 examples: {'rewards_train/chosen': '-1.5631', 'rewards_train/rejected': '-8.494', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.9309', 'logps_train/rejected': '-210.71', 'logps_train/chosen': '-55.301', 'loss/train': '0.097224', 'examples_per_second': '5.3747', 'grad_norm': '11', 'counters/examples': 17536, 'counters/updates': 1096}
skipping logging after 17552 examples to avoid logging too frequently
skipping logging after 17568 examples to avoid logging too frequently
skipping logging after 17584 examples to avoid logging too frequently
train stats after 17600 examples: {'rewards_train/chosen': '-1.7058', 'rewards_train/rejected': '-8.9403', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.2354', 'logps_train/rejected': '-223.98', 'logps_train/chosen': '-56.526', 'loss/train': '0.084232', 'examples_per_second': '5.8722', 'grad_norm': '9', 'counters/examples': 17600, 'counters/updates': 1100}
skipping logging after 17616 examples to avoid logging too frequently
skipping logging after 17632 examples to avoid logging too frequently
skipping logging after 17648 examples to avoid logging too frequently
train stats after 17664 examples: {'rewards_train/chosen': '-1.9099', 'rewards_train/rejected': '-10.309', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.3977', 'logps_train/rejected': '-236.4', 'logps_train/chosen': '-57.843', 'loss/train': '0.096721', 'examples_per_second': '4.444', 'grad_norm': '13.875', 'counters/examples': 17664, 'counters/updates': 1104}
skipping logging after 17680 examples to avoid logging too frequently
skipping logging after 17696 examples to avoid logging too frequently
skipping logging after 17712 examples to avoid logging too frequently
train stats after 17728 examples: {'rewards_train/chosen': '-1.5972', 'rewards_train/rejected': '-8.7466', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.1501', 'logps_train/rejected': '-217.79', 'logps_train/chosen': '-54.998', 'loss/train': '0.056273', 'examples_per_second': '4.723', 'grad_norm': '6.125', 'counters/examples': 17728, 'counters/updates': 1108}
skipping logging after 17744 examples to avoid logging too frequently
skipping logging after 17760 examples to avoid logging too frequently
skipping logging after 17776 examples to avoid logging too frequently
train stats after 17792 examples: {'rewards_train/chosen': '-1.3128', 'rewards_train/rejected': '-9.7416', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.4249', 'logps_train/rejected': '-249.89', 'logps_train/chosen': '-55.214', 'loss/train': '0.055748', 'examples_per_second': '5.213', 'grad_norm': '9.375', 'counters/examples': 17792, 'counters/updates': 1112}
skipping logging after 17808 examples to avoid logging too frequently
skipping logging after 17824 examples to avoid logging too frequently
skipping logging after 17840 examples to avoid logging too frequently
train stats after 17856 examples: {'rewards_train/chosen': '-1.5754', 'rewards_train/rejected': '-8.1968', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.6232', 'logps_train/rejected': '-193.3', 'logps_train/chosen': '-52.97', 'loss/train': '0.084299', 'examples_per_second': '5.1253', 'grad_norm': '12.938', 'counters/examples': 17856, 'counters/updates': 1116}
skipping logging after 17872 examples to avoid logging too frequently
skipping logging after 17888 examples to avoid logging too frequently
skipping logging after 17904 examples to avoid logging too frequently
train stats after 17920 examples: {'rewards_train/chosen': '-1.4545', 'rewards_train/rejected': '-8.2689', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.8102', 'logps_train/rejected': '-216.16', 'logps_train/chosen': '-48.063', 'loss/train': '0.11983', 'examples_per_second': '5.842', 'grad_norm': '11.688', 'counters/examples': 17920, 'counters/updates': 1120}
skipping logging after 17936 examples to avoid logging too frequently
skipping logging after 17952 examples to avoid logging too frequently
skipping logging after 17968 examples to avoid logging too frequently
train stats after 17984 examples: {'rewards_train/chosen': '-1.6525', 'rewards_train/rejected': '-9.2234', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.5679', 'logps_train/rejected': '-227.06', 'logps_train/chosen': '-57.445', 'loss/train': '0.075777', 'examples_per_second': '4.6453', 'grad_norm': '10.625', 'counters/examples': 17984, 'counters/updates': 1124}
skipping logging after 18000 examples to avoid logging too frequently
skipping logging after 18016 examples to avoid logging too frequently
skipping logging after 18032 examples to avoid logging too frequently
train stats after 18048 examples: {'rewards_train/chosen': '-1.2161', 'rewards_train/rejected': '-8.5239', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.308', 'logps_train/rejected': '-242.84', 'logps_train/chosen': '-60.442', 'loss/train': '0.072983', 'examples_per_second': '5.5874', 'grad_norm': '11.062', 'counters/examples': 18048, 'counters/updates': 1128}
skipping logging after 18064 examples to avoid logging too frequently
skipping logging after 18080 examples to avoid logging too frequently
skipping logging after 18096 examples to avoid logging too frequently
train stats after 18112 examples: {'rewards_train/chosen': '-1.2102', 'rewards_train/rejected': '-7.9362', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.7287', 'logps_train/rejected': '-198.62', 'logps_train/chosen': '-44.925', 'loss/train': '0.09086', 'examples_per_second': '5.3409', 'grad_norm': '9.0625', 'counters/examples': 18112, 'counters/updates': 1132}
skipping logging after 18128 examples to avoid logging too frequently
skipping logging after 18144 examples to avoid logging too frequently
skipping logging after 18160 examples to avoid logging too frequently
train stats after 18176 examples: {'rewards_train/chosen': '-0.86107', 'rewards_train/rejected': '-6.5071', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '5.647', 'logps_train/rejected': '-173.43', 'logps_train/chosen': '-39.885', 'loss/train': '0.048351', 'examples_per_second': '5.6425', 'grad_norm': '5.9375', 'counters/examples': 18176, 'counters/updates': 1136}
skipping logging after 18192 examples to avoid logging too frequently
skipping logging after 18208 examples to avoid logging too frequently
skipping logging after 18224 examples to avoid logging too frequently
train stats after 18240 examples: {'rewards_train/chosen': '-1.2001', 'rewards_train/rejected': '-8.5107', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.3075', 'logps_train/rejected': '-214.64', 'logps_train/chosen': '-50.391', 'loss/train': '0.088668', 'examples_per_second': '5.2866', 'grad_norm': '8.5625', 'counters/examples': 18240, 'counters/updates': 1140}
skipping logging after 18256 examples to avoid logging too frequently
skipping logging after 18272 examples to avoid logging too frequently
skipping logging after 18288 examples to avoid logging too frequently
train stats after 18304 examples: {'rewards_train/chosen': '-0.98761', 'rewards_train/rejected': '-7.8511', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.8627', 'logps_train/rejected': '-210.51', 'logps_train/chosen': '-51.874', 'loss/train': '0.11666', 'examples_per_second': '5.5118', 'grad_norm': '11.75', 'counters/examples': 18304, 'counters/updates': 1144}
skipping logging after 18320 examples to avoid logging too frequently
skipping logging after 18336 examples to avoid logging too frequently
skipping logging after 18352 examples to avoid logging too frequently
train stats after 18368 examples: {'rewards_train/chosen': '-1.276', 'rewards_train/rejected': '-7.903', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.6278', 'logps_train/rejected': '-205.55', 'logps_train/chosen': '-52.601', 'loss/train': '0.074812', 'examples_per_second': '5.7871', 'grad_norm': '14.875', 'counters/examples': 18368, 'counters/updates': 1148}
skipping logging after 18384 examples to avoid logging too frequently
skipping logging after 18400 examples to avoid logging too frequently
skipping logging after 18416 examples to avoid logging too frequently
train stats after 18432 examples: {'rewards_train/chosen': '-1.1934', 'rewards_train/rejected': '-7.9473', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.7536', 'logps_train/rejected': '-224.7', 'logps_train/chosen': '-53.24', 'loss/train': '0.14264', 'examples_per_second': '4.8224', 'grad_norm': '13.438', 'counters/examples': 18432, 'counters/updates': 1152}
skipping logging after 18448 examples to avoid logging too frequently
skipping logging after 18464 examples to avoid logging too frequently
skipping logging after 18480 examples to avoid logging too frequently
train stats after 18496 examples: {'rewards_train/chosen': '-0.68301', 'rewards_train/rejected': '-7.4244', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.7416', 'logps_train/rejected': '-221.8', 'logps_train/chosen': '-48.992', 'loss/train': '0.088967', 'examples_per_second': '5.7084', 'grad_norm': '7.9375', 'counters/examples': 18496, 'counters/updates': 1156}
skipping logging after 18512 examples to avoid logging too frequently
skipping logging after 18528 examples to avoid logging too frequently
skipping logging after 18544 examples to avoid logging too frequently
train stats after 18560 examples: {'rewards_train/chosen': '-0.93891', 'rewards_train/rejected': '-8.3518', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.4143', 'logps_train/rejected': '-235.84', 'logps_train/chosen': '-56.637', 'loss/train': '0.094358', 'examples_per_second': '5.1032', 'grad_norm': '13.25', 'counters/examples': 18560, 'counters/updates': 1160}
skipping logging after 18576 examples to avoid logging too frequently
skipping logging after 18592 examples to avoid logging too frequently
skipping logging after 18608 examples to avoid logging too frequently
train stats after 18624 examples: {'rewards_train/chosen': '-0.95893', 'rewards_train/rejected': '-7.2625', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.302', 'logps_train/rejected': '-203.64', 'logps_train/chosen': '-39.952', 'loss/train': '0.07762', 'examples_per_second': '5.2606', 'grad_norm': '9.125', 'counters/examples': 18624, 'counters/updates': 1164}
skipping logging after 18640 examples to avoid logging too frequently
skipping logging after 18656 examples to avoid logging too frequently
skipping logging after 18672 examples to avoid logging too frequently
train stats after 18688 examples: {'rewards_train/chosen': '-1.0976', 'rewards_train/rejected': '-8.1294', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.0332', 'logps_train/rejected': '-215.72', 'logps_train/chosen': '-49.331', 'loss/train': '0.054182', 'examples_per_second': '5.3741', 'grad_norm': '5.5625', 'counters/examples': 18688, 'counters/updates': 1168}
skipping logging after 18704 examples to avoid logging too frequently
skipping logging after 18720 examples to avoid logging too frequently
skipping logging after 18736 examples to avoid logging too frequently
train stats after 18752 examples: {'rewards_train/chosen': '-1.3087', 'rewards_train/rejected': '-8.6412', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '7.3358', 'logps_train/rejected': '-237.8', 'logps_train/chosen': '-53.04', 'loss/train': '0.12839', 'examples_per_second': '4.377', 'grad_norm': '7.9375', 'counters/examples': 18752, 'counters/updates': 1172}
skipping logging after 18768 examples to avoid logging too frequently
skipping logging after 18784 examples to avoid logging too frequently
skipping logging after 18800 examples to avoid logging too frequently
train stats after 18816 examples: {'rewards_train/chosen': '-1.2276', 'rewards_train/rejected': '-7.9553', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.7256', 'logps_train/rejected': '-225.28', 'logps_train/chosen': '-60.439', 'loss/train': '0.086832', 'examples_per_second': '4.3202', 'grad_norm': '7.4375', 'counters/examples': 18816, 'counters/updates': 1176}
skipping logging after 18832 examples to avoid logging too frequently
skipping logging after 18848 examples to avoid logging too frequently
skipping logging after 18864 examples to avoid logging too frequently
train stats after 18880 examples: {'rewards_train/chosen': '-1.0663', 'rewards_train/rejected': '-8.6954', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.6302', 'logps_train/rejected': '-218.47', 'logps_train/chosen': '-44.923', 'loss/train': '0.070176', 'examples_per_second': '4.518', 'grad_norm': '4.125', 'counters/examples': 18880, 'counters/updates': 1180}
skipping logging after 18896 examples to avoid logging too frequently
skipping logging after 18912 examples to avoid logging too frequently
skipping logging after 18928 examples to avoid logging too frequently
train stats after 18944 examples: {'rewards_train/chosen': '-1.2457', 'rewards_train/rejected': '-8.9686', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.7217', 'logps_train/rejected': '-245.09', 'logps_train/chosen': '-55.944', 'loss/train': '0.066792', 'examples_per_second': '5.0467', 'grad_norm': '6.2812', 'counters/examples': 18944, 'counters/updates': 1184}
skipping logging after 18960 examples to avoid logging too frequently
skipping logging after 18976 examples to avoid logging too frequently
skipping logging after 18992 examples to avoid logging too frequently
train stats after 19008 examples: {'rewards_train/chosen': '-1.3236', 'rewards_train/rejected': '-8.784', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.462', 'logps_train/rejected': '-229.32', 'logps_train/chosen': '-53.905', 'loss/train': '0.094494', 'examples_per_second': '5.0756', 'grad_norm': '6.4688', 'counters/examples': 19008, 'counters/updates': 1188}
skipping logging after 19024 examples to avoid logging too frequently
skipping logging after 19040 examples to avoid logging too frequently
skipping logging after 19056 examples to avoid logging too frequently
train stats after 19072 examples: {'rewards_train/chosen': '-1.3891', 'rewards_train/rejected': '-9.5219', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1332', 'logps_train/rejected': '-244.97', 'logps_train/chosen': '-56.361', 'loss/train': '0.046632', 'examples_per_second': '4.7681', 'grad_norm': '6.5', 'counters/examples': 19072, 'counters/updates': 1192}
skipping logging after 19088 examples to avoid logging too frequently
skipping logging after 19104 examples to avoid logging too frequently
skipping logging after 19120 examples to avoid logging too frequently
train stats after 19136 examples: {'rewards_train/chosen': '-1.209', 'rewards_train/rejected': '-8.7399', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.5299', 'logps_train/rejected': '-226.67', 'logps_train/chosen': '-49.11', 'loss/train': '0.082408', 'examples_per_second': '4.7521', 'grad_norm': '7.3438', 'counters/examples': 19136, 'counters/updates': 1196}
skipping logging after 19152 examples to avoid logging too frequently
skipping logging after 19168 examples to avoid logging too frequently
skipping logging after 19184 examples to avoid logging too frequently
train stats after 19200 examples: {'rewards_train/chosen': '-1.6735', 'rewards_train/rejected': '-9.1872', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.5142', 'logps_train/rejected': '-225.57', 'logps_train/chosen': '-55.804', 'loss/train': '0.088968', 'examples_per_second': '4.8625', 'grad_norm': '7.2188', 'counters/examples': 19200, 'counters/updates': 1200}
skipping logging after 19216 examples to avoid logging too frequently
skipping logging after 19232 examples to avoid logging too frequently
skipping logging after 19248 examples to avoid logging too frequently
train stats after 19264 examples: {'rewards_train/chosen': '-1.7004', 'rewards_train/rejected': '-10.591', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.891', 'logps_train/rejected': '-247.16', 'logps_train/chosen': '-51.077', 'loss/train': '0.067195', 'examples_per_second': '5.1528', 'grad_norm': '6.3125', 'counters/examples': 19264, 'counters/updates': 1204}
skipping logging after 19280 examples to avoid logging too frequently
skipping logging after 19296 examples to avoid logging too frequently
skipping logging after 19312 examples to avoid logging too frequently
train stats after 19328 examples: {'rewards_train/chosen': '-1.6647', 'rewards_train/rejected': '-10.577', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.9114', 'logps_train/rejected': '-260.81', 'logps_train/chosen': '-62.524', 'loss/train': '0.057076', 'examples_per_second': '5.1758', 'grad_norm': '9.5625', 'counters/examples': 19328, 'counters/updates': 1208}
skipping logging after 19344 examples to avoid logging too frequently
skipping logging after 19360 examples to avoid logging too frequently
skipping logging after 19376 examples to avoid logging too frequently
train stats after 19392 examples: {'rewards_train/chosen': '-1.598', 'rewards_train/rejected': '-9.619', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.0201', 'logps_train/rejected': '-243.69', 'logps_train/chosen': '-55.51', 'loss/train': '0.11225', 'examples_per_second': '4.3496', 'grad_norm': '11.938', 'counters/examples': 19392, 'counters/updates': 1212}
skipping logging after 19408 examples to avoid logging too frequently
skipping logging after 19424 examples to avoid logging too frequently
skipping logging after 19440 examples to avoid logging too frequently
train stats after 19456 examples: {'rewards_train/chosen': '-1.3504', 'rewards_train/rejected': '-9.4824', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1284', 'logps_train/rejected': '-230.65', 'logps_train/chosen': '-51.561', 'loss/train': '0.023628', 'examples_per_second': '5.3653', 'grad_norm': '4.8125', 'counters/examples': 19456, 'counters/updates': 1216}
skipping logging after 19472 examples to avoid logging too frequently
skipping logging after 19488 examples to avoid logging too frequently
skipping logging after 19504 examples to avoid logging too frequently
train stats after 19520 examples: {'rewards_train/chosen': '-1.8205', 'rewards_train/rejected': '-9.4155', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.5963', 'logps_train/rejected': '-228.89', 'logps_train/chosen': '-56.475', 'loss/train': '0.069952', 'examples_per_second': '4.9224', 'grad_norm': '7.0312', 'counters/examples': 19520, 'counters/updates': 1220}
skipping logging after 19536 examples to avoid logging too frequently
skipping logging after 19552 examples to avoid logging too frequently
skipping logging after 19568 examples to avoid logging too frequently
train stats after 19584 examples: {'rewards_train/chosen': '-1.6094', 'rewards_train/rejected': '-10.027', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.4185', 'logps_train/rejected': '-250', 'logps_train/chosen': '-60.514', 'loss/train': '0.060338', 'examples_per_second': '4.8819', 'grad_norm': '11.438', 'counters/examples': 19584, 'counters/updates': 1224}
skipping logging after 19600 examples to avoid logging too frequently
skipping logging after 19616 examples to avoid logging too frequently
skipping logging after 19632 examples to avoid logging too frequently
train stats after 19648 examples: {'rewards_train/chosen': '-1.2836', 'rewards_train/rejected': '-9.1691', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.8838', 'logps_train/rejected': '-258.61', 'logps_train/chosen': '-60.491', 'loss/train': '0.070779', 'examples_per_second': '5.6968', 'grad_norm': '8', 'counters/examples': 19648, 'counters/updates': 1228}
skipping logging after 19664 examples to avoid logging too frequently
skipping logging after 19680 examples to avoid logging too frequently
skipping logging after 19696 examples to avoid logging too frequently
train stats after 19712 examples: {'rewards_train/chosen': '-1.3931', 'rewards_train/rejected': '-8.89', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.4989', 'logps_train/rejected': '-216.71', 'logps_train/chosen': '-51.72', 'loss/train': '0.14264', 'examples_per_second': '5.2773', 'grad_norm': '19.375', 'counters/examples': 19712, 'counters/updates': 1232}
skipping logging after 19728 examples to avoid logging too frequently
skipping logging after 19744 examples to avoid logging too frequently
skipping logging after 19760 examples to avoid logging too frequently
train stats after 19776 examples: {'rewards_train/chosen': '-1.2561', 'rewards_train/rejected': '-8.8872', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.6298', 'logps_train/rejected': '-227.26', 'logps_train/chosen': '-49.122', 'loss/train': '0.090957', 'examples_per_second': '4.5255', 'grad_norm': '11', 'counters/examples': 19776, 'counters/updates': 1236}
skipping logging after 19792 examples to avoid logging too frequently
skipping logging after 19808 examples to avoid logging too frequently
skipping logging after 19824 examples to avoid logging too frequently
train stats after 19840 examples: {'rewards_train/chosen': '-1.3052', 'rewards_train/rejected': '-8.0842', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.7794', 'logps_train/rejected': '-215.57', 'logps_train/chosen': '-60.923', 'loss/train': '0.075244', 'examples_per_second': '4.8939', 'grad_norm': '10.188', 'counters/examples': 19840, 'counters/updates': 1240}
skipping logging after 19856 examples to avoid logging too frequently
skipping logging after 19872 examples to avoid logging too frequently
skipping logging after 19888 examples to avoid logging too frequently
train stats after 19904 examples: {'rewards_train/chosen': '-0.88139', 'rewards_train/rejected': '-9.8162', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.9327', 'logps_train/rejected': '-277.32', 'logps_train/chosen': '-55.003', 'loss/train': '0.022944', 'examples_per_second': '4.627', 'grad_norm': '4.0938', 'counters/examples': 19904, 'counters/updates': 1244}
skipping logging after 19920 examples to avoid logging too frequently
skipping logging after 19936 examples to avoid logging too frequently
skipping logging after 19952 examples to avoid logging too frequently
train stats after 19968 examples: {'rewards_train/chosen': '-1.5839', 'rewards_train/rejected': '-7.9651', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '6.3828', 'logps_train/rejected': '-188.89', 'logps_train/chosen': '-50.514', 'loss/train': '0.09408', 'examples_per_second': '4.9334', 'grad_norm': '10.938', 'counters/examples': 19968, 'counters/updates': 1248}
skipping logging after 19984 examples to avoid logging too frequently
skipping logging after 20000 examples to avoid logging too frequently
Running evaluation after 20000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:15,  2.42s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:06,  2.22s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:56,  1.95s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:08<00:53,  1.93s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:42,  1.57s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.68s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:12<00:37,  1.51s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.58s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:36,  1.58s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:33,  1.50s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:33,  1.57s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:30,  1.51s/it]Computing eval metrics:  41%|████      | 13/32 [00:21<00:27,  1.46s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:22,  1.30s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.25s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:26<00:20,  1.33s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.35s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:31<00:14,  1.28s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:32<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:33<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.30s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:36<00:08,  1.27s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:37<00:07,  1.31s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:39<00:07,  1.48s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.42s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.62s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.43s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:45<00:01,  1.43s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.41s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.45s/it]
eval after 20000: {'rewards_eval/chosen': '-8.8462', 'rewards_eval/rejected': '-9.2559', 'rewards_eval/accuracies': '0.49609', 'rewards_eval/margins': '0.40989', 'logps_eval/rejected': '-240.23', 'logps_eval/chosen': '-233.38', 'loss/eval': '2.1556'}
skipping logging after 20016 examples to avoid logging too frequently
train stats after 20032 examples: {'rewards_train/chosen': '-1.2165', 'rewards_train/rejected': '-9.4031', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.1881', 'logps_train/rejected': '-241.19', 'logps_train/chosen': '-52.362', 'loss/train': '0.070038', 'examples_per_second': '6.1727', 'grad_norm': '9.8125', 'counters/examples': 20032, 'counters/updates': 1252}
skipping logging after 20048 examples to avoid logging too frequently
skipping logging after 20064 examples to avoid logging too frequently
skipping logging after 20080 examples to avoid logging too frequently
train stats after 20096 examples: {'rewards_train/chosen': '-1.7933', 'rewards_train/rejected': '-10.321', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.5289', 'logps_train/rejected': '-252.2', 'logps_train/chosen': '-63.937', 'loss/train': '0.043848', 'examples_per_second': '5.462', 'grad_norm': '6.5312', 'counters/examples': 20096, 'counters/updates': 1256}
skipping logging after 20112 examples to avoid logging too frequently
skipping logging after 20128 examples to avoid logging too frequently
skipping logging after 20144 examples to avoid logging too frequently
train stats after 20160 examples: {'rewards_train/chosen': '-1.649', 'rewards_train/rejected': '-10.177', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.527', 'logps_train/rejected': '-227.74', 'logps_train/chosen': '-64.27', 'loss/train': '0.029991', 'examples_per_second': '5.4729', 'grad_norm': '5.3438', 'counters/examples': 20160, 'counters/updates': 1260}
skipping logging after 20176 examples to avoid logging too frequently
skipping logging after 20192 examples to avoid logging too frequently
skipping logging after 20208 examples to avoid logging too frequently
train stats after 20224 examples: {'rewards_train/chosen': '-1.6949', 'rewards_train/rejected': '-12.25', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '10.556', 'logps_train/rejected': '-302.85', 'logps_train/chosen': '-60.075', 'loss/train': '0.043454', 'examples_per_second': '4.9412', 'grad_norm': '7.1562', 'counters/examples': 20224, 'counters/updates': 1264}
skipping logging after 20240 examples to avoid logging too frequently
skipping logging after 20256 examples to avoid logging too frequently
skipping logging after 20272 examples to avoid logging too frequently
train stats after 20288 examples: {'rewards_train/chosen': '-1.658', 'rewards_train/rejected': '-11.168', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '9.5168', 'logps_train/rejected': '-265.07', 'logps_train/chosen': '-57.463', 'loss/train': '0.12287', 'examples_per_second': '4.19', 'grad_norm': '13.188', 'counters/examples': 20288, 'counters/updates': 1268}
skipping logging after 20304 examples to avoid logging too frequently
skipping logging after 20320 examples to avoid logging too frequently
skipping logging after 20336 examples to avoid logging too frequently
train stats after 20352 examples: {'rewards_train/chosen': '-1.6429', 'rewards_train/rejected': '-9.0242', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '7.382', 'logps_train/rejected': '-197.22', 'logps_train/chosen': '-48.956', 'loss/train': '0.14171', 'examples_per_second': '5.7998', 'grad_norm': '12.812', 'counters/examples': 20352, 'counters/updates': 1272}
skipping logging after 20368 examples to avoid logging too frequently
skipping logging after 20384 examples to avoid logging too frequently
skipping logging after 20400 examples to avoid logging too frequently
train stats after 20416 examples: {'rewards_train/chosen': '-1.8315', 'rewards_train/rejected': '-8.7993', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.9692', 'logps_train/rejected': '-208.61', 'logps_train/chosen': '-65.309', 'loss/train': '0.14406', 'examples_per_second': '3.9906', 'grad_norm': '19.125', 'counters/examples': 20416, 'counters/updates': 1276}
skipping logging after 20432 examples to avoid logging too frequently
skipping logging after 20448 examples to avoid logging too frequently
skipping logging after 20464 examples to avoid logging too frequently
train stats after 20480 examples: {'rewards_train/chosen': '-1.4853', 'rewards_train/rejected': '-9.9635', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.4806', 'logps_train/rejected': '-258.28', 'logps_train/chosen': '-59.713', 'loss/train': '0.079322', 'examples_per_second': '4.6192', 'grad_norm': '6.4375', 'counters/examples': 20480, 'counters/updates': 1280}
skipping logging after 20496 examples to avoid logging too frequently
skipping logging after 20512 examples to avoid logging too frequently
skipping logging after 20528 examples to avoid logging too frequently
train stats after 20544 examples: {'rewards_train/chosen': '-1.5736', 'rewards_train/rejected': '-9.9893', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.4155', 'logps_train/rejected': '-269.57', 'logps_train/chosen': '-63.512', 'loss/train': '0.060567', 'examples_per_second': '4.8347', 'grad_norm': '11.188', 'counters/examples': 20544, 'counters/updates': 1284}
skipping logging after 20560 examples to avoid logging too frequently
skipping logging after 20576 examples to avoid logging too frequently
skipping logging after 20592 examples to avoid logging too frequently
train stats after 20608 examples: {'rewards_train/chosen': '-1.3775', 'rewards_train/rejected': '-9.4891', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1078', 'logps_train/rejected': '-247.47', 'logps_train/chosen': '-54.045', 'loss/train': '0.06783', 'examples_per_second': '4.8374', 'grad_norm': '7.6562', 'counters/examples': 20608, 'counters/updates': 1288}
skipping logging after 20624 examples to avoid logging too frequently
skipping logging after 20640 examples to avoid logging too frequently
skipping logging after 20656 examples to avoid logging too frequently
train stats after 20672 examples: {'rewards_train/chosen': '-1.7013', 'rewards_train/rejected': '-9.1918', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.4871', 'logps_train/rejected': '-219.03', 'logps_train/chosen': '-55.303', 'loss/train': '0.081633', 'examples_per_second': '4.2469', 'grad_norm': '7.8438', 'counters/examples': 20672, 'counters/updates': 1292}
skipping logging after 20688 examples to avoid logging too frequently
skipping logging after 20704 examples to avoid logging too frequently
skipping logging after 20720 examples to avoid logging too frequently
train stats after 20736 examples: {'rewards_train/chosen': '-1.4683', 'rewards_train/rejected': '-9.657', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.189', 'logps_train/rejected': '-237.13', 'logps_train/chosen': '-58.73', 'loss/train': '0.067104', 'examples_per_second': '5.3189', 'grad_norm': '6.4688', 'counters/examples': 20736, 'counters/updates': 1296}
skipping logging after 20752 examples to avoid logging too frequently
skipping logging after 20768 examples to avoid logging too frequently
skipping logging after 20784 examples to avoid logging too frequently
train stats after 20800 examples: {'rewards_train/chosen': '-1.655', 'rewards_train/rejected': '-10.09', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.4355', 'logps_train/rejected': '-239.67', 'logps_train/chosen': '-60.079', 'loss/train': '0.056498', 'examples_per_second': '4.4914', 'grad_norm': '9.875', 'counters/examples': 20800, 'counters/updates': 1300}
skipping logging after 20816 examples to avoid logging too frequently
skipping logging after 20832 examples to avoid logging too frequently
skipping logging after 20848 examples to avoid logging too frequently
train stats after 20864 examples: {'rewards_train/chosen': '-1.8856', 'rewards_train/rejected': '-10.581', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.6927', 'logps_train/rejected': '-248.46', 'logps_train/chosen': '-61.009', 'loss/train': '0.1072', 'examples_per_second': '4.4586', 'grad_norm': '17.125', 'counters/examples': 20864, 'counters/updates': 1304}
skipping logging after 20880 examples to avoid logging too frequently
skipping logging after 20896 examples to avoid logging too frequently
skipping logging after 20912 examples to avoid logging too frequently
train stats after 20928 examples: {'rewards_train/chosen': '-1.2769', 'rewards_train/rejected': '-8.6492', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.3754', 'logps_train/rejected': '-219.63', 'logps_train/chosen': '-57.689', 'loss/train': '0.04608', 'examples_per_second': '4.4629', 'grad_norm': '6', 'counters/examples': 20928, 'counters/updates': 1308}
skipping logging after 20944 examples to avoid logging too frequently
skipping logging after 20960 examples to avoid logging too frequently
skipping logging after 20976 examples to avoid logging too frequently
train stats after 20992 examples: {'rewards_train/chosen': '-1.3823', 'rewards_train/rejected': '-9.5061', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1233', 'logps_train/rejected': '-249.88', 'logps_train/chosen': '-51.47', 'loss/train': '0.065449', 'examples_per_second': '5.5056', 'grad_norm': '9', 'counters/examples': 20992, 'counters/updates': 1312}
skipping logging after 21008 examples to avoid logging too frequently
skipping logging after 21024 examples to avoid logging too frequently
skipping logging after 21040 examples to avoid logging too frequently
train stats after 21056 examples: {'rewards_train/chosen': '-1.543', 'rewards_train/rejected': '-8.9891', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.4476', 'logps_train/rejected': '-200.91', 'logps_train/chosen': '-52.44', 'loss/train': '0.04789', 'examples_per_second': '5.0583', 'grad_norm': '9.125', 'counters/examples': 21056, 'counters/updates': 1316}
skipping logging after 21072 examples to avoid logging too frequently
skipping logging after 21088 examples to avoid logging too frequently
skipping logging after 21104 examples to avoid logging too frequently
train stats after 21120 examples: {'rewards_train/chosen': '-1.5456', 'rewards_train/rejected': '-9.012', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.4673', 'logps_train/rejected': '-222.73', 'logps_train/chosen': '-49.755', 'loss/train': '0.062249', 'examples_per_second': '5.0778', 'grad_norm': '10.312', 'counters/examples': 21120, 'counters/updates': 1320}
skipping logging after 21136 examples to avoid logging too frequently
skipping logging after 21152 examples to avoid logging too frequently
skipping logging after 21168 examples to avoid logging too frequently
train stats after 21184 examples: {'rewards_train/chosen': '-1.5905', 'rewards_train/rejected': '-12.038', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '10.45', 'logps_train/rejected': '-272.31', 'logps_train/chosen': '-64.082', 'loss/train': '0.033013', 'examples_per_second': '6.119', 'grad_norm': '5.6562', 'counters/examples': 21184, 'counters/updates': 1324}
skipping logging after 21200 examples to avoid logging too frequently
skipping logging after 21216 examples to avoid logging too frequently
skipping logging after 21232 examples to avoid logging too frequently
train stats after 21248 examples: {'rewards_train/chosen': '-1.3715', 'rewards_train/rejected': '-10.265', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.89', 'logps_train/rejected': '-262.55', 'logps_train/chosen': '-53.406', 'loss/train': '0.066694', 'examples_per_second': '4.3018', 'grad_norm': '8.4375', 'counters/examples': 21248, 'counters/updates': 1328}
skipping logging after 21264 examples to avoid logging too frequently
skipping logging after 21280 examples to avoid logging too frequently
skipping logging after 21296 examples to avoid logging too frequently
train stats after 21312 examples: {'rewards_train/chosen': '-1.5897', 'rewards_train/rejected': '-11.071', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.4818', 'logps_train/rejected': '-267.06', 'logps_train/chosen': '-51.985', 'loss/train': '0.026057', 'examples_per_second': '4.7819', 'grad_norm': '4.75', 'counters/examples': 21312, 'counters/updates': 1332}
skipping logging after 21328 examples to avoid logging too frequently
skipping logging after 21344 examples to avoid logging too frequently
skipping logging after 21360 examples to avoid logging too frequently
train stats after 21376 examples: {'rewards_train/chosen': '-1.5675', 'rewards_train/rejected': '-9.6648', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.1027', 'logps_train/rejected': '-238.88', 'logps_train/chosen': '-58.931', 'loss/train': '0.0557', 'examples_per_second': '5.497', 'grad_norm': '8.0625', 'counters/examples': 21376, 'counters/updates': 1336}
skipping logging after 21392 examples to avoid logging too frequently
skipping logging after 21408 examples to avoid logging too frequently
skipping logging after 21424 examples to avoid logging too frequently
train stats after 21440 examples: {'rewards_train/chosen': '-1.5761', 'rewards_train/rejected': '-8.8156', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.2404', 'logps_train/rejected': '-202.17', 'logps_train/chosen': '-62.52', 'loss/train': '0.10192', 'examples_per_second': '4.6552', 'grad_norm': '13.438', 'counters/examples': 21440, 'counters/updates': 1340}
skipping logging after 21456 examples to avoid logging too frequently
skipping logging after 21472 examples to avoid logging too frequently
skipping logging after 21488 examples to avoid logging too frequently
train stats after 21504 examples: {'rewards_train/chosen': '-1.583', 'rewards_train/rejected': '-9.1301', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.5433', 'logps_train/rejected': '-216.85', 'logps_train/chosen': '-56.917', 'loss/train': '0.053547', 'examples_per_second': '4.9658', 'grad_norm': '7.0312', 'counters/examples': 21504, 'counters/updates': 1344}
skipping logging after 21520 examples to avoid logging too frequently
skipping logging after 21536 examples to avoid logging too frequently
skipping logging after 21552 examples to avoid logging too frequently
train stats after 21568 examples: {'rewards_train/chosen': '-1.578', 'rewards_train/rejected': '-9.2294', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.6443', 'logps_train/rejected': '-214.96', 'logps_train/chosen': '-53.129', 'loss/train': '0.096527', 'examples_per_second': '6.4528', 'grad_norm': '9.375', 'counters/examples': 21568, 'counters/updates': 1348}
skipping logging after 21584 examples to avoid logging too frequently
skipping logging after 21600 examples to avoid logging too frequently
skipping logging after 21616 examples to avoid logging too frequently
train stats after 21632 examples: {'rewards_train/chosen': '-1.3408', 'rewards_train/rejected': '-8.9795', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.6365', 'logps_train/rejected': '-222.4', 'logps_train/chosen': '-50.691', 'loss/train': '0.068337', 'examples_per_second': '4.4616', 'grad_norm': '9', 'counters/examples': 21632, 'counters/updates': 1352}
skipping logging after 21648 examples to avoid logging too frequently
skipping logging after 21664 examples to avoid logging too frequently
skipping logging after 21680 examples to avoid logging too frequently
train stats after 21696 examples: {'rewards_train/chosen': '-1.8537', 'rewards_train/rejected': '-10.71', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.8547', 'logps_train/rejected': '-259.85', 'logps_train/chosen': '-55.198', 'loss/train': '0.062694', 'examples_per_second': '4.3792', 'grad_norm': '8.4375', 'counters/examples': 21696, 'counters/updates': 1356}
skipping logging after 21712 examples to avoid logging too frequently
skipping logging after 21728 examples to avoid logging too frequently
skipping logging after 21744 examples to avoid logging too frequently
train stats after 21760 examples: {'rewards_train/chosen': '-1.719', 'rewards_train/rejected': '-10.493', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.7739', 'logps_train/rejected': '-263.89', 'logps_train/chosen': '-58.242', 'loss/train': '0.12701', 'examples_per_second': '5.3277', 'grad_norm': '18.75', 'counters/examples': 21760, 'counters/updates': 1360}
skipping logging after 21776 examples to avoid logging too frequently
skipping logging after 21792 examples to avoid logging too frequently
skipping logging after 21808 examples to avoid logging too frequently
train stats after 21824 examples: {'rewards_train/chosen': '-1.4349', 'rewards_train/rejected': '-9.9046', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.4714', 'logps_train/rejected': '-252.32', 'logps_train/chosen': '-56.525', 'loss/train': '0.10081', 'examples_per_second': '5.0465', 'grad_norm': '8.25', 'counters/examples': 21824, 'counters/updates': 1364}
skipping logging after 21840 examples to avoid logging too frequently
skipping logging after 21856 examples to avoid logging too frequently
skipping logging after 21872 examples to avoid logging too frequently
train stats after 21888 examples: {'rewards_train/chosen': '-1.6095', 'rewards_train/rejected': '-8.1962', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.5865', 'logps_train/rejected': '-208.41', 'logps_train/chosen': '-51.958', 'loss/train': '0.080419', 'examples_per_second': '4.9526', 'grad_norm': '9.25', 'counters/examples': 21888, 'counters/updates': 1368}
skipping logging after 21904 examples to avoid logging too frequently
skipping logging after 21920 examples to avoid logging too frequently
skipping logging after 21936 examples to avoid logging too frequently
train stats after 21952 examples: {'rewards_train/chosen': '-1.6095', 'rewards_train/rejected': '-8.8325', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.2224', 'logps_train/rejected': '-216.42', 'logps_train/chosen': '-64.174', 'loss/train': '0.041912', 'examples_per_second': '6.3526', 'grad_norm': '11.125', 'counters/examples': 21952, 'counters/updates': 1372}
skipping logging after 21968 examples to avoid logging too frequently
skipping logging after 21984 examples to avoid logging too frequently
skipping logging after 22000 examples to avoid logging too frequently
train stats after 22016 examples: {'rewards_train/chosen': '-2.0331', 'rewards_train/rejected': '-10.078', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.0442', 'logps_train/rejected': '-231.54', 'logps_train/chosen': '-66.852', 'loss/train': '0.088985', 'examples_per_second': '5.0091', 'grad_norm': '20.25', 'counters/examples': 22016, 'counters/updates': 1376}
skipping logging after 22032 examples to avoid logging too frequently
skipping logging after 22048 examples to avoid logging too frequently
skipping logging after 22064 examples to avoid logging too frequently
train stats after 22080 examples: {'rewards_train/chosen': '-1.2993', 'rewards_train/rejected': '-9.0608', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.7634', 'logps_train/rejected': '-232.89', 'logps_train/chosen': '-48.815', 'loss/train': '0.035629', 'examples_per_second': '5.4502', 'grad_norm': '7.25', 'counters/examples': 22080, 'counters/updates': 1380}
skipping logging after 22096 examples to avoid logging too frequently
skipping logging after 22112 examples to avoid logging too frequently
skipping logging after 22128 examples to avoid logging too frequently
train stats after 22144 examples: {'rewards_train/chosen': '-1.8142', 'rewards_train/rejected': '-9.0125', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.1978', 'logps_train/rejected': '-224', 'logps_train/chosen': '-57.319', 'loss/train': '0.058545', 'examples_per_second': '5.7923', 'grad_norm': '10.5', 'counters/examples': 22144, 'counters/updates': 1384}
skipping logging after 22160 examples to avoid logging too frequently
skipping logging after 22176 examples to avoid logging too frequently
skipping logging after 22192 examples to avoid logging too frequently
train stats after 22208 examples: {'rewards_train/chosen': '-1.8079', 'rewards_train/rejected': '-9.4489', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.6407', 'logps_train/rejected': '-204.01', 'logps_train/chosen': '-54.179', 'loss/train': '0.095888', 'examples_per_second': '5.0748', 'grad_norm': '14.438', 'counters/examples': 22208, 'counters/updates': 1388}
skipping logging after 22224 examples to avoid logging too frequently
skipping logging after 22240 examples to avoid logging too frequently
skipping logging after 22256 examples to avoid logging too frequently
train stats after 22272 examples: {'rewards_train/chosen': '-1.6895', 'rewards_train/rejected': '-10.478', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.7876', 'logps_train/rejected': '-253.79', 'logps_train/chosen': '-60.398', 'loss/train': '0.06485', 'examples_per_second': '5.0476', 'grad_norm': '13.938', 'counters/examples': 22272, 'counters/updates': 1392}
skipping logging after 22288 examples to avoid logging too frequently
skipping logging after 22304 examples to avoid logging too frequently
skipping logging after 22320 examples to avoid logging too frequently
train stats after 22336 examples: {'rewards_train/chosen': '-1.7543', 'rewards_train/rejected': '-9.0132', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.2589', 'logps_train/rejected': '-215.96', 'logps_train/chosen': '-64.735', 'loss/train': '0.25296', 'examples_per_second': '4.107', 'grad_norm': '21.375', 'counters/examples': 22336, 'counters/updates': 1396}
skipping logging after 22352 examples to avoid logging too frequently
skipping logging after 22368 examples to avoid logging too frequently
skipping logging after 22384 examples to avoid logging too frequently
train stats after 22400 examples: {'rewards_train/chosen': '-1.5035', 'rewards_train/rejected': '-8.2501', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.7458', 'logps_train/rejected': '-187.93', 'logps_train/chosen': '-55.218', 'loss/train': '0.078874', 'examples_per_second': '5.1828', 'grad_norm': '6.5', 'counters/examples': 22400, 'counters/updates': 1400}
skipping logging after 22416 examples to avoid logging too frequently
skipping logging after 22432 examples to avoid logging too frequently
skipping logging after 22448 examples to avoid logging too frequently
train stats after 22464 examples: {'rewards_train/chosen': '-1.3419', 'rewards_train/rejected': '-8.1776', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.8352', 'logps_train/rejected': '-223.62', 'logps_train/chosen': '-53.505', 'loss/train': '0.1035', 'examples_per_second': '5.6662', 'grad_norm': '9.5625', 'counters/examples': 22464, 'counters/updates': 1404}
skipping logging after 22480 examples to avoid logging too frequently
skipping logging after 22496 examples to avoid logging too frequently
skipping logging after 22512 examples to avoid logging too frequently
train stats after 22528 examples: {'rewards_train/chosen': '-1.4168', 'rewards_train/rejected': '-8.2762', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.8588', 'logps_train/rejected': '-233.14', 'logps_train/chosen': '-58.63', 'loss/train': '0.081446', 'examples_per_second': '4.3193', 'grad_norm': '7.4688', 'counters/examples': 22528, 'counters/updates': 1408}
skipping logging after 22544 examples to avoid logging too frequently
skipping logging after 22560 examples to avoid logging too frequently
skipping logging after 22576 examples to avoid logging too frequently
train stats after 22592 examples: {'rewards_train/chosen': '-1.5918', 'rewards_train/rejected': '-8.7776', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.1897', 'logps_train/rejected': '-233.2', 'logps_train/chosen': '-60.926', 'loss/train': '0.10025', 'examples_per_second': '6.1296', 'grad_norm': '16.25', 'counters/examples': 22592, 'counters/updates': 1412}
skipping logging after 22608 examples to avoid logging too frequently
skipping logging after 22624 examples to avoid logging too frequently
skipping logging after 22640 examples to avoid logging too frequently
train stats after 22656 examples: {'rewards_train/chosen': '-1.2791', 'rewards_train/rejected': '-8.8227', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.5417', 'logps_train/rejected': '-214.23', 'logps_train/chosen': '-47.196', 'loss/train': '0.067568', 'examples_per_second': '4.1907', 'grad_norm': '6.0312', 'counters/examples': 22656, 'counters/updates': 1416}
skipping logging after 22672 examples to avoid logging too frequently
skipping logging after 22688 examples to avoid logging too frequently
skipping logging after 22704 examples to avoid logging too frequently
train stats after 22720 examples: {'rewards_train/chosen': '-1.9315', 'rewards_train/rejected': '-7.6658', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '5.7333', 'logps_train/rejected': '-196.55', 'logps_train/chosen': '-60.787', 'loss/train': '0.11361', 'examples_per_second': '6.5792', 'grad_norm': '11.25', 'counters/examples': 22720, 'counters/updates': 1420}
skipping logging after 22736 examples to avoid logging too frequently
skipping logging after 22752 examples to avoid logging too frequently
skipping logging after 22768 examples to avoid logging too frequently
train stats after 22784 examples: {'rewards_train/chosen': '-1.6033', 'rewards_train/rejected': '-10.504', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.8977', 'logps_train/rejected': '-281.45', 'logps_train/chosen': '-52.637', 'loss/train': '0.03473', 'examples_per_second': '5.0636', 'grad_norm': '4.3125', 'counters/examples': 22784, 'counters/updates': 1424}
skipping logging after 22800 examples to avoid logging too frequently
skipping logging after 22816 examples to avoid logging too frequently
skipping logging after 22832 examples to avoid logging too frequently
train stats after 22848 examples: {'rewards_train/chosen': '-2.05', 'rewards_train/rejected': '-9.2334', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.1814', 'logps_train/rejected': '-208.39', 'logps_train/chosen': '-59.44', 'loss/train': '0.15592', 'examples_per_second': '3.9157', 'grad_norm': '10.625', 'counters/examples': 22848, 'counters/updates': 1428}
skipping logging after 22864 examples to avoid logging too frequently
skipping logging after 22880 examples to avoid logging too frequently
skipping logging after 22896 examples to avoid logging too frequently
train stats after 22912 examples: {'rewards_train/chosen': '-1.2816', 'rewards_train/rejected': '-9.1859', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.9049', 'logps_train/rejected': '-235.87', 'logps_train/chosen': '-59.09', 'loss/train': '0.066081', 'examples_per_second': '4.1032', 'grad_norm': '6.75', 'counters/examples': 22912, 'counters/updates': 1432}
skipping logging after 22928 examples to avoid logging too frequently
skipping logging after 22944 examples to avoid logging too frequently
skipping logging after 22960 examples to avoid logging too frequently
train stats after 22976 examples: {'rewards_train/chosen': '-1.2988', 'rewards_train/rejected': '-8.881', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.5827', 'logps_train/rejected': '-220.15', 'logps_train/chosen': '-58.424', 'loss/train': '0.049453', 'examples_per_second': '4.9355', 'grad_norm': '4.9375', 'counters/examples': 22976, 'counters/updates': 1436}
skipping logging after 22992 examples to avoid logging too frequently
skipping logging after 23008 examples to avoid logging too frequently
skipping logging after 23024 examples to avoid logging too frequently
train stats after 23040 examples: {'rewards_train/chosen': '-1.7956', 'rewards_train/rejected': '-8.7892', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.9961', 'logps_train/rejected': '-213.91', 'logps_train/chosen': '-55.981', 'loss/train': '0.10037', 'examples_per_second': '4.4408', 'grad_norm': '10.5', 'counters/examples': 23040, 'counters/updates': 1440}
skipping logging after 23056 examples to avoid logging too frequently
skipping logging after 23072 examples to avoid logging too frequently
skipping logging after 23088 examples to avoid logging too frequently
train stats after 23104 examples: {'rewards_train/chosen': '-1.8028', 'rewards_train/rejected': '-8.6911', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.8878', 'logps_train/rejected': '-198.16', 'logps_train/chosen': '-54.258', 'loss/train': '0.074813', 'examples_per_second': '6.3233', 'grad_norm': '7.0312', 'counters/examples': 23104, 'counters/updates': 1444}
skipping logging after 23120 examples to avoid logging too frequently
skipping logging after 23136 examples to avoid logging too frequently
skipping logging after 23152 examples to avoid logging too frequently
train stats after 23168 examples: {'rewards_train/chosen': '-1.5137', 'rewards_train/rejected': '-8.4441', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.9288', 'logps_train/rejected': '-196.63', 'logps_train/chosen': '-56.505', 'loss/train': '0.10987', 'examples_per_second': '5.6986', 'grad_norm': '9.375', 'counters/examples': 23168, 'counters/updates': 1448}
skipping logging after 23184 examples to avoid logging too frequently
skipping logging after 23200 examples to avoid logging too frequently
skipping logging after 23216 examples to avoid logging too frequently
train stats after 23232 examples: {'rewards_train/chosen': '-1.6374', 'rewards_train/rejected': '-10.458', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.8231', 'logps_train/rejected': '-262.24', 'logps_train/chosen': '-55.619', 'loss/train': '0.041198', 'examples_per_second': '4.2981', 'grad_norm': '5.1875', 'counters/examples': 23232, 'counters/updates': 1452}
skipping logging after 23248 examples to avoid logging too frequently
skipping logging after 23264 examples to avoid logging too frequently
skipping logging after 23280 examples to avoid logging too frequently
train stats after 23296 examples: {'rewards_train/chosen': '-1.6167', 'rewards_train/rejected': '-10.114', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.4996', 'logps_train/rejected': '-240.47', 'logps_train/chosen': '-56.932', 'loss/train': '0.078649', 'examples_per_second': '5.5673', 'grad_norm': '11.562', 'counters/examples': 23296, 'counters/updates': 1456}
skipping logging after 23312 examples to avoid logging too frequently
skipping logging after 23328 examples to avoid logging too frequently
skipping logging after 23344 examples to avoid logging too frequently
train stats after 23360 examples: {'rewards_train/chosen': '-1.8068', 'rewards_train/rejected': '-11.736', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '9.9298', 'logps_train/rejected': '-287.69', 'logps_train/chosen': '-70.845', 'loss/train': '0.12762', 'examples_per_second': '5.0621', 'grad_norm': '13.938', 'counters/examples': 23360, 'counters/updates': 1460}
skipping logging after 23376 examples to avoid logging too frequently
skipping logging after 23392 examples to avoid logging too frequently
skipping logging after 23408 examples to avoid logging too frequently
train stats after 23424 examples: {'rewards_train/chosen': '-1.3933', 'rewards_train/rejected': '-9.0815', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.6887', 'logps_train/rejected': '-236.48', 'logps_train/chosen': '-57.481', 'loss/train': '0.16846', 'examples_per_second': '3.9693', 'grad_norm': '13', 'counters/examples': 23424, 'counters/updates': 1464}
skipping logging after 23440 examples to avoid logging too frequently
skipping logging after 23456 examples to avoid logging too frequently
skipping logging after 23472 examples to avoid logging too frequently
train stats after 23488 examples: {'rewards_train/chosen': '-1.5776', 'rewards_train/rejected': '-7.5135', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '5.9374', 'logps_train/rejected': '-177.37', 'logps_train/chosen': '-60.436', 'loss/train': '0.11174', 'examples_per_second': '6.604', 'grad_norm': '15.875', 'counters/examples': 23488, 'counters/updates': 1468}
skipping logging after 23504 examples to avoid logging too frequently
skipping logging after 23520 examples to avoid logging too frequently
skipping logging after 23536 examples to avoid logging too frequently
train stats after 23552 examples: {'rewards_train/chosen': '-1.3893', 'rewards_train/rejected': '-9.0444', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.6561', 'logps_train/rejected': '-263.54', 'logps_train/chosen': '-54.42', 'loss/train': '0.11683', 'examples_per_second': '4.3475', 'grad_norm': '12.312', 'counters/examples': 23552, 'counters/updates': 1472}
skipping logging after 23568 examples to avoid logging too frequently
skipping logging after 23584 examples to avoid logging too frequently
skipping logging after 23600 examples to avoid logging too frequently
train stats after 23616 examples: {'rewards_train/chosen': '-1.1778', 'rewards_train/rejected': '-7.7634', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.5884', 'logps_train/rejected': '-196.71', 'logps_train/chosen': '-46.301', 'loss/train': '0.050153', 'examples_per_second': '5.9699', 'grad_norm': '4.8125', 'counters/examples': 23616, 'counters/updates': 1476}
skipping logging after 23632 examples to avoid logging too frequently
skipping logging after 23648 examples to avoid logging too frequently
skipping logging after 23664 examples to avoid logging too frequently
train stats after 23680 examples: {'rewards_train/chosen': '-1.008', 'rewards_train/rejected': '-7.9987', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.9932', 'logps_train/rejected': '-224.59', 'logps_train/chosen': '-46.072', 'loss/train': '0.1061', 'examples_per_second': '5.1323', 'grad_norm': '6.1875', 'counters/examples': 23680, 'counters/updates': 1480}
skipping logging after 23696 examples to avoid logging too frequently
skipping logging after 23712 examples to avoid logging too frequently
skipping logging after 23728 examples to avoid logging too frequently
train stats after 23744 examples: {'rewards_train/chosen': '-1.2789', 'rewards_train/rejected': '-7.9767', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.6994', 'logps_train/rejected': '-223.29', 'logps_train/chosen': '-56.25', 'loss/train': '0.076233', 'examples_per_second': '5.1536', 'grad_norm': '7.9062', 'counters/examples': 23744, 'counters/updates': 1484}
skipping logging after 23760 examples to avoid logging too frequently
skipping logging after 23776 examples to avoid logging too frequently
skipping logging after 23792 examples to avoid logging too frequently
train stats after 23808 examples: {'rewards_train/chosen': '-1.5266', 'rewards_train/rejected': '-10.42', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.8966', 'logps_train/rejected': '-260.48', 'logps_train/chosen': '-54.931', 'loss/train': '0.074093', 'examples_per_second': '4.4503', 'grad_norm': '6.9375', 'counters/examples': 23808, 'counters/updates': 1488}
skipping logging after 23824 examples to avoid logging too frequently
skipping logging after 23840 examples to avoid logging too frequently
skipping logging after 23856 examples to avoid logging too frequently
train stats after 23872 examples: {'rewards_train/chosen': '-1.3386', 'rewards_train/rejected': '-8.7103', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.3726', 'logps_train/rejected': '-209.54', 'logps_train/chosen': '-46.512', 'loss/train': '0.044278', 'examples_per_second': '4.5478', 'grad_norm': '7.4375', 'counters/examples': 23872, 'counters/updates': 1492}
skipping logging after 23888 examples to avoid logging too frequently
skipping logging after 23904 examples to avoid logging too frequently
skipping logging after 23920 examples to avoid logging too frequently
train stats after 23936 examples: {'rewards_train/chosen': '-1.1881', 'rewards_train/rejected': '-9.4578', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.2704', 'logps_train/rejected': '-239.93', 'logps_train/chosen': '-53.041', 'loss/train': '0.038487', 'examples_per_second': '5.4455', 'grad_norm': '5.875', 'counters/examples': 23936, 'counters/updates': 1496}
skipping logging after 23952 examples to avoid logging too frequently
skipping logging after 23968 examples to avoid logging too frequently
skipping logging after 23984 examples to avoid logging too frequently
train stats after 24000 examples: {'rewards_train/chosen': '-1.5391', 'rewards_train/rejected': '-9.0688', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.5278', 'logps_train/rejected': '-230.91', 'logps_train/chosen': '-54.03', 'loss/train': '0.060857', 'examples_per_second': '4.5023', 'grad_norm': '8.1875', 'counters/examples': 24000, 'counters/updates': 1500}
Running evaluation after 24000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<01:00,  1.94s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:00,  2.01s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:53,  1.84s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.85s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.52s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.49s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:22,  1.30s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.24s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.33s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.34s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.27s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.29s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.26s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.30s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.48s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.41s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.61s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.42s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.41s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 24000: {'rewards_eval/chosen': '-9.3381', 'rewards_eval/rejected': '-9.6803', 'rewards_eval/accuracies': '0.50586', 'rewards_eval/margins': '0.34171', 'logps_eval/rejected': '-244.47', 'logps_eval/chosen': '-238.31', 'loss/eval': '2.1747'}
skipping logging after 24016 examples to avoid logging too frequently
skipping logging after 24032 examples to avoid logging too frequently
skipping logging after 24048 examples to avoid logging too frequently
train stats after 24064 examples: {'rewards_train/chosen': '-1.5777', 'rewards_train/rejected': '-8.1665', 'rewards_train/accuracies': '1', 'rewards_train/margins': '6.5875', 'logps_train/rejected': '-198.41', 'logps_train/chosen': '-46.818', 'loss/train': '0.054339', 'examples_per_second': '5.8875', 'grad_norm': '7.5625', 'counters/examples': 24064, 'counters/updates': 1504}
skipping logging after 24080 examples to avoid logging too frequently
skipping logging after 24096 examples to avoid logging too frequently
skipping logging after 24112 examples to avoid logging too frequently
train stats after 24128 examples: {'rewards_train/chosen': '-1.9433', 'rewards_train/rejected': '-9.1287', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.1857', 'logps_train/rejected': '-230.86', 'logps_train/chosen': '-55.276', 'loss/train': '0.078443', 'examples_per_second': '5.0869', 'grad_norm': '10.125', 'counters/examples': 24128, 'counters/updates': 1508}
skipping logging after 24144 examples to avoid logging too frequently
skipping logging after 24160 examples to avoid logging too frequently
skipping logging after 24176 examples to avoid logging too frequently
train stats after 24192 examples: {'rewards_train/chosen': '-1.722', 'rewards_train/rejected': '-9.5232', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.7996', 'logps_train/rejected': '-230.29', 'logps_train/chosen': '-65.502', 'loss/train': '0.038622', 'examples_per_second': '4.9644', 'grad_norm': '6.625', 'counters/examples': 24192, 'counters/updates': 1512}
skipping logging after 24208 examples to avoid logging too frequently
skipping logging after 24224 examples to avoid logging too frequently
skipping logging after 24240 examples to avoid logging too frequently
train stats after 24256 examples: {'rewards_train/chosen': '-1.6415', 'rewards_train/rejected': '-9.6162', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.9771', 'logps_train/rejected': '-223.66', 'logps_train/chosen': '-49.877', 'loss/train': '0.037198', 'examples_per_second': '5.0461', 'grad_norm': '4.0312', 'counters/examples': 24256, 'counters/updates': 1516}
skipping logging after 24272 examples to avoid logging too frequently
skipping logging after 24288 examples to avoid logging too frequently
skipping logging after 24304 examples to avoid logging too frequently
train stats after 24320 examples: {'rewards_train/chosen': '-1.7754', 'rewards_train/rejected': '-8.3548', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.5769', 'logps_train/rejected': '-185.47', 'logps_train/chosen': '-50.551', 'loss/train': '0.11085', 'examples_per_second': '6.5767', 'grad_norm': '8.25', 'counters/examples': 24320, 'counters/updates': 1520}
skipping logging after 24336 examples to avoid logging too frequently
skipping logging after 24352 examples to avoid logging too frequently
skipping logging after 24368 examples to avoid logging too frequently
train stats after 24384 examples: {'rewards_train/chosen': '-2.1308', 'rewards_train/rejected': '-9.9598', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.8296', 'logps_train/rejected': '-229.86', 'logps_train/chosen': '-57.28', 'loss/train': '0.10058', 'examples_per_second': '5.9552', 'grad_norm': '9.125', 'counters/examples': 24384, 'counters/updates': 1524}
skipping logging after 24400 examples to avoid logging too frequently
skipping logging after 24416 examples to avoid logging too frequently
skipping logging after 24432 examples to avoid logging too frequently
train stats after 24448 examples: {'rewards_train/chosen': '-1.8151', 'rewards_train/rejected': '-10.13', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.3177', 'logps_train/rejected': '-243.16', 'logps_train/chosen': '-51.177', 'loss/train': '0.073433', 'examples_per_second': '4.3204', 'grad_norm': '8.8125', 'counters/examples': 24448, 'counters/updates': 1528}
skipping logging after 24464 examples to avoid logging too frequently
skipping logging after 24480 examples to avoid logging too frequently
skipping logging after 24496 examples to avoid logging too frequently
train stats after 24512 examples: {'rewards_train/chosen': '-1.852', 'rewards_train/rejected': '-10.265', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.4108', 'logps_train/rejected': '-240.96', 'logps_train/chosen': '-57.562', 'loss/train': '0.066936', 'examples_per_second': '5.4614', 'grad_norm': '9.6875', 'counters/examples': 24512, 'counters/updates': 1532}
skipping logging after 24528 examples to avoid logging too frequently
skipping logging after 24544 examples to avoid logging too frequently
skipping logging after 24560 examples to avoid logging too frequently
train stats after 24576 examples: {'rewards_train/chosen': '-1.793', 'rewards_train/rejected': '-9.5344', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.7439', 'logps_train/rejected': '-219.02', 'logps_train/chosen': '-58.551', 'loss/train': '0.066697', 'examples_per_second': '5.5828', 'grad_norm': '6.5', 'counters/examples': 24576, 'counters/updates': 1536}
skipping logging after 24592 examples to avoid logging too frequently
skipping logging after 24608 examples to avoid logging too frequently
skipping logging after 24624 examples to avoid logging too frequently
train stats after 24640 examples: {'rewards_train/chosen': '-1.4431', 'rewards_train/rejected': '-11.091', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.6467', 'logps_train/rejected': '-284.7', 'logps_train/chosen': '-63.694', 'loss/train': '0.048783', 'examples_per_second': '3.9479', 'grad_norm': '6.4688', 'counters/examples': 24640, 'counters/updates': 1540}
skipping logging after 24656 examples to avoid logging too frequently
skipping logging after 24672 examples to avoid logging too frequently
skipping logging after 24688 examples to avoid logging too frequently
train stats after 24704 examples: {'rewards_train/chosen': '-1.8457', 'rewards_train/rejected': '-10.614', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.7708', 'logps_train/rejected': '-266.75', 'logps_train/chosen': '-63.122', 'loss/train': '0.037038', 'examples_per_second': '5.2962', 'grad_norm': '4.4688', 'counters/examples': 24704, 'counters/updates': 1544}
skipping logging after 24720 examples to avoid logging too frequently
skipping logging after 24736 examples to avoid logging too frequently
skipping logging after 24752 examples to avoid logging too frequently
train stats after 24768 examples: {'rewards_train/chosen': '-2.1495', 'rewards_train/rejected': '-9.5776', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.4324', 'logps_train/rejected': '-208.22', 'logps_train/chosen': '-56.23', 'loss/train': '0.1043', 'examples_per_second': '4.788', 'grad_norm': '9.25', 'counters/examples': 24768, 'counters/updates': 1548}
skipping logging after 24784 examples to avoid logging too frequently
skipping logging after 24800 examples to avoid logging too frequently
skipping logging after 24816 examples to avoid logging too frequently
train stats after 24832 examples: {'rewards_train/chosen': '-2.3009', 'rewards_train/rejected': '-11.845', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.5464', 'logps_train/rejected': '-278.56', 'logps_train/chosen': '-71.536', 'loss/train': '0.087191', 'examples_per_second': '4.9254', 'grad_norm': '13.5', 'counters/examples': 24832, 'counters/updates': 1552}
skipping logging after 24848 examples to avoid logging too frequently
skipping logging after 24864 examples to avoid logging too frequently
skipping logging after 24880 examples to avoid logging too frequently
train stats after 24896 examples: {'rewards_train/chosen': '-1.5598', 'rewards_train/rejected': '-10.755', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.1945', 'logps_train/rejected': '-264.45', 'logps_train/chosen': '-59.215', 'loss/train': '0.085427', 'examples_per_second': '4.7189', 'grad_norm': '10.062', 'counters/examples': 24896, 'counters/updates': 1556}
skipping logging after 24912 examples to avoid logging too frequently
skipping logging after 24928 examples to avoid logging too frequently
skipping logging after 24944 examples to avoid logging too frequently
train stats after 24960 examples: {'rewards_train/chosen': '-1.6803', 'rewards_train/rejected': '-9.6098', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.9281', 'logps_train/rejected': '-226.93', 'logps_train/chosen': '-55.372', 'loss/train': '0.13026', 'examples_per_second': '5.3115', 'grad_norm': '13.438', 'counters/examples': 24960, 'counters/updates': 1560}
skipping logging after 24976 examples to avoid logging too frequently
skipping logging after 24992 examples to avoid logging too frequently
skipping logging after 25008 examples to avoid logging too frequently
train stats after 25024 examples: {'rewards_train/chosen': '-1.1303', 'rewards_train/rejected': '-9.7668', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.6365', 'logps_train/rejected': '-267.64', 'logps_train/chosen': '-62.406', 'loss/train': '0.1145', 'examples_per_second': '4.378', 'grad_norm': '9.5625', 'counters/examples': 25024, 'counters/updates': 1564}
skipping logging after 25040 examples to avoid logging too frequently
skipping logging after 25056 examples to avoid logging too frequently
skipping logging after 25072 examples to avoid logging too frequently
train stats after 25088 examples: {'rewards_train/chosen': '-1.3455', 'rewards_train/rejected': '-8.8567', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.5089', 'logps_train/rejected': '-240.57', 'logps_train/chosen': '-56.106', 'loss/train': '0.044256', 'examples_per_second': '5.3287', 'grad_norm': '7.0312', 'counters/examples': 25088, 'counters/updates': 1568}
skipping logging after 25104 examples to avoid logging too frequently
skipping logging after 25120 examples to avoid logging too frequently
skipping logging after 25136 examples to avoid logging too frequently
train stats after 25152 examples: {'rewards_train/chosen': '-1.3149', 'rewards_train/rejected': '-9.833', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.5155', 'logps_train/rejected': '-268.59', 'logps_train/chosen': '-53.477', 'loss/train': '0.049914', 'examples_per_second': '4.1053', 'grad_norm': '5.5938', 'counters/examples': 25152, 'counters/updates': 1572}
skipping logging after 25168 examples to avoid logging too frequently
skipping logging after 25184 examples to avoid logging too frequently
skipping logging after 25200 examples to avoid logging too frequently
train stats after 25216 examples: {'rewards_train/chosen': '-1.638', 'rewards_train/rejected': '-8.342', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.7028', 'logps_train/rejected': '-187.61', 'logps_train/chosen': '-60.425', 'loss/train': '0.0493', 'examples_per_second': '5.9193', 'grad_norm': '7.8125', 'counters/examples': 25216, 'counters/updates': 1576}
skipping logging after 25232 examples to avoid logging too frequently
skipping logging after 25248 examples to avoid logging too frequently
skipping logging after 25264 examples to avoid logging too frequently
train stats after 25280 examples: {'rewards_train/chosen': '-1.617', 'rewards_train/rejected': '-9.8802', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.2666', 'logps_train/rejected': '-247.91', 'logps_train/chosen': '-58.875', 'loss/train': '0.073341', 'examples_per_second': '4.877', 'grad_norm': '10.5', 'counters/examples': 25280, 'counters/updates': 1580}
skipping logging after 25296 examples to avoid logging too frequently
skipping logging after 25312 examples to avoid logging too frequently
skipping logging after 25328 examples to avoid logging too frequently
train stats after 25344 examples: {'rewards_train/chosen': '-1.9756', 'rewards_train/rejected': '-8.901', 'rewards_train/accuracies': '1', 'rewards_train/margins': '6.9243', 'logps_train/rejected': '-201.25', 'logps_train/chosen': '-55.323', 'loss/train': '0.14844', 'examples_per_second': '5.0154', 'grad_norm': '22.375', 'counters/examples': 25344, 'counters/updates': 1584}
skipping logging after 25360 examples to avoid logging too frequently
skipping logging after 25376 examples to avoid logging too frequently
skipping logging after 25392 examples to avoid logging too frequently
train stats after 25408 examples: {'rewards_train/chosen': '-1.6961', 'rewards_train/rejected': '-8.3032', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.6053', 'logps_train/rejected': '-213.18', 'logps_train/chosen': '-54.098', 'loss/train': '0.091493', 'examples_per_second': '5.3037', 'grad_norm': '7.8125', 'counters/examples': 25408, 'counters/updates': 1588}
skipping logging after 25424 examples to avoid logging too frequently
skipping logging after 25440 examples to avoid logging too frequently
skipping logging after 25456 examples to avoid logging too frequently
train stats after 25472 examples: {'rewards_train/chosen': '-2.1007', 'rewards_train/rejected': '-9.7004', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.5978', 'logps_train/rejected': '-223.64', 'logps_train/chosen': '-55.5', 'loss/train': '0.13562', 'examples_per_second': '5.0513', 'grad_norm': '18.125', 'counters/examples': 25472, 'counters/updates': 1592}
skipping logging after 25488 examples to avoid logging too frequently
skipping logging after 25504 examples to avoid logging too frequently
skipping logging after 25520 examples to avoid logging too frequently
train stats after 25536 examples: {'rewards_train/chosen': '-1.6459', 'rewards_train/rejected': '-7.7994', 'rewards_train/accuracies': '0.89062', 'rewards_train/margins': '6.1536', 'logps_train/rejected': '-195.34', 'logps_train/chosen': '-51.747', 'loss/train': '0.15084', 'examples_per_second': '5.6212', 'grad_norm': '10.75', 'counters/examples': 25536, 'counters/updates': 1596}
skipping logging after 25552 examples to avoid logging too frequently
skipping logging after 25568 examples to avoid logging too frequently
skipping logging after 25584 examples to avoid logging too frequently
train stats after 25600 examples: {'rewards_train/chosen': '-1.6424', 'rewards_train/rejected': '-9.2844', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.6453', 'logps_train/rejected': '-241.59', 'logps_train/chosen': '-61.071', 'loss/train': '0.051585', 'examples_per_second': '4.2378', 'grad_norm': '6.9375', 'counters/examples': 25600, 'counters/updates': 1600}
skipping logging after 25616 examples to avoid logging too frequently
skipping logging after 25632 examples to avoid logging too frequently
skipping logging after 25648 examples to avoid logging too frequently
train stats after 25664 examples: {'rewards_train/chosen': '-1.4925', 'rewards_train/rejected': '-9.645', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.155', 'logps_train/rejected': '-223.2', 'logps_train/chosen': '-61.168', 'loss/train': '0.016436', 'examples_per_second': '4.1945', 'grad_norm': '3.0938', 'counters/examples': 25664, 'counters/updates': 1604}
skipping logging after 25680 examples to avoid logging too frequently
skipping logging after 25696 examples to avoid logging too frequently
skipping logging after 25712 examples to avoid logging too frequently
train stats after 25728 examples: {'rewards_train/chosen': '-1.5861', 'rewards_train/rejected': '-9.9259', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.3405', 'logps_train/rejected': '-238.96', 'logps_train/chosen': '-61.913', 'loss/train': '0.054064', 'examples_per_second': '5.6327', 'grad_norm': '9.6875', 'counters/examples': 25728, 'counters/updates': 1608}
skipping logging after 25744 examples to avoid logging too frequently
skipping logging after 25760 examples to avoid logging too frequently
skipping logging after 25776 examples to avoid logging too frequently
train stats after 25792 examples: {'rewards_train/chosen': '-1.6963', 'rewards_train/rejected': '-9.7324', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.0354', 'logps_train/rejected': '-262.04', 'logps_train/chosen': '-66.744', 'loss/train': '0.051608', 'examples_per_second': '4.2104', 'grad_norm': '6.4688', 'counters/examples': 25792, 'counters/updates': 1612}
skipping logging after 25808 examples to avoid logging too frequently
skipping logging after 25824 examples to avoid logging too frequently
skipping logging after 25840 examples to avoid logging too frequently
train stats after 25856 examples: {'rewards_train/chosen': '-1.786', 'rewards_train/rejected': '-9.4279', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.6401', 'logps_train/rejected': '-216.36', 'logps_train/chosen': '-57.459', 'loss/train': '0.19229', 'examples_per_second': '4.9484', 'grad_norm': '19.75', 'counters/examples': 25856, 'counters/updates': 1616}
skipping logging after 25872 examples to avoid logging too frequently
skipping logging after 25888 examples to avoid logging too frequently
skipping logging after 25904 examples to avoid logging too frequently
train stats after 25920 examples: {'rewards_train/chosen': '-1.8247', 'rewards_train/rejected': '-10.71', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.8846', 'logps_train/rejected': '-271.21', 'logps_train/chosen': '-68.953', 'loss/train': '0.19177', 'examples_per_second': '4.5253', 'grad_norm': '22', 'counters/examples': 25920, 'counters/updates': 1620}
skipping logging after 25936 examples to avoid logging too frequently
skipping logging after 25952 examples to avoid logging too frequently
skipping logging after 25968 examples to avoid logging too frequently
train stats after 25984 examples: {'rewards_train/chosen': '-1.5434', 'rewards_train/rejected': '-9.2404', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.6967', 'logps_train/rejected': '-228.26', 'logps_train/chosen': '-59.614', 'loss/train': '0.048402', 'examples_per_second': '5.9588', 'grad_norm': '4.75', 'counters/examples': 25984, 'counters/updates': 1624}
skipping logging after 26000 examples to avoid logging too frequently
skipping logging after 26016 examples to avoid logging too frequently
skipping logging after 26032 examples to avoid logging too frequently
train stats after 26048 examples: {'rewards_train/chosen': '-1.7641', 'rewards_train/rejected': '-8.8496', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.0856', 'logps_train/rejected': '-202.78', 'logps_train/chosen': '-56.891', 'loss/train': '0.074712', 'examples_per_second': '4.74', 'grad_norm': '10.25', 'counters/examples': 26048, 'counters/updates': 1628}
skipping logging after 26064 examples to avoid logging too frequently
skipping logging after 26080 examples to avoid logging too frequently
skipping logging after 26096 examples to avoid logging too frequently
train stats after 26112 examples: {'rewards_train/chosen': '-2.0686', 'rewards_train/rejected': '-10.261', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1914', 'logps_train/rejected': '-239.67', 'logps_train/chosen': '-56.601', 'loss/train': '0.05791', 'examples_per_second': '5.0266', 'grad_norm': '9.0625', 'counters/examples': 26112, 'counters/updates': 1632}
skipping logging after 26128 examples to avoid logging too frequently
skipping logging after 26144 examples to avoid logging too frequently
skipping logging after 26160 examples to avoid logging too frequently
train stats after 26176 examples: {'rewards_train/chosen': '-1.9185', 'rewards_train/rejected': '-10.784', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.8673', 'logps_train/rejected': '-259.79', 'logps_train/chosen': '-60.262', 'loss/train': '0.060496', 'examples_per_second': '5.9989', 'grad_norm': '6.875', 'counters/examples': 26176, 'counters/updates': 1636}
skipping logging after 26192 examples to avoid logging too frequently
skipping logging after 26208 examples to avoid logging too frequently
skipping logging after 26224 examples to avoid logging too frequently
train stats after 26240 examples: {'rewards_train/chosen': '-2.0946', 'rewards_train/rejected': '-11.426', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.3345', 'logps_train/rejected': '-286.28', 'logps_train/chosen': '-69.85', 'loss/train': '0.063037', 'examples_per_second': '5.2999', 'grad_norm': '10.75', 'counters/examples': 26240, 'counters/updates': 1640}
skipping logging after 26256 examples to avoid logging too frequently
skipping logging after 26272 examples to avoid logging too frequently
skipping logging after 26288 examples to avoid logging too frequently
train stats after 26304 examples: {'rewards_train/chosen': '-2.6241', 'rewards_train/rejected': '-10.308', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.6821', 'logps_train/rejected': '-241', 'logps_train/chosen': '-68.037', 'loss/train': '0.059905', 'examples_per_second': '5.4535', 'grad_norm': '8.0625', 'counters/examples': 26304, 'counters/updates': 1644}
skipping logging after 26320 examples to avoid logging too frequently
skipping logging after 26336 examples to avoid logging too frequently
skipping logging after 26352 examples to avoid logging too frequently
train stats after 26368 examples: {'rewards_train/chosen': '-2.3226', 'rewards_train/rejected': '-10.409', 'rewards_train/accuracies': '0.89062', 'rewards_train/margins': '8.088', 'logps_train/rejected': '-209.09', 'logps_train/chosen': '-63.138', 'loss/train': '0.13993', 'examples_per_second': '4.4252', 'grad_norm': '15', 'counters/examples': 26368, 'counters/updates': 1648}
skipping logging after 26384 examples to avoid logging too frequently
skipping logging after 26400 examples to avoid logging too frequently
skipping logging after 26416 examples to avoid logging too frequently
train stats after 26432 examples: {'rewards_train/chosen': '-2.2502', 'rewards_train/rejected': '-9.8684', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.6173', 'logps_train/rejected': '-222.53', 'logps_train/chosen': '-62.28', 'loss/train': '0.064802', 'examples_per_second': '5.6516', 'grad_norm': '7.9375', 'counters/examples': 26432, 'counters/updates': 1652}
skipping logging after 26448 examples to avoid logging too frequently
skipping logging after 26464 examples to avoid logging too frequently
skipping logging after 26480 examples to avoid logging too frequently
train stats after 26496 examples: {'rewards_train/chosen': '-2.2299', 'rewards_train/rejected': '-11.655', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.4221', 'logps_train/rejected': '-259.71', 'logps_train/chosen': '-59.697', 'loss/train': '0.040823', 'examples_per_second': '5.5369', 'grad_norm': '10.75', 'counters/examples': 26496, 'counters/updates': 1656}
skipping logging after 26512 examples to avoid logging too frequently
skipping logging after 26528 examples to avoid logging too frequently
skipping logging after 26544 examples to avoid logging too frequently
train stats after 26560 examples: {'rewards_train/chosen': '-2.1315', 'rewards_train/rejected': '-9.8232', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.6895', 'logps_train/rejected': '-206.58', 'logps_train/chosen': '-65.265', 'loss/train': '0.09267', 'examples_per_second': '5.0542', 'grad_norm': '6.8125', 'counters/examples': 26560, 'counters/updates': 1660}
skipping logging after 26576 examples to avoid logging too frequently
skipping logging after 26592 examples to avoid logging too frequently
skipping logging after 26608 examples to avoid logging too frequently
train stats after 26624 examples: {'rewards_train/chosen': '-2.1105', 'rewards_train/rejected': '-10.117', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.0073', 'logps_train/rejected': '-230.18', 'logps_train/chosen': '-53.885', 'loss/train': '0.027288', 'examples_per_second': '6.845', 'grad_norm': '4.5938', 'counters/examples': 26624, 'counters/updates': 1664}
skipping logging after 26640 examples to avoid logging too frequently
skipping logging after 26656 examples to avoid logging too frequently
skipping logging after 26672 examples to avoid logging too frequently
train stats after 26688 examples: {'rewards_train/chosen': '-2.2777', 'rewards_train/rejected': '-10.88', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.6006', 'logps_train/rejected': '-248.95', 'logps_train/chosen': '-67.268', 'loss/train': '0.010963', 'examples_per_second': '5.0978', 'grad_norm': '2.3125', 'counters/examples': 26688, 'counters/updates': 1668}
skipping logging after 26704 examples to avoid logging too frequently
skipping logging after 26720 examples to avoid logging too frequently
skipping logging after 26736 examples to avoid logging too frequently
train stats after 26752 examples: {'rewards_train/chosen': '-2.2666', 'rewards_train/rejected': '-10.388', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1196', 'logps_train/rejected': '-254.44', 'logps_train/chosen': '-57.307', 'loss/train': '0.05198', 'examples_per_second': '4.6521', 'grad_norm': '12.875', 'counters/examples': 26752, 'counters/updates': 1672}
skipping logging after 26768 examples to avoid logging too frequently
skipping logging after 26784 examples to avoid logging too frequently
skipping logging after 26800 examples to avoid logging too frequently
train stats after 26816 examples: {'rewards_train/chosen': '-2.3013', 'rewards_train/rejected': '-9.2803', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '6.9786', 'logps_train/rejected': '-216.83', 'logps_train/chosen': '-59.299', 'loss/train': '0.15109', 'examples_per_second': '4.508', 'grad_norm': '17.375', 'counters/examples': 26816, 'counters/updates': 1676}
skipping logging after 26832 examples to avoid logging too frequently
skipping logging after 26848 examples to avoid logging too frequently
skipping logging after 26864 examples to avoid logging too frequently
train stats after 26880 examples: {'rewards_train/chosen': '-2.0752', 'rewards_train/rejected': '-10.022', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.9479', 'logps_train/rejected': '-225.54', 'logps_train/chosen': '-57.314', 'loss/train': '0.084977', 'examples_per_second': '4.3922', 'grad_norm': '8.8125', 'counters/examples': 26880, 'counters/updates': 1680}
skipping logging after 26896 examples to avoid logging too frequently
skipping logging after 26912 examples to avoid logging too frequently
skipping logging after 26928 examples to avoid logging too frequently
train stats after 26944 examples: {'rewards_train/chosen': '-2.0412', 'rewards_train/rejected': '-10.784', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.743', 'logps_train/rejected': '-259.81', 'logps_train/chosen': '-68.336', 'loss/train': '0.05632', 'examples_per_second': '4.7183', 'grad_norm': '9.875', 'counters/examples': 26944, 'counters/updates': 1684}
skipping logging after 26960 examples to avoid logging too frequently
skipping logging after 26976 examples to avoid logging too frequently
skipping logging after 26992 examples to avoid logging too frequently
train stats after 27008 examples: {'rewards_train/chosen': '-2.209', 'rewards_train/rejected': '-11.214', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.0052', 'logps_train/rejected': '-257.63', 'logps_train/chosen': '-69.04', 'loss/train': '0.053459', 'examples_per_second': '4.5582', 'grad_norm': '4.9062', 'counters/examples': 27008, 'counters/updates': 1688}
skipping logging after 27024 examples to avoid logging too frequently
skipping logging after 27040 examples to avoid logging too frequently
skipping logging after 27056 examples to avoid logging too frequently
train stats after 27072 examples: {'rewards_train/chosen': '-2.0624', 'rewards_train/rejected': '-10.727', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.6628', 'logps_train/rejected': '-256.75', 'logps_train/chosen': '-62.976', 'loss/train': '0.086578', 'examples_per_second': '4.4591', 'grad_norm': '12.312', 'counters/examples': 27072, 'counters/updates': 1692}
skipping logging after 27088 examples to avoid logging too frequently
skipping logging after 27104 examples to avoid logging too frequently
skipping logging after 27120 examples to avoid logging too frequently
train stats after 27136 examples: {'rewards_train/chosen': '-2.442', 'rewards_train/rejected': '-9.2627', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.8186', 'logps_train/rejected': '-222.48', 'logps_train/chosen': '-62.939', 'loss/train': '0.17552', 'examples_per_second': '5.1965', 'grad_norm': '25.25', 'counters/examples': 27136, 'counters/updates': 1696}
skipping logging after 27152 examples to avoid logging too frequently
skipping logging after 27168 examples to avoid logging too frequently
skipping logging after 27184 examples to avoid logging too frequently
train stats after 27200 examples: {'rewards_train/chosen': '-2.0309', 'rewards_train/rejected': '-9.0257', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.9956', 'logps_train/rejected': '-241.44', 'logps_train/chosen': '-68.861', 'loss/train': '0.079244', 'examples_per_second': '4.3789', 'grad_norm': '10.062', 'counters/examples': 27200, 'counters/updates': 1700}
skipping logging after 27216 examples to avoid logging too frequently
skipping logging after 27232 examples to avoid logging too frequently
skipping logging after 27248 examples to avoid logging too frequently
train stats after 27264 examples: {'rewards_train/chosen': '-2.0487', 'rewards_train/rejected': '-10.473', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.4231', 'logps_train/rejected': '-254.05', 'logps_train/chosen': '-65.027', 'loss/train': '0.0537', 'examples_per_second': '5.4302', 'grad_norm': '8.125', 'counters/examples': 27264, 'counters/updates': 1704}
skipping logging after 27280 examples to avoid logging too frequently
skipping logging after 27296 examples to avoid logging too frequently
skipping logging after 27312 examples to avoid logging too frequently
train stats after 27328 examples: {'rewards_train/chosen': '-2.1248', 'rewards_train/rejected': '-11.537', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.4088', 'logps_train/rejected': '-287.48', 'logps_train/chosen': '-63.137', 'loss/train': '0.068024', 'examples_per_second': '4.304', 'grad_norm': '6.625', 'counters/examples': 27328, 'counters/updates': 1708}
skipping logging after 27344 examples to avoid logging too frequently
skipping logging after 27360 examples to avoid logging too frequently
skipping logging after 27376 examples to avoid logging too frequently
train stats after 27392 examples: {'rewards_train/chosen': '-2.3513', 'rewards_train/rejected': '-10.785', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.4343', 'logps_train/rejected': '-234.6', 'logps_train/chosen': '-66.674', 'loss/train': '0.098934', 'examples_per_second': '5.3762', 'grad_norm': '11.562', 'counters/examples': 27392, 'counters/updates': 1712}
skipping logging after 27408 examples to avoid logging too frequently
skipping logging after 27424 examples to avoid logging too frequently
skipping logging after 27440 examples to avoid logging too frequently
train stats after 27456 examples: {'rewards_train/chosen': '-2.3757', 'rewards_train/rejected': '-10.133', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.7595', 'logps_train/rejected': '-248.53', 'logps_train/chosen': '-69.667', 'loss/train': '0.13361', 'examples_per_second': '5.4625', 'grad_norm': '15.625', 'counters/examples': 27456, 'counters/updates': 1716}
skipping logging after 27472 examples to avoid logging too frequently
skipping logging after 27488 examples to avoid logging too frequently
skipping logging after 27504 examples to avoid logging too frequently
train stats after 27520 examples: {'rewards_train/chosen': '-2.4579', 'rewards_train/rejected': '-10.018', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.5603', 'logps_train/rejected': '-230.68', 'logps_train/chosen': '-70.262', 'loss/train': '0.035535', 'examples_per_second': '5.088', 'grad_norm': '8.5625', 'counters/examples': 27520, 'counters/updates': 1720}
skipping logging after 27536 examples to avoid logging too frequently
skipping logging after 27552 examples to avoid logging too frequently
skipping logging after 27568 examples to avoid logging too frequently
train stats after 27584 examples: {'rewards_train/chosen': '-2.1632', 'rewards_train/rejected': '-10.364', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.2031', 'logps_train/rejected': '-228.3', 'logps_train/chosen': '-54.467', 'loss/train': '0.12997', 'examples_per_second': '5.2371', 'grad_norm': '12.938', 'counters/examples': 27584, 'counters/updates': 1724}
skipping logging after 27600 examples to avoid logging too frequently
skipping logging after 27616 examples to avoid logging too frequently
skipping logging after 27632 examples to avoid logging too frequently
train stats after 27648 examples: {'rewards_train/chosen': '-1.7409', 'rewards_train/rejected': '-10.512', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.7712', 'logps_train/rejected': '-245.55', 'logps_train/chosen': '-54.963', 'loss/train': '0.025261', 'examples_per_second': '4.4282', 'grad_norm': '5.0625', 'counters/examples': 27648, 'counters/updates': 1728}
skipping logging after 27664 examples to avoid logging too frequently
skipping logging after 27680 examples to avoid logging too frequently
skipping logging after 27696 examples to avoid logging too frequently
train stats after 27712 examples: {'rewards_train/chosen': '-2.2601', 'rewards_train/rejected': '-10.618', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.3613', 'logps_train/rejected': '-232.26', 'logps_train/chosen': '-57.467', 'loss/train': '0.11867', 'examples_per_second': '5.64', 'grad_norm': '12.5', 'counters/examples': 27712, 'counters/updates': 1732}
skipping logging after 27728 examples to avoid logging too frequently
skipping logging after 27744 examples to avoid logging too frequently
skipping logging after 27760 examples to avoid logging too frequently
train stats after 27776 examples: {'rewards_train/chosen': '-1.9568', 'rewards_train/rejected': '-9.8545', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.897', 'logps_train/rejected': '-232.32', 'logps_train/chosen': '-55.822', 'loss/train': '0.048705', 'examples_per_second': '5.1535', 'grad_norm': '7.3438', 'counters/examples': 27776, 'counters/updates': 1736}
skipping logging after 27792 examples to avoid logging too frequently
skipping logging after 27808 examples to avoid logging too frequently
skipping logging after 27824 examples to avoid logging too frequently
train stats after 27840 examples: {'rewards_train/chosen': '-2.1954', 'rewards_train/rejected': '-9.558', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.3634', 'logps_train/rejected': '-220.49', 'logps_train/chosen': '-66.748', 'loss/train': '0.13216', 'examples_per_second': '5.42', 'grad_norm': '17.75', 'counters/examples': 27840, 'counters/updates': 1740}
skipping logging after 27856 examples to avoid logging too frequently
skipping logging after 27872 examples to avoid logging too frequently
skipping logging after 27888 examples to avoid logging too frequently
train stats after 27904 examples: {'rewards_train/chosen': '-2.0175', 'rewards_train/rejected': '-9.5161', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.4983', 'logps_train/rejected': '-248.15', 'logps_train/chosen': '-61.475', 'loss/train': '0.084091', 'examples_per_second': '4.5828', 'grad_norm': '10.938', 'counters/examples': 27904, 'counters/updates': 1744}
skipping logging after 27920 examples to avoid logging too frequently
skipping logging after 27936 examples to avoid logging too frequently
skipping logging after 27952 examples to avoid logging too frequently
train stats after 27968 examples: {'rewards_train/chosen': '-2.0412', 'rewards_train/rejected': '-10.16', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.1194', 'logps_train/rejected': '-262.34', 'logps_train/chosen': '-53.886', 'loss/train': '0.081266', 'examples_per_second': '4.7601', 'grad_norm': '10.125', 'counters/examples': 27968, 'counters/updates': 1748}
skipping logging after 27984 examples to avoid logging too frequently
skipping logging after 28000 examples to avoid logging too frequently
Running evaluation after 28000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:08,  2.20s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:03,  2.12s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:55,  1.90s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.89s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.55s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.65s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.49s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.49s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:22,  1.30s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.24s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.33s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.34s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.27s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.30s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.26s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:37<00:07,  1.30s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.48s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.41s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.61s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.42s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.42s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.44s/it]
eval after 28000: {'rewards_eval/chosen': '-8.935', 'rewards_eval/rejected': '-9.2898', 'rewards_eval/accuracies': '0.5293', 'rewards_eval/margins': '0.35466', 'logps_eval/rejected': '-240.56', 'logps_eval/chosen': '-234.26', 'loss/eval': '1.9257'}
skipping logging after 28016 examples to avoid logging too frequently
train stats after 28032 examples: {'rewards_train/chosen': '-2.0244', 'rewards_train/rejected': '-9.7698', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.7438', 'logps_train/rejected': '-245.13', 'logps_train/chosen': '-59.041', 'loss/train': '0.074544', 'examples_per_second': '5.1127', 'grad_norm': '6.25', 'counters/examples': 28032, 'counters/updates': 1752}
skipping logging after 28048 examples to avoid logging too frequently
skipping logging after 28064 examples to avoid logging too frequently
skipping logging after 28080 examples to avoid logging too frequently
train stats after 28096 examples: {'rewards_train/chosen': '-2.1728', 'rewards_train/rejected': '-10.121', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.9512', 'logps_train/rejected': '-244.15', 'logps_train/chosen': '-63.845', 'loss/train': '0.043105', 'examples_per_second': '4.6704', 'grad_norm': '7.375', 'counters/examples': 28096, 'counters/updates': 1756}
skipping logging after 28112 examples to avoid logging too frequently
skipping logging after 28128 examples to avoid logging too frequently
skipping logging after 28144 examples to avoid logging too frequently
train stats after 28160 examples: {'rewards_train/chosen': '-2.2988', 'rewards_train/rejected': '-9.9497', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.6493', 'logps_train/rejected': '-241.7', 'logps_train/chosen': '-61.046', 'loss/train': '0.062303', 'examples_per_second': '5.5416', 'grad_norm': '10.812', 'counters/examples': 28160, 'counters/updates': 1760}
skipping logging after 28176 examples to avoid logging too frequently
skipping logging after 28192 examples to avoid logging too frequently
skipping logging after 28208 examples to avoid logging too frequently
train stats after 28224 examples: {'rewards_train/chosen': '-2.8206', 'rewards_train/rejected': '-10.066', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.2473', 'logps_train/rejected': '-208.58', 'logps_train/chosen': '-59.296', 'loss/train': '0.096839', 'examples_per_second': '5.3483', 'grad_norm': '12.062', 'counters/examples': 28224, 'counters/updates': 1764}
skipping logging after 28240 examples to avoid logging too frequently
skipping logging after 28256 examples to avoid logging too frequently
skipping logging after 28272 examples to avoid logging too frequently
train stats after 28288 examples: {'rewards_train/chosen': '-2.4949', 'rewards_train/rejected': '-11.09', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.5958', 'logps_train/rejected': '-254.86', 'logps_train/chosen': '-67.444', 'loss/train': '0.088977', 'examples_per_second': '4.6849', 'grad_norm': '8.0625', 'counters/examples': 28288, 'counters/updates': 1768}
skipping logging after 28304 examples to avoid logging too frequently
skipping logging after 28320 examples to avoid logging too frequently
skipping logging after 28336 examples to avoid logging too frequently
train stats after 28352 examples: {'rewards_train/chosen': '-2.4284', 'rewards_train/rejected': '-11.873', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.4429', 'logps_train/rejected': '-277.67', 'logps_train/chosen': '-67.182', 'loss/train': '0.049849', 'examples_per_second': '4.6476', 'grad_norm': '4.25', 'counters/examples': 28352, 'counters/updates': 1772}
skipping logging after 28368 examples to avoid logging too frequently
skipping logging after 28384 examples to avoid logging too frequently
skipping logging after 28400 examples to avoid logging too frequently
train stats after 28416 examples: {'rewards_train/chosen': '-2.6806', 'rewards_train/rejected': '-11.305', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.6222', 'logps_train/rejected': '-241.59', 'logps_train/chosen': '-68.821', 'loss/train': '0.088273', 'examples_per_second': '6.4431', 'grad_norm': '15.875', 'counters/examples': 28416, 'counters/updates': 1776}
skipping logging after 28432 examples to avoid logging too frequently
skipping logging after 28448 examples to avoid logging too frequently
skipping logging after 28464 examples to avoid logging too frequently
train stats after 28480 examples: {'rewards_train/chosen': '-2.4149', 'rewards_train/rejected': '-9.8542', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.4397', 'logps_train/rejected': '-221.07', 'logps_train/chosen': '-64.701', 'loss/train': '0.1269', 'examples_per_second': '5.032', 'grad_norm': '18', 'counters/examples': 28480, 'counters/updates': 1780}
skipping logging after 28496 examples to avoid logging too frequently
skipping logging after 28512 examples to avoid logging too frequently
skipping logging after 28528 examples to avoid logging too frequently
train stats after 28544 examples: {'rewards_train/chosen': '-2.2961', 'rewards_train/rejected': '-11.089', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.7944', 'logps_train/rejected': '-286.11', 'logps_train/chosen': '-62.418', 'loss/train': '0.049973', 'examples_per_second': '4.7553', 'grad_norm': '9.875', 'counters/examples': 28544, 'counters/updates': 1784}
skipping logging after 28560 examples to avoid logging too frequently
skipping logging after 28576 examples to avoid logging too frequently
skipping logging after 28592 examples to avoid logging too frequently
train stats after 28608 examples: {'rewards_train/chosen': '-2.1019', 'rewards_train/rejected': '-10.677', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.5729', 'logps_train/rejected': '-254.57', 'logps_train/chosen': '-70.184', 'loss/train': '0.11623', 'examples_per_second': '4.8712', 'grad_norm': '14.938', 'counters/examples': 28608, 'counters/updates': 1788}
skipping logging after 28624 examples to avoid logging too frequently
skipping logging after 28640 examples to avoid logging too frequently
skipping logging after 28656 examples to avoid logging too frequently
train stats after 28672 examples: {'rewards_train/chosen': '-1.8338', 'rewards_train/rejected': '-8.4521', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.618', 'logps_train/rejected': '-243.8', 'logps_train/chosen': '-55.489', 'loss/train': '0.1085', 'examples_per_second': '4.6915', 'grad_norm': '9', 'counters/examples': 28672, 'counters/updates': 1792}
skipping logging after 28688 examples to avoid logging too frequently
skipping logging after 28704 examples to avoid logging too frequently
skipping logging after 28720 examples to avoid logging too frequently
train stats after 28736 examples: {'rewards_train/chosen': '-1.6094', 'rewards_train/rejected': '-8.0591', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.4485', 'logps_train/rejected': '-195.72', 'logps_train/chosen': '-58.382', 'loss/train': '0.0828', 'examples_per_second': '5.3361', 'grad_norm': '5.5312', 'counters/examples': 28736, 'counters/updates': 1796}
skipping logging after 28752 examples to avoid logging too frequently
skipping logging after 28768 examples to avoid logging too frequently
skipping logging after 28784 examples to avoid logging too frequently
train stats after 28800 examples: {'rewards_train/chosen': '-1.866', 'rewards_train/rejected': '-8.5593', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.6914', 'logps_train/rejected': '-225.38', 'logps_train/chosen': '-56.199', 'loss/train': '0.10057', 'examples_per_second': '5.3052', 'grad_norm': '6.5312', 'counters/examples': 28800, 'counters/updates': 1800}
skipping logging after 28816 examples to avoid logging too frequently
skipping logging after 28832 examples to avoid logging too frequently
skipping logging after 28848 examples to avoid logging too frequently
train stats after 28864 examples: {'rewards_train/chosen': '-1.9655', 'rewards_train/rejected': '-10.213', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.248', 'logps_train/rejected': '-272.82', 'logps_train/chosen': '-60.34', 'loss/train': '0.046595', 'examples_per_second': '4.3868', 'grad_norm': '7.1875', 'counters/examples': 28864, 'counters/updates': 1804}
skipping logging after 28880 examples to avoid logging too frequently
skipping logging after 28896 examples to avoid logging too frequently
skipping logging after 28912 examples to avoid logging too frequently
train stats after 28928 examples: {'rewards_train/chosen': '-2.0757', 'rewards_train/rejected': '-8.5915', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.5158', 'logps_train/rejected': '-216.32', 'logps_train/chosen': '-70.306', 'loss/train': '0.13185', 'examples_per_second': '5.6622', 'grad_norm': '11.5', 'counters/examples': 28928, 'counters/updates': 1808}
skipping logging after 28944 examples to avoid logging too frequently
skipping logging after 28960 examples to avoid logging too frequently
skipping logging after 28976 examples to avoid logging too frequently
train stats after 28992 examples: {'rewards_train/chosen': '-1.9666', 'rewards_train/rejected': '-10.383', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.4143', 'logps_train/rejected': '-262.88', 'logps_train/chosen': '-60.415', 'loss/train': '0.034015', 'examples_per_second': '5.2919', 'grad_norm': '8.875', 'counters/examples': 28992, 'counters/updates': 1812}
skipping logging after 29008 examples to avoid logging too frequently
skipping logging after 29024 examples to avoid logging too frequently
skipping logging after 29040 examples to avoid logging too frequently
train stats after 29056 examples: {'rewards_train/chosen': '-2.0428', 'rewards_train/rejected': '-9.8636', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.8225', 'logps_train/rejected': '-232.47', 'logps_train/chosen': '-53.893', 'loss/train': '0.066315', 'examples_per_second': '4.9291', 'grad_norm': '4.5938', 'counters/examples': 29056, 'counters/updates': 1816}
skipping logging after 29072 examples to avoid logging too frequently
skipping logging after 29088 examples to avoid logging too frequently
skipping logging after 29104 examples to avoid logging too frequently
train stats after 29120 examples: {'rewards_train/chosen': '-2.1169', 'rewards_train/rejected': '-9.5002', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.3824', 'logps_train/rejected': '-222.48', 'logps_train/chosen': '-61.634', 'loss/train': '0.074623', 'examples_per_second': '4.5515', 'grad_norm': '7.1562', 'counters/examples': 29120, 'counters/updates': 1820}
skipping logging after 29136 examples to avoid logging too frequently
skipping logging after 29152 examples to avoid logging too frequently
skipping logging after 29168 examples to avoid logging too frequently
train stats after 29184 examples: {'rewards_train/chosen': '-2.0132', 'rewards_train/rejected': '-11.034', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.0193', 'logps_train/rejected': '-274.74', 'logps_train/chosen': '-63.689', 'loss/train': '0.042127', 'examples_per_second': '4.5474', 'grad_norm': '6.5312', 'counters/examples': 29184, 'counters/updates': 1824}
skipping logging after 29200 examples to avoid logging too frequently
skipping logging after 29216 examples to avoid logging too frequently
skipping logging after 29232 examples to avoid logging too frequently
train stats after 29248 examples: {'rewards_train/chosen': '-2.1931', 'rewards_train/rejected': '-11.098', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.9058', 'logps_train/rejected': '-267.38', 'logps_train/chosen': '-69.914', 'loss/train': '0.12077', 'examples_per_second': '5.5581', 'grad_norm': '18.875', 'counters/examples': 29248, 'counters/updates': 1828}
skipping logging after 29264 examples to avoid logging too frequently
skipping logging after 29280 examples to avoid logging too frequently
skipping logging after 29296 examples to avoid logging too frequently
train stats after 29312 examples: {'rewards_train/chosen': '-2.0891', 'rewards_train/rejected': '-10.047', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.9563', 'logps_train/rejected': '-240.31', 'logps_train/chosen': '-60.146', 'loss/train': '0.088715', 'examples_per_second': '4.2465', 'grad_norm': '10.688', 'counters/examples': 29312, 'counters/updates': 1832}
skipping logging after 29328 examples to avoid logging too frequently
skipping logging after 29344 examples to avoid logging too frequently
skipping logging after 29360 examples to avoid logging too frequently
train stats after 29376 examples: {'rewards_train/chosen': '-2.1629', 'rewards_train/rejected': '-10.648', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.4832', 'logps_train/rejected': '-265.78', 'logps_train/chosen': '-62.26', 'loss/train': '0.066283', 'examples_per_second': '4.1554', 'grad_norm': '12.125', 'counters/examples': 29376, 'counters/updates': 1836}
skipping logging after 29392 examples to avoid logging too frequently
skipping logging after 29408 examples to avoid logging too frequently
skipping logging after 29424 examples to avoid logging too frequently
train stats after 29440 examples: {'rewards_train/chosen': '-2.3696', 'rewards_train/rejected': '-10.879', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.5109', 'logps_train/rejected': '-292.09', 'logps_train/chosen': '-77.087', 'loss/train': '0.040537', 'examples_per_second': '4.4689', 'grad_norm': '3.8281', 'counters/examples': 29440, 'counters/updates': 1840}
skipping logging after 29456 examples to avoid logging too frequently
skipping logging after 29472 examples to avoid logging too frequently
skipping logging after 29488 examples to avoid logging too frequently
train stats after 29504 examples: {'rewards_train/chosen': '-2.0962', 'rewards_train/rejected': '-8.6545', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.5568', 'logps_train/rejected': '-193.68', 'logps_train/chosen': '-65.941', 'loss/train': '0.1757', 'examples_per_second': '4.1393', 'grad_norm': '20.125', 'counters/examples': 29504, 'counters/updates': 1844}
skipping logging after 29520 examples to avoid logging too frequently
skipping logging after 29536 examples to avoid logging too frequently
skipping logging after 29552 examples to avoid logging too frequently
train stats after 29568 examples: {'rewards_train/chosen': '-2.016', 'rewards_train/rejected': '-8.2329', 'rewards_train/accuracies': '0.89062', 'rewards_train/margins': '6.2168', 'logps_train/rejected': '-203.13', 'logps_train/chosen': '-68.001', 'loss/train': '0.22998', 'examples_per_second': '5.2428', 'grad_norm': '18.375', 'counters/examples': 29568, 'counters/updates': 1848}
skipping logging after 29584 examples to avoid logging too frequently
skipping logging after 29600 examples to avoid logging too frequently
skipping logging after 29616 examples to avoid logging too frequently
train stats after 29632 examples: {'rewards_train/chosen': '-1.9879', 'rewards_train/rejected': '-7.5695', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '5.5807', 'logps_train/rejected': '-206.2', 'logps_train/chosen': '-57.62', 'loss/train': '0.13957', 'examples_per_second': '5.4877', 'grad_norm': '13.875', 'counters/examples': 29632, 'counters/updates': 1852}
skipping logging after 29648 examples to avoid logging too frequently
skipping logging after 29664 examples to avoid logging too frequently
skipping logging after 29680 examples to avoid logging too frequently
train stats after 29696 examples: {'rewards_train/chosen': '-1.496', 'rewards_train/rejected': '-8.5365', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.0383', 'logps_train/rejected': '-259.95', 'logps_train/chosen': '-58.769', 'loss/train': '0.04746', 'examples_per_second': '4.9372', 'grad_norm': '4.7188', 'counters/examples': 29696, 'counters/updates': 1856}
skipping logging after 29712 examples to avoid logging too frequently
skipping logging after 29728 examples to avoid logging too frequently
skipping logging after 29744 examples to avoid logging too frequently
train stats after 29760 examples: {'rewards_train/chosen': '-1.5772', 'rewards_train/rejected': '-8.8479', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.2678', 'logps_train/rejected': '-244.22', 'logps_train/chosen': '-57.783', 'loss/train': '0.053931', 'examples_per_second': '5.4727', 'grad_norm': '7.125', 'counters/examples': 29760, 'counters/updates': 1860}
skipping logging after 29776 examples to avoid logging too frequently
skipping logging after 29792 examples to avoid logging too frequently
skipping logging after 29808 examples to avoid logging too frequently
train stats after 29824 examples: {'rewards_train/chosen': '-1.9801', 'rewards_train/rejected': '-9.1382', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.1602', 'logps_train/rejected': '-263.57', 'logps_train/chosen': '-62.65', 'loss/train': '0.076911', 'examples_per_second': '4.6039', 'grad_norm': '12.938', 'counters/examples': 29824, 'counters/updates': 1864}
skipping logging after 29840 examples to avoid logging too frequently
skipping logging after 29856 examples to avoid logging too frequently
skipping logging after 29872 examples to avoid logging too frequently
train stats after 29888 examples: {'rewards_train/chosen': '-1.8978', 'rewards_train/rejected': '-8.2458', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.3486', 'logps_train/rejected': '-219.64', 'logps_train/chosen': '-74.811', 'loss/train': '0.054843', 'examples_per_second': '5.3938', 'grad_norm': '4.375', 'counters/examples': 29888, 'counters/updates': 1868}
skipping logging after 29904 examples to avoid logging too frequently
skipping logging after 29920 examples to avoid logging too frequently
skipping logging after 29936 examples to avoid logging too frequently
train stats after 29952 examples: {'rewards_train/chosen': '-1.9177', 'rewards_train/rejected': '-8.1792', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.2628', 'logps_train/rejected': '-210.8', 'logps_train/chosen': '-56.479', 'loss/train': '0.13439', 'examples_per_second': '5.381', 'grad_norm': '22.125', 'counters/examples': 29952, 'counters/updates': 1872}
skipping logging after 29968 examples to avoid logging too frequently
skipping logging after 29984 examples to avoid logging too frequently
skipping logging after 30000 examples to avoid logging too frequently
train stats after 30016 examples: {'rewards_train/chosen': '-1.4373', 'rewards_train/rejected': '-8.2783', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.8428', 'logps_train/rejected': '-223.73', 'logps_train/chosen': '-57.111', 'loss/train': '0.030014', 'examples_per_second': '4.9543', 'grad_norm': '5.0312', 'counters/examples': 30016, 'counters/updates': 1876}
skipping logging after 30032 examples to avoid logging too frequently
skipping logging after 30048 examples to avoid logging too frequently
skipping logging after 30064 examples to avoid logging too frequently
train stats after 30080 examples: {'rewards_train/chosen': '-2.201', 'rewards_train/rejected': '-8.2487', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.0461', 'logps_train/rejected': '-199.2', 'logps_train/chosen': '-60.216', 'loss/train': '0.14084', 'examples_per_second': '4.9531', 'grad_norm': '19', 'counters/examples': 30080, 'counters/updates': 1880}
skipping logging after 30096 examples to avoid logging too frequently
skipping logging after 30112 examples to avoid logging too frequently
skipping logging after 30128 examples to avoid logging too frequently
train stats after 30144 examples: {'rewards_train/chosen': '-1.5724', 'rewards_train/rejected': '-8.6528', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.0812', 'logps_train/rejected': '-266.93', 'logps_train/chosen': '-63.734', 'loss/train': '0.033866', 'examples_per_second': '4.5894', 'grad_norm': '3.875', 'counters/examples': 30144, 'counters/updates': 1884}
skipping logging after 30160 examples to avoid logging too frequently
skipping logging after 30176 examples to avoid logging too frequently
skipping logging after 30192 examples to avoid logging too frequently
train stats after 30208 examples: {'rewards_train/chosen': '-1.9021', 'rewards_train/rejected': '-7.8513', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '5.9515', 'logps_train/rejected': '-206.68', 'logps_train/chosen': '-61.442', 'loss/train': '0.083974', 'examples_per_second': '5.368', 'grad_norm': '11.5', 'counters/examples': 30208, 'counters/updates': 1888}
skipping logging after 30224 examples to avoid logging too frequently
skipping logging after 30240 examples to avoid logging too frequently
skipping logging after 30256 examples to avoid logging too frequently
train stats after 30272 examples: {'rewards_train/chosen': '-1.5449', 'rewards_train/rejected': '-7.7294', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.1856', 'logps_train/rejected': '-208.82', 'logps_train/chosen': '-59.614', 'loss/train': '0.047003', 'examples_per_second': '6.2102', 'grad_norm': '5.5625', 'counters/examples': 30272, 'counters/updates': 1892}
skipping logging after 30288 examples to avoid logging too frequently
skipping logging after 30304 examples to avoid logging too frequently
skipping logging after 30320 examples to avoid logging too frequently
train stats after 30336 examples: {'rewards_train/chosen': '-1.5707', 'rewards_train/rejected': '-8.3456', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.775', 'logps_train/rejected': '-190.2', 'logps_train/chosen': '-52.892', 'loss/train': '0.056698', 'examples_per_second': '5.5875', 'grad_norm': '5.5625', 'counters/examples': 30336, 'counters/updates': 1896}
skipping logging after 30352 examples to avoid logging too frequently
skipping logging after 30368 examples to avoid logging too frequently
skipping logging after 30384 examples to avoid logging too frequently
train stats after 30400 examples: {'rewards_train/chosen': '-2.0368', 'rewards_train/rejected': '-10.04', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.0016', 'logps_train/rejected': '-244.13', 'logps_train/chosen': '-63.15', 'loss/train': '0.037966', 'examples_per_second': '4.7094', 'grad_norm': '5.2812', 'counters/examples': 30400, 'counters/updates': 1900}
skipping logging after 30416 examples to avoid logging too frequently
skipping logging after 30432 examples to avoid logging too frequently
skipping logging after 30448 examples to avoid logging too frequently
train stats after 30464 examples: {'rewards_train/chosen': '-2.4431', 'rewards_train/rejected': '-9.0747', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.6309', 'logps_train/rejected': '-195.94', 'logps_train/chosen': '-69.519', 'loss/train': '0.11732', 'examples_per_second': '6.3538', 'grad_norm': '13.625', 'counters/examples': 30464, 'counters/updates': 1904}
skipping logging after 30480 examples to avoid logging too frequently
skipping logging after 30496 examples to avoid logging too frequently
skipping logging after 30512 examples to avoid logging too frequently
train stats after 30528 examples: {'rewards_train/chosen': '-2.3198', 'rewards_train/rejected': '-9.1699', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.8505', 'logps_train/rejected': '-224.46', 'logps_train/chosen': '-58.946', 'loss/train': '0.077156', 'examples_per_second': '5.2079', 'grad_norm': '11.188', 'counters/examples': 30528, 'counters/updates': 1908}
skipping logging after 30544 examples to avoid logging too frequently
skipping logging after 30560 examples to avoid logging too frequently
skipping logging after 30576 examples to avoid logging too frequently
train stats after 30592 examples: {'rewards_train/chosen': '-2.2956', 'rewards_train/rejected': '-10.478', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.1744', 'logps_train/rejected': '-229.69', 'logps_train/chosen': '-58.211', 'loss/train': '0.09837', 'examples_per_second': '5.1181', 'grad_norm': '11.125', 'counters/examples': 30592, 'counters/updates': 1912}
skipping logging after 30608 examples to avoid logging too frequently
skipping logging after 30624 examples to avoid logging too frequently
skipping logging after 30640 examples to avoid logging too frequently
train stats after 30656 examples: {'rewards_train/chosen': '-2.5757', 'rewards_train/rejected': '-9.895', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.3218', 'logps_train/rejected': '-224.86', 'logps_train/chosen': '-62.884', 'loss/train': '0.089475', 'examples_per_second': '4.4249', 'grad_norm': '11.375', 'counters/examples': 30656, 'counters/updates': 1916}
skipping logging after 30672 examples to avoid logging too frequently
skipping logging after 30688 examples to avoid logging too frequently
skipping logging after 30704 examples to avoid logging too frequently
train stats after 30720 examples: {'rewards_train/chosen': '-2.5635', 'rewards_train/rejected': '-10.562', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.9995', 'logps_train/rejected': '-251.4', 'logps_train/chosen': '-72.686', 'loss/train': '0.046066', 'examples_per_second': '5.6687', 'grad_norm': '8.0625', 'counters/examples': 30720, 'counters/updates': 1920}
skipping logging after 30736 examples to avoid logging too frequently
skipping logging after 30752 examples to avoid logging too frequently
skipping logging after 30768 examples to avoid logging too frequently
train stats after 30784 examples: {'rewards_train/chosen': '-2.3739', 'rewards_train/rejected': '-10.479', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.104', 'logps_train/rejected': '-246.87', 'logps_train/chosen': '-57.431', 'loss/train': '0.06951', 'examples_per_second': '5.0564', 'grad_norm': '11.75', 'counters/examples': 30784, 'counters/updates': 1924}
skipping logging after 30800 examples to avoid logging too frequently
skipping logging after 30816 examples to avoid logging too frequently
skipping logging after 30832 examples to avoid logging too frequently
train stats after 30848 examples: {'rewards_train/chosen': '-1.9314', 'rewards_train/rejected': '-9.2285', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.2986', 'logps_train/rejected': '-221.86', 'logps_train/chosen': '-61.209', 'loss/train': '0.040317', 'examples_per_second': '5.6778', 'grad_norm': '7.125', 'counters/examples': 30848, 'counters/updates': 1928}
skipping logging after 30864 examples to avoid logging too frequently
skipping logging after 30880 examples to avoid logging too frequently
skipping logging after 30896 examples to avoid logging too frequently
train stats after 30912 examples: {'rewards_train/chosen': '-2.0226', 'rewards_train/rejected': '-9.7561', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.7341', 'logps_train/rejected': '-221.89', 'logps_train/chosen': '-52.493', 'loss/train': '0.040871', 'examples_per_second': '5.8938', 'grad_norm': '8.5', 'counters/examples': 30912, 'counters/updates': 1932}
skipping logging after 30928 examples to avoid logging too frequently
skipping logging after 30944 examples to avoid logging too frequently
skipping logging after 30960 examples to avoid logging too frequently
train stats after 30976 examples: {'rewards_train/chosen': '-1.7968', 'rewards_train/rejected': '-9.0447', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.2452', 'logps_train/rejected': '-215.93', 'logps_train/chosen': '-57.73', 'loss/train': '0.069362', 'examples_per_second': '5.5462', 'grad_norm': '6.875', 'counters/examples': 30976, 'counters/updates': 1936}
skipping logging after 30992 examples to avoid logging too frequently
skipping logging after 31008 examples to avoid logging too frequently
skipping logging after 31024 examples to avoid logging too frequently
train stats after 31040 examples: {'rewards_train/chosen': '-1.7708', 'rewards_train/rejected': '-10.498', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.7288', 'logps_train/rejected': '-267.88', 'logps_train/chosen': '-66.303', 'loss/train': '0.072117', 'examples_per_second': '5.1952', 'grad_norm': '8.375', 'counters/examples': 31040, 'counters/updates': 1940}
skipping logging after 31056 examples to avoid logging too frequently
skipping logging after 31072 examples to avoid logging too frequently
skipping logging after 31088 examples to avoid logging too frequently
train stats after 31104 examples: {'rewards_train/chosen': '-2.214', 'rewards_train/rejected': '-9.095', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.876', 'logps_train/rejected': '-221.95', 'logps_train/chosen': '-56.134', 'loss/train': '0.054172', 'examples_per_second': '5.9239', 'grad_norm': '10.188', 'counters/examples': 31104, 'counters/updates': 1944}
skipping logging after 31120 examples to avoid logging too frequently
skipping logging after 31136 examples to avoid logging too frequently
skipping logging after 31152 examples to avoid logging too frequently
train stats after 31168 examples: {'rewards_train/chosen': '-2.0116', 'rewards_train/rejected': '-9.1661', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.1527', 'logps_train/rejected': '-231.12', 'logps_train/chosen': '-60.293', 'loss/train': '0.14583', 'examples_per_second': '4.9465', 'grad_norm': '10.875', 'counters/examples': 31168, 'counters/updates': 1948}
skipping logging after 31184 examples to avoid logging too frequently
skipping logging after 31200 examples to avoid logging too frequently
skipping logging after 31216 examples to avoid logging too frequently
train stats after 31232 examples: {'rewards_train/chosen': '-2.0905', 'rewards_train/rejected': '-8.3253', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.233', 'logps_train/rejected': '-204.14', 'logps_train/chosen': '-57.953', 'loss/train': '0.098146', 'examples_per_second': '5.0739', 'grad_norm': '9.5', 'counters/examples': 31232, 'counters/updates': 1952}
skipping logging after 31248 examples to avoid logging too frequently
skipping logging after 31264 examples to avoid logging too frequently
skipping logging after 31280 examples to avoid logging too frequently
train stats after 31296 examples: {'rewards_train/chosen': '-2.0444', 'rewards_train/rejected': '-8.9886', 'rewards_train/accuracies': '0.89062', 'rewards_train/margins': '6.9402', 'logps_train/rejected': '-216.55', 'logps_train/chosen': '-55.871', 'loss/train': '0.13757', 'examples_per_second': '6.1198', 'grad_norm': '10.375', 'counters/examples': 31296, 'counters/updates': 1956}
skipping logging after 31312 examples to avoid logging too frequently
skipping logging after 31328 examples to avoid logging too frequently
skipping logging after 31344 examples to avoid logging too frequently
train stats after 31360 examples: {'rewards_train/chosen': '-1.9423', 'rewards_train/rejected': '-9.7423', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.7988', 'logps_train/rejected': '-223.56', 'logps_train/chosen': '-54.805', 'loss/train': '0.12185', 'examples_per_second': '6.047', 'grad_norm': '7.375', 'counters/examples': 31360, 'counters/updates': 1960}
skipping logging after 31376 examples to avoid logging too frequently
skipping logging after 31392 examples to avoid logging too frequently
skipping logging after 31408 examples to avoid logging too frequently
train stats after 31424 examples: {'rewards_train/chosen': '-2.2023', 'rewards_train/rejected': '-9.8024', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.6029', 'logps_train/rejected': '-229.84', 'logps_train/chosen': '-63.565', 'loss/train': '0.090635', 'examples_per_second': '5.2413', 'grad_norm': '9', 'counters/examples': 31424, 'counters/updates': 1964}
skipping logging after 31440 examples to avoid logging too frequently
skipping logging after 31456 examples to avoid logging too frequently
skipping logging after 31472 examples to avoid logging too frequently
train stats after 31488 examples: {'rewards_train/chosen': '-1.9791', 'rewards_train/rejected': '-11.009', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.0295', 'logps_train/rejected': '-316.87', 'logps_train/chosen': '-56.813', 'loss/train': '0.036382', 'examples_per_second': '3.6577', 'grad_norm': '7.375', 'counters/examples': 31488, 'counters/updates': 1968}
skipping logging after 31504 examples to avoid logging too frequently
skipping logging after 31520 examples to avoid logging too frequently
skipping logging after 31536 examples to avoid logging too frequently
train stats after 31552 examples: {'rewards_train/chosen': '-1.8572', 'rewards_train/rejected': '-10.704', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.8427', 'logps_train/rejected': '-227.46', 'logps_train/chosen': '-51.913', 'loss/train': '0.033376', 'examples_per_second': '5.4465', 'grad_norm': '4.8438', 'counters/examples': 31552, 'counters/updates': 1972}
skipping logging after 31568 examples to avoid logging too frequently
skipping logging after 31584 examples to avoid logging too frequently
skipping logging after 31600 examples to avoid logging too frequently
train stats after 31616 examples: {'rewards_train/chosen': '-1.8943', 'rewards_train/rejected': '-10.642', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.7507', 'logps_train/rejected': '-234.32', 'logps_train/chosen': '-56.323', 'loss/train': '0.047531', 'examples_per_second': '4.8728', 'grad_norm': '8.6875', 'counters/examples': 31616, 'counters/updates': 1976}
skipping logging after 31632 examples to avoid logging too frequently
skipping logging after 31648 examples to avoid logging too frequently
skipping logging after 31664 examples to avoid logging too frequently
train stats after 31680 examples: {'rewards_train/chosen': '-2.1008', 'rewards_train/rejected': '-9.5365', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.4377', 'logps_train/rejected': '-239.19', 'logps_train/chosen': '-54.429', 'loss/train': '0.083527', 'examples_per_second': '5.544', 'grad_norm': '8.6875', 'counters/examples': 31680, 'counters/updates': 1980}
skipping logging after 31696 examples to avoid logging too frequently
skipping logging after 31712 examples to avoid logging too frequently
skipping logging after 31728 examples to avoid logging too frequently
train stats after 31744 examples: {'rewards_train/chosen': '-2.2919', 'rewards_train/rejected': '-11.182', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.8887', 'logps_train/rejected': '-265.28', 'logps_train/chosen': '-61.126', 'loss/train': '0.102', 'examples_per_second': '4.8066', 'grad_norm': '14', 'counters/examples': 31744, 'counters/updates': 1984}
skipping logging after 31760 examples to avoid logging too frequently
skipping logging after 31776 examples to avoid logging too frequently
skipping logging after 31792 examples to avoid logging too frequently
train stats after 31808 examples: {'rewards_train/chosen': '-2.4728', 'rewards_train/rejected': '-10.446', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.9729', 'logps_train/rejected': '-232.12', 'logps_train/chosen': '-67.449', 'loss/train': '0.10146', 'examples_per_second': '5.5851', 'grad_norm': '13.688', 'counters/examples': 31808, 'counters/updates': 1988}
skipping logging after 31824 examples to avoid logging too frequently
skipping logging after 31840 examples to avoid logging too frequently
skipping logging after 31856 examples to avoid logging too frequently
train stats after 31872 examples: {'rewards_train/chosen': '-2.4055', 'rewards_train/rejected': '-9.9471', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.5397', 'logps_train/rejected': '-226.86', 'logps_train/chosen': '-61.892', 'loss/train': '0.13004', 'examples_per_second': '4.7465', 'grad_norm': '11.062', 'counters/examples': 31872, 'counters/updates': 1992}
skipping logging after 31888 examples to avoid logging too frequently
skipping logging after 31904 examples to avoid logging too frequently
skipping logging after 31920 examples to avoid logging too frequently
train stats after 31936 examples: {'rewards_train/chosen': '-2.4406', 'rewards_train/rejected': '-10.561', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.1184', 'logps_train/rejected': '-234.66', 'logps_train/chosen': '-64.863', 'loss/train': '0.04015', 'examples_per_second': '5.2156', 'grad_norm': '9.375', 'counters/examples': 31936, 'counters/updates': 1996}
skipping logging after 31952 examples to avoid logging too frequently
skipping logging after 31968 examples to avoid logging too frequently
skipping logging after 31984 examples to avoid logging too frequently
train stats after 32000 examples: {'rewards_train/chosen': '-2.5992', 'rewards_train/rejected': '-9.5671', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '6.9679', 'logps_train/rejected': '-215.35', 'logps_train/chosen': '-66.671', 'loss/train': '0.10319', 'examples_per_second': '5.6079', 'grad_norm': '12.812', 'counters/examples': 32000, 'counters/updates': 2000}
Running evaluation after 32000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<01:00,  1.96s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:00,  2.03s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:53,  1.85s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.86s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.52s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.50s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:22,  1.30s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.25s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:20,  1.33s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.34s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.27s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.30s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.26s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.30s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.48s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.42s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.62s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.42s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.42s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 32000: {'rewards_eval/chosen': '-11.212', 'rewards_eval/rejected': '-11.637', 'rewards_eval/accuracies': '0.51562', 'rewards_eval/margins': '0.42506', 'logps_eval/rejected': '-264.04', 'logps_eval/chosen': '-257.04', 'loss/eval': '2.407'}
skipping logging after 32016 examples to avoid logging too frequently
skipping logging after 32032 examples to avoid logging too frequently
skipping logging after 32048 examples to avoid logging too frequently
train stats after 32064 examples: {'rewards_train/chosen': '-2.519', 'rewards_train/rejected': '-12.21', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.6896', 'logps_train/rejected': '-309.35', 'logps_train/chosen': '-72.165', 'loss/train': '0.055188', 'examples_per_second': '4.701', 'grad_norm': '10.188', 'counters/examples': 32064, 'counters/updates': 2004}
skipping logging after 32080 examples to avoid logging too frequently
skipping logging after 32096 examples to avoid logging too frequently
skipping logging after 32112 examples to avoid logging too frequently
train stats after 32128 examples: {'rewards_train/chosen': '-2.8059', 'rewards_train/rejected': '-10.605', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.802', 'logps_train/rejected': '-238.34', 'logps_train/chosen': '-71.135', 'loss/train': '0.060504', 'examples_per_second': '4.1699', 'grad_norm': '8.1875', 'counters/examples': 32128, 'counters/updates': 2008}
skipping logging after 32144 examples to avoid logging too frequently
skipping logging after 32160 examples to avoid logging too frequently
skipping logging after 32176 examples to avoid logging too frequently
train stats after 32192 examples: {'rewards_train/chosen': '-2.3768', 'rewards_train/rejected': '-10.863', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.4839', 'logps_train/rejected': '-240.99', 'logps_train/chosen': '-64.23', 'loss/train': '0.12147', 'examples_per_second': '4.9356', 'grad_norm': '13.812', 'counters/examples': 32192, 'counters/updates': 2012}
skipping logging after 32208 examples to avoid logging too frequently
skipping logging after 32224 examples to avoid logging too frequently
skipping logging after 32240 examples to avoid logging too frequently
train stats after 32256 examples: {'rewards_train/chosen': '-2.3612', 'rewards_train/rejected': '-10.694', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.3317', 'logps_train/rejected': '-281.34', 'logps_train/chosen': '-72.189', 'loss/train': '0.049907', 'examples_per_second': '4.7046', 'grad_norm': '9', 'counters/examples': 32256, 'counters/updates': 2016}
skipping logging after 32272 examples to avoid logging too frequently
skipping logging after 32288 examples to avoid logging too frequently
skipping logging after 32304 examples to avoid logging too frequently
train stats after 32320 examples: {'rewards_train/chosen': '-2.5328', 'rewards_train/rejected': '-10.094', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.5638', 'logps_train/rejected': '-224.14', 'logps_train/chosen': '-69.849', 'loss/train': '0.089029', 'examples_per_second': '5.3505', 'grad_norm': '17.875', 'counters/examples': 32320, 'counters/updates': 2020}
skipping logging after 32336 examples to avoid logging too frequently
skipping logging after 32352 examples to avoid logging too frequently
skipping logging after 32368 examples to avoid logging too frequently
train stats after 32384 examples: {'rewards_train/chosen': '-2.1188', 'rewards_train/rejected': '-10.146', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.0255', 'logps_train/rejected': '-231.5', 'logps_train/chosen': '-61.244', 'loss/train': '0.083791', 'examples_per_second': '4.7333', 'grad_norm': '11.312', 'counters/examples': 32384, 'counters/updates': 2024}
skipping logging after 32400 examples to avoid logging too frequently
skipping logging after 32416 examples to avoid logging too frequently
skipping logging after 32432 examples to avoid logging too frequently
train stats after 32448 examples: {'rewards_train/chosen': '-2.7209', 'rewards_train/rejected': '-11.939', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.2161', 'logps_train/rejected': '-264.7', 'logps_train/chosen': '-60.602', 'loss/train': '0.068539', 'examples_per_second': '5.034', 'grad_norm': '12.062', 'counters/examples': 32448, 'counters/updates': 2028}
skipping logging after 32464 examples to avoid logging too frequently
skipping logging after 32480 examples to avoid logging too frequently
skipping logging after 32496 examples to avoid logging too frequently
train stats after 32512 examples: {'rewards_train/chosen': '-2.2167', 'rewards_train/rejected': '-9.8655', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.6506', 'logps_train/rejected': '-208.69', 'logps_train/chosen': '-58.25', 'loss/train': '0.060664', 'examples_per_second': '5.7137', 'grad_norm': '7.1875', 'counters/examples': 32512, 'counters/updates': 2032}
skipping logging after 32528 examples to avoid logging too frequently
skipping logging after 32544 examples to avoid logging too frequently
skipping logging after 32560 examples to avoid logging too frequently
train stats after 32576 examples: {'rewards_train/chosen': '-1.8567', 'rewards_train/rejected': '-10.576', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.7174', 'logps_train/rejected': '-255.11', 'logps_train/chosen': '-56.138', 'loss/train': '0.027379', 'examples_per_second': '4.6805', 'grad_norm': '3.7031', 'counters/examples': 32576, 'counters/updates': 2036}
skipping logging after 32592 examples to avoid logging too frequently
skipping logging after 32608 examples to avoid logging too frequently
skipping logging after 32624 examples to avoid logging too frequently
train stats after 32640 examples: {'rewards_train/chosen': '-1.9817', 'rewards_train/rejected': '-10.184', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.2043', 'logps_train/rejected': '-243.52', 'logps_train/chosen': '-58.425', 'loss/train': '0.068548', 'examples_per_second': '5.742', 'grad_norm': '5.5625', 'counters/examples': 32640, 'counters/updates': 2040}
skipping logging after 32656 examples to avoid logging too frequently
skipping logging after 32672 examples to avoid logging too frequently
skipping logging after 32688 examples to avoid logging too frequently
train stats after 32704 examples: {'rewards_train/chosen': '-2.4581', 'rewards_train/rejected': '-9.7848', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.3275', 'logps_train/rejected': '-234.95', 'logps_train/chosen': '-76.598', 'loss/train': '0.22517', 'examples_per_second': '4.7773', 'grad_norm': '19.75', 'counters/examples': 32704, 'counters/updates': 2044}
skipping logging after 32720 examples to avoid logging too frequently
skipping logging after 32736 examples to avoid logging too frequently
skipping logging after 32752 examples to avoid logging too frequently
train stats after 32768 examples: {'rewards_train/chosen': '-2.1546', 'rewards_train/rejected': '-9.3613', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.2067', 'logps_train/rejected': '-215.09', 'logps_train/chosen': '-57.337', 'loss/train': '0.056413', 'examples_per_second': '5.4776', 'grad_norm': '6.6875', 'counters/examples': 32768, 'counters/updates': 2048}
skipping logging after 32784 examples to avoid logging too frequently
skipping logging after 32800 examples to avoid logging too frequently
skipping logging after 32816 examples to avoid logging too frequently
train stats after 32832 examples: {'rewards_train/chosen': '-1.8739', 'rewards_train/rejected': '-11.19', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.3154', 'logps_train/rejected': '-279.56', 'logps_train/chosen': '-57.939', 'loss/train': '0.069638', 'examples_per_second': '5.2222', 'grad_norm': '9.125', 'counters/examples': 32832, 'counters/updates': 2052}
skipping logging after 32848 examples to avoid logging too frequently
skipping logging after 32864 examples to avoid logging too frequently
skipping logging after 32880 examples to avoid logging too frequently
train stats after 32896 examples: {'rewards_train/chosen': '-2.2165', 'rewards_train/rejected': '-11.703', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.4885', 'logps_train/rejected': '-265.02', 'logps_train/chosen': '-60.324', 'loss/train': '0.079931', 'examples_per_second': '6.0146', 'grad_norm': '15', 'counters/examples': 32896, 'counters/updates': 2056}
skipping logging after 32912 examples to avoid logging too frequently
skipping logging after 32928 examples to avoid logging too frequently
skipping logging after 32944 examples to avoid logging too frequently
train stats after 32960 examples: {'rewards_train/chosen': '-2.158', 'rewards_train/rejected': '-10.138', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.9784', 'logps_train/rejected': '-267', 'logps_train/chosen': '-67.201', 'loss/train': '0.089072', 'examples_per_second': '4.3595', 'grad_norm': '11.625', 'counters/examples': 32960, 'counters/updates': 2060}
skipping logging after 32976 examples to avoid logging too frequently
skipping logging after 32992 examples to avoid logging too frequently
skipping logging after 33008 examples to avoid logging too frequently
train stats after 33024 examples: {'rewards_train/chosen': '-2.2901', 'rewards_train/rejected': '-10.544', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.2568', 'logps_train/rejected': '-238.92', 'logps_train/chosen': '-66.902', 'loss/train': '0.15149', 'examples_per_second': '4.979', 'grad_norm': '18.5', 'counters/examples': 33024, 'counters/updates': 2064}
skipping logging after 33040 examples to avoid logging too frequently
skipping logging after 33056 examples to avoid logging too frequently
skipping logging after 33072 examples to avoid logging too frequently
train stats after 33088 examples: {'rewards_train/chosen': '-2.5058', 'rewards_train/rejected': '-10.766', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.2656', 'logps_train/rejected': '-254.9', 'logps_train/chosen': '-70.998', 'loss/train': '0.037593', 'examples_per_second': '5.4883', 'grad_norm': '5.6875', 'counters/examples': 33088, 'counters/updates': 2068}
skipping logging after 33104 examples to avoid logging too frequently
skipping logging after 33120 examples to avoid logging too frequently
skipping logging after 33136 examples to avoid logging too frequently
train stats after 33152 examples: {'rewards_train/chosen': '-2.1543', 'rewards_train/rejected': '-9.8167', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.6602', 'logps_train/rejected': '-221', 'logps_train/chosen': '-66.126', 'loss/train': '0.11321', 'examples_per_second': '5.5955', 'grad_norm': '8.8125', 'counters/examples': 33152, 'counters/updates': 2072}
skipping logging after 33168 examples to avoid logging too frequently
skipping logging after 33184 examples to avoid logging too frequently
skipping logging after 33200 examples to avoid logging too frequently
train stats after 33216 examples: {'rewards_train/chosen': '-2.2654', 'rewards_train/rejected': '-9.9531', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.6881', 'logps_train/rejected': '-225.44', 'logps_train/chosen': '-62.546', 'loss/train': '0.059278', 'examples_per_second': '4.9549', 'grad_norm': '11.562', 'counters/examples': 33216, 'counters/updates': 2076}
skipping logging after 33232 examples to avoid logging too frequently
skipping logging after 33248 examples to avoid logging too frequently
skipping logging after 33264 examples to avoid logging too frequently
train stats after 33280 examples: {'rewards_train/chosen': '-2.2818', 'rewards_train/rejected': '-10.822', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.5394', 'logps_train/rejected': '-268.62', 'logps_train/chosen': '-57.594', 'loss/train': '0.061866', 'examples_per_second': '4.3659', 'grad_norm': '9.625', 'counters/examples': 33280, 'counters/updates': 2080}
skipping logging after 33296 examples to avoid logging too frequently
skipping logging after 33312 examples to avoid logging too frequently
skipping logging after 33328 examples to avoid logging too frequently
train stats after 33344 examples: {'rewards_train/chosen': '-2.0979', 'rewards_train/rejected': '-10.3', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.2002', 'logps_train/rejected': '-247.29', 'logps_train/chosen': '-60.967', 'loss/train': '0.039372', 'examples_per_second': '4.6785', 'grad_norm': '4.5625', 'counters/examples': 33344, 'counters/updates': 2084}
skipping logging after 33360 examples to avoid logging too frequently
skipping logging after 33376 examples to avoid logging too frequently
skipping logging after 33392 examples to avoid logging too frequently
train stats after 33408 examples: {'rewards_train/chosen': '-2.3905', 'rewards_train/rejected': '-9.7229', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.3341', 'logps_train/rejected': '-234.39', 'logps_train/chosen': '-66.331', 'loss/train': '0.042371', 'examples_per_second': '5.1826', 'grad_norm': '6.4375', 'counters/examples': 33408, 'counters/updates': 2088}
skipping logging after 33424 examples to avoid logging too frequently
skipping logging after 33440 examples to avoid logging too frequently
skipping logging after 33456 examples to avoid logging too frequently
train stats after 33472 examples: {'rewards_train/chosen': '-2.0325', 'rewards_train/rejected': '-10.142', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1094', 'logps_train/rejected': '-244.54', 'logps_train/chosen': '-65.078', 'loss/train': '0.081382', 'examples_per_second': '5.2511', 'grad_norm': '8.125', 'counters/examples': 33472, 'counters/updates': 2092}
skipping logging after 33488 examples to avoid logging too frequently
skipping logging after 33504 examples to avoid logging too frequently
skipping logging after 33520 examples to avoid logging too frequently
train stats after 33536 examples: {'rewards_train/chosen': '-2.724', 'rewards_train/rejected': '-10.355', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.6299', 'logps_train/rejected': '-245.62', 'logps_train/chosen': '-71.008', 'loss/train': '0.092887', 'examples_per_second': '5.9639', 'grad_norm': '13.625', 'counters/examples': 33536, 'counters/updates': 2096}
skipping logging after 33552 examples to avoid logging too frequently
skipping logging after 33568 examples to avoid logging too frequently
skipping logging after 33584 examples to avoid logging too frequently
train stats after 33600 examples: {'rewards_train/chosen': '-2.3059', 'rewards_train/rejected': '-8.5857', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.2822', 'logps_train/rejected': '-196.28', 'logps_train/chosen': '-61.168', 'loss/train': '0.076739', 'examples_per_second': '5.1006', 'grad_norm': '9.6875', 'counters/examples': 33600, 'counters/updates': 2100}
skipping logging after 33616 examples to avoid logging too frequently
skipping logging after 33632 examples to avoid logging too frequently
skipping logging after 33648 examples to avoid logging too frequently
train stats after 33664 examples: {'rewards_train/chosen': '-2.2157', 'rewards_train/rejected': '-9.96', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.7449', 'logps_train/rejected': '-246.75', 'logps_train/chosen': '-67.068', 'loss/train': '0.088886', 'examples_per_second': '4.4069', 'grad_norm': '10.875', 'counters/examples': 33664, 'counters/updates': 2104}
skipping logging after 33680 examples to avoid logging too frequently
skipping logging after 33696 examples to avoid logging too frequently
skipping logging after 33712 examples to avoid logging too frequently
train stats after 33728 examples: {'rewards_train/chosen': '-2.1115', 'rewards_train/rejected': '-10.596', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.4851', 'logps_train/rejected': '-247.9', 'logps_train/chosen': '-54.22', 'loss/train': '0.033581', 'examples_per_second': '6.0332', 'grad_norm': '6.0625', 'counters/examples': 33728, 'counters/updates': 2108}
skipping logging after 33744 examples to avoid logging too frequently
skipping logging after 33760 examples to avoid logging too frequently
skipping logging after 33776 examples to avoid logging too frequently
train stats after 33792 examples: {'rewards_train/chosen': '-2.3354', 'rewards_train/rejected': '-9.2324', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.897', 'logps_train/rejected': '-231.59', 'logps_train/chosen': '-62.576', 'loss/train': '0.050146', 'examples_per_second': '6.0251', 'grad_norm': '8.6875', 'counters/examples': 33792, 'counters/updates': 2112}
skipping logging after 33808 examples to avoid logging too frequently
skipping logging after 33824 examples to avoid logging too frequently
skipping logging after 33840 examples to avoid logging too frequently
train stats after 33856 examples: {'rewards_train/chosen': '-2.4827', 'rewards_train/rejected': '-10.505', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.0198', 'logps_train/rejected': '-253.31', 'logps_train/chosen': '-70.279', 'loss/train': '0.11295', 'examples_per_second': '4.6536', 'grad_norm': '10', 'counters/examples': 33856, 'counters/updates': 2116}
skipping logging after 33872 examples to avoid logging too frequently
skipping logging after 33888 examples to avoid logging too frequently
skipping logging after 33904 examples to avoid logging too frequently
train stats after 33920 examples: {'rewards_train/chosen': '-2.7737', 'rewards_train/rejected': '-10.919', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1445', 'logps_train/rejected': '-273.64', 'logps_train/chosen': '-78.049', 'loss/train': '0.080671', 'examples_per_second': '4.5009', 'grad_norm': '12.562', 'counters/examples': 33920, 'counters/updates': 2120}
skipping logging after 33936 examples to avoid logging too frequently
skipping logging after 33952 examples to avoid logging too frequently
skipping logging after 33968 examples to avoid logging too frequently
train stats after 33984 examples: {'rewards_train/chosen': '-3.1433', 'rewards_train/rejected': '-11.174', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.0312', 'logps_train/rejected': '-255.72', 'logps_train/chosen': '-81.461', 'loss/train': '0.13027', 'examples_per_second': '4.7917', 'grad_norm': '19.375', 'counters/examples': 33984, 'counters/updates': 2124}
skipping logging after 34000 examples to avoid logging too frequently
skipping logging after 34016 examples to avoid logging too frequently
skipping logging after 34032 examples to avoid logging too frequently
train stats after 34048 examples: {'rewards_train/chosen': '-2.3045', 'rewards_train/rejected': '-10.471', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1682', 'logps_train/rejected': '-250.09', 'logps_train/chosen': '-71.25', 'loss/train': '0.019923', 'examples_per_second': '5.5438', 'grad_norm': '2.9531', 'counters/examples': 34048, 'counters/updates': 2128}
skipping logging after 34064 examples to avoid logging too frequently
skipping logging after 34080 examples to avoid logging too frequently
skipping logging after 34096 examples to avoid logging too frequently
train stats after 34112 examples: {'rewards_train/chosen': '-2.5626', 'rewards_train/rejected': '-10.469', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.9114', 'logps_train/rejected': '-245.84', 'logps_train/chosen': '-66.115', 'loss/train': '0.10622', 'examples_per_second': '5.3946', 'grad_norm': '12', 'counters/examples': 34112, 'counters/updates': 2132}
skipping logging after 34128 examples to avoid logging too frequently
skipping logging after 34144 examples to avoid logging too frequently
skipping logging after 34160 examples to avoid logging too frequently
train stats after 34176 examples: {'rewards_train/chosen': '-2.4856', 'rewards_train/rejected': '-10.031', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.5435', 'logps_train/rejected': '-257.75', 'logps_train/chosen': '-76.959', 'loss/train': '0.060217', 'examples_per_second': '4.841', 'grad_norm': '12.375', 'counters/examples': 34176, 'counters/updates': 2136}
skipping logging after 34192 examples to avoid logging too frequently
skipping logging after 34208 examples to avoid logging too frequently
skipping logging after 34224 examples to avoid logging too frequently
train stats after 34240 examples: {'rewards_train/chosen': '-2.5626', 'rewards_train/rejected': '-9.9568', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.3954', 'logps_train/rejected': '-254.75', 'logps_train/chosen': '-61.371', 'loss/train': '0.093912', 'examples_per_second': '4.6589', 'grad_norm': '11.875', 'counters/examples': 34240, 'counters/updates': 2140}
skipping logging after 34256 examples to avoid logging too frequently
skipping logging after 34272 examples to avoid logging too frequently
skipping logging after 34288 examples to avoid logging too frequently
train stats after 34304 examples: {'rewards_train/chosen': '-2.5887', 'rewards_train/rejected': '-10.486', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.8979', 'logps_train/rejected': '-221.77', 'logps_train/chosen': '-58.535', 'loss/train': '0.081853', 'examples_per_second': '4.8107', 'grad_norm': '7.8438', 'counters/examples': 34304, 'counters/updates': 2144}
skipping logging after 34320 examples to avoid logging too frequently
skipping logging after 34336 examples to avoid logging too frequently
skipping logging after 34352 examples to avoid logging too frequently
train stats after 34368 examples: {'rewards_train/chosen': '-3.0007', 'rewards_train/rejected': '-11.896', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.895', 'logps_train/rejected': '-253.79', 'logps_train/chosen': '-80.717', 'loss/train': '0.059146', 'examples_per_second': '5.1287', 'grad_norm': '6.4688', 'counters/examples': 34368, 'counters/updates': 2148}
skipping logging after 34384 examples to avoid logging too frequently
skipping logging after 34400 examples to avoid logging too frequently
skipping logging after 34416 examples to avoid logging too frequently
train stats after 34432 examples: {'rewards_train/chosen': '-2.6414', 'rewards_train/rejected': '-11.236', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.5933', 'logps_train/rejected': '-236.13', 'logps_train/chosen': '-73.312', 'loss/train': '0.20174', 'examples_per_second': '5.7877', 'grad_norm': '27.625', 'counters/examples': 34432, 'counters/updates': 2152}
skipping logging after 34448 examples to avoid logging too frequently
skipping logging after 34464 examples to avoid logging too frequently
skipping logging after 34480 examples to avoid logging too frequently
train stats after 34496 examples: {'rewards_train/chosen': '-2.0385', 'rewards_train/rejected': '-10.094', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.0549', 'logps_train/rejected': '-257.07', 'logps_train/chosen': '-61.174', 'loss/train': '0.03806', 'examples_per_second': '5.0863', 'grad_norm': '7.1562', 'counters/examples': 34496, 'counters/updates': 2156}
skipping logging after 34512 examples to avoid logging too frequently
skipping logging after 34528 examples to avoid logging too frequently
skipping logging after 34544 examples to avoid logging too frequently
train stats after 34560 examples: {'rewards_train/chosen': '-2.8499', 'rewards_train/rejected': '-11.622', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.772', 'logps_train/rejected': '-268.83', 'logps_train/chosen': '-72.51', 'loss/train': '0.057701', 'examples_per_second': '6.1073', 'grad_norm': '10.688', 'counters/examples': 34560, 'counters/updates': 2160}
skipping logging after 34576 examples to avoid logging too frequently
skipping logging after 34592 examples to avoid logging too frequently
skipping logging after 34608 examples to avoid logging too frequently
train stats after 34624 examples: {'rewards_train/chosen': '-2.3508', 'rewards_train/rejected': '-10.535', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1868', 'logps_train/rejected': '-261.98', 'logps_train/chosen': '-66.706', 'loss/train': '0.027582', 'examples_per_second': '6.6334', 'grad_norm': '3.4844', 'counters/examples': 34624, 'counters/updates': 2164}
skipping logging after 34640 examples to avoid logging too frequently
skipping logging after 34656 examples to avoid logging too frequently
skipping logging after 34672 examples to avoid logging too frequently
train stats after 34688 examples: {'rewards_train/chosen': '-2.5103', 'rewards_train/rejected': '-11.249', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.7388', 'logps_train/rejected': '-255.62', 'logps_train/chosen': '-60.104', 'loss/train': '0.089598', 'examples_per_second': '5.2243', 'grad_norm': '10.312', 'counters/examples': 34688, 'counters/updates': 2168}
skipping logging after 34704 examples to avoid logging too frequently
skipping logging after 34720 examples to avoid logging too frequently
skipping logging after 34736 examples to avoid logging too frequently
train stats after 34752 examples: {'rewards_train/chosen': '-2.1257', 'rewards_train/rejected': '-9.7288', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.6025', 'logps_train/rejected': '-221.02', 'logps_train/chosen': '-63.003', 'loss/train': '0.024431', 'examples_per_second': '3.7262', 'grad_norm': '3.5', 'counters/examples': 34752, 'counters/updates': 2172}
skipping logging after 34768 examples to avoid logging too frequently
skipping logging after 34784 examples to avoid logging too frequently
skipping logging after 34800 examples to avoid logging too frequently
train stats after 34816 examples: {'rewards_train/chosen': '-2.7616', 'rewards_train/rejected': '-10.448', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.6859', 'logps_train/rejected': '-277.37', 'logps_train/chosen': '-67.303', 'loss/train': '0.061617', 'examples_per_second': '5.035', 'grad_norm': '10.625', 'counters/examples': 34816, 'counters/updates': 2176}
skipping logging after 34832 examples to avoid logging too frequently
skipping logging after 34848 examples to avoid logging too frequently
skipping logging after 34864 examples to avoid logging too frequently
train stats after 34880 examples: {'rewards_train/chosen': '-2.7142', 'rewards_train/rejected': '-10.873', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.1575', 'logps_train/rejected': '-243.39', 'logps_train/chosen': '-67.312', 'loss/train': '0.093585', 'examples_per_second': '5.3361', 'grad_norm': '12.625', 'counters/examples': 34880, 'counters/updates': 2180}
skipping logging after 34896 examples to avoid logging too frequently
skipping logging after 34912 examples to avoid logging too frequently
skipping logging after 34928 examples to avoid logging too frequently
train stats after 34944 examples: {'rewards_train/chosen': '-2.3682', 'rewards_train/rejected': '-10.102', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.7316', 'logps_train/rejected': '-265.58', 'logps_train/chosen': '-61.442', 'loss/train': '0.046477', 'examples_per_second': '5.7391', 'grad_norm': '7.0938', 'counters/examples': 34944, 'counters/updates': 2184}
skipping logging after 34960 examples to avoid logging too frequently
skipping logging after 34976 examples to avoid logging too frequently
skipping logging after 34992 examples to avoid logging too frequently
train stats after 35008 examples: {'rewards_train/chosen': '-2.5594', 'rewards_train/rejected': '-10.086', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.5269', 'logps_train/rejected': '-262.95', 'logps_train/chosen': '-69.812', 'loss/train': '0.028669', 'examples_per_second': '5.0016', 'grad_norm': '4.6875', 'counters/examples': 35008, 'counters/updates': 2188}
skipping logging after 35024 examples to avoid logging too frequently
skipping logging after 35040 examples to avoid logging too frequently
skipping logging after 35056 examples to avoid logging too frequently
train stats after 35072 examples: {'rewards_train/chosen': '-2.5379', 'rewards_train/rejected': '-9.6704', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.1322', 'logps_train/rejected': '-223.71', 'logps_train/chosen': '-76.144', 'loss/train': '0.082504', 'examples_per_second': '4.3036', 'grad_norm': '6.5938', 'counters/examples': 35072, 'counters/updates': 2192}
skipping logging after 35088 examples to avoid logging too frequently
skipping logging after 35104 examples to avoid logging too frequently
skipping logging after 35120 examples to avoid logging too frequently
train stats after 35136 examples: {'rewards_train/chosen': '-2.2324', 'rewards_train/rejected': '-10.285', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.0524', 'logps_train/rejected': '-232.46', 'logps_train/chosen': '-64.158', 'loss/train': '0.042111', 'examples_per_second': '5.0815', 'grad_norm': '4.4062', 'counters/examples': 35136, 'counters/updates': 2196}
skipping logging after 35152 examples to avoid logging too frequently
skipping logging after 35168 examples to avoid logging too frequently
skipping logging after 35184 examples to avoid logging too frequently
train stats after 35200 examples: {'rewards_train/chosen': '-2.4343', 'rewards_train/rejected': '-10.273', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.8394', 'logps_train/rejected': '-236.7', 'logps_train/chosen': '-61.894', 'loss/train': '0.11126', 'examples_per_second': '4.4744', 'grad_norm': '13.938', 'counters/examples': 35200, 'counters/updates': 2200}
skipping logging after 35216 examples to avoid logging too frequently
skipping logging after 35232 examples to avoid logging too frequently
skipping logging after 35248 examples to avoid logging too frequently
train stats after 35264 examples: {'rewards_train/chosen': '-2.4933', 'rewards_train/rejected': '-10.491', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.9973', 'logps_train/rejected': '-211.45', 'logps_train/chosen': '-57.736', 'loss/train': '0.033152', 'examples_per_second': '5.8026', 'grad_norm': '3.9531', 'counters/examples': 35264, 'counters/updates': 2204}
skipping logging after 35280 examples to avoid logging too frequently
skipping logging after 35296 examples to avoid logging too frequently
skipping logging after 35312 examples to avoid logging too frequently
train stats after 35328 examples: {'rewards_train/chosen': '-2.7127', 'rewards_train/rejected': '-11.605', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.8901', 'logps_train/rejected': '-255.32', 'logps_train/chosen': '-68.104', 'loss/train': '0.061811', 'examples_per_second': '4.6183', 'grad_norm': '7.125', 'counters/examples': 35328, 'counters/updates': 2208}
skipping logging after 35344 examples to avoid logging too frequently
skipping logging after 35360 examples to avoid logging too frequently
skipping logging after 35376 examples to avoid logging too frequently
train stats after 35392 examples: {'rewards_train/chosen': '-3.158', 'rewards_train/rejected': '-12.077', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.9172', 'logps_train/rejected': '-267.44', 'logps_train/chosen': '-70.371', 'loss/train': '0.14098', 'examples_per_second': '5.0215', 'grad_norm': '18.75', 'counters/examples': 35392, 'counters/updates': 2212}
skipping logging after 35408 examples to avoid logging too frequently
skipping logging after 35424 examples to avoid logging too frequently
skipping logging after 35440 examples to avoid logging too frequently
train stats after 35456 examples: {'rewards_train/chosen': '-2.0441', 'rewards_train/rejected': '-10.655', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.6104', 'logps_train/rejected': '-266.16', 'logps_train/chosen': '-62.169', 'loss/train': '0.079078', 'examples_per_second': '5.4144', 'grad_norm': '14.312', 'counters/examples': 35456, 'counters/updates': 2216}
skipping logging after 35472 examples to avoid logging too frequently
skipping logging after 35488 examples to avoid logging too frequently
skipping logging after 35504 examples to avoid logging too frequently
train stats after 35520 examples: {'rewards_train/chosen': '-2.4329', 'rewards_train/rejected': '-8.7593', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.3232', 'logps_train/rejected': '-223.54', 'logps_train/chosen': '-70.119', 'loss/train': '0.092282', 'examples_per_second': '5.9665', 'grad_norm': '11.438', 'counters/examples': 35520, 'counters/updates': 2220}
skipping logging after 35536 examples to avoid logging too frequently
skipping logging after 35552 examples to avoid logging too frequently
skipping logging after 35568 examples to avoid logging too frequently
train stats after 35584 examples: {'rewards_train/chosen': '-1.8504', 'rewards_train/rejected': '-8.9778', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.127', 'logps_train/rejected': '-237.54', 'logps_train/chosen': '-52.361', 'loss/train': '0.087633', 'examples_per_second': '5.4305', 'grad_norm': '9.1875', 'counters/examples': 35584, 'counters/updates': 2224}
skipping logging after 35600 examples to avoid logging too frequently
skipping logging after 35616 examples to avoid logging too frequently
skipping logging after 35632 examples to avoid logging too frequently
train stats after 35648 examples: {'rewards_train/chosen': '-2.166', 'rewards_train/rejected': '-8.2471', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.0818', 'logps_train/rejected': '-191.46', 'logps_train/chosen': '-59.354', 'loss/train': '0.076043', 'examples_per_second': '4.9026', 'grad_norm': '10.438', 'counters/examples': 35648, 'counters/updates': 2228}
skipping logging after 35664 examples to avoid logging too frequently
skipping logging after 35680 examples to avoid logging too frequently
skipping logging after 35696 examples to avoid logging too frequently
train stats after 35712 examples: {'rewards_train/chosen': '-1.826', 'rewards_train/rejected': '-9.2854', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.4569', 'logps_train/rejected': '-225.66', 'logps_train/chosen': '-58.953', 'loss/train': '0.060828', 'examples_per_second': '4.5148', 'grad_norm': '5.625', 'counters/examples': 35712, 'counters/updates': 2232}
skipping logging after 35728 examples to avoid logging too frequently
skipping logging after 35744 examples to avoid logging too frequently
skipping logging after 35760 examples to avoid logging too frequently
train stats after 35776 examples: {'rewards_train/chosen': '-2.355', 'rewards_train/rejected': '-9.6221', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.2678', 'logps_train/rejected': '-231.29', 'logps_train/chosen': '-64.833', 'loss/train': '0.065784', 'examples_per_second': '5.9645', 'grad_norm': '10.688', 'counters/examples': 35776, 'counters/updates': 2236}
skipping logging after 35792 examples to avoid logging too frequently
skipping logging after 35808 examples to avoid logging too frequently
skipping logging after 35824 examples to avoid logging too frequently
train stats after 35840 examples: {'rewards_train/chosen': '-2.4035', 'rewards_train/rejected': '-9.6973', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.2941', 'logps_train/rejected': '-252.69', 'logps_train/chosen': '-67.785', 'loss/train': '0.071847', 'examples_per_second': '6.0451', 'grad_norm': '8.25', 'counters/examples': 35840, 'counters/updates': 2240}
skipping logging after 35856 examples to avoid logging too frequently
skipping logging after 35872 examples to avoid logging too frequently
skipping logging after 35888 examples to avoid logging too frequently
train stats after 35904 examples: {'rewards_train/chosen': '-2.1099', 'rewards_train/rejected': '-10.695', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.5863', 'logps_train/rejected': '-259.67', 'logps_train/chosen': '-69.415', 'loss/train': '0.03668', 'examples_per_second': '4.0627', 'grad_norm': '7.625', 'counters/examples': 35904, 'counters/updates': 2244}
skipping logging after 35920 examples to avoid logging too frequently
skipping logging after 35936 examples to avoid logging too frequently
skipping logging after 35952 examples to avoid logging too frequently
train stats after 35968 examples: {'rewards_train/chosen': '-2.3535', 'rewards_train/rejected': '-11.543', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.1907', 'logps_train/rejected': '-267.66', 'logps_train/chosen': '-70.426', 'loss/train': '0.062563', 'examples_per_second': '4.4262', 'grad_norm': '10.938', 'counters/examples': 35968, 'counters/updates': 2248}
skipping logging after 35984 examples to avoid logging too frequently
skipping logging after 36000 examples to avoid logging too frequently
Running evaluation after 36000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:13,  2.37s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:05,  2.19s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:56,  1.94s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.91s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:42,  1.56s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.66s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.50s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.57s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:36,  1.57s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.50s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:22,  1.30s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.24s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.33s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.34s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.27s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:33<00:10,  1.21s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.29s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.26s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:37<00:07,  1.30s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:39<00:07,  1.48s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.41s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.61s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.42s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.41s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.44s/it]
eval after 36000: {'rewards_eval/chosen': '-9.8657', 'rewards_eval/rejected': '-10.307', 'rewards_eval/accuracies': '0.5293', 'rewards_eval/margins': '0.44113', 'logps_eval/rejected': '-250.72', 'logps_eval/chosen': '-243.56', 'loss/eval': '2.0252'}
skipping logging after 36016 examples to avoid logging too frequently
train stats after 36032 examples: {'rewards_train/chosen': '-2.1198', 'rewards_train/rejected': '-10.458', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.3417', 'logps_train/rejected': '-248.28', 'logps_train/chosen': '-66.482', 'loss/train': '0.094709', 'examples_per_second': '4.56', 'grad_norm': '13.438', 'counters/examples': 36032, 'counters/updates': 2252}
skipping logging after 36048 examples to avoid logging too frequently
skipping logging after 36064 examples to avoid logging too frequently
skipping logging after 36080 examples to avoid logging too frequently
train stats after 36096 examples: {'rewards_train/chosen': '-2.3614', 'rewards_train/rejected': '-11.168', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.8069', 'logps_train/rejected': '-259.79', 'logps_train/chosen': '-68.016', 'loss/train': '0.018769', 'examples_per_second': '4.6897', 'grad_norm': '6.0625', 'counters/examples': 36096, 'counters/updates': 2256}
skipping logging after 36112 examples to avoid logging too frequently
skipping logging after 36128 examples to avoid logging too frequently
skipping logging after 36144 examples to avoid logging too frequently
train stats after 36160 examples: {'rewards_train/chosen': '-2.5174', 'rewards_train/rejected': '-11.498', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.9824', 'logps_train/rejected': '-272.46', 'logps_train/chosen': '-66.701', 'loss/train': '0.11349', 'examples_per_second': '5.0334', 'grad_norm': '11.938', 'counters/examples': 36160, 'counters/updates': 2260}
skipping logging after 36176 examples to avoid logging too frequently
skipping logging after 36192 examples to avoid logging too frequently
skipping logging after 36208 examples to avoid logging too frequently
train stats after 36224 examples: {'rewards_train/chosen': '-2.6094', 'rewards_train/rejected': '-10.869', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.2581', 'logps_train/rejected': '-247.87', 'logps_train/chosen': '-66.867', 'loss/train': '0.11494', 'examples_per_second': '5.9996', 'grad_norm': '17.25', 'counters/examples': 36224, 'counters/updates': 2264}
skipping logging after 36240 examples to avoid logging too frequently
skipping logging after 36256 examples to avoid logging too frequently
skipping logging after 36272 examples to avoid logging too frequently
train stats after 36288 examples: {'rewards_train/chosen': '-2.2464', 'rewards_train/rejected': '-9.6631', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.4158', 'logps_train/rejected': '-231.3', 'logps_train/chosen': '-59.773', 'loss/train': '0.080887', 'examples_per_second': '4.7514', 'grad_norm': '19.375', 'counters/examples': 36288, 'counters/updates': 2268}
skipping logging after 36304 examples to avoid logging too frequently
skipping logging after 36320 examples to avoid logging too frequently
skipping logging after 36336 examples to avoid logging too frequently
train stats after 36352 examples: {'rewards_train/chosen': '-3.116', 'rewards_train/rejected': '-11.539', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.4221', 'logps_train/rejected': '-246.95', 'logps_train/chosen': '-72.129', 'loss/train': '0.11075', 'examples_per_second': '5.311', 'grad_norm': '19', 'counters/examples': 36352, 'counters/updates': 2272}
skipping logging after 36368 examples to avoid logging too frequently
skipping logging after 36384 examples to avoid logging too frequently
skipping logging after 36400 examples to avoid logging too frequently
train stats after 36416 examples: {'rewards_train/chosen': '-2.7868', 'rewards_train/rejected': '-10.662', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.8755', 'logps_train/rejected': '-233.58', 'logps_train/chosen': '-66.696', 'loss/train': '0.11789', 'examples_per_second': '4.9261', 'grad_norm': '15.25', 'counters/examples': 36416, 'counters/updates': 2276}
skipping logging after 36432 examples to avoid logging too frequently
skipping logging after 36448 examples to avoid logging too frequently
skipping logging after 36464 examples to avoid logging too frequently
train stats after 36480 examples: {'rewards_train/chosen': '-2.5481', 'rewards_train/rejected': '-10.066', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.519', 'logps_train/rejected': '-233.95', 'logps_train/chosen': '-64.308', 'loss/train': '0.079596', 'examples_per_second': '4.9605', 'grad_norm': '9.5625', 'counters/examples': 36480, 'counters/updates': 2280}
skipping logging after 36496 examples to avoid logging too frequently
skipping logging after 36512 examples to avoid logging too frequently
skipping logging after 36528 examples to avoid logging too frequently
train stats after 36544 examples: {'rewards_train/chosen': '-2.483', 'rewards_train/rejected': '-11.51', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.0276', 'logps_train/rejected': '-277.82', 'logps_train/chosen': '-65.483', 'loss/train': '0.048776', 'examples_per_second': '5.0551', 'grad_norm': '5', 'counters/examples': 36544, 'counters/updates': 2284}
skipping logging after 36560 examples to avoid logging too frequently
skipping logging after 36576 examples to avoid logging too frequently
skipping logging after 36592 examples to avoid logging too frequently
train stats after 36608 examples: {'rewards_train/chosen': '-2.8838', 'rewards_train/rejected': '-10.346', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.4607', 'logps_train/rejected': '-235.41', 'logps_train/chosen': '-75.068', 'loss/train': '0.098904', 'examples_per_second': '5.0846', 'grad_norm': '14.375', 'counters/examples': 36608, 'counters/updates': 2288}
skipping logging after 36624 examples to avoid logging too frequently
skipping logging after 36640 examples to avoid logging too frequently
skipping logging after 36656 examples to avoid logging too frequently
train stats after 36672 examples: {'rewards_train/chosen': '-2.3137', 'rewards_train/rejected': '-11.814', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.5005', 'logps_train/rejected': '-291.22', 'logps_train/chosen': '-70.499', 'loss/train': '0.055571', 'examples_per_second': '4.892', 'grad_norm': '12.562', 'counters/examples': 36672, 'counters/updates': 2292}
skipping logging after 36688 examples to avoid logging too frequently
skipping logging after 36704 examples to avoid logging too frequently
skipping logging after 36720 examples to avoid logging too frequently
train stats after 36736 examples: {'rewards_train/chosen': '-2.26', 'rewards_train/rejected': '-10.58', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '8.3176', 'logps_train/rejected': '-239.11', 'logps_train/chosen': '-62.266', 'loss/train': '0.047077', 'examples_per_second': '4.4386', 'grad_norm': '4.0625', 'counters/examples': 36736, 'counters/updates': 2296}
skipping logging after 36752 examples to avoid logging too frequently
skipping logging after 36768 examples to avoid logging too frequently
skipping logging after 36784 examples to avoid logging too frequently
train stats after 36800 examples: {'rewards_train/chosen': '-2.6546', 'rewards_train/rejected': '-10.548', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.8956', 'logps_train/rejected': '-263.73', 'logps_train/chosen': '-70.271', 'loss/train': '0.1245', 'examples_per_second': '4.7275', 'grad_norm': '13.375', 'counters/examples': 36800, 'counters/updates': 2300}
skipping logging after 36816 examples to avoid logging too frequently
skipping logging after 36832 examples to avoid logging too frequently
skipping logging after 36848 examples to avoid logging too frequently
train stats after 36864 examples: {'rewards_train/chosen': '-2.4101', 'rewards_train/rejected': '-8.9464', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.5378', 'logps_train/rejected': '-210.55', 'logps_train/chosen': '-55.042', 'loss/train': '0.056792', 'examples_per_second': '5.4217', 'grad_norm': '6.8438', 'counters/examples': 36864, 'counters/updates': 2304}
skipping logging after 36880 examples to avoid logging too frequently
skipping logging after 36896 examples to avoid logging too frequently
skipping logging after 36912 examples to avoid logging too frequently
train stats after 36928 examples: {'rewards_train/chosen': '-2.4186', 'rewards_train/rejected': '-9.7285', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.3092', 'logps_train/rejected': '-238.48', 'logps_train/chosen': '-67.66', 'loss/train': '0.11474', 'examples_per_second': '5.4349', 'grad_norm': '8.6875', 'counters/examples': 36928, 'counters/updates': 2308}
skipping logging after 36944 examples to avoid logging too frequently
skipping logging after 36960 examples to avoid logging too frequently
skipping logging after 36976 examples to avoid logging too frequently
train stats after 36992 examples: {'rewards_train/chosen': '-2.0101', 'rewards_train/rejected': '-10.278', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.265', 'logps_train/rejected': '-283.21', 'logps_train/chosen': '-71.572', 'loss/train': '0.06835', 'examples_per_second': '4.0064', 'grad_norm': '6.6875', 'counters/examples': 36992, 'counters/updates': 2312}
skipping logging after 37008 examples to avoid logging too frequently
skipping logging after 37024 examples to avoid logging too frequently
skipping logging after 37040 examples to avoid logging too frequently
train stats after 37056 examples: {'rewards_train/chosen': '-1.9072', 'rewards_train/rejected': '-9.3689', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.4613', 'logps_train/rejected': '-243', 'logps_train/chosen': '-68.189', 'loss/train': '0.04909', 'examples_per_second': '4.6801', 'grad_norm': '7.8125', 'counters/examples': 37056, 'counters/updates': 2316}
skipping logging after 37072 examples to avoid logging too frequently
skipping logging after 37088 examples to avoid logging too frequently
skipping logging after 37104 examples to avoid logging too frequently
train stats after 37120 examples: {'rewards_train/chosen': '-2.1383', 'rewards_train/rejected': '-9.068', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.9287', 'logps_train/rejected': '-202.9', 'logps_train/chosen': '-56.75', 'loss/train': '0.060849', 'examples_per_second': '4.8859', 'grad_norm': '6.5', 'counters/examples': 37120, 'counters/updates': 2320}
skipping logging after 37136 examples to avoid logging too frequently
skipping logging after 37152 examples to avoid logging too frequently
skipping logging after 37168 examples to avoid logging too frequently
train stats after 37184 examples: {'rewards_train/chosen': '-1.9829', 'rewards_train/rejected': '-9.5925', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.6094', 'logps_train/rejected': '-234.08', 'logps_train/chosen': '-58.438', 'loss/train': '0.080108', 'examples_per_second': '4.9725', 'grad_norm': '10.312', 'counters/examples': 37184, 'counters/updates': 2324}
skipping logging after 37200 examples to avoid logging too frequently
skipping logging after 37216 examples to avoid logging too frequently
skipping logging after 37232 examples to avoid logging too frequently
train stats after 37248 examples: {'rewards_train/chosen': '-2.0865', 'rewards_train/rejected': '-9.2664', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.1803', 'logps_train/rejected': '-240.04', 'logps_train/chosen': '-60.132', 'loss/train': '0.11938', 'examples_per_second': '4.8637', 'grad_norm': '10.312', 'counters/examples': 37248, 'counters/updates': 2328}
skipping logging after 37264 examples to avoid logging too frequently
skipping logging after 37280 examples to avoid logging too frequently
skipping logging after 37296 examples to avoid logging too frequently
train stats after 37312 examples: {'rewards_train/chosen': '-2.0208', 'rewards_train/rejected': '-9.1741', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.1514', 'logps_train/rejected': '-242.67', 'logps_train/chosen': '-57.897', 'loss/train': '0.085998', 'examples_per_second': '3.9433', 'grad_norm': '7.3125', 'counters/examples': 37312, 'counters/updates': 2332}
skipping logging after 37328 examples to avoid logging too frequently
skipping logging after 37344 examples to avoid logging too frequently
skipping logging after 37360 examples to avoid logging too frequently
train stats after 37376 examples: {'rewards_train/chosen': '-2.0224', 'rewards_train/rejected': '-10.479', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.4579', 'logps_train/rejected': '-253.42', 'logps_train/chosen': '-62.24', 'loss/train': '0.063089', 'examples_per_second': '5.0403', 'grad_norm': '5.4062', 'counters/examples': 37376, 'counters/updates': 2336}
skipping logging after 37392 examples to avoid logging too frequently
skipping logging after 37408 examples to avoid logging too frequently
skipping logging after 37424 examples to avoid logging too frequently
train stats after 37440 examples: {'rewards_train/chosen': '-2.381', 'rewards_train/rejected': '-10.244', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.8616', 'logps_train/rejected': '-228.95', 'logps_train/chosen': '-69.676', 'loss/train': '0.09668', 'examples_per_second': '5.139', 'grad_norm': '9.9375', 'counters/examples': 37440, 'counters/updates': 2340}
skipping logging after 37456 examples to avoid logging too frequently
skipping logging after 37472 examples to avoid logging too frequently
skipping logging after 37488 examples to avoid logging too frequently
train stats after 37504 examples: {'rewards_train/chosen': '-2.7394', 'rewards_train/rejected': '-10.855', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.1176', 'logps_train/rejected': '-239.28', 'logps_train/chosen': '-71.005', 'loss/train': '0.098276', 'examples_per_second': '5.0809', 'grad_norm': '9.8125', 'counters/examples': 37504, 'counters/updates': 2344}
skipping logging after 37520 examples to avoid logging too frequently
skipping logging after 37536 examples to avoid logging too frequently
skipping logging after 37552 examples to avoid logging too frequently
train stats after 37568 examples: {'rewards_train/chosen': '-2.6509', 'rewards_train/rejected': '-11.602', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.9526', 'logps_train/rejected': '-256.66', 'logps_train/chosen': '-65.313', 'loss/train': '0.072269', 'examples_per_second': '3.699', 'grad_norm': '6.5', 'counters/examples': 37568, 'counters/updates': 2348}
skipping logging after 37584 examples to avoid logging too frequently
skipping logging after 37600 examples to avoid logging too frequently
skipping logging after 37616 examples to avoid logging too frequently
train stats after 37632 examples: {'rewards_train/chosen': '-2.1702', 'rewards_train/rejected': '-12.625', 'rewards_train/accuracies': '1', 'rewards_train/margins': '10.452', 'logps_train/rejected': '-306.07', 'logps_train/chosen': '-69.394', 'loss/train': '0.048059', 'examples_per_second': '4.9526', 'grad_norm': '5.2812', 'counters/examples': 37632, 'counters/updates': 2352}
skipping logging after 37648 examples to avoid logging too frequently
skipping logging after 37664 examples to avoid logging too frequently
skipping logging after 37680 examples to avoid logging too frequently
train stats after 37696 examples: {'rewards_train/chosen': '-2.9319', 'rewards_train/rejected': '-11.217', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '8.2854', 'logps_train/rejected': '-254.48', 'logps_train/chosen': '-66.845', 'loss/train': '0.13606', 'examples_per_second': '4.3942', 'grad_norm': '10.75', 'counters/examples': 37696, 'counters/updates': 2356}
skipping logging after 37712 examples to avoid logging too frequently
skipping logging after 37728 examples to avoid logging too frequently
skipping logging after 37744 examples to avoid logging too frequently
train stats after 37760 examples: {'rewards_train/chosen': '-1.8194', 'rewards_train/rejected': '-11.961', 'rewards_train/accuracies': '1', 'rewards_train/margins': '10.142', 'logps_train/rejected': '-276.13', 'logps_train/chosen': '-61.79', 'loss/train': '0.027288', 'examples_per_second': '4.9521', 'grad_norm': '6.9375', 'counters/examples': 37760, 'counters/updates': 2360}
skipping logging after 37776 examples to avoid logging too frequently
skipping logging after 37792 examples to avoid logging too frequently
skipping logging after 37808 examples to avoid logging too frequently
train stats after 37824 examples: {'rewards_train/chosen': '-2.5177', 'rewards_train/rejected': '-9.6147', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.0981', 'logps_train/rejected': '-212.29', 'logps_train/chosen': '-64.569', 'loss/train': '0.054212', 'examples_per_second': '6.279', 'grad_norm': '15.625', 'counters/examples': 37824, 'counters/updates': 2364}
skipping logging after 37840 examples to avoid logging too frequently
skipping logging after 37856 examples to avoid logging too frequently
skipping logging after 37872 examples to avoid logging too frequently
train stats after 37888 examples: {'rewards_train/chosen': '-2.9173', 'rewards_train/rejected': '-11.03', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.114', 'logps_train/rejected': '-247.25', 'logps_train/chosen': '-72.809', 'loss/train': '0.13211', 'examples_per_second': '5.8577', 'grad_norm': '19.5', 'counters/examples': 37888, 'counters/updates': 2368}
skipping logging after 37904 examples to avoid logging too frequently
skipping logging after 37920 examples to avoid logging too frequently
skipping logging after 37936 examples to avoid logging too frequently
train stats after 37952 examples: {'rewards_train/chosen': '-2.7764', 'rewards_train/rejected': '-12.121', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.3405', 'logps_train/rejected': '-283.64', 'logps_train/chosen': '-72.805', 'loss/train': '0.095497', 'examples_per_second': '4.8322', 'grad_norm': '17.25', 'counters/examples': 37952, 'counters/updates': 2372}
skipping logging after 37968 examples to avoid logging too frequently
skipping logging after 37984 examples to avoid logging too frequently
skipping logging after 38000 examples to avoid logging too frequently
train stats after 38016 examples: {'rewards_train/chosen': '-2.3965', 'rewards_train/rejected': '-10.668', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.2715', 'logps_train/rejected': '-228.35', 'logps_train/chosen': '-60.41', 'loss/train': '0.042915', 'examples_per_second': '5.7677', 'grad_norm': '3.9688', 'counters/examples': 38016, 'counters/updates': 2376}
skipping logging after 38032 examples to avoid logging too frequently
skipping logging after 38048 examples to avoid logging too frequently
skipping logging after 38064 examples to avoid logging too frequently
train stats after 38080 examples: {'rewards_train/chosen': '-2.3112', 'rewards_train/rejected': '-11.194', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.8848', 'logps_train/rejected': '-277.25', 'logps_train/chosen': '-64.75', 'loss/train': '0.06774', 'examples_per_second': '4.9841', 'grad_norm': '15.375', 'counters/examples': 38080, 'counters/updates': 2380}
skipping logging after 38096 examples to avoid logging too frequently
skipping logging after 38112 examples to avoid logging too frequently
skipping logging after 38128 examples to avoid logging too frequently
train stats after 38144 examples: {'rewards_train/chosen': '-2.2883', 'rewards_train/rejected': '-9.8431', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.5564', 'logps_train/rejected': '-215.82', 'logps_train/chosen': '-61.61', 'loss/train': '0.084709', 'examples_per_second': '4.8601', 'grad_norm': '9.875', 'counters/examples': 38144, 'counters/updates': 2384}
skipping logging after 38160 examples to avoid logging too frequently
skipping logging after 38176 examples to avoid logging too frequently
skipping logging after 38192 examples to avoid logging too frequently
train stats after 38208 examples: {'rewards_train/chosen': '-2.3961', 'rewards_train/rejected': '-9.5787', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.1805', 'logps_train/rejected': '-214.59', 'logps_train/chosen': '-56.823', 'loss/train': '0.082675', 'examples_per_second': '5.8295', 'grad_norm': '9.75', 'counters/examples': 38208, 'counters/updates': 2388}
skipping logging after 38224 examples to avoid logging too frequently
skipping logging after 38240 examples to avoid logging too frequently
skipping logging after 38256 examples to avoid logging too frequently
train stats after 38272 examples: {'rewards_train/chosen': '-1.6601', 'rewards_train/rejected': '-12.457', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '10.795', 'logps_train/rejected': '-329.09', 'logps_train/chosen': '-56.39', 'loss/train': '0.014888', 'examples_per_second': '4.2741', 'grad_norm': '2.875', 'counters/examples': 38272, 'counters/updates': 2392}
skipping logging after 38288 examples to avoid logging too frequently
skipping logging after 38304 examples to avoid logging too frequently
skipping logging after 38320 examples to avoid logging too frequently
train stats after 38336 examples: {'rewards_train/chosen': '-2.4738', 'rewards_train/rejected': '-9.3722', 'rewards_train/accuracies': '0.89062', 'rewards_train/margins': '6.8937', 'logps_train/rejected': '-207.32', 'logps_train/chosen': '-59.189', 'loss/train': '0.16182', 'examples_per_second': '5.0333', 'grad_norm': '14.812', 'counters/examples': 38336, 'counters/updates': 2396}
skipping logging after 38352 examples to avoid logging too frequently
skipping logging after 38368 examples to avoid logging too frequently
skipping logging after 38384 examples to avoid logging too frequently
train stats after 38400 examples: {'rewards_train/chosen': '-1.846', 'rewards_train/rejected': '-10.172', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.3248', 'logps_train/rejected': '-266.84', 'logps_train/chosen': '-61.131', 'loss/train': '0.04483', 'examples_per_second': '5.1282', 'grad_norm': '4.0625', 'counters/examples': 38400, 'counters/updates': 2400}
skipping logging after 38416 examples to avoid logging too frequently
skipping logging after 38432 examples to avoid logging too frequently
skipping logging after 38448 examples to avoid logging too frequently
train stats after 38464 examples: {'rewards_train/chosen': '-1.8524', 'rewards_train/rejected': '-9.7237', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.8685', 'logps_train/rejected': '-274.41', 'logps_train/chosen': '-58.064', 'loss/train': '0.079196', 'examples_per_second': '4.3477', 'grad_norm': '8.125', 'counters/examples': 38464, 'counters/updates': 2404}
skipping logging after 38480 examples to avoid logging too frequently
skipping logging after 38496 examples to avoid logging too frequently
skipping logging after 38512 examples to avoid logging too frequently
train stats after 38528 examples: {'rewards_train/chosen': '-2.1341', 'rewards_train/rejected': '-9.8367', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.7049', 'logps_train/rejected': '-233.02', 'logps_train/chosen': '-60.016', 'loss/train': '0.062031', 'examples_per_second': '4.5847', 'grad_norm': '5.7188', 'counters/examples': 38528, 'counters/updates': 2408}
skipping logging after 38544 examples to avoid logging too frequently
skipping logging after 38560 examples to avoid logging too frequently
skipping logging after 38576 examples to avoid logging too frequently
train stats after 38592 examples: {'rewards_train/chosen': '-2.4937', 'rewards_train/rejected': '-10.875', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.3812', 'logps_train/rejected': '-248.36', 'logps_train/chosen': '-66.409', 'loss/train': '0.047472', 'examples_per_second': '4.2055', 'grad_norm': '11.312', 'counters/examples': 38592, 'counters/updates': 2412}
skipping logging after 38608 examples to avoid logging too frequently
skipping logging after 38624 examples to avoid logging too frequently
skipping logging after 38640 examples to avoid logging too frequently
train stats after 38656 examples: {'rewards_train/chosen': '-2.2098', 'rewards_train/rejected': '-10.153', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.9436', 'logps_train/rejected': '-218.45', 'logps_train/chosen': '-60.008', 'loss/train': '0.055279', 'examples_per_second': '5.8956', 'grad_norm': '5.7812', 'counters/examples': 38656, 'counters/updates': 2416}
skipping logging after 38672 examples to avoid logging too frequently
skipping logging after 38688 examples to avoid logging too frequently
skipping logging after 38704 examples to avoid logging too frequently
train stats after 38720 examples: {'rewards_train/chosen': '-2.2789', 'rewards_train/rejected': '-11.573', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.29', 'logps_train/rejected': '-252.04', 'logps_train/chosen': '-71.804', 'loss/train': '0.083641', 'examples_per_second': '6.1611', 'grad_norm': '13.312', 'counters/examples': 38720, 'counters/updates': 2420}
skipping logging after 38736 examples to avoid logging too frequently
skipping logging after 38752 examples to avoid logging too frequently
skipping logging after 38768 examples to avoid logging too frequently
train stats after 38784 examples: {'rewards_train/chosen': '-2.4341', 'rewards_train/rejected': '-11.007', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.5721', 'logps_train/rejected': '-260.67', 'logps_train/chosen': '-60.927', 'loss/train': '0.11199', 'examples_per_second': '5.1834', 'grad_norm': '16.375', 'counters/examples': 38784, 'counters/updates': 2424}
skipping logging after 38800 examples to avoid logging too frequently
skipping logging after 38816 examples to avoid logging too frequently
skipping logging after 38832 examples to avoid logging too frequently
train stats after 38848 examples: {'rewards_train/chosen': '-1.6333', 'rewards_train/rejected': '-10.268', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.6351', 'logps_train/rejected': '-237.52', 'logps_train/chosen': '-55.341', 'loss/train': '0.052039', 'examples_per_second': '5.2886', 'grad_norm': '4.7188', 'counters/examples': 38848, 'counters/updates': 2428}
skipping logging after 38864 examples to avoid logging too frequently
skipping logging after 38880 examples to avoid logging too frequently
skipping logging after 38896 examples to avoid logging too frequently
train stats after 38912 examples: {'rewards_train/chosen': '-2.3613', 'rewards_train/rejected': '-10.022', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.664', 'logps_train/rejected': '-242.14', 'logps_train/chosen': '-60.762', 'loss/train': '0.059976', 'examples_per_second': '4.9577', 'grad_norm': '8.125', 'counters/examples': 38912, 'counters/updates': 2432}
skipping logging after 38928 examples to avoid logging too frequently
skipping logging after 38944 examples to avoid logging too frequently
skipping logging after 38960 examples to avoid logging too frequently
train stats after 38976 examples: {'rewards_train/chosen': '-2.261', 'rewards_train/rejected': '-10.174', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.9126', 'logps_train/rejected': '-231.93', 'logps_train/chosen': '-60.762', 'loss/train': '0.023021', 'examples_per_second': '4.9557', 'grad_norm': '3.9688', 'counters/examples': 38976, 'counters/updates': 2436}
skipping logging after 38992 examples to avoid logging too frequently
skipping logging after 39008 examples to avoid logging too frequently
skipping logging after 39024 examples to avoid logging too frequently
train stats after 39040 examples: {'rewards_train/chosen': '-2.5741', 'rewards_train/rejected': '-10.714', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.1382', 'logps_train/rejected': '-235.19', 'logps_train/chosen': '-65.867', 'loss/train': '0.047131', 'examples_per_second': '5.9554', 'grad_norm': '7.0312', 'counters/examples': 39040, 'counters/updates': 2440}
skipping logging after 39056 examples to avoid logging too frequently
skipping logging after 39072 examples to avoid logging too frequently
skipping logging after 39088 examples to avoid logging too frequently
train stats after 39104 examples: {'rewards_train/chosen': '-2.1387', 'rewards_train/rejected': '-11.036', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.8997', 'logps_train/rejected': '-253.06', 'logps_train/chosen': '-61.736', 'loss/train': '0.036433', 'examples_per_second': '6.0032', 'grad_norm': '6.0312', 'counters/examples': 39104, 'counters/updates': 2444}
skipping logging after 39120 examples to avoid logging too frequently
skipping logging after 39136 examples to avoid logging too frequently
skipping logging after 39152 examples to avoid logging too frequently
train stats after 39168 examples: {'rewards_train/chosen': '-2.1942', 'rewards_train/rejected': '-10.392', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.199', 'logps_train/rejected': '-233.89', 'logps_train/chosen': '-63.627', 'loss/train': '0.10414', 'examples_per_second': '4.7114', 'grad_norm': '15.875', 'counters/examples': 39168, 'counters/updates': 2448}
skipping logging after 39184 examples to avoid logging too frequently
skipping logging after 39200 examples to avoid logging too frequently
skipping logging after 39216 examples to avoid logging too frequently
train stats after 39232 examples: {'rewards_train/chosen': '-1.9777', 'rewards_train/rejected': '-9.9224', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.9459', 'logps_train/rejected': '-254.18', 'logps_train/chosen': '-58.418', 'loss/train': '0.040464', 'examples_per_second': '4.3654', 'grad_norm': '6.5312', 'counters/examples': 39232, 'counters/updates': 2452}
skipping logging after 39248 examples to avoid logging too frequently
skipping logging after 39264 examples to avoid logging too frequently
skipping logging after 39280 examples to avoid logging too frequently
train stats after 39296 examples: {'rewards_train/chosen': '-1.7949', 'rewards_train/rejected': '-10.159', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.361', 'logps_train/rejected': '-244.6', 'logps_train/chosen': '-70.457', 'loss/train': '0.029716', 'examples_per_second': '5.4918', 'grad_norm': '4.0625', 'counters/examples': 39296, 'counters/updates': 2456}
skipping logging after 39312 examples to avoid logging too frequently
skipping logging after 39328 examples to avoid logging too frequently
skipping logging after 39344 examples to avoid logging too frequently
train stats after 39360 examples: {'rewards_train/chosen': '-1.9571', 'rewards_train/rejected': '-10.072', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.1143', 'logps_train/rejected': '-249.36', 'logps_train/chosen': '-58.881', 'loss/train': '0.1025', 'examples_per_second': '4.1857', 'grad_norm': '14.375', 'counters/examples': 39360, 'counters/updates': 2460}
skipping logging after 39376 examples to avoid logging too frequently
skipping logging after 39392 examples to avoid logging too frequently
skipping logging after 39408 examples to avoid logging too frequently
train stats after 39424 examples: {'rewards_train/chosen': '-1.998', 'rewards_train/rejected': '-9.6524', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.6572', 'logps_train/rejected': '-240.86', 'logps_train/chosen': '-70.95', 'loss/train': '0.11106', 'examples_per_second': '4.6539', 'grad_norm': '18.75', 'counters/examples': 39424, 'counters/updates': 2464}
skipping logging after 39440 examples to avoid logging too frequently
skipping logging after 39456 examples to avoid logging too frequently
skipping logging after 39472 examples to avoid logging too frequently
train stats after 39488 examples: {'rewards_train/chosen': '-2.1497', 'rewards_train/rejected': '-9.4619', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.3118', 'logps_train/rejected': '-223.9', 'logps_train/chosen': '-54.356', 'loss/train': '0.076899', 'examples_per_second': '5.566', 'grad_norm': '11.5', 'counters/examples': 39488, 'counters/updates': 2468}
skipping logging after 39504 examples to avoid logging too frequently
skipping logging after 39520 examples to avoid logging too frequently
skipping logging after 39536 examples to avoid logging too frequently
train stats after 39552 examples: {'rewards_train/chosen': '-2.267', 'rewards_train/rejected': '-10.861', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.5923', 'logps_train/rejected': '-257.52', 'logps_train/chosen': '-61.424', 'loss/train': '0.06147', 'examples_per_second': '4.8805', 'grad_norm': '11.812', 'counters/examples': 39552, 'counters/updates': 2472}
skipping logging after 39568 examples to avoid logging too frequently
skipping logging after 39584 examples to avoid logging too frequently
skipping logging after 39600 examples to avoid logging too frequently
train stats after 39616 examples: {'rewards_train/chosen': '-2.14', 'rewards_train/rejected': '-9.7297', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.5892', 'logps_train/rejected': '-238.94', 'logps_train/chosen': '-63.114', 'loss/train': '0.039321', 'examples_per_second': '4.6696', 'grad_norm': '6.5625', 'counters/examples': 39616, 'counters/updates': 2476}
skipping logging after 39632 examples to avoid logging too frequently
skipping logging after 39648 examples to avoid logging too frequently
skipping logging after 39664 examples to avoid logging too frequently
train stats after 39680 examples: {'rewards_train/chosen': '-2.3363', 'rewards_train/rejected': '-9.8287', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.4928', 'logps_train/rejected': '-228.79', 'logps_train/chosen': '-57.552', 'loss/train': '0.14373', 'examples_per_second': '4.4333', 'grad_norm': '13.875', 'counters/examples': 39680, 'counters/updates': 2480}
skipping logging after 39696 examples to avoid logging too frequently
skipping logging after 39712 examples to avoid logging too frequently
skipping logging after 39728 examples to avoid logging too frequently
train stats after 39744 examples: {'rewards_train/chosen': '-1.9395', 'rewards_train/rejected': '-9.7754', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '7.8336', 'logps_train/rejected': '-255.34', 'logps_train/chosen': '-58.839', 'loss/train': '0.11359', 'examples_per_second': '5.2237', 'grad_norm': '8.6875', 'counters/examples': 39744, 'counters/updates': 2484}
skipping logging after 39760 examples to avoid logging too frequently
skipping logging after 39776 examples to avoid logging too frequently
skipping logging after 39792 examples to avoid logging too frequently
train stats after 39808 examples: {'rewards_train/chosen': '-1.9781', 'rewards_train/rejected': '-9.0776', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.0986', 'logps_train/rejected': '-219.67', 'logps_train/chosen': '-54.143', 'loss/train': '0.12016', 'examples_per_second': '5.1432', 'grad_norm': '10.375', 'counters/examples': 39808, 'counters/updates': 2488}
skipping logging after 39824 examples to avoid logging too frequently
skipping logging after 39840 examples to avoid logging too frequently
skipping logging after 39856 examples to avoid logging too frequently
train stats after 39872 examples: {'rewards_train/chosen': '-2.1448', 'rewards_train/rejected': '-9.9944', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.8516', 'logps_train/rejected': '-262.71', 'logps_train/chosen': '-66.207', 'loss/train': '0.066373', 'examples_per_second': '5.0446', 'grad_norm': '11.062', 'counters/examples': 39872, 'counters/updates': 2492}
skipping logging after 39888 examples to avoid logging too frequently
skipping logging after 39904 examples to avoid logging too frequently
skipping logging after 39920 examples to avoid logging too frequently
train stats after 39936 examples: {'rewards_train/chosen': '-2.2311', 'rewards_train/rejected': '-8.9321', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.7026', 'logps_train/rejected': '-194.38', 'logps_train/chosen': '-61.456', 'loss/train': '0.096756', 'examples_per_second': '5.2931', 'grad_norm': '11.25', 'counters/examples': 39936, 'counters/updates': 2496}
skipping logging after 39952 examples to avoid logging too frequently
skipping logging after 39968 examples to avoid logging too frequently
skipping logging after 39984 examples to avoid logging too frequently
train stats after 40000 examples: {'rewards_train/chosen': '-2.4148', 'rewards_train/rejected': '-9.0229', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.6088', 'logps_train/rejected': '-212.47', 'logps_train/chosen': '-58.343', 'loss/train': '0.2067', 'examples_per_second': '5.4823', 'grad_norm': '12.5', 'counters/examples': 40000, 'counters/updates': 2500}
Running evaluation after 40000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<01:00,  1.95s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:00,  2.02s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:53,  1.84s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.86s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.52s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.50s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:22,  1.30s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.24s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.33s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.34s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.23s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.27s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.29s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.26s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.30s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.48s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.41s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.62s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.42s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.42s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 40000: {'rewards_eval/chosen': '-9.0675', 'rewards_eval/rejected': '-9.4939', 'rewards_eval/accuracies': '0.54102', 'rewards_eval/margins': '0.42583', 'logps_eval/rejected': '-242.59', 'logps_eval/chosen': '-235.58', 'loss/eval': '1.8905'}
skipping logging after 40016 examples to avoid logging too frequently
skipping logging after 40032 examples to avoid logging too frequently
skipping logging after 40048 examples to avoid logging too frequently
train stats after 40064 examples: {'rewards_train/chosen': '-2.1134', 'rewards_train/rejected': '-9.2935', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.1808', 'logps_train/rejected': '-229.41', 'logps_train/chosen': '-57.388', 'loss/train': '0.078852', 'examples_per_second': '5.754', 'grad_norm': '8.8125', 'counters/examples': 40064, 'counters/updates': 2504}
skipping logging after 40080 examples to avoid logging too frequently
skipping logging after 40096 examples to avoid logging too frequently
skipping logging after 40112 examples to avoid logging too frequently
train stats after 40128 examples: {'rewards_train/chosen': '-1.9842', 'rewards_train/rejected': '-9.5724', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.5865', 'logps_train/rejected': '-226.55', 'logps_train/chosen': '-64.084', 'loss/train': '0.050516', 'examples_per_second': '5.2983', 'grad_norm': '5.3125', 'counters/examples': 40128, 'counters/updates': 2508}
skipping logging after 40144 examples to avoid logging too frequently
skipping logging after 40160 examples to avoid logging too frequently
skipping logging after 40176 examples to avoid logging too frequently
train stats after 40192 examples: {'rewards_train/chosen': '-2.287', 'rewards_train/rejected': '-10.704', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.4136', 'logps_train/rejected': '-268.79', 'logps_train/chosen': '-60.104', 'loss/train': '0.046149', 'examples_per_second': '5.1028', 'grad_norm': '6.7188', 'counters/examples': 40192, 'counters/updates': 2512}
skipping logging after 40208 examples to avoid logging too frequently
skipping logging after 40224 examples to avoid logging too frequently
skipping logging after 40240 examples to avoid logging too frequently
train stats after 40256 examples: {'rewards_train/chosen': '-2.6586', 'rewards_train/rejected': '-10.754', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.0952', 'logps_train/rejected': '-248.35', 'logps_train/chosen': '-67.217', 'loss/train': '0.06007', 'examples_per_second': '6.7532', 'grad_norm': '8.125', 'counters/examples': 40256, 'counters/updates': 2516}
skipping logging after 40272 examples to avoid logging too frequently
skipping logging after 40288 examples to avoid logging too frequently
skipping logging after 40304 examples to avoid logging too frequently
train stats after 40320 examples: {'rewards_train/chosen': '-2.5421', 'rewards_train/rejected': '-10.335', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.7914', 'logps_train/rejected': '-233.31', 'logps_train/chosen': '-75.158', 'loss/train': '0.11144', 'examples_per_second': '6.159', 'grad_norm': '18.875', 'counters/examples': 40320, 'counters/updates': 2520}
skipping logging after 40336 examples to avoid logging too frequently
skipping logging after 40352 examples to avoid logging too frequently
skipping logging after 40368 examples to avoid logging too frequently
train stats after 40384 examples: {'rewards_train/chosen': '-2.2751', 'rewards_train/rejected': '-10.441', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.1678', 'logps_train/rejected': '-238.27', 'logps_train/chosen': '-58.108', 'loss/train': '0.062621', 'examples_per_second': '5.3408', 'grad_norm': '12.75', 'counters/examples': 40384, 'counters/updates': 2524}
skipping logging after 40400 examples to avoid logging too frequently
skipping logging after 40416 examples to avoid logging too frequently
skipping logging after 40432 examples to avoid logging too frequently
train stats after 40448 examples: {'rewards_train/chosen': '-2.2755', 'rewards_train/rejected': '-9.4339', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.1561', 'logps_train/rejected': '-227.94', 'logps_train/chosen': '-54.002', 'loss/train': '0.093254', 'examples_per_second': '6.2726', 'grad_norm': '7.3438', 'counters/examples': 40448, 'counters/updates': 2528}
skipping logging after 40464 examples to avoid logging too frequently
skipping logging after 40480 examples to avoid logging too frequently
skipping logging after 40496 examples to avoid logging too frequently
train stats after 40512 examples: {'rewards_train/chosen': '-2.2064', 'rewards_train/rejected': '-9.8306', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.6237', 'logps_train/rejected': '-217.77', 'logps_train/chosen': '-59.566', 'loss/train': '0.042191', 'examples_per_second': '6.4126', 'grad_norm': '7.9688', 'counters/examples': 40512, 'counters/updates': 2532}
skipping logging after 40528 examples to avoid logging too frequently
skipping logging after 40544 examples to avoid logging too frequently
skipping logging after 40560 examples to avoid logging too frequently
train stats after 40576 examples: {'rewards_train/chosen': '-2.1553', 'rewards_train/rejected': '-10.946', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.7941', 'logps_train/rejected': '-268.5', 'logps_train/chosen': '-69.1', 'loss/train': '0.066959', 'examples_per_second': '4.6126', 'grad_norm': '24.625', 'counters/examples': 40576, 'counters/updates': 2536}
skipping logging after 40592 examples to avoid logging too frequently
skipping logging after 40608 examples to avoid logging too frequently
skipping logging after 40624 examples to avoid logging too frequently
train stats after 40640 examples: {'rewards_train/chosen': '-2.5925', 'rewards_train/rejected': '-10.858', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.2674', 'logps_train/rejected': '-259.84', 'logps_train/chosen': '-69.504', 'loss/train': '0.068976', 'examples_per_second': '4.4717', 'grad_norm': '13.625', 'counters/examples': 40640, 'counters/updates': 2540}
skipping logging after 40656 examples to avoid logging too frequently
skipping logging after 40672 examples to avoid logging too frequently
skipping logging after 40688 examples to avoid logging too frequently
train stats after 40704 examples: {'rewards_train/chosen': '-2.4576', 'rewards_train/rejected': '-11.27', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.8169', 'logps_train/rejected': '-279.72', 'logps_train/chosen': '-69.031', 'loss/train': '0.065808', 'examples_per_second': '4.5681', 'grad_norm': '9.4375', 'counters/examples': 40704, 'counters/updates': 2544}
skipping logging after 40720 examples to avoid logging too frequently
skipping logging after 40736 examples to avoid logging too frequently
skipping logging after 40752 examples to avoid logging too frequently
train stats after 40768 examples: {'rewards_train/chosen': '-2.1319', 'rewards_train/rejected': '-11.336', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.2036', 'logps_train/rejected': '-288.66', 'logps_train/chosen': '-62.296', 'loss/train': '0.014216', 'examples_per_second': '4.5277', 'grad_norm': '2.3438', 'counters/examples': 40768, 'counters/updates': 2548}
skipping logging after 40784 examples to avoid logging too frequently
skipping logging after 40800 examples to avoid logging too frequently
skipping logging after 40816 examples to avoid logging too frequently
train stats after 40832 examples: {'rewards_train/chosen': '-2.3895', 'rewards_train/rejected': '-10.291', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.9003', 'logps_train/rejected': '-241.27', 'logps_train/chosen': '-66.5', 'loss/train': '0.092864', 'examples_per_second': '5.5548', 'grad_norm': '9.4375', 'counters/examples': 40832, 'counters/updates': 2552}
skipping logging after 40848 examples to avoid logging too frequently
skipping logging after 40864 examples to avoid logging too frequently
skipping logging after 40880 examples to avoid logging too frequently
train stats after 40896 examples: {'rewards_train/chosen': '-2.1529', 'rewards_train/rejected': '-10.929', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.776', 'logps_train/rejected': '-265.5', 'logps_train/chosen': '-62.595', 'loss/train': '0.061899', 'examples_per_second': '5.1207', 'grad_norm': '8.5', 'counters/examples': 40896, 'counters/updates': 2556}
skipping logging after 40912 examples to avoid logging too frequently
skipping logging after 40928 examples to avoid logging too frequently
skipping logging after 40944 examples to avoid logging too frequently
train stats after 40960 examples: {'rewards_train/chosen': '-2.5616', 'rewards_train/rejected': '-10.343', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.7809', 'logps_train/rejected': '-238.54', 'logps_train/chosen': '-61.811', 'loss/train': '0.051881', 'examples_per_second': '4.6686', 'grad_norm': '5.9062', 'counters/examples': 40960, 'counters/updates': 2560}
skipping logging after 40976 examples to avoid logging too frequently
skipping logging after 40992 examples to avoid logging too frequently
skipping logging after 41008 examples to avoid logging too frequently
train stats after 41024 examples: {'rewards_train/chosen': '-1.8527', 'rewards_train/rejected': '-10.198', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.343', 'logps_train/rejected': '-231.79', 'logps_train/chosen': '-63.854', 'loss/train': '0.11889', 'examples_per_second': '4.6139', 'grad_norm': '9.25', 'counters/examples': 41024, 'counters/updates': 2564}
skipping logging after 41040 examples to avoid logging too frequently
skipping logging after 41056 examples to avoid logging too frequently
skipping logging after 41072 examples to avoid logging too frequently
train stats after 41088 examples: {'rewards_train/chosen': '-2.3857', 'rewards_train/rejected': '-10.566', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.1775', 'logps_train/rejected': '-261.62', 'logps_train/chosen': '-60.866', 'loss/train': '0.069815', 'examples_per_second': '4.9692', 'grad_norm': '10.938', 'counters/examples': 41088, 'counters/updates': 2568}
skipping logging after 41104 examples to avoid logging too frequently
skipping logging after 41120 examples to avoid logging too frequently
skipping logging after 41136 examples to avoid logging too frequently
train stats after 41152 examples: {'rewards_train/chosen': '-2.0704', 'rewards_train/rejected': '-10.573', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.5005', 'logps_train/rejected': '-268.25', 'logps_train/chosen': '-63.64', 'loss/train': '0.06199', 'examples_per_second': '4.6418', 'grad_norm': '7.5938', 'counters/examples': 41152, 'counters/updates': 2572}
skipping logging after 41168 examples to avoid logging too frequently
skipping logging after 41184 examples to avoid logging too frequently
skipping logging after 41200 examples to avoid logging too frequently
train stats after 41216 examples: {'rewards_train/chosen': '-2.2129', 'rewards_train/rejected': '-10.818', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.6057', 'logps_train/rejected': '-255.19', 'logps_train/chosen': '-66.871', 'loss/train': '0.064886', 'examples_per_second': '4.2022', 'grad_norm': '9.0625', 'counters/examples': 41216, 'counters/updates': 2576}
skipping logging after 41232 examples to avoid logging too frequently
skipping logging after 41248 examples to avoid logging too frequently
skipping logging after 41264 examples to avoid logging too frequently
train stats after 41280 examples: {'rewards_train/chosen': '-2.3934', 'rewards_train/rejected': '-10.566', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.1735', 'logps_train/rejected': '-241.24', 'logps_train/chosen': '-64.389', 'loss/train': '0.063793', 'examples_per_second': '4.9271', 'grad_norm': '13.375', 'counters/examples': 41280, 'counters/updates': 2580}
skipping logging after 41296 examples to avoid logging too frequently
skipping logging after 41312 examples to avoid logging too frequently
skipping logging after 41328 examples to avoid logging too frequently
train stats after 41344 examples: {'rewards_train/chosen': '-2.6185', 'rewards_train/rejected': '-10.565', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.9441', 'logps_train/rejected': '-260.36', 'logps_train/chosen': '-77.326', 'loss/train': '0.10726', 'examples_per_second': '5.3675', 'grad_norm': '19.125', 'counters/examples': 41344, 'counters/updates': 2584}
skipping logging after 41360 examples to avoid logging too frequently
skipping logging after 41376 examples to avoid logging too frequently
skipping logging after 41392 examples to avoid logging too frequently
train stats after 41408 examples: {'rewards_train/chosen': '-2.5106', 'rewards_train/rejected': '-12.078', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.5677', 'logps_train/rejected': '-292.04', 'logps_train/chosen': '-64.085', 'loss/train': '0.058355', 'examples_per_second': '4.5369', 'grad_norm': '6.8438', 'counters/examples': 41408, 'counters/updates': 2588}
skipping logging after 41424 examples to avoid logging too frequently
skipping logging after 41440 examples to avoid logging too frequently
skipping logging after 41456 examples to avoid logging too frequently
train stats after 41472 examples: {'rewards_train/chosen': '-2.0093', 'rewards_train/rejected': '-9.8141', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.8055', 'logps_train/rejected': '-202.36', 'logps_train/chosen': '-57.89', 'loss/train': '0.077435', 'examples_per_second': '6.1257', 'grad_norm': '7.0625', 'counters/examples': 41472, 'counters/updates': 2592}
skipping logging after 41488 examples to avoid logging too frequently
skipping logging after 41504 examples to avoid logging too frequently
skipping logging after 41520 examples to avoid logging too frequently
train stats after 41536 examples: {'rewards_train/chosen': '-2.5817', 'rewards_train/rejected': '-10.981', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.4041', 'logps_train/rejected': '-245.91', 'logps_train/chosen': '-70.171', 'loss/train': '0.083699', 'examples_per_second': '6.0054', 'grad_norm': '9.8125', 'counters/examples': 41536, 'counters/updates': 2596}
skipping logging after 41552 examples to avoid logging too frequently
skipping logging after 41568 examples to avoid logging too frequently
skipping logging after 41584 examples to avoid logging too frequently
train stats after 41600 examples: {'rewards_train/chosen': '-2.2566', 'rewards_train/rejected': '-10.754', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.4995', 'logps_train/rejected': '-236.92', 'logps_train/chosen': '-56.765', 'loss/train': '0.051207', 'examples_per_second': '4.2882', 'grad_norm': '8.0625', 'counters/examples': 41600, 'counters/updates': 2600}
skipping logging after 41616 examples to avoid logging too frequently
skipping logging after 41632 examples to avoid logging too frequently
skipping logging after 41648 examples to avoid logging too frequently
train stats after 41664 examples: {'rewards_train/chosen': '-2.7684', 'rewards_train/rejected': '-11.225', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.4535', 'logps_train/rejected': '-250.89', 'logps_train/chosen': '-70.594', 'loss/train': '0.045904', 'examples_per_second': '3.9177', 'grad_norm': '8.25', 'counters/examples': 41664, 'counters/updates': 2604}
skipping logging after 41680 examples to avoid logging too frequently
skipping logging after 41696 examples to avoid logging too frequently
skipping logging after 41712 examples to avoid logging too frequently
train stats after 41728 examples: {'rewards_train/chosen': '-2.9347', 'rewards_train/rejected': '-13.041', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '10.106', 'logps_train/rejected': '-295.03', 'logps_train/chosen': '-72.918', 'loss/train': '0.10396', 'examples_per_second': '5.2758', 'grad_norm': '17.25', 'counters/examples': 41728, 'counters/updates': 2608}
skipping logging after 41744 examples to avoid logging too frequently
skipping logging after 41760 examples to avoid logging too frequently
skipping logging after 41776 examples to avoid logging too frequently
train stats after 41792 examples: {'rewards_train/chosen': '-2.9337', 'rewards_train/rejected': '-11.571', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.6415', 'logps_train/rejected': '-279.89', 'logps_train/chosen': '-76.107', 'loss/train': '0.1078', 'examples_per_second': '4.4857', 'grad_norm': '18.875', 'counters/examples': 41792, 'counters/updates': 2612}
skipping logging after 41808 examples to avoid logging too frequently
skipping logging after 41824 examples to avoid logging too frequently
skipping logging after 41840 examples to avoid logging too frequently
train stats after 41856 examples: {'rewards_train/chosen': '-2.7625', 'rewards_train/rejected': '-11.92', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.1602', 'logps_train/rejected': '-278.83', 'logps_train/chosen': '-80.806', 'loss/train': '0.093984', 'examples_per_second': '4.4069', 'grad_norm': '13.562', 'counters/examples': 41856, 'counters/updates': 2616}
skipping logging after 41872 examples to avoid logging too frequently
skipping logging after 41888 examples to avoid logging too frequently
skipping logging after 41904 examples to avoid logging too frequently
train stats after 41920 examples: {'rewards_train/chosen': '-2.4953', 'rewards_train/rejected': '-10.456', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.9587', 'logps_train/rejected': '-230.48', 'logps_train/chosen': '-59.755', 'loss/train': '0.03849', 'examples_per_second': '4.5417', 'grad_norm': '7.0625', 'counters/examples': 41920, 'counters/updates': 2620}
skipping logging after 41936 examples to avoid logging too frequently
skipping logging after 41952 examples to avoid logging too frequently
skipping logging after 41968 examples to avoid logging too frequently
train stats after 41984 examples: {'rewards_train/chosen': '-2.3823', 'rewards_train/rejected': '-11.335', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.9538', 'logps_train/rejected': '-288.88', 'logps_train/chosen': '-60.591', 'loss/train': '0.058458', 'examples_per_second': '4.637', 'grad_norm': '6.3125', 'counters/examples': 41984, 'counters/updates': 2624}
skipping logging after 42000 examples to avoid logging too frequently
skipping logging after 42016 examples to avoid logging too frequently
skipping logging after 42032 examples to avoid logging too frequently
train stats after 42048 examples: {'rewards_train/chosen': '-2.7288', 'rewards_train/rejected': '-11.206', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.4768', 'logps_train/rejected': '-244.25', 'logps_train/chosen': '-61.539', 'loss/train': '0.047806', 'examples_per_second': '5.8866', 'grad_norm': '5.6875', 'counters/examples': 42048, 'counters/updates': 2628}
skipping logging after 42064 examples to avoid logging too frequently
skipping logging after 42080 examples to avoid logging too frequently
skipping logging after 42096 examples to avoid logging too frequently
train stats after 42112 examples: {'rewards_train/chosen': '-2.6043', 'rewards_train/rejected': '-11.04', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.4302', 'logps_train/rejected': '-252.48', 'logps_train/chosen': '-69.057', 'loss/train': '0.066421', 'examples_per_second': '5.0489', 'grad_norm': '15.5', 'counters/examples': 42112, 'counters/updates': 2632}
skipping logging after 42128 examples to avoid logging too frequently
skipping logging after 42144 examples to avoid logging too frequently
skipping logging after 42160 examples to avoid logging too frequently
train stats after 42176 examples: {'rewards_train/chosen': '-2.6379', 'rewards_train/rejected': '-11.654', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.0151', 'logps_train/rejected': '-270', 'logps_train/chosen': '-61.092', 'loss/train': '0.14718', 'examples_per_second': '5.5311', 'grad_norm': '16.75', 'counters/examples': 42176, 'counters/updates': 2636}
skipping logging after 42192 examples to avoid logging too frequently
skipping logging after 42208 examples to avoid logging too frequently
skipping logging after 42224 examples to avoid logging too frequently
train stats after 42240 examples: {'rewards_train/chosen': '-2.0497', 'rewards_train/rejected': '-10.282', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.229', 'logps_train/rejected': '-250.16', 'logps_train/chosen': '-62.617', 'loss/train': '0.064161', 'examples_per_second': '4.7996', 'grad_norm': '12.312', 'counters/examples': 42240, 'counters/updates': 2640}
skipping logging after 42256 examples to avoid logging too frequently
skipping logging after 42272 examples to avoid logging too frequently
skipping logging after 42288 examples to avoid logging too frequently
train stats after 42304 examples: {'rewards_train/chosen': '-2.4071', 'rewards_train/rejected': '-10.008', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.6035', 'logps_train/rejected': '-241.04', 'logps_train/chosen': '-62.194', 'loss/train': '0.060623', 'examples_per_second': '4.4995', 'grad_norm': '6.5625', 'counters/examples': 42304, 'counters/updates': 2644}
skipping logging after 42320 examples to avoid logging too frequently
skipping logging after 42336 examples to avoid logging too frequently
skipping logging after 42352 examples to avoid logging too frequently
train stats after 42368 examples: {'rewards_train/chosen': '-2.7166', 'rewards_train/rejected': '-11.916', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.1975', 'logps_train/rejected': '-288.15', 'logps_train/chosen': '-67.131', 'loss/train': '0.081364', 'examples_per_second': '4.574', 'grad_norm': '20.625', 'counters/examples': 42368, 'counters/updates': 2648}
skipping logging after 42384 examples to avoid logging too frequently
skipping logging after 42400 examples to avoid logging too frequently
skipping logging after 42416 examples to avoid logging too frequently
train stats after 42432 examples: {'rewards_train/chosen': '-2.5014', 'rewards_train/rejected': '-11.48', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.9772', 'logps_train/rejected': '-250.11', 'logps_train/chosen': '-67.967', 'loss/train': '0.073286', 'examples_per_second': '4.9585', 'grad_norm': '10.812', 'counters/examples': 42432, 'counters/updates': 2652}
skipping logging after 42448 examples to avoid logging too frequently
skipping logging after 42464 examples to avoid logging too frequently
skipping logging after 42480 examples to avoid logging too frequently
train stats after 42496 examples: {'rewards_train/chosen': '-2.7166', 'rewards_train/rejected': '-11.366', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.6527', 'logps_train/rejected': '-264.03', 'logps_train/chosen': '-70.064', 'loss/train': '0.10758', 'examples_per_second': '5.1599', 'grad_norm': '7.8438', 'counters/examples': 42496, 'counters/updates': 2656}
skipping logging after 42512 examples to avoid logging too frequently
skipping logging after 42528 examples to avoid logging too frequently
skipping logging after 42544 examples to avoid logging too frequently
train stats after 42560 examples: {'rewards_train/chosen': '-2.548', 'rewards_train/rejected': '-8.9589', 'rewards_train/accuracies': '0.875', 'rewards_train/margins': '6.412', 'logps_train/rejected': '-192.18', 'logps_train/chosen': '-60.373', 'loss/train': '0.14354', 'examples_per_second': '5.4457', 'grad_norm': '13.875', 'counters/examples': 42560, 'counters/updates': 2660}
skipping logging after 42576 examples to avoid logging too frequently
skipping logging after 42592 examples to avoid logging too frequently
skipping logging after 42608 examples to avoid logging too frequently
train stats after 42624 examples: {'rewards_train/chosen': '-1.9268', 'rewards_train/rejected': '-10.611', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.687', 'logps_train/rejected': '-230.09', 'logps_train/chosen': '-51.02', 'loss/train': '0.054896', 'examples_per_second': '4.35', 'grad_norm': '7.2188', 'counters/examples': 42624, 'counters/updates': 2664}
skipping logging after 42640 examples to avoid logging too frequently
skipping logging after 42656 examples to avoid logging too frequently
skipping logging after 42672 examples to avoid logging too frequently
train stats after 42688 examples: {'rewards_train/chosen': '-2.3544', 'rewards_train/rejected': '-11.51', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.1576', 'logps_train/rejected': '-266.57', 'logps_train/chosen': '-61.456', 'loss/train': '0.046505', 'examples_per_second': '4.9661', 'grad_norm': '10.75', 'counters/examples': 42688, 'counters/updates': 2668}
skipping logging after 42704 examples to avoid logging too frequently
skipping logging after 42720 examples to avoid logging too frequently
skipping logging after 42736 examples to avoid logging too frequently
train stats after 42752 examples: {'rewards_train/chosen': '-3.5687', 'rewards_train/rejected': '-12.169', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.6016', 'logps_train/rejected': '-248.34', 'logps_train/chosen': '-72.621', 'loss/train': '0.14829', 'examples_per_second': '4.821', 'grad_norm': '14.25', 'counters/examples': 42752, 'counters/updates': 2672}
skipping logging after 42768 examples to avoid logging too frequently
skipping logging after 42784 examples to avoid logging too frequently
skipping logging after 42800 examples to avoid logging too frequently
train stats after 42816 examples: {'rewards_train/chosen': '-2.716', 'rewards_train/rejected': '-12.212', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '9.4924', 'logps_train/rejected': '-282.23', 'logps_train/chosen': '-72.537', 'loss/train': '0.13565', 'examples_per_second': '4.4275', 'grad_norm': '22', 'counters/examples': 42816, 'counters/updates': 2676}
skipping logging after 42832 examples to avoid logging too frequently
skipping logging after 42848 examples to avoid logging too frequently
skipping logging after 42864 examples to avoid logging too frequently
train stats after 42880 examples: {'rewards_train/chosen': '-2.7844', 'rewards_train/rejected': '-11.576', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.7916', 'logps_train/rejected': '-262.83', 'logps_train/chosen': '-71.547', 'loss/train': '0.085285', 'examples_per_second': '4.8375', 'grad_norm': '5.6562', 'counters/examples': 42880, 'counters/updates': 2680}
skipping logging after 42896 examples to avoid logging too frequently
skipping logging after 42912 examples to avoid logging too frequently
skipping logging after 42928 examples to avoid logging too frequently
train stats after 42944 examples: {'rewards_train/chosen': '-2.5107', 'rewards_train/rejected': '-11.596', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.0803', 'logps_train/rejected': '-257.16', 'logps_train/chosen': '-66.981', 'loss/train': '0.072323', 'examples_per_second': '6.045', 'grad_norm': '10.375', 'counters/examples': 42944, 'counters/updates': 2684}
skipping logging after 42960 examples to avoid logging too frequently
skipping logging after 42976 examples to avoid logging too frequently
skipping logging after 42992 examples to avoid logging too frequently
train stats after 43008 examples: {'rewards_train/chosen': '-2.9123', 'rewards_train/rejected': '-10.823', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.9126', 'logps_train/rejected': '-239.52', 'logps_train/chosen': '-73.439', 'loss/train': '0.11939', 'examples_per_second': '4.8938', 'grad_norm': '11.875', 'counters/examples': 43008, 'counters/updates': 2688}
skipping logging after 43024 examples to avoid logging too frequently
skipping logging after 43040 examples to avoid logging too frequently
skipping logging after 43056 examples to avoid logging too frequently
train stats after 43072 examples: {'rewards_train/chosen': '-2.3061', 'rewards_train/rejected': '-12.312', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '10.002', 'logps_train/rejected': '-299.92', 'logps_train/chosen': '-61.777', 'loss/train': '0.048425', 'examples_per_second': '5.0051', 'grad_norm': '7.1562', 'counters/examples': 43072, 'counters/updates': 2692}
skipping logging after 43088 examples to avoid logging too frequently
skipping logging after 43104 examples to avoid logging too frequently
skipping logging after 43120 examples to avoid logging too frequently
train stats after 43136 examples: {'rewards_train/chosen': '-2.2861', 'rewards_train/rejected': '-10.283', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.9954', 'logps_train/rejected': '-219.97', 'logps_train/chosen': '-59.211', 'loss/train': '0.043218', 'examples_per_second': '4.6213', 'grad_norm': '6.0625', 'counters/examples': 43136, 'counters/updates': 2696}
skipping logging after 43152 examples to avoid logging too frequently
skipping logging after 43168 examples to avoid logging too frequently
skipping logging after 43184 examples to avoid logging too frequently
train stats after 43200 examples: {'rewards_train/chosen': '-2.7842', 'rewards_train/rejected': '-11.087', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.3037', 'logps_train/rejected': '-255.45', 'logps_train/chosen': '-73.87', 'loss/train': '0.1062', 'examples_per_second': '5.235', 'grad_norm': '14.375', 'counters/examples': 43200, 'counters/updates': 2700}
skipping logging after 43216 examples to avoid logging too frequently
skipping logging after 43232 examples to avoid logging too frequently
skipping logging after 43248 examples to avoid logging too frequently
train stats after 43264 examples: {'rewards_train/chosen': '-2.9438', 'rewards_train/rejected': '-11.769', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.827', 'logps_train/rejected': '-244.26', 'logps_train/chosen': '-69.126', 'loss/train': '0.11293', 'examples_per_second': '4.9811', 'grad_norm': '14.188', 'counters/examples': 43264, 'counters/updates': 2704}
skipping logging after 43280 examples to avoid logging too frequently
skipping logging after 43296 examples to avoid logging too frequently
skipping logging after 43312 examples to avoid logging too frequently
train stats after 43328 examples: {'rewards_train/chosen': '-2.1786', 'rewards_train/rejected': '-9.5798', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.4034', 'logps_train/rejected': '-221.47', 'logps_train/chosen': '-64.83', 'loss/train': '0.080672', 'examples_per_second': '5.7903', 'grad_norm': '9.5625', 'counters/examples': 43328, 'counters/updates': 2708}
skipping logging after 43344 examples to avoid logging too frequently
skipping logging after 43360 examples to avoid logging too frequently
skipping logging after 43376 examples to avoid logging too frequently
train stats after 43392 examples: {'rewards_train/chosen': '-2.3721', 'rewards_train/rejected': '-9.0593', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.6882', 'logps_train/rejected': '-201.38', 'logps_train/chosen': '-62.072', 'loss/train': '0.096911', 'examples_per_second': '5.0188', 'grad_norm': '8.0625', 'counters/examples': 43392, 'counters/updates': 2712}
skipping logging after 43408 examples to avoid logging too frequently
skipping logging after 43424 examples to avoid logging too frequently
skipping logging after 43440 examples to avoid logging too frequently
train stats after 43456 examples: {'rewards_train/chosen': '-2.1046', 'rewards_train/rejected': '-10.646', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.5353', 'logps_train/rejected': '-272.46', 'logps_train/chosen': '-62.739', 'loss/train': '0.056714', 'examples_per_second': '4.513', 'grad_norm': '5.125', 'counters/examples': 43456, 'counters/updates': 2716}
skipping logging after 43472 examples to avoid logging too frequently
skipping logging after 43488 examples to avoid logging too frequently
skipping logging after 43504 examples to avoid logging too frequently
train stats after 43520 examples: {'rewards_train/chosen': '-2.1222', 'rewards_train/rejected': '-8.7493', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '6.6292', 'logps_train/rejected': '-198.54', 'logps_train/chosen': '-60.832', 'loss/train': '0.13759', 'examples_per_second': '5.1975', 'grad_norm': '20.25', 'counters/examples': 43520, 'counters/updates': 2720}
skipping logging after 43536 examples to avoid logging too frequently
skipping logging after 43552 examples to avoid logging too frequently
skipping logging after 43568 examples to avoid logging too frequently
train stats after 43584 examples: {'rewards_train/chosen': '-2.0353', 'rewards_train/rejected': '-9.2805', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.2477', 'logps_train/rejected': '-208.88', 'logps_train/chosen': '-63.041', 'loss/train': '0.071186', 'examples_per_second': '4.1442', 'grad_norm': '11.5', 'counters/examples': 43584, 'counters/updates': 2724}
skipping logging after 43600 examples to avoid logging too frequently
skipping logging after 43616 examples to avoid logging too frequently
skipping logging after 43632 examples to avoid logging too frequently
train stats after 43648 examples: {'rewards_train/chosen': '-2.1988', 'rewards_train/rejected': '-9.6739', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.4755', 'logps_train/rejected': '-229.97', 'logps_train/chosen': '-69.167', 'loss/train': '0.095297', 'examples_per_second': '4.8261', 'grad_norm': '8.0625', 'counters/examples': 43648, 'counters/updates': 2728}
skipping logging after 43664 examples to avoid logging too frequently
skipping logging after 43680 examples to avoid logging too frequently
skipping logging after 43696 examples to avoid logging too frequently
train stats after 43712 examples: {'rewards_train/chosen': '-2.1623', 'rewards_train/rejected': '-10.43', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.2693', 'logps_train/rejected': '-240.85', 'logps_train/chosen': '-60.783', 'loss/train': '0.098126', 'examples_per_second': '6.0679', 'grad_norm': '9.4375', 'counters/examples': 43712, 'counters/updates': 2732}
skipping logging after 43728 examples to avoid logging too frequently
skipping logging after 43744 examples to avoid logging too frequently
skipping logging after 43760 examples to avoid logging too frequently
train stats after 43776 examples: {'rewards_train/chosen': '-2.4721', 'rewards_train/rejected': '-10.533', 'rewards_train/accuracies': '0.85938', 'rewards_train/margins': '8.0596', 'logps_train/rejected': '-254.76', 'logps_train/chosen': '-80.792', 'loss/train': '0.13634', 'examples_per_second': '5.0075', 'grad_norm': '21.875', 'counters/examples': 43776, 'counters/updates': 2736}
skipping logging after 43792 examples to avoid logging too frequently
skipping logging after 43808 examples to avoid logging too frequently
skipping logging after 43824 examples to avoid logging too frequently
train stats after 43840 examples: {'rewards_train/chosen': '-1.4476', 'rewards_train/rejected': '-9.7142', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.2642', 'logps_train/rejected': '-264.55', 'logps_train/chosen': '-53.55', 'loss/train': '0.089653', 'examples_per_second': '4.7222', 'grad_norm': '9', 'counters/examples': 43840, 'counters/updates': 2740}
skipping logging after 43856 examples to avoid logging too frequently
skipping logging after 43872 examples to avoid logging too frequently
skipping logging after 43888 examples to avoid logging too frequently
train stats after 43904 examples: {'rewards_train/chosen': '-1.8758', 'rewards_train/rejected': '-9.9846', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.1086', 'logps_train/rejected': '-265', 'logps_train/chosen': '-62.568', 'loss/train': '0.029649', 'examples_per_second': '4.7844', 'grad_norm': '3.1875', 'counters/examples': 43904, 'counters/updates': 2744}
skipping logging after 43920 examples to avoid logging too frequently
skipping logging after 43936 examples to avoid logging too frequently
skipping logging after 43952 examples to avoid logging too frequently
train stats after 43968 examples: {'rewards_train/chosen': '-1.8596', 'rewards_train/rejected': '-9.4045', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.5442', 'logps_train/rejected': '-223.44', 'logps_train/chosen': '-60.298', 'loss/train': '0.095975', 'examples_per_second': '6.7082', 'grad_norm': '10.812', 'counters/examples': 43968, 'counters/updates': 2748}
skipping logging after 43984 examples to avoid logging too frequently
skipping logging after 44000 examples to avoid logging too frequently
Running evaluation after 44000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:14,  2.40s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:06,  2.20s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:56,  1.94s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.91s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:42,  1.56s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.67s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.50s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.57s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:36,  1.57s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:30,  1.50s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:22,  1.30s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.24s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.33s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.34s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.27s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:33<00:10,  1.21s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.29s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.26s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:37<00:07,  1.30s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:39<00:07,  1.48s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.42s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.62s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.42s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.42s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.45s/it]
eval after 44000: {'rewards_eval/chosen': '-9.7345', 'rewards_eval/rejected': '-10.311', 'rewards_eval/accuracies': '0.52734', 'rewards_eval/margins': '0.57648', 'logps_eval/rejected': '-250.77', 'logps_eval/chosen': '-242.26', 'loss/eval': '2.0367'}
skipping logging after 44016 examples to avoid logging too frequently
train stats after 44032 examples: {'rewards_train/chosen': '-2.4189', 'rewards_train/rejected': '-10.784', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.3657', 'logps_train/rejected': '-258.24', 'logps_train/chosen': '-69.318', 'loss/train': '0.055569', 'examples_per_second': '5.3304', 'grad_norm': '6.5625', 'counters/examples': 44032, 'counters/updates': 2752}
skipping logging after 44048 examples to avoid logging too frequently
skipping logging after 44064 examples to avoid logging too frequently
skipping logging after 44080 examples to avoid logging too frequently
train stats after 44096 examples: {'rewards_train/chosen': '-2.3881', 'rewards_train/rejected': '-9.1613', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.772', 'logps_train/rejected': '-208.81', 'logps_train/chosen': '-64.405', 'loss/train': '0.13352', 'examples_per_second': '6.457', 'grad_norm': '18.375', 'counters/examples': 44096, 'counters/updates': 2756}
skipping logging after 44112 examples to avoid logging too frequently
skipping logging after 44128 examples to avoid logging too frequently
skipping logging after 44144 examples to avoid logging too frequently
train stats after 44160 examples: {'rewards_train/chosen': '-1.6921', 'rewards_train/rejected': '-10.801', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.1099', 'logps_train/rejected': '-275.79', 'logps_train/chosen': '-57.604', 'loss/train': '0.040804', 'examples_per_second': '5.0369', 'grad_norm': '6.3438', 'counters/examples': 44160, 'counters/updates': 2760}
skipping logging after 44176 examples to avoid logging too frequently
skipping logging after 44192 examples to avoid logging too frequently
skipping logging after 44208 examples to avoid logging too frequently
train stats after 44224 examples: {'rewards_train/chosen': '-2.3402', 'rewards_train/rejected': '-11.376', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.0349', 'logps_train/rejected': '-239.88', 'logps_train/chosen': '-62.298', 'loss/train': '0.069339', 'examples_per_second': '4.3732', 'grad_norm': '7.75', 'counters/examples': 44224, 'counters/updates': 2764}
skipping logging after 44240 examples to avoid logging too frequently
skipping logging after 44256 examples to avoid logging too frequently
skipping logging after 44272 examples to avoid logging too frequently
train stats after 44288 examples: {'rewards_train/chosen': '-2.4148', 'rewards_train/rejected': '-10.657', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.2451', 'logps_train/rejected': '-276.32', 'logps_train/chosen': '-64.445', 'loss/train': '0.043184', 'examples_per_second': '4.6699', 'grad_norm': '4.6562', 'counters/examples': 44288, 'counters/updates': 2768}
skipping logging after 44304 examples to avoid logging too frequently
skipping logging after 44320 examples to avoid logging too frequently
skipping logging after 44336 examples to avoid logging too frequently
train stats after 44352 examples: {'rewards_train/chosen': '-2.2559', 'rewards_train/rejected': '-9.9056', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.6482', 'logps_train/rejected': '-220.43', 'logps_train/chosen': '-55.624', 'loss/train': '0.13412', 'examples_per_second': '6.7127', 'grad_norm': '14.375', 'counters/examples': 44352, 'counters/updates': 2772}
skipping logging after 44368 examples to avoid logging too frequently
skipping logging after 44384 examples to avoid logging too frequently
skipping logging after 44400 examples to avoid logging too frequently
train stats after 44416 examples: {'rewards_train/chosen': '-2.126', 'rewards_train/rejected': '-11.335', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.2078', 'logps_train/rejected': '-284.65', 'logps_train/chosen': '-71.245', 'loss/train': '0.06304', 'examples_per_second': '5.3573', 'grad_norm': '14.125', 'counters/examples': 44416, 'counters/updates': 2776}
skipping logging after 44432 examples to avoid logging too frequently
skipping logging after 44448 examples to avoid logging too frequently
skipping logging after 44464 examples to avoid logging too frequently
train stats after 44480 examples: {'rewards_train/chosen': '-1.7013', 'rewards_train/rejected': '-10.265', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.5596', 'logps_train/rejected': '-255.36', 'logps_train/chosen': '-58.716', 'loss/train': '0.03458', 'examples_per_second': '4.71', 'grad_norm': '5.3125', 'counters/examples': 44480, 'counters/updates': 2780}
skipping logging after 44496 examples to avoid logging too frequently
skipping logging after 44512 examples to avoid logging too frequently
skipping logging after 44528 examples to avoid logging too frequently
train stats after 44544 examples: {'rewards_train/chosen': '-2.0967', 'rewards_train/rejected': '-9.3206', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.2239', 'logps_train/rejected': '-243.63', 'logps_train/chosen': '-61.466', 'loss/train': '0.13801', 'examples_per_second': '4.175', 'grad_norm': '11.812', 'counters/examples': 44544, 'counters/updates': 2784}
skipping logging after 44560 examples to avoid logging too frequently
skipping logging after 44576 examples to avoid logging too frequently
skipping logging after 44592 examples to avoid logging too frequently
train stats after 44608 examples: {'rewards_train/chosen': '-2.2588', 'rewards_train/rejected': '-9.8024', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.5424', 'logps_train/rejected': '-235.65', 'logps_train/chosen': '-60.02', 'loss/train': '0.086059', 'examples_per_second': '4.0699', 'grad_norm': '9.75', 'counters/examples': 44608, 'counters/updates': 2788}
skipping logging after 44624 examples to avoid logging too frequently
skipping logging after 44640 examples to avoid logging too frequently
skipping logging after 44656 examples to avoid logging too frequently
train stats after 44672 examples: {'rewards_train/chosen': '-2.4836', 'rewards_train/rejected': '-9.9939', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.5105', 'logps_train/rejected': '-215.24', 'logps_train/chosen': '-67.928', 'loss/train': '0.037154', 'examples_per_second': '5.0768', 'grad_norm': '5.7188', 'counters/examples': 44672, 'counters/updates': 2792}
skipping logging after 44688 examples to avoid logging too frequently
skipping logging after 44704 examples to avoid logging too frequently
skipping logging after 44720 examples to avoid logging too frequently
train stats after 44736 examples: {'rewards_train/chosen': '-2.5374', 'rewards_train/rejected': '-10.713', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.1815', 'logps_train/rejected': '-248.67', 'logps_train/chosen': '-66.852', 'loss/train': '0.040514', 'examples_per_second': '5.5907', 'grad_norm': '11', 'counters/examples': 44736, 'counters/updates': 2796}
skipping logging after 44752 examples to avoid logging too frequently
skipping logging after 44768 examples to avoid logging too frequently
skipping logging after 44784 examples to avoid logging too frequently
train stats after 44800 examples: {'rewards_train/chosen': '-2.3785', 'rewards_train/rejected': '-12.17', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.7904', 'logps_train/rejected': '-284.58', 'logps_train/chosen': '-58.814', 'loss/train': '0.08504', 'examples_per_second': '5.5158', 'grad_norm': '13.938', 'counters/examples': 44800, 'counters/updates': 2800}
skipping logging after 44816 examples to avoid logging too frequently
skipping logging after 44832 examples to avoid logging too frequently
skipping logging after 44848 examples to avoid logging too frequently
train stats after 44864 examples: {'rewards_train/chosen': '-2.532', 'rewards_train/rejected': '-12.703', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '10.173', 'logps_train/rejected': '-266.92', 'logps_train/chosen': '-64.936', 'loss/train': '0.045502', 'examples_per_second': '4.7759', 'grad_norm': '6.4062', 'counters/examples': 44864, 'counters/updates': 2804}
skipping logging after 44880 examples to avoid logging too frequently
skipping logging after 44896 examples to avoid logging too frequently
skipping logging after 44912 examples to avoid logging too frequently
train stats after 44928 examples: {'rewards_train/chosen': '-3.2755', 'rewards_train/rejected': '-11.625', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.349', 'logps_train/rejected': '-243.04', 'logps_train/chosen': '-68.84', 'loss/train': '0.0603', 'examples_per_second': '4.5907', 'grad_norm': '12', 'counters/examples': 44928, 'counters/updates': 2808}
skipping logging after 44944 examples to avoid logging too frequently
skipping logging after 44960 examples to avoid logging too frequently
skipping logging after 44976 examples to avoid logging too frequently
train stats after 44992 examples: {'rewards_train/chosen': '-2.8346', 'rewards_train/rejected': '-12.026', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.1853', 'logps_train/rejected': '-268.53', 'logps_train/chosen': '-74.545', 'loss/train': '0.031172', 'examples_per_second': '4.5094', 'grad_norm': '4.7188', 'counters/examples': 44992, 'counters/updates': 2812}
skipping logging after 45008 examples to avoid logging too frequently
skipping logging after 45024 examples to avoid logging too frequently
skipping logging after 45040 examples to avoid logging too frequently
train stats after 45056 examples: {'rewards_train/chosen': '-3.0603', 'rewards_train/rejected': '-11.217', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.1584', 'logps_train/rejected': '-240.66', 'logps_train/chosen': '-80.825', 'loss/train': '0.079078', 'examples_per_second': '5.4206', 'grad_norm': '12.312', 'counters/examples': 45056, 'counters/updates': 2816}
skipping logging after 45072 examples to avoid logging too frequently
skipping logging after 45088 examples to avoid logging too frequently
skipping logging after 45104 examples to avoid logging too frequently
train stats after 45120 examples: {'rewards_train/chosen': '-3.0902', 'rewards_train/rejected': '-12.188', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.0929', 'logps_train/rejected': '-276.75', 'logps_train/chosen': '-73.006', 'loss/train': '0.050954', 'examples_per_second': '4.1233', 'grad_norm': '9.625', 'counters/examples': 45120, 'counters/updates': 2820}
skipping logging after 45136 examples to avoid logging too frequently
skipping logging after 45152 examples to avoid logging too frequently
skipping logging after 45168 examples to avoid logging too frequently
train stats after 45184 examples: {'rewards_train/chosen': '-3.1564', 'rewards_train/rejected': '-13.176', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '10.014', 'logps_train/rejected': '-306.15', 'logps_train/chosen': '-73.533', 'loss/train': '0.11475', 'examples_per_second': '5.5042', 'grad_norm': '26', 'counters/examples': 45184, 'counters/updates': 2824}
skipping logging after 45200 examples to avoid logging too frequently
skipping logging after 45216 examples to avoid logging too frequently
skipping logging after 45232 examples to avoid logging too frequently
train stats after 45248 examples: {'rewards_train/chosen': '-2.8719', 'rewards_train/rejected': '-11.373', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.4986', 'logps_train/rejected': '-254.97', 'logps_train/chosen': '-73.521', 'loss/train': '0.076869', 'examples_per_second': '5.9849', 'grad_norm': '9.5', 'counters/examples': 45248, 'counters/updates': 2828}
skipping logging after 45264 examples to avoid logging too frequently
skipping logging after 45280 examples to avoid logging too frequently
skipping logging after 45296 examples to avoid logging too frequently
train stats after 45312 examples: {'rewards_train/chosen': '-2.5351', 'rewards_train/rejected': '-9.968', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.4331', 'logps_train/rejected': '-209.24', 'logps_train/chosen': '-54.356', 'loss/train': '0.069398', 'examples_per_second': '6.3536', 'grad_norm': '10.625', 'counters/examples': 45312, 'counters/updates': 2832}
skipping logging after 45328 examples to avoid logging too frequently
skipping logging after 45344 examples to avoid logging too frequently
skipping logging after 45360 examples to avoid logging too frequently
train stats after 45376 examples: {'rewards_train/chosen': '-2.8143', 'rewards_train/rejected': '-11.462', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.6466', 'logps_train/rejected': '-238.01', 'logps_train/chosen': '-64.496', 'loss/train': '0.067955', 'examples_per_second': '4.9275', 'grad_norm': '9.9375', 'counters/examples': 45376, 'counters/updates': 2836}
skipping logging after 45392 examples to avoid logging too frequently
skipping logging after 45408 examples to avoid logging too frequently
skipping logging after 45424 examples to avoid logging too frequently
train stats after 45440 examples: {'rewards_train/chosen': '-2.8185', 'rewards_train/rejected': '-11.275', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.4553', 'logps_train/rejected': '-239', 'logps_train/chosen': '-65.7', 'loss/train': '0.12145', 'examples_per_second': '5.0411', 'grad_norm': '20.875', 'counters/examples': 45440, 'counters/updates': 2840}
skipping logging after 45456 examples to avoid logging too frequently
skipping logging after 45472 examples to avoid logging too frequently
skipping logging after 45488 examples to avoid logging too frequently
train stats after 45504 examples: {'rewards_train/chosen': '-2.5627', 'rewards_train/rejected': '-11.392', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.8291', 'logps_train/rejected': '-257.43', 'logps_train/chosen': '-71.277', 'loss/train': '0.11109', 'examples_per_second': '5.4761', 'grad_norm': '22.625', 'counters/examples': 45504, 'counters/updates': 2844}
skipping logging after 45520 examples to avoid logging too frequently
skipping logging after 45536 examples to avoid logging too frequently
skipping logging after 45552 examples to avoid logging too frequently
train stats after 45568 examples: {'rewards_train/chosen': '-2.8569', 'rewards_train/rejected': '-10.435', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.5808', 'logps_train/rejected': '-255.91', 'logps_train/chosen': '-78.444', 'loss/train': '0.065885', 'examples_per_second': '5.0092', 'grad_norm': '14.188', 'counters/examples': 45568, 'counters/updates': 2848}
skipping logging after 45584 examples to avoid logging too frequently
skipping logging after 45600 examples to avoid logging too frequently
skipping logging after 45616 examples to avoid logging too frequently
train stats after 45632 examples: {'rewards_train/chosen': '-2.9377', 'rewards_train/rejected': '-11.297', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.3599', 'logps_train/rejected': '-254.08', 'logps_train/chosen': '-73.898', 'loss/train': '0.041237', 'examples_per_second': '5.9693', 'grad_norm': '6.375', 'counters/examples': 45632, 'counters/updates': 2852}
skipping logging after 45648 examples to avoid logging too frequently
skipping logging after 45664 examples to avoid logging too frequently
skipping logging after 45680 examples to avoid logging too frequently
train stats after 45696 examples: {'rewards_train/chosen': '-2.9325', 'rewards_train/rejected': '-10.833', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.9021', 'logps_train/rejected': '-224.38', 'logps_train/chosen': '-66.07', 'loss/train': '0.068899', 'examples_per_second': '5.4565', 'grad_norm': '8.875', 'counters/examples': 45696, 'counters/updates': 2856}
skipping logging after 45712 examples to avoid logging too frequently
skipping logging after 45728 examples to avoid logging too frequently
skipping logging after 45744 examples to avoid logging too frequently
train stats after 45760 examples: {'rewards_train/chosen': '-2.6925', 'rewards_train/rejected': '-9.3237', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.6289', 'logps_train/rejected': '-188.63', 'logps_train/chosen': '-76.979', 'loss/train': '0.16452', 'examples_per_second': '4.6695', 'grad_norm': '17.625', 'counters/examples': 45760, 'counters/updates': 2860}
skipping logging after 45776 examples to avoid logging too frequently
skipping logging after 45792 examples to avoid logging too frequently
skipping logging after 45808 examples to avoid logging too frequently
train stats after 45824 examples: {'rewards_train/chosen': '-2.4758', 'rewards_train/rejected': '-11.04', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.5654', 'logps_train/rejected': '-253.18', 'logps_train/chosen': '-64.401', 'loss/train': '0.084527', 'examples_per_second': '4.905', 'grad_norm': '14.625', 'counters/examples': 45824, 'counters/updates': 2864}
skipping logging after 45840 examples to avoid logging too frequently
skipping logging after 45856 examples to avoid logging too frequently
skipping logging after 45872 examples to avoid logging too frequently
train stats after 45888 examples: {'rewards_train/chosen': '-2.3165', 'rewards_train/rejected': '-10.411', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.0938', 'logps_train/rejected': '-232.55', 'logps_train/chosen': '-66.701', 'loss/train': '0.05472', 'examples_per_second': '6.823', 'grad_norm': '7.8125', 'counters/examples': 45888, 'counters/updates': 2868}
skipping logging after 45904 examples to avoid logging too frequently
skipping logging after 45920 examples to avoid logging too frequently
skipping logging after 45936 examples to avoid logging too frequently
train stats after 45952 examples: {'rewards_train/chosen': '-2.7329', 'rewards_train/rejected': '-12', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.2688', 'logps_train/rejected': '-284.54', 'logps_train/chosen': '-67.176', 'loss/train': '0.020858', 'examples_per_second': '5.1562', 'grad_norm': '3.4531', 'counters/examples': 45952, 'counters/updates': 2872}
skipping logging after 45968 examples to avoid logging too frequently
skipping logging after 45984 examples to avoid logging too frequently
skipping logging after 46000 examples to avoid logging too frequently
train stats after 46016 examples: {'rewards_train/chosen': '-2.5572', 'rewards_train/rejected': '-10.853', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.2981', 'logps_train/rejected': '-244.81', 'logps_train/chosen': '-63.965', 'loss/train': '0.02384', 'examples_per_second': '4.4714', 'grad_norm': '4.25', 'counters/examples': 46016, 'counters/updates': 2876}
skipping logging after 46032 examples to avoid logging too frequently
skipping logging after 46048 examples to avoid logging too frequently
skipping logging after 46064 examples to avoid logging too frequently
train stats after 46080 examples: {'rewards_train/chosen': '-2.1748', 'rewards_train/rejected': '-10.017', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.8431', 'logps_train/rejected': '-222.5', 'logps_train/chosen': '-63.17', 'loss/train': '0.055598', 'examples_per_second': '5.7488', 'grad_norm': '6.9062', 'counters/examples': 46080, 'counters/updates': 2880}
skipping logging after 46096 examples to avoid logging too frequently
skipping logging after 46112 examples to avoid logging too frequently
skipping logging after 46128 examples to avoid logging too frequently
train stats after 46144 examples: {'rewards_train/chosen': '-2.7912', 'rewards_train/rejected': '-11.482', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.6923', 'logps_train/rejected': '-250.42', 'logps_train/chosen': '-60.059', 'loss/train': '0.078853', 'examples_per_second': '5.3015', 'grad_norm': '14.875', 'counters/examples': 46144, 'counters/updates': 2884}
skipping logging after 46160 examples to avoid logging too frequently
skipping logging after 46176 examples to avoid logging too frequently
skipping logging after 46192 examples to avoid logging too frequently
train stats after 46208 examples: {'rewards_train/chosen': '-2.6983', 'rewards_train/rejected': '-10.955', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.2578', 'logps_train/rejected': '-236.2', 'logps_train/chosen': '-61.637', 'loss/train': '0.093456', 'examples_per_second': '5.8712', 'grad_norm': '13.688', 'counters/examples': 46208, 'counters/updates': 2888}
skipping logging after 46224 examples to avoid logging too frequently
skipping logging after 46240 examples to avoid logging too frequently
skipping logging after 46256 examples to avoid logging too frequently
train stats after 46272 examples: {'rewards_train/chosen': '-2.4978', 'rewards_train/rejected': '-10.893', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.3984', 'logps_train/rejected': '-263.33', 'logps_train/chosen': '-72.678', 'loss/train': '0.050458', 'examples_per_second': '5.0335', 'grad_norm': '8.4375', 'counters/examples': 46272, 'counters/updates': 2892}
skipping logging after 46288 examples to avoid logging too frequently
skipping logging after 46304 examples to avoid logging too frequently
skipping logging after 46320 examples to avoid logging too frequently
train stats after 46336 examples: {'rewards_train/chosen': '-2.2093', 'rewards_train/rejected': '-10.846', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.6362', 'logps_train/rejected': '-280.12', 'logps_train/chosen': '-71.566', 'loss/train': '0.024924', 'examples_per_second': '6.3626', 'grad_norm': '3.4688', 'counters/examples': 46336, 'counters/updates': 2896}
skipping logging after 46352 examples to avoid logging too frequently
skipping logging after 46368 examples to avoid logging too frequently
skipping logging after 46384 examples to avoid logging too frequently
train stats after 46400 examples: {'rewards_train/chosen': '-2.8644', 'rewards_train/rejected': '-11.266', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.4041', 'logps_train/rejected': '-267.9', 'logps_train/chosen': '-77.986', 'loss/train': '0.040015', 'examples_per_second': '5.7745', 'grad_norm': '7.625', 'counters/examples': 46400, 'counters/updates': 2900}
skipping logging after 46416 examples to avoid logging too frequently
skipping logging after 46432 examples to avoid logging too frequently
skipping logging after 46448 examples to avoid logging too frequently
train stats after 46464 examples: {'rewards_train/chosen': '-2.311', 'rewards_train/rejected': '-11.063', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.7526', 'logps_train/rejected': '-276.74', 'logps_train/chosen': '-67.279', 'loss/train': '0.063874', 'examples_per_second': '5.1568', 'grad_norm': '9.8125', 'counters/examples': 46464, 'counters/updates': 2904}
skipping logging after 46480 examples to avoid logging too frequently
skipping logging after 46496 examples to avoid logging too frequently
skipping logging after 46512 examples to avoid logging too frequently
train stats after 46528 examples: {'rewards_train/chosen': '-2.3652', 'rewards_train/rejected': '-9.926', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.5586', 'logps_train/rejected': '-225.38', 'logps_train/chosen': '-66.165', 'loss/train': '0.080438', 'examples_per_second': '5.842', 'grad_norm': '11.25', 'counters/examples': 46528, 'counters/updates': 2908}
skipping logging after 46544 examples to avoid logging too frequently
skipping logging after 46560 examples to avoid logging too frequently
skipping logging after 46576 examples to avoid logging too frequently
train stats after 46592 examples: {'rewards_train/chosen': '-2.3605', 'rewards_train/rejected': '-9.3499', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.9894', 'logps_train/rejected': '-219.5', 'logps_train/chosen': '-64.676', 'loss/train': '0.090547', 'examples_per_second': '4.8797', 'grad_norm': '12.188', 'counters/examples': 46592, 'counters/updates': 2912}
skipping logging after 46608 examples to avoid logging too frequently
skipping logging after 46624 examples to avoid logging too frequently
skipping logging after 46640 examples to avoid logging too frequently
train stats after 46656 examples: {'rewards_train/chosen': '-2.5451', 'rewards_train/rejected': '-10.714', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1654', 'logps_train/rejected': '-265.71', 'logps_train/chosen': '-62.619', 'loss/train': '0.055453', 'examples_per_second': '4.994', 'grad_norm': '7.875', 'counters/examples': 46656, 'counters/updates': 2916}
skipping logging after 46672 examples to avoid logging too frequently
skipping logging after 46688 examples to avoid logging too frequently
skipping logging after 46704 examples to avoid logging too frequently
train stats after 46720 examples: {'rewards_train/chosen': '-2.2392', 'rewards_train/rejected': '-10.173', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.9313', 'logps_train/rejected': '-262.42', 'logps_train/chosen': '-63.125', 'loss/train': '0.082822', 'examples_per_second': '3.9669', 'grad_norm': '18.375', 'counters/examples': 46720, 'counters/updates': 2920}
skipping logging after 46736 examples to avoid logging too frequently
skipping logging after 46752 examples to avoid logging too frequently
skipping logging after 46768 examples to avoid logging too frequently
train stats after 46784 examples: {'rewards_train/chosen': '-2.8521', 'rewards_train/rejected': '-9.8894', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.0406', 'logps_train/rejected': '-219.61', 'logps_train/chosen': '-70.175', 'loss/train': '0.15846', 'examples_per_second': '4.29', 'grad_norm': '16', 'counters/examples': 46784, 'counters/updates': 2924}
skipping logging after 46800 examples to avoid logging too frequently
skipping logging after 46816 examples to avoid logging too frequently
skipping logging after 46832 examples to avoid logging too frequently
train stats after 46848 examples: {'rewards_train/chosen': '-1.8614', 'rewards_train/rejected': '-9.8889', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.0291', 'logps_train/rejected': '-271.67', 'logps_train/chosen': '-63.896', 'loss/train': '0.041758', 'examples_per_second': '5.2061', 'grad_norm': '7.5938', 'counters/examples': 46848, 'counters/updates': 2928}
skipping logging after 46864 examples to avoid logging too frequently
skipping logging after 46880 examples to avoid logging too frequently
skipping logging after 46896 examples to avoid logging too frequently
train stats after 46912 examples: {'rewards_train/chosen': '-2.5095', 'rewards_train/rejected': '-9.1127', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '6.6042', 'logps_train/rejected': '-227.38', 'logps_train/chosen': '-61.815', 'loss/train': '0.13348', 'examples_per_second': '5.2347', 'grad_norm': '11.5', 'counters/examples': 46912, 'counters/updates': 2932}
skipping logging after 46928 examples to avoid logging too frequently
skipping logging after 46944 examples to avoid logging too frequently
skipping logging after 46960 examples to avoid logging too frequently
train stats after 46976 examples: {'rewards_train/chosen': '-2.0683', 'rewards_train/rejected': '-9.6853', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.6171', 'logps_train/rejected': '-223.98', 'logps_train/chosen': '-57.519', 'loss/train': '0.064056', 'examples_per_second': '5.7042', 'grad_norm': '9.5', 'counters/examples': 46976, 'counters/updates': 2936}
skipping logging after 46992 examples to avoid logging too frequently
skipping logging after 47008 examples to avoid logging too frequently
skipping logging after 47024 examples to avoid logging too frequently
train stats after 47040 examples: {'rewards_train/chosen': '-2.1195', 'rewards_train/rejected': '-10.504', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.3862', 'logps_train/rejected': '-240.38', 'logps_train/chosen': '-66.848', 'loss/train': '0.041235', 'examples_per_second': '5.5018', 'grad_norm': '8.1875', 'counters/examples': 47040, 'counters/updates': 2940}
skipping logging after 47056 examples to avoid logging too frequently
skipping logging after 47072 examples to avoid logging too frequently
skipping logging after 47088 examples to avoid logging too frequently
train stats after 47104 examples: {'rewards_train/chosen': '-2.5782', 'rewards_train/rejected': '-10.068', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.4908', 'logps_train/rejected': '-249.17', 'logps_train/chosen': '-70.441', 'loss/train': '0.071831', 'examples_per_second': '5.17', 'grad_norm': '11.312', 'counters/examples': 47104, 'counters/updates': 2944}
skipping logging after 47120 examples to avoid logging too frequently
skipping logging after 47136 examples to avoid logging too frequently
skipping logging after 47152 examples to avoid logging too frequently
train stats after 47168 examples: {'rewards_train/chosen': '-2.5326', 'rewards_train/rejected': '-11.477', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.9424', 'logps_train/rejected': '-278.45', 'logps_train/chosen': '-72.229', 'loss/train': '0.052827', 'examples_per_second': '4.2882', 'grad_norm': '14.125', 'counters/examples': 47168, 'counters/updates': 2948}
skipping logging after 47184 examples to avoid logging too frequently
skipping logging after 47200 examples to avoid logging too frequently
skipping logging after 47216 examples to avoid logging too frequently
train stats after 47232 examples: {'rewards_train/chosen': '-2.3503', 'rewards_train/rejected': '-10.669', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.3208', 'logps_train/rejected': '-238.1', 'logps_train/chosen': '-71.752', 'loss/train': '0.076', 'examples_per_second': '4.9171', 'grad_norm': '12.125', 'counters/examples': 47232, 'counters/updates': 2952}
skipping logging after 47248 examples to avoid logging too frequently
skipping logging after 47264 examples to avoid logging too frequently
skipping logging after 47280 examples to avoid logging too frequently
train stats after 47296 examples: {'rewards_train/chosen': '-2.296', 'rewards_train/rejected': '-11.068', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.7732', 'logps_train/rejected': '-249.78', 'logps_train/chosen': '-67.945', 'loss/train': '0.039433', 'examples_per_second': '5.6876', 'grad_norm': '6.25', 'counters/examples': 47296, 'counters/updates': 2956}
skipping logging after 47312 examples to avoid logging too frequently
skipping logging after 47328 examples to avoid logging too frequently
skipping logging after 47344 examples to avoid logging too frequently
train stats after 47360 examples: {'rewards_train/chosen': '-2.8908', 'rewards_train/rejected': '-11.782', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.8909', 'logps_train/rejected': '-277.97', 'logps_train/chosen': '-77.705', 'loss/train': '0.11839', 'examples_per_second': '4.546', 'grad_norm': '17.75', 'counters/examples': 47360, 'counters/updates': 2960}
skipping logging after 47376 examples to avoid logging too frequently
skipping logging after 47392 examples to avoid logging too frequently
skipping logging after 47408 examples to avoid logging too frequently
train stats after 47424 examples: {'rewards_train/chosen': '-3.148', 'rewards_train/rejected': '-10.38', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.2346', 'logps_train/rejected': '-230.97', 'logps_train/chosen': '-73.039', 'loss/train': '0.096423', 'examples_per_second': '4.7785', 'grad_norm': '12.812', 'counters/examples': 47424, 'counters/updates': 2964}
skipping logging after 47440 examples to avoid logging too frequently
skipping logging after 47456 examples to avoid logging too frequently
skipping logging after 47472 examples to avoid logging too frequently
train stats after 47488 examples: {'rewards_train/chosen': '-2.6933', 'rewards_train/rejected': '-11.576', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.8807', 'logps_train/rejected': '-275.78', 'logps_train/chosen': '-63.635', 'loss/train': '0.062496', 'examples_per_second': '4.7932', 'grad_norm': '12.75', 'counters/examples': 47488, 'counters/updates': 2968}
skipping logging after 47504 examples to avoid logging too frequently
skipping logging after 47520 examples to avoid logging too frequently
skipping logging after 47536 examples to avoid logging too frequently
train stats after 47552 examples: {'rewards_train/chosen': '-3.1392', 'rewards_train/rejected': '-13.01', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.871', 'logps_train/rejected': '-276.08', 'logps_train/chosen': '-67.295', 'loss/train': '0.0839', 'examples_per_second': '5.6314', 'grad_norm': '15.438', 'counters/examples': 47552, 'counters/updates': 2972}
skipping logging after 47568 examples to avoid logging too frequently
skipping logging after 47584 examples to avoid logging too frequently
skipping logging after 47600 examples to avoid logging too frequently
train stats after 47616 examples: {'rewards_train/chosen': '-3.2906', 'rewards_train/rejected': '-10.244', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.9543', 'logps_train/rejected': '-212.99', 'logps_train/chosen': '-73.302', 'loss/train': '0.1062', 'examples_per_second': '5.4625', 'grad_norm': '15.5', 'counters/examples': 47616, 'counters/updates': 2976}
skipping logging after 47632 examples to avoid logging too frequently
skipping logging after 47648 examples to avoid logging too frequently
skipping logging after 47664 examples to avoid logging too frequently
train stats after 47680 examples: {'rewards_train/chosen': '-2.3235', 'rewards_train/rejected': '-10.415', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.0881', 'logps_train/rejected': '-228.08', 'logps_train/chosen': '-63.482', 'loss/train': '0.06375', 'examples_per_second': '5.4514', 'grad_norm': '15.125', 'counters/examples': 47680, 'counters/updates': 2980}
skipping logging after 47696 examples to avoid logging too frequently
skipping logging after 47712 examples to avoid logging too frequently
skipping logging after 47728 examples to avoid logging too frequently
train stats after 47744 examples: {'rewards_train/chosen': '-2.4634', 'rewards_train/rejected': '-9.8952', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.4335', 'logps_train/rejected': '-222.77', 'logps_train/chosen': '-65.681', 'loss/train': '0.05787', 'examples_per_second': '5.4187', 'grad_norm': '7.375', 'counters/examples': 47744, 'counters/updates': 2984}
skipping logging after 47760 examples to avoid logging too frequently
skipping logging after 47776 examples to avoid logging too frequently
skipping logging after 47792 examples to avoid logging too frequently
train stats after 47808 examples: {'rewards_train/chosen': '-2.6271', 'rewards_train/rejected': '-11.155', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.5261', 'logps_train/rejected': '-284.18', 'logps_train/chosen': '-65.49', 'loss/train': '0.16352', 'examples_per_second': '4.4208', 'grad_norm': '21.75', 'counters/examples': 47808, 'counters/updates': 2988}
skipping logging after 47824 examples to avoid logging too frequently
skipping logging after 47840 examples to avoid logging too frequently
skipping logging after 47856 examples to avoid logging too frequently
train stats after 47872 examples: {'rewards_train/chosen': '-2.1896', 'rewards_train/rejected': '-11.538', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '9.3512', 'logps_train/rejected': '-256.62', 'logps_train/chosen': '-58.491', 'loss/train': '0.054784', 'examples_per_second': '4.3224', 'grad_norm': '9.3125', 'counters/examples': 47872, 'counters/updates': 2992}
skipping logging after 47888 examples to avoid logging too frequently
skipping logging after 47904 examples to avoid logging too frequently
skipping logging after 47920 examples to avoid logging too frequently
train stats after 47936 examples: {'rewards_train/chosen': '-2.8965', 'rewards_train/rejected': '-11.909', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '9.0116', 'logps_train/rejected': '-273.2', 'logps_train/chosen': '-68.035', 'loss/train': '0.080278', 'examples_per_second': '4.8729', 'grad_norm': '11.5', 'counters/examples': 47936, 'counters/updates': 2996}
skipping logging after 47952 examples to avoid logging too frequently
skipping logging after 47968 examples to avoid logging too frequently
skipping logging after 47984 examples to avoid logging too frequently
train stats after 48000 examples: {'rewards_train/chosen': '-2.4225', 'rewards_train/rejected': '-10.635', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.2131', 'logps_train/rejected': '-243.41', 'logps_train/chosen': '-61.234', 'loss/train': '0.080943', 'examples_per_second': '5.2184', 'grad_norm': '7.1875', 'counters/examples': 48000, 'counters/updates': 3000}
Running evaluation after 48000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<01:00,  1.96s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:00,  2.02s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:53,  1.85s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.86s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.65s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:36,  1.57s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.57s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:30,  1.50s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.46s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:26,  1.45s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:22,  1.31s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:20,  1.25s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:20,  1.34s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.35s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:14,  1.27s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.30s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.27s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:37<00:07,  1.31s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.49s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.42s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.63s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.43s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.42s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.41s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.44s/it]
eval after 48000: {'rewards_eval/chosen': '-10.896', 'rewards_eval/rejected': '-11.51', 'rewards_eval/accuracies': '0.54102', 'rewards_eval/margins': '0.6151', 'logps_eval/rejected': '-262.78', 'logps_eval/chosen': '-253.87', 'loss/eval': '1.9917'}
skipping logging after 48016 examples to avoid logging too frequently
skipping logging after 48032 examples to avoid logging too frequently
skipping logging after 48048 examples to avoid logging too frequently
train stats after 48064 examples: {'rewards_train/chosen': '-2.9531', 'rewards_train/rejected': '-11.067', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '8.1163', 'logps_train/rejected': '-240.75', 'logps_train/chosen': '-64.156', 'loss/train': '0.10238', 'examples_per_second': '4.1605', 'grad_norm': '15.75', 'counters/examples': 48064, 'counters/updates': 3004}
skipping logging after 48080 examples to avoid logging too frequently
skipping logging after 48096 examples to avoid logging too frequently
skipping logging after 48112 examples to avoid logging too frequently
train stats after 48128 examples: {'rewards_train/chosen': '-3.3229', 'rewards_train/rejected': '-12.353', 'rewards_train/accuracies': '0.89062', 'rewards_train/margins': '9.0249', 'logps_train/rejected': '-280.52', 'logps_train/chosen': '-73.084', 'loss/train': '0.086308', 'examples_per_second': '5.661', 'grad_norm': '17.125', 'counters/examples': 48128, 'counters/updates': 3008}
skipping logging after 48144 examples to avoid logging too frequently
skipping logging after 48160 examples to avoid logging too frequently
skipping logging after 48176 examples to avoid logging too frequently
train stats after 48192 examples: {'rewards_train/chosen': '-2.8763', 'rewards_train/rejected': '-12.254', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.3787', 'logps_train/rejected': '-290.87', 'logps_train/chosen': '-78.904', 'loss/train': '0.027174', 'examples_per_second': '6.0788', 'grad_norm': '5.6875', 'counters/examples': 48192, 'counters/updates': 3012}
skipping logging after 48208 examples to avoid logging too frequently
skipping logging after 48224 examples to avoid logging too frequently
skipping logging after 48240 examples to avoid logging too frequently
train stats after 48256 examples: {'rewards_train/chosen': '-2.8692', 'rewards_train/rejected': '-12.101', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.2305', 'logps_train/rejected': '-303.63', 'logps_train/chosen': '-79.887', 'loss/train': '0.11865', 'examples_per_second': '5.1413', 'grad_norm': '16', 'counters/examples': 48256, 'counters/updates': 3016}
skipping logging after 48272 examples to avoid logging too frequently
skipping logging after 48288 examples to avoid logging too frequently
skipping logging after 48304 examples to avoid logging too frequently
train stats after 48320 examples: {'rewards_train/chosen': '-2.7975', 'rewards_train/rejected': '-11.396', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.5979', 'logps_train/rejected': '-257.64', 'logps_train/chosen': '-61.621', 'loss/train': '0.034529', 'examples_per_second': '4.3381', 'grad_norm': '7.0938', 'counters/examples': 48320, 'counters/updates': 3020}
skipping logging after 48336 examples to avoid logging too frequently
skipping logging after 48352 examples to avoid logging too frequently
skipping logging after 48368 examples to avoid logging too frequently
train stats after 48384 examples: {'rewards_train/chosen': '-2.8914', 'rewards_train/rejected': '-10.81', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.9182', 'logps_train/rejected': '-230.85', 'logps_train/chosen': '-66.692', 'loss/train': '0.045973', 'examples_per_second': '5.5677', 'grad_norm': '5.9688', 'counters/examples': 48384, 'counters/updates': 3024}
skipping logging after 48400 examples to avoid logging too frequently
skipping logging after 48416 examples to avoid logging too frequently
skipping logging after 48432 examples to avoid logging too frequently
train stats after 48448 examples: {'rewards_train/chosen': '-2.6131', 'rewards_train/rejected': '-10.953', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.3408', 'logps_train/rejected': '-258.96', 'logps_train/chosen': '-62.668', 'loss/train': '0.14648', 'examples_per_second': '4.4884', 'grad_norm': '8', 'counters/examples': 48448, 'counters/updates': 3028}
skipping logging after 48464 examples to avoid logging too frequently
skipping logging after 48480 examples to avoid logging too frequently
skipping logging after 48496 examples to avoid logging too frequently
train stats after 48512 examples: {'rewards_train/chosen': '-2.586', 'rewards_train/rejected': '-10.449', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.865', 'logps_train/rejected': '-232.96', 'logps_train/chosen': '-67.748', 'loss/train': '0.029571', 'examples_per_second': '5.2074', 'grad_norm': '3.3906', 'counters/examples': 48512, 'counters/updates': 3032}
skipping logging after 48528 examples to avoid logging too frequently
skipping logging after 48544 examples to avoid logging too frequently
skipping logging after 48560 examples to avoid logging too frequently
train stats after 48576 examples: {'rewards_train/chosen': '-2.7213', 'rewards_train/rejected': '-10.971', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.2478', 'logps_train/rejected': '-249.18', 'logps_train/chosen': '-67.519', 'loss/train': '0.042408', 'examples_per_second': '4.7487', 'grad_norm': '4.625', 'counters/examples': 48576, 'counters/updates': 3036}
skipping logging after 48592 examples to avoid logging too frequently
skipping logging after 48608 examples to avoid logging too frequently
skipping logging after 48624 examples to avoid logging too frequently
train stats after 48640 examples: {'rewards_train/chosen': '-2.7504', 'rewards_train/rejected': '-11.259', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.5104', 'logps_train/rejected': '-251.45', 'logps_train/chosen': '-64.607', 'loss/train': '0.11614', 'examples_per_second': '5.2932', 'grad_norm': '14.812', 'counters/examples': 48640, 'counters/updates': 3040}
skipping logging after 48656 examples to avoid logging too frequently
skipping logging after 48672 examples to avoid logging too frequently
skipping logging after 48688 examples to avoid logging too frequently
train stats after 48704 examples: {'rewards_train/chosen': '-2.6679', 'rewards_train/rejected': '-10.636', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.9707', 'logps_train/rejected': '-280.33', 'logps_train/chosen': '-73.916', 'loss/train': '0.10573', 'examples_per_second': '5.3194', 'grad_norm': '17.625', 'counters/examples': 48704, 'counters/updates': 3044}
skipping logging after 48720 examples to avoid logging too frequently
skipping logging after 48736 examples to avoid logging too frequently
skipping logging after 48752 examples to avoid logging too frequently
train stats after 48768 examples: {'rewards_train/chosen': '-2.5516', 'rewards_train/rejected': '-9.3845', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.8311', 'logps_train/rejected': '-206.5', 'logps_train/chosen': '-60.32', 'loss/train': '0.056014', 'examples_per_second': '5.2022', 'grad_norm': '7.0938', 'counters/examples': 48768, 'counters/updates': 3048}
skipping logging after 48784 examples to avoid logging too frequently
skipping logging after 48800 examples to avoid logging too frequently
skipping logging after 48816 examples to avoid logging too frequently
train stats after 48832 examples: {'rewards_train/chosen': '-2.5203', 'rewards_train/rejected': '-11.402', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.8796', 'logps_train/rejected': '-251.93', 'logps_train/chosen': '-61.75', 'loss/train': '0.060412', 'examples_per_second': '5.4769', 'grad_norm': '9.1875', 'counters/examples': 48832, 'counters/updates': 3052}
skipping logging after 48848 examples to avoid logging too frequently
skipping logging after 48864 examples to avoid logging too frequently
skipping logging after 48880 examples to avoid logging too frequently
train stats after 48896 examples: {'rewards_train/chosen': '-2.7386', 'rewards_train/rejected': '-11.889', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.1484', 'logps_train/rejected': '-291.13', 'logps_train/chosen': '-76.017', 'loss/train': '0.036505', 'examples_per_second': '4.905', 'grad_norm': '6.4688', 'counters/examples': 48896, 'counters/updates': 3056}
skipping logging after 48912 examples to avoid logging too frequently
skipping logging after 48928 examples to avoid logging too frequently
skipping logging after 48944 examples to avoid logging too frequently
train stats after 48960 examples: {'rewards_train/chosen': '-2.769', 'rewards_train/rejected': '-11.886', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.114', 'logps_train/rejected': '-256.64', 'logps_train/chosen': '-72.056', 'loss/train': '0.049235', 'examples_per_second': '6.0956', 'grad_norm': '12.688', 'counters/examples': 48960, 'counters/updates': 3060}
skipping logging after 48976 examples to avoid logging too frequently
skipping logging after 48992 examples to avoid logging too frequently
skipping logging after 49008 examples to avoid logging too frequently
train stats after 49024 examples: {'rewards_train/chosen': '-2.8831', 'rewards_train/rejected': '-12.705', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.8224', 'logps_train/rejected': '-261.99', 'logps_train/chosen': '-61.852', 'loss/train': '0.078902', 'examples_per_second': '5.7487', 'grad_norm': '9.3125', 'counters/examples': 49024, 'counters/updates': 3064}
skipping logging after 49040 examples to avoid logging too frequently
skipping logging after 49056 examples to avoid logging too frequently
skipping logging after 49072 examples to avoid logging too frequently
train stats after 49088 examples: {'rewards_train/chosen': '-3.2765', 'rewards_train/rejected': '-12.958', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.6753', 'logps_train/rejected': '-269.97', 'logps_train/chosen': '-72.217', 'loss/train': '0.021446', 'examples_per_second': '5.7097', 'grad_norm': '4.6562', 'counters/examples': 49088, 'counters/updates': 3068}
skipping logging after 49104 examples to avoid logging too frequently
skipping logging after 49120 examples to avoid logging too frequently
skipping logging after 49136 examples to avoid logging too frequently
train stats after 49152 examples: {'rewards_train/chosen': '-2.9021', 'rewards_train/rejected': '-13.357', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '10.452', 'logps_train/rejected': '-307.8', 'logps_train/chosen': '-74.528', 'loss/train': '0.07759', 'examples_per_second': '4.8293', 'grad_norm': '15.562', 'counters/examples': 49152, 'counters/updates': 3072}
skipping logging after 49168 examples to avoid logging too frequently
skipping logging after 49184 examples to avoid logging too frequently
skipping logging after 49200 examples to avoid logging too frequently
train stats after 49216 examples: {'rewards_train/chosen': '-3.3869', 'rewards_train/rejected': '-12.267', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.8782', 'logps_train/rejected': '-280.2', 'logps_train/chosen': '-76.611', 'loss/train': '0.067475', 'examples_per_second': '5.4492', 'grad_norm': '21.75', 'counters/examples': 49216, 'counters/updates': 3076}
skipping logging after 49232 examples to avoid logging too frequently
skipping logging after 49248 examples to avoid logging too frequently
skipping logging after 49264 examples to avoid logging too frequently
train stats after 49280 examples: {'rewards_train/chosen': '-2.7337', 'rewards_train/rejected': '-11.02', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.2853', 'logps_train/rejected': '-240.14', 'logps_train/chosen': '-61.763', 'loss/train': '0.069932', 'examples_per_second': '6.0908', 'grad_norm': '15.75', 'counters/examples': 49280, 'counters/updates': 3080}
skipping logging after 49296 examples to avoid logging too frequently
skipping logging after 49312 examples to avoid logging too frequently
skipping logging after 49328 examples to avoid logging too frequently
train stats after 49344 examples: {'rewards_train/chosen': '-3.0348', 'rewards_train/rejected': '-12.029', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.9942', 'logps_train/rejected': '-262.79', 'logps_train/chosen': '-71.637', 'loss/train': '0.085671', 'examples_per_second': '4.6348', 'grad_norm': '7.9062', 'counters/examples': 49344, 'counters/updates': 3084}
skipping logging after 49360 examples to avoid logging too frequently
skipping logging after 49376 examples to avoid logging too frequently
skipping logging after 49392 examples to avoid logging too frequently
train stats after 49408 examples: {'rewards_train/chosen': '-3.3051', 'rewards_train/rejected': '-12.427', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '9.1228', 'logps_train/rejected': '-251.65', 'logps_train/chosen': '-64.121', 'loss/train': '0.099942', 'examples_per_second': '4.2595', 'grad_norm': '10.25', 'counters/examples': 49408, 'counters/updates': 3088}
skipping logging after 49424 examples to avoid logging too frequently
skipping logging after 49440 examples to avoid logging too frequently
skipping logging after 49456 examples to avoid logging too frequently
train stats after 49472 examples: {'rewards_train/chosen': '-3.0958', 'rewards_train/rejected': '-12.342', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.2446', 'logps_train/rejected': '-259.59', 'logps_train/chosen': '-75.666', 'loss/train': '0.051731', 'examples_per_second': '5.0846', 'grad_norm': '7.4375', 'counters/examples': 49472, 'counters/updates': 3092}
skipping logging after 49488 examples to avoid logging too frequently
skipping logging after 49504 examples to avoid logging too frequently
skipping logging after 49520 examples to avoid logging too frequently
train stats after 49536 examples: {'rewards_train/chosen': '-3.0232', 'rewards_train/rejected': '-10.616', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.5969', 'logps_train/rejected': '-214.6', 'logps_train/chosen': '-63.463', 'loss/train': '0.067557', 'examples_per_second': '4.6774', 'grad_norm': '5.9688', 'counters/examples': 49536, 'counters/updates': 3096}
skipping logging after 49552 examples to avoid logging too frequently
skipping logging after 49568 examples to avoid logging too frequently
skipping logging after 49584 examples to avoid logging too frequently
train stats after 49600 examples: {'rewards_train/chosen': '-2.9278', 'rewards_train/rejected': '-10.835', 'rewards_train/accuracies': '0.89062', 'rewards_train/margins': '7.9041', 'logps_train/rejected': '-246.3', 'logps_train/chosen': '-65.729', 'loss/train': '0.11079', 'examples_per_second': '4.3115', 'grad_norm': '10.375', 'counters/examples': 49600, 'counters/updates': 3100}
skipping logging after 49616 examples to avoid logging too frequently
skipping logging after 49632 examples to avoid logging too frequently
skipping logging after 49648 examples to avoid logging too frequently
train stats after 49664 examples: {'rewards_train/chosen': '-2.8891', 'rewards_train/rejected': '-10.579', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.6891', 'logps_train/rejected': '-223.66', 'logps_train/chosen': '-69.021', 'loss/train': '0.083841', 'examples_per_second': '5.4332', 'grad_norm': '9.75', 'counters/examples': 49664, 'counters/updates': 3104}
skipping logging after 49680 examples to avoid logging too frequently
skipping logging after 49696 examples to avoid logging too frequently
skipping logging after 49712 examples to avoid logging too frequently
train stats after 49728 examples: {'rewards_train/chosen': '-3.1964', 'rewards_train/rejected': '-11.523', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.3254', 'logps_train/rejected': '-246.14', 'logps_train/chosen': '-69.624', 'loss/train': '0.071558', 'examples_per_second': '5.4151', 'grad_norm': '12.438', 'counters/examples': 49728, 'counters/updates': 3108}
skipping logging after 49744 examples to avoid logging too frequently
skipping logging after 49760 examples to avoid logging too frequently
skipping logging after 49776 examples to avoid logging too frequently
train stats after 49792 examples: {'rewards_train/chosen': '-3.5935', 'rewards_train/rejected': '-14.097', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '10.503', 'logps_train/rejected': '-310.86', 'logps_train/chosen': '-72.141', 'loss/train': '0.017885', 'examples_per_second': '4.9568', 'grad_norm': '2.7188', 'counters/examples': 49792, 'counters/updates': 3112}
skipping logging after 49808 examples to avoid logging too frequently
skipping logging after 49824 examples to avoid logging too frequently
skipping logging after 49840 examples to avoid logging too frequently
train stats after 49856 examples: {'rewards_train/chosen': '-2.9813', 'rewards_train/rejected': '-11.615', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.6311', 'logps_train/rejected': '-226.73', 'logps_train/chosen': '-67.763', 'loss/train': '0.077775', 'examples_per_second': '5.8335', 'grad_norm': '15.062', 'counters/examples': 49856, 'counters/updates': 3116}
skipping logging after 49872 examples to avoid logging too frequently
skipping logging after 49888 examples to avoid logging too frequently
skipping logging after 49904 examples to avoid logging too frequently
train stats after 49920 examples: {'rewards_train/chosen': '-2.2748', 'rewards_train/rejected': '-11.03', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.759', 'logps_train/rejected': '-264.44', 'logps_train/chosen': '-66.629', 'loss/train': '0.085434', 'examples_per_second': '5.214', 'grad_norm': '12.438', 'counters/examples': 49920, 'counters/updates': 3120}
skipping logging after 49936 examples to avoid logging too frequently
skipping logging after 49952 examples to avoid logging too frequently
skipping logging after 49968 examples to avoid logging too frequently
train stats after 49984 examples: {'rewards_train/chosen': '-2.7904', 'rewards_train/rejected': '-10.091', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '7.3008', 'logps_train/rejected': '-230.28', 'logps_train/chosen': '-61.945', 'loss/train': '0.16051', 'examples_per_second': '4.9881', 'grad_norm': '16.375', 'counters/examples': 49984, 'counters/updates': 3124}
skipping logging after 50000 examples to avoid logging too frequently
skipping logging after 50016 examples to avoid logging too frequently
skipping logging after 50032 examples to avoid logging too frequently
train stats after 50048 examples: {'rewards_train/chosen': '-2.5232', 'rewards_train/rejected': '-10.124', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.603', 'logps_train/rejected': '-236.27', 'logps_train/chosen': '-68.186', 'loss/train': '0.12317', 'examples_per_second': '5.1355', 'grad_norm': '12.375', 'counters/examples': 50048, 'counters/updates': 3128}
skipping logging after 50064 examples to avoid logging too frequently
skipping logging after 50080 examples to avoid logging too frequently
skipping logging after 50096 examples to avoid logging too frequently
train stats after 50112 examples: {'rewards_train/chosen': '-2.8147', 'rewards_train/rejected': '-12.134', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.3177', 'logps_train/rejected': '-266.53', 'logps_train/chosen': '-78.643', 'loss/train': '0.084192', 'examples_per_second': '4.4562', 'grad_norm': '14.812', 'counters/examples': 50112, 'counters/updates': 3132}
skipping logging after 50128 examples to avoid logging too frequently
skipping logging after 50144 examples to avoid logging too frequently
skipping logging after 50160 examples to avoid logging too frequently
train stats after 50176 examples: {'rewards_train/chosen': '-2.3878', 'rewards_train/rejected': '-9.7073', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.3182', 'logps_train/rejected': '-226.12', 'logps_train/chosen': '-62.071', 'loss/train': '0.12281', 'examples_per_second': '4.7688', 'grad_norm': '15.75', 'counters/examples': 50176, 'counters/updates': 3136}
skipping logging after 50192 examples to avoid logging too frequently
skipping logging after 50208 examples to avoid logging too frequently
skipping logging after 50224 examples to avoid logging too frequently
train stats after 50240 examples: {'rewards_train/chosen': '-2.5932', 'rewards_train/rejected': '-10.987', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.3915', 'logps_train/rejected': '-256.22', 'logps_train/chosen': '-64.406', 'loss/train': '0.040868', 'examples_per_second': '5.5594', 'grad_norm': '7.4062', 'counters/examples': 50240, 'counters/updates': 3140}
skipping logging after 50256 examples to avoid logging too frequently
skipping logging after 50272 examples to avoid logging too frequently
skipping logging after 50288 examples to avoid logging too frequently
train stats after 50304 examples: {'rewards_train/chosen': '-2.8706', 'rewards_train/rejected': '-12.071', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.1985', 'logps_train/rejected': '-265.79', 'logps_train/chosen': '-75.408', 'loss/train': '0.036358', 'examples_per_second': '5.8408', 'grad_norm': '7.75', 'counters/examples': 50304, 'counters/updates': 3144}
skipping logging after 50320 examples to avoid logging too frequently
skipping logging after 50336 examples to avoid logging too frequently
skipping logging after 50352 examples to avoid logging too frequently
train stats after 50368 examples: {'rewards_train/chosen': '-2.3487', 'rewards_train/rejected': '-10.883', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.5337', 'logps_train/rejected': '-252.5', 'logps_train/chosen': '-55.748', 'loss/train': '0.050795', 'examples_per_second': '4.6951', 'grad_norm': '8.25', 'counters/examples': 50368, 'counters/updates': 3148}
skipping logging after 50384 examples to avoid logging too frequently
skipping logging after 50400 examples to avoid logging too frequently
skipping logging after 50416 examples to avoid logging too frequently
train stats after 50432 examples: {'rewards_train/chosen': '-2.5225', 'rewards_train/rejected': '-12.209', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.6853', 'logps_train/rejected': '-299.89', 'logps_train/chosen': '-66.504', 'loss/train': '0.037081', 'examples_per_second': '5.3654', 'grad_norm': '2.7656', 'counters/examples': 50432, 'counters/updates': 3152}
skipping logging after 50448 examples to avoid logging too frequently
skipping logging after 50464 examples to avoid logging too frequently
skipping logging after 50480 examples to avoid logging too frequently
train stats after 50496 examples: {'rewards_train/chosen': '-2.2109', 'rewards_train/rejected': '-12.159', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.9492', 'logps_train/rejected': '-299.91', 'logps_train/chosen': '-64.172', 'loss/train': '0.053578', 'examples_per_second': '4.114', 'grad_norm': '8.5', 'counters/examples': 50496, 'counters/updates': 3156}
skipping logging after 50512 examples to avoid logging too frequently
skipping logging after 50528 examples to avoid logging too frequently
skipping logging after 50544 examples to avoid logging too frequently
train stats after 50560 examples: {'rewards_train/chosen': '-2.7841', 'rewards_train/rejected': '-11.013', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '8.2277', 'logps_train/rejected': '-251.06', 'logps_train/chosen': '-79.71', 'loss/train': '0.22022', 'examples_per_second': '5.2153', 'grad_norm': '28.75', 'counters/examples': 50560, 'counters/updates': 3160}
skipping logging after 50576 examples to avoid logging too frequently
skipping logging after 50592 examples to avoid logging too frequently
skipping logging after 50608 examples to avoid logging too frequently
train stats after 50624 examples: {'rewards_train/chosen': '-2.5562', 'rewards_train/rejected': '-10.32', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.7634', 'logps_train/rejected': '-216.82', 'logps_train/chosen': '-57.134', 'loss/train': '0.097808', 'examples_per_second': '5.3028', 'grad_norm': '10.375', 'counters/examples': 50624, 'counters/updates': 3164}
skipping logging after 50640 examples to avoid logging too frequently
skipping logging after 50656 examples to avoid logging too frequently
skipping logging after 50672 examples to avoid logging too frequently
train stats after 50688 examples: {'rewards_train/chosen': '-2.7338', 'rewards_train/rejected': '-9.4865', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.7513', 'logps_train/rejected': '-207.28', 'logps_train/chosen': '-63.059', 'loss/train': '0.08984', 'examples_per_second': '4.343', 'grad_norm': '7.4062', 'counters/examples': 50688, 'counters/updates': 3168}
skipping logging after 50704 examples to avoid logging too frequently
skipping logging after 50720 examples to avoid logging too frequently
skipping logging after 50736 examples to avoid logging too frequently
train stats after 50752 examples: {'rewards_train/chosen': '-2.2523', 'rewards_train/rejected': '-10.563', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.3101', 'logps_train/rejected': '-233.77', 'logps_train/chosen': '-60.21', 'loss/train': '0.060666', 'examples_per_second': '5.7642', 'grad_norm': '4.8438', 'counters/examples': 50752, 'counters/updates': 3172}
skipping logging after 50768 examples to avoid logging too frequently
skipping logging after 50784 examples to avoid logging too frequently
skipping logging after 50800 examples to avoid logging too frequently
train stats after 50816 examples: {'rewards_train/chosen': '-2.4317', 'rewards_train/rejected': '-11.185', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.7535', 'logps_train/rejected': '-263.47', 'logps_train/chosen': '-59.175', 'loss/train': '0.061588', 'examples_per_second': '5.1492', 'grad_norm': '6.3438', 'counters/examples': 50816, 'counters/updates': 3176}
skipping logging after 50832 examples to avoid logging too frequently
skipping logging after 50848 examples to avoid logging too frequently
skipping logging after 50864 examples to avoid logging too frequently
train stats after 50880 examples: {'rewards_train/chosen': '-2.661', 'rewards_train/rejected': '-12.27', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.6062', 'logps_train/rejected': '-272.07', 'logps_train/chosen': '-71.755', 'loss/train': '0.024911', 'examples_per_second': '5.1548', 'grad_norm': '6.25', 'counters/examples': 50880, 'counters/updates': 3180}
skipping logging after 50896 examples to avoid logging too frequently
skipping logging after 50912 examples to avoid logging too frequently
skipping logging after 50928 examples to avoid logging too frequently
train stats after 50944 examples: {'rewards_train/chosen': '-3.2802', 'rewards_train/rejected': '-12.474', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.1926', 'logps_train/rejected': '-269.22', 'logps_train/chosen': '-62.82', 'loss/train': '0.13018', 'examples_per_second': '5.7896', 'grad_norm': '21.125', 'counters/examples': 50944, 'counters/updates': 3184}
skipping logging after 50960 examples to avoid logging too frequently
skipping logging after 50976 examples to avoid logging too frequently
skipping logging after 50992 examples to avoid logging too frequently
train stats after 51008 examples: {'rewards_train/chosen': '-2.492', 'rewards_train/rejected': '-11.045', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.5503', 'logps_train/rejected': '-249.68', 'logps_train/chosen': '-66.561', 'loss/train': '0.12587', 'examples_per_second': '5.7455', 'grad_norm': '13.125', 'counters/examples': 51008, 'counters/updates': 3188}
skipping logging after 51024 examples to avoid logging too frequently
skipping logging after 51040 examples to avoid logging too frequently
skipping logging after 51056 examples to avoid logging too frequently
train stats after 51072 examples: {'rewards_train/chosen': '-2.4313', 'rewards_train/rejected': '-10.879', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.4493', 'logps_train/rejected': '-217.28', 'logps_train/chosen': '-68.383', 'loss/train': '0.070478', 'examples_per_second': '5.0223', 'grad_norm': '7.125', 'counters/examples': 51072, 'counters/updates': 3192}
skipping logging after 51088 examples to avoid logging too frequently
skipping logging after 51104 examples to avoid logging too frequently
skipping logging after 51120 examples to avoid logging too frequently
train stats after 51136 examples: {'rewards_train/chosen': '-2.5834', 'rewards_train/rejected': '-12.179', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.5974', 'logps_train/rejected': '-261.28', 'logps_train/chosen': '-61.468', 'loss/train': '0.057264', 'examples_per_second': '5.2983', 'grad_norm': '6.5', 'counters/examples': 51136, 'counters/updates': 3196}
skipping logging after 51152 examples to avoid logging too frequently
skipping logging after 51168 examples to avoid logging too frequently
skipping logging after 51184 examples to avoid logging too frequently
train stats after 51200 examples: {'rewards_train/chosen': '-2.4832', 'rewards_train/rejected': '-11.711', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.2292', 'logps_train/rejected': '-277.7', 'logps_train/chosen': '-73.374', 'loss/train': '0.02824', 'examples_per_second': '4.0499', 'grad_norm': '5.5312', 'counters/examples': 51200, 'counters/updates': 3200}
skipping logging after 51216 examples to avoid logging too frequently
skipping logging after 51232 examples to avoid logging too frequently
skipping logging after 51248 examples to avoid logging too frequently
train stats after 51264 examples: {'rewards_train/chosen': '-2.8008', 'rewards_train/rejected': '-11.884', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.0813', 'logps_train/rejected': '-263.11', 'logps_train/chosen': '-72.389', 'loss/train': '0.06625', 'examples_per_second': '4.5585', 'grad_norm': '14.312', 'counters/examples': 51264, 'counters/updates': 3204}
skipping logging after 51280 examples to avoid logging too frequently
skipping logging after 51296 examples to avoid logging too frequently
skipping logging after 51312 examples to avoid logging too frequently
train stats after 51328 examples: {'rewards_train/chosen': '-3.1073', 'rewards_train/rejected': '-13.208', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '10.1', 'logps_train/rejected': '-297.15', 'logps_train/chosen': '-70.941', 'loss/train': '0.035142', 'examples_per_second': '5.0633', 'grad_norm': '8.125', 'counters/examples': 51328, 'counters/updates': 3208}
skipping logging after 51344 examples to avoid logging too frequently
skipping logging after 51360 examples to avoid logging too frequently
skipping logging after 51376 examples to avoid logging too frequently
train stats after 51392 examples: {'rewards_train/chosen': '-2.4142', 'rewards_train/rejected': '-11.715', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.3032', 'logps_train/rejected': '-252.74', 'logps_train/chosen': '-58.346', 'loss/train': '0.070307', 'examples_per_second': '5.6418', 'grad_norm': '11', 'counters/examples': 51392, 'counters/updates': 3212}
skipping logging after 51408 examples to avoid logging too frequently
skipping logging after 51424 examples to avoid logging too frequently
skipping logging after 51440 examples to avoid logging too frequently
train stats after 51456 examples: {'rewards_train/chosen': '-2.8689', 'rewards_train/rejected': '-12.27', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.4004', 'logps_train/rejected': '-271.32', 'logps_train/chosen': '-74.617', 'loss/train': '0.019344', 'examples_per_second': '4.6101', 'grad_norm': '2.6875', 'counters/examples': 51456, 'counters/updates': 3216}
skipping logging after 51472 examples to avoid logging too frequently
skipping logging after 51488 examples to avoid logging too frequently
skipping logging after 51504 examples to avoid logging too frequently
train stats after 51520 examples: {'rewards_train/chosen': '-2.4531', 'rewards_train/rejected': '-12.579', 'rewards_train/accuracies': '1', 'rewards_train/margins': '10.128', 'logps_train/rejected': '-265.69', 'logps_train/chosen': '-59.1', 'loss/train': '0.010949', 'examples_per_second': '5.3824', 'grad_norm': '3.2812', 'counters/examples': 51520, 'counters/updates': 3220}
skipping logging after 51536 examples to avoid logging too frequently
skipping logging after 51552 examples to avoid logging too frequently
skipping logging after 51568 examples to avoid logging too frequently
train stats after 51584 examples: {'rewards_train/chosen': '-2.3263', 'rewards_train/rejected': '-12.339', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '10.016', 'logps_train/rejected': '-269.3', 'logps_train/chosen': '-59.992', 'loss/train': '0.045329', 'examples_per_second': '5.1731', 'grad_norm': '6.3438', 'counters/examples': 51584, 'counters/updates': 3224}
skipping logging after 51600 examples to avoid logging too frequently
skipping logging after 51616 examples to avoid logging too frequently
skipping logging after 51632 examples to avoid logging too frequently
train stats after 51648 examples: {'rewards_train/chosen': '-2.1456', 'rewards_train/rejected': '-12.329', 'rewards_train/accuracies': '1', 'rewards_train/margins': '10.18', 'logps_train/rejected': '-279.89', 'logps_train/chosen': '-67.374', 'loss/train': '0.0094193', 'examples_per_second': '4.7883', 'grad_norm': '4.3125', 'counters/examples': 51648, 'counters/updates': 3228}
skipping logging after 51664 examples to avoid logging too frequently
skipping logging after 51680 examples to avoid logging too frequently
skipping logging after 51696 examples to avoid logging too frequently
train stats after 51712 examples: {'rewards_train/chosen': '-2.6966', 'rewards_train/rejected': '-12.619', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.9202', 'logps_train/rejected': '-279.63', 'logps_train/chosen': '-60.344', 'loss/train': '0.06449', 'examples_per_second': '4.8497', 'grad_norm': '16.5', 'counters/examples': 51712, 'counters/updates': 3232}
skipping logging after 51728 examples to avoid logging too frequently
skipping logging after 51744 examples to avoid logging too frequently
skipping logging after 51760 examples to avoid logging too frequently
train stats after 51776 examples: {'rewards_train/chosen': '-2.6743', 'rewards_train/rejected': '-12.524', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.8542', 'logps_train/rejected': '-280.36', 'logps_train/chosen': '-68.968', 'loss/train': '0.051413', 'examples_per_second': '4.5557', 'grad_norm': '10.062', 'counters/examples': 51776, 'counters/updates': 3236}
skipping logging after 51792 examples to avoid logging too frequently
skipping logging after 51808 examples to avoid logging too frequently
skipping logging after 51824 examples to avoid logging too frequently
train stats after 51840 examples: {'rewards_train/chosen': '-2.9205', 'rewards_train/rejected': '-10.583', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.6606', 'logps_train/rejected': '-220.81', 'logps_train/chosen': '-70.576', 'loss/train': '0.11318', 'examples_per_second': '4.9898', 'grad_norm': '23.875', 'counters/examples': 51840, 'counters/updates': 3240}
skipping logging after 51856 examples to avoid logging too frequently
skipping logging after 51872 examples to avoid logging too frequently
skipping logging after 51888 examples to avoid logging too frequently
train stats after 51904 examples: {'rewards_train/chosen': '-2.3937', 'rewards_train/rejected': '-11.584', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.1903', 'logps_train/rejected': '-264.27', 'logps_train/chosen': '-67.065', 'loss/train': '0.020543', 'examples_per_second': '4.3582', 'grad_norm': '4.1562', 'counters/examples': 51904, 'counters/updates': 3244}
skipping logging after 51920 examples to avoid logging too frequently
skipping logging after 51936 examples to avoid logging too frequently
skipping logging after 51952 examples to avoid logging too frequently
train stats after 51968 examples: {'rewards_train/chosen': '-2.6408', 'rewards_train/rejected': '-10.604', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.9631', 'logps_train/rejected': '-231.28', 'logps_train/chosen': '-64.67', 'loss/train': '0.049502', 'examples_per_second': '4.7184', 'grad_norm': '9.5625', 'counters/examples': 51968, 'counters/updates': 3248}
skipping logging after 51984 examples to avoid logging too frequently
skipping logging after 52000 examples to avoid logging too frequently
Running evaluation after 52000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:07,  2.18s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:03,  2.11s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.89s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.88s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.54s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.65s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.49s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:36,  1.57s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.50s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:22,  1.30s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.25s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:20,  1.34s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.35s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:14,  1.28s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.16s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:33<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.30s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.27s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:37<00:07,  1.31s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:39<00:07,  1.48s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.42s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.62s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.43s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.42s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.41s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.44s/it]
eval after 52000: {'rewards_eval/chosen': '-10.487', 'rewards_eval/rejected': '-11.098', 'rewards_eval/accuracies': '0.54297', 'rewards_eval/margins': '0.61017', 'logps_eval/rejected': '-258.64', 'logps_eval/chosen': '-249.78', 'loss/eval': '2.0027'}
skipping logging after 52016 examples to avoid logging too frequently
train stats after 52032 examples: {'rewards_train/chosen': '-2.4149', 'rewards_train/rejected': '-11.496', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.0787', 'logps_train/rejected': '-269.55', 'logps_train/chosen': '-63.414', 'loss/train': '0.0375', 'examples_per_second': '4.5003', 'grad_norm': '5.0312', 'counters/examples': 52032, 'counters/updates': 3252}
skipping logging after 52048 examples to avoid logging too frequently
skipping logging after 52064 examples to avoid logging too frequently
skipping logging after 52080 examples to avoid logging too frequently
train stats after 52096 examples: {'rewards_train/chosen': '-2.1572', 'rewards_train/rejected': '-10.693', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.5386', 'logps_train/rejected': '-259.06', 'logps_train/chosen': '-69.385', 'loss/train': '0.03122', 'examples_per_second': '4.5099', 'grad_norm': '5.2812', 'counters/examples': 52096, 'counters/updates': 3256}
skipping logging after 52112 examples to avoid logging too frequently
skipping logging after 52128 examples to avoid logging too frequently
skipping logging after 52144 examples to avoid logging too frequently
train stats after 52160 examples: {'rewards_train/chosen': '-2.6224', 'rewards_train/rejected': '-12.011', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.3938', 'logps_train/rejected': '-264.33', 'logps_train/chosen': '-61.589', 'loss/train': '0.059243', 'examples_per_second': '4.8838', 'grad_norm': '12.812', 'counters/examples': 52160, 'counters/updates': 3260}
skipping logging after 52176 examples to avoid logging too frequently
skipping logging after 52192 examples to avoid logging too frequently
skipping logging after 52208 examples to avoid logging too frequently
train stats after 52224 examples: {'rewards_train/chosen': '-2.8531', 'rewards_train/rejected': '-10.817', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.9655', 'logps_train/rejected': '-224.06', 'logps_train/chosen': '-71.824', 'loss/train': '0.043505', 'examples_per_second': '5.6883', 'grad_norm': '4.125', 'counters/examples': 52224, 'counters/updates': 3264}
skipping logging after 52240 examples to avoid logging too frequently
skipping logging after 52256 examples to avoid logging too frequently
skipping logging after 52272 examples to avoid logging too frequently
train stats after 52288 examples: {'rewards_train/chosen': '-2.6373', 'rewards_train/rejected': '-11.617', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.978', 'logps_train/rejected': '-263.86', 'logps_train/chosen': '-71.09', 'loss/train': '0.028637', 'examples_per_second': '4.6666', 'grad_norm': '10.125', 'counters/examples': 52288, 'counters/updates': 3268}
skipping logging after 52304 examples to avoid logging too frequently
skipping logging after 52320 examples to avoid logging too frequently
skipping logging after 52336 examples to avoid logging too frequently
train stats after 52352 examples: {'rewards_train/chosen': '-3.1639', 'rewards_train/rejected': '-12.601', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '9.4388', 'logps_train/rejected': '-275.52', 'logps_train/chosen': '-77.952', 'loss/train': '0.14546', 'examples_per_second': '4.7992', 'grad_norm': '19.75', 'counters/examples': 52352, 'counters/updates': 3272}
skipping logging after 52368 examples to avoid logging too frequently
skipping logging after 52384 examples to avoid logging too frequently
skipping logging after 52400 examples to avoid logging too frequently
train stats after 52416 examples: {'rewards_train/chosen': '-3.0627', 'rewards_train/rejected': '-13.491', 'rewards_train/accuracies': '1', 'rewards_train/margins': '10.432', 'logps_train/rejected': '-284.62', 'logps_train/chosen': '-73.809', 'loss/train': '0.045852', 'examples_per_second': '5.1652', 'grad_norm': '15.5', 'counters/examples': 52416, 'counters/updates': 3276}
skipping logging after 52432 examples to avoid logging too frequently
skipping logging after 52448 examples to avoid logging too frequently
skipping logging after 52464 examples to avoid logging too frequently
train stats after 52480 examples: {'rewards_train/chosen': '-3.1887', 'rewards_train/rejected': '-13.441', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '10.253', 'logps_train/rejected': '-294.41', 'logps_train/chosen': '-74.289', 'loss/train': '0.098241', 'examples_per_second': '4.9533', 'grad_norm': '15.75', 'counters/examples': 52480, 'counters/updates': 3280}
skipping logging after 52496 examples to avoid logging too frequently
skipping logging after 52512 examples to avoid logging too frequently
skipping logging after 52528 examples to avoid logging too frequently
train stats after 52544 examples: {'rewards_train/chosen': '-2.7785', 'rewards_train/rejected': '-13.048', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '10.271', 'logps_train/rejected': '-286.27', 'logps_train/chosen': '-64.879', 'loss/train': '0.03573', 'examples_per_second': '4.6061', 'grad_norm': '4.0625', 'counters/examples': 52544, 'counters/updates': 3284}
skipping logging after 52560 examples to avoid logging too frequently
skipping logging after 52576 examples to avoid logging too frequently
skipping logging after 52592 examples to avoid logging too frequently
train stats after 52608 examples: {'rewards_train/chosen': '-3.1693', 'rewards_train/rejected': '-11.313', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.1432', 'logps_train/rejected': '-228.82', 'logps_train/chosen': '-76.384', 'loss/train': '0.12396', 'examples_per_second': '5.6403', 'grad_norm': '22.375', 'counters/examples': 52608, 'counters/updates': 3288}
skipping logging after 52624 examples to avoid logging too frequently
skipping logging after 52640 examples to avoid logging too frequently
skipping logging after 52656 examples to avoid logging too frequently
train stats after 52672 examples: {'rewards_train/chosen': '-3.3297', 'rewards_train/rejected': '-13.249', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.9143', 'logps_train/rejected': '-312.44', 'logps_train/chosen': '-75.79', 'loss/train': '0.0072135', 'examples_per_second': '5.0674', 'grad_norm': '2.1406', 'counters/examples': 52672, 'counters/updates': 3292}
skipping logging after 52688 examples to avoid logging too frequently
skipping logging after 52704 examples to avoid logging too frequently
skipping logging after 52720 examples to avoid logging too frequently
train stats after 52736 examples: {'rewards_train/chosen': '-2.7731', 'rewards_train/rejected': '-12.516', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '9.7383', 'logps_train/rejected': '-279.36', 'logps_train/chosen': '-77.491', 'loss/train': '0.048461', 'examples_per_second': '4.8593', 'grad_norm': '4.4688', 'counters/examples': 52736, 'counters/updates': 3296}
skipping logging after 52752 examples to avoid logging too frequently
skipping logging after 52768 examples to avoid logging too frequently
skipping logging after 52784 examples to avoid logging too frequently
train stats after 52800 examples: {'rewards_train/chosen': '-2.7875', 'rewards_train/rejected': '-9.7934', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.0043', 'logps_train/rejected': '-197.28', 'logps_train/chosen': '-60.973', 'loss/train': '0.13132', 'examples_per_second': '5.0117', 'grad_norm': '9.9375', 'counters/examples': 52800, 'counters/updates': 3300}
skipping logging after 52816 examples to avoid logging too frequently
skipping logging after 52832 examples to avoid logging too frequently
skipping logging after 52848 examples to avoid logging too frequently
train stats after 52864 examples: {'rewards_train/chosen': '-2.8712', 'rewards_train/rejected': '-12.645', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.781', 'logps_train/rejected': '-260.15', 'logps_train/chosen': '-69.829', 'loss/train': '0.087164', 'examples_per_second': '4.5169', 'grad_norm': '11.938', 'counters/examples': 52864, 'counters/updates': 3304}
skipping logging after 52880 examples to avoid logging too frequently
skipping logging after 52896 examples to avoid logging too frequently
skipping logging after 52912 examples to avoid logging too frequently
train stats after 52928 examples: {'rewards_train/chosen': '-2.8495', 'rewards_train/rejected': '-11.633', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.7791', 'logps_train/rejected': '-269.34', 'logps_train/chosen': '-70.973', 'loss/train': '0.049568', 'examples_per_second': '4.1664', 'grad_norm': '10.062', 'counters/examples': 52928, 'counters/updates': 3308}
skipping logging after 52944 examples to avoid logging too frequently
skipping logging after 52960 examples to avoid logging too frequently
skipping logging after 52976 examples to avoid logging too frequently
train stats after 52992 examples: {'rewards_train/chosen': '-2.4598', 'rewards_train/rejected': '-11.215', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.7493', 'logps_train/rejected': '-254.09', 'logps_train/chosen': '-66.195', 'loss/train': '0.075439', 'examples_per_second': '5.0295', 'grad_norm': '10.438', 'counters/examples': 52992, 'counters/updates': 3312}
skipping logging after 53008 examples to avoid logging too frequently
skipping logging after 53024 examples to avoid logging too frequently
skipping logging after 53040 examples to avoid logging too frequently
train stats after 53056 examples: {'rewards_train/chosen': '-2.7559', 'rewards_train/rejected': '-11.236', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.4805', 'logps_train/rejected': '-259.13', 'logps_train/chosen': '-73.024', 'loss/train': '0.044916', 'examples_per_second': '5.5312', 'grad_norm': '8.6875', 'counters/examples': 53056, 'counters/updates': 3316}
skipping logging after 53072 examples to avoid logging too frequently
skipping logging after 53088 examples to avoid logging too frequently
skipping logging after 53104 examples to avoid logging too frequently
train stats after 53120 examples: {'rewards_train/chosen': '-2.5182', 'rewards_train/rejected': '-13.122', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '10.606', 'logps_train/rejected': '-285.5', 'logps_train/chosen': '-63.617', 'loss/train': '0.068041', 'examples_per_second': '5.8779', 'grad_norm': '16.375', 'counters/examples': 53120, 'counters/updates': 3320}
skipping logging after 53136 examples to avoid logging too frequently
skipping logging after 53152 examples to avoid logging too frequently
skipping logging after 53168 examples to avoid logging too frequently
train stats after 53184 examples: {'rewards_train/chosen': '-2.5206', 'rewards_train/rejected': '-10.675', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.1538', 'logps_train/rejected': '-259.15', 'logps_train/chosen': '-66.37', 'loss/train': '0.095949', 'examples_per_second': '4.3748', 'grad_norm': '14.312', 'counters/examples': 53184, 'counters/updates': 3324}
skipping logging after 53200 examples to avoid logging too frequently
skipping logging after 53216 examples to avoid logging too frequently
skipping logging after 53232 examples to avoid logging too frequently
train stats after 53248 examples: {'rewards_train/chosen': '-2.23', 'rewards_train/rejected': '-9.9374', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.7061', 'logps_train/rejected': '-216.01', 'logps_train/chosen': '-59.973', 'loss/train': '0.16121', 'examples_per_second': '5.4707', 'grad_norm': '15.562', 'counters/examples': 53248, 'counters/updates': 3328}
skipping logging after 53264 examples to avoid logging too frequently
skipping logging after 53280 examples to avoid logging too frequently
skipping logging after 53296 examples to avoid logging too frequently
train stats after 53312 examples: {'rewards_train/chosen': '-1.9448', 'rewards_train/rejected': '-10.185', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.2393', 'logps_train/rejected': '-243.19', 'logps_train/chosen': '-58.188', 'loss/train': '0.051875', 'examples_per_second': '4.9466', 'grad_norm': '6.9688', 'counters/examples': 53312, 'counters/updates': 3332}
skipping logging after 53328 examples to avoid logging too frequently
skipping logging after 53344 examples to avoid logging too frequently
skipping logging after 53360 examples to avoid logging too frequently
train stats after 53376 examples: {'rewards_train/chosen': '-2.176', 'rewards_train/rejected': '-10.163', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.989', 'logps_train/rejected': '-262.37', 'logps_train/chosen': '-61.698', 'loss/train': '0.093309', 'examples_per_second': '5.0863', 'grad_norm': '12.375', 'counters/examples': 53376, 'counters/updates': 3336}
skipping logging after 53392 examples to avoid logging too frequently
skipping logging after 53408 examples to avoid logging too frequently
skipping logging after 53424 examples to avoid logging too frequently
train stats after 53440 examples: {'rewards_train/chosen': '-2.0709', 'rewards_train/rejected': '-9.3003', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.2282', 'logps_train/rejected': '-214.65', 'logps_train/chosen': '-57.091', 'loss/train': '0.039562', 'examples_per_second': '5.7887', 'grad_norm': '5.875', 'counters/examples': 53440, 'counters/updates': 3340}
skipping logging after 53456 examples to avoid logging too frequently
skipping logging after 53472 examples to avoid logging too frequently
skipping logging after 53488 examples to avoid logging too frequently
train stats after 53504 examples: {'rewards_train/chosen': '-2.251', 'rewards_train/rejected': '-11.091', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.839', 'logps_train/rejected': '-273.62', 'logps_train/chosen': '-76.624', 'loss/train': '0.063228', 'examples_per_second': '4.9594', 'grad_norm': '8.5', 'counters/examples': 53504, 'counters/updates': 3344}
skipping logging after 53520 examples to avoid logging too frequently
skipping logging after 53536 examples to avoid logging too frequently
skipping logging after 53552 examples to avoid logging too frequently
train stats after 53568 examples: {'rewards_train/chosen': '-2.2485', 'rewards_train/rejected': '-10.747', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.4963', 'logps_train/rejected': '-256.93', 'logps_train/chosen': '-66.434', 'loss/train': '0.049098', 'examples_per_second': '5.6283', 'grad_norm': '6.7812', 'counters/examples': 53568, 'counters/updates': 3348}
skipping logging after 53584 examples to avoid logging too frequently
skipping logging after 53600 examples to avoid logging too frequently
skipping logging after 53616 examples to avoid logging too frequently
train stats after 53632 examples: {'rewards_train/chosen': '-2.0899', 'rewards_train/rejected': '-11.153', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.0608', 'logps_train/rejected': '-263.42', 'logps_train/chosen': '-60.188', 'loss/train': '0.050307', 'examples_per_second': '6.2432', 'grad_norm': '13.188', 'counters/examples': 53632, 'counters/updates': 3352}
skipping logging after 53648 examples to avoid logging too frequently
skipping logging after 53664 examples to avoid logging too frequently
skipping logging after 53680 examples to avoid logging too frequently
train stats after 53696 examples: {'rewards_train/chosen': '-1.9916', 'rewards_train/rejected': '-10.312', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.3177', 'logps_train/rejected': '-234.55', 'logps_train/chosen': '-60.078', 'loss/train': '0.039093', 'examples_per_second': '4.2694', 'grad_norm': '6.3438', 'counters/examples': 53696, 'counters/updates': 3356}
skipping logging after 53712 examples to avoid logging too frequently
skipping logging after 53728 examples to avoid logging too frequently
skipping logging after 53744 examples to avoid logging too frequently
train stats after 53760 examples: {'rewards_train/chosen': '-2.4975', 'rewards_train/rejected': '-12.009', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.5112', 'logps_train/rejected': '-256.34', 'logps_train/chosen': '-66.416', 'loss/train': '0.10412', 'examples_per_second': '6.2205', 'grad_norm': '14.188', 'counters/examples': 53760, 'counters/updates': 3360}
skipping logging after 53776 examples to avoid logging too frequently
skipping logging after 53792 examples to avoid logging too frequently
skipping logging after 53808 examples to avoid logging too frequently
train stats after 53824 examples: {'rewards_train/chosen': '-2.5589', 'rewards_train/rejected': '-12.368', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.8114', 'logps_train/rejected': '-284.71', 'logps_train/chosen': '-62.994', 'loss/train': '0.064611', 'examples_per_second': '4.5176', 'grad_norm': '11', 'counters/examples': 53824, 'counters/updates': 3364}
skipping logging after 53840 examples to avoid logging too frequently
skipping logging after 53856 examples to avoid logging too frequently
skipping logging after 53872 examples to avoid logging too frequently
train stats after 53888 examples: {'rewards_train/chosen': '-2.4426', 'rewards_train/rejected': '-11.559', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.119', 'logps_train/rejected': '-270.04', 'logps_train/chosen': '-75.26', 'loss/train': '0.013843', 'examples_per_second': '5.1524', 'grad_norm': '3.5469', 'counters/examples': 53888, 'counters/updates': 3368}
skipping logging after 53904 examples to avoid logging too frequently
skipping logging after 53920 examples to avoid logging too frequently
skipping logging after 53936 examples to avoid logging too frequently
train stats after 53952 examples: {'rewards_train/chosen': '-2.8569', 'rewards_train/rejected': '-11.079', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.2166', 'logps_train/rejected': '-237.89', 'logps_train/chosen': '-64.869', 'loss/train': '0.093979', 'examples_per_second': '5.7002', 'grad_norm': '16.875', 'counters/examples': 53952, 'counters/updates': 3372}
skipping logging after 53968 examples to avoid logging too frequently
skipping logging after 53984 examples to avoid logging too frequently
skipping logging after 54000 examples to avoid logging too frequently
train stats after 54016 examples: {'rewards_train/chosen': '-2.3027', 'rewards_train/rejected': '-10.343', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.0399', 'logps_train/rejected': '-244.61', 'logps_train/chosen': '-60.545', 'loss/train': '0.049867', 'examples_per_second': '4.6759', 'grad_norm': '10', 'counters/examples': 54016, 'counters/updates': 3376}
skipping logging after 54032 examples to avoid logging too frequently
skipping logging after 54048 examples to avoid logging too frequently
skipping logging after 54064 examples to avoid logging too frequently
train stats after 54080 examples: {'rewards_train/chosen': '-2.8889', 'rewards_train/rejected': '-10.452', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.5623', 'logps_train/rejected': '-231.93', 'logps_train/chosen': '-66.418', 'loss/train': '0.071376', 'examples_per_second': '4.833', 'grad_norm': '11.688', 'counters/examples': 54080, 'counters/updates': 3380}
skipping logging after 54096 examples to avoid logging too frequently
skipping logging after 54112 examples to avoid logging too frequently
skipping logging after 54128 examples to avoid logging too frequently
train stats after 54144 examples: {'rewards_train/chosen': '-2.5235', 'rewards_train/rejected': '-9.8973', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.3728', 'logps_train/rejected': '-207.5', 'logps_train/chosen': '-58.07', 'loss/train': '0.11804', 'examples_per_second': '5.4066', 'grad_norm': '19.125', 'counters/examples': 54144, 'counters/updates': 3384}
skipping logging after 54160 examples to avoid logging too frequently
skipping logging after 54176 examples to avoid logging too frequently
skipping logging after 54192 examples to avoid logging too frequently
train stats after 54208 examples: {'rewards_train/chosen': '-2.5494', 'rewards_train/rejected': '-11.19', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.6406', 'logps_train/rejected': '-256.58', 'logps_train/chosen': '-65.805', 'loss/train': '0.18227', 'examples_per_second': '4.7882', 'grad_norm': '24.375', 'counters/examples': 54208, 'counters/updates': 3388}
skipping logging after 54224 examples to avoid logging too frequently
skipping logging after 54240 examples to avoid logging too frequently
skipping logging after 54256 examples to avoid logging too frequently
train stats after 54272 examples: {'rewards_train/chosen': '-2.3912', 'rewards_train/rejected': '-10.527', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '8.1359', 'logps_train/rejected': '-248.4', 'logps_train/chosen': '-70.937', 'loss/train': '0.10111', 'examples_per_second': '5.1841', 'grad_norm': '17.5', 'counters/examples': 54272, 'counters/updates': 3392}
skipping logging after 54288 examples to avoid logging too frequently
skipping logging after 54304 examples to avoid logging too frequently
skipping logging after 54320 examples to avoid logging too frequently
train stats after 54336 examples: {'rewards_train/chosen': '-2.7038', 'rewards_train/rejected': '-12.718', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '10.016', 'logps_train/rejected': '-319.22', 'logps_train/chosen': '-68.593', 'loss/train': '0.090668', 'examples_per_second': '4.5956', 'grad_norm': '11.5', 'counters/examples': 54336, 'counters/updates': 3396}
skipping logging after 54352 examples to avoid logging too frequently
skipping logging after 54368 examples to avoid logging too frequently
skipping logging after 54384 examples to avoid logging too frequently
train stats after 54400 examples: {'rewards_train/chosen': '-2.3059', 'rewards_train/rejected': '-10.512', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.2062', 'logps_train/rejected': '-246.45', 'logps_train/chosen': '-65.348', 'loss/train': '0.050042', 'examples_per_second': '5.3114', 'grad_norm': '6', 'counters/examples': 54400, 'counters/updates': 3400}
skipping logging after 54416 examples to avoid logging too frequently
skipping logging after 54432 examples to avoid logging too frequently
skipping logging after 54448 examples to avoid logging too frequently
train stats after 54464 examples: {'rewards_train/chosen': '-2.6789', 'rewards_train/rejected': '-11.763', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.0807', 'logps_train/rejected': '-298.97', 'logps_train/chosen': '-72.53', 'loss/train': '0.064703', 'examples_per_second': '4.7574', 'grad_norm': '6.3438', 'counters/examples': 54464, 'counters/updates': 3404}
skipping logging after 54480 examples to avoid logging too frequently
skipping logging after 54496 examples to avoid logging too frequently
skipping logging after 54512 examples to avoid logging too frequently
train stats after 54528 examples: {'rewards_train/chosen': '-2.4844', 'rewards_train/rejected': '-10.405', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.9189', 'logps_train/rejected': '-246.19', 'logps_train/chosen': '-58.983', 'loss/train': '0.087', 'examples_per_second': '5.829', 'grad_norm': '12.938', 'counters/examples': 54528, 'counters/updates': 3408}
skipping logging after 54544 examples to avoid logging too frequently
skipping logging after 54560 examples to avoid logging too frequently
skipping logging after 54576 examples to avoid logging too frequently
train stats after 54592 examples: {'rewards_train/chosen': '-2.3462', 'rewards_train/rejected': '-10.961', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.6184', 'logps_train/rejected': '-274.69', 'logps_train/chosen': '-64.365', 'loss/train': '0.076592', 'examples_per_second': '5.0205', 'grad_norm': '11.125', 'counters/examples': 54592, 'counters/updates': 3412}
skipping logging after 54608 examples to avoid logging too frequently
skipping logging after 54624 examples to avoid logging too frequently
skipping logging after 54640 examples to avoid logging too frequently
train stats after 54656 examples: {'rewards_train/chosen': '-2.6764', 'rewards_train/rejected': '-10.655', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.978', 'logps_train/rejected': '-231.59', 'logps_train/chosen': '-67.993', 'loss/train': '0.043673', 'examples_per_second': '4.8125', 'grad_norm': '3.6406', 'counters/examples': 54656, 'counters/updates': 3416}
skipping logging after 54672 examples to avoid logging too frequently
skipping logging after 54688 examples to avoid logging too frequently
skipping logging after 54704 examples to avoid logging too frequently
train stats after 54720 examples: {'rewards_train/chosen': '-2.471', 'rewards_train/rejected': '-10.642', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1729', 'logps_train/rejected': '-241.75', 'logps_train/chosen': '-68.322', 'loss/train': '0.10365', 'examples_per_second': '5.3374', 'grad_norm': '16', 'counters/examples': 54720, 'counters/updates': 3420}
skipping logging after 54736 examples to avoid logging too frequently
skipping logging after 54752 examples to avoid logging too frequently
skipping logging after 54768 examples to avoid logging too frequently
train stats after 54784 examples: {'rewards_train/chosen': '-2.3465', 'rewards_train/rejected': '-11.411', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.0605', 'logps_train/rejected': '-263.29', 'logps_train/chosen': '-59.659', 'loss/train': '0.040824', 'examples_per_second': '4.2549', 'grad_norm': '9.4375', 'counters/examples': 54784, 'counters/updates': 3424}
skipping logging after 54800 examples to avoid logging too frequently
skipping logging after 54816 examples to avoid logging too frequently
skipping logging after 54832 examples to avoid logging too frequently
train stats after 54848 examples: {'rewards_train/chosen': '-2.5885', 'rewards_train/rejected': '-12.225', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.6398', 'logps_train/rejected': '-288.91', 'logps_train/chosen': '-67.937', 'loss/train': '0.059963', 'examples_per_second': '3.8338', 'grad_norm': '5.875', 'counters/examples': 54848, 'counters/updates': 3428}
skipping logging after 54864 examples to avoid logging too frequently
skipping logging after 54880 examples to avoid logging too frequently
skipping logging after 54896 examples to avoid logging too frequently
train stats after 54912 examples: {'rewards_train/chosen': '-2.8969', 'rewards_train/rejected': '-10.645', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.7483', 'logps_train/rejected': '-226.79', 'logps_train/chosen': '-64.272', 'loss/train': '0.10036', 'examples_per_second': '5.6596', 'grad_norm': '12.688', 'counters/examples': 54912, 'counters/updates': 3432}
skipping logging after 54928 examples to avoid logging too frequently
skipping logging after 54944 examples to avoid logging too frequently
skipping logging after 54960 examples to avoid logging too frequently
train stats after 54976 examples: {'rewards_train/chosen': '-2.5949', 'rewards_train/rejected': '-10.738', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.1443', 'logps_train/rejected': '-238.15', 'logps_train/chosen': '-59.808', 'loss/train': '0.056205', 'examples_per_second': '6.1028', 'grad_norm': '6.1875', 'counters/examples': 54976, 'counters/updates': 3436}
skipping logging after 54992 examples to avoid logging too frequently
skipping logging after 55008 examples to avoid logging too frequently
skipping logging after 55024 examples to avoid logging too frequently
train stats after 55040 examples: {'rewards_train/chosen': '-2.5949', 'rewards_train/rejected': '-12.584', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.9905', 'logps_train/rejected': '-289.43', 'logps_train/chosen': '-82.186', 'loss/train': '0.11121', 'examples_per_second': '4.5078', 'grad_norm': '15', 'counters/examples': 55040, 'counters/updates': 3440}
skipping logging after 55056 examples to avoid logging too frequently
skipping logging after 55072 examples to avoid logging too frequently
skipping logging after 55088 examples to avoid logging too frequently
train stats after 55104 examples: {'rewards_train/chosen': '-2.1825', 'rewards_train/rejected': '-10.262', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.0797', 'logps_train/rejected': '-264.77', 'logps_train/chosen': '-56.311', 'loss/train': '0.05717', 'examples_per_second': '5.3303', 'grad_norm': '6.25', 'counters/examples': 55104, 'counters/updates': 3444}
skipping logging after 55120 examples to avoid logging too frequently
skipping logging after 55136 examples to avoid logging too frequently
skipping logging after 55152 examples to avoid logging too frequently
train stats after 55168 examples: {'rewards_train/chosen': '-2.4198', 'rewards_train/rejected': '-8.5691', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.1477', 'logps_train/rejected': '-201.22', 'logps_train/chosen': '-62.607', 'loss/train': '0.089793', 'examples_per_second': '5.1594', 'grad_norm': '10.125', 'counters/examples': 55168, 'counters/updates': 3448}
skipping logging after 55184 examples to avoid logging too frequently
skipping logging after 55200 examples to avoid logging too frequently
skipping logging after 55216 examples to avoid logging too frequently
train stats after 55232 examples: {'rewards_train/chosen': '-2.1261', 'rewards_train/rejected': '-9.7351', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.608', 'logps_train/rejected': '-245.75', 'logps_train/chosen': '-66.659', 'loss/train': '0.13203', 'examples_per_second': '4.9732', 'grad_norm': '14.062', 'counters/examples': 55232, 'counters/updates': 3452}
skipping logging after 55248 examples to avoid logging too frequently
skipping logging after 55264 examples to avoid logging too frequently
skipping logging after 55280 examples to avoid logging too frequently
train stats after 55296 examples: {'rewards_train/chosen': '-2.6901', 'rewards_train/rejected': '-10.354', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.665', 'logps_train/rejected': '-264.97', 'logps_train/chosen': '-73.02', 'loss/train': '0.057768', 'examples_per_second': '4.7407', 'grad_norm': '9.1875', 'counters/examples': 55296, 'counters/updates': 3456}
skipping logging after 55312 examples to avoid logging too frequently
skipping logging after 55328 examples to avoid logging too frequently
skipping logging after 55344 examples to avoid logging too frequently
train stats after 55360 examples: {'rewards_train/chosen': '-2.9527', 'rewards_train/rejected': '-12.15', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '9.1925', 'logps_train/rejected': '-291.18', 'logps_train/chosen': '-68.567', 'loss/train': '0.07225', 'examples_per_second': '5.3039', 'grad_norm': '7.9375', 'counters/examples': 55360, 'counters/updates': 3460}
skipping logging after 55376 examples to avoid logging too frequently
skipping logging after 55392 examples to avoid logging too frequently
skipping logging after 55408 examples to avoid logging too frequently
train stats after 55424 examples: {'rewards_train/chosen': '-3.359', 'rewards_train/rejected': '-12.111', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.7542', 'logps_train/rejected': '-228.77', 'logps_train/chosen': '-68.443', 'loss/train': '0.066499', 'examples_per_second': '5.9893', 'grad_norm': '13.188', 'counters/examples': 55424, 'counters/updates': 3464}
skipping logging after 55440 examples to avoid logging too frequently
skipping logging after 55456 examples to avoid logging too frequently
skipping logging after 55472 examples to avoid logging too frequently
train stats after 55488 examples: {'rewards_train/chosen': '-3.1564', 'rewards_train/rejected': '-12.65', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.4954', 'logps_train/rejected': '-297.41', 'logps_train/chosen': '-76.362', 'loss/train': '0.082847', 'examples_per_second': '5.0264', 'grad_norm': '11.875', 'counters/examples': 55488, 'counters/updates': 3468}
skipping logging after 55504 examples to avoid logging too frequently
skipping logging after 55520 examples to avoid logging too frequently
skipping logging after 55536 examples to avoid logging too frequently
train stats after 55552 examples: {'rewards_train/chosen': '-3.2453', 'rewards_train/rejected': '-12.135', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.886', 'logps_train/rejected': '-250.89', 'logps_train/chosen': '-70.396', 'loss/train': '0.07328', 'examples_per_second': '5.7061', 'grad_norm': '9.6875', 'counters/examples': 55552, 'counters/updates': 3472}
skipping logging after 55568 examples to avoid logging too frequently
skipping logging after 55584 examples to avoid logging too frequently
skipping logging after 55600 examples to avoid logging too frequently
train stats after 55616 examples: {'rewards_train/chosen': '-3.2818', 'rewards_train/rejected': '-10.897', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.6152', 'logps_train/rejected': '-227.64', 'logps_train/chosen': '-72.844', 'loss/train': '0.046742', 'examples_per_second': '4.7416', 'grad_norm': '8.0625', 'counters/examples': 55616, 'counters/updates': 3476}
skipping logging after 55632 examples to avoid logging too frequently
skipping logging after 55648 examples to avoid logging too frequently
skipping logging after 55664 examples to avoid logging too frequently
train stats after 55680 examples: {'rewards_train/chosen': '-3.3797', 'rewards_train/rejected': '-11.657', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '8.2773', 'logps_train/rejected': '-222.35', 'logps_train/chosen': '-72.436', 'loss/train': '0.14069', 'examples_per_second': '5.1395', 'grad_norm': '11.312', 'counters/examples': 55680, 'counters/updates': 3480}
skipping logging after 55696 examples to avoid logging too frequently
skipping logging after 55712 examples to avoid logging too frequently
skipping logging after 55728 examples to avoid logging too frequently
train stats after 55744 examples: {'rewards_train/chosen': '-3.5843', 'rewards_train/rejected': '-14.261', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '10.677', 'logps_train/rejected': '-298.92', 'logps_train/chosen': '-76.023', 'loss/train': '0.14528', 'examples_per_second': '5.4291', 'grad_norm': '13.875', 'counters/examples': 55744, 'counters/updates': 3484}
skipping logging after 55760 examples to avoid logging too frequently
skipping logging after 55776 examples to avoid logging too frequently
skipping logging after 55792 examples to avoid logging too frequently
train stats after 55808 examples: {'rewards_train/chosen': '-3.4183', 'rewards_train/rejected': '-13.829', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '10.414', 'logps_train/rejected': '-280.88', 'logps_train/chosen': '-71.062', 'loss/train': '0.032552', 'examples_per_second': '5.1877', 'grad_norm': '5.5', 'counters/examples': 55808, 'counters/updates': 3488}
skipping logging after 55824 examples to avoid logging too frequently
skipping logging after 55840 examples to avoid logging too frequently
skipping logging after 55856 examples to avoid logging too frequently
train stats after 55872 examples: {'rewards_train/chosen': '-3.8682', 'rewards_train/rejected': '-13.956', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '10.086', 'logps_train/rejected': '-297.26', 'logps_train/chosen': '-91.096', 'loss/train': '0.054757', 'examples_per_second': '5.1198', 'grad_norm': '11.625', 'counters/examples': 55872, 'counters/updates': 3492}
skipping logging after 55888 examples to avoid logging too frequently
skipping logging after 55904 examples to avoid logging too frequently
skipping logging after 55920 examples to avoid logging too frequently
train stats after 55936 examples: {'rewards_train/chosen': '-3.5255', 'rewards_train/rejected': '-13.163', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '9.6337', 'logps_train/rejected': '-265', 'logps_train/chosen': '-73.283', 'loss/train': '0.097069', 'examples_per_second': '5.3555', 'grad_norm': '11.938', 'counters/examples': 55936, 'counters/updates': 3496}
skipping logging after 55952 examples to avoid logging too frequently
skipping logging after 55968 examples to avoid logging too frequently
skipping logging after 55984 examples to avoid logging too frequently
train stats after 56000 examples: {'rewards_train/chosen': '-3.5015', 'rewards_train/rejected': '-13.537', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '10.036', 'logps_train/rejected': '-285.18', 'logps_train/chosen': '-79.576', 'loss/train': '0.1274', 'examples_per_second': '5.125', 'grad_norm': '14.312', 'counters/examples': 56000, 'counters/updates': 3500}
Running evaluation after 56000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<01:00,  1.94s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:00,  2.02s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:53,  1.85s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.86s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.49s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:22,  1.30s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.24s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.33s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.34s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.27s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.30s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.26s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.30s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.48s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.41s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.61s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.42s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.42s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 56000: {'rewards_eval/chosen': '-11.803', 'rewards_eval/rejected': '-12.417', 'rewards_eval/accuracies': '0.55469', 'rewards_eval/margins': '0.61374', 'logps_eval/rejected': '-271.85', 'logps_eval/chosen': '-262.96', 'loss/eval': '2.295'}
skipping logging after 56016 examples to avoid logging too frequently
skipping logging after 56032 examples to avoid logging too frequently
skipping logging after 56048 examples to avoid logging too frequently
train stats after 56064 examples: {'rewards_train/chosen': '-3.2051', 'rewards_train/rejected': '-12.308', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.1068', 'logps_train/rejected': '-258.53', 'logps_train/chosen': '-69.016', 'loss/train': '0.063632', 'examples_per_second': '5.0291', 'grad_norm': '10.812', 'counters/examples': 56064, 'counters/updates': 3504}
skipping logging after 56080 examples to avoid logging too frequently
skipping logging after 56096 examples to avoid logging too frequently
skipping logging after 56112 examples to avoid logging too frequently
train stats after 56128 examples: {'rewards_train/chosen': '-2.8271', 'rewards_train/rejected': '-13.219', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '10.393', 'logps_train/rejected': '-316.77', 'logps_train/chosen': '-71.048', 'loss/train': '0.088638', 'examples_per_second': '5.2684', 'grad_norm': '12.562', 'counters/examples': 56128, 'counters/updates': 3508}
skipping logging after 56144 examples to avoid logging too frequently
skipping logging after 56160 examples to avoid logging too frequently
skipping logging after 56176 examples to avoid logging too frequently
train stats after 56192 examples: {'rewards_train/chosen': '-2.5893', 'rewards_train/rejected': '-10.967', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.3777', 'logps_train/rejected': '-234.67', 'logps_train/chosen': '-60.901', 'loss/train': '0.12339', 'examples_per_second': '5.4545', 'grad_norm': '14.062', 'counters/examples': 56192, 'counters/updates': 3512}
skipping logging after 56208 examples to avoid logging too frequently
skipping logging after 56224 examples to avoid logging too frequently
skipping logging after 56240 examples to avoid logging too frequently
train stats after 56256 examples: {'rewards_train/chosen': '-3.0465', 'rewards_train/rejected': '-11.529', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.4834', 'logps_train/rejected': '-246.63', 'logps_train/chosen': '-64.088', 'loss/train': '0.072994', 'examples_per_second': '5.2709', 'grad_norm': '12', 'counters/examples': 56256, 'counters/updates': 3516}
skipping logging after 56272 examples to avoid logging too frequently
skipping logging after 56288 examples to avoid logging too frequently
skipping logging after 56304 examples to avoid logging too frequently
train stats after 56320 examples: {'rewards_train/chosen': '-3.2307', 'rewards_train/rejected': '-14.312', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '11.08', 'logps_train/rejected': '-309.42', 'logps_train/chosen': '-70.272', 'loss/train': '0.18774', 'examples_per_second': '5.3107', 'grad_norm': '17.5', 'counters/examples': 56320, 'counters/updates': 3520}
skipping logging after 56336 examples to avoid logging too frequently
skipping logging after 56352 examples to avoid logging too frequently
skipping logging after 56368 examples to avoid logging too frequently
train stats after 56384 examples: {'rewards_train/chosen': '-2.9512', 'rewards_train/rejected': '-11.874', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.9265', 'logps_train/rejected': '-255.23', 'logps_train/chosen': '-73.812', 'loss/train': '0.060037', 'examples_per_second': '4.8526', 'grad_norm': '14.875', 'counters/examples': 56384, 'counters/updates': 3524}
skipping logging after 56400 examples to avoid logging too frequently
skipping logging after 56416 examples to avoid logging too frequently
skipping logging after 56432 examples to avoid logging too frequently
train stats after 56448 examples: {'rewards_train/chosen': '-3.4857', 'rewards_train/rejected': '-11.266', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.7798', 'logps_train/rejected': '-236.13', 'logps_train/chosen': '-72.721', 'loss/train': '0.26977', 'examples_per_second': '4.847', 'grad_norm': '16', 'counters/examples': 56448, 'counters/updates': 3528}
skipping logging after 56464 examples to avoid logging too frequently
skipping logging after 56480 examples to avoid logging too frequently
skipping logging after 56496 examples to avoid logging too frequently
train stats after 56512 examples: {'rewards_train/chosen': '-2.4104', 'rewards_train/rejected': '-11.18', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.766', 'logps_train/rejected': '-236.3', 'logps_train/chosen': '-60.43', 'loss/train': '0.063427', 'examples_per_second': '5.2652', 'grad_norm': '9.625', 'counters/examples': 56512, 'counters/updates': 3532}
skipping logging after 56528 examples to avoid logging too frequently
skipping logging after 56544 examples to avoid logging too frequently
skipping logging after 56560 examples to avoid logging too frequently
train stats after 56576 examples: {'rewards_train/chosen': '-3.143', 'rewards_train/rejected': '-13.383', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '10.242', 'logps_train/rejected': '-279.46', 'logps_train/chosen': '-71.47', 'loss/train': '0.060588', 'examples_per_second': '5.3383', 'grad_norm': '10.125', 'counters/examples': 56576, 'counters/updates': 3536}
skipping logging after 56592 examples to avoid logging too frequently
skipping logging after 56608 examples to avoid logging too frequently
skipping logging after 56624 examples to avoid logging too frequently
train stats after 56640 examples: {'rewards_train/chosen': '-2.805', 'rewards_train/rejected': '-11.329', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.5244', 'logps_train/rejected': '-241.5', 'logps_train/chosen': '-66.121', 'loss/train': '0.10725', 'examples_per_second': '4.419', 'grad_norm': '16.625', 'counters/examples': 56640, 'counters/updates': 3540}
skipping logging after 56656 examples to avoid logging too frequently
skipping logging after 56672 examples to avoid logging too frequently
skipping logging after 56688 examples to avoid logging too frequently
train stats after 56704 examples: {'rewards_train/chosen': '-2.7565', 'rewards_train/rejected': '-11.279', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.5249', 'logps_train/rejected': '-268.16', 'logps_train/chosen': '-75.916', 'loss/train': '0.1029', 'examples_per_second': '4.7824', 'grad_norm': '22.875', 'counters/examples': 56704, 'counters/updates': 3544}
skipping logging after 56720 examples to avoid logging too frequently
skipping logging after 56736 examples to avoid logging too frequently
skipping logging after 56752 examples to avoid logging too frequently
train stats after 56768 examples: {'rewards_train/chosen': '-2.4634', 'rewards_train/rejected': '-9.9119', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '7.4493', 'logps_train/rejected': '-216.51', 'logps_train/chosen': '-60.676', 'loss/train': '0.11809', 'examples_per_second': '5.5992', 'grad_norm': '12.188', 'counters/examples': 56768, 'counters/updates': 3548}
skipping logging after 56784 examples to avoid logging too frequently
skipping logging after 56800 examples to avoid logging too frequently
skipping logging after 56816 examples to avoid logging too frequently
train stats after 56832 examples: {'rewards_train/chosen': '-2.0955', 'rewards_train/rejected': '-10.791', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.6974', 'logps_train/rejected': '-253.95', 'logps_train/chosen': '-52.61', 'loss/train': '0.062692', 'examples_per_second': '6.1918', 'grad_norm': '4.2812', 'counters/examples': 56832, 'counters/updates': 3552}
skipping logging after 56848 examples to avoid logging too frequently
skipping logging after 56864 examples to avoid logging too frequently
skipping logging after 56880 examples to avoid logging too frequently
train stats after 56896 examples: {'rewards_train/chosen': '-2.3988', 'rewards_train/rejected': '-10.257', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.8571', 'logps_train/rejected': '-229.45', 'logps_train/chosen': '-62.178', 'loss/train': '0.071194', 'examples_per_second': '5.0912', 'grad_norm': '11.875', 'counters/examples': 56896, 'counters/updates': 3556}
skipping logging after 56912 examples to avoid logging too frequently
skipping logging after 56928 examples to avoid logging too frequently
skipping logging after 56944 examples to avoid logging too frequently
train stats after 56960 examples: {'rewards_train/chosen': '-2.6367', 'rewards_train/rejected': '-9.7947', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.1594', 'logps_train/rejected': '-210.14', 'logps_train/chosen': '-58.441', 'loss/train': '0.06279', 'examples_per_second': '6.2093', 'grad_norm': '10.25', 'counters/examples': 56960, 'counters/updates': 3560}
skipping logging after 56976 examples to avoid logging too frequently
skipping logging after 56992 examples to avoid logging too frequently
skipping logging after 57008 examples to avoid logging too frequently
train stats after 57024 examples: {'rewards_train/chosen': '-2.8455', 'rewards_train/rejected': '-10.649', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.8044', 'logps_train/rejected': '-226.32', 'logps_train/chosen': '-59.621', 'loss/train': '0.10633', 'examples_per_second': '6.2205', 'grad_norm': '13.062', 'counters/examples': 57024, 'counters/updates': 3564}
skipping logging after 57040 examples to avoid logging too frequently
skipping logging after 57056 examples to avoid logging too frequently
skipping logging after 57072 examples to avoid logging too frequently
train stats after 57088 examples: {'rewards_train/chosen': '-2.7742', 'rewards_train/rejected': '-10.946', 'rewards_train/accuracies': '0.89062', 'rewards_train/margins': '8.1729', 'logps_train/rejected': '-236.8', 'logps_train/chosen': '-71.559', 'loss/train': '0.24577', 'examples_per_second': '5.4157', 'grad_norm': '22.75', 'counters/examples': 57088, 'counters/updates': 3568}
skipping logging after 57104 examples to avoid logging too frequently
skipping logging after 57120 examples to avoid logging too frequently
skipping logging after 57136 examples to avoid logging too frequently
train stats after 57152 examples: {'rewards_train/chosen': '-2.313', 'rewards_train/rejected': '-10.805', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.4937', 'logps_train/rejected': '-264.12', 'logps_train/chosen': '-66.649', 'loss/train': '0.054598', 'examples_per_second': '4.6992', 'grad_norm': '12.375', 'counters/examples': 57152, 'counters/updates': 3572}
skipping logging after 57168 examples to avoid logging too frequently
skipping logging after 57184 examples to avoid logging too frequently
skipping logging after 57200 examples to avoid logging too frequently
train stats after 57216 examples: {'rewards_train/chosen': '-2.5046', 'rewards_train/rejected': '-10.504', 'rewards_train/accuracies': '0.89062', 'rewards_train/margins': '8.0007', 'logps_train/rejected': '-228.25', 'logps_train/chosen': '-66.017', 'loss/train': '0.19683', 'examples_per_second': '6.2424', 'grad_norm': '15.312', 'counters/examples': 57216, 'counters/updates': 3576}
skipping logging after 57232 examples to avoid logging too frequently
skipping logging after 57248 examples to avoid logging too frequently
skipping logging after 57264 examples to avoid logging too frequently
train stats after 57280 examples: {'rewards_train/chosen': '-2.9765', 'rewards_train/rejected': '-11.079', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.1025', 'logps_train/rejected': '-255.62', 'logps_train/chosen': '-72.277', 'loss/train': '0.22013', 'examples_per_second': '4.9206', 'grad_norm': '23.5', 'counters/examples': 57280, 'counters/updates': 3580}
skipping logging after 57296 examples to avoid logging too frequently
skipping logging after 57312 examples to avoid logging too frequently
skipping logging after 57328 examples to avoid logging too frequently
train stats after 57344 examples: {'rewards_train/chosen': '-2.5839', 'rewards_train/rejected': '-10.537', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.9553', 'logps_train/rejected': '-227.98', 'logps_train/chosen': '-60.515', 'loss/train': '0.062708', 'examples_per_second': '6.1204', 'grad_norm': '13.562', 'counters/examples': 57344, 'counters/updates': 3584}
skipping logging after 57360 examples to avoid logging too frequently
skipping logging after 57376 examples to avoid logging too frequently
skipping logging after 57392 examples to avoid logging too frequently
train stats after 57408 examples: {'rewards_train/chosen': '-2.64', 'rewards_train/rejected': '-10.161', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.5183', 'logps_train/rejected': '-218.63', 'logps_train/chosen': '-75.143', 'loss/train': '0.070886', 'examples_per_second': '5.2037', 'grad_norm': '12', 'counters/examples': 57408, 'counters/updates': 3588}
skipping logging after 57424 examples to avoid logging too frequently
skipping logging after 57440 examples to avoid logging too frequently
skipping logging after 57456 examples to avoid logging too frequently
train stats after 57472 examples: {'rewards_train/chosen': '-2.7101', 'rewards_train/rejected': '-10.364', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '7.6537', 'logps_train/rejected': '-225.14', 'logps_train/chosen': '-61.646', 'loss/train': '0.10484', 'examples_per_second': '6.3213', 'grad_norm': '10.5', 'counters/examples': 57472, 'counters/updates': 3592}
skipping logging after 57488 examples to avoid logging too frequently
skipping logging after 57504 examples to avoid logging too frequently
skipping logging after 57520 examples to avoid logging too frequently
train stats after 57536 examples: {'rewards_train/chosen': '-2.5931', 'rewards_train/rejected': '-11.699', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.1077', 'logps_train/rejected': '-278.76', 'logps_train/chosen': '-69.005', 'loss/train': '0.045223', 'examples_per_second': '5.7283', 'grad_norm': '8.75', 'counters/examples': 57536, 'counters/updates': 3596}
skipping logging after 57552 examples to avoid logging too frequently
skipping logging after 57568 examples to avoid logging too frequently
skipping logging after 57584 examples to avoid logging too frequently
train stats after 57600 examples: {'rewards_train/chosen': '-2.4878', 'rewards_train/rejected': '-10.848', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.3604', 'logps_train/rejected': '-265.18', 'logps_train/chosen': '-72.53', 'loss/train': '0.18514', 'examples_per_second': '4.8817', 'grad_norm': '26.625', 'counters/examples': 57600, 'counters/updates': 3600}
skipping logging after 57616 examples to avoid logging too frequently
skipping logging after 57632 examples to avoid logging too frequently
skipping logging after 57648 examples to avoid logging too frequently
train stats after 57664 examples: {'rewards_train/chosen': '-2.0736', 'rewards_train/rejected': '-10.882', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.8089', 'logps_train/rejected': '-269.71', 'logps_train/chosen': '-58.532', 'loss/train': '0.06534', 'examples_per_second': '5.0136', 'grad_norm': '9.9375', 'counters/examples': 57664, 'counters/updates': 3604}
skipping logging after 57680 examples to avoid logging too frequently
skipping logging after 57696 examples to avoid logging too frequently
skipping logging after 57712 examples to avoid logging too frequently
train stats after 57728 examples: {'rewards_train/chosen': '-2.1423', 'rewards_train/rejected': '-10.256', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.114', 'logps_train/rejected': '-233.89', 'logps_train/chosen': '-60.644', 'loss/train': '0.047102', 'examples_per_second': '6.109', 'grad_norm': '6.8125', 'counters/examples': 57728, 'counters/updates': 3608}
skipping logging after 57744 examples to avoid logging too frequently
skipping logging after 57760 examples to avoid logging too frequently
skipping logging after 57776 examples to avoid logging too frequently
train stats after 57792 examples: {'rewards_train/chosen': '-2.6369', 'rewards_train/rejected': '-11.256', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.6194', 'logps_train/rejected': '-267.04', 'logps_train/chosen': '-66.815', 'loss/train': '0.048736', 'examples_per_second': '4.1265', 'grad_norm': '5.7812', 'counters/examples': 57792, 'counters/updates': 3612}
skipping logging after 57808 examples to avoid logging too frequently
skipping logging after 57824 examples to avoid logging too frequently
skipping logging after 57840 examples to avoid logging too frequently
train stats after 57856 examples: {'rewards_train/chosen': '-2.9184', 'rewards_train/rejected': '-11.519', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.5973', 'logps_train/rejected': '-271.86', 'logps_train/chosen': '-68.01', 'loss/train': '0.072811', 'examples_per_second': '5.4581', 'grad_norm': '14.125', 'counters/examples': 57856, 'counters/updates': 3616}
skipping logging after 57872 examples to avoid logging too frequently
skipping logging after 57888 examples to avoid logging too frequently
skipping logging after 57904 examples to avoid logging too frequently
train stats after 57920 examples: {'rewards_train/chosen': '-2.875', 'rewards_train/rejected': '-11.272', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '8.3969', 'logps_train/rejected': '-252.37', 'logps_train/chosen': '-60.984', 'loss/train': '0.12574', 'examples_per_second': '5.7531', 'grad_norm': '12.625', 'counters/examples': 57920, 'counters/updates': 3620}
skipping logging after 57936 examples to avoid logging too frequently
skipping logging after 57952 examples to avoid logging too frequently
skipping logging after 57968 examples to avoid logging too frequently
train stats after 57984 examples: {'rewards_train/chosen': '-3.5728', 'rewards_train/rejected': '-10.872', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.3005', 'logps_train/rejected': '-228.41', 'logps_train/chosen': '-79.119', 'loss/train': '0.14446', 'examples_per_second': '4.8857', 'grad_norm': '8.5625', 'counters/examples': 57984, 'counters/updates': 3624}
skipping logging after 58000 examples to avoid logging too frequently
skipping logging after 58016 examples to avoid logging too frequently
skipping logging after 58032 examples to avoid logging too frequently
train stats after 58048 examples: {'rewards_train/chosen': '-2.6308', 'rewards_train/rejected': '-11.935', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.3054', 'logps_train/rejected': '-276.9', 'logps_train/chosen': '-71.681', 'loss/train': '0.04828', 'examples_per_second': '4.7663', 'grad_norm': '8.125', 'counters/examples': 58048, 'counters/updates': 3628}
skipping logging after 58064 examples to avoid logging too frequently
skipping logging after 58080 examples to avoid logging too frequently
skipping logging after 58096 examples to avoid logging too frequently
train stats after 58112 examples: {'rewards_train/chosen': '-2.4672', 'rewards_train/rejected': '-11.219', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.752', 'logps_train/rejected': '-252.63', 'logps_train/chosen': '-64.502', 'loss/train': '0.08214', 'examples_per_second': '5.0131', 'grad_norm': '15.625', 'counters/examples': 58112, 'counters/updates': 3632}
skipping logging after 58128 examples to avoid logging too frequently
skipping logging after 58144 examples to avoid logging too frequently
skipping logging after 58160 examples to avoid logging too frequently
train stats after 58176 examples: {'rewards_train/chosen': '-2.4123', 'rewards_train/rejected': '-10.517', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.1045', 'logps_train/rejected': '-229.77', 'logps_train/chosen': '-68.914', 'loss/train': '0.16698', 'examples_per_second': '5.4022', 'grad_norm': '20.125', 'counters/examples': 58176, 'counters/updates': 3636}
skipping logging after 58192 examples to avoid logging too frequently
skipping logging after 58208 examples to avoid logging too frequently
skipping logging after 58224 examples to avoid logging too frequently
train stats after 58240 examples: {'rewards_train/chosen': '-1.852', 'rewards_train/rejected': '-9.9885', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.135', 'logps_train/rejected': '-234.97', 'logps_train/chosen': '-59.731', 'loss/train': '0.073175', 'examples_per_second': '5.5788', 'grad_norm': '4.4375', 'counters/examples': 58240, 'counters/updates': 3640}
skipping logging after 58256 examples to avoid logging too frequently
skipping logging after 58272 examples to avoid logging too frequently
skipping logging after 58288 examples to avoid logging too frequently
train stats after 58304 examples: {'rewards_train/chosen': '-2.4102', 'rewards_train/rejected': '-10.523', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.1149', 'logps_train/rejected': '-232.89', 'logps_train/chosen': '-60.303', 'loss/train': '0.050145', 'examples_per_second': '7.3567', 'grad_norm': '7.5312', 'counters/examples': 58304, 'counters/updates': 3644}
skipping logging after 58320 examples to avoid logging too frequently
skipping logging after 58336 examples to avoid logging too frequently
skipping logging after 58352 examples to avoid logging too frequently
train stats after 58368 examples: {'rewards_train/chosen': '-2.0369', 'rewards_train/rejected': '-10.754', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.7163', 'logps_train/rejected': '-268.39', 'logps_train/chosen': '-62.73', 'loss/train': '0.10145', 'examples_per_second': '5.0411', 'grad_norm': '15.562', 'counters/examples': 58368, 'counters/updates': 3648}
skipping logging after 58384 examples to avoid logging too frequently
skipping logging after 58400 examples to avoid logging too frequently
skipping logging after 58416 examples to avoid logging too frequently
train stats after 58432 examples: {'rewards_train/chosen': '-1.9948', 'rewards_train/rejected': '-10.687', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.6945', 'logps_train/rejected': '-261.61', 'logps_train/chosen': '-66.662', 'loss/train': '0.12745', 'examples_per_second': '5.1131', 'grad_norm': '15.875', 'counters/examples': 58432, 'counters/updates': 3652}
skipping logging after 58448 examples to avoid logging too frequently
skipping logging after 58464 examples to avoid logging too frequently
skipping logging after 58480 examples to avoid logging too frequently
train stats after 58496 examples: {'rewards_train/chosen': '-2.2793', 'rewards_train/rejected': '-9.3662', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.0888', 'logps_train/rejected': '-227.9', 'logps_train/chosen': '-59.502', 'loss/train': '0.086586', 'examples_per_second': '5.3648', 'grad_norm': '16', 'counters/examples': 58496, 'counters/updates': 3656}
skipping logging after 58512 examples to avoid logging too frequently
skipping logging after 58528 examples to avoid logging too frequently
skipping logging after 58544 examples to avoid logging too frequently
train stats after 58560 examples: {'rewards_train/chosen': '-2.2471', 'rewards_train/rejected': '-9.7144', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.4674', 'logps_train/rejected': '-264.26', 'logps_train/chosen': '-68.18', 'loss/train': '0.082378', 'examples_per_second': '4.3542', 'grad_norm': '13.562', 'counters/examples': 58560, 'counters/updates': 3660}
skipping logging after 58576 examples to avoid logging too frequently
skipping logging after 58592 examples to avoid logging too frequently
skipping logging after 58608 examples to avoid logging too frequently
train stats after 58624 examples: {'rewards_train/chosen': '-2.081', 'rewards_train/rejected': '-9.5084', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.4271', 'logps_train/rejected': '-241.07', 'logps_train/chosen': '-67.822', 'loss/train': '0.065362', 'examples_per_second': '4.8916', 'grad_norm': '5.8125', 'counters/examples': 58624, 'counters/updates': 3664}
skipping logging after 58640 examples to avoid logging too frequently
skipping logging after 58656 examples to avoid logging too frequently
skipping logging after 58672 examples to avoid logging too frequently
train stats after 58688 examples: {'rewards_train/chosen': '-2.3259', 'rewards_train/rejected': '-9.1262', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '6.7993', 'logps_train/rejected': '-216.43', 'logps_train/chosen': '-61.278', 'loss/train': '0.093767', 'examples_per_second': '4.7434', 'grad_norm': '12.625', 'counters/examples': 58688, 'counters/updates': 3668}
skipping logging after 58704 examples to avoid logging too frequently
skipping logging after 58720 examples to avoid logging too frequently
skipping logging after 58736 examples to avoid logging too frequently
train stats after 58752 examples: {'rewards_train/chosen': '-2.4768', 'rewards_train/rejected': '-9.2292', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.7511', 'logps_train/rejected': '-201.45', 'logps_train/chosen': '-60.861', 'loss/train': '0.1161', 'examples_per_second': '5.636', 'grad_norm': '19.125', 'counters/examples': 58752, 'counters/updates': 3672}
skipping logging after 58768 examples to avoid logging too frequently
skipping logging after 58784 examples to avoid logging too frequently
skipping logging after 58800 examples to avoid logging too frequently
train stats after 58816 examples: {'rewards_train/chosen': '-2.4524', 'rewards_train/rejected': '-11.345', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.8923', 'logps_train/rejected': '-300.68', 'logps_train/chosen': '-81.757', 'loss/train': '0.064136', 'examples_per_second': '4.2595', 'grad_norm': '6.5938', 'counters/examples': 58816, 'counters/updates': 3676}
skipping logging after 58832 examples to avoid logging too frequently
skipping logging after 58848 examples to avoid logging too frequently
skipping logging after 58864 examples to avoid logging too frequently
train stats after 58880 examples: {'rewards_train/chosen': '-2.2019', 'rewards_train/rejected': '-10.197', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.9957', 'logps_train/rejected': '-239.92', 'logps_train/chosen': '-63.066', 'loss/train': '0.077954', 'examples_per_second': '5.0229', 'grad_norm': '9.3125', 'counters/examples': 58880, 'counters/updates': 3680}
skipping logging after 58896 examples to avoid logging too frequently
skipping logging after 58912 examples to avoid logging too frequently
skipping logging after 58928 examples to avoid logging too frequently
train stats after 58944 examples: {'rewards_train/chosen': '-2.8329', 'rewards_train/rejected': '-10.698', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.8647', 'logps_train/rejected': '-245.37', 'logps_train/chosen': '-68.38', 'loss/train': '0.054127', 'examples_per_second': '5.2962', 'grad_norm': '7.625', 'counters/examples': 58944, 'counters/updates': 3684}
skipping logging after 58960 examples to avoid logging too frequently
skipping logging after 58976 examples to avoid logging too frequently
skipping logging after 58992 examples to avoid logging too frequently
train stats after 59008 examples: {'rewards_train/chosen': '-2.4687', 'rewards_train/rejected': '-11.593', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.1278', 'logps_train/rejected': '-272.48', 'logps_train/chosen': '-68.604', 'loss/train': '0.088155', 'examples_per_second': '4.6483', 'grad_norm': '12.125', 'counters/examples': 59008, 'counters/updates': 3688}
skipping logging after 59024 examples to avoid logging too frequently
skipping logging after 59040 examples to avoid logging too frequently
skipping logging after 59056 examples to avoid logging too frequently
train stats after 59072 examples: {'rewards_train/chosen': '-3.4072', 'rewards_train/rejected': '-12.23', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.8221', 'logps_train/rejected': '-254.97', 'logps_train/chosen': '-71.021', 'loss/train': '0.087961', 'examples_per_second': '5.1372', 'grad_norm': '15.438', 'counters/examples': 59072, 'counters/updates': 3692}
skipping logging after 59088 examples to avoid logging too frequently
skipping logging after 59104 examples to avoid logging too frequently
skipping logging after 59120 examples to avoid logging too frequently
train stats after 59136 examples: {'rewards_train/chosen': '-3.2347', 'rewards_train/rejected': '-13.409', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '10.172', 'logps_train/rejected': '-299.16', 'logps_train/chosen': '-78.316', 'loss/train': '0.12772', 'examples_per_second': '4.2689', 'grad_norm': '20.75', 'counters/examples': 59136, 'counters/updates': 3696}
skipping logging after 59152 examples to avoid logging too frequently
skipping logging after 59168 examples to avoid logging too frequently
skipping logging after 59184 examples to avoid logging too frequently
train stats after 59200 examples: {'rewards_train/chosen': '-2.8419', 'rewards_train/rejected': '-11.173', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '8.327', 'logps_train/rejected': '-246.5', 'logps_train/chosen': '-66.406', 'loss/train': '0.062818', 'examples_per_second': '5.5386', 'grad_norm': '7.0312', 'counters/examples': 59200, 'counters/updates': 3700}
skipping logging after 59216 examples to avoid logging too frequently
skipping logging after 59232 examples to avoid logging too frequently
skipping logging after 59248 examples to avoid logging too frequently
train stats after 59264 examples: {'rewards_train/chosen': '-3.2316', 'rewards_train/rejected': '-12.086', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.8536', 'logps_train/rejected': '-255.82', 'logps_train/chosen': '-77.812', 'loss/train': '0.20049', 'examples_per_second': '5.7927', 'grad_norm': '16.625', 'counters/examples': 59264, 'counters/updates': 3704}
skipping logging after 59280 examples to avoid logging too frequently
skipping logging after 59296 examples to avoid logging too frequently
skipping logging after 59312 examples to avoid logging too frequently
train stats after 59328 examples: {'rewards_train/chosen': '-2.4716', 'rewards_train/rejected': '-10.783', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.3119', 'logps_train/rejected': '-248.92', 'logps_train/chosen': '-64.203', 'loss/train': '0.061424', 'examples_per_second': '6.0138', 'grad_norm': '6.625', 'counters/examples': 59328, 'counters/updates': 3708}
skipping logging after 59344 examples to avoid logging too frequently
skipping logging after 59360 examples to avoid logging too frequently
skipping logging after 59376 examples to avoid logging too frequently
train stats after 59392 examples: {'rewards_train/chosen': '-2.3843', 'rewards_train/rejected': '-10.765', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.3831', 'logps_train/rejected': '-245.96', 'logps_train/chosen': '-73.312', 'loss/train': '0.05668', 'examples_per_second': '4.341', 'grad_norm': '6.4688', 'counters/examples': 59392, 'counters/updates': 3712}
skipping logging after 59408 examples to avoid logging too frequently
skipping logging after 59424 examples to avoid logging too frequently
skipping logging after 59440 examples to avoid logging too frequently
train stats after 59456 examples: {'rewards_train/chosen': '-2.8232', 'rewards_train/rejected': '-10.376', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.5527', 'logps_train/rejected': '-221.83', 'logps_train/chosen': '-57.11', 'loss/train': '0.10627', 'examples_per_second': '4.9664', 'grad_norm': '10.188', 'counters/examples': 59456, 'counters/updates': 3716}
skipping logging after 59472 examples to avoid logging too frequently
skipping logging after 59488 examples to avoid logging too frequently
skipping logging after 59504 examples to avoid logging too frequently
train stats after 59520 examples: {'rewards_train/chosen': '-3.1509', 'rewards_train/rejected': '-13.438', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '10.289', 'logps_train/rejected': '-300.78', 'logps_train/chosen': '-75.768', 'loss/train': '0.10559', 'examples_per_second': '4.8745', 'grad_norm': '11.812', 'counters/examples': 59520, 'counters/updates': 3720}
skipping logging after 59536 examples to avoid logging too frequently
skipping logging after 59552 examples to avoid logging too frequently
skipping logging after 59568 examples to avoid logging too frequently
train stats after 59584 examples: {'rewards_train/chosen': '-2.8915', 'rewards_train/rejected': '-11.166', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.2731', 'logps_train/rejected': '-240.01', 'logps_train/chosen': '-66.559', 'loss/train': '0.073344', 'examples_per_second': '5.6111', 'grad_norm': '9.125', 'counters/examples': 59584, 'counters/updates': 3724}
skipping logging after 59600 examples to avoid logging too frequently
skipping logging after 59616 examples to avoid logging too frequently
skipping logging after 59632 examples to avoid logging too frequently
train stats after 59648 examples: {'rewards_train/chosen': '-3.2661', 'rewards_train/rejected': '-12.388', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '9.1163', 'logps_train/rejected': '-277.95', 'logps_train/chosen': '-73.291', 'loss/train': '0.024119', 'examples_per_second': '5.5525', 'grad_norm': '6.8125', 'counters/examples': 59648, 'counters/updates': 3728}
skipping logging after 59664 examples to avoid logging too frequently
skipping logging after 59680 examples to avoid logging too frequently
skipping logging after 59696 examples to avoid logging too frequently
train stats after 59712 examples: {'rewards_train/chosen': '-3.0291', 'rewards_train/rejected': '-11.976', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.9452', 'logps_train/rejected': '-250.69', 'logps_train/chosen': '-63.66', 'loss/train': '0.11577', 'examples_per_second': '5.3737', 'grad_norm': '10', 'counters/examples': 59712, 'counters/updates': 3732}
skipping logging after 59728 examples to avoid logging too frequently
skipping logging after 59744 examples to avoid logging too frequently
skipping logging after 59760 examples to avoid logging too frequently
train stats after 59776 examples: {'rewards_train/chosen': '-2.8523', 'rewards_train/rejected': '-13.212', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '10.36', 'logps_train/rejected': '-299.42', 'logps_train/chosen': '-75.406', 'loss/train': '0.047479', 'examples_per_second': '4.9222', 'grad_norm': '4.8438', 'counters/examples': 59776, 'counters/updates': 3736}
skipping logging after 59792 examples to avoid logging too frequently
skipping logging after 59808 examples to avoid logging too frequently
skipping logging after 59824 examples to avoid logging too frequently
train stats after 59840 examples: {'rewards_train/chosen': '-2.8565', 'rewards_train/rejected': '-11.942', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.0828', 'logps_train/rejected': '-233.31', 'logps_train/chosen': '-69.545', 'loss/train': '0.088372', 'examples_per_second': '4.923', 'grad_norm': '10.562', 'counters/examples': 59840, 'counters/updates': 3740}
skipping logging after 59856 examples to avoid logging too frequently
skipping logging after 59872 examples to avoid logging too frequently
skipping logging after 59888 examples to avoid logging too frequently
train stats after 59904 examples: {'rewards_train/chosen': '-2.9535', 'rewards_train/rejected': '-12.904', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.9518', 'logps_train/rejected': '-305.59', 'logps_train/chosen': '-70.974', 'loss/train': '0.07609', 'examples_per_second': '4.7525', 'grad_norm': '15.375', 'counters/examples': 59904, 'counters/updates': 3744}
skipping logging after 59920 examples to avoid logging too frequently
skipping logging after 59936 examples to avoid logging too frequently
skipping logging after 59952 examples to avoid logging too frequently
train stats after 59968 examples: {'rewards_train/chosen': '-2.6099', 'rewards_train/rejected': '-11.976', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.3669', 'logps_train/rejected': '-290.7', 'logps_train/chosen': '-64.688', 'loss/train': '0.031298', 'examples_per_second': '4.8215', 'grad_norm': '4.6875', 'counters/examples': 59968, 'counters/updates': 3748}
skipping logging after 59984 examples to avoid logging too frequently
skipping logging after 60000 examples to avoid logging too frequently
Running evaluation after 60000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:10,  2.27s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:04,  2.15s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:55,  1.91s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.90s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.55s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.66s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.49s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:36,  1.57s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.50s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:22,  1.30s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.24s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.33s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.34s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:14,  1.27s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:33<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.30s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.27s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:37<00:07,  1.30s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:39<00:07,  1.48s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.41s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.62s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.42s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.42s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.44s/it]
eval after 60000: {'rewards_eval/chosen': '-11.097', 'rewards_eval/rejected': '-11.555', 'rewards_eval/accuracies': '0.53516', 'rewards_eval/margins': '0.45767', 'logps_eval/rejected': '-263.21', 'logps_eval/chosen': '-255.9', 'loss/eval': '2.1809'}
skipping logging after 60016 examples to avoid logging too frequently
train stats after 60032 examples: {'rewards_train/chosen': '-2.8419', 'rewards_train/rejected': '-11.075', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.2313', 'logps_train/rejected': '-248.69', 'logps_train/chosen': '-64.553', 'loss/train': '0.090258', 'examples_per_second': '5.2986', 'grad_norm': '11.312', 'counters/examples': 60032, 'counters/updates': 3752}
skipping logging after 60048 examples to avoid logging too frequently
skipping logging after 60064 examples to avoid logging too frequently
skipping logging after 60080 examples to avoid logging too frequently
train stats after 60096 examples: {'rewards_train/chosen': '-2.7874', 'rewards_train/rejected': '-13.145', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '10.359', 'logps_train/rejected': '-300.39', 'logps_train/chosen': '-79.773', 'loss/train': '0.10144', 'examples_per_second': '4.3071', 'grad_norm': '15.875', 'counters/examples': 60096, 'counters/updates': 3756}
skipping logging after 60112 examples to avoid logging too frequently
skipping logging after 60128 examples to avoid logging too frequently
skipping logging after 60144 examples to avoid logging too frequently
train stats after 60160 examples: {'rewards_train/chosen': '-2.8644', 'rewards_train/rejected': '-12.579', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.7168', 'logps_train/rejected': '-305.1', 'logps_train/chosen': '-74.509', 'loss/train': '0.11064', 'examples_per_second': '4.6847', 'grad_norm': '16.25', 'counters/examples': 60160, 'counters/updates': 3760}
skipping logging after 60176 examples to avoid logging too frequently
skipping logging after 60192 examples to avoid logging too frequently
skipping logging after 60208 examples to avoid logging too frequently
train stats after 60224 examples: {'rewards_train/chosen': '-3.0375', 'rewards_train/rejected': '-11.022', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.9822', 'logps_train/rejected': '-235.14', 'logps_train/chosen': '-68.65', 'loss/train': '0.087296', 'examples_per_second': '5.6736', 'grad_norm': '9.9375', 'counters/examples': 60224, 'counters/updates': 3764}
skipping logging after 60240 examples to avoid logging too frequently
skipping logging after 60256 examples to avoid logging too frequently
skipping logging after 60272 examples to avoid logging too frequently
train stats after 60288 examples: {'rewards_train/chosen': '-3.1518', 'rewards_train/rejected': '-12.155', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.9988', 'logps_train/rejected': '-271.93', 'logps_train/chosen': '-71.189', 'loss/train': '0.045603', 'examples_per_second': '5.4932', 'grad_norm': '4.7812', 'counters/examples': 60288, 'counters/updates': 3768}
skipping logging after 60304 examples to avoid logging too frequently
skipping logging after 60320 examples to avoid logging too frequently
skipping logging after 60336 examples to avoid logging too frequently
train stats after 60352 examples: {'rewards_train/chosen': '-2.899', 'rewards_train/rejected': '-11.584', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.6873', 'logps_train/rejected': '-252.25', 'logps_train/chosen': '-69.108', 'loss/train': '0.075239', 'examples_per_second': '5.1077', 'grad_norm': '12.438', 'counters/examples': 60352, 'counters/updates': 3772}
skipping logging after 60368 examples to avoid logging too frequently
skipping logging after 60384 examples to avoid logging too frequently
skipping logging after 60400 examples to avoid logging too frequently
train stats after 60416 examples: {'rewards_train/chosen': '-2.9255', 'rewards_train/rejected': '-11.06', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.1326', 'logps_train/rejected': '-254.93', 'logps_train/chosen': '-70.427', 'loss/train': '0.13506', 'examples_per_second': '6.1053', 'grad_norm': '13.938', 'counters/examples': 60416, 'counters/updates': 3776}
skipping logging after 60432 examples to avoid logging too frequently
skipping logging after 60448 examples to avoid logging too frequently
skipping logging after 60464 examples to avoid logging too frequently
train stats after 60480 examples: {'rewards_train/chosen': '-3.0921', 'rewards_train/rejected': '-10.802', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.7146', 'logps_train/rejected': '-234.42', 'logps_train/chosen': '-74.783', 'loss/train': '0.04814', 'examples_per_second': '5.1811', 'grad_norm': '5.6875', 'counters/examples': 60480, 'counters/updates': 3780}
skipping logging after 60496 examples to avoid logging too frequently
skipping logging after 60512 examples to avoid logging too frequently
skipping logging after 60528 examples to avoid logging too frequently
train stats after 60544 examples: {'rewards_train/chosen': '-2.6852', 'rewards_train/rejected': '-10.793', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.1101', 'logps_train/rejected': '-224.62', 'logps_train/chosen': '-75.103', 'loss/train': '0.032556', 'examples_per_second': '5.6946', 'grad_norm': '6.625', 'counters/examples': 60544, 'counters/updates': 3784}
skipping logging after 60560 examples to avoid logging too frequently
skipping logging after 60576 examples to avoid logging too frequently
skipping logging after 60592 examples to avoid logging too frequently
train stats after 60608 examples: {'rewards_train/chosen': '-3.2557', 'rewards_train/rejected': '-12.067', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.8129', 'logps_train/rejected': '-245.2', 'logps_train/chosen': '-73.188', 'loss/train': '0.035294', 'examples_per_second': '5.2443', 'grad_norm': '4.1562', 'counters/examples': 60608, 'counters/updates': 3788}
skipping logging after 60624 examples to avoid logging too frequently
skipping logging after 60640 examples to avoid logging too frequently
skipping logging after 60656 examples to avoid logging too frequently
train stats after 60672 examples: {'rewards_train/chosen': '-3.5792', 'rewards_train/rejected': '-13.597', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '10.018', 'logps_train/rejected': '-289.77', 'logps_train/chosen': '-83.569', 'loss/train': '0.056091', 'examples_per_second': '4.8043', 'grad_norm': '9.375', 'counters/examples': 60672, 'counters/updates': 3792}
skipping logging after 60688 examples to avoid logging too frequently
skipping logging after 60704 examples to avoid logging too frequently
skipping logging after 60720 examples to avoid logging too frequently
train stats after 60736 examples: {'rewards_train/chosen': '-3.3168', 'rewards_train/rejected': '-13.051', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.7312', 'logps_train/rejected': '-254.95', 'logps_train/chosen': '-71.483', 'loss/train': '0.1122', 'examples_per_second': '4.9226', 'grad_norm': '17.75', 'counters/examples': 60736, 'counters/updates': 3796}
skipping logging after 60752 examples to avoid logging too frequently
skipping logging after 60768 examples to avoid logging too frequently
skipping logging after 60784 examples to avoid logging too frequently
train stats after 60800 examples: {'rewards_train/chosen': '-3.0798', 'rewards_train/rejected': '-13.878', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '10.799', 'logps_train/rejected': '-324.71', 'logps_train/chosen': '-69.579', 'loss/train': '0.01955', 'examples_per_second': '3.983', 'grad_norm': '3.6406', 'counters/examples': 60800, 'counters/updates': 3800}
skipping logging after 60816 examples to avoid logging too frequently
skipping logging after 60832 examples to avoid logging too frequently
skipping logging after 60848 examples to avoid logging too frequently
train stats after 60864 examples: {'rewards_train/chosen': '-3.5432', 'rewards_train/rejected': '-13.027', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.4797', 'logps_train/rejected': '-286.4', 'logps_train/chosen': '-84.773', 'loss/train': '0.061621', 'examples_per_second': '4.6709', 'grad_norm': '9.625', 'counters/examples': 60864, 'counters/updates': 3804}
skipping logging after 60880 examples to avoid logging too frequently
skipping logging after 60896 examples to avoid logging too frequently
skipping logging after 60912 examples to avoid logging too frequently
train stats after 60928 examples: {'rewards_train/chosen': '-3.2134', 'rewards_train/rejected': '-11.92', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.7085', 'logps_train/rejected': '-233.69', 'logps_train/chosen': '-65.146', 'loss/train': '0.066602', 'examples_per_second': '5.6147', 'grad_norm': '8.1875', 'counters/examples': 60928, 'counters/updates': 3808}
skipping logging after 60944 examples to avoid logging too frequently
skipping logging after 60960 examples to avoid logging too frequently
skipping logging after 60976 examples to avoid logging too frequently
train stats after 60992 examples: {'rewards_train/chosen': '-2.9146', 'rewards_train/rejected': '-11.732', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.8176', 'logps_train/rejected': '-269.14', 'logps_train/chosen': '-73.879', 'loss/train': '0.048928', 'examples_per_second': '5.692', 'grad_norm': '10.75', 'counters/examples': 60992, 'counters/updates': 3812}
skipping logging after 61008 examples to avoid logging too frequently
skipping logging after 61024 examples to avoid logging too frequently
skipping logging after 61040 examples to avoid logging too frequently
train stats after 61056 examples: {'rewards_train/chosen': '-2.7469', 'rewards_train/rejected': '-11.298', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.5522', 'logps_train/rejected': '-245.46', 'logps_train/chosen': '-72.521', 'loss/train': '0.02786', 'examples_per_second': '5.1697', 'grad_norm': '6.125', 'counters/examples': 61056, 'counters/updates': 3816}
skipping logging after 61072 examples to avoid logging too frequently
skipping logging after 61088 examples to avoid logging too frequently
skipping logging after 61104 examples to avoid logging too frequently
train stats after 61120 examples: {'rewards_train/chosen': '-3.3001', 'rewards_train/rejected': '-12.076', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.7773', 'logps_train/rejected': '-261.04', 'logps_train/chosen': '-71.439', 'loss/train': '0.029422', 'examples_per_second': '5.152', 'grad_norm': '5.625', 'counters/examples': 61120, 'counters/updates': 3820}
skipping logging after 61136 examples to avoid logging too frequently
skipping logging after 61152 examples to avoid logging too frequently
skipping logging after 61168 examples to avoid logging too frequently
train stats after 61184 examples: {'rewards_train/chosen': '-3.0706', 'rewards_train/rejected': '-12.151', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.0776', 'logps_train/rejected': '-264.25', 'logps_train/chosen': '-68.969', 'loss/train': '0.060146', 'examples_per_second': '4.3654', 'grad_norm': '9.6875', 'counters/examples': 61184, 'counters/updates': 3824}
skipping logging after 61200 examples to avoid logging too frequently
skipping logging after 61216 examples to avoid logging too frequently
skipping logging after 61232 examples to avoid logging too frequently
train stats after 61248 examples: {'rewards_train/chosen': '-3.748', 'rewards_train/rejected': '-12.194', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.4443', 'logps_train/rejected': '-261.82', 'logps_train/chosen': '-76.521', 'loss/train': '0.065653', 'examples_per_second': '5.1704', 'grad_norm': '6.6875', 'counters/examples': 61248, 'counters/updates': 3828}
skipping logging after 61264 examples to avoid logging too frequently
skipping logging after 61280 examples to avoid logging too frequently
skipping logging after 61296 examples to avoid logging too frequently
train stats after 61312 examples: {'rewards_train/chosen': '-3.3625', 'rewards_train/rejected': '-13.491', 'rewards_train/accuracies': '1', 'rewards_train/margins': '10.134', 'logps_train/rejected': '-271.84', 'logps_train/chosen': '-69.612', 'loss/train': '0.023506', 'examples_per_second': '4.1903', 'grad_norm': '6.0625', 'counters/examples': 61312, 'counters/updates': 3832}
skipping logging after 61328 examples to avoid logging too frequently
skipping logging after 61344 examples to avoid logging too frequently
skipping logging after 61360 examples to avoid logging too frequently
train stats after 61376 examples: {'rewards_train/chosen': '-3.6133', 'rewards_train/rejected': '-13.016', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '9.4032', 'logps_train/rejected': '-276.94', 'logps_train/chosen': '-88.576', 'loss/train': '0.04839', 'examples_per_second': '5.792', 'grad_norm': '5.0312', 'counters/examples': 61376, 'counters/updates': 3836}
skipping logging after 61392 examples to avoid logging too frequently
skipping logging after 61408 examples to avoid logging too frequently
skipping logging after 61424 examples to avoid logging too frequently
train stats after 61440 examples: {'rewards_train/chosen': '-3.6274', 'rewards_train/rejected': '-13.066', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.4395', 'logps_train/rejected': '-262.73', 'logps_train/chosen': '-70.686', 'loss/train': '0.061475', 'examples_per_second': '5.0683', 'grad_norm': '12.188', 'counters/examples': 61440, 'counters/updates': 3840}
skipping logging after 61456 examples to avoid logging too frequently
skipping logging after 61472 examples to avoid logging too frequently
skipping logging after 61488 examples to avoid logging too frequently
train stats after 61504 examples: {'rewards_train/chosen': '-3.0218', 'rewards_train/rejected': '-12.031', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.0049', 'logps_train/rejected': '-260.14', 'logps_train/chosen': '-70.386', 'loss/train': '0.086138', 'examples_per_second': '5.3878', 'grad_norm': '11.875', 'counters/examples': 61504, 'counters/updates': 3844}
skipping logging after 61520 examples to avoid logging too frequently
skipping logging after 61536 examples to avoid logging too frequently
skipping logging after 61552 examples to avoid logging too frequently
train stats after 61568 examples: {'rewards_train/chosen': '-2.6201', 'rewards_train/rejected': '-11.624', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '9.0068', 'logps_train/rejected': '-251.36', 'logps_train/chosen': '-67.264', 'loss/train': '0.10617', 'examples_per_second': '4.9419', 'grad_norm': '8.5', 'counters/examples': 61568, 'counters/updates': 3848}
skipping logging after 61584 examples to avoid logging too frequently
skipping logging after 61600 examples to avoid logging too frequently
skipping logging after 61616 examples to avoid logging too frequently
train stats after 61632 examples: {'rewards_train/chosen': '-2.9895', 'rewards_train/rejected': '-11.313', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.3235', 'logps_train/rejected': '-225.65', 'logps_train/chosen': '-68.398', 'loss/train': '0.046442', 'examples_per_second': '5.0678', 'grad_norm': '8.5', 'counters/examples': 61632, 'counters/updates': 3852}
skipping logging after 61648 examples to avoid logging too frequently
skipping logging after 61664 examples to avoid logging too frequently
skipping logging after 61680 examples to avoid logging too frequently
train stats after 61696 examples: {'rewards_train/chosen': '-3.4136', 'rewards_train/rejected': '-12.592', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.174', 'logps_train/rejected': '-268.62', 'logps_train/chosen': '-78.038', 'loss/train': '0.056206', 'examples_per_second': '5.8401', 'grad_norm': '10.5', 'counters/examples': 61696, 'counters/updates': 3856}
skipping logging after 61712 examples to avoid logging too frequently
skipping logging after 61728 examples to avoid logging too frequently
skipping logging after 61744 examples to avoid logging too frequently
train stats after 61760 examples: {'rewards_train/chosen': '-3.4183', 'rewards_train/rejected': '-13.104', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.6833', 'logps_train/rejected': '-294.09', 'logps_train/chosen': '-72.026', 'loss/train': '0.057788', 'examples_per_second': '6.2869', 'grad_norm': '8.25', 'counters/examples': 61760, 'counters/updates': 3860}
skipping logging after 61776 examples to avoid logging too frequently
skipping logging after 61792 examples to avoid logging too frequently
skipping logging after 61808 examples to avoid logging too frequently
train stats after 61824 examples: {'rewards_train/chosen': '-3.2924', 'rewards_train/rejected': '-12.149', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.8547', 'logps_train/rejected': '-247.96', 'logps_train/chosen': '-73.57', 'loss/train': '0.072929', 'examples_per_second': '5.9158', 'grad_norm': '7.375', 'counters/examples': 61824, 'counters/updates': 3864}
skipping logging after 61840 examples to avoid logging too frequently
skipping logging after 61856 examples to avoid logging too frequently
skipping logging after 61872 examples to avoid logging too frequently
train stats after 61888 examples: {'rewards_train/chosen': '-3.5802', 'rewards_train/rejected': '-13.448', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.8684', 'logps_train/rejected': '-286.5', 'logps_train/chosen': '-86.551', 'loss/train': '0.10279', 'examples_per_second': '4.3798', 'grad_norm': '20.125', 'counters/examples': 61888, 'counters/updates': 3868}
skipping logging after 61904 examples to avoid logging too frequently
skipping logging after 61920 examples to avoid logging too frequently
skipping logging after 61936 examples to avoid logging too frequently
train stats after 61952 examples: {'rewards_train/chosen': '-2.8831', 'rewards_train/rejected': '-11.737', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.8547', 'logps_train/rejected': '-242.5', 'logps_train/chosen': '-74.151', 'loss/train': '0.036405', 'examples_per_second': '3.9455', 'grad_norm': '8.25', 'counters/examples': 61952, 'counters/updates': 3872}
skipping logging after 61968 examples to avoid logging too frequently
skipping logging after 61984 examples to avoid logging too frequently
skipping logging after 62000 examples to avoid logging too frequently
train stats after 62016 examples: {'rewards_train/chosen': '-3.1027', 'rewards_train/rejected': '-14.194', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '11.094', 'logps_train/rejected': '-343.06', 'logps_train/chosen': '-79.495', 'loss/train': '0.034211', 'examples_per_second': '4.3763', 'grad_norm': '5.8438', 'counters/examples': 62016, 'counters/updates': 3876}
skipping logging after 62032 examples to avoid logging too frequently
skipping logging after 62048 examples to avoid logging too frequently
skipping logging after 62064 examples to avoid logging too frequently
train stats after 62080 examples: {'rewards_train/chosen': '-2.9817', 'rewards_train/rejected': '-12.661', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.6794', 'logps_train/rejected': '-265.76', 'logps_train/chosen': '-64.226', 'loss/train': '0.030378', 'examples_per_second': '5.0348', 'grad_norm': '4.9375', 'counters/examples': 62080, 'counters/updates': 3880}
skipping logging after 62096 examples to avoid logging too frequently
skipping logging after 62112 examples to avoid logging too frequently
skipping logging after 62128 examples to avoid logging too frequently
train stats after 62144 examples: {'rewards_train/chosen': '-3.4488', 'rewards_train/rejected': '-13.059', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.613', 'logps_train/rejected': '-267.38', 'logps_train/chosen': '-72.77', 'loss/train': '0.061496', 'examples_per_second': '5.0099', 'grad_norm': '13.125', 'counters/examples': 62144, 'counters/updates': 3884}
skipping logging after 62160 examples to avoid logging too frequently
skipping logging after 62176 examples to avoid logging too frequently
skipping logging after 62192 examples to avoid logging too frequently
train stats after 62208 examples: {'rewards_train/chosen': '-2.845', 'rewards_train/rejected': '-12.188', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.3408', 'logps_train/rejected': '-277.3', 'logps_train/chosen': '-80.881', 'loss/train': '0.041791', 'examples_per_second': '5.5595', 'grad_norm': '12.625', 'counters/examples': 62208, 'counters/updates': 3888}
skipping logging after 62224 examples to avoid logging too frequently
skipping logging after 62240 examples to avoid logging too frequently
skipping logging after 62256 examples to avoid logging too frequently
train stats after 62272 examples: {'rewards_train/chosen': '-2.8331', 'rewards_train/rejected': '-11.457', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.6245', 'logps_train/rejected': '-257.91', 'logps_train/chosen': '-71.376', 'loss/train': '0.068258', 'examples_per_second': '5.0144', 'grad_norm': '11.938', 'counters/examples': 62272, 'counters/updates': 3892}
skipping logging after 62288 examples to avoid logging too frequently
skipping logging after 62304 examples to avoid logging too frequently
skipping logging after 62320 examples to avoid logging too frequently
train stats after 62336 examples: {'rewards_train/chosen': '-2.5769', 'rewards_train/rejected': '-11.251', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.6757', 'logps_train/rejected': '-254.44', 'logps_train/chosen': '-69.572', 'loss/train': '0.064007', 'examples_per_second': '4.8478', 'grad_norm': '9.375', 'counters/examples': 62336, 'counters/updates': 3896}
skipping logging after 62352 examples to avoid logging too frequently
skipping logging after 62368 examples to avoid logging too frequently
skipping logging after 62384 examples to avoid logging too frequently
train stats after 62400 examples: {'rewards_train/chosen': '-2.843', 'rewards_train/rejected': '-11.87', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.0295', 'logps_train/rejected': '-251.9', 'logps_train/chosen': '-70.287', 'loss/train': '0.08783', 'examples_per_second': '4.9841', 'grad_norm': '19.125', 'counters/examples': 62400, 'counters/updates': 3900}
skipping logging after 62416 examples to avoid logging too frequently
skipping logging after 62432 examples to avoid logging too frequently
skipping logging after 62448 examples to avoid logging too frequently
train stats after 62464 examples: {'rewards_train/chosen': '-2.6369', 'rewards_train/rejected': '-11.043', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.4066', 'logps_train/rejected': '-248.52', 'logps_train/chosen': '-69.108', 'loss/train': '0.13032', 'examples_per_second': '4.6991', 'grad_norm': '13.062', 'counters/examples': 62464, 'counters/updates': 3904}
skipping logging after 62480 examples to avoid logging too frequently
skipping logging after 62496 examples to avoid logging too frequently
skipping logging after 62512 examples to avoid logging too frequently
train stats after 62528 examples: {'rewards_train/chosen': '-2.6278', 'rewards_train/rejected': '-12.827', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '10.204', 'logps_train/rejected': '-291.7', 'logps_train/chosen': '-71.306', 'loss/train': '0.044008', 'examples_per_second': '5.5958', 'grad_norm': '6.3125', 'counters/examples': 62528, 'counters/updates': 3908}
skipping logging after 62544 examples to avoid logging too frequently
skipping logging after 62560 examples to avoid logging too frequently
skipping logging after 62576 examples to avoid logging too frequently
train stats after 62592 examples: {'rewards_train/chosen': '-2.5581', 'rewards_train/rejected': '-11.962', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.4036', 'logps_train/rejected': '-283', 'logps_train/chosen': '-66.861', 'loss/train': '0.059901', 'examples_per_second': '4.7183', 'grad_norm': '11.062', 'counters/examples': 62592, 'counters/updates': 3912}
skipping logging after 62608 examples to avoid logging too frequently
skipping logging after 62624 examples to avoid logging too frequently
skipping logging after 62640 examples to avoid logging too frequently
train stats after 62656 examples: {'rewards_train/chosen': '-2.4342', 'rewards_train/rejected': '-10.045', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.6118', 'logps_train/rejected': '-251.08', 'logps_train/chosen': '-58.104', 'loss/train': '0.13356', 'examples_per_second': '4.9078', 'grad_norm': '8.3125', 'counters/examples': 62656, 'counters/updates': 3916}
skipping logging after 62672 examples to avoid logging too frequently
skipping logging after 62688 examples to avoid logging too frequently
skipping logging after 62704 examples to avoid logging too frequently
train stats after 62720 examples: {'rewards_train/chosen': '-2.8191', 'rewards_train/rejected': '-11.99', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.1691', 'logps_train/rejected': '-284.29', 'logps_train/chosen': '-67.143', 'loss/train': '0.080361', 'examples_per_second': '5.0008', 'grad_norm': '14.188', 'counters/examples': 62720, 'counters/updates': 3920}
skipping logging after 62736 examples to avoid logging too frequently
skipping logging after 62752 examples to avoid logging too frequently
skipping logging after 62768 examples to avoid logging too frequently
train stats after 62784 examples: {'rewards_train/chosen': '-3.1317', 'rewards_train/rejected': '-11.085', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.9541', 'logps_train/rejected': '-243.27', 'logps_train/chosen': '-70.482', 'loss/train': '0.085678', 'examples_per_second': '5.8806', 'grad_norm': '12.312', 'counters/examples': 62784, 'counters/updates': 3924}
skipping logging after 62800 examples to avoid logging too frequently
skipping logging after 62816 examples to avoid logging too frequently
skipping logging after 62832 examples to avoid logging too frequently
train stats after 62848 examples: {'rewards_train/chosen': '-2.3499', 'rewards_train/rejected': '-11.619', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.2698', 'logps_train/rejected': '-261.63', 'logps_train/chosen': '-56.145', 'loss/train': '0.036979', 'examples_per_second': '4.8523', 'grad_norm': '5.5', 'counters/examples': 62848, 'counters/updates': 3928}
skipping logging after 62864 examples to avoid logging too frequently
skipping logging after 62880 examples to avoid logging too frequently
skipping logging after 62896 examples to avoid logging too frequently
train stats after 62912 examples: {'rewards_train/chosen': '-3.0343', 'rewards_train/rejected': '-11.518', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.4829', 'logps_train/rejected': '-248.54', 'logps_train/chosen': '-62.393', 'loss/train': '0.068767', 'examples_per_second': '6.1397', 'grad_norm': '10.625', 'counters/examples': 62912, 'counters/updates': 3932}
skipping logging after 62928 examples to avoid logging too frequently
skipping logging after 62944 examples to avoid logging too frequently
skipping logging after 62960 examples to avoid logging too frequently
train stats after 62976 examples: {'rewards_train/chosen': '-2.2998', 'rewards_train/rejected': '-10.865', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.5645', 'logps_train/rejected': '-256.45', 'logps_train/chosen': '-64.165', 'loss/train': '0.05641', 'examples_per_second': '5.1404', 'grad_norm': '6.8438', 'counters/examples': 62976, 'counters/updates': 3936}
skipping logging after 62992 examples to avoid logging too frequently
skipping logging after 63008 examples to avoid logging too frequently
skipping logging after 63024 examples to avoid logging too frequently
train stats after 63040 examples: {'rewards_train/chosen': '-2.8253', 'rewards_train/rejected': '-11.171', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.3489', 'logps_train/rejected': '-258.05', 'logps_train/chosen': '-63.388', 'loss/train': '0.088331', 'examples_per_second': '4.5843', 'grad_norm': '9.0625', 'counters/examples': 63040, 'counters/updates': 3940}
skipping logging after 63056 examples to avoid logging too frequently
skipping logging after 63072 examples to avoid logging too frequently
skipping logging after 63088 examples to avoid logging too frequently
train stats after 63104 examples: {'rewards_train/chosen': '-2.3287', 'rewards_train/rejected': '-10.202', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.8757', 'logps_train/rejected': '-226.94', 'logps_train/chosen': '-62.292', 'loss/train': '0.038771', 'examples_per_second': '5.6691', 'grad_norm': '4.1562', 'counters/examples': 63104, 'counters/updates': 3944}
skipping logging after 63120 examples to avoid logging too frequently
skipping logging after 63136 examples to avoid logging too frequently
skipping logging after 63152 examples to avoid logging too frequently
train stats after 63168 examples: {'rewards_train/chosen': '-2.8355', 'rewards_train/rejected': '-10.843', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.0085', 'logps_train/rejected': '-237.92', 'logps_train/chosen': '-76.866', 'loss/train': '0.04415', 'examples_per_second': '5.1873', 'grad_norm': '6.7188', 'counters/examples': 63168, 'counters/updates': 3948}
skipping logging after 63184 examples to avoid logging too frequently
skipping logging after 63200 examples to avoid logging too frequently
skipping logging after 63216 examples to avoid logging too frequently
train stats after 63232 examples: {'rewards_train/chosen': '-2.3739', 'rewards_train/rejected': '-11.065', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.6915', 'logps_train/rejected': '-261.1', 'logps_train/chosen': '-69.67', 'loss/train': '0.029088', 'examples_per_second': '4.7898', 'grad_norm': '5.5938', 'counters/examples': 63232, 'counters/updates': 3952}
skipping logging after 63248 examples to avoid logging too frequently
skipping logging after 63264 examples to avoid logging too frequently
skipping logging after 63280 examples to avoid logging too frequently
train stats after 63296 examples: {'rewards_train/chosen': '-2.795', 'rewards_train/rejected': '-11.176', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.3833', 'logps_train/rejected': '-248.16', 'logps_train/chosen': '-68.695', 'loss/train': '0.13044', 'examples_per_second': '5.9927', 'grad_norm': '12.25', 'counters/examples': 63296, 'counters/updates': 3956}
skipping logging after 63312 examples to avoid logging too frequently
skipping logging after 63328 examples to avoid logging too frequently
skipping logging after 63344 examples to avoid logging too frequently
train stats after 63360 examples: {'rewards_train/chosen': '-2.9375', 'rewards_train/rejected': '-11.615', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.6758', 'logps_train/rejected': '-269.07', 'logps_train/chosen': '-79.76', 'loss/train': '0.083258', 'examples_per_second': '4.6452', 'grad_norm': '14.688', 'counters/examples': 63360, 'counters/updates': 3960}
skipping logging after 63376 examples to avoid logging too frequently
skipping logging after 63392 examples to avoid logging too frequently
skipping logging after 63408 examples to avoid logging too frequently
train stats after 63424 examples: {'rewards_train/chosen': '-3.4663', 'rewards_train/rejected': '-11.56', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '8.0931', 'logps_train/rejected': '-248.28', 'logps_train/chosen': '-71.745', 'loss/train': '0.090112', 'examples_per_second': '4.9844', 'grad_norm': '12.125', 'counters/examples': 63424, 'counters/updates': 3964}
skipping logging after 63440 examples to avoid logging too frequently
skipping logging after 63456 examples to avoid logging too frequently
skipping logging after 63472 examples to avoid logging too frequently
train stats after 63488 examples: {'rewards_train/chosen': '-3.4477', 'rewards_train/rejected': '-12.4', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.9575', 'logps_train/rejected': '-290.04', 'logps_train/chosen': '-70.02', 'loss/train': '0.13246', 'examples_per_second': '4.7309', 'grad_norm': '22.375', 'counters/examples': 63488, 'counters/updates': 3968}
skipping logging after 63504 examples to avoid logging too frequently
skipping logging after 63520 examples to avoid logging too frequently
skipping logging after 63536 examples to avoid logging too frequently
train stats after 63552 examples: {'rewards_train/chosen': '-2.6918', 'rewards_train/rejected': '-11.924', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.2271', 'logps_train/rejected': '-261.14', 'logps_train/chosen': '-66.143', 'loss/train': '0.084338', 'examples_per_second': '6.701', 'grad_norm': '13.125', 'counters/examples': 63552, 'counters/updates': 3972}
skipping logging after 63568 examples to avoid logging too frequently
skipping logging after 63584 examples to avoid logging too frequently
skipping logging after 63600 examples to avoid logging too frequently
train stats after 63616 examples: {'rewards_train/chosen': '-2.7564', 'rewards_train/rejected': '-11.927', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.1675', 'logps_train/rejected': '-281.96', 'logps_train/chosen': '-67.938', 'loss/train': '0.048416', 'examples_per_second': '6.3694', 'grad_norm': '11.562', 'counters/examples': 63616, 'counters/updates': 3976}
skipping logging after 63632 examples to avoid logging too frequently
skipping logging after 63648 examples to avoid logging too frequently
skipping logging after 63664 examples to avoid logging too frequently
train stats after 63680 examples: {'rewards_train/chosen': '-2.3514', 'rewards_train/rejected': '-11.965', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.6125', 'logps_train/rejected': '-257.43', 'logps_train/chosen': '-67.679', 'loss/train': '0.0095708', 'examples_per_second': '5.9205', 'grad_norm': '1.9062', 'counters/examples': 63680, 'counters/updates': 3980}
skipping logging after 63696 examples to avoid logging too frequently
skipping logging after 63712 examples to avoid logging too frequently
skipping logging after 63728 examples to avoid logging too frequently
train stats after 63744 examples: {'rewards_train/chosen': '-2.8635', 'rewards_train/rejected': '-11.316', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.4535', 'logps_train/rejected': '-255.66', 'logps_train/chosen': '-74.094', 'loss/train': '0.073709', 'examples_per_second': '5.8221', 'grad_norm': '10.438', 'counters/examples': 63744, 'counters/updates': 3984}
skipping logging after 63760 examples to avoid logging too frequently
skipping logging after 63776 examples to avoid logging too frequently
skipping logging after 63792 examples to avoid logging too frequently
train stats after 63808 examples: {'rewards_train/chosen': '-3.674', 'rewards_train/rejected': '-11.66', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.9882', 'logps_train/rejected': '-242.59', 'logps_train/chosen': '-77.842', 'loss/train': '0.12781', 'examples_per_second': '4.9596', 'grad_norm': '13.375', 'counters/examples': 63808, 'counters/updates': 3988}
skipping logging after 63824 examples to avoid logging too frequently
skipping logging after 63840 examples to avoid logging too frequently
skipping logging after 63856 examples to avoid logging too frequently
train stats after 63872 examples: {'rewards_train/chosen': '-3.0847', 'rewards_train/rejected': '-12.174', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.0872', 'logps_train/rejected': '-240.76', 'logps_train/chosen': '-76.564', 'loss/train': '0.039877', 'examples_per_second': '4.6435', 'grad_norm': '7.4062', 'counters/examples': 63872, 'counters/updates': 3992}
skipping logging after 63888 examples to avoid logging too frequently
skipping logging after 63904 examples to avoid logging too frequently
skipping logging after 63920 examples to avoid logging too frequently
train stats after 63936 examples: {'rewards_train/chosen': '-3.4598', 'rewards_train/rejected': '-12.903', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.4421', 'logps_train/rejected': '-284.74', 'logps_train/chosen': '-81.232', 'loss/train': '0.13283', 'examples_per_second': '4.8542', 'grad_norm': '14.812', 'counters/examples': 63936, 'counters/updates': 3996}
skipping logging after 63952 examples to avoid logging too frequently
skipping logging after 63968 examples to avoid logging too frequently
skipping logging after 63984 examples to avoid logging too frequently
train stats after 64000 examples: {'rewards_train/chosen': '-3.321', 'rewards_train/rejected': '-12.461', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.1392', 'logps_train/rejected': '-289.29', 'logps_train/chosen': '-87.578', 'loss/train': '0.091251', 'examples_per_second': '4.7109', 'grad_norm': '14.375', 'counters/examples': 64000, 'counters/updates': 4000}
Running evaluation after 64000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<01:00,  1.95s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:00,  2.02s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:53,  1.84s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.85s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.52s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:36,  1.57s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:30,  1.50s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:22,  1.30s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.24s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.33s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.34s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:14,  1.27s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.30s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.26s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.30s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.48s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.41s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.61s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.42s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.42s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 64000: {'rewards_eval/chosen': '-12.286', 'rewards_eval/rejected': '-12.957', 'rewards_eval/accuracies': '0.52344', 'rewards_eval/margins': '0.67111', 'logps_eval/rejected': '-277.23', 'logps_eval/chosen': '-267.78', 'loss/eval': '2.3074'}
skipping logging after 64016 examples to avoid logging too frequently
skipping logging after 64032 examples to avoid logging too frequently
skipping logging after 64048 examples to avoid logging too frequently
train stats after 64064 examples: {'rewards_train/chosen': '-3.1175', 'rewards_train/rejected': '-12.456', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.3386', 'logps_train/rejected': '-267.45', 'logps_train/chosen': '-68.827', 'loss/train': '0.08984', 'examples_per_second': '3.7975', 'grad_norm': '16.875', 'counters/examples': 64064, 'counters/updates': 4004}
skipping logging after 64080 examples to avoid logging too frequently
skipping logging after 64096 examples to avoid logging too frequently
skipping logging after 64112 examples to avoid logging too frequently
train stats after 64128 examples: {'rewards_train/chosen': '-3.4166', 'rewards_train/rejected': '-12.069', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.6516', 'logps_train/rejected': '-255.62', 'logps_train/chosen': '-71.313', 'loss/train': '0.10932', 'examples_per_second': '5.1336', 'grad_norm': '12.5', 'counters/examples': 64128, 'counters/updates': 4008}
skipping logging after 64144 examples to avoid logging too frequently
skipping logging after 64160 examples to avoid logging too frequently
skipping logging after 64176 examples to avoid logging too frequently
train stats after 64192 examples: {'rewards_train/chosen': '-3.1757', 'rewards_train/rejected': '-12.293', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.1191', 'logps_train/rejected': '-255.26', 'logps_train/chosen': '-75.277', 'loss/train': '0.018507', 'examples_per_second': '4.6902', 'grad_norm': '4.3125', 'counters/examples': 64192, 'counters/updates': 4012}
skipping logging after 64208 examples to avoid logging too frequently
skipping logging after 64224 examples to avoid logging too frequently
skipping logging after 64240 examples to avoid logging too frequently
train stats after 64256 examples: {'rewards_train/chosen': '-2.9552', 'rewards_train/rejected': '-12.293', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.3409', 'logps_train/rejected': '-284.75', 'logps_train/chosen': '-65.147', 'loss/train': '0.03624', 'examples_per_second': '4.7256', 'grad_norm': '7.2188', 'counters/examples': 64256, 'counters/updates': 4016}
skipping logging after 64272 examples to avoid logging too frequently
skipping logging after 64288 examples to avoid logging too frequently
skipping logging after 64304 examples to avoid logging too frequently
train stats after 64320 examples: {'rewards_train/chosen': '-3.5401', 'rewards_train/rejected': '-11.355', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.8151', 'logps_train/rejected': '-238.28', 'logps_train/chosen': '-81.483', 'loss/train': '0.14221', 'examples_per_second': '5.3541', 'grad_norm': '17.25', 'counters/examples': 64320, 'counters/updates': 4020}
skipping logging after 64336 examples to avoid logging too frequently
skipping logging after 64352 examples to avoid logging too frequently
skipping logging after 64368 examples to avoid logging too frequently
train stats after 64384 examples: {'rewards_train/chosen': '-3.3442', 'rewards_train/rejected': '-12.5', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.1533', 'logps_train/rejected': '-263.81', 'logps_train/chosen': '-73.309', 'loss/train': '0.075959', 'examples_per_second': '4.2773', 'grad_norm': '11.438', 'counters/examples': 64384, 'counters/updates': 4024}
skipping logging after 64400 examples to avoid logging too frequently
skipping logging after 64416 examples to avoid logging too frequently
skipping logging after 64432 examples to avoid logging too frequently
train stats after 64448 examples: {'rewards_train/chosen': '-2.9798', 'rewards_train/rejected': '-11.361', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.3799', 'logps_train/rejected': '-247.21', 'logps_train/chosen': '-67.104', 'loss/train': '0.058082', 'examples_per_second': '6.8159', 'grad_norm': '11.812', 'counters/examples': 64448, 'counters/updates': 4028}
skipping logging after 64464 examples to avoid logging too frequently
skipping logging after 64480 examples to avoid logging too frequently
skipping logging after 64496 examples to avoid logging too frequently
train stats after 64512 examples: {'rewards_train/chosen': '-3.3391', 'rewards_train/rejected': '-12.578', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.2368', 'logps_train/rejected': '-265.17', 'logps_train/chosen': '-82.514', 'loss/train': '0.092599', 'examples_per_second': '5.0724', 'grad_norm': '11.875', 'counters/examples': 64512, 'counters/updates': 4032}
skipping logging after 64528 examples to avoid logging too frequently
skipping logging after 64544 examples to avoid logging too frequently
skipping logging after 64560 examples to avoid logging too frequently
train stats after 64576 examples: {'rewards_train/chosen': '-2.9743', 'rewards_train/rejected': '-11.345', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.3712', 'logps_train/rejected': '-261.21', 'logps_train/chosen': '-65.84', 'loss/train': '0.045837', 'examples_per_second': '4.7248', 'grad_norm': '6.2812', 'counters/examples': 64576, 'counters/updates': 4036}
skipping logging after 64592 examples to avoid logging too frequently
skipping logging after 64608 examples to avoid logging too frequently
skipping logging after 64624 examples to avoid logging too frequently
train stats after 64640 examples: {'rewards_train/chosen': '-3.2534', 'rewards_train/rejected': '-11.421', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.168', 'logps_train/rejected': '-223.76', 'logps_train/chosen': '-63.408', 'loss/train': '0.10035', 'examples_per_second': '5.6999', 'grad_norm': '17.5', 'counters/examples': 64640, 'counters/updates': 4040}
skipping logging after 64656 examples to avoid logging too frequently
skipping logging after 64672 examples to avoid logging too frequently
skipping logging after 64688 examples to avoid logging too frequently
train stats after 64704 examples: {'rewards_train/chosen': '-3.0192', 'rewards_train/rejected': '-12.788', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.7638', 'logps_train/rejected': '-304.92', 'logps_train/chosen': '-76.932', 'loss/train': '0.067688', 'examples_per_second': '4.6842', 'grad_norm': '12.438', 'counters/examples': 64704, 'counters/updates': 4044}
skipping logging after 64720 examples to avoid logging too frequently
skipping logging after 64736 examples to avoid logging too frequently
skipping logging after 64752 examples to avoid logging too frequently
train stats after 64768 examples: {'rewards_train/chosen': '-2.4184', 'rewards_train/rejected': '-10.572', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.153', 'logps_train/rejected': '-259.19', 'logps_train/chosen': '-62.362', 'loss/train': '0.06113', 'examples_per_second': '5.4839', 'grad_norm': '8', 'counters/examples': 64768, 'counters/updates': 4048}
skipping logging after 64784 examples to avoid logging too frequently
skipping logging after 64800 examples to avoid logging too frequently
skipping logging after 64816 examples to avoid logging too frequently
train stats after 64832 examples: {'rewards_train/chosen': '-2.7381', 'rewards_train/rejected': '-11.566', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.8267', 'logps_train/rejected': '-273.08', 'logps_train/chosen': '-70.006', 'loss/train': '0.059422', 'examples_per_second': '4.2244', 'grad_norm': '14.125', 'counters/examples': 64832, 'counters/updates': 4052}
skipping logging after 64848 examples to avoid logging too frequently
skipping logging after 64864 examples to avoid logging too frequently
skipping logging after 64880 examples to avoid logging too frequently
train stats after 64896 examples: {'rewards_train/chosen': '-3.1092', 'rewards_train/rejected': '-11.139', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.0328', 'logps_train/rejected': '-238.01', 'logps_train/chosen': '-80.012', 'loss/train': '0.23069', 'examples_per_second': '4.9443', 'grad_norm': '21.625', 'counters/examples': 64896, 'counters/updates': 4056}
skipping logging after 64912 examples to avoid logging too frequently
skipping logging after 64928 examples to avoid logging too frequently
skipping logging after 64944 examples to avoid logging too frequently
train stats after 64960 examples: {'rewards_train/chosen': '-2.555', 'rewards_train/rejected': '-9.6028', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.0486', 'logps_train/rejected': '-235.34', 'logps_train/chosen': '-74.725', 'loss/train': '0.075027', 'examples_per_second': '4.5855', 'grad_norm': '6.4375', 'counters/examples': 64960, 'counters/updates': 4060}
skipping logging after 64976 examples to avoid logging too frequently
skipping logging after 64992 examples to avoid logging too frequently
skipping logging after 65008 examples to avoid logging too frequently
train stats after 65024 examples: {'rewards_train/chosen': '-2.7349', 'rewards_train/rejected': '-10.042', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.3042', 'logps_train/rejected': '-234.07', 'logps_train/chosen': '-70.219', 'loss/train': '0.13709', 'examples_per_second': '4.9644', 'grad_norm': '11.812', 'counters/examples': 65024, 'counters/updates': 4064}
skipping logging after 65040 examples to avoid logging too frequently
skipping logging after 65056 examples to avoid logging too frequently
skipping logging after 65072 examples to avoid logging too frequently
train stats after 65088 examples: {'rewards_train/chosen': '-2.9606', 'rewards_train/rejected': '-10.742', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.7852', 'logps_train/rejected': '-250.6', 'logps_train/chosen': '-73.906', 'loss/train': '0.093982', 'examples_per_second': '4.0418', 'grad_norm': '14.75', 'counters/examples': 65088, 'counters/updates': 4068}
skipping logging after 65104 examples to avoid logging too frequently
skipping logging after 65120 examples to avoid logging too frequently
skipping logging after 65136 examples to avoid logging too frequently
train stats after 65152 examples: {'rewards_train/chosen': '-2.4095', 'rewards_train/rejected': '-9.2717', 'rewards_train/accuracies': '1', 'rewards_train/margins': '6.8628', 'logps_train/rejected': '-214.73', 'logps_train/chosen': '-59.942', 'loss/train': '0.06503', 'examples_per_second': '6.0196', 'grad_norm': '12.125', 'counters/examples': 65152, 'counters/updates': 4072}
skipping logging after 65168 examples to avoid logging too frequently
skipping logging after 65184 examples to avoid logging too frequently
skipping logging after 65200 examples to avoid logging too frequently
train stats after 65216 examples: {'rewards_train/chosen': '-2.6574', 'rewards_train/rejected': '-10.575', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.915', 'logps_train/rejected': '-253.37', 'logps_train/chosen': '-68.805', 'loss/train': '0.025141', 'examples_per_second': '5.4328', 'grad_norm': '4.6562', 'counters/examples': 65216, 'counters/updates': 4076}
skipping logging after 65232 examples to avoid logging too frequently
skipping logging after 65248 examples to avoid logging too frequently
skipping logging after 65264 examples to avoid logging too frequently
train stats after 65280 examples: {'rewards_train/chosen': '-2.9619', 'rewards_train/rejected': '-11.171', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.2097', 'logps_train/rejected': '-271.78', 'logps_train/chosen': '-84.533', 'loss/train': '0.15494', 'examples_per_second': '5.723', 'grad_norm': '16.375', 'counters/examples': 65280, 'counters/updates': 4080}
skipping logging after 65296 examples to avoid logging too frequently
skipping logging after 65312 examples to avoid logging too frequently
skipping logging after 65328 examples to avoid logging too frequently
train stats after 65344 examples: {'rewards_train/chosen': '-2.7211', 'rewards_train/rejected': '-11.072', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.3518', 'logps_train/rejected': '-266.32', 'logps_train/chosen': '-66.459', 'loss/train': '0.030609', 'examples_per_second': '4.0839', 'grad_norm': '8.0625', 'counters/examples': 65344, 'counters/updates': 4084}
skipping logging after 65360 examples to avoid logging too frequently
skipping logging after 65376 examples to avoid logging too frequently
skipping logging after 65392 examples to avoid logging too frequently
train stats after 65408 examples: {'rewards_train/chosen': '-2.2997', 'rewards_train/rejected': '-10.603', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.3016', 'logps_train/rejected': '-246.58', 'logps_train/chosen': '-67.322', 'loss/train': '0.077465', 'examples_per_second': '5.4099', 'grad_norm': '9.75', 'counters/examples': 65408, 'counters/updates': 4088}
skipping logging after 65424 examples to avoid logging too frequently
skipping logging after 65440 examples to avoid logging too frequently
skipping logging after 65456 examples to avoid logging too frequently
train stats after 65472 examples: {'rewards_train/chosen': '-3.2222', 'rewards_train/rejected': '-10.861', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.6405', 'logps_train/rejected': '-211.62', 'logps_train/chosen': '-70.266', 'loss/train': '0.06838', 'examples_per_second': '6.5624', 'grad_norm': '10.062', 'counters/examples': 65472, 'counters/updates': 4092}
skipping logging after 65488 examples to avoid logging too frequently
skipping logging after 65504 examples to avoid logging too frequently
skipping logging after 65520 examples to avoid logging too frequently
train stats after 65536 examples: {'rewards_train/chosen': '-2.7556', 'rewards_train/rejected': '-12.14', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.3896', 'logps_train/rejected': '-269.73', 'logps_train/chosen': '-69.208', 'loss/train': '0.056645', 'examples_per_second': '5.1031', 'grad_norm': '8.25', 'counters/examples': 65536, 'counters/updates': 4096}
skipping logging after 65552 examples to avoid logging too frequently
skipping logging after 65568 examples to avoid logging too frequently
skipping logging after 65584 examples to avoid logging too frequently
train stats after 65600 examples: {'rewards_train/chosen': '-2.9523', 'rewards_train/rejected': '-11.082', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.1262', 'logps_train/rejected': '-238.73', 'logps_train/chosen': '-70.446', 'loss/train': '0.059593', 'examples_per_second': '4.8892', 'grad_norm': '6.5312', 'counters/examples': 65600, 'counters/updates': 4100}
skipping logging after 65616 examples to avoid logging too frequently
skipping logging after 65632 examples to avoid logging too frequently
skipping logging after 65648 examples to avoid logging too frequently
train stats after 65664 examples: {'rewards_train/chosen': '-3.07', 'rewards_train/rejected': '-12.053', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.9828', 'logps_train/rejected': '-270.89', 'logps_train/chosen': '-73.41', 'loss/train': '0.11894', 'examples_per_second': '5.0913', 'grad_norm': '13.625', 'counters/examples': 65664, 'counters/updates': 4104}
skipping logging after 65680 examples to avoid logging too frequently
skipping logging after 65696 examples to avoid logging too frequently
skipping logging after 65712 examples to avoid logging too frequently
train stats after 65728 examples: {'rewards_train/chosen': '-3.5289', 'rewards_train/rejected': '-12.105', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.5765', 'logps_train/rejected': '-255.8', 'logps_train/chosen': '-69.969', 'loss/train': '0.065969', 'examples_per_second': '5.4648', 'grad_norm': '7.875', 'counters/examples': 65728, 'counters/updates': 4108}
skipping logging after 65744 examples to avoid logging too frequently
skipping logging after 65760 examples to avoid logging too frequently
skipping logging after 65776 examples to avoid logging too frequently
train stats after 65792 examples: {'rewards_train/chosen': '-2.8376', 'rewards_train/rejected': '-12.875', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '10.039', 'logps_train/rejected': '-285.62', 'logps_train/chosen': '-69.357', 'loss/train': '0.041767', 'examples_per_second': '4.6549', 'grad_norm': '13', 'counters/examples': 65792, 'counters/updates': 4112}
skipping logging after 65808 examples to avoid logging too frequently
skipping logging after 65824 examples to avoid logging too frequently
skipping logging after 65840 examples to avoid logging too frequently
train stats after 65856 examples: {'rewards_train/chosen': '-2.822', 'rewards_train/rejected': '-12.179', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.3562', 'logps_train/rejected': '-260.78', 'logps_train/chosen': '-63.958', 'loss/train': '0.044744', 'examples_per_second': '6.204', 'grad_norm': '6.4375', 'counters/examples': 65856, 'counters/updates': 4116}
skipping logging after 65872 examples to avoid logging too frequently
skipping logging after 65888 examples to avoid logging too frequently
skipping logging after 65904 examples to avoid logging too frequently
train stats after 65920 examples: {'rewards_train/chosen': '-3.4109', 'rewards_train/rejected': '-11.53', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.1196', 'logps_train/rejected': '-250.42', 'logps_train/chosen': '-72.707', 'loss/train': '0.081934', 'examples_per_second': '4.9045', 'grad_norm': '10', 'counters/examples': 65920, 'counters/updates': 4120}
skipping logging after 65936 examples to avoid logging too frequently
skipping logging after 65952 examples to avoid logging too frequently
skipping logging after 65968 examples to avoid logging too frequently
train stats after 65984 examples: {'rewards_train/chosen': '-3.9277', 'rewards_train/rejected': '-14.46', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '10.53', 'logps_train/rejected': '-319.45', 'logps_train/chosen': '-81.924', 'loss/train': '0.084154', 'examples_per_second': '3.7035', 'grad_norm': '19', 'counters/examples': 65984, 'counters/updates': 4124}
skipping logging after 66000 examples to avoid logging too frequently
skipping logging after 66016 examples to avoid logging too frequently
skipping logging after 66032 examples to avoid logging too frequently
train stats after 66048 examples: {'rewards_train/chosen': '-3.3864', 'rewards_train/rejected': '-11.881', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.4951', 'logps_train/rejected': '-218.07', 'logps_train/chosen': '-70.335', 'loss/train': '0.023834', 'examples_per_second': '4.8318', 'grad_norm': '9.6875', 'counters/examples': 66048, 'counters/updates': 4128}
skipping logging after 66064 examples to avoid logging too frequently
skipping logging after 66080 examples to avoid logging too frequently
skipping logging after 66096 examples to avoid logging too frequently
train stats after 66112 examples: {'rewards_train/chosen': '-3.0841', 'rewards_train/rejected': '-12.229', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.1418', 'logps_train/rejected': '-281.32', 'logps_train/chosen': '-74.299', 'loss/train': '0.058517', 'examples_per_second': '4.3427', 'grad_norm': '10.875', 'counters/examples': 66112, 'counters/updates': 4132}
skipping logging after 66128 examples to avoid logging too frequently
skipping logging after 66144 examples to avoid logging too frequently
skipping logging after 66160 examples to avoid logging too frequently
train stats after 66176 examples: {'rewards_train/chosen': '-3.2416', 'rewards_train/rejected': '-11.597', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.3535', 'logps_train/rejected': '-252.08', 'logps_train/chosen': '-71.762', 'loss/train': '0.067425', 'examples_per_second': '5.5549', 'grad_norm': '6.875', 'counters/examples': 66176, 'counters/updates': 4136}
skipping logging after 66192 examples to avoid logging too frequently
skipping logging after 66208 examples to avoid logging too frequently
skipping logging after 66224 examples to avoid logging too frequently
train stats after 66240 examples: {'rewards_train/chosen': '-3.0981', 'rewards_train/rejected': '-10.5', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.4045', 'logps_train/rejected': '-226.78', 'logps_train/chosen': '-64.977', 'loss/train': '0.08107', 'examples_per_second': '5.6747', 'grad_norm': '8.9375', 'counters/examples': 66240, 'counters/updates': 4140}
skipping logging after 66256 examples to avoid logging too frequently
skipping logging after 66272 examples to avoid logging too frequently
skipping logging after 66288 examples to avoid logging too frequently
train stats after 66304 examples: {'rewards_train/chosen': '-3.1971', 'rewards_train/rejected': '-11.33', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.1328', 'logps_train/rejected': '-252.93', 'logps_train/chosen': '-62.021', 'loss/train': '0.15797', 'examples_per_second': '5.5756', 'grad_norm': '16.25', 'counters/examples': 66304, 'counters/updates': 4144}
skipping logging after 66320 examples to avoid logging too frequently
skipping logging after 66336 examples to avoid logging too frequently
skipping logging after 66352 examples to avoid logging too frequently
train stats after 66368 examples: {'rewards_train/chosen': '-2.7762', 'rewards_train/rejected': '-11.04', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.2695', 'logps_train/rejected': '-261.9', 'logps_train/chosen': '-70.987', 'loss/train': '0.096033', 'examples_per_second': '5.1204', 'grad_norm': '12.375', 'counters/examples': 66368, 'counters/updates': 4148}
skipping logging after 66384 examples to avoid logging too frequently
skipping logging after 66400 examples to avoid logging too frequently
skipping logging after 66416 examples to avoid logging too frequently
train stats after 66432 examples: {'rewards_train/chosen': '-3.233', 'rewards_train/rejected': '-11.965', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.7319', 'logps_train/rejected': '-274.03', 'logps_train/chosen': '-67.782', 'loss/train': '0.033102', 'examples_per_second': '5.3309', 'grad_norm': '8.5', 'counters/examples': 66432, 'counters/updates': 4152}
skipping logging after 66448 examples to avoid logging too frequently
skipping logging after 66464 examples to avoid logging too frequently
skipping logging after 66480 examples to avoid logging too frequently
train stats after 66496 examples: {'rewards_train/chosen': '-3.3862', 'rewards_train/rejected': '-10.753', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.3707', 'logps_train/rejected': '-241.77', 'logps_train/chosen': '-69.291', 'loss/train': '0.079974', 'examples_per_second': '5.6134', 'grad_norm': '11.5', 'counters/examples': 66496, 'counters/updates': 4156}
skipping logging after 66512 examples to avoid logging too frequently
skipping logging after 66528 examples to avoid logging too frequently
skipping logging after 66544 examples to avoid logging too frequently
train stats after 66560 examples: {'rewards_train/chosen': '-3.0579', 'rewards_train/rejected': '-10.811', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.752', 'logps_train/rejected': '-268.32', 'logps_train/chosen': '-75.541', 'loss/train': '0.17097', 'examples_per_second': '5.2642', 'grad_norm': '18.625', 'counters/examples': 66560, 'counters/updates': 4160}
skipping logging after 66576 examples to avoid logging too frequently
skipping logging after 66592 examples to avoid logging too frequently
skipping logging after 66608 examples to avoid logging too frequently
train stats after 66624 examples: {'rewards_train/chosen': '-3.1942', 'rewards_train/rejected': '-10.336', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.1438', 'logps_train/rejected': '-219.11', 'logps_train/chosen': '-71.908', 'loss/train': '0.033637', 'examples_per_second': '6.4146', 'grad_norm': '6.75', 'counters/examples': 66624, 'counters/updates': 4164}
skipping logging after 66640 examples to avoid logging too frequently
skipping logging after 66656 examples to avoid logging too frequently
skipping logging after 66672 examples to avoid logging too frequently
train stats after 66688 examples: {'rewards_train/chosen': '-2.6634', 'rewards_train/rejected': '-10.453', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.7925', 'logps_train/rejected': '-241.9', 'logps_train/chosen': '-64.423', 'loss/train': '0.088238', 'examples_per_second': '5.6185', 'grad_norm': '10.812', 'counters/examples': 66688, 'counters/updates': 4168}
skipping logging after 66704 examples to avoid logging too frequently
skipping logging after 66720 examples to avoid logging too frequently
skipping logging after 66736 examples to avoid logging too frequently
train stats after 66752 examples: {'rewards_train/chosen': '-2.342', 'rewards_train/rejected': '-11.797', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.4506', 'logps_train/rejected': '-292.18', 'logps_train/chosen': '-57.229', 'loss/train': '0.015062', 'examples_per_second': '5.3784', 'grad_norm': '2.7812', 'counters/examples': 66752, 'counters/updates': 4172}
skipping logging after 66768 examples to avoid logging too frequently
skipping logging after 66784 examples to avoid logging too frequently
skipping logging after 66800 examples to avoid logging too frequently
train stats after 66816 examples: {'rewards_train/chosen': '-2.7112', 'rewards_train/rejected': '-11.033', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.3232', 'logps_train/rejected': '-242.6', 'logps_train/chosen': '-66.524', 'loss/train': '0.066881', 'examples_per_second': '4.9738', 'grad_norm': '8.0625', 'counters/examples': 66816, 'counters/updates': 4176}
skipping logging after 66832 examples to avoid logging too frequently
skipping logging after 66848 examples to avoid logging too frequently
skipping logging after 66864 examples to avoid logging too frequently
train stats after 66880 examples: {'rewards_train/chosen': '-3.2061', 'rewards_train/rejected': '-11.972', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.7681', 'logps_train/rejected': '-265.36', 'logps_train/chosen': '-69.192', 'loss/train': '0.076366', 'examples_per_second': '4.6016', 'grad_norm': '16.25', 'counters/examples': 66880, 'counters/updates': 4180}
skipping logging after 66896 examples to avoid logging too frequently
skipping logging after 66912 examples to avoid logging too frequently
skipping logging after 66928 examples to avoid logging too frequently
train stats after 66944 examples: {'rewards_train/chosen': '-2.9545', 'rewards_train/rejected': '-11.524', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.5701', 'logps_train/rejected': '-256.19', 'logps_train/chosen': '-64.195', 'loss/train': '0.084505', 'examples_per_second': '5.3943', 'grad_norm': '15.875', 'counters/examples': 66944, 'counters/updates': 4184}
skipping logging after 66960 examples to avoid logging too frequently
skipping logging after 66976 examples to avoid logging too frequently
skipping logging after 66992 examples to avoid logging too frequently
train stats after 67008 examples: {'rewards_train/chosen': '-2.801', 'rewards_train/rejected': '-11.896', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.0958', 'logps_train/rejected': '-277.82', 'logps_train/chosen': '-71.763', 'loss/train': '0.030035', 'examples_per_second': '4.1103', 'grad_norm': '3.8906', 'counters/examples': 67008, 'counters/updates': 4188}
skipping logging after 67024 examples to avoid logging too frequently
skipping logging after 67040 examples to avoid logging too frequently
skipping logging after 67056 examples to avoid logging too frequently
train stats after 67072 examples: {'rewards_train/chosen': '-2.5811', 'rewards_train/rejected': '-10.696', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.1172', 'logps_train/rejected': '-236.69', 'logps_train/chosen': '-63.597', 'loss/train': '0.0351', 'examples_per_second': '5.327', 'grad_norm': '7.6562', 'counters/examples': 67072, 'counters/updates': 4192}
skipping logging after 67088 examples to avoid logging too frequently
skipping logging after 67104 examples to avoid logging too frequently
skipping logging after 67120 examples to avoid logging too frequently
train stats after 67136 examples: {'rewards_train/chosen': '-2.8803', 'rewards_train/rejected': '-11.076', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1973', 'logps_train/rejected': '-245.01', 'logps_train/chosen': '-67.617', 'loss/train': '0.074073', 'examples_per_second': '6.1911', 'grad_norm': '10.312', 'counters/examples': 67136, 'counters/updates': 4196}
skipping logging after 67152 examples to avoid logging too frequently
skipping logging after 67168 examples to avoid logging too frequently
skipping logging after 67184 examples to avoid logging too frequently
train stats after 67200 examples: {'rewards_train/chosen': '-3.1191', 'rewards_train/rejected': '-12.936', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.8169', 'logps_train/rejected': '-289.89', 'logps_train/chosen': '-72.252', 'loss/train': '0.047219', 'examples_per_second': '5.1914', 'grad_norm': '6.6875', 'counters/examples': 67200, 'counters/updates': 4200}
skipping logging after 67216 examples to avoid logging too frequently
skipping logging after 67232 examples to avoid logging too frequently
skipping logging after 67248 examples to avoid logging too frequently
train stats after 67264 examples: {'rewards_train/chosen': '-2.9984', 'rewards_train/rejected': '-11.909', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.9086', 'logps_train/rejected': '-253.56', 'logps_train/chosen': '-69.353', 'loss/train': '0.067794', 'examples_per_second': '5.4636', 'grad_norm': '15.688', 'counters/examples': 67264, 'counters/updates': 4204}
skipping logging after 67280 examples to avoid logging too frequently
skipping logging after 67296 examples to avoid logging too frequently
skipping logging after 67312 examples to avoid logging too frequently
train stats after 67328 examples: {'rewards_train/chosen': '-3.268', 'rewards_train/rejected': '-12.331', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.0623', 'logps_train/rejected': '-279.88', 'logps_train/chosen': '-69.543', 'loss/train': '0.043017', 'examples_per_second': '4.543', 'grad_norm': '6.0625', 'counters/examples': 67328, 'counters/updates': 4208}
skipping logging after 67344 examples to avoid logging too frequently
skipping logging after 67360 examples to avoid logging too frequently
skipping logging after 67376 examples to avoid logging too frequently
train stats after 67392 examples: {'rewards_train/chosen': '-2.8854', 'rewards_train/rejected': '-12.259', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.3691', 'logps_train/rejected': '-275.49', 'logps_train/chosen': '-73.13', 'loss/train': '0.10563', 'examples_per_second': '4.8553', 'grad_norm': '10.625', 'counters/examples': 67392, 'counters/updates': 4212}
skipping logging after 67408 examples to avoid logging too frequently
skipping logging after 67424 examples to avoid logging too frequently
skipping logging after 67440 examples to avoid logging too frequently
train stats after 67456 examples: {'rewards_train/chosen': '-2.4915', 'rewards_train/rejected': '-11.714', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '9.2201', 'logps_train/rejected': '-299.81', 'logps_train/chosen': '-74.011', 'loss/train': '0.074412', 'examples_per_second': '5.0225', 'grad_norm': '8.6875', 'counters/examples': 67456, 'counters/updates': 4216}
skipping logging after 67472 examples to avoid logging too frequently
skipping logging after 67488 examples to avoid logging too frequently
skipping logging after 67504 examples to avoid logging too frequently
train stats after 67520 examples: {'rewards_train/chosen': '-2.5622', 'rewards_train/rejected': '-11.224', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.6646', 'logps_train/rejected': '-276.82', 'logps_train/chosen': '-71.553', 'loss/train': '0.080084', 'examples_per_second': '5.2399', 'grad_norm': '8.625', 'counters/examples': 67520, 'counters/updates': 4220}
skipping logging after 67536 examples to avoid logging too frequently
skipping logging after 67552 examples to avoid logging too frequently
skipping logging after 67568 examples to avoid logging too frequently
train stats after 67584 examples: {'rewards_train/chosen': '-2.5894', 'rewards_train/rejected': '-9.5992', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.0071', 'logps_train/rejected': '-229.12', 'logps_train/chosen': '-69.355', 'loss/train': '0.079241', 'examples_per_second': '4.7374', 'grad_norm': '12.062', 'counters/examples': 67584, 'counters/updates': 4224}
skipping logging after 67600 examples to avoid logging too frequently
skipping logging after 67616 examples to avoid logging too frequently
skipping logging after 67632 examples to avoid logging too frequently
train stats after 67648 examples: {'rewards_train/chosen': '-2.4641', 'rewards_train/rejected': '-11.021', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.5598', 'logps_train/rejected': '-254.89', 'logps_train/chosen': '-68.646', 'loss/train': '0.070131', 'examples_per_second': '4.4189', 'grad_norm': '15.875', 'counters/examples': 67648, 'counters/updates': 4228}
skipping logging after 67664 examples to avoid logging too frequently
skipping logging after 67680 examples to avoid logging too frequently
skipping logging after 67696 examples to avoid logging too frequently
train stats after 67712 examples: {'rewards_train/chosen': '-2.5533', 'rewards_train/rejected': '-10.734', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1833', 'logps_train/rejected': '-253.29', 'logps_train/chosen': '-73.855', 'loss/train': '0.084919', 'examples_per_second': '5.7458', 'grad_norm': '9', 'counters/examples': 67712, 'counters/updates': 4232}
skipping logging after 67728 examples to avoid logging too frequently
skipping logging after 67744 examples to avoid logging too frequently
skipping logging after 67760 examples to avoid logging too frequently
train stats after 67776 examples: {'rewards_train/chosen': '-2.464', 'rewards_train/rejected': '-9.5107', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.0439', 'logps_train/rejected': '-224.97', 'logps_train/chosen': '-65.774', 'loss/train': '0.044953', 'examples_per_second': '5.3066', 'grad_norm': '5.125', 'counters/examples': 67776, 'counters/updates': 4236}
skipping logging after 67792 examples to avoid logging too frequently
skipping logging after 67808 examples to avoid logging too frequently
skipping logging after 67824 examples to avoid logging too frequently
train stats after 67840 examples: {'rewards_train/chosen': '-2.8282', 'rewards_train/rejected': '-10.339', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.5151', 'logps_train/rejected': '-236.49', 'logps_train/chosen': '-63.63', 'loss/train': '0.11002', 'examples_per_second': '3.9429', 'grad_norm': '13', 'counters/examples': 67840, 'counters/updates': 4240}
skipping logging after 67856 examples to avoid logging too frequently
skipping logging after 67872 examples to avoid logging too frequently
skipping logging after 67888 examples to avoid logging too frequently
train stats after 67904 examples: {'rewards_train/chosen': '-2.8981', 'rewards_train/rejected': '-11.297', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.3989', 'logps_train/rejected': '-237.01', 'logps_train/chosen': '-69.918', 'loss/train': '0.068766', 'examples_per_second': '5.4787', 'grad_norm': '7.5', 'counters/examples': 67904, 'counters/updates': 4244}
skipping logging after 67920 examples to avoid logging too frequently
skipping logging after 67936 examples to avoid logging too frequently
skipping logging after 67952 examples to avoid logging too frequently
train stats after 67968 examples: {'rewards_train/chosen': '-2.9071', 'rewards_train/rejected': '-11.675', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.769', 'logps_train/rejected': '-288.31', 'logps_train/chosen': '-75.496', 'loss/train': '0.051695', 'examples_per_second': '5.8188', 'grad_norm': '5.0938', 'counters/examples': 67968, 'counters/updates': 4248}
skipping logging after 67984 examples to avoid logging too frequently
skipping logging after 68000 examples to avoid logging too frequently
Running evaluation after 68000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:10,  2.26s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:04,  2.15s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:55,  1.92s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.90s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.55s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.66s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.49s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.57s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:36,  1.57s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.50s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:22,  1.30s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.25s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:20,  1.33s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.35s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:14,  1.28s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:33<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.30s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.27s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:37<00:07,  1.31s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:39<00:07,  1.48s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.42s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.62s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.43s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.42s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.41s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.44s/it]
eval after 68000: {'rewards_eval/chosen': '-11.046', 'rewards_eval/rejected': '-11.577', 'rewards_eval/accuracies': '0.53906', 'rewards_eval/margins': '0.53152', 'logps_eval/rejected': '-263.45', 'logps_eval/chosen': '-255.36', 'loss/eval': '2.0761'}
skipping logging after 68016 examples to avoid logging too frequently
train stats after 68032 examples: {'rewards_train/chosen': '-2.8559', 'rewards_train/rejected': '-11.29', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.4331', 'logps_train/rejected': '-252.51', 'logps_train/chosen': '-72.111', 'loss/train': '0.053168', 'examples_per_second': '5.4045', 'grad_norm': '6.7188', 'counters/examples': 68032, 'counters/updates': 4252}
skipping logging after 68048 examples to avoid logging too frequently
skipping logging after 68064 examples to avoid logging too frequently
skipping logging after 68080 examples to avoid logging too frequently
train stats after 68096 examples: {'rewards_train/chosen': '-2.9758', 'rewards_train/rejected': '-11.202', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.2264', 'logps_train/rejected': '-251.27', 'logps_train/chosen': '-65.487', 'loss/train': '0.054513', 'examples_per_second': '4.5172', 'grad_norm': '7.4375', 'counters/examples': 68096, 'counters/updates': 4256}
skipping logging after 68112 examples to avoid logging too frequently
skipping logging after 68128 examples to avoid logging too frequently
skipping logging after 68144 examples to avoid logging too frequently
train stats after 68160 examples: {'rewards_train/chosen': '-2.5659', 'rewards_train/rejected': '-10.379', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.8118', 'logps_train/rejected': '-237.59', 'logps_train/chosen': '-71.832', 'loss/train': '0.037426', 'examples_per_second': '4.5328', 'grad_norm': '6.3125', 'counters/examples': 68160, 'counters/updates': 4260}
skipping logging after 68176 examples to avoid logging too frequently
skipping logging after 68192 examples to avoid logging too frequently
skipping logging after 68208 examples to avoid logging too frequently
train stats after 68224 examples: {'rewards_train/chosen': '-2.1674', 'rewards_train/rejected': '-12.078', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.9098', 'logps_train/rejected': '-287.51', 'logps_train/chosen': '-61.954', 'loss/train': '0.015085', 'examples_per_second': '3.9663', 'grad_norm': '3.4688', 'counters/examples': 68224, 'counters/updates': 4264}
skipping logging after 68240 examples to avoid logging too frequently
skipping logging after 68256 examples to avoid logging too frequently
skipping logging after 68272 examples to avoid logging too frequently
train stats after 68288 examples: {'rewards_train/chosen': '-3.2295', 'rewards_train/rejected': '-10.644', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.4127', 'logps_train/rejected': '-226.14', 'logps_train/chosen': '-65.554', 'loss/train': '0.076945', 'examples_per_second': '4.707', 'grad_norm': '11.75', 'counters/examples': 68288, 'counters/updates': 4268}
skipping logging after 68304 examples to avoid logging too frequently
skipping logging after 68320 examples to avoid logging too frequently
skipping logging after 68336 examples to avoid logging too frequently
train stats after 68352 examples: {'rewards_train/chosen': '-2.8821', 'rewards_train/rejected': '-12.313', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.4316', 'logps_train/rejected': '-266.52', 'logps_train/chosen': '-63.765', 'loss/train': '0.033304', 'examples_per_second': '4.496', 'grad_norm': '6.5625', 'counters/examples': 68352, 'counters/updates': 4272}
skipping logging after 68368 examples to avoid logging too frequently
skipping logging after 68384 examples to avoid logging too frequently
skipping logging after 68400 examples to avoid logging too frequently
train stats after 68416 examples: {'rewards_train/chosen': '-3.6395', 'rewards_train/rejected': '-13.507', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.8669', 'logps_train/rejected': '-286.36', 'logps_train/chosen': '-85.328', 'loss/train': '0.11988', 'examples_per_second': '4.4078', 'grad_norm': '17.75', 'counters/examples': 68416, 'counters/updates': 4276}
skipping logging after 68432 examples to avoid logging too frequently
skipping logging after 68448 examples to avoid logging too frequently
skipping logging after 68464 examples to avoid logging too frequently
train stats after 68480 examples: {'rewards_train/chosen': '-2.6764', 'rewards_train/rejected': '-10.647', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.9707', 'logps_train/rejected': '-257.36', 'logps_train/chosen': '-66.429', 'loss/train': '0.067245', 'examples_per_second': '4.655', 'grad_norm': '8', 'counters/examples': 68480, 'counters/updates': 4280}
skipping logging after 68496 examples to avoid logging too frequently
skipping logging after 68512 examples to avoid logging too frequently
skipping logging after 68528 examples to avoid logging too frequently
train stats after 68544 examples: {'rewards_train/chosen': '-3.2245', 'rewards_train/rejected': '-11.351', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '8.1318', 'logps_train/rejected': '-263.95', 'logps_train/chosen': '-65.469', 'loss/train': '0.12136', 'examples_per_second': '5.5293', 'grad_norm': '15.562', 'counters/examples': 68544, 'counters/updates': 4284}
skipping logging after 68560 examples to avoid logging too frequently
skipping logging after 68576 examples to avoid logging too frequently
skipping logging after 68592 examples to avoid logging too frequently
train stats after 68608 examples: {'rewards_train/chosen': '-2.537', 'rewards_train/rejected': '-10.598', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.059', 'logps_train/rejected': '-250.39', 'logps_train/chosen': '-66.653', 'loss/train': '0.051394', 'examples_per_second': '4.7724', 'grad_norm': '4.5625', 'counters/examples': 68608, 'counters/updates': 4288}
skipping logging after 68624 examples to avoid logging too frequently
skipping logging after 68640 examples to avoid logging too frequently
skipping logging after 68656 examples to avoid logging too frequently
train stats after 68672 examples: {'rewards_train/chosen': '-2.556', 'rewards_train/rejected': '-10.651', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.0927', 'logps_train/rejected': '-253.49', 'logps_train/chosen': '-57.989', 'loss/train': '0.13308', 'examples_per_second': '4.7954', 'grad_norm': '14.5', 'counters/examples': 68672, 'counters/updates': 4292}
skipping logging after 68688 examples to avoid logging too frequently
skipping logging after 68704 examples to avoid logging too frequently
skipping logging after 68720 examples to avoid logging too frequently
train stats after 68736 examples: {'rewards_train/chosen': '-2.5444', 'rewards_train/rejected': '-11.193', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.6519', 'logps_train/rejected': '-252.24', 'logps_train/chosen': '-65.688', 'loss/train': '0.046734', 'examples_per_second': '6.3507', 'grad_norm': '5.5', 'counters/examples': 68736, 'counters/updates': 4296}
skipping logging after 68752 examples to avoid logging too frequently
skipping logging after 68768 examples to avoid logging too frequently
skipping logging after 68784 examples to avoid logging too frequently
train stats after 68800 examples: {'rewards_train/chosen': '-2.4204', 'rewards_train/rejected': '-11.082', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.6572', 'logps_train/rejected': '-260.17', 'logps_train/chosen': '-69.691', 'loss/train': '0.0588', 'examples_per_second': '6.0228', 'grad_norm': '8.375', 'counters/examples': 68800, 'counters/updates': 4300}
skipping logging after 68816 examples to avoid logging too frequently
skipping logging after 68832 examples to avoid logging too frequently
skipping logging after 68848 examples to avoid logging too frequently
train stats after 68864 examples: {'rewards_train/chosen': '-3.0542', 'rewards_train/rejected': '-12.354', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '9.3041', 'logps_train/rejected': '-261.61', 'logps_train/chosen': '-71.133', 'loss/train': '0.11629', 'examples_per_second': '5.5026', 'grad_norm': '21.375', 'counters/examples': 68864, 'counters/updates': 4304}
skipping logging after 68880 examples to avoid logging too frequently
skipping logging after 68896 examples to avoid logging too frequently
skipping logging after 68912 examples to avoid logging too frequently
train stats after 68928 examples: {'rewards_train/chosen': '-2.5752', 'rewards_train/rejected': '-12.608', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '10.035', 'logps_train/rejected': '-294.13', 'logps_train/chosen': '-68.322', 'loss/train': '0.074489', 'examples_per_second': '4.8903', 'grad_norm': '12.062', 'counters/examples': 68928, 'counters/updates': 4308}
skipping logging after 68944 examples to avoid logging too frequently
skipping logging after 68960 examples to avoid logging too frequently
skipping logging after 68976 examples to avoid logging too frequently
train stats after 68992 examples: {'rewards_train/chosen': '-2.7935', 'rewards_train/rejected': '-10.14', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.3489', 'logps_train/rejected': '-219.02', 'logps_train/chosen': '-67.955', 'loss/train': '0.095507', 'examples_per_second': '4.9108', 'grad_norm': '13.75', 'counters/examples': 68992, 'counters/updates': 4312}
skipping logging after 69008 examples to avoid logging too frequently
skipping logging after 69024 examples to avoid logging too frequently
skipping logging after 69040 examples to avoid logging too frequently
train stats after 69056 examples: {'rewards_train/chosen': '-3.1664', 'rewards_train/rejected': '-10.862', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.6928', 'logps_train/rejected': '-239.17', 'logps_train/chosen': '-76.521', 'loss/train': '0.088724', 'examples_per_second': '5.4786', 'grad_norm': '12.75', 'counters/examples': 69056, 'counters/updates': 4316}
skipping logging after 69072 examples to avoid logging too frequently
skipping logging after 69088 examples to avoid logging too frequently
skipping logging after 69104 examples to avoid logging too frequently
train stats after 69120 examples: {'rewards_train/chosen': '-2.4666', 'rewards_train/rejected': '-10.74', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.2737', 'logps_train/rejected': '-241.46', 'logps_train/chosen': '-71.378', 'loss/train': '0.048478', 'examples_per_second': '5.3869', 'grad_norm': '6.25', 'counters/examples': 69120, 'counters/updates': 4320}
skipping logging after 69136 examples to avoid logging too frequently
skipping logging after 69152 examples to avoid logging too frequently
skipping logging after 69168 examples to avoid logging too frequently
train stats after 69184 examples: {'rewards_train/chosen': '-2.2809', 'rewards_train/rejected': '-10.567', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.2842', 'logps_train/rejected': '-227.37', 'logps_train/chosen': '-56.102', 'loss/train': '0.074736', 'examples_per_second': '5.1749', 'grad_norm': '9.0625', 'counters/examples': 69184, 'counters/updates': 4324}
skipping logging after 69200 examples to avoid logging too frequently
skipping logging after 69216 examples to avoid logging too frequently
skipping logging after 69232 examples to avoid logging too frequently
train stats after 69248 examples: {'rewards_train/chosen': '-2.5516', 'rewards_train/rejected': '-11.372', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.8198', 'logps_train/rejected': '-260.6', 'logps_train/chosen': '-79.162', 'loss/train': '0.10786', 'examples_per_second': '4.6578', 'grad_norm': '14.938', 'counters/examples': 69248, 'counters/updates': 4328}
skipping logging after 69264 examples to avoid logging too frequently
skipping logging after 69280 examples to avoid logging too frequently
skipping logging after 69296 examples to avoid logging too frequently
train stats after 69312 examples: {'rewards_train/chosen': '-2.6693', 'rewards_train/rejected': '-10.584', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.9143', 'logps_train/rejected': '-242.53', 'logps_train/chosen': '-69.025', 'loss/train': '0.11133', 'examples_per_second': '5.7097', 'grad_norm': '13.312', 'counters/examples': 69312, 'counters/updates': 4332}
skipping logging after 69328 examples to avoid logging too frequently
skipping logging after 69344 examples to avoid logging too frequently
skipping logging after 69360 examples to avoid logging too frequently
train stats after 69376 examples: {'rewards_train/chosen': '-2.6335', 'rewards_train/rejected': '-9.7368', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.104', 'logps_train/rejected': '-231.17', 'logps_train/chosen': '-65.396', 'loss/train': '0.062722', 'examples_per_second': '4.7849', 'grad_norm': '9.1875', 'counters/examples': 69376, 'counters/updates': 4336}
skipping logging after 69392 examples to avoid logging too frequently
skipping logging after 69408 examples to avoid logging too frequently
skipping logging after 69424 examples to avoid logging too frequently
train stats after 69440 examples: {'rewards_train/chosen': '-2.4485', 'rewards_train/rejected': '-11.55', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.1033', 'logps_train/rejected': '-261.5', 'logps_train/chosen': '-63.789', 'loss/train': '0.024811', 'examples_per_second': '4.7025', 'grad_norm': '5.7812', 'counters/examples': 69440, 'counters/updates': 4340}
skipping logging after 69456 examples to avoid logging too frequently
skipping logging after 69472 examples to avoid logging too frequently
skipping logging after 69488 examples to avoid logging too frequently
train stats after 69504 examples: {'rewards_train/chosen': '-2.6708', 'rewards_train/rejected': '-10.392', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.7217', 'logps_train/rejected': '-232.37', 'logps_train/chosen': '-59.839', 'loss/train': '0.083394', 'examples_per_second': '4.77', 'grad_norm': '6.4375', 'counters/examples': 69504, 'counters/updates': 4344}
skipping logging after 69520 examples to avoid logging too frequently
skipping logging after 69536 examples to avoid logging too frequently
skipping logging after 69552 examples to avoid logging too frequently
train stats after 69568 examples: {'rewards_train/chosen': '-2.6326', 'rewards_train/rejected': '-11.895', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.2644', 'logps_train/rejected': '-281.77', 'logps_train/chosen': '-73.557', 'loss/train': '0.057014', 'examples_per_second': '4.0807', 'grad_norm': '6.4375', 'counters/examples': 69568, 'counters/updates': 4348}
skipping logging after 69584 examples to avoid logging too frequently
skipping logging after 69600 examples to avoid logging too frequently
skipping logging after 69616 examples to avoid logging too frequently
train stats after 69632 examples: {'rewards_train/chosen': '-2.7272', 'rewards_train/rejected': '-10.381', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.6531', 'logps_train/rejected': '-224.18', 'logps_train/chosen': '-59.742', 'loss/train': '0.047345', 'examples_per_second': '5.0006', 'grad_norm': '9.4375', 'counters/examples': 69632, 'counters/updates': 4352}
skipping logging after 69648 examples to avoid logging too frequently
skipping logging after 69664 examples to avoid logging too frequently
skipping logging after 69680 examples to avoid logging too frequently
train stats after 69696 examples: {'rewards_train/chosen': '-2.6691', 'rewards_train/rejected': '-10.237', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.5697', 'logps_train/rejected': '-231.8', 'logps_train/chosen': '-64.977', 'loss/train': '0.079156', 'examples_per_second': '5.8682', 'grad_norm': '11.312', 'counters/examples': 69696, 'counters/updates': 4356}
skipping logging after 69712 examples to avoid logging too frequently
skipping logging after 69728 examples to avoid logging too frequently
skipping logging after 69744 examples to avoid logging too frequently
train stats after 69760 examples: {'rewards_train/chosen': '-2.5414', 'rewards_train/rejected': '-10.592', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.0522', 'logps_train/rejected': '-252.2', 'logps_train/chosen': '-66.568', 'loss/train': '0.071229', 'examples_per_second': '4.3462', 'grad_norm': '11.812', 'counters/examples': 69760, 'counters/updates': 4360}
skipping logging after 69776 examples to avoid logging too frequently
skipping logging after 69792 examples to avoid logging too frequently
skipping logging after 69808 examples to avoid logging too frequently
train stats after 69824 examples: {'rewards_train/chosen': '-2.79', 'rewards_train/rejected': '-10.239', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.4468', 'logps_train/rejected': '-242.39', 'logps_train/chosen': '-68.167', 'loss/train': '0.051322', 'examples_per_second': '5.3936', 'grad_norm': '8', 'counters/examples': 69824, 'counters/updates': 4364}
skipping logging after 69840 examples to avoid logging too frequently
skipping logging after 69856 examples to avoid logging too frequently
skipping logging after 69872 examples to avoid logging too frequently
train stats after 69888 examples: {'rewards_train/chosen': '-2.5023', 'rewards_train/rejected': '-9.6292', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.1267', 'logps_train/rejected': '-208.08', 'logps_train/chosen': '-66.363', 'loss/train': '0.032016', 'examples_per_second': '5.6374', 'grad_norm': '7.625', 'counters/examples': 69888, 'counters/updates': 4368}
skipping logging after 69904 examples to avoid logging too frequently
skipping logging after 69920 examples to avoid logging too frequently
skipping logging after 69936 examples to avoid logging too frequently
train stats after 69952 examples: {'rewards_train/chosen': '-2.4903', 'rewards_train/rejected': '-11.829', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.3427', 'logps_train/rejected': '-272.58', 'logps_train/chosen': '-68.535', 'loss/train': '0.032093', 'examples_per_second': '5.2118', 'grad_norm': '2.8438', 'counters/examples': 69952, 'counters/updates': 4372}
skipping logging after 69968 examples to avoid logging too frequently
skipping logging after 69984 examples to avoid logging too frequently
skipping logging after 70000 examples to avoid logging too frequently
train stats after 70016 examples: {'rewards_train/chosen': '-2.7342', 'rewards_train/rejected': '-11.529', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.7957', 'logps_train/rejected': '-264.95', 'logps_train/chosen': '-66.591', 'loss/train': '0.23701', 'examples_per_second': '4.6014', 'grad_norm': '22.875', 'counters/examples': 70016, 'counters/updates': 4376}
skipping logging after 70032 examples to avoid logging too frequently
skipping logging after 70048 examples to avoid logging too frequently
skipping logging after 70064 examples to avoid logging too frequently
train stats after 70080 examples: {'rewards_train/chosen': '-2.8555', 'rewards_train/rejected': '-10.653', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.7996', 'logps_train/rejected': '-246.76', 'logps_train/chosen': '-66.33', 'loss/train': '0.048612', 'examples_per_second': '4.7547', 'grad_norm': '8.4375', 'counters/examples': 70080, 'counters/updates': 4380}
skipping logging after 70096 examples to avoid logging too frequently
skipping logging after 70112 examples to avoid logging too frequently
skipping logging after 70128 examples to avoid logging too frequently
train stats after 70144 examples: {'rewards_train/chosen': '-2.8685', 'rewards_train/rejected': '-10.835', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.9695', 'logps_train/rejected': '-225.14', 'logps_train/chosen': '-68.832', 'loss/train': '0.090532', 'examples_per_second': '5.6101', 'grad_norm': '12.625', 'counters/examples': 70144, 'counters/updates': 4384}
skipping logging after 70160 examples to avoid logging too frequently
skipping logging after 70176 examples to avoid logging too frequently
skipping logging after 70192 examples to avoid logging too frequently
train stats after 70208 examples: {'rewards_train/chosen': '-3.1391', 'rewards_train/rejected': '-10.387', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.249', 'logps_train/rejected': '-232.53', 'logps_train/chosen': '-67.924', 'loss/train': '0.058289', 'examples_per_second': '5.2131', 'grad_norm': '19.875', 'counters/examples': 70208, 'counters/updates': 4388}
skipping logging after 70224 examples to avoid logging too frequently
skipping logging after 70240 examples to avoid logging too frequently
skipping logging after 70256 examples to avoid logging too frequently
train stats after 70272 examples: {'rewards_train/chosen': '-2.6592', 'rewards_train/rejected': '-9.6904', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.0317', 'logps_train/rejected': '-226.98', 'logps_train/chosen': '-67.16', 'loss/train': '0.11954', 'examples_per_second': '5.6787', 'grad_norm': '13.25', 'counters/examples': 70272, 'counters/updates': 4392}
skipping logging after 70288 examples to avoid logging too frequently
skipping logging after 70304 examples to avoid logging too frequently
skipping logging after 70320 examples to avoid logging too frequently
train stats after 70336 examples: {'rewards_train/chosen': '-2.9269', 'rewards_train/rejected': '-11.922', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.9927', 'logps_train/rejected': '-264.41', 'logps_train/chosen': '-72.807', 'loss/train': '0.13265', 'examples_per_second': '3.9629', 'grad_norm': '15.438', 'counters/examples': 70336, 'counters/updates': 4396}
skipping logging after 70352 examples to avoid logging too frequently
skipping logging after 70368 examples to avoid logging too frequently
skipping logging after 70384 examples to avoid logging too frequently
train stats after 70400 examples: {'rewards_train/chosen': '-3.1191', 'rewards_train/rejected': '-10.882', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.7609', 'logps_train/rejected': '-257.35', 'logps_train/chosen': '-66.775', 'loss/train': '0.085887', 'examples_per_second': '5.8641', 'grad_norm': '15', 'counters/examples': 70400, 'counters/updates': 4400}
skipping logging after 70416 examples to avoid logging too frequently
skipping logging after 70432 examples to avoid logging too frequently
skipping logging after 70448 examples to avoid logging too frequently
train stats after 70464 examples: {'rewards_train/chosen': '-2.7999', 'rewards_train/rejected': '-11.35', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.5479', 'logps_train/rejected': '-259.27', 'logps_train/chosen': '-71.59', 'loss/train': '0.084381', 'examples_per_second': '5.9434', 'grad_norm': '9.0625', 'counters/examples': 70464, 'counters/updates': 4404}
skipping logging after 70480 examples to avoid logging too frequently
skipping logging after 70496 examples to avoid logging too frequently
skipping logging after 70512 examples to avoid logging too frequently
train stats after 70528 examples: {'rewards_train/chosen': '-2.6286', 'rewards_train/rejected': '-9.7986', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.1729', 'logps_train/rejected': '-211.94', 'logps_train/chosen': '-69.136', 'loss/train': '0.16982', 'examples_per_second': '5.7945', 'grad_norm': '17.125', 'counters/examples': 70528, 'counters/updates': 4408}
skipping logging after 70544 examples to avoid logging too frequently
skipping logging after 70560 examples to avoid logging too frequently
skipping logging after 70576 examples to avoid logging too frequently
train stats after 70592 examples: {'rewards_train/chosen': '-2.5058', 'rewards_train/rejected': '-10.345', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.8389', 'logps_train/rejected': '-252.48', 'logps_train/chosen': '-63.973', 'loss/train': '0.064526', 'examples_per_second': '5.0395', 'grad_norm': '5.125', 'counters/examples': 70592, 'counters/updates': 4412}
skipping logging after 70608 examples to avoid logging too frequently
skipping logging after 70624 examples to avoid logging too frequently
skipping logging after 70640 examples to avoid logging too frequently
train stats after 70656 examples: {'rewards_train/chosen': '-2.841', 'rewards_train/rejected': '-11.228', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.3875', 'logps_train/rejected': '-283.4', 'logps_train/chosen': '-71.053', 'loss/train': '0.08661', 'examples_per_second': '4.4802', 'grad_norm': '11.312', 'counters/examples': 70656, 'counters/updates': 4416}
skipping logging after 70672 examples to avoid logging too frequently
skipping logging after 70688 examples to avoid logging too frequently
skipping logging after 70704 examples to avoid logging too frequently
train stats after 70720 examples: {'rewards_train/chosen': '-2.3794', 'rewards_train/rejected': '-10.85', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.4714', 'logps_train/rejected': '-249.75', 'logps_train/chosen': '-58.637', 'loss/train': '0.071875', 'examples_per_second': '5.7617', 'grad_norm': '7.0625', 'counters/examples': 70720, 'counters/updates': 4420}
skipping logging after 70736 examples to avoid logging too frequently
skipping logging after 70752 examples to avoid logging too frequently
skipping logging after 70768 examples to avoid logging too frequently
train stats after 70784 examples: {'rewards_train/chosen': '-3.2408', 'rewards_train/rejected': '-10.714', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.4723', 'logps_train/rejected': '-229', 'logps_train/chosen': '-69.845', 'loss/train': '0.080328', 'examples_per_second': '5.6626', 'grad_norm': '15.312', 'counters/examples': 70784, 'counters/updates': 4424}
skipping logging after 70800 examples to avoid logging too frequently
skipping logging after 70816 examples to avoid logging too frequently
skipping logging after 70832 examples to avoid logging too frequently
train stats after 70848 examples: {'rewards_train/chosen': '-3.1936', 'rewards_train/rejected': '-10.527', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.3369', 'logps_train/rejected': '-240.47', 'logps_train/chosen': '-66.496', 'loss/train': '0.12745', 'examples_per_second': '4.2037', 'grad_norm': '13.438', 'counters/examples': 70848, 'counters/updates': 4428}
skipping logging after 70864 examples to avoid logging too frequently
skipping logging after 70880 examples to avoid logging too frequently
skipping logging after 70896 examples to avoid logging too frequently
train stats after 70912 examples: {'rewards_train/chosen': '-2.6091', 'rewards_train/rejected': '-10.462', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.856', 'logps_train/rejected': '-243.96', 'logps_train/chosen': '-70.159', 'loss/train': '0.056763', 'examples_per_second': '5.9122', 'grad_norm': '7.1562', 'counters/examples': 70912, 'counters/updates': 4432}
skipping logging after 70928 examples to avoid logging too frequently
skipping logging after 70944 examples to avoid logging too frequently
skipping logging after 70960 examples to avoid logging too frequently
train stats after 70976 examples: {'rewards_train/chosen': '-2.8875', 'rewards_train/rejected': '-10.427', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.5388', 'logps_train/rejected': '-215.8', 'logps_train/chosen': '-76.434', 'loss/train': '0.054172', 'examples_per_second': '5.0786', 'grad_norm': '10.375', 'counters/examples': 70976, 'counters/updates': 4436}
skipping logging after 70992 examples to avoid logging too frequently
skipping logging after 71008 examples to avoid logging too frequently
skipping logging after 71024 examples to avoid logging too frequently
train stats after 71040 examples: {'rewards_train/chosen': '-2.7471', 'rewards_train/rejected': '-11.833', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.0886', 'logps_train/rejected': '-291.54', 'logps_train/chosen': '-76.018', 'loss/train': '0.055211', 'examples_per_second': '4.71', 'grad_norm': '7.4062', 'counters/examples': 71040, 'counters/updates': 4440}
skipping logging after 71056 examples to avoid logging too frequently
skipping logging after 71072 examples to avoid logging too frequently
skipping logging after 71088 examples to avoid logging too frequently
train stats after 71104 examples: {'rewards_train/chosen': '-3.1369', 'rewards_train/rejected': '-12.319', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '9.1841', 'logps_train/rejected': '-252.86', 'logps_train/chosen': '-68.522', 'loss/train': '0.092597', 'examples_per_second': '4.3677', 'grad_norm': '9.5', 'counters/examples': 71104, 'counters/updates': 4444}
skipping logging after 71120 examples to avoid logging too frequently
skipping logging after 71136 examples to avoid logging too frequently
skipping logging after 71152 examples to avoid logging too frequently
train stats after 71168 examples: {'rewards_train/chosen': '-3.4212', 'rewards_train/rejected': '-12.053', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.6319', 'logps_train/rejected': '-254.24', 'logps_train/chosen': '-79.646', 'loss/train': '0.14067', 'examples_per_second': '5.4088', 'grad_norm': '13.125', 'counters/examples': 71168, 'counters/updates': 4448}
skipping logging after 71184 examples to avoid logging too frequently
skipping logging after 71200 examples to avoid logging too frequently
skipping logging after 71216 examples to avoid logging too frequently
train stats after 71232 examples: {'rewards_train/chosen': '-3.2242', 'rewards_train/rejected': '-13.06', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.8369', 'logps_train/rejected': '-278.45', 'logps_train/chosen': '-75.236', 'loss/train': '0.055737', 'examples_per_second': '6.0478', 'grad_norm': '4.875', 'counters/examples': 71232, 'counters/updates': 4452}
skipping logging after 71248 examples to avoid logging too frequently
skipping logging after 71264 examples to avoid logging too frequently
skipping logging after 71280 examples to avoid logging too frequently
train stats after 71296 examples: {'rewards_train/chosen': '-3.7849', 'rewards_train/rejected': '-12.538', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.7544', 'logps_train/rejected': '-266.73', 'logps_train/chosen': '-73.09', 'loss/train': '0.1069', 'examples_per_second': '4.5109', 'grad_norm': '11.938', 'counters/examples': 71296, 'counters/updates': 4456}
skipping logging after 71312 examples to avoid logging too frequently
skipping logging after 71328 examples to avoid logging too frequently
skipping logging after 71344 examples to avoid logging too frequently
train stats after 71360 examples: {'rewards_train/chosen': '-3.3033', 'rewards_train/rejected': '-12.012', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.7087', 'logps_train/rejected': '-246.69', 'logps_train/chosen': '-65.482', 'loss/train': '0.038743', 'examples_per_second': '5.6378', 'grad_norm': '7.0938', 'counters/examples': 71360, 'counters/updates': 4460}
skipping logging after 71376 examples to avoid logging too frequently
skipping logging after 71392 examples to avoid logging too frequently
skipping logging after 71408 examples to avoid logging too frequently
train stats after 71424 examples: {'rewards_train/chosen': '-3.4331', 'rewards_train/rejected': '-11.015', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.582', 'logps_train/rejected': '-227.56', 'logps_train/chosen': '-60.562', 'loss/train': '0.051794', 'examples_per_second': '6.513', 'grad_norm': '6.25', 'counters/examples': 71424, 'counters/updates': 4464}
skipping logging after 71440 examples to avoid logging too frequently
skipping logging after 71456 examples to avoid logging too frequently
skipping logging after 71472 examples to avoid logging too frequently
train stats after 71488 examples: {'rewards_train/chosen': '-3.3597', 'rewards_train/rejected': '-13.109', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.7505', 'logps_train/rejected': '-289.7', 'logps_train/chosen': '-81.946', 'loss/train': '0.15391', 'examples_per_second': '4.4775', 'grad_norm': '19.625', 'counters/examples': 71488, 'counters/updates': 4468}
skipping logging after 71504 examples to avoid logging too frequently
skipping logging after 71520 examples to avoid logging too frequently
skipping logging after 71536 examples to avoid logging too frequently
train stats after 71552 examples: {'rewards_train/chosen': '-3.2068', 'rewards_train/rejected': '-12.167', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.9631', 'logps_train/rejected': '-252.85', 'logps_train/chosen': '-66.976', 'loss/train': '0.05025', 'examples_per_second': '4.6881', 'grad_norm': '10', 'counters/examples': 71552, 'counters/updates': 4472}
skipping logging after 71568 examples to avoid logging too frequently
skipping logging after 71584 examples to avoid logging too frequently
skipping logging after 71600 examples to avoid logging too frequently
train stats after 71616 examples: {'rewards_train/chosen': '-3.0292', 'rewards_train/rejected': '-9.988', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.9626', 'logps_train/rejected': '-222.96', 'logps_train/chosen': '-75.396', 'loss/train': '0.081869', 'examples_per_second': '5.2323', 'grad_norm': '12.312', 'counters/examples': 71616, 'counters/updates': 4476}
skipping logging after 71632 examples to avoid logging too frequently
skipping logging after 71648 examples to avoid logging too frequently
skipping logging after 71664 examples to avoid logging too frequently
train stats after 71680 examples: {'rewards_train/chosen': '-3.1485', 'rewards_train/rejected': '-12.183', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.0396', 'logps_train/rejected': '-278.12', 'logps_train/chosen': '-71.346', 'loss/train': '0.05306', 'examples_per_second': '5.4408', 'grad_norm': '8.0625', 'counters/examples': 71680, 'counters/updates': 4480}
skipping logging after 71696 examples to avoid logging too frequently
skipping logging after 71712 examples to avoid logging too frequently
skipping logging after 71728 examples to avoid logging too frequently
train stats after 71744 examples: {'rewards_train/chosen': '-3.4432', 'rewards_train/rejected': '-11.087', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.6416', 'logps_train/rejected': '-224.05', 'logps_train/chosen': '-82.524', 'loss/train': '0.12385', 'examples_per_second': '5.8118', 'grad_norm': '12.562', 'counters/examples': 71744, 'counters/updates': 4484}
skipping logging after 71760 examples to avoid logging too frequently
skipping logging after 71776 examples to avoid logging too frequently
skipping logging after 71792 examples to avoid logging too frequently
train stats after 71808 examples: {'rewards_train/chosen': '-3.0585', 'rewards_train/rejected': '-12.38', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.3245', 'logps_train/rejected': '-244.07', 'logps_train/chosen': '-65.941', 'loss/train': '0.049258', 'examples_per_second': '6.1777', 'grad_norm': '6.75', 'counters/examples': 71808, 'counters/updates': 4488}
skipping logging after 71824 examples to avoid logging too frequently
skipping logging after 71840 examples to avoid logging too frequently
skipping logging after 71856 examples to avoid logging too frequently
train stats after 71872 examples: {'rewards_train/chosen': '-2.9375', 'rewards_train/rejected': '-11.528', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '8.5902', 'logps_train/rejected': '-243.99', 'logps_train/chosen': '-74.561', 'loss/train': '0.094165', 'examples_per_second': '4.923', 'grad_norm': '12.188', 'counters/examples': 71872, 'counters/updates': 4492}
skipping logging after 71888 examples to avoid logging too frequently
skipping logging after 71904 examples to avoid logging too frequently
skipping logging after 71920 examples to avoid logging too frequently
train stats after 71936 examples: {'rewards_train/chosen': '-2.881', 'rewards_train/rejected': '-13.047', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '10.169', 'logps_train/rejected': '-283', 'logps_train/chosen': '-61.457', 'loss/train': '0.065274', 'examples_per_second': '5.685', 'grad_norm': '11.875', 'counters/examples': 71936, 'counters/updates': 4496}
skipping logging after 71952 examples to avoid logging too frequently
skipping logging after 71968 examples to avoid logging too frequently
skipping logging after 71984 examples to avoid logging too frequently
train stats after 72000 examples: {'rewards_train/chosen': '-2.908', 'rewards_train/rejected': '-11.925', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.0179', 'logps_train/rejected': '-271.88', 'logps_train/chosen': '-72.271', 'loss/train': '0.047219', 'examples_per_second': '4.9113', 'grad_norm': '11.25', 'counters/examples': 72000, 'counters/updates': 4500}
Running evaluation after 72000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<01:00,  1.94s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:00,  2.01s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:53,  1.84s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.85s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.52s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.49s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:22,  1.30s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.24s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.33s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.34s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:14,  1.28s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.16s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.30s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.27s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.31s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.48s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.42s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.62s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.43s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.42s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 72000: {'rewards_eval/chosen': '-12.312', 'rewards_eval/rejected': '-12.863', 'rewards_eval/accuracies': '0.53711', 'rewards_eval/margins': '0.5509', 'logps_eval/rejected': '-276.3', 'logps_eval/chosen': '-268.03', 'loss/eval': '2.3738'}
skipping logging after 72016 examples to avoid logging too frequently
skipping logging after 72032 examples to avoid logging too frequently
skipping logging after 72048 examples to avoid logging too frequently
train stats after 72064 examples: {'rewards_train/chosen': '-3.1646', 'rewards_train/rejected': '-10.915', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.7466', 'logps_train/rejected': '-228.48', 'logps_train/chosen': '-72.848', 'loss/train': '0.098332', 'examples_per_second': '6.2923', 'grad_norm': '17.375', 'counters/examples': 72064, 'counters/updates': 4504}
skipping logging after 72080 examples to avoid logging too frequently
skipping logging after 72096 examples to avoid logging too frequently
skipping logging after 72112 examples to avoid logging too frequently
train stats after 72128 examples: {'rewards_train/chosen': '-3.2246', 'rewards_train/rejected': '-12.843', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.6218', 'logps_train/rejected': '-262.48', 'logps_train/chosen': '-67.173', 'loss/train': '0.036071', 'examples_per_second': '5.7464', 'grad_norm': '3.2344', 'counters/examples': 72128, 'counters/updates': 4508}
skipping logging after 72144 examples to avoid logging too frequently
skipping logging after 72160 examples to avoid logging too frequently
skipping logging after 72176 examples to avoid logging too frequently
train stats after 72192 examples: {'rewards_train/chosen': '-3.3554', 'rewards_train/rejected': '-13.208', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.855', 'logps_train/rejected': '-270.86', 'logps_train/chosen': '-71.799', 'loss/train': '0.081583', 'examples_per_second': '5.326', 'grad_norm': '6.875', 'counters/examples': 72192, 'counters/updates': 4512}
skipping logging after 72208 examples to avoid logging too frequently
skipping logging after 72224 examples to avoid logging too frequently
skipping logging after 72240 examples to avoid logging too frequently
train stats after 72256 examples: {'rewards_train/chosen': '-3.5443', 'rewards_train/rejected': '-13.467', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.9238', 'logps_train/rejected': '-277.3', 'logps_train/chosen': '-67.86', 'loss/train': '0.03196', 'examples_per_second': '5.1172', 'grad_norm': '8.875', 'counters/examples': 72256, 'counters/updates': 4516}
skipping logging after 72272 examples to avoid logging too frequently
skipping logging after 72288 examples to avoid logging too frequently
skipping logging after 72304 examples to avoid logging too frequently
train stats after 72320 examples: {'rewards_train/chosen': '-3.2992', 'rewards_train/rejected': '-11.753', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.4573', 'logps_train/rejected': '-245.5', 'logps_train/chosen': '-80.476', 'loss/train': '0.044376', 'examples_per_second': '4.3643', 'grad_norm': '4.375', 'counters/examples': 72320, 'counters/updates': 4520}
skipping logging after 72336 examples to avoid logging too frequently
skipping logging after 72352 examples to avoid logging too frequently
skipping logging after 72368 examples to avoid logging too frequently
train stats after 72384 examples: {'rewards_train/chosen': '-3.367', 'rewards_train/rejected': '-12.524', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.1562', 'logps_train/rejected': '-291.92', 'logps_train/chosen': '-78.436', 'loss/train': '0.090529', 'examples_per_second': '4.7672', 'grad_norm': '13.062', 'counters/examples': 72384, 'counters/updates': 4524}
skipping logging after 72400 examples to avoid logging too frequently
skipping logging after 72416 examples to avoid logging too frequently
skipping logging after 72432 examples to avoid logging too frequently
train stats after 72448 examples: {'rewards_train/chosen': '-3.0311', 'rewards_train/rejected': '-12.615', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.5803', 'logps_train/rejected': '-272.64', 'logps_train/chosen': '-65.645', 'loss/train': '0.061802', 'examples_per_second': '5.8365', 'grad_norm': '11.938', 'counters/examples': 72448, 'counters/updates': 4528}
skipping logging after 72464 examples to avoid logging too frequently
skipping logging after 72480 examples to avoid logging too frequently
skipping logging after 72496 examples to avoid logging too frequently
train stats after 72512 examples: {'rewards_train/chosen': '-3.3831', 'rewards_train/rejected': '-10.824', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.4379', 'logps_train/rejected': '-208.8', 'logps_train/chosen': '-71.955', 'loss/train': '0.095774', 'examples_per_second': '7.1215', 'grad_norm': '14.562', 'counters/examples': 72512, 'counters/updates': 4532}
skipping logging after 72528 examples to avoid logging too frequently
skipping logging after 72544 examples to avoid logging too frequently
skipping logging after 72560 examples to avoid logging too frequently
train stats after 72576 examples: {'rewards_train/chosen': '-3.0417', 'rewards_train/rejected': '-13.149', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '10.107', 'logps_train/rejected': '-299.21', 'logps_train/chosen': '-78.75', 'loss/train': '0.017126', 'examples_per_second': '5.1267', 'grad_norm': '4.5', 'counters/examples': 72576, 'counters/updates': 4536}
skipping logging after 72592 examples to avoid logging too frequently
skipping logging after 72608 examples to avoid logging too frequently
skipping logging after 72624 examples to avoid logging too frequently
train stats after 72640 examples: {'rewards_train/chosen': '-2.9071', 'rewards_train/rejected': '-12.271', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.3618', 'logps_train/rejected': '-231.45', 'logps_train/chosen': '-74.391', 'loss/train': '0.063277', 'examples_per_second': '5.5855', 'grad_norm': '18.875', 'counters/examples': 72640, 'counters/updates': 4540}
skipping logging after 72656 examples to avoid logging too frequently
skipping logging after 72672 examples to avoid logging too frequently
skipping logging after 72688 examples to avoid logging too frequently
train stats after 72704 examples: {'rewards_train/chosen': '-2.9996', 'rewards_train/rejected': '-12.347', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.3447', 'logps_train/rejected': '-256.55', 'logps_train/chosen': '-75.288', 'loss/train': '0.090515', 'examples_per_second': '5.6054', 'grad_norm': '8.5', 'counters/examples': 72704, 'counters/updates': 4544}
skipping logging after 72720 examples to avoid logging too frequently
skipping logging after 72736 examples to avoid logging too frequently
skipping logging after 72752 examples to avoid logging too frequently
train stats after 72768 examples: {'rewards_train/chosen': '-3.0516', 'rewards_train/rejected': '-11.06', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.0103', 'logps_train/rejected': '-248.25', 'logps_train/chosen': '-70.795', 'loss/train': '0.12062', 'examples_per_second': '5.1304', 'grad_norm': '12.875', 'counters/examples': 72768, 'counters/updates': 4548}
skipping logging after 72784 examples to avoid logging too frequently
skipping logging after 72800 examples to avoid logging too frequently
skipping logging after 72816 examples to avoid logging too frequently
train stats after 72832 examples: {'rewards_train/chosen': '-3.1329', 'rewards_train/rejected': '-10.708', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.575', 'logps_train/rejected': '-242.48', 'logps_train/chosen': '-75.797', 'loss/train': '0.089936', 'examples_per_second': '5.3862', 'grad_norm': '11.938', 'counters/examples': 72832, 'counters/updates': 4552}
skipping logging after 72848 examples to avoid logging too frequently
skipping logging after 72864 examples to avoid logging too frequently
skipping logging after 72880 examples to avoid logging too frequently
train stats after 72896 examples: {'rewards_train/chosen': '-2.6612', 'rewards_train/rejected': '-11.194', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.533', 'logps_train/rejected': '-249.21', 'logps_train/chosen': '-74.269', 'loss/train': '0.049206', 'examples_per_second': '5.9881', 'grad_norm': '8.25', 'counters/examples': 72896, 'counters/updates': 4556}
skipping logging after 72912 examples to avoid logging too frequently
skipping logging after 72928 examples to avoid logging too frequently
skipping logging after 72944 examples to avoid logging too frequently
train stats after 72960 examples: {'rewards_train/chosen': '-3.3956', 'rewards_train/rejected': '-11.567', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.1699', 'logps_train/rejected': '-229.3', 'logps_train/chosen': '-65.354', 'loss/train': '0.053925', 'examples_per_second': '5.0962', 'grad_norm': '11.75', 'counters/examples': 72960, 'counters/updates': 4560}
skipping logging after 72976 examples to avoid logging too frequently
skipping logging after 72992 examples to avoid logging too frequently
skipping logging after 73008 examples to avoid logging too frequently
train stats after 73024 examples: {'rewards_train/chosen': '-3.3953', 'rewards_train/rejected': '-12.51', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.1182', 'logps_train/rejected': '-287.04', 'logps_train/chosen': '-71.261', 'loss/train': '0.085541', 'examples_per_second': '4.259', 'grad_norm': '13.562', 'counters/examples': 73024, 'counters/updates': 4564}
skipping logging after 73040 examples to avoid logging too frequently
skipping logging after 73056 examples to avoid logging too frequently
skipping logging after 73072 examples to avoid logging too frequently
train stats after 73088 examples: {'rewards_train/chosen': '-3.0652', 'rewards_train/rejected': '-11.145', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.0818', 'logps_train/rejected': '-246.74', 'logps_train/chosen': '-70.051', 'loss/train': '0.1567', 'examples_per_second': '4.358', 'grad_norm': '16.5', 'counters/examples': 73088, 'counters/updates': 4568}
skipping logging after 73104 examples to avoid logging too frequently
skipping logging after 73120 examples to avoid logging too frequently
skipping logging after 73136 examples to avoid logging too frequently
train stats after 73152 examples: {'rewards_train/chosen': '-3.0218', 'rewards_train/rejected': '-10.552', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.5308', 'logps_train/rejected': '-240.11', 'logps_train/chosen': '-73.066', 'loss/train': '0.078471', 'examples_per_second': '5.2448', 'grad_norm': '12.375', 'counters/examples': 73152, 'counters/updates': 4572}
skipping logging after 73168 examples to avoid logging too frequently
skipping logging after 73184 examples to avoid logging too frequently
skipping logging after 73200 examples to avoid logging too frequently
train stats after 73216 examples: {'rewards_train/chosen': '-2.7888', 'rewards_train/rejected': '-11.505', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.7184', 'logps_train/rejected': '-265.04', 'logps_train/chosen': '-69.066', 'loss/train': '0.040752', 'examples_per_second': '5.2645', 'grad_norm': '6.4062', 'counters/examples': 73216, 'counters/updates': 4576}
skipping logging after 73232 examples to avoid logging too frequently
skipping logging after 73248 examples to avoid logging too frequently
skipping logging after 73264 examples to avoid logging too frequently
train stats after 73280 examples: {'rewards_train/chosen': '-2.6211', 'rewards_train/rejected': '-12.399', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.7792', 'logps_train/rejected': '-275.47', 'logps_train/chosen': '-65.324', 'loss/train': '0.050735', 'examples_per_second': '5.0637', 'grad_norm': '4.6562', 'counters/examples': 73280, 'counters/updates': 4580}
skipping logging after 73296 examples to avoid logging too frequently
skipping logging after 73312 examples to avoid logging too frequently
skipping logging after 73328 examples to avoid logging too frequently
train stats after 73344 examples: {'rewards_train/chosen': '-2.6591', 'rewards_train/rejected': '-11.212', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.5486', 'logps_train/rejected': '-239', 'logps_train/chosen': '-65.438', 'loss/train': '0.092745', 'examples_per_second': '5.529', 'grad_norm': '12.625', 'counters/examples': 73344, 'counters/updates': 4584}
skipping logging after 73360 examples to avoid logging too frequently
skipping logging after 73376 examples to avoid logging too frequently
skipping logging after 73392 examples to avoid logging too frequently
train stats after 73408 examples: {'rewards_train/chosen': '-2.7271', 'rewards_train/rejected': '-12.012', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.2871', 'logps_train/rejected': '-281.84', 'logps_train/chosen': '-71.109', 'loss/train': '0.038213', 'examples_per_second': '4.9994', 'grad_norm': '6.7188', 'counters/examples': 73408, 'counters/updates': 4588}
skipping logging after 73424 examples to avoid logging too frequently
skipping logging after 73440 examples to avoid logging too frequently
skipping logging after 73456 examples to avoid logging too frequently
train stats after 73472 examples: {'rewards_train/chosen': '-2.7125', 'rewards_train/rejected': '-11.274', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.5649', 'logps_train/rejected': '-271.15', 'logps_train/chosen': '-62.379', 'loss/train': '0.076644', 'examples_per_second': '5.9107', 'grad_norm': '6.625', 'counters/examples': 73472, 'counters/updates': 4592}
skipping logging after 73488 examples to avoid logging too frequently
skipping logging after 73504 examples to avoid logging too frequently
skipping logging after 73520 examples to avoid logging too frequently
train stats after 73536 examples: {'rewards_train/chosen': '-2.8483', 'rewards_train/rejected': '-10.792', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.9396', 'logps_train/rejected': '-245.76', 'logps_train/chosen': '-72.838', 'loss/train': '0.060136', 'examples_per_second': '4.5343', 'grad_norm': '10.875', 'counters/examples': 73536, 'counters/updates': 4596}
skipping logging after 73552 examples to avoid logging too frequently
skipping logging after 73568 examples to avoid logging too frequently
skipping logging after 73584 examples to avoid logging too frequently
train stats after 73600 examples: {'rewards_train/chosen': '-3.5564', 'rewards_train/rejected': '-13.836', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '10.279', 'logps_train/rejected': '-318.33', 'logps_train/chosen': '-80.791', 'loss/train': '0.050638', 'examples_per_second': '4.6777', 'grad_norm': '8.8125', 'counters/examples': 73600, 'counters/updates': 4600}
skipping logging after 73616 examples to avoid logging too frequently
skipping logging after 73632 examples to avoid logging too frequently
skipping logging after 73648 examples to avoid logging too frequently
train stats after 73664 examples: {'rewards_train/chosen': '-2.9819', 'rewards_train/rejected': '-12.637', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.6553', 'logps_train/rejected': '-282.33', 'logps_train/chosen': '-84.93', 'loss/train': '0.12044', 'examples_per_second': '4.3787', 'grad_norm': '18.25', 'counters/examples': 73664, 'counters/updates': 4604}
skipping logging after 73680 examples to avoid logging too frequently
skipping logging after 73696 examples to avoid logging too frequently
skipping logging after 73712 examples to avoid logging too frequently
train stats after 73728 examples: {'rewards_train/chosen': '-2.6614', 'rewards_train/rejected': '-11.067', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.4053', 'logps_train/rejected': '-244.26', 'logps_train/chosen': '-62.802', 'loss/train': '0.059566', 'examples_per_second': '5.4247', 'grad_norm': '7.1875', 'counters/examples': 73728, 'counters/updates': 4608}
skipping logging after 73744 examples to avoid logging too frequently
skipping logging after 73760 examples to avoid logging too frequently
skipping logging after 73776 examples to avoid logging too frequently
train stats after 73792 examples: {'rewards_train/chosen': '-2.6859', 'rewards_train/rejected': '-10.967', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.2799', 'logps_train/rejected': '-258.22', 'logps_train/chosen': '-67.307', 'loss/train': '0.080632', 'examples_per_second': '5.3772', 'grad_norm': '8.875', 'counters/examples': 73792, 'counters/updates': 4612}
skipping logging after 73808 examples to avoid logging too frequently
skipping logging after 73824 examples to avoid logging too frequently
skipping logging after 73840 examples to avoid logging too frequently
train stats after 73856 examples: {'rewards_train/chosen': '-2.4009', 'rewards_train/rejected': '-10.18', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.7767', 'logps_train/rejected': '-217.86', 'logps_train/chosen': '-59.33', 'loss/train': '0.080421', 'examples_per_second': '5.5101', 'grad_norm': '5.375', 'counters/examples': 73856, 'counters/updates': 4616}
skipping logging after 73872 examples to avoid logging too frequently
skipping logging after 73888 examples to avoid logging too frequently
skipping logging after 73904 examples to avoid logging too frequently
train stats after 73920 examples: {'rewards_train/chosen': '-2.878', 'rewards_train/rejected': '-11.809', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.9331', 'logps_train/rejected': '-257.12', 'logps_train/chosen': '-59.396', 'loss/train': '0.15171', 'examples_per_second': '4.9447', 'grad_norm': '14.938', 'counters/examples': 73920, 'counters/updates': 4620}
skipping logging after 73936 examples to avoid logging too frequently
skipping logging after 73952 examples to avoid logging too frequently
skipping logging after 73968 examples to avoid logging too frequently
train stats after 73984 examples: {'rewards_train/chosen': '-3.3413', 'rewards_train/rejected': '-11.443', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1033', 'logps_train/rejected': '-256.45', 'logps_train/chosen': '-72.346', 'loss/train': '0.052058', 'examples_per_second': '4.5428', 'grad_norm': '10.062', 'counters/examples': 73984, 'counters/updates': 4624}
skipping logging after 74000 examples to avoid logging too frequently
skipping logging after 74016 examples to avoid logging too frequently
skipping logging after 74032 examples to avoid logging too frequently
train stats after 74048 examples: {'rewards_train/chosen': '-2.81', 'rewards_train/rejected': '-10.526', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.7168', 'logps_train/rejected': '-245.24', 'logps_train/chosen': '-65.998', 'loss/train': '0.067589', 'examples_per_second': '5.3669', 'grad_norm': '7.7812', 'counters/examples': 74048, 'counters/updates': 4628}
skipping logging after 74064 examples to avoid logging too frequently
skipping logging after 74080 examples to avoid logging too frequently
skipping logging after 74096 examples to avoid logging too frequently
train stats after 74112 examples: {'rewards_train/chosen': '-2.4306', 'rewards_train/rejected': '-10.699', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.2688', 'logps_train/rejected': '-291.17', 'logps_train/chosen': '-75.928', 'loss/train': '0.11376', 'examples_per_second': '4.561', 'grad_norm': '18.25', 'counters/examples': 74112, 'counters/updates': 4632}
skipping logging after 74128 examples to avoid logging too frequently
skipping logging after 74144 examples to avoid logging too frequently
skipping logging after 74160 examples to avoid logging too frequently
train stats after 74176 examples: {'rewards_train/chosen': '-2.2618', 'rewards_train/rejected': '-9.7844', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.5208', 'logps_train/rejected': '-273.2', 'logps_train/chosen': '-59.562', 'loss/train': '0.063336', 'examples_per_second': '4.3266', 'grad_norm': '7.3125', 'counters/examples': 74176, 'counters/updates': 4636}
skipping logging after 74192 examples to avoid logging too frequently
skipping logging after 74208 examples to avoid logging too frequently
skipping logging after 74224 examples to avoid logging too frequently
train stats after 74240 examples: {'rewards_train/chosen': '-2.1387', 'rewards_train/rejected': '-8.8474', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.709', 'logps_train/rejected': '-201.32', 'logps_train/chosen': '-56.697', 'loss/train': '0.055715', 'examples_per_second': '4.5018', 'grad_norm': '9.5', 'counters/examples': 74240, 'counters/updates': 4640}
skipping logging after 74256 examples to avoid logging too frequently
skipping logging after 74272 examples to avoid logging too frequently
skipping logging after 74288 examples to avoid logging too frequently
train stats after 74304 examples: {'rewards_train/chosen': '-2.4544', 'rewards_train/rejected': '-10.409', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.9607', 'logps_train/rejected': '-236.38', 'logps_train/chosen': '-69.785', 'loss/train': '0.08366', 'examples_per_second': '5.6229', 'grad_norm': '15.562', 'counters/examples': 74304, 'counters/updates': 4644}
skipping logging after 74320 examples to avoid logging too frequently
skipping logging after 74336 examples to avoid logging too frequently
skipping logging after 74352 examples to avoid logging too frequently
train stats after 74368 examples: {'rewards_train/chosen': '-2.4207', 'rewards_train/rejected': '-9.499', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.0774', 'logps_train/rejected': '-240.96', 'logps_train/chosen': '-67.766', 'loss/train': '0.054661', 'examples_per_second': '5.4176', 'grad_norm': '10.25', 'counters/examples': 74368, 'counters/updates': 4648}
skipping logging after 74384 examples to avoid logging too frequently
skipping logging after 74400 examples to avoid logging too frequently
skipping logging after 74416 examples to avoid logging too frequently
train stats after 74432 examples: {'rewards_train/chosen': '-2.3192', 'rewards_train/rejected': '-9.3408', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.0217', 'logps_train/rejected': '-228.03', 'logps_train/chosen': '-65.519', 'loss/train': '0.13659', 'examples_per_second': '4.3699', 'grad_norm': '18.25', 'counters/examples': 74432, 'counters/updates': 4652}
skipping logging after 74448 examples to avoid logging too frequently
skipping logging after 74464 examples to avoid logging too frequently
skipping logging after 74480 examples to avoid logging too frequently
train stats after 74496 examples: {'rewards_train/chosen': '-2.3443', 'rewards_train/rejected': '-9.4666', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.1235', 'logps_train/rejected': '-217.04', 'logps_train/chosen': '-62.444', 'loss/train': '0.029647', 'examples_per_second': '6.7506', 'grad_norm': '4', 'counters/examples': 74496, 'counters/updates': 4656}
skipping logging after 74512 examples to avoid logging too frequently
skipping logging after 74528 examples to avoid logging too frequently
skipping logging after 74544 examples to avoid logging too frequently
train stats after 74560 examples: {'rewards_train/chosen': '-2.5326', 'rewards_train/rejected': '-9.6648', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.131', 'logps_train/rejected': '-229.67', 'logps_train/chosen': '-61.738', 'loss/train': '0.096356', 'examples_per_second': '5.9713', 'grad_norm': '7.8125', 'counters/examples': 74560, 'counters/updates': 4660}
skipping logging after 74576 examples to avoid logging too frequently
skipping logging after 74592 examples to avoid logging too frequently
skipping logging after 74608 examples to avoid logging too frequently
train stats after 74624 examples: {'rewards_train/chosen': '-3.0945', 'rewards_train/rejected': '-10.985', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.8912', 'logps_train/rejected': '-267.63', 'logps_train/chosen': '-73.872', 'loss/train': '0.071045', 'examples_per_second': '5.3615', 'grad_norm': '6.5', 'counters/examples': 74624, 'counters/updates': 4664}
skipping logging after 74640 examples to avoid logging too frequently
skipping logging after 74656 examples to avoid logging too frequently
skipping logging after 74672 examples to avoid logging too frequently
train stats after 74688 examples: {'rewards_train/chosen': '-3.0976', 'rewards_train/rejected': '-10.588', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.4917', 'logps_train/rejected': '-288.79', 'logps_train/chosen': '-75.884', 'loss/train': '0.17905', 'examples_per_second': '4.7346', 'grad_norm': '16.5', 'counters/examples': 74688, 'counters/updates': 4668}
skipping logging after 74704 examples to avoid logging too frequently
skipping logging after 74720 examples to avoid logging too frequently
skipping logging after 74736 examples to avoid logging too frequently
train stats after 74752 examples: {'rewards_train/chosen': '-2.6191', 'rewards_train/rejected': '-9.2759', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.658', 'logps_train/rejected': '-210.38', 'logps_train/chosen': '-61.176', 'loss/train': '0.073136', 'examples_per_second': '5.1603', 'grad_norm': '8.5625', 'counters/examples': 74752, 'counters/updates': 4672}
skipping logging after 74768 examples to avoid logging too frequently
skipping logging after 74784 examples to avoid logging too frequently
skipping logging after 74800 examples to avoid logging too frequently
train stats after 74816 examples: {'rewards_train/chosen': '-2.9103', 'rewards_train/rejected': '-10.475', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.5658', 'logps_train/rejected': '-236.16', 'logps_train/chosen': '-74.887', 'loss/train': '0.069642', 'examples_per_second': '4.948', 'grad_norm': '16.625', 'counters/examples': 74816, 'counters/updates': 4676}
skipping logging after 74832 examples to avoid logging too frequently
skipping logging after 74848 examples to avoid logging too frequently
skipping logging after 74864 examples to avoid logging too frequently
train stats after 74880 examples: {'rewards_train/chosen': '-3.2594', 'rewards_train/rejected': '-11.417', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.1587', 'logps_train/rejected': '-249.09', 'logps_train/chosen': '-73.152', 'loss/train': '0.17207', 'examples_per_second': '5.989', 'grad_norm': '18.625', 'counters/examples': 74880, 'counters/updates': 4680}
skipping logging after 74896 examples to avoid logging too frequently
skipping logging after 74912 examples to avoid logging too frequently
skipping logging after 74928 examples to avoid logging too frequently
train stats after 74944 examples: {'rewards_train/chosen': '-3.4835', 'rewards_train/rejected': '-11.956', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.4651', 'logps_train/rejected': '-273.25', 'logps_train/chosen': '-77.961', 'loss/train': '0.11302', 'examples_per_second': '4.8973', 'grad_norm': '13.875', 'counters/examples': 74944, 'counters/updates': 4684}
skipping logging after 74960 examples to avoid logging too frequently
skipping logging after 74976 examples to avoid logging too frequently
skipping logging after 74992 examples to avoid logging too frequently
train stats after 75008 examples: {'rewards_train/chosen': '-2.6231', 'rewards_train/rejected': '-12.13', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.5029', 'logps_train/rejected': '-284.92', 'logps_train/chosen': '-69.547', 'loss/train': '0.042951', 'examples_per_second': '5.6457', 'grad_norm': '8.5625', 'counters/examples': 75008, 'counters/updates': 4688}
skipping logging after 75024 examples to avoid logging too frequently
skipping logging after 75040 examples to avoid logging too frequently
skipping logging after 75056 examples to avoid logging too frequently
train stats after 75072 examples: {'rewards_train/chosen': '-2.8338', 'rewards_train/rejected': '-10.687', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.854', 'logps_train/rejected': '-252.66', 'logps_train/chosen': '-64.749', 'loss/train': '0.063787', 'examples_per_second': '5.3388', 'grad_norm': '7.6875', 'counters/examples': 75072, 'counters/updates': 4692}
skipping logging after 75088 examples to avoid logging too frequently
skipping logging after 75104 examples to avoid logging too frequently
skipping logging after 75120 examples to avoid logging too frequently
train stats after 75136 examples: {'rewards_train/chosen': '-2.8834', 'rewards_train/rejected': '-11.326', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.4424', 'logps_train/rejected': '-263.25', 'logps_train/chosen': '-72.157', 'loss/train': '0.044968', 'examples_per_second': '4.5983', 'grad_norm': '9.3125', 'counters/examples': 75136, 'counters/updates': 4696}
skipping logging after 75152 examples to avoid logging too frequently
skipping logging after 75168 examples to avoid logging too frequently
skipping logging after 75184 examples to avoid logging too frequently
train stats after 75200 examples: {'rewards_train/chosen': '-2.9968', 'rewards_train/rejected': '-11.677', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.6816', 'logps_train/rejected': '-245.98', 'logps_train/chosen': '-66.564', 'loss/train': '0.097798', 'examples_per_second': '5.1119', 'grad_norm': '11.688', 'counters/examples': 75200, 'counters/updates': 4700}
skipping logging after 75216 examples to avoid logging too frequently
skipping logging after 75232 examples to avoid logging too frequently
skipping logging after 75248 examples to avoid logging too frequently
train stats after 75264 examples: {'rewards_train/chosen': '-3.7696', 'rewards_train/rejected': '-12.3', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.5293', 'logps_train/rejected': '-260.9', 'logps_train/chosen': '-86.577', 'loss/train': '0.27943', 'examples_per_second': '6.3017', 'grad_norm': '28', 'counters/examples': 75264, 'counters/updates': 4704}
skipping logging after 75280 examples to avoid logging too frequently
skipping logging after 75296 examples to avoid logging too frequently
skipping logging after 75312 examples to avoid logging too frequently
train stats after 75328 examples: {'rewards_train/chosen': '-3.1149', 'rewards_train/rejected': '-10.88', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.7656', 'logps_train/rejected': '-263.6', 'logps_train/chosen': '-74.418', 'loss/train': '0.07676', 'examples_per_second': '4.295', 'grad_norm': '11.812', 'counters/examples': 75328, 'counters/updates': 4708}
skipping logging after 75344 examples to avoid logging too frequently
skipping logging after 75360 examples to avoid logging too frequently
skipping logging after 75376 examples to avoid logging too frequently
train stats after 75392 examples: {'rewards_train/chosen': '-2.9898', 'rewards_train/rejected': '-11.146', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.1565', 'logps_train/rejected': '-252.44', 'logps_train/chosen': '-72.051', 'loss/train': '0.1985', 'examples_per_second': '4.4756', 'grad_norm': '22.25', 'counters/examples': 75392, 'counters/updates': 4712}
skipping logging after 75408 examples to avoid logging too frequently
skipping logging after 75424 examples to avoid logging too frequently
skipping logging after 75440 examples to avoid logging too frequently
train stats after 75456 examples: {'rewards_train/chosen': '-2.2899', 'rewards_train/rejected': '-9.3306', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.042', 'logps_train/rejected': '-238.28', 'logps_train/chosen': '-64.869', 'loss/train': '0.060575', 'examples_per_second': '4.4636', 'grad_norm': '6.9375', 'counters/examples': 75456, 'counters/updates': 4716}
skipping logging after 75472 examples to avoid logging too frequently
skipping logging after 75488 examples to avoid logging too frequently
skipping logging after 75504 examples to avoid logging too frequently
train stats after 75520 examples: {'rewards_train/chosen': '-2.8335', 'rewards_train/rejected': '-8.9785', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.1464', 'logps_train/rejected': '-203.49', 'logps_train/chosen': '-66.943', 'loss/train': '0.12803', 'examples_per_second': '5.4985', 'grad_norm': '10.938', 'counters/examples': 75520, 'counters/updates': 4720}
skipping logging after 75536 examples to avoid logging too frequently
skipping logging after 75552 examples to avoid logging too frequently
skipping logging after 75568 examples to avoid logging too frequently
train stats after 75584 examples: {'rewards_train/chosen': '-2.7984', 'rewards_train/rejected': '-10.076', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.2766', 'logps_train/rejected': '-221.36', 'logps_train/chosen': '-66.527', 'loss/train': '0.05896', 'examples_per_second': '4.0653', 'grad_norm': '7.1875', 'counters/examples': 75584, 'counters/updates': 4724}
skipping logging after 75600 examples to avoid logging too frequently
skipping logging after 75616 examples to avoid logging too frequently
skipping logging after 75632 examples to avoid logging too frequently
train stats after 75648 examples: {'rewards_train/chosen': '-2.9934', 'rewards_train/rejected': '-10.131', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.1367', 'logps_train/rejected': '-224.75', 'logps_train/chosen': '-66.624', 'loss/train': '0.039152', 'examples_per_second': '4.7367', 'grad_norm': '9.1875', 'counters/examples': 75648, 'counters/updates': 4728}
skipping logging after 75664 examples to avoid logging too frequently
skipping logging after 75680 examples to avoid logging too frequently
skipping logging after 75696 examples to avoid logging too frequently
train stats after 75712 examples: {'rewards_train/chosen': '-3.2763', 'rewards_train/rejected': '-11.406', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.1331', 'logps_train/rejected': '-264.24', 'logps_train/chosen': '-73.359', 'loss/train': '0.070193', 'examples_per_second': '5.9859', 'grad_norm': '9.875', 'counters/examples': 75712, 'counters/updates': 4732}
skipping logging after 75728 examples to avoid logging too frequently
skipping logging after 75744 examples to avoid logging too frequently
skipping logging after 75760 examples to avoid logging too frequently
train stats after 75776 examples: {'rewards_train/chosen': '-3.4745', 'rewards_train/rejected': '-10.948', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.4736', 'logps_train/rejected': '-245.23', 'logps_train/chosen': '-73.694', 'loss/train': '0.063439', 'examples_per_second': '6.0478', 'grad_norm': '9.3125', 'counters/examples': 75776, 'counters/updates': 4736}
skipping logging after 75792 examples to avoid logging too frequently
skipping logging after 75808 examples to avoid logging too frequently
skipping logging after 75824 examples to avoid logging too frequently
train stats after 75840 examples: {'rewards_train/chosen': '-3.552', 'rewards_train/rejected': '-13.439', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.8918', 'logps_train/rejected': '-309.99', 'logps_train/chosen': '-77.271', 'loss/train': '0.041952', 'examples_per_second': '4.1493', 'grad_norm': '15.438', 'counters/examples': 75840, 'counters/updates': 4740}
skipping logging after 75856 examples to avoid logging too frequently
skipping logging after 75872 examples to avoid logging too frequently
skipping logging after 75888 examples to avoid logging too frequently
train stats after 75904 examples: {'rewards_train/chosen': '-3.2881', 'rewards_train/rejected': '-12.74', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.4504', 'logps_train/rejected': '-287.21', 'logps_train/chosen': '-74.354', 'loss/train': '0.043867', 'examples_per_second': '5.5295', 'grad_norm': '8.625', 'counters/examples': 75904, 'counters/updates': 4744}
skipping logging after 75920 examples to avoid logging too frequently
skipping logging after 75936 examples to avoid logging too frequently
skipping logging after 75952 examples to avoid logging too frequently
train stats after 75968 examples: {'rewards_train/chosen': '-3.7519', 'rewards_train/rejected': '-12.246', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.4932', 'logps_train/rejected': '-252.44', 'logps_train/chosen': '-74.049', 'loss/train': '0.086221', 'examples_per_second': '4.7901', 'grad_norm': '12.75', 'counters/examples': 75968, 'counters/updates': 4748}
skipping logging after 75984 examples to avoid logging too frequently
skipping logging after 76000 examples to avoid logging too frequently
Running evaluation after 76000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:13,  2.39s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:05,  2.19s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:56,  1.94s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.91s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:42,  1.56s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.66s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.49s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.57s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:36,  1.57s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.50s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:22,  1.30s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.24s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.33s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.34s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.23s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.27s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:33<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.30s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.26s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:37<00:07,  1.30s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:39<00:07,  1.48s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.41s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.61s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.42s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.42s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.44s/it]
eval after 76000: {'rewards_eval/chosen': '-11.988', 'rewards_eval/rejected': '-12.585', 'rewards_eval/accuracies': '0.54297', 'rewards_eval/margins': '0.5965', 'logps_eval/rejected': '-273.51', 'logps_eval/chosen': '-264.79', 'loss/eval': '2.1281'}
skipping logging after 76016 examples to avoid logging too frequently
train stats after 76032 examples: {'rewards_train/chosen': '-3.4764', 'rewards_train/rejected': '-11.861', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.3831', 'logps_train/rejected': '-237.08', 'logps_train/chosen': '-73.762', 'loss/train': '0.085426', 'examples_per_second': '5.8991', 'grad_norm': '14.688', 'counters/examples': 76032, 'counters/updates': 4752}
skipping logging after 76048 examples to avoid logging too frequently
skipping logging after 76064 examples to avoid logging too frequently
skipping logging after 76080 examples to avoid logging too frequently
train stats after 76096 examples: {'rewards_train/chosen': '-3.3261', 'rewards_train/rejected': '-12.161', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.8372', 'logps_train/rejected': '-282.72', 'logps_train/chosen': '-81.961', 'loss/train': '0.037381', 'examples_per_second': '5.4446', 'grad_norm': '4.0625', 'counters/examples': 76096, 'counters/updates': 4756}
skipping logging after 76112 examples to avoid logging too frequently
skipping logging after 76128 examples to avoid logging too frequently
skipping logging after 76144 examples to avoid logging too frequently
train stats after 76160 examples: {'rewards_train/chosen': '-3.5254', 'rewards_train/rejected': '-12.452', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.9253', 'logps_train/rejected': '-261.86', 'logps_train/chosen': '-69.771', 'loss/train': '0.054106', 'examples_per_second': '4.2714', 'grad_norm': '5.5', 'counters/examples': 76160, 'counters/updates': 4760}
skipping logging after 76176 examples to avoid logging too frequently
skipping logging after 76192 examples to avoid logging too frequently
skipping logging after 76208 examples to avoid logging too frequently
train stats after 76224 examples: {'rewards_train/chosen': '-3.7349', 'rewards_train/rejected': '-12.205', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.4741', 'logps_train/rejected': '-279.56', 'logps_train/chosen': '-70.87', 'loss/train': '0.059308', 'examples_per_second': '5.688', 'grad_norm': '6.75', 'counters/examples': 76224, 'counters/updates': 4764}
skipping logging after 76240 examples to avoid logging too frequently
skipping logging after 76256 examples to avoid logging too frequently
skipping logging after 76272 examples to avoid logging too frequently
train stats after 76288 examples: {'rewards_train/chosen': '-3.2509', 'rewards_train/rejected': '-12.422', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.1746', 'logps_train/rejected': '-269.2', 'logps_train/chosen': '-73.777', 'loss/train': '0.095347', 'examples_per_second': '5.235', 'grad_norm': '15.062', 'counters/examples': 76288, 'counters/updates': 4768}
skipping logging after 76304 examples to avoid logging too frequently
skipping logging after 76320 examples to avoid logging too frequently
skipping logging after 76336 examples to avoid logging too frequently
train stats after 76352 examples: {'rewards_train/chosen': '-3.8288', 'rewards_train/rejected': '-12.703', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.873', 'logps_train/rejected': '-248', 'logps_train/chosen': '-78.744', 'loss/train': '0.070266', 'examples_per_second': '4.8996', 'grad_norm': '7.6875', 'counters/examples': 76352, 'counters/updates': 4772}
skipping logging after 76368 examples to avoid logging too frequently
skipping logging after 76384 examples to avoid logging too frequently
skipping logging after 76400 examples to avoid logging too frequently
train stats after 76416 examples: {'rewards_train/chosen': '-3.6763', 'rewards_train/rejected': '-12.603', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.9255', 'logps_train/rejected': '-286.99', 'logps_train/chosen': '-77.6', 'loss/train': '0.075563', 'examples_per_second': '4.6242', 'grad_norm': '10.688', 'counters/examples': 76416, 'counters/updates': 4776}
skipping logging after 76432 examples to avoid logging too frequently
skipping logging after 76448 examples to avoid logging too frequently
skipping logging after 76464 examples to avoid logging too frequently
train stats after 76480 examples: {'rewards_train/chosen': '-3.4899', 'rewards_train/rejected': '-12.459', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.9749', 'logps_train/rejected': '-268.81', 'logps_train/chosen': '-76.68', 'loss/train': '0.082486', 'examples_per_second': '5.2257', 'grad_norm': '11.25', 'counters/examples': 76480, 'counters/updates': 4780}
skipping logging after 76496 examples to avoid logging too frequently
skipping logging after 76512 examples to avoid logging too frequently
skipping logging after 76528 examples to avoid logging too frequently
train stats after 76544 examples: {'rewards_train/chosen': '-3.3415', 'rewards_train/rejected': '-12.164', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.8223', 'logps_train/rejected': '-249.3', 'logps_train/chosen': '-69.783', 'loss/train': '0.029901', 'examples_per_second': '6.2893', 'grad_norm': '7.2812', 'counters/examples': 76544, 'counters/updates': 4784}
skipping logging after 76560 examples to avoid logging too frequently
skipping logging after 76576 examples to avoid logging too frequently
skipping logging after 76592 examples to avoid logging too frequently
train stats after 76608 examples: {'rewards_train/chosen': '-3.2772', 'rewards_train/rejected': '-12.05', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.7722', 'logps_train/rejected': '-259.06', 'logps_train/chosen': '-77.746', 'loss/train': '0.14947', 'examples_per_second': '5.3246', 'grad_norm': '16.5', 'counters/examples': 76608, 'counters/updates': 4788}
skipping logging after 76624 examples to avoid logging too frequently
skipping logging after 76640 examples to avoid logging too frequently
skipping logging after 76656 examples to avoid logging too frequently
train stats after 76672 examples: {'rewards_train/chosen': '-3.266', 'rewards_train/rejected': '-10.841', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.5735', 'logps_train/rejected': '-235.35', 'logps_train/chosen': '-77.403', 'loss/train': '0.074674', 'examples_per_second': '4.9683', 'grad_norm': '11.875', 'counters/examples': 76672, 'counters/updates': 4792}
skipping logging after 76688 examples to avoid logging too frequently
skipping logging after 76704 examples to avoid logging too frequently
skipping logging after 76720 examples to avoid logging too frequently
train stats after 76736 examples: {'rewards_train/chosen': '-3.0444', 'rewards_train/rejected': '-12.83', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.7854', 'logps_train/rejected': '-274.71', 'logps_train/chosen': '-76.146', 'loss/train': '0.067247', 'examples_per_second': '5.7533', 'grad_norm': '11.062', 'counters/examples': 76736, 'counters/updates': 4796}
skipping logging after 76752 examples to avoid logging too frequently
skipping logging after 76768 examples to avoid logging too frequently
skipping logging after 76784 examples to avoid logging too frequently
train stats after 76800 examples: {'rewards_train/chosen': '-3.3545', 'rewards_train/rejected': '-11.22', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.8677', 'logps_train/rejected': '-244.23', 'logps_train/chosen': '-71.729', 'loss/train': '0.0558', 'examples_per_second': '4.4597', 'grad_norm': '12.5', 'counters/examples': 76800, 'counters/updates': 4800}
skipping logging after 76816 examples to avoid logging too frequently
skipping logging after 76832 examples to avoid logging too frequently
skipping logging after 76848 examples to avoid logging too frequently
train stats after 76864 examples: {'rewards_train/chosen': '-3.7995', 'rewards_train/rejected': '-12.155', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.3589', 'logps_train/rejected': '-238.55', 'logps_train/chosen': '-77.646', 'loss/train': '0.029763', 'examples_per_second': '5.9554', 'grad_norm': '5.625', 'counters/examples': 76864, 'counters/updates': 4804}
skipping logging after 76880 examples to avoid logging too frequently
skipping logging after 76896 examples to avoid logging too frequently
skipping logging after 76912 examples to avoid logging too frequently
train stats after 76928 examples: {'rewards_train/chosen': '-2.8256', 'rewards_train/rejected': '-11.502', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.6785', 'logps_train/rejected': '-244.74', 'logps_train/chosen': '-63.502', 'loss/train': '0.079709', 'examples_per_second': '4.8718', 'grad_norm': '8.8125', 'counters/examples': 76928, 'counters/updates': 4808}
skipping logging after 76944 examples to avoid logging too frequently
skipping logging after 76960 examples to avoid logging too frequently
skipping logging after 76976 examples to avoid logging too frequently
train stats after 76992 examples: {'rewards_train/chosen': '-3.3416', 'rewards_train/rejected': '-11.797', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.4534', 'logps_train/rejected': '-258.68', 'logps_train/chosen': '-72.55', 'loss/train': '0.12841', 'examples_per_second': '5.2922', 'grad_norm': '14.625', 'counters/examples': 76992, 'counters/updates': 4812}
skipping logging after 77008 examples to avoid logging too frequently
skipping logging after 77024 examples to avoid logging too frequently
skipping logging after 77040 examples to avoid logging too frequently
train stats after 77056 examples: {'rewards_train/chosen': '-2.6585', 'rewards_train/rejected': '-9.7292', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.0692', 'logps_train/rejected': '-236', 'logps_train/chosen': '-63.967', 'loss/train': '0.051379', 'examples_per_second': '5.1036', 'grad_norm': '6.7812', 'counters/examples': 77056, 'counters/updates': 4816}
skipping logging after 77072 examples to avoid logging too frequently
skipping logging after 77088 examples to avoid logging too frequently
skipping logging after 77104 examples to avoid logging too frequently
train stats after 77120 examples: {'rewards_train/chosen': '-2.4632', 'rewards_train/rejected': '-10.388', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.9241', 'logps_train/rejected': '-258.19', 'logps_train/chosen': '-57.91', 'loss/train': '0.085493', 'examples_per_second': '4.8048', 'grad_norm': '13.188', 'counters/examples': 77120, 'counters/updates': 4820}
skipping logging after 77136 examples to avoid logging too frequently
skipping logging after 77152 examples to avoid logging too frequently
skipping logging after 77168 examples to avoid logging too frequently
train stats after 77184 examples: {'rewards_train/chosen': '-3.023', 'rewards_train/rejected': '-10.501', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.4798', 'logps_train/rejected': '-241.52', 'logps_train/chosen': '-73.129', 'loss/train': '0.058134', 'examples_per_second': '5.0099', 'grad_norm': '6.3125', 'counters/examples': 77184, 'counters/updates': 4824}
skipping logging after 77200 examples to avoid logging too frequently
skipping logging after 77216 examples to avoid logging too frequently
skipping logging after 77232 examples to avoid logging too frequently
train stats after 77248 examples: {'rewards_train/chosen': '-2.7022', 'rewards_train/rejected': '-10.589', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.8862', 'logps_train/rejected': '-248.79', 'logps_train/chosen': '-68.978', 'loss/train': '0.068678', 'examples_per_second': '5.4526', 'grad_norm': '8.4375', 'counters/examples': 77248, 'counters/updates': 4828}
skipping logging after 77264 examples to avoid logging too frequently
skipping logging after 77280 examples to avoid logging too frequently
skipping logging after 77296 examples to avoid logging too frequently
train stats after 77312 examples: {'rewards_train/chosen': '-3.2447', 'rewards_train/rejected': '-9.7983', 'rewards_train/accuracies': '1', 'rewards_train/margins': '6.5511', 'logps_train/rejected': '-230.84', 'logps_train/chosen': '-69.732', 'loss/train': '0.13333', 'examples_per_second': '5.5413', 'grad_norm': '16.125', 'counters/examples': 77312, 'counters/updates': 4832}
skipping logging after 77328 examples to avoid logging too frequently
skipping logging after 77344 examples to avoid logging too frequently
skipping logging after 77360 examples to avoid logging too frequently
train stats after 77376 examples: {'rewards_train/chosen': '-2.5288', 'rewards_train/rejected': '-10.674', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1453', 'logps_train/rejected': '-258.84', 'logps_train/chosen': '-65.893', 'loss/train': '0.061902', 'examples_per_second': '4.6596', 'grad_norm': '9.5', 'counters/examples': 77376, 'counters/updates': 4836}
skipping logging after 77392 examples to avoid logging too frequently
skipping logging after 77408 examples to avoid logging too frequently
skipping logging after 77424 examples to avoid logging too frequently
train stats after 77440 examples: {'rewards_train/chosen': '-3.0726', 'rewards_train/rejected': '-10.94', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.8684', 'logps_train/rejected': '-242.42', 'logps_train/chosen': '-61.914', 'loss/train': '0.11252', 'examples_per_second': '4.1345', 'grad_norm': '13', 'counters/examples': 77440, 'counters/updates': 4840}
skipping logging after 77456 examples to avoid logging too frequently
skipping logging after 77472 examples to avoid logging too frequently
skipping logging after 77488 examples to avoid logging too frequently
train stats after 77504 examples: {'rewards_train/chosen': '-2.4718', 'rewards_train/rejected': '-11.766', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.2954', 'logps_train/rejected': '-323.01', 'logps_train/chosen': '-73.848', 'loss/train': '0.027589', 'examples_per_second': '4.5353', 'grad_norm': '6.0938', 'counters/examples': 77504, 'counters/updates': 4844}
skipping logging after 77520 examples to avoid logging too frequently
skipping logging after 77536 examples to avoid logging too frequently
skipping logging after 77552 examples to avoid logging too frequently
train stats after 77568 examples: {'rewards_train/chosen': '-3.0253', 'rewards_train/rejected': '-10.427', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.4011', 'logps_train/rejected': '-231.88', 'logps_train/chosen': '-70.037', 'loss/train': '0.095697', 'examples_per_second': '4.9644', 'grad_norm': '12.5', 'counters/examples': 77568, 'counters/updates': 4848}
skipping logging after 77584 examples to avoid logging too frequently
skipping logging after 77600 examples to avoid logging too frequently
skipping logging after 77616 examples to avoid logging too frequently
train stats after 77632 examples: {'rewards_train/chosen': '-3.4069', 'rewards_train/rejected': '-11.941', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.5349', 'logps_train/rejected': '-306.93', 'logps_train/chosen': '-84.107', 'loss/train': '0.055378', 'examples_per_second': '4.036', 'grad_norm': '8.3125', 'counters/examples': 77632, 'counters/updates': 4852}
skipping logging after 77648 examples to avoid logging too frequently
skipping logging after 77664 examples to avoid logging too frequently
skipping logging after 77680 examples to avoid logging too frequently
train stats after 77696 examples: {'rewards_train/chosen': '-3.2515', 'rewards_train/rejected': '-11.379', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.1292', 'logps_train/rejected': '-257.12', 'logps_train/chosen': '-74.785', 'loss/train': '0.071966', 'examples_per_second': '5.5416', 'grad_norm': '10.938', 'counters/examples': 77696, 'counters/updates': 4856}
skipping logging after 77712 examples to avoid logging too frequently
skipping logging after 77728 examples to avoid logging too frequently
skipping logging after 77744 examples to avoid logging too frequently
train stats after 77760 examples: {'rewards_train/chosen': '-3.9572', 'rewards_train/rejected': '-13.664', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.7075', 'logps_train/rejected': '-280.98', 'logps_train/chosen': '-76.648', 'loss/train': '0.075969', 'examples_per_second': '4.8875', 'grad_norm': '12.125', 'counters/examples': 77760, 'counters/updates': 4860}
skipping logging after 77776 examples to avoid logging too frequently
skipping logging after 77792 examples to avoid logging too frequently
skipping logging after 77808 examples to avoid logging too frequently
train stats after 77824 examples: {'rewards_train/chosen': '-2.8774', 'rewards_train/rejected': '-11.75', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.8735', 'logps_train/rejected': '-286.52', 'logps_train/chosen': '-71.267', 'loss/train': '0.059788', 'examples_per_second': '4.8034', 'grad_norm': '9.5625', 'counters/examples': 77824, 'counters/updates': 4864}
skipping logging after 77840 examples to avoid logging too frequently
skipping logging after 77856 examples to avoid logging too frequently
skipping logging after 77872 examples to avoid logging too frequently
train stats after 77888 examples: {'rewards_train/chosen': '-3.3711', 'rewards_train/rejected': '-11.106', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.735', 'logps_train/rejected': '-291.86', 'logps_train/chosen': '-81.371', 'loss/train': '0.084812', 'examples_per_second': '4.9838', 'grad_norm': '18.375', 'counters/examples': 77888, 'counters/updates': 4868}
skipping logging after 77904 examples to avoid logging too frequently
skipping logging after 77920 examples to avoid logging too frequently
skipping logging after 77936 examples to avoid logging too frequently
train stats after 77952 examples: {'rewards_train/chosen': '-4.0323', 'rewards_train/rejected': '-11.64', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.6096', 'logps_train/rejected': '-262.07', 'logps_train/chosen': '-78.527', 'loss/train': '0.059173', 'examples_per_second': '4.859', 'grad_norm': '7.9062', 'counters/examples': 77952, 'counters/updates': 4872}
skipping logging after 77968 examples to avoid logging too frequently
skipping logging after 77984 examples to avoid logging too frequently
skipping logging after 78000 examples to avoid logging too frequently
train stats after 78016 examples: {'rewards_train/chosen': '-4.0179', 'rewards_train/rejected': '-15.145', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '11.128', 'logps_train/rejected': '-296.05', 'logps_train/chosen': '-80.223', 'loss/train': '0.031184', 'examples_per_second': '5.8423', 'grad_norm': '11.875', 'counters/examples': 78016, 'counters/updates': 4876}
skipping logging after 78032 examples to avoid logging too frequently
skipping logging after 78048 examples to avoid logging too frequently
skipping logging after 78064 examples to avoid logging too frequently
train stats after 78080 examples: {'rewards_train/chosen': '-4.1833', 'rewards_train/rejected': '-12.644', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.4567', 'logps_train/rejected': '-279', 'logps_train/chosen': '-87.278', 'loss/train': '0.078984', 'examples_per_second': '4.1559', 'grad_norm': '9.125', 'counters/examples': 78080, 'counters/updates': 4880}
skipping logging after 78096 examples to avoid logging too frequently
skipping logging after 78112 examples to avoid logging too frequently
skipping logging after 78128 examples to avoid logging too frequently
train stats after 78144 examples: {'rewards_train/chosen': '-3.7606', 'rewards_train/rejected': '-12.419', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.6548', 'logps_train/rejected': '-256.71', 'logps_train/chosen': '-82.908', 'loss/train': '0.062362', 'examples_per_second': '5.8443', 'grad_norm': '9.5', 'counters/examples': 78144, 'counters/updates': 4884}
skipping logging after 78160 examples to avoid logging too frequently
skipping logging after 78176 examples to avoid logging too frequently
skipping logging after 78192 examples to avoid logging too frequently
train stats after 78208 examples: {'rewards_train/chosen': '-3.7003', 'rewards_train/rejected': '-11.758', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.0601', 'logps_train/rejected': '-258.91', 'logps_train/chosen': '-76.621', 'loss/train': '0.097933', 'examples_per_second': '4.8112', 'grad_norm': '16.5', 'counters/examples': 78208, 'counters/updates': 4888}
skipping logging after 78224 examples to avoid logging too frequently
skipping logging after 78240 examples to avoid logging too frequently
skipping logging after 78256 examples to avoid logging too frequently
train stats after 78272 examples: {'rewards_train/chosen': '-3.0359', 'rewards_train/rejected': '-11.151', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.1121', 'logps_train/rejected': '-267.9', 'logps_train/chosen': '-77.709', 'loss/train': '0.056341', 'examples_per_second': '5.3007', 'grad_norm': '9.875', 'counters/examples': 78272, 'counters/updates': 4892}
skipping logging after 78288 examples to avoid logging too frequently
skipping logging after 78304 examples to avoid logging too frequently
skipping logging after 78320 examples to avoid logging too frequently
train stats after 78336 examples: {'rewards_train/chosen': '-3.1471', 'rewards_train/rejected': '-12.506', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.3582', 'logps_train/rejected': '-283.91', 'logps_train/chosen': '-76.1', 'loss/train': '0.071493', 'examples_per_second': '4.5416', 'grad_norm': '5.5312', 'counters/examples': 78336, 'counters/updates': 4896}
skipping logging after 78352 examples to avoid logging too frequently
skipping logging after 78368 examples to avoid logging too frequently
skipping logging after 78384 examples to avoid logging too frequently
train stats after 78400 examples: {'rewards_train/chosen': '-3.1814', 'rewards_train/rejected': '-11.471', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.2876', 'logps_train/rejected': '-254.75', 'logps_train/chosen': '-66.042', 'loss/train': '0.051361', 'examples_per_second': '5.8291', 'grad_norm': '6.25', 'counters/examples': 78400, 'counters/updates': 4900}
skipping logging after 78416 examples to avoid logging too frequently
skipping logging after 78432 examples to avoid logging too frequently
skipping logging after 78448 examples to avoid logging too frequently
train stats after 78464 examples: {'rewards_train/chosen': '-3.2418', 'rewards_train/rejected': '-10.982', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.74', 'logps_train/rejected': '-239.21', 'logps_train/chosen': '-71.115', 'loss/train': '0.17304', 'examples_per_second': '4.9508', 'grad_norm': '17', 'counters/examples': 78464, 'counters/updates': 4904}
skipping logging after 78480 examples to avoid logging too frequently
skipping logging after 78496 examples to avoid logging too frequently
skipping logging after 78512 examples to avoid logging too frequently
train stats after 78528 examples: {'rewards_train/chosen': '-3.1083', 'rewards_train/rejected': '-11.609', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.5012', 'logps_train/rejected': '-245.76', 'logps_train/chosen': '-71.961', 'loss/train': '0.053162', 'examples_per_second': '4.4438', 'grad_norm': '6.5625', 'counters/examples': 78528, 'counters/updates': 4908}
skipping logging after 78544 examples to avoid logging too frequently
skipping logging after 78560 examples to avoid logging too frequently
skipping logging after 78576 examples to avoid logging too frequently
train stats after 78592 examples: {'rewards_train/chosen': '-3.1071', 'rewards_train/rejected': '-11.97', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.8618', 'logps_train/rejected': '-267.61', 'logps_train/chosen': '-80.826', 'loss/train': '0.10629', 'examples_per_second': '5.5173', 'grad_norm': '18.625', 'counters/examples': 78592, 'counters/updates': 4912}
skipping logging after 78608 examples to avoid logging too frequently
skipping logging after 78624 examples to avoid logging too frequently
skipping logging after 78640 examples to avoid logging too frequently
train stats after 78656 examples: {'rewards_train/chosen': '-3.2018', 'rewards_train/rejected': '-11.946', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.7434', 'logps_train/rejected': '-260.29', 'logps_train/chosen': '-69.307', 'loss/train': '0.054319', 'examples_per_second': '4.7518', 'grad_norm': '6.5312', 'counters/examples': 78656, 'counters/updates': 4916}
skipping logging after 78672 examples to avoid logging too frequently
skipping logging after 78688 examples to avoid logging too frequently
skipping logging after 78704 examples to avoid logging too frequently
train stats after 78720 examples: {'rewards_train/chosen': '-2.9585', 'rewards_train/rejected': '-11.101', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1414', 'logps_train/rejected': '-248', 'logps_train/chosen': '-71.42', 'loss/train': '0.037893', 'examples_per_second': '5.0591', 'grad_norm': '5.9375', 'counters/examples': 78720, 'counters/updates': 4920}
skipping logging after 78736 examples to avoid logging too frequently
skipping logging after 78752 examples to avoid logging too frequently
skipping logging after 78768 examples to avoid logging too frequently
train stats after 78784 examples: {'rewards_train/chosen': '-3.5914', 'rewards_train/rejected': '-11.739', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1504', 'logps_train/rejected': '-246.85', 'logps_train/chosen': '-71.344', 'loss/train': '0.083555', 'examples_per_second': '4.4808', 'grad_norm': '13.812', 'counters/examples': 78784, 'counters/updates': 4924}
skipping logging after 78800 examples to avoid logging too frequently
skipping logging after 78816 examples to avoid logging too frequently
skipping logging after 78832 examples to avoid logging too frequently
train stats after 78848 examples: {'rewards_train/chosen': '-3.104', 'rewards_train/rejected': '-12.837', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.7366', 'logps_train/rejected': '-283.6', 'logps_train/chosen': '-65.77', 'loss/train': '0.040892', 'examples_per_second': '5.9593', 'grad_norm': '3.2812', 'counters/examples': 78848, 'counters/updates': 4928}
skipping logging after 78864 examples to avoid logging too frequently
skipping logging after 78880 examples to avoid logging too frequently
skipping logging after 78896 examples to avoid logging too frequently
train stats after 78912 examples: {'rewards_train/chosen': '-3.8135', 'rewards_train/rejected': '-13.318', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '9.5081', 'logps_train/rejected': '-299.84', 'logps_train/chosen': '-72.359', 'loss/train': '0.073154', 'examples_per_second': '5.307', 'grad_norm': '13.812', 'counters/examples': 78912, 'counters/updates': 4932}
skipping logging after 78928 examples to avoid logging too frequently
skipping logging after 78944 examples to avoid logging too frequently
skipping logging after 78960 examples to avoid logging too frequently
train stats after 78976 examples: {'rewards_train/chosen': '-2.9939', 'rewards_train/rejected': '-12.225', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.2285', 'logps_train/rejected': '-294.06', 'logps_train/chosen': '-71.156', 'loss/train': '0.078592', 'examples_per_second': '5.8632', 'grad_norm': '13.438', 'counters/examples': 78976, 'counters/updates': 4936}
skipping logging after 78992 examples to avoid logging too frequently
skipping logging after 79008 examples to avoid logging too frequently
skipping logging after 79024 examples to avoid logging too frequently
train stats after 79040 examples: {'rewards_train/chosen': '-3.0196', 'rewards_train/rejected': '-11.127', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.1084', 'logps_train/rejected': '-254.73', 'logps_train/chosen': '-78.17', 'loss/train': '0.018623', 'examples_per_second': '5.8686', 'grad_norm': '3.1719', 'counters/examples': 79040, 'counters/updates': 4940}
skipping logging after 79056 examples to avoid logging too frequently
skipping logging after 79072 examples to avoid logging too frequently
skipping logging after 79088 examples to avoid logging too frequently
train stats after 79104 examples: {'rewards_train/chosen': '-3.2828', 'rewards_train/rejected': '-10.921', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.6399', 'logps_train/rejected': '-225.46', 'logps_train/chosen': '-66.117', 'loss/train': '0.068445', 'examples_per_second': '4.9776', 'grad_norm': '9.25', 'counters/examples': 79104, 'counters/updates': 4944}
skipping logging after 79120 examples to avoid logging too frequently
skipping logging after 79136 examples to avoid logging too frequently
skipping logging after 79152 examples to avoid logging too frequently
train stats after 79168 examples: {'rewards_train/chosen': '-3.5407', 'rewards_train/rejected': '-11.756', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.2173', 'logps_train/rejected': '-259.65', 'logps_train/chosen': '-75.804', 'loss/train': '0.083343', 'examples_per_second': '4.9184', 'grad_norm': '9.3125', 'counters/examples': 79168, 'counters/updates': 4948}
skipping logging after 79184 examples to avoid logging too frequently
skipping logging after 79200 examples to avoid logging too frequently
skipping logging after 79216 examples to avoid logging too frequently
train stats after 79232 examples: {'rewards_train/chosen': '-3.1297', 'rewards_train/rejected': '-11.081', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.9529', 'logps_train/rejected': '-260.52', 'logps_train/chosen': '-73.553', 'loss/train': '0.078093', 'examples_per_second': '5.6845', 'grad_norm': '13.375', 'counters/examples': 79232, 'counters/updates': 4952}
skipping logging after 79248 examples to avoid logging too frequently
skipping logging after 79264 examples to avoid logging too frequently
skipping logging after 79280 examples to avoid logging too frequently
train stats after 79296 examples: {'rewards_train/chosen': '-3.0961', 'rewards_train/rejected': '-12.042', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.9458', 'logps_train/rejected': '-281.67', 'logps_train/chosen': '-76.669', 'loss/train': '0.015724', 'examples_per_second': '5.1787', 'grad_norm': '5.625', 'counters/examples': 79296, 'counters/updates': 4956}
skipping logging after 79312 examples to avoid logging too frequently
skipping logging after 79328 examples to avoid logging too frequently
skipping logging after 79344 examples to avoid logging too frequently
train stats after 79360 examples: {'rewards_train/chosen': '-2.8604', 'rewards_train/rejected': '-11.604', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.7436', 'logps_train/rejected': '-258.97', 'logps_train/chosen': '-72.269', 'loss/train': '0.068605', 'examples_per_second': '4.8772', 'grad_norm': '3.6406', 'counters/examples': 79360, 'counters/updates': 4960}
skipping logging after 79376 examples to avoid logging too frequently
skipping logging after 79392 examples to avoid logging too frequently
skipping logging after 79408 examples to avoid logging too frequently
train stats after 79424 examples: {'rewards_train/chosen': '-3.2322', 'rewards_train/rejected': '-11.25', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.0161', 'logps_train/rejected': '-254.73', 'logps_train/chosen': '-74.484', 'loss/train': '0.072022', 'examples_per_second': '5.5102', 'grad_norm': '9.5625', 'counters/examples': 79424, 'counters/updates': 4964}
skipping logging after 79440 examples to avoid logging too frequently
skipping logging after 79456 examples to avoid logging too frequently
skipping logging after 79472 examples to avoid logging too frequently
train stats after 79488 examples: {'rewards_train/chosen': '-3.4402', 'rewards_train/rejected': '-11.339', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.9019', 'logps_train/rejected': '-270.38', 'logps_train/chosen': '-84.27', 'loss/train': '0.060874', 'examples_per_second': '5.1329', 'grad_norm': '9.875', 'counters/examples': 79488, 'counters/updates': 4968}
skipping logging after 79504 examples to avoid logging too frequently
skipping logging after 79520 examples to avoid logging too frequently
skipping logging after 79536 examples to avoid logging too frequently
train stats after 79552 examples: {'rewards_train/chosen': '-3.6436', 'rewards_train/rejected': '-11.659', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.0115', 'logps_train/rejected': '-252.06', 'logps_train/chosen': '-80.428', 'loss/train': '0.053368', 'examples_per_second': '5.3601', 'grad_norm': '7.5938', 'counters/examples': 79552, 'counters/updates': 4972}
skipping logging after 79568 examples to avoid logging too frequently
skipping logging after 79584 examples to avoid logging too frequently
skipping logging after 79600 examples to avoid logging too frequently
train stats after 79616 examples: {'rewards_train/chosen': '-3.3019', 'rewards_train/rejected': '-11.237', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.9325', 'logps_train/rejected': '-263.75', 'logps_train/chosen': '-73.067', 'loss/train': '0.08454', 'examples_per_second': '5.482', 'grad_norm': '7.8438', 'counters/examples': 79616, 'counters/updates': 4976}
skipping logging after 79632 examples to avoid logging too frequently
skipping logging after 79648 examples to avoid logging too frequently
skipping logging after 79664 examples to avoid logging too frequently
train stats after 79680 examples: {'rewards_train/chosen': '-3.3625', 'rewards_train/rejected': '-11.901', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.5383', 'logps_train/rejected': '-269.87', 'logps_train/chosen': '-87.26', 'loss/train': '0.07953', 'examples_per_second': '4.3784', 'grad_norm': '15.688', 'counters/examples': 79680, 'counters/updates': 4980}
skipping logging after 79696 examples to avoid logging too frequently
skipping logging after 79712 examples to avoid logging too frequently
skipping logging after 79728 examples to avoid logging too frequently
train stats after 79744 examples: {'rewards_train/chosen': '-4.0946', 'rewards_train/rejected': '-12.124', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.032', 'logps_train/rejected': '-252.75', 'logps_train/chosen': '-81.619', 'loss/train': '0.093039', 'examples_per_second': '5.074', 'grad_norm': '12.438', 'counters/examples': 79744, 'counters/updates': 4984}
skipping logging after 79760 examples to avoid logging too frequently
skipping logging after 79776 examples to avoid logging too frequently
skipping logging after 79792 examples to avoid logging too frequently
train stats after 79808 examples: {'rewards_train/chosen': '-3.7894', 'rewards_train/rejected': '-12.414', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.6265', 'logps_train/rejected': '-261.61', 'logps_train/chosen': '-75.809', 'loss/train': '0.1073', 'examples_per_second': '5.3316', 'grad_norm': '13.438', 'counters/examples': 79808, 'counters/updates': 4988}
skipping logging after 79824 examples to avoid logging too frequently
skipping logging after 79840 examples to avoid logging too frequently
skipping logging after 79856 examples to avoid logging too frequently
train stats after 79872 examples: {'rewards_train/chosen': '-3.7', 'rewards_train/rejected': '-12.461', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.7581', 'logps_train/rejected': '-264.59', 'logps_train/chosen': '-68.176', 'loss/train': '0.10027', 'examples_per_second': '5.9036', 'grad_norm': '14.688', 'counters/examples': 79872, 'counters/updates': 4992}
skipping logging after 79888 examples to avoid logging too frequently
skipping logging after 79904 examples to avoid logging too frequently
skipping logging after 79920 examples to avoid logging too frequently
train stats after 79936 examples: {'rewards_train/chosen': '-2.9949', 'rewards_train/rejected': '-10.594', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.6008', 'logps_train/rejected': '-234.77', 'logps_train/chosen': '-72.301', 'loss/train': '0.042581', 'examples_per_second': '4.7698', 'grad_norm': '7.2188', 'counters/examples': 79936, 'counters/updates': 4996}
skipping logging after 79952 examples to avoid logging too frequently
skipping logging after 79968 examples to avoid logging too frequently
skipping logging after 79984 examples to avoid logging too frequently
train stats after 80000 examples: {'rewards_train/chosen': '-3.3651', 'rewards_train/rejected': '-11.061', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.6937', 'logps_train/rejected': '-246.86', 'logps_train/chosen': '-75.34', 'loss/train': '0.10514', 'examples_per_second': '5.881', 'grad_norm': '7.2188', 'counters/examples': 80000, 'counters/updates': 5000}
Running evaluation after 80000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<01:00,  1.95s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:00,  2.01s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:53,  1.84s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.86s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.52s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.55s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.48s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.55s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.49s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:22,  1.30s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.24s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.33s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.34s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.27s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.30s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.26s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.30s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.48s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.41s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.62s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.42s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.42s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 80000: {'rewards_eval/chosen': '-10.599', 'rewards_eval/rejected': '-11.11', 'rewards_eval/accuracies': '0.52734', 'rewards_eval/margins': '0.51193', 'logps_eval/rejected': '-258.76', 'logps_eval/chosen': '-250.9', 'loss/eval': '1.9439'}
skipping logging after 80016 examples to avoid logging too frequently
skipping logging after 80032 examples to avoid logging too frequently
skipping logging after 80048 examples to avoid logging too frequently
train stats after 80064 examples: {'rewards_train/chosen': '-2.9551', 'rewards_train/rejected': '-10.684', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.7307', 'logps_train/rejected': '-245.67', 'logps_train/chosen': '-69.305', 'loss/train': '0.056196', 'examples_per_second': '5.6925', 'grad_norm': '7.3438', 'counters/examples': 80064, 'counters/updates': 5004}
skipping logging after 80080 examples to avoid logging too frequently
skipping logging after 80096 examples to avoid logging too frequently
skipping logging after 80112 examples to avoid logging too frequently
train stats after 80128 examples: {'rewards_train/chosen': '-3.1667', 'rewards_train/rejected': '-12.584', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.4138', 'logps_train/rejected': '-263.7', 'logps_train/chosen': '-70.076', 'loss/train': '0.053823', 'examples_per_second': '5.5509', 'grad_norm': '11.312', 'counters/examples': 80128, 'counters/updates': 5008}
skipping logging after 80144 examples to avoid logging too frequently
skipping logging after 80160 examples to avoid logging too frequently
skipping logging after 80176 examples to avoid logging too frequently
train stats after 80192 examples: {'rewards_train/chosen': '-3.472', 'rewards_train/rejected': '-13.276', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.8066', 'logps_train/rejected': '-283.82', 'logps_train/chosen': '-73.746', 'loss/train': '0.08321', 'examples_per_second': '4.6065', 'grad_norm': '12.75', 'counters/examples': 80192, 'counters/updates': 5012}
skipping logging after 80208 examples to avoid logging too frequently
skipping logging after 80224 examples to avoid logging too frequently
skipping logging after 80240 examples to avoid logging too frequently
train stats after 80256 examples: {'rewards_train/chosen': '-3.6525', 'rewards_train/rejected': '-10.806', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.1548', 'logps_train/rejected': '-213.2', 'logps_train/chosen': '-68.529', 'loss/train': '0.071847', 'examples_per_second': '5.9347', 'grad_norm': '9.5', 'counters/examples': 80256, 'counters/updates': 5016}
skipping logging after 80272 examples to avoid logging too frequently
skipping logging after 80288 examples to avoid logging too frequently
skipping logging after 80304 examples to avoid logging too frequently
train stats after 80320 examples: {'rewards_train/chosen': '-3.7485', 'rewards_train/rejected': '-12.302', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.5552', 'logps_train/rejected': '-269.58', 'logps_train/chosen': '-86.117', 'loss/train': '0.084862', 'examples_per_second': '4.6885', 'grad_norm': '18.375', 'counters/examples': 80320, 'counters/updates': 5020}
skipping logging after 80336 examples to avoid logging too frequently
skipping logging after 80352 examples to avoid logging too frequently
skipping logging after 80368 examples to avoid logging too frequently
train stats after 80384 examples: {'rewards_train/chosen': '-3.7445', 'rewards_train/rejected': '-12.95', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.2029', 'logps_train/rejected': '-267.84', 'logps_train/chosen': '-83.182', 'loss/train': '0.043206', 'examples_per_second': '5.0012', 'grad_norm': '9.25', 'counters/examples': 80384, 'counters/updates': 5024}
skipping logging after 80400 examples to avoid logging too frequently
skipping logging after 80416 examples to avoid logging too frequently
skipping logging after 80432 examples to avoid logging too frequently
train stats after 80448 examples: {'rewards_train/chosen': '-3.9061', 'rewards_train/rejected': '-12.902', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.9978', 'logps_train/rejected': '-270.54', 'logps_train/chosen': '-82.4', 'loss/train': '0.044798', 'examples_per_second': '5.3408', 'grad_norm': '7.2812', 'counters/examples': 80448, 'counters/updates': 5028}
skipping logging after 80464 examples to avoid logging too frequently
skipping logging after 80480 examples to avoid logging too frequently
skipping logging after 80496 examples to avoid logging too frequently
train stats after 80512 examples: {'rewards_train/chosen': '-3.3426', 'rewards_train/rejected': '-13.52', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '10.178', 'logps_train/rejected': '-311.78', 'logps_train/chosen': '-87.603', 'loss/train': '0.069188', 'examples_per_second': '5.2077', 'grad_norm': '14.125', 'counters/examples': 80512, 'counters/updates': 5032}
skipping logging after 80528 examples to avoid logging too frequently
skipping logging after 80544 examples to avoid logging too frequently
skipping logging after 80560 examples to avoid logging too frequently
train stats after 80576 examples: {'rewards_train/chosen': '-3.2902', 'rewards_train/rejected': '-10.989', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.6968', 'logps_train/rejected': '-227.7', 'logps_train/chosen': '-67.756', 'loss/train': '0.089546', 'examples_per_second': '5.0387', 'grad_norm': '10.5', 'counters/examples': 80576, 'counters/updates': 5036}
skipping logging after 80592 examples to avoid logging too frequently
skipping logging after 80608 examples to avoid logging too frequently
skipping logging after 80624 examples to avoid logging too frequently
train stats after 80640 examples: {'rewards_train/chosen': '-2.9565', 'rewards_train/rejected': '-12.42', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.4624', 'logps_train/rejected': '-305.47', 'logps_train/chosen': '-68.932', 'loss/train': '0.022395', 'examples_per_second': '4.3266', 'grad_norm': '4.4062', 'counters/examples': 80640, 'counters/updates': 5040}
skipping logging after 80656 examples to avoid logging too frequently
skipping logging after 80672 examples to avoid logging too frequently
skipping logging after 80688 examples to avoid logging too frequently
train stats after 80704 examples: {'rewards_train/chosen': '-3.0191', 'rewards_train/rejected': '-11.099', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.0809', 'logps_train/rejected': '-227.43', 'logps_train/chosen': '-69.24', 'loss/train': '0.051564', 'examples_per_second': '5.1089', 'grad_norm': '7', 'counters/examples': 80704, 'counters/updates': 5044}
skipping logging after 80720 examples to avoid logging too frequently
skipping logging after 80736 examples to avoid logging too frequently
skipping logging after 80752 examples to avoid logging too frequently
train stats after 80768 examples: {'rewards_train/chosen': '-3.0754', 'rewards_train/rejected': '-12.088', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.0129', 'logps_train/rejected': '-275.12', 'logps_train/chosen': '-75.287', 'loss/train': '0.063212', 'examples_per_second': '4.0827', 'grad_norm': '10.188', 'counters/examples': 80768, 'counters/updates': 5048}
skipping logging after 80784 examples to avoid logging too frequently
skipping logging after 80800 examples to avoid logging too frequently
skipping logging after 80816 examples to avoid logging too frequently
train stats after 80832 examples: {'rewards_train/chosen': '-3.6139', 'rewards_train/rejected': '-12.367', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.7476', 'logps_train/rejected': '-266.79', 'logps_train/chosen': '-85.908', 'loss/train': '0.094662', 'examples_per_second': '5.8748', 'grad_norm': '15.562', 'counters/examples': 80832, 'counters/updates': 5052}
skipping logging after 80848 examples to avoid logging too frequently
skipping logging after 80864 examples to avoid logging too frequently
skipping logging after 80880 examples to avoid logging too frequently
train stats after 80896 examples: {'rewards_train/chosen': '-3.4289', 'rewards_train/rejected': '-11.128', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.6992', 'logps_train/rejected': '-263.47', 'logps_train/chosen': '-75.793', 'loss/train': '0.046967', 'examples_per_second': '4.7201', 'grad_norm': '7.1562', 'counters/examples': 80896, 'counters/updates': 5056}
skipping logging after 80912 examples to avoid logging too frequently
skipping logging after 80928 examples to avoid logging too frequently
skipping logging after 80944 examples to avoid logging too frequently
train stats after 80960 examples: {'rewards_train/chosen': '-3.31', 'rewards_train/rejected': '-12.687', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.3746', 'logps_train/rejected': '-271.76', 'logps_train/chosen': '-72.73', 'loss/train': '0.13931', 'examples_per_second': '4.3451', 'grad_norm': '17.375', 'counters/examples': 80960, 'counters/updates': 5060}
skipping logging after 80976 examples to avoid logging too frequently
skipping logging after 80992 examples to avoid logging too frequently
skipping logging after 81008 examples to avoid logging too frequently
train stats after 81024 examples: {'rewards_train/chosen': '-3.3683', 'rewards_train/rejected': '-11.471', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.1011', 'logps_train/rejected': '-267.8', 'logps_train/chosen': '-68.086', 'loss/train': '0.13885', 'examples_per_second': '5.3014', 'grad_norm': '15.5', 'counters/examples': 81024, 'counters/updates': 5064}
skipping logging after 81040 examples to avoid logging too frequently
skipping logging after 81056 examples to avoid logging too frequently
skipping logging after 81072 examples to avoid logging too frequently
train stats after 81088 examples: {'rewards_train/chosen': '-2.9517', 'rewards_train/rejected': '-12.176', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.224', 'logps_train/rejected': '-262.11', 'logps_train/chosen': '-73.177', 'loss/train': '0.060435', 'examples_per_second': '4.1293', 'grad_norm': '6.6875', 'counters/examples': 81088, 'counters/updates': 5068}
skipping logging after 81104 examples to avoid logging too frequently
skipping logging after 81120 examples to avoid logging too frequently
skipping logging after 81136 examples to avoid logging too frequently
train stats after 81152 examples: {'rewards_train/chosen': '-3.3007', 'rewards_train/rejected': '-13.026', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.72', 'logps_train/rejected': '-297.7', 'logps_train/chosen': '-74.309', 'loss/train': '0.063312', 'examples_per_second': '5.1254', 'grad_norm': '12.125', 'counters/examples': 81152, 'counters/updates': 5072}
skipping logging after 81168 examples to avoid logging too frequently
skipping logging after 81184 examples to avoid logging too frequently
skipping logging after 81200 examples to avoid logging too frequently
train stats after 81216 examples: {'rewards_train/chosen': '-3.2093', 'rewards_train/rejected': '-11.858', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.6465', 'logps_train/rejected': '-269.57', 'logps_train/chosen': '-81.025', 'loss/train': '0.036483', 'examples_per_second': '4.4471', 'grad_norm': '4.0938', 'counters/examples': 81216, 'counters/updates': 5076}
skipping logging after 81232 examples to avoid logging too frequently
skipping logging after 81248 examples to avoid logging too frequently
skipping logging after 81264 examples to avoid logging too frequently
train stats after 81280 examples: {'rewards_train/chosen': '-3.1736', 'rewards_train/rejected': '-11.498', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.3247', 'logps_train/rejected': '-252.63', 'logps_train/chosen': '-67.438', 'loss/train': '0.02077', 'examples_per_second': '5.5443', 'grad_norm': '5.0625', 'counters/examples': 81280, 'counters/updates': 5080}
skipping logging after 81296 examples to avoid logging too frequently
skipping logging after 81312 examples to avoid logging too frequently
skipping logging after 81328 examples to avoid logging too frequently
train stats after 81344 examples: {'rewards_train/chosen': '-3.2659', 'rewards_train/rejected': '-12.05', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.7842', 'logps_train/rejected': '-252.57', 'logps_train/chosen': '-72.68', 'loss/train': '0.13104', 'examples_per_second': '5.2629', 'grad_norm': '19', 'counters/examples': 81344, 'counters/updates': 5084}
skipping logging after 81360 examples to avoid logging too frequently
skipping logging after 81376 examples to avoid logging too frequently
skipping logging after 81392 examples to avoid logging too frequently
train stats after 81408 examples: {'rewards_train/chosen': '-3.0512', 'rewards_train/rejected': '-12.041', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.99', 'logps_train/rejected': '-255.6', 'logps_train/chosen': '-71.197', 'loss/train': '0.02577', 'examples_per_second': '4.7462', 'grad_norm': '3.625', 'counters/examples': 81408, 'counters/updates': 5088}
skipping logging after 81424 examples to avoid logging too frequently
skipping logging after 81440 examples to avoid logging too frequently
skipping logging after 81456 examples to avoid logging too frequently
train stats after 81472 examples: {'rewards_train/chosen': '-3.4388', 'rewards_train/rejected': '-11.722', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.2856', 'logps_train/rejected': '-244.79', 'logps_train/chosen': '-81.799', 'loss/train': '0.2416', 'examples_per_second': '5.2049', 'grad_norm': '17.75', 'counters/examples': 81472, 'counters/updates': 5092}
skipping logging after 81488 examples to avoid logging too frequently
skipping logging after 81504 examples to avoid logging too frequently
skipping logging after 81520 examples to avoid logging too frequently
train stats after 81536 examples: {'rewards_train/chosen': '-3.4865', 'rewards_train/rejected': '-11.029', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.5396', 'logps_train/rejected': '-232.51', 'logps_train/chosen': '-68.256', 'loss/train': '0.049851', 'examples_per_second': '4.3218', 'grad_norm': '9', 'counters/examples': 81536, 'counters/updates': 5096}
skipping logging after 81552 examples to avoid logging too frequently
skipping logging after 81568 examples to avoid logging too frequently
skipping logging after 81584 examples to avoid logging too frequently
train stats after 81600 examples: {'rewards_train/chosen': '-2.8472', 'rewards_train/rejected': '-11.122', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.2695', 'logps_train/rejected': '-259.57', 'logps_train/chosen': '-72.491', 'loss/train': '0.048324', 'examples_per_second': '6.1754', 'grad_norm': '8.125', 'counters/examples': 81600, 'counters/updates': 5100}
skipping logging after 81616 examples to avoid logging too frequently
skipping logging after 81632 examples to avoid logging too frequently
skipping logging after 81648 examples to avoid logging too frequently
train stats after 81664 examples: {'rewards_train/chosen': '-2.9939', 'rewards_train/rejected': '-11.694', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.698', 'logps_train/rejected': '-280.76', 'logps_train/chosen': '-66.438', 'loss/train': '0.02144', 'examples_per_second': '4.5782', 'grad_norm': '4.5312', 'counters/examples': 81664, 'counters/updates': 5104}
skipping logging after 81680 examples to avoid logging too frequently
skipping logging after 81696 examples to avoid logging too frequently
skipping logging after 81712 examples to avoid logging too frequently
train stats after 81728 examples: {'rewards_train/chosen': '-3.5587', 'rewards_train/rejected': '-10.683', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.1211', 'logps_train/rejected': '-224.4', 'logps_train/chosen': '-68.242', 'loss/train': '0.10079', 'examples_per_second': '5.2775', 'grad_norm': '13.5', 'counters/examples': 81728, 'counters/updates': 5108}
skipping logging after 81744 examples to avoid logging too frequently
skipping logging after 81760 examples to avoid logging too frequently
skipping logging after 81776 examples to avoid logging too frequently
train stats after 81792 examples: {'rewards_train/chosen': '-3.2779', 'rewards_train/rejected': '-12.168', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.8921', 'logps_train/rejected': '-277.11', 'logps_train/chosen': '-73.307', 'loss/train': '0.040713', 'examples_per_second': '4.1101', 'grad_norm': '10.562', 'counters/examples': 81792, 'counters/updates': 5112}
skipping logging after 81808 examples to avoid logging too frequently
skipping logging after 81824 examples to avoid logging too frequently
skipping logging after 81840 examples to avoid logging too frequently
train stats after 81856 examples: {'rewards_train/chosen': '-3.1905', 'rewards_train/rejected': '-11.503', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.3079', 'logps_train/rejected': '-245.91', 'logps_train/chosen': '-68.551', 'loss/train': '0.086396', 'examples_per_second': '5.5624', 'grad_norm': '18.75', 'counters/examples': 81856, 'counters/updates': 5116}
skipping logging after 81872 examples to avoid logging too frequently
skipping logging after 81888 examples to avoid logging too frequently
skipping logging after 81904 examples to avoid logging too frequently
train stats after 81920 examples: {'rewards_train/chosen': '-3.2214', 'rewards_train/rejected': '-10.733', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.5129', 'logps_train/rejected': '-220.86', 'logps_train/chosen': '-71.932', 'loss/train': '0.065137', 'examples_per_second': '5.2951', 'grad_norm': '8.9375', 'counters/examples': 81920, 'counters/updates': 5120}
skipping logging after 81936 examples to avoid logging too frequently
skipping logging after 81952 examples to avoid logging too frequently
skipping logging after 81968 examples to avoid logging too frequently
train stats after 81984 examples: {'rewards_train/chosen': '-2.9391', 'rewards_train/rejected': '-11.289', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.3473', 'logps_train/rejected': '-249.5', 'logps_train/chosen': '-71.426', 'loss/train': '0.072681', 'examples_per_second': '4.7261', 'grad_norm': '7.6562', 'counters/examples': 81984, 'counters/updates': 5124}
skipping logging after 82000 examples to avoid logging too frequently
skipping logging after 82016 examples to avoid logging too frequently
skipping logging after 82032 examples to avoid logging too frequently
train stats after 82048 examples: {'rewards_train/chosen': '-3.1009', 'rewards_train/rejected': '-11.226', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.126', 'logps_train/rejected': '-235.54', 'logps_train/chosen': '-70.026', 'loss/train': '0.19464', 'examples_per_second': '5.6958', 'grad_norm': '16', 'counters/examples': 82048, 'counters/updates': 5128}
skipping logging after 82064 examples to avoid logging too frequently
skipping logging after 82080 examples to avoid logging too frequently
skipping logging after 82096 examples to avoid logging too frequently
train stats after 82112 examples: {'rewards_train/chosen': '-3.0429', 'rewards_train/rejected': '-10.22', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.1787', 'logps_train/rejected': '-249.3', 'logps_train/chosen': '-68.337', 'loss/train': '0.028928', 'examples_per_second': '4.3856', 'grad_norm': '5.5625', 'counters/examples': 82112, 'counters/updates': 5132}
skipping logging after 82128 examples to avoid logging too frequently
skipping logging after 82144 examples to avoid logging too frequently
skipping logging after 82160 examples to avoid logging too frequently
train stats after 82176 examples: {'rewards_train/chosen': '-2.9621', 'rewards_train/rejected': '-9.7075', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.7449', 'logps_train/rejected': '-225.67', 'logps_train/chosen': '-71.986', 'loss/train': '0.060924', 'examples_per_second': '5.4234', 'grad_norm': '14', 'counters/examples': 82176, 'counters/updates': 5136}
skipping logging after 82192 examples to avoid logging too frequently
skipping logging after 82208 examples to avoid logging too frequently
skipping logging after 82224 examples to avoid logging too frequently
train stats after 82240 examples: {'rewards_train/chosen': '-2.9025', 'rewards_train/rejected': '-10.517', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.6162', 'logps_train/rejected': '-261.99', 'logps_train/chosen': '-72.043', 'loss/train': '0.025482', 'examples_per_second': '5.4397', 'grad_norm': '3.7969', 'counters/examples': 82240, 'counters/updates': 5140}
skipping logging after 82256 examples to avoid logging too frequently
skipping logging after 82272 examples to avoid logging too frequently
skipping logging after 82288 examples to avoid logging too frequently
train stats after 82304 examples: {'rewards_train/chosen': '-2.8773', 'rewards_train/rejected': '-10.396', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.5166', 'logps_train/rejected': '-232.93', 'logps_train/chosen': '-70.354', 'loss/train': '0.076283', 'examples_per_second': '6.2628', 'grad_norm': '7.6875', 'counters/examples': 82304, 'counters/updates': 5144}
skipping logging after 82320 examples to avoid logging too frequently
skipping logging after 82336 examples to avoid logging too frequently
skipping logging after 82352 examples to avoid logging too frequently
train stats after 82368 examples: {'rewards_train/chosen': '-3.0268', 'rewards_train/rejected': '-11.291', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.2631', 'logps_train/rejected': '-237.36', 'logps_train/chosen': '-67.91', 'loss/train': '0.049195', 'examples_per_second': '4.0117', 'grad_norm': '15.312', 'counters/examples': 82368, 'counters/updates': 5148}
skipping logging after 82384 examples to avoid logging too frequently
skipping logging after 82400 examples to avoid logging too frequently
skipping logging after 82416 examples to avoid logging too frequently
train stats after 82432 examples: {'rewards_train/chosen': '-3.3719', 'rewards_train/rejected': '-10.894', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.5198', 'logps_train/rejected': '-242.39', 'logps_train/chosen': '-76.047', 'loss/train': '0.11936', 'examples_per_second': '5.3022', 'grad_norm': '24.375', 'counters/examples': 82432, 'counters/updates': 5152}
skipping logging after 82448 examples to avoid logging too frequently
skipping logging after 82464 examples to avoid logging too frequently
skipping logging after 82480 examples to avoid logging too frequently
train stats after 82496 examples: {'rewards_train/chosen': '-3.2533', 'rewards_train/rejected': '-11.148', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.8958', 'logps_train/rejected': '-238.08', 'logps_train/chosen': '-73.112', 'loss/train': '0.04329', 'examples_per_second': '5.5025', 'grad_norm': '8.9375', 'counters/examples': 82496, 'counters/updates': 5156}
skipping logging after 82512 examples to avoid logging too frequently
skipping logging after 82528 examples to avoid logging too frequently
skipping logging after 82544 examples to avoid logging too frequently
train stats after 82560 examples: {'rewards_train/chosen': '-3.0058', 'rewards_train/rejected': '-10.965', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.9592', 'logps_train/rejected': '-240.25', 'logps_train/chosen': '-66.123', 'loss/train': '0.09956', 'examples_per_second': '6.1675', 'grad_norm': '16.125', 'counters/examples': 82560, 'counters/updates': 5160}
skipping logging after 82576 examples to avoid logging too frequently
skipping logging after 82592 examples to avoid logging too frequently
skipping logging after 82608 examples to avoid logging too frequently
train stats after 82624 examples: {'rewards_train/chosen': '-3.236', 'rewards_train/rejected': '-12.466', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.2307', 'logps_train/rejected': '-271.38', 'logps_train/chosen': '-81.693', 'loss/train': '0.16172', 'examples_per_second': '4.6573', 'grad_norm': '14.938', 'counters/examples': 82624, 'counters/updates': 5164}
skipping logging after 82640 examples to avoid logging too frequently
skipping logging after 82656 examples to avoid logging too frequently
skipping logging after 82672 examples to avoid logging too frequently
train stats after 82688 examples: {'rewards_train/chosen': '-3.2233', 'rewards_train/rejected': '-11.74', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.5164', 'logps_train/rejected': '-253.38', 'logps_train/chosen': '-63.852', 'loss/train': '0.10957', 'examples_per_second': '5.3277', 'grad_norm': '14.312', 'counters/examples': 82688, 'counters/updates': 5168}
skipping logging after 82704 examples to avoid logging too frequently
skipping logging after 82720 examples to avoid logging too frequently
skipping logging after 82736 examples to avoid logging too frequently
train stats after 82752 examples: {'rewards_train/chosen': '-2.7437', 'rewards_train/rejected': '-10.577', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.8335', 'logps_train/rejected': '-231.55', 'logps_train/chosen': '-63.735', 'loss/train': '0.085898', 'examples_per_second': '5.9923', 'grad_norm': '11.375', 'counters/examples': 82752, 'counters/updates': 5172}
skipping logging after 82768 examples to avoid logging too frequently
skipping logging after 82784 examples to avoid logging too frequently
skipping logging after 82800 examples to avoid logging too frequently
train stats after 82816 examples: {'rewards_train/chosen': '-2.8036', 'rewards_train/rejected': '-10.717', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.9093', 'logps_train/rejected': '-229.44', 'logps_train/chosen': '-61.65', 'loss/train': '0.16186', 'examples_per_second': '4.9501', 'grad_norm': '14.625', 'counters/examples': 82816, 'counters/updates': 5176}
skipping logging after 82832 examples to avoid logging too frequently
skipping logging after 82848 examples to avoid logging too frequently
skipping logging after 82864 examples to avoid logging too frequently
train stats after 82880 examples: {'rewards_train/chosen': '-3.1121', 'rewards_train/rejected': '-12.24', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.1277', 'logps_train/rejected': '-255.16', 'logps_train/chosen': '-64.521', 'loss/train': '0.02102', 'examples_per_second': '5.6184', 'grad_norm': '4.9062', 'counters/examples': 82880, 'counters/updates': 5180}
skipping logging after 82896 examples to avoid logging too frequently
skipping logging after 82912 examples to avoid logging too frequently
skipping logging after 82928 examples to avoid logging too frequently
train stats after 82944 examples: {'rewards_train/chosen': '-3.5685', 'rewards_train/rejected': '-12.199', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.6288', 'logps_train/rejected': '-265.05', 'logps_train/chosen': '-64.741', 'loss/train': '0.091698', 'examples_per_second': '5.2046', 'grad_norm': '8.3125', 'counters/examples': 82944, 'counters/updates': 5184}
skipping logging after 82960 examples to avoid logging too frequently
skipping logging after 82976 examples to avoid logging too frequently
skipping logging after 82992 examples to avoid logging too frequently
train stats after 83008 examples: {'rewards_train/chosen': '-3.1756', 'rewards_train/rejected': '-12.048', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.8708', 'logps_train/rejected': '-259.84', 'logps_train/chosen': '-67.201', 'loss/train': '0.047541', 'examples_per_second': '5.0537', 'grad_norm': '9.4375', 'counters/examples': 83008, 'counters/updates': 5188}
skipping logging after 83024 examples to avoid logging too frequently
skipping logging after 83040 examples to avoid logging too frequently
skipping logging after 83056 examples to avoid logging too frequently
train stats after 83072 examples: {'rewards_train/chosen': '-3.0921', 'rewards_train/rejected': '-10.62', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.5259', 'logps_train/rejected': '-245.12', 'logps_train/chosen': '-82.054', 'loss/train': '0.10361', 'examples_per_second': '6.3422', 'grad_norm': '19.625', 'counters/examples': 83072, 'counters/updates': 5192}
skipping logging after 83088 examples to avoid logging too frequently
skipping logging after 83104 examples to avoid logging too frequently
skipping logging after 83120 examples to avoid logging too frequently
train stats after 83136 examples: {'rewards_train/chosen': '-2.8895', 'rewards_train/rejected': '-12.737', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.8481', 'logps_train/rejected': '-304.29', 'logps_train/chosen': '-69.273', 'loss/train': '0.051492', 'examples_per_second': '4.8041', 'grad_norm': '3.9531', 'counters/examples': 83136, 'counters/updates': 5196}
skipping logging after 83152 examples to avoid logging too frequently
skipping logging after 83168 examples to avoid logging too frequently
skipping logging after 83184 examples to avoid logging too frequently
train stats after 83200 examples: {'rewards_train/chosen': '-2.8034', 'rewards_train/rejected': '-12.604', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.8022', 'logps_train/rejected': '-284.53', 'logps_train/chosen': '-77.518', 'loss/train': '0.017103', 'examples_per_second': '3.7375', 'grad_norm': '6.2812', 'counters/examples': 83200, 'counters/updates': 5200}
skipping logging after 83216 examples to avoid logging too frequently
skipping logging after 83232 examples to avoid logging too frequently
skipping logging after 83248 examples to avoid logging too frequently
train stats after 83264 examples: {'rewards_train/chosen': '-3.0564', 'rewards_train/rejected': '-10.095', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.0415', 'logps_train/rejected': '-224.68', 'logps_train/chosen': '-73.452', 'loss/train': '0.12017', 'examples_per_second': '4.6784', 'grad_norm': '15.812', 'counters/examples': 83264, 'counters/updates': 5204}
skipping logging after 83280 examples to avoid logging too frequently
skipping logging after 83296 examples to avoid logging too frequently
skipping logging after 83312 examples to avoid logging too frequently
train stats after 83328 examples: {'rewards_train/chosen': '-3.5461', 'rewards_train/rejected': '-11.401', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.8545', 'logps_train/rejected': '-255.77', 'logps_train/chosen': '-77.65', 'loss/train': '0.18116', 'examples_per_second': '6.1822', 'grad_norm': '16.625', 'counters/examples': 83328, 'counters/updates': 5208}
skipping logging after 83344 examples to avoid logging too frequently
skipping logging after 83360 examples to avoid logging too frequently
skipping logging after 83376 examples to avoid logging too frequently
train stats after 83392 examples: {'rewards_train/chosen': '-3.4335', 'rewards_train/rejected': '-10.809', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.3745', 'logps_train/rejected': '-224.02', 'logps_train/chosen': '-73.062', 'loss/train': '0.055252', 'examples_per_second': '4.7643', 'grad_norm': '4.7188', 'counters/examples': 83392, 'counters/updates': 5212}
skipping logging after 83408 examples to avoid logging too frequently
skipping logging after 83424 examples to avoid logging too frequently
skipping logging after 83440 examples to avoid logging too frequently
train stats after 83456 examples: {'rewards_train/chosen': '-3.2756', 'rewards_train/rejected': '-12.343', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.0662', 'logps_train/rejected': '-271.72', 'logps_train/chosen': '-71.566', 'loss/train': '0.052081', 'examples_per_second': '4.6548', 'grad_norm': '5.1875', 'counters/examples': 83456, 'counters/updates': 5216}
skipping logging after 83472 examples to avoid logging too frequently
skipping logging after 83488 examples to avoid logging too frequently
skipping logging after 83504 examples to avoid logging too frequently
train stats after 83520 examples: {'rewards_train/chosen': '-2.9581', 'rewards_train/rejected': '-12.39', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.4314', 'logps_train/rejected': '-310.77', 'logps_train/chosen': '-67.047', 'loss/train': '0.083457', 'examples_per_second': '4.6826', 'grad_norm': '12.5', 'counters/examples': 83520, 'counters/updates': 5220}
skipping logging after 83536 examples to avoid logging too frequently
skipping logging after 83552 examples to avoid logging too frequently
skipping logging after 83568 examples to avoid logging too frequently
train stats after 83584 examples: {'rewards_train/chosen': '-3.1603', 'rewards_train/rejected': '-11.732', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.5728', 'logps_train/rejected': '-263.1', 'logps_train/chosen': '-68.608', 'loss/train': '0.12958', 'examples_per_second': '4.1825', 'grad_norm': '12.125', 'counters/examples': 83584, 'counters/updates': 5224}
skipping logging after 83600 examples to avoid logging too frequently
skipping logging after 83616 examples to avoid logging too frequently
skipping logging after 83632 examples to avoid logging too frequently
train stats after 83648 examples: {'rewards_train/chosen': '-3.3754', 'rewards_train/rejected': '-11.876', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.5005', 'logps_train/rejected': '-245.97', 'logps_train/chosen': '-75.572', 'loss/train': '0.15093', 'examples_per_second': '5.1429', 'grad_norm': '18.375', 'counters/examples': 83648, 'counters/updates': 5228}
skipping logging after 83664 examples to avoid logging too frequently
skipping logging after 83680 examples to avoid logging too frequently
skipping logging after 83696 examples to avoid logging too frequently
train stats after 83712 examples: {'rewards_train/chosen': '-2.9079', 'rewards_train/rejected': '-11.476', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.5686', 'logps_train/rejected': '-287.07', 'logps_train/chosen': '-66.467', 'loss/train': '0.058256', 'examples_per_second': '5.6094', 'grad_norm': '7.1562', 'counters/examples': 83712, 'counters/updates': 5232}
skipping logging after 83728 examples to avoid logging too frequently
skipping logging after 83744 examples to avoid logging too frequently
skipping logging after 83760 examples to avoid logging too frequently
train stats after 83776 examples: {'rewards_train/chosen': '-3.1435', 'rewards_train/rejected': '-10.849', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.7083', 'logps_train/rejected': '-238.65', 'logps_train/chosen': '-67.377', 'loss/train': '0.053794', 'examples_per_second': '5.2621', 'grad_norm': '5.8438', 'counters/examples': 83776, 'counters/updates': 5236}
skipping logging after 83792 examples to avoid logging too frequently
skipping logging after 83808 examples to avoid logging too frequently
skipping logging after 83824 examples to avoid logging too frequently
train stats after 83840 examples: {'rewards_train/chosen': '-2.7276', 'rewards_train/rejected': '-10.941', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.2126', 'logps_train/rejected': '-242.05', 'logps_train/chosen': '-65.739', 'loss/train': '0.054698', 'examples_per_second': '6.2475', 'grad_norm': '9.75', 'counters/examples': 83840, 'counters/updates': 5240}
skipping logging after 83856 examples to avoid logging too frequently
skipping logging after 83872 examples to avoid logging too frequently
skipping logging after 83888 examples to avoid logging too frequently
train stats after 83904 examples: {'rewards_train/chosen': '-2.8558', 'rewards_train/rejected': '-12.266', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.4084', 'logps_train/rejected': '-290.17', 'logps_train/chosen': '-70.609', 'loss/train': '0.034726', 'examples_per_second': '4.5746', 'grad_norm': '4.125', 'counters/examples': 83904, 'counters/updates': 5244}
skipping logging after 83920 examples to avoid logging too frequently
skipping logging after 83936 examples to avoid logging too frequently
skipping logging after 83952 examples to avoid logging too frequently
train stats after 83968 examples: {'rewards_train/chosen': '-2.8082', 'rewards_train/rejected': '-11.938', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.1323', 'logps_train/rejected': '-276.31', 'logps_train/chosen': '-71.477', 'loss/train': '0.032828', 'examples_per_second': '4.1095', 'grad_norm': '4.9688', 'counters/examples': 83968, 'counters/updates': 5248}
skipping logging after 83984 examples to avoid logging too frequently
skipping logging after 84000 examples to avoid logging too frequently
Running evaluation after 84000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:07,  2.19s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:03,  2.12s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:55,  1.90s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.89s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.55s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.66s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.49s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.57s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:36,  1.57s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.50s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.57s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:30,  1.50s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.46s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:22,  1.30s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.24s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.33s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.34s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:14,  1.27s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:33<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.30s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.26s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:37<00:07,  1.30s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:39<00:07,  1.48s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.42s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.62s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.42s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.42s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.44s/it]
eval after 84000: {'rewards_eval/chosen': '-11.071', 'rewards_eval/rejected': '-11.72', 'rewards_eval/accuracies': '0.5332', 'rewards_eval/margins': '0.64828', 'logps_eval/rejected': '-264.86', 'logps_eval/chosen': '-255.63', 'loss/eval': '2.0344'}
skipping logging after 84016 examples to avoid logging too frequently
train stats after 84032 examples: {'rewards_train/chosen': '-2.963', 'rewards_train/rejected': '-11.637', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.677', 'logps_train/rejected': '-249.69', 'logps_train/chosen': '-68.39', 'loss/train': '0.08838', 'examples_per_second': '5.5469', 'grad_norm': '9.625', 'counters/examples': 84032, 'counters/updates': 5252}
skipping logging after 84048 examples to avoid logging too frequently
skipping logging after 84064 examples to avoid logging too frequently
skipping logging after 84080 examples to avoid logging too frequently
train stats after 84096 examples: {'rewards_train/chosen': '-3.4603', 'rewards_train/rejected': '-11.601', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.1433', 'logps_train/rejected': '-244.03', 'logps_train/chosen': '-73.268', 'loss/train': '0.044554', 'examples_per_second': '4.964', 'grad_norm': '6.5625', 'counters/examples': 84096, 'counters/updates': 5256}
skipping logging after 84112 examples to avoid logging too frequently
skipping logging after 84128 examples to avoid logging too frequently
skipping logging after 84144 examples to avoid logging too frequently
train stats after 84160 examples: {'rewards_train/chosen': '-3.127', 'rewards_train/rejected': '-12.214', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.0852', 'logps_train/rejected': '-261.23', 'logps_train/chosen': '-73.778', 'loss/train': '0.074011', 'examples_per_second': '4.6874', 'grad_norm': '13.438', 'counters/examples': 84160, 'counters/updates': 5260}
skipping logging after 84176 examples to avoid logging too frequently
skipping logging after 84192 examples to avoid logging too frequently
skipping logging after 84208 examples to avoid logging too frequently
train stats after 84224 examples: {'rewards_train/chosen': '-3.4879', 'rewards_train/rejected': '-12.483', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.9905', 'logps_train/rejected': '-299.96', 'logps_train/chosen': '-81.617', 'loss/train': '0.047365', 'examples_per_second': '4.8547', 'grad_norm': '8.9375', 'counters/examples': 84224, 'counters/updates': 5264}
skipping logging after 84240 examples to avoid logging too frequently
skipping logging after 84256 examples to avoid logging too frequently
skipping logging after 84272 examples to avoid logging too frequently
train stats after 84288 examples: {'rewards_train/chosen': '-3.4875', 'rewards_train/rejected': '-12.147', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.6614', 'logps_train/rejected': '-283.4', 'logps_train/chosen': '-69.611', 'loss/train': '0.16902', 'examples_per_second': '4.9011', 'grad_norm': '24.25', 'counters/examples': 84288, 'counters/updates': 5268}
skipping logging after 84304 examples to avoid logging too frequently
skipping logging after 84320 examples to avoid logging too frequently
skipping logging after 84336 examples to avoid logging too frequently
train stats after 84352 examples: {'rewards_train/chosen': '-2.6807', 'rewards_train/rejected': '-10.088', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.4097', 'logps_train/rejected': '-240.44', 'logps_train/chosen': '-65.379', 'loss/train': '0.032161', 'examples_per_second': '5.3071', 'grad_norm': '1.6484', 'counters/examples': 84352, 'counters/updates': 5272}
skipping logging after 84368 examples to avoid logging too frequently
skipping logging after 84384 examples to avoid logging too frequently
skipping logging after 84400 examples to avoid logging too frequently
train stats after 84416 examples: {'rewards_train/chosen': '-2.9469', 'rewards_train/rejected': '-9.8188', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.8711', 'logps_train/rejected': '-216.68', 'logps_train/chosen': '-69.229', 'loss/train': '0.054613', 'examples_per_second': '5.1569', 'grad_norm': '12.062', 'counters/examples': 84416, 'counters/updates': 5276}
skipping logging after 84432 examples to avoid logging too frequently
skipping logging after 84448 examples to avoid logging too frequently
skipping logging after 84464 examples to avoid logging too frequently
train stats after 84480 examples: {'rewards_train/chosen': '-2.7949', 'rewards_train/rejected': '-11.74', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.9426', 'logps_train/rejected': '-266.74', 'logps_train/chosen': '-68.707', 'loss/train': '0.024779', 'examples_per_second': '5.1516', 'grad_norm': '4.2812', 'counters/examples': 84480, 'counters/updates': 5280}
skipping logging after 84496 examples to avoid logging too frequently
skipping logging after 84512 examples to avoid logging too frequently
skipping logging after 84528 examples to avoid logging too frequently
train stats after 84544 examples: {'rewards_train/chosen': '-3.3607', 'rewards_train/rejected': '-12.623', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '9.261', 'logps_train/rejected': '-267.49', 'logps_train/chosen': '-65.414', 'loss/train': '0.18915', 'examples_per_second': '5.8052', 'grad_norm': '19', 'counters/examples': 84544, 'counters/updates': 5284}
skipping logging after 84560 examples to avoid logging too frequently
skipping logging after 84576 examples to avoid logging too frequently
skipping logging after 84592 examples to avoid logging too frequently
train stats after 84608 examples: {'rewards_train/chosen': '-3.0842', 'rewards_train/rejected': '-11.579', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.4902', 'logps_train/rejected': '-255.39', 'logps_train/chosen': '-76.756', 'loss/train': '0.095921', 'examples_per_second': '4.6801', 'grad_norm': '10.5', 'counters/examples': 84608, 'counters/updates': 5288}
skipping logging after 84624 examples to avoid logging too frequently
skipping logging after 84640 examples to avoid logging too frequently
skipping logging after 84656 examples to avoid logging too frequently
train stats after 84672 examples: {'rewards_train/chosen': '-3.5067', 'rewards_train/rejected': '-12.833', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.3247', 'logps_train/rejected': '-277.9', 'logps_train/chosen': '-74.105', 'loss/train': '0.12891', 'examples_per_second': '5.0803', 'grad_norm': '19.375', 'counters/examples': 84672, 'counters/updates': 5292}
skipping logging after 84688 examples to avoid logging too frequently
skipping logging after 84704 examples to avoid logging too frequently
skipping logging after 84720 examples to avoid logging too frequently
train stats after 84736 examples: {'rewards_train/chosen': '-3.093', 'rewards_train/rejected': '-12.165', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.0713', 'logps_train/rejected': '-249.61', 'logps_train/chosen': '-64.309', 'loss/train': '0.097108', 'examples_per_second': '5.6368', 'grad_norm': '11.125', 'counters/examples': 84736, 'counters/updates': 5296}
skipping logging after 84752 examples to avoid logging too frequently
skipping logging after 84768 examples to avoid logging too frequently
skipping logging after 84784 examples to avoid logging too frequently
train stats after 84800 examples: {'rewards_train/chosen': '-3.0492', 'rewards_train/rejected': '-12.386', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '9.3353', 'logps_train/rejected': '-278.33', 'logps_train/chosen': '-80.615', 'loss/train': '0.050219', 'examples_per_second': '5.0902', 'grad_norm': '10.25', 'counters/examples': 84800, 'counters/updates': 5300}
skipping logging after 84816 examples to avoid logging too frequently
skipping logging after 84832 examples to avoid logging too frequently
skipping logging after 84848 examples to avoid logging too frequently
train stats after 84864 examples: {'rewards_train/chosen': '-2.9735', 'rewards_train/rejected': '-12.376', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.4016', 'logps_train/rejected': '-253.87', 'logps_train/chosen': '-73.71', 'loss/train': '0.040033', 'examples_per_second': '5.9983', 'grad_norm': '5.0312', 'counters/examples': 84864, 'counters/updates': 5304}
skipping logging after 84880 examples to avoid logging too frequently
skipping logging after 84896 examples to avoid logging too frequently
skipping logging after 84912 examples to avoid logging too frequently
train stats after 84928 examples: {'rewards_train/chosen': '-2.995', 'rewards_train/rejected': '-12.99', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.9941', 'logps_train/rejected': '-258.93', 'logps_train/chosen': '-69.686', 'loss/train': '0.047299', 'examples_per_second': '5.2387', 'grad_norm': '6.75', 'counters/examples': 84928, 'counters/updates': 5308}
skipping logging after 84944 examples to avoid logging too frequently
skipping logging after 84960 examples to avoid logging too frequently
skipping logging after 84976 examples to avoid logging too frequently
train stats after 84992 examples: {'rewards_train/chosen': '-3.2508', 'rewards_train/rejected': '-11.605', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.3584', 'logps_train/rejected': '-243.28', 'logps_train/chosen': '-68.984', 'loss/train': '0.084981', 'examples_per_second': '5.5915', 'grad_norm': '11.188', 'counters/examples': 84992, 'counters/updates': 5312}
skipping logging after 85008 examples to avoid logging too frequently
skipping logging after 85024 examples to avoid logging too frequently
skipping logging after 85040 examples to avoid logging too frequently
train stats after 85056 examples: {'rewards_train/chosen': '-3.4151', 'rewards_train/rejected': '-12.744', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.3229', 'logps_train/rejected': '-282.54', 'logps_train/chosen': '-73.207', 'loss/train': '0.071759', 'examples_per_second': '4.3376', 'grad_norm': '10.125', 'counters/examples': 85056, 'counters/updates': 5316}
skipping logging after 85072 examples to avoid logging too frequently
skipping logging after 85088 examples to avoid logging too frequently
skipping logging after 85104 examples to avoid logging too frequently
train stats after 85120 examples: {'rewards_train/chosen': '-3.1649', 'rewards_train/rejected': '-13.201', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '10.036', 'logps_train/rejected': '-302.47', 'logps_train/chosen': '-73.546', 'loss/train': '0.060366', 'examples_per_second': '4.5143', 'grad_norm': '6.7188', 'counters/examples': 85120, 'counters/updates': 5320}
skipping logging after 85136 examples to avoid logging too frequently
skipping logging after 85152 examples to avoid logging too frequently
skipping logging after 85168 examples to avoid logging too frequently
train stats after 85184 examples: {'rewards_train/chosen': '-3.3181', 'rewards_train/rejected': '-11.567', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.2498', 'logps_train/rejected': '-244.48', 'logps_train/chosen': '-77.448', 'loss/train': '0.054909', 'examples_per_second': '4.5736', 'grad_norm': '5.9375', 'counters/examples': 85184, 'counters/updates': 5324}
skipping logging after 85200 examples to avoid logging too frequently
skipping logging after 85216 examples to avoid logging too frequently
skipping logging after 85232 examples to avoid logging too frequently
train stats after 85248 examples: {'rewards_train/chosen': '-2.973', 'rewards_train/rejected': '-11.044', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.074', 'logps_train/rejected': '-237.93', 'logps_train/chosen': '-64.877', 'loss/train': '0.14148', 'examples_per_second': '3.9265', 'grad_norm': '21.25', 'counters/examples': 85248, 'counters/updates': 5328}
skipping logging after 85264 examples to avoid logging too frequently
skipping logging after 85280 examples to avoid logging too frequently
skipping logging after 85296 examples to avoid logging too frequently
train stats after 85312 examples: {'rewards_train/chosen': '-2.694', 'rewards_train/rejected': '-11.732', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.0352', 'logps_train/rejected': '-276.24', 'logps_train/chosen': '-64.983', 'loss/train': '0.065938', 'examples_per_second': '4.6971', 'grad_norm': '16.25', 'counters/examples': 85312, 'counters/updates': 5332}
skipping logging after 85328 examples to avoid logging too frequently
skipping logging after 85344 examples to avoid logging too frequently
skipping logging after 85360 examples to avoid logging too frequently
train stats after 85376 examples: {'rewards_train/chosen': '-3.0555', 'rewards_train/rejected': '-11.283', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.2278', 'logps_train/rejected': '-238.06', 'logps_train/chosen': '-70.753', 'loss/train': '0.0842', 'examples_per_second': '6.215', 'grad_norm': '10.125', 'counters/examples': 85376, 'counters/updates': 5336}
skipping logging after 85392 examples to avoid logging too frequently
skipping logging after 85408 examples to avoid logging too frequently
skipping logging after 85424 examples to avoid logging too frequently
train stats after 85440 examples: {'rewards_train/chosen': '-3.0101', 'rewards_train/rejected': '-13.406', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '10.394', 'logps_train/rejected': '-310.27', 'logps_train/chosen': '-69.922', 'loss/train': '0.05595', 'examples_per_second': '4.44', 'grad_norm': '10.125', 'counters/examples': 85440, 'counters/updates': 5340}
skipping logging after 85456 examples to avoid logging too frequently
skipping logging after 85472 examples to avoid logging too frequently
skipping logging after 85488 examples to avoid logging too frequently
train stats after 85504 examples: {'rewards_train/chosen': '-3.6221', 'rewards_train/rejected': '-12.81', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '9.1893', 'logps_train/rejected': '-264.79', 'logps_train/chosen': '-75.08', 'loss/train': '0.050038', 'examples_per_second': '4.4034', 'grad_norm': '6.0938', 'counters/examples': 85504, 'counters/updates': 5344}
skipping logging after 85520 examples to avoid logging too frequently
skipping logging after 85536 examples to avoid logging too frequently
skipping logging after 85552 examples to avoid logging too frequently
train stats after 85568 examples: {'rewards_train/chosen': '-3.9085', 'rewards_train/rejected': '-15.012', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '11.106', 'logps_train/rejected': '-309.7', 'logps_train/chosen': '-84.871', 'loss/train': '0.073592', 'examples_per_second': '5.7037', 'grad_norm': '17.25', 'counters/examples': 85568, 'counters/updates': 5348}
skipping logging after 85584 examples to avoid logging too frequently
skipping logging after 85600 examples to avoid logging too frequently
skipping logging after 85616 examples to avoid logging too frequently
train stats after 85632 examples: {'rewards_train/chosen': '-3.6969', 'rewards_train/rejected': '-12.776', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '9.0771', 'logps_train/rejected': '-258.49', 'logps_train/chosen': '-84.216', 'loss/train': '0.061518', 'examples_per_second': '5.5678', 'grad_norm': '11.875', 'counters/examples': 85632, 'counters/updates': 5352}
skipping logging after 85648 examples to avoid logging too frequently
skipping logging after 85664 examples to avoid logging too frequently
skipping logging after 85680 examples to avoid logging too frequently
train stats after 85696 examples: {'rewards_train/chosen': '-3.3262', 'rewards_train/rejected': '-12.548', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.2227', 'logps_train/rejected': '-264.58', 'logps_train/chosen': '-69.375', 'loss/train': '0.13527', 'examples_per_second': '5.233', 'grad_norm': '16.375', 'counters/examples': 85696, 'counters/updates': 5356}
skipping logging after 85712 examples to avoid logging too frequently
skipping logging after 85728 examples to avoid logging too frequently
skipping logging after 85744 examples to avoid logging too frequently
train stats after 85760 examples: {'rewards_train/chosen': '-3.0456', 'rewards_train/rejected': '-12.481', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.4375', 'logps_train/rejected': '-236.53', 'logps_train/chosen': '-67.195', 'loss/train': '0.066729', 'examples_per_second': '5.3208', 'grad_norm': '7.4375', 'counters/examples': 85760, 'counters/updates': 5360}
skipping logging after 85776 examples to avoid logging too frequently
skipping logging after 85792 examples to avoid logging too frequently
skipping logging after 85808 examples to avoid logging too frequently
train stats after 85824 examples: {'rewards_train/chosen': '-3.6148', 'rewards_train/rejected': '-12.404', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '8.79', 'logps_train/rejected': '-275.7', 'logps_train/chosen': '-85.75', 'loss/train': '0.086659', 'examples_per_second': '5.2825', 'grad_norm': '15.75', 'counters/examples': 85824, 'counters/updates': 5364}
skipping logging after 85840 examples to avoid logging too frequently
skipping logging after 85856 examples to avoid logging too frequently
skipping logging after 85872 examples to avoid logging too frequently
train stats after 85888 examples: {'rewards_train/chosen': '-3.5632', 'rewards_train/rejected': '-11.01', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.4468', 'logps_train/rejected': '-240.66', 'logps_train/chosen': '-85.969', 'loss/train': '0.10586', 'examples_per_second': '5.1894', 'grad_norm': '15.438', 'counters/examples': 85888, 'counters/updates': 5368}
skipping logging after 85904 examples to avoid logging too frequently
skipping logging after 85920 examples to avoid logging too frequently
skipping logging after 85936 examples to avoid logging too frequently
train stats after 85952 examples: {'rewards_train/chosen': '-3.41', 'rewards_train/rejected': '-11.854', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.4507', 'logps_train/rejected': '-258.09', 'logps_train/chosen': '-82.938', 'loss/train': '0.04802', 'examples_per_second': '4.7361', 'grad_norm': '6.2812', 'counters/examples': 85952, 'counters/updates': 5372}
skipping logging after 85968 examples to avoid logging too frequently
skipping logging after 85984 examples to avoid logging too frequently
skipping logging after 86000 examples to avoid logging too frequently
train stats after 86016 examples: {'rewards_train/chosen': '-3.2726', 'rewards_train/rejected': '-12.663', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.3975', 'logps_train/rejected': '-282.87', 'logps_train/chosen': '-78.465', 'loss/train': '0.073624', 'examples_per_second': '4.1977', 'grad_norm': '15.375', 'counters/examples': 86016, 'counters/updates': 5376}
skipping logging after 86032 examples to avoid logging too frequently
skipping logging after 86048 examples to avoid logging too frequently
skipping logging after 86064 examples to avoid logging too frequently
train stats after 86080 examples: {'rewards_train/chosen': '-3.1929', 'rewards_train/rejected': '-10.798', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.6023', 'logps_train/rejected': '-249.38', 'logps_train/chosen': '-77.964', 'loss/train': '0.21703', 'examples_per_second': '4.1656', 'grad_norm': '22', 'counters/examples': 86080, 'counters/updates': 5380}
skipping logging after 86096 examples to avoid logging too frequently
skipping logging after 86112 examples to avoid logging too frequently
skipping logging after 86128 examples to avoid logging too frequently
train stats after 86144 examples: {'rewards_train/chosen': '-3.3006', 'rewards_train/rejected': '-10.752', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.4565', 'logps_train/rejected': '-241.6', 'logps_train/chosen': '-77.684', 'loss/train': '0.089279', 'examples_per_second': '4.6465', 'grad_norm': '9.5', 'counters/examples': 86144, 'counters/updates': 5384}
skipping logging after 86160 examples to avoid logging too frequently
skipping logging after 86176 examples to avoid logging too frequently
skipping logging after 86192 examples to avoid logging too frequently
train stats after 86208 examples: {'rewards_train/chosen': '-3.1858', 'rewards_train/rejected': '-11.112', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.9272', 'logps_train/rejected': '-236.51', 'logps_train/chosen': '-71.342', 'loss/train': '0.090127', 'examples_per_second': '5.5009', 'grad_norm': '11', 'counters/examples': 86208, 'counters/updates': 5388}
skipping logging after 86224 examples to avoid logging too frequently
skipping logging after 86240 examples to avoid logging too frequently
skipping logging after 86256 examples to avoid logging too frequently
train stats after 86272 examples: {'rewards_train/chosen': '-3.2505', 'rewards_train/rejected': '-10.845', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.5935', 'logps_train/rejected': '-213.61', 'logps_train/chosen': '-64.828', 'loss/train': '0.054635', 'examples_per_second': '5.4039', 'grad_norm': '7.1562', 'counters/examples': 86272, 'counters/updates': 5392}
skipping logging after 86288 examples to avoid logging too frequently
skipping logging after 86304 examples to avoid logging too frequently
skipping logging after 86320 examples to avoid logging too frequently
train stats after 86336 examples: {'rewards_train/chosen': '-3.532', 'rewards_train/rejected': '-12.914', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.3855', 'logps_train/rejected': '-292.18', 'logps_train/chosen': '-86', 'loss/train': '0.065185', 'examples_per_second': '4.7264', 'grad_norm': '10.688', 'counters/examples': 86336, 'counters/updates': 5396}
skipping logging after 86352 examples to avoid logging too frequently
skipping logging after 86368 examples to avoid logging too frequently
skipping logging after 86384 examples to avoid logging too frequently
train stats after 86400 examples: {'rewards_train/chosen': '-2.8759', 'rewards_train/rejected': '-12.381', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.5063', 'logps_train/rejected': '-272.48', 'logps_train/chosen': '-67.232', 'loss/train': '0.032355', 'examples_per_second': '4.7957', 'grad_norm': '6', 'counters/examples': 86400, 'counters/updates': 5400}
skipping logging after 86416 examples to avoid logging too frequently
skipping logging after 86432 examples to avoid logging too frequently
skipping logging after 86448 examples to avoid logging too frequently
train stats after 86464 examples: {'rewards_train/chosen': '-3.1741', 'rewards_train/rejected': '-12.368', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.1921', 'logps_train/rejected': '-278.26', 'logps_train/chosen': '-73.523', 'loss/train': '0.10265', 'examples_per_second': '4.5832', 'grad_norm': '18.125', 'counters/examples': 86464, 'counters/updates': 5404}
skipping logging after 86480 examples to avoid logging too frequently
skipping logging after 86496 examples to avoid logging too frequently
skipping logging after 86512 examples to avoid logging too frequently
train stats after 86528 examples: {'rewards_train/chosen': '-3.423', 'rewards_train/rejected': '-12.135', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.7141', 'logps_train/rejected': '-292.32', 'logps_train/chosen': '-79.708', 'loss/train': '0.055214', 'examples_per_second': '4.9155', 'grad_norm': '10.875', 'counters/examples': 86528, 'counters/updates': 5408}
skipping logging after 86544 examples to avoid logging too frequently
skipping logging after 86560 examples to avoid logging too frequently
skipping logging after 86576 examples to avoid logging too frequently
train stats after 86592 examples: {'rewards_train/chosen': '-3.7842', 'rewards_train/rejected': '-12.27', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.4856', 'logps_train/rejected': '-240.74', 'logps_train/chosen': '-78.793', 'loss/train': '0.038331', 'examples_per_second': '5.4595', 'grad_norm': '7.1562', 'counters/examples': 86592, 'counters/updates': 5412}
skipping logging after 86608 examples to avoid logging too frequently
skipping logging after 86624 examples to avoid logging too frequently
skipping logging after 86640 examples to avoid logging too frequently
train stats after 86656 examples: {'rewards_train/chosen': '-3.4642', 'rewards_train/rejected': '-12.476', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.0156', 'logps_train/rejected': '-284.62', 'logps_train/chosen': '-71.104', 'loss/train': '0.14126', 'examples_per_second': '5.0272', 'grad_norm': '19.625', 'counters/examples': 86656, 'counters/updates': 5416}
skipping logging after 86672 examples to avoid logging too frequently
skipping logging after 86688 examples to avoid logging too frequently
skipping logging after 86704 examples to avoid logging too frequently
train stats after 86720 examples: {'rewards_train/chosen': '-3.3294', 'rewards_train/rejected': '-11.242', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.9119', 'logps_train/rejected': '-240.8', 'logps_train/chosen': '-78.684', 'loss/train': '0.064836', 'examples_per_second': '5.5131', 'grad_norm': '10.75', 'counters/examples': 86720, 'counters/updates': 5420}
skipping logging after 86736 examples to avoid logging too frequently
skipping logging after 86752 examples to avoid logging too frequently
skipping logging after 86768 examples to avoid logging too frequently
train stats after 86784 examples: {'rewards_train/chosen': '-3.0298', 'rewards_train/rejected': '-11.541', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.5098', 'logps_train/rejected': '-260.13', 'logps_train/chosen': '-71.393', 'loss/train': '0.042974', 'examples_per_second': '4.9641', 'grad_norm': '8.875', 'counters/examples': 86784, 'counters/updates': 5424}
skipping logging after 86800 examples to avoid logging too frequently
skipping logging after 86816 examples to avoid logging too frequently
skipping logging after 86832 examples to avoid logging too frequently
train stats after 86848 examples: {'rewards_train/chosen': '-3.4248', 'rewards_train/rejected': '-12.807', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.3823', 'logps_train/rejected': '-264.99', 'logps_train/chosen': '-78.162', 'loss/train': '0.12067', 'examples_per_second': '4.9604', 'grad_norm': '10.312', 'counters/examples': 86848, 'counters/updates': 5428}
skipping logging after 86864 examples to avoid logging too frequently
skipping logging after 86880 examples to avoid logging too frequently
skipping logging after 86896 examples to avoid logging too frequently
train stats after 86912 examples: {'rewards_train/chosen': '-3.5903', 'rewards_train/rejected': '-12.741', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.1531', 'logps_train/rejected': '-264.57', 'logps_train/chosen': '-73.814', 'loss/train': '0.028661', 'examples_per_second': '4.2871', 'grad_norm': '5.5312', 'counters/examples': 86912, 'counters/updates': 5432}
skipping logging after 86928 examples to avoid logging too frequently
skipping logging after 86944 examples to avoid logging too frequently
skipping logging after 86960 examples to avoid logging too frequently
train stats after 86976 examples: {'rewards_train/chosen': '-3.6134', 'rewards_train/rejected': '-12.445', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.8293', 'logps_train/rejected': '-263.99', 'logps_train/chosen': '-71.569', 'loss/train': '0.079265', 'examples_per_second': '4.441', 'grad_norm': '10.188', 'counters/examples': 86976, 'counters/updates': 5436}
skipping logging after 86992 examples to avoid logging too frequently
skipping logging after 87008 examples to avoid logging too frequently
skipping logging after 87024 examples to avoid logging too frequently
train stats after 87040 examples: {'rewards_train/chosen': '-4.0364', 'rewards_train/rejected': '-14.233', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '10.191', 'logps_train/rejected': '-275.05', 'logps_train/chosen': '-77.207', 'loss/train': '0.044741', 'examples_per_second': '5.1816', 'grad_norm': '7.2188', 'counters/examples': 87040, 'counters/updates': 5440}
skipping logging after 87056 examples to avoid logging too frequently
skipping logging after 87072 examples to avoid logging too frequently
skipping logging after 87088 examples to avoid logging too frequently
train stats after 87104 examples: {'rewards_train/chosen': '-3.8254', 'rewards_train/rejected': '-14.343', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '10.52', 'logps_train/rejected': '-281.52', 'logps_train/chosen': '-74.898', 'loss/train': '0.059232', 'examples_per_second': '5.1655', 'grad_norm': '20.25', 'counters/examples': 87104, 'counters/updates': 5444}
skipping logging after 87120 examples to avoid logging too frequently
skipping logging after 87136 examples to avoid logging too frequently
skipping logging after 87152 examples to avoid logging too frequently
train stats after 87168 examples: {'rewards_train/chosen': '-4.1639', 'rewards_train/rejected': '-13.113', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.9446', 'logps_train/rejected': '-255.33', 'logps_train/chosen': '-77.475', 'loss/train': '0.076771', 'examples_per_second': '5.7032', 'grad_norm': '16.125', 'counters/examples': 87168, 'counters/updates': 5448}
skipping logging after 87184 examples to avoid logging too frequently
skipping logging after 87200 examples to avoid logging too frequently
skipping logging after 87216 examples to avoid logging too frequently
train stats after 87232 examples: {'rewards_train/chosen': '-3.8392', 'rewards_train/rejected': '-14.569', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '10.729', 'logps_train/rejected': '-334.57', 'logps_train/chosen': '-84.665', 'loss/train': '0.074289', 'examples_per_second': '4.8717', 'grad_norm': '7.6562', 'counters/examples': 87232, 'counters/updates': 5452}
skipping logging after 87248 examples to avoid logging too frequently
skipping logging after 87264 examples to avoid logging too frequently
skipping logging after 87280 examples to avoid logging too frequently
train stats after 87296 examples: {'rewards_train/chosen': '-3.3549', 'rewards_train/rejected': '-12.748', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.3967', 'logps_train/rejected': '-291.44', 'logps_train/chosen': '-77.83', 'loss/train': '0.11571', 'examples_per_second': '5.2542', 'grad_norm': '14.625', 'counters/examples': 87296, 'counters/updates': 5456}
skipping logging after 87312 examples to avoid logging too frequently
skipping logging after 87328 examples to avoid logging too frequently
skipping logging after 87344 examples to avoid logging too frequently
train stats after 87360 examples: {'rewards_train/chosen': '-3.33', 'rewards_train/rejected': '-12.898', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.5703', 'logps_train/rejected': '-280.88', 'logps_train/chosen': '-75.215', 'loss/train': '0.096378', 'examples_per_second': '5.6397', 'grad_norm': '11.125', 'counters/examples': 87360, 'counters/updates': 5460}
skipping logging after 87376 examples to avoid logging too frequently
skipping logging after 87392 examples to avoid logging too frequently
skipping logging after 87408 examples to avoid logging too frequently
train stats after 87424 examples: {'rewards_train/chosen': '-3.4231', 'rewards_train/rejected': '-11.957', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.5342', 'logps_train/rejected': '-234.06', 'logps_train/chosen': '-72.521', 'loss/train': '0.073536', 'examples_per_second': '5.7103', 'grad_norm': '10.25', 'counters/examples': 87424, 'counters/updates': 5464}
skipping logging after 87440 examples to avoid logging too frequently
skipping logging after 87456 examples to avoid logging too frequently
skipping logging after 87472 examples to avoid logging too frequently
train stats after 87488 examples: {'rewards_train/chosen': '-3.3847', 'rewards_train/rejected': '-13.299', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.9221', 'logps_train/rejected': '-281.23', 'logps_train/chosen': '-73.582', 'loss/train': '0.024199', 'examples_per_second': '5.5425', 'grad_norm': '8.5', 'counters/examples': 87488, 'counters/updates': 5468}
skipping logging after 87504 examples to avoid logging too frequently
skipping logging after 87520 examples to avoid logging too frequently
skipping logging after 87536 examples to avoid logging too frequently
train stats after 87552 examples: {'rewards_train/chosen': '-3.6223', 'rewards_train/rejected': '-13.895', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '10.268', 'logps_train/rejected': '-278.57', 'logps_train/chosen': '-77.783', 'loss/train': '0.042764', 'examples_per_second': '4.0853', 'grad_norm': '4.6562', 'counters/examples': 87552, 'counters/updates': 5472}
skipping logging after 87568 examples to avoid logging too frequently
skipping logging after 87584 examples to avoid logging too frequently
skipping logging after 87600 examples to avoid logging too frequently
train stats after 87616 examples: {'rewards_train/chosen': '-4.0996', 'rewards_train/rejected': '-14.686', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '10.583', 'logps_train/rejected': '-299.95', 'logps_train/chosen': '-80.486', 'loss/train': '0.026812', 'examples_per_second': '4.7669', 'grad_norm': '7.125', 'counters/examples': 87616, 'counters/updates': 5476}
skipping logging after 87632 examples to avoid logging too frequently
skipping logging after 87648 examples to avoid logging too frequently
skipping logging after 87664 examples to avoid logging too frequently
train stats after 87680 examples: {'rewards_train/chosen': '-4.2139', 'rewards_train/rejected': '-14.691', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '10.479', 'logps_train/rejected': '-318.73', 'logps_train/chosen': '-87.117', 'loss/train': '0.1259', 'examples_per_second': '5.24', 'grad_norm': '17.75', 'counters/examples': 87680, 'counters/updates': 5480}
skipping logging after 87696 examples to avoid logging too frequently
skipping logging after 87712 examples to avoid logging too frequently
skipping logging after 87728 examples to avoid logging too frequently
train stats after 87744 examples: {'rewards_train/chosen': '-3.5735', 'rewards_train/rejected': '-11.599', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.0193', 'logps_train/rejected': '-237.4', 'logps_train/chosen': '-72.855', 'loss/train': '0.11151', 'examples_per_second': '6.1075', 'grad_norm': '10.438', 'counters/examples': 87744, 'counters/updates': 5484}
skipping logging after 87760 examples to avoid logging too frequently
skipping logging after 87776 examples to avoid logging too frequently
skipping logging after 87792 examples to avoid logging too frequently
train stats after 87808 examples: {'rewards_train/chosen': '-3.5647', 'rewards_train/rejected': '-13.559', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.9932', 'logps_train/rejected': '-279.93', 'logps_train/chosen': '-80.175', 'loss/train': '0.094802', 'examples_per_second': '5.2333', 'grad_norm': '15.938', 'counters/examples': 87808, 'counters/updates': 5488}
skipping logging after 87824 examples to avoid logging too frequently
skipping logging after 87840 examples to avoid logging too frequently
skipping logging after 87856 examples to avoid logging too frequently
train stats after 87872 examples: {'rewards_train/chosen': '-3.6307', 'rewards_train/rejected': '-13.76', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '10.132', 'logps_train/rejected': '-285.24', 'logps_train/chosen': '-77.507', 'loss/train': '0.03416', 'examples_per_second': '5.2524', 'grad_norm': '4.7812', 'counters/examples': 87872, 'counters/updates': 5492}
skipping logging after 87888 examples to avoid logging too frequently
skipping logging after 87904 examples to avoid logging too frequently
skipping logging after 87920 examples to avoid logging too frequently
train stats after 87936 examples: {'rewards_train/chosen': '-3.8849', 'rewards_train/rejected': '-12.829', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.9421', 'logps_train/rejected': '-257.31', 'logps_train/chosen': '-75.43', 'loss/train': '0.11505', 'examples_per_second': '4.2321', 'grad_norm': '17.5', 'counters/examples': 87936, 'counters/updates': 5496}
skipping logging after 87952 examples to avoid logging too frequently
skipping logging after 87968 examples to avoid logging too frequently
skipping logging after 87984 examples to avoid logging too frequently
train stats after 88000 examples: {'rewards_train/chosen': '-3.5296', 'rewards_train/rejected': '-14.308', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '10.778', 'logps_train/rejected': '-299.98', 'logps_train/chosen': '-66.467', 'loss/train': '0.051508', 'examples_per_second': '4.6381', 'grad_norm': '5.125', 'counters/examples': 88000, 'counters/updates': 5500}
Running evaluation after 88000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<01:00,  1.94s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:00,  2.01s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:53,  1.84s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.85s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.52s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.50s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:22,  1.30s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.24s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.33s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.34s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:14,  1.27s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.30s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.27s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.30s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.48s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.41s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.62s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.42s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.42s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 88000: {'rewards_eval/chosen': '-14.014', 'rewards_eval/rejected': '-14.528', 'rewards_eval/accuracies': '0.52344', 'rewards_eval/margins': '0.51376', 'logps_eval/rejected': '-292.93', 'logps_eval/chosen': '-285.04', 'loss/eval': '2.7501'}
skipping logging after 88016 examples to avoid logging too frequently
skipping logging after 88032 examples to avoid logging too frequently
skipping logging after 88048 examples to avoid logging too frequently
train stats after 88064 examples: {'rewards_train/chosen': '-4.1432', 'rewards_train/rejected': '-15.492', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '11.346', 'logps_train/rejected': '-304.7', 'logps_train/chosen': '-76.658', 'loss/train': '0.032139', 'examples_per_second': '6.0199', 'grad_norm': '9.75', 'counters/examples': 88064, 'counters/updates': 5504}
skipping logging after 88080 examples to avoid logging too frequently
skipping logging after 88096 examples to avoid logging too frequently
skipping logging after 88112 examples to avoid logging too frequently
train stats after 88128 examples: {'rewards_train/chosen': '-3.756', 'rewards_train/rejected': '-14.051', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '10.296', 'logps_train/rejected': '-274.2', 'logps_train/chosen': '-76.048', 'loss/train': '0.1192', 'examples_per_second': '6.0041', 'grad_norm': '11.562', 'counters/examples': 88128, 'counters/updates': 5508}
skipping logging after 88144 examples to avoid logging too frequently
skipping logging after 88160 examples to avoid logging too frequently
skipping logging after 88176 examples to avoid logging too frequently
train stats after 88192 examples: {'rewards_train/chosen': '-3.7693', 'rewards_train/rejected': '-13.787', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '10.017', 'logps_train/rejected': '-269.53', 'logps_train/chosen': '-76.873', 'loss/train': '0.10811', 'examples_per_second': '5.1712', 'grad_norm': '17.875', 'counters/examples': 88192, 'counters/updates': 5512}
skipping logging after 88208 examples to avoid logging too frequently
skipping logging after 88224 examples to avoid logging too frequently
skipping logging after 88240 examples to avoid logging too frequently
train stats after 88256 examples: {'rewards_train/chosen': '-3.6255', 'rewards_train/rejected': '-13.465', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.8398', 'logps_train/rejected': '-266.2', 'logps_train/chosen': '-86.049', 'loss/train': '0.074914', 'examples_per_second': '4.327', 'grad_norm': '14.312', 'counters/examples': 88256, 'counters/updates': 5516}
skipping logging after 88272 examples to avoid logging too frequently
skipping logging after 88288 examples to avoid logging too frequently
skipping logging after 88304 examples to avoid logging too frequently
train stats after 88320 examples: {'rewards_train/chosen': '-3.4088', 'rewards_train/rejected': '-13.832', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '10.424', 'logps_train/rejected': '-261.6', 'logps_train/chosen': '-69.342', 'loss/train': '0.047967', 'examples_per_second': '6.2956', 'grad_norm': '8.4375', 'counters/examples': 88320, 'counters/updates': 5520}
skipping logging after 88336 examples to avoid logging too frequently
skipping logging after 88352 examples to avoid logging too frequently
skipping logging after 88368 examples to avoid logging too frequently
train stats after 88384 examples: {'rewards_train/chosen': '-3.3883', 'rewards_train/rejected': '-14.781', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '11.391', 'logps_train/rejected': '-324.02', 'logps_train/chosen': '-89.346', 'loss/train': '0.024293', 'examples_per_second': '4.7244', 'grad_norm': '7.875', 'counters/examples': 88384, 'counters/updates': 5524}
skipping logging after 88400 examples to avoid logging too frequently
skipping logging after 88416 examples to avoid logging too frequently
skipping logging after 88432 examples to avoid logging too frequently
train stats after 88448 examples: {'rewards_train/chosen': '-3.2798', 'rewards_train/rejected': '-11.705', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.425', 'logps_train/rejected': '-234.71', 'logps_train/chosen': '-69.633', 'loss/train': '0.059333', 'examples_per_second': '5.9147', 'grad_norm': '6.6562', 'counters/examples': 88448, 'counters/updates': 5528}
skipping logging after 88464 examples to avoid logging too frequently
skipping logging after 88480 examples to avoid logging too frequently
skipping logging after 88496 examples to avoid logging too frequently
train stats after 88512 examples: {'rewards_train/chosen': '-3.3514', 'rewards_train/rejected': '-12.896', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.541', 'logps_train/rejected': '-249.49', 'logps_train/chosen': '-76.021', 'loss/train': '0.022698', 'examples_per_second': '4.5153', 'grad_norm': '7.3438', 'counters/examples': 88512, 'counters/updates': 5532}
skipping logging after 88528 examples to avoid logging too frequently
skipping logging after 88544 examples to avoid logging too frequently
skipping logging after 88560 examples to avoid logging too frequently
train stats after 88576 examples: {'rewards_train/chosen': '-3.3027', 'rewards_train/rejected': '-11.416', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.115', 'logps_train/rejected': '-240.89', 'logps_train/chosen': '-76.607', 'loss/train': '0.076201', 'examples_per_second': '4.5263', 'grad_norm': '6', 'counters/examples': 88576, 'counters/updates': 5536}
skipping logging after 88592 examples to avoid logging too frequently
skipping logging after 88608 examples to avoid logging too frequently
skipping logging after 88624 examples to avoid logging too frequently
train stats after 88640 examples: {'rewards_train/chosen': '-3.8379', 'rewards_train/rejected': '-11.47', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.6321', 'logps_train/rejected': '-221.88', 'logps_train/chosen': '-84.961', 'loss/train': '0.042532', 'examples_per_second': '5.3063', 'grad_norm': '9.75', 'counters/examples': 88640, 'counters/updates': 5540}
skipping logging after 88656 examples to avoid logging too frequently
skipping logging after 88672 examples to avoid logging too frequently
skipping logging after 88688 examples to avoid logging too frequently
train stats after 88704 examples: {'rewards_train/chosen': '-3.5141', 'rewards_train/rejected': '-12.248', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.7358', 'logps_train/rejected': '-268.6', 'logps_train/chosen': '-70.83', 'loss/train': '0.10344', 'examples_per_second': '5.0188', 'grad_norm': '9.25', 'counters/examples': 88704, 'counters/updates': 5544}
skipping logging after 88720 examples to avoid logging too frequently
skipping logging after 88736 examples to avoid logging too frequently
skipping logging after 88752 examples to avoid logging too frequently
train stats after 88768 examples: {'rewards_train/chosen': '-4.3604', 'rewards_train/rejected': '-11.922', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '7.562', 'logps_train/rejected': '-235.42', 'logps_train/chosen': '-81.082', 'loss/train': '0.22092', 'examples_per_second': '4.6017', 'grad_norm': '30.75', 'counters/examples': 88768, 'counters/updates': 5548}
skipping logging after 88784 examples to avoid logging too frequently
skipping logging after 88800 examples to avoid logging too frequently
skipping logging after 88816 examples to avoid logging too frequently
train stats after 88832 examples: {'rewards_train/chosen': '-3.3797', 'rewards_train/rejected': '-11.963', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.5828', 'logps_train/rejected': '-250.28', 'logps_train/chosen': '-66.45', 'loss/train': '0.095669', 'examples_per_second': '5.3314', 'grad_norm': '10.438', 'counters/examples': 88832, 'counters/updates': 5552}
skipping logging after 88848 examples to avoid logging too frequently
skipping logging after 88864 examples to avoid logging too frequently
skipping logging after 88880 examples to avoid logging too frequently
train stats after 88896 examples: {'rewards_train/chosen': '-3.636', 'rewards_train/rejected': '-13.183', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '9.5474', 'logps_train/rejected': '-264.59', 'logps_train/chosen': '-80.327', 'loss/train': '0.099317', 'examples_per_second': '5.9707', 'grad_norm': '15.688', 'counters/examples': 88896, 'counters/updates': 5556}
skipping logging after 88912 examples to avoid logging too frequently
skipping logging after 88928 examples to avoid logging too frequently
skipping logging after 88944 examples to avoid logging too frequently
train stats after 88960 examples: {'rewards_train/chosen': '-3.9293', 'rewards_train/rejected': '-13.533', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.6025', 'logps_train/rejected': '-274.91', 'logps_train/chosen': '-82.812', 'loss/train': '0.09188', 'examples_per_second': '5.7726', 'grad_norm': '22', 'counters/examples': 88960, 'counters/updates': 5560}
skipping logging after 88976 examples to avoid logging too frequently
skipping logging after 88992 examples to avoid logging too frequently
skipping logging after 89008 examples to avoid logging too frequently
train stats after 89024 examples: {'rewards_train/chosen': '-3.4861', 'rewards_train/rejected': '-12.904', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.4175', 'logps_train/rejected': '-292.73', 'logps_train/chosen': '-74.412', 'loss/train': '0.056706', 'examples_per_second': '5.7921', 'grad_norm': '8.25', 'counters/examples': 89024, 'counters/updates': 5564}
skipping logging after 89040 examples to avoid logging too frequently
skipping logging after 89056 examples to avoid logging too frequently
skipping logging after 89072 examples to avoid logging too frequently
train stats after 89088 examples: {'rewards_train/chosen': '-3.452', 'rewards_train/rejected': '-12.935', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '9.4844', 'logps_train/rejected': '-278.21', 'logps_train/chosen': '-86.252', 'loss/train': '0.10508', 'examples_per_second': '4.7246', 'grad_norm': '22', 'counters/examples': 89088, 'counters/updates': 5568}
skipping logging after 89104 examples to avoid logging too frequently
skipping logging after 89120 examples to avoid logging too frequently
skipping logging after 89136 examples to avoid logging too frequently
train stats after 89152 examples: {'rewards_train/chosen': '-3.9745', 'rewards_train/rejected': '-11.537', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.5664', 'logps_train/rejected': '-244.73', 'logps_train/chosen': '-81.436', 'loss/train': '0.074432', 'examples_per_second': '4.481', 'grad_norm': '11', 'counters/examples': 89152, 'counters/updates': 5572}
skipping logging after 89168 examples to avoid logging too frequently
skipping logging after 89184 examples to avoid logging too frequently
skipping logging after 89200 examples to avoid logging too frequently
train stats after 89216 examples: {'rewards_train/chosen': '-3.2768', 'rewards_train/rejected': '-12.297', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.0183', 'logps_train/rejected': '-280.93', 'logps_train/chosen': '-72.627', 'loss/train': '0.035076', 'examples_per_second': '4.4971', 'grad_norm': '5.3438', 'counters/examples': 89216, 'counters/updates': 5576}
skipping logging after 89232 examples to avoid logging too frequently
skipping logging after 89248 examples to avoid logging too frequently
skipping logging after 89264 examples to avoid logging too frequently
train stats after 89280 examples: {'rewards_train/chosen': '-3.3643', 'rewards_train/rejected': '-12.561', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.2014', 'logps_train/rejected': '-291.18', 'logps_train/chosen': '-71.512', 'loss/train': '0.11929', 'examples_per_second': '4.1844', 'grad_norm': '17.125', 'counters/examples': 89280, 'counters/updates': 5580}
skipping logging after 89296 examples to avoid logging too frequently
skipping logging after 89312 examples to avoid logging too frequently
skipping logging after 89328 examples to avoid logging too frequently
train stats after 89344 examples: {'rewards_train/chosen': '-3.3602', 'rewards_train/rejected': '-11.553', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1875', 'logps_train/rejected': '-243.67', 'logps_train/chosen': '-68.218', 'loss/train': '0.14841', 'examples_per_second': '4.4316', 'grad_norm': '15.938', 'counters/examples': 89344, 'counters/updates': 5584}
skipping logging after 89360 examples to avoid logging too frequently
skipping logging after 89376 examples to avoid logging too frequently
skipping logging after 89392 examples to avoid logging too frequently
train stats after 89408 examples: {'rewards_train/chosen': '-3.279', 'rewards_train/rejected': '-11.587', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.3071', 'logps_train/rejected': '-279.52', 'logps_train/chosen': '-72.245', 'loss/train': '0.094401', 'examples_per_second': '5.0152', 'grad_norm': '12.688', 'counters/examples': 89408, 'counters/updates': 5588}
skipping logging after 89424 examples to avoid logging too frequently
skipping logging after 89440 examples to avoid logging too frequently
skipping logging after 89456 examples to avoid logging too frequently
train stats after 89472 examples: {'rewards_train/chosen': '-3.0689', 'rewards_train/rejected': '-12.083', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.0154', 'logps_train/rejected': '-279.37', 'logps_train/chosen': '-67.499', 'loss/train': '0.071545', 'examples_per_second': '4.5629', 'grad_norm': '10.812', 'counters/examples': 89472, 'counters/updates': 5592}
skipping logging after 89488 examples to avoid logging too frequently
skipping logging after 89504 examples to avoid logging too frequently
skipping logging after 89520 examples to avoid logging too frequently
train stats after 89536 examples: {'rewards_train/chosen': '-3.7898', 'rewards_train/rejected': '-12.245', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.4521', 'logps_train/rejected': '-263.72', 'logps_train/chosen': '-75.098', 'loss/train': '0.04635', 'examples_per_second': '5.1275', 'grad_norm': '11.562', 'counters/examples': 89536, 'counters/updates': 5596}
skipping logging after 89552 examples to avoid logging too frequently
skipping logging after 89568 examples to avoid logging too frequently
skipping logging after 89584 examples to avoid logging too frequently
train stats after 89600 examples: {'rewards_train/chosen': '-3.2894', 'rewards_train/rejected': '-12.268', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.9805', 'logps_train/rejected': '-275.62', 'logps_train/chosen': '-74.25', 'loss/train': '0.09715', 'examples_per_second': '4.5375', 'grad_norm': '11', 'counters/examples': 89600, 'counters/updates': 5600}
skipping logging after 89616 examples to avoid logging too frequently
skipping logging after 89632 examples to avoid logging too frequently
skipping logging after 89648 examples to avoid logging too frequently
train stats after 89664 examples: {'rewards_train/chosen': '-3.2955', 'rewards_train/rejected': '-12.654', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.3601', 'logps_train/rejected': '-279.94', 'logps_train/chosen': '-74.602', 'loss/train': '0.050295', 'examples_per_second': '4.0687', 'grad_norm': '7.9688', 'counters/examples': 89664, 'counters/updates': 5604}
skipping logging after 89680 examples to avoid logging too frequently
skipping logging after 89696 examples to avoid logging too frequently
skipping logging after 89712 examples to avoid logging too frequently
train stats after 89728 examples: {'rewards_train/chosen': '-3.4101', 'rewards_train/rejected': '-12.863', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.4539', 'logps_train/rejected': '-275.78', 'logps_train/chosen': '-84.678', 'loss/train': '0.041374', 'examples_per_second': '4.3018', 'grad_norm': '9.3125', 'counters/examples': 89728, 'counters/updates': 5608}
skipping logging after 89744 examples to avoid logging too frequently
skipping logging after 89760 examples to avoid logging too frequently
skipping logging after 89776 examples to avoid logging too frequently
train stats after 89792 examples: {'rewards_train/chosen': '-3.3688', 'rewards_train/rejected': '-11.96', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.5906', 'logps_train/rejected': '-268.73', 'logps_train/chosen': '-71.203', 'loss/train': '0.074623', 'examples_per_second': '4.1896', 'grad_norm': '10.188', 'counters/examples': 89792, 'counters/updates': 5612}
skipping logging after 89808 examples to avoid logging too frequently
skipping logging after 89824 examples to avoid logging too frequently
skipping logging after 89840 examples to avoid logging too frequently
train stats after 89856 examples: {'rewards_train/chosen': '-4.0327', 'rewards_train/rejected': '-11.739', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.7058', 'logps_train/rejected': '-248.08', 'logps_train/chosen': '-81.971', 'loss/train': '0.10965', 'examples_per_second': '6.0147', 'grad_norm': '12.188', 'counters/examples': 89856, 'counters/updates': 5616}
skipping logging after 89872 examples to avoid logging too frequently
skipping logging after 89888 examples to avoid logging too frequently
skipping logging after 89904 examples to avoid logging too frequently
train stats after 89920 examples: {'rewards_train/chosen': '-3.3296', 'rewards_train/rejected': '-12.359', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '9.0303', 'logps_train/rejected': '-274.84', 'logps_train/chosen': '-74.998', 'loss/train': '0.089407', 'examples_per_second': '5.2442', 'grad_norm': '9.3125', 'counters/examples': 89920, 'counters/updates': 5620}
skipping logging after 89936 examples to avoid logging too frequently
skipping logging after 89952 examples to avoid logging too frequently
skipping logging after 89968 examples to avoid logging too frequently
train stats after 89984 examples: {'rewards_train/chosen': '-3.5798', 'rewards_train/rejected': '-12.266', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.6919', 'logps_train/rejected': '-265.08', 'logps_train/chosen': '-71.16', 'loss/train': '0.052107', 'examples_per_second': '4.3807', 'grad_norm': '11.938', 'counters/examples': 89984, 'counters/updates': 5624}
skipping logging after 90000 examples to avoid logging too frequently
skipping logging after 90016 examples to avoid logging too frequently
skipping logging after 90032 examples to avoid logging too frequently
train stats after 90048 examples: {'rewards_train/chosen': '-3.1371', 'rewards_train/rejected': '-11.111', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.9724', 'logps_train/rejected': '-226.6', 'logps_train/chosen': '-76.531', 'loss/train': '0.096877', 'examples_per_second': '4.7369', 'grad_norm': '14.125', 'counters/examples': 90048, 'counters/updates': 5628}
skipping logging after 90064 examples to avoid logging too frequently
skipping logging after 90080 examples to avoid logging too frequently
skipping logging after 90096 examples to avoid logging too frequently
train stats after 90112 examples: {'rewards_train/chosen': '-2.9673', 'rewards_train/rejected': '-10.632', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.6661', 'logps_train/rejected': '-231.73', 'logps_train/chosen': '-59.905', 'loss/train': '0.12799', 'examples_per_second': '6.3178', 'grad_norm': '18.875', 'counters/examples': 90112, 'counters/updates': 5632}
skipping logging after 90128 examples to avoid logging too frequently
skipping logging after 90144 examples to avoid logging too frequently
skipping logging after 90160 examples to avoid logging too frequently
train stats after 90176 examples: {'rewards_train/chosen': '-3.5569', 'rewards_train/rejected': '-12.474', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.9143', 'logps_train/rejected': '-273.89', 'logps_train/chosen': '-85.588', 'loss/train': '0.06143', 'examples_per_second': '4.9886', 'grad_norm': '7.5312', 'counters/examples': 90176, 'counters/updates': 5636}
skipping logging after 90192 examples to avoid logging too frequently
skipping logging after 90208 examples to avoid logging too frequently
skipping logging after 90224 examples to avoid logging too frequently
train stats after 90240 examples: {'rewards_train/chosen': '-3.7435', 'rewards_train/rejected': '-12.468', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.7207', 'logps_train/rejected': '-261.54', 'logps_train/chosen': '-77.646', 'loss/train': '0.023216', 'examples_per_second': '5.5796', 'grad_norm': '3.9375', 'counters/examples': 90240, 'counters/updates': 5640}
skipping logging after 90256 examples to avoid logging too frequently
skipping logging after 90272 examples to avoid logging too frequently
skipping logging after 90288 examples to avoid logging too frequently
train stats after 90304 examples: {'rewards_train/chosen': '-3.9443', 'rewards_train/rejected': '-12.091', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.1487', 'logps_train/rejected': '-232.34', 'logps_train/chosen': '-79.381', 'loss/train': '0.09044', 'examples_per_second': '4.9516', 'grad_norm': '11.25', 'counters/examples': 90304, 'counters/updates': 5644}
skipping logging after 90320 examples to avoid logging too frequently
skipping logging after 90336 examples to avoid logging too frequently
skipping logging after 90352 examples to avoid logging too frequently
train stats after 90368 examples: {'rewards_train/chosen': '-3.9529', 'rewards_train/rejected': '-13.514', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.562', 'logps_train/rejected': '-278.35', 'logps_train/chosen': '-81.568', 'loss/train': '0.082345', 'examples_per_second': '4.5847', 'grad_norm': '12.938', 'counters/examples': 90368, 'counters/updates': 5648}
skipping logging after 90384 examples to avoid logging too frequently
skipping logging after 90400 examples to avoid logging too frequently
skipping logging after 90416 examples to avoid logging too frequently
train stats after 90432 examples: {'rewards_train/chosen': '-4.0996', 'rewards_train/rejected': '-12.833', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.7378', 'logps_train/rejected': '-258.16', 'logps_train/chosen': '-80.928', 'loss/train': '0.24466', 'examples_per_second': '4.4645', 'grad_norm': '25.875', 'counters/examples': 90432, 'counters/updates': 5652}
skipping logging after 90448 examples to avoid logging too frequently
skipping logging after 90464 examples to avoid logging too frequently
skipping logging after 90480 examples to avoid logging too frequently
train stats after 90496 examples: {'rewards_train/chosen': '-3.6471', 'rewards_train/rejected': '-14.077', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '10.429', 'logps_train/rejected': '-302.47', 'logps_train/chosen': '-80.105', 'loss/train': '0.05796', 'examples_per_second': '4.9168', 'grad_norm': '10.875', 'counters/examples': 90496, 'counters/updates': 5656}
skipping logging after 90512 examples to avoid logging too frequently
skipping logging after 90528 examples to avoid logging too frequently
skipping logging after 90544 examples to avoid logging too frequently
train stats after 90560 examples: {'rewards_train/chosen': '-3.3771', 'rewards_train/rejected': '-11.072', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.6936', 'logps_train/rejected': '-247.3', 'logps_train/chosen': '-75.748', 'loss/train': '0.068138', 'examples_per_second': '5.4782', 'grad_norm': '8.5625', 'counters/examples': 90560, 'counters/updates': 5660}
skipping logging after 90576 examples to avoid logging too frequently
skipping logging after 90592 examples to avoid logging too frequently
skipping logging after 90608 examples to avoid logging too frequently
train stats after 90624 examples: {'rewards_train/chosen': '-2.8181', 'rewards_train/rejected': '-11.227', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.406', 'logps_train/rejected': '-272.02', 'logps_train/chosen': '-73.577', 'loss/train': '0.21663', 'examples_per_second': '4.3085', 'grad_norm': '23.375', 'counters/examples': 90624, 'counters/updates': 5664}
skipping logging after 90640 examples to avoid logging too frequently
skipping logging after 90656 examples to avoid logging too frequently
skipping logging after 90672 examples to avoid logging too frequently
train stats after 90688 examples: {'rewards_train/chosen': '-3.1721', 'rewards_train/rejected': '-10.603', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.4331', 'logps_train/rejected': '-228.36', 'logps_train/chosen': '-75.148', 'loss/train': '0.030554', 'examples_per_second': '5.2257', 'grad_norm': '5.3438', 'counters/examples': 90688, 'counters/updates': 5668}
skipping logging after 90704 examples to avoid logging too frequently
skipping logging after 90720 examples to avoid logging too frequently
skipping logging after 90736 examples to avoid logging too frequently
train stats after 90752 examples: {'rewards_train/chosen': '-2.6258', 'rewards_train/rejected': '-12.392', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.7683', 'logps_train/rejected': '-285.53', 'logps_train/chosen': '-63.783', 'loss/train': '0.049584', 'examples_per_second': '6.0468', 'grad_norm': '4.4688', 'counters/examples': 90752, 'counters/updates': 5672}
skipping logging after 90768 examples to avoid logging too frequently
skipping logging after 90784 examples to avoid logging too frequently
skipping logging after 90800 examples to avoid logging too frequently
train stats after 90816 examples: {'rewards_train/chosen': '-3.2466', 'rewards_train/rejected': '-11.75', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.5028', 'logps_train/rejected': '-266.71', 'logps_train/chosen': '-76.098', 'loss/train': '0.038843', 'examples_per_second': '4.7831', 'grad_norm': '6.6875', 'counters/examples': 90816, 'counters/updates': 5676}
skipping logging after 90832 examples to avoid logging too frequently
skipping logging after 90848 examples to avoid logging too frequently
skipping logging after 90864 examples to avoid logging too frequently
train stats after 90880 examples: {'rewards_train/chosen': '-3.2489', 'rewards_train/rejected': '-11.83', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.5806', 'logps_train/rejected': '-271.79', 'logps_train/chosen': '-73.502', 'loss/train': '0.10565', 'examples_per_second': '4.3997', 'grad_norm': '9.625', 'counters/examples': 90880, 'counters/updates': 5680}
skipping logging after 90896 examples to avoid logging too frequently
skipping logging after 90912 examples to avoid logging too frequently
skipping logging after 90928 examples to avoid logging too frequently
train stats after 90944 examples: {'rewards_train/chosen': '-3.4132', 'rewards_train/rejected': '-10.176', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.7656', 'logps_train/rejected': '-231.45', 'logps_train/chosen': '-83.614', 'loss/train': '0.2099', 'examples_per_second': '6.1144', 'grad_norm': '22.375', 'counters/examples': 90944, 'counters/updates': 5684}
skipping logging after 90960 examples to avoid logging too frequently
skipping logging after 90976 examples to avoid logging too frequently
skipping logging after 90992 examples to avoid logging too frequently
train stats after 91008 examples: {'rewards_train/chosen': '-3.1524', 'rewards_train/rejected': '-10.891', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.7397', 'logps_train/rejected': '-248.42', 'logps_train/chosen': '-81.91', 'loss/train': '0.08199', 'examples_per_second': '4.2235', 'grad_norm': '14.688', 'counters/examples': 91008, 'counters/updates': 5688}
skipping logging after 91024 examples to avoid logging too frequently
skipping logging after 91040 examples to avoid logging too frequently
skipping logging after 91056 examples to avoid logging too frequently
train stats after 91072 examples: {'rewards_train/chosen': '-3.0001', 'rewards_train/rejected': '-10.633', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.6294', 'logps_train/rejected': '-258.78', 'logps_train/chosen': '-76.912', 'loss/train': '0.048016', 'examples_per_second': '5.4006', 'grad_norm': '9.5', 'counters/examples': 91072, 'counters/updates': 5692}
skipping logging after 91088 examples to avoid logging too frequently
skipping logging after 91104 examples to avoid logging too frequently
skipping logging after 91120 examples to avoid logging too frequently
train stats after 91136 examples: {'rewards_train/chosen': '-3.1966', 'rewards_train/rejected': '-13.266', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '10.07', 'logps_train/rejected': '-305.32', 'logps_train/chosen': '-76.718', 'loss/train': '0.035261', 'examples_per_second': '4.261', 'grad_norm': '4.5', 'counters/examples': 91136, 'counters/updates': 5696}
skipping logging after 91152 examples to avoid logging too frequently
skipping logging after 91168 examples to avoid logging too frequently
skipping logging after 91184 examples to avoid logging too frequently
train stats after 91200 examples: {'rewards_train/chosen': '-3.5754', 'rewards_train/rejected': '-12.156', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.5803', 'logps_train/rejected': '-266.73', 'logps_train/chosen': '-81.592', 'loss/train': '0.069708', 'examples_per_second': '4.5246', 'grad_norm': '8.9375', 'counters/examples': 91200, 'counters/updates': 5700}
skipping logging after 91216 examples to avoid logging too frequently
skipping logging after 91232 examples to avoid logging too frequently
skipping logging after 91248 examples to avoid logging too frequently
train stats after 91264 examples: {'rewards_train/chosen': '-3.4408', 'rewards_train/rejected': '-15.216', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '11.777', 'logps_train/rejected': '-370.52', 'logps_train/chosen': '-86.311', 'loss/train': '0.040876', 'examples_per_second': '4.2627', 'grad_norm': '18', 'counters/examples': 91264, 'counters/updates': 5704}
skipping logging after 91280 examples to avoid logging too frequently
skipping logging after 91296 examples to avoid logging too frequently
skipping logging after 91312 examples to avoid logging too frequently
train stats after 91328 examples: {'rewards_train/chosen': '-3.2523', 'rewards_train/rejected': '-11.669', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.4182', 'logps_train/rejected': '-257.59', 'logps_train/chosen': '-72.607', 'loss/train': '0.054804', 'examples_per_second': '4.7482', 'grad_norm': '7.6562', 'counters/examples': 91328, 'counters/updates': 5708}
skipping logging after 91344 examples to avoid logging too frequently
skipping logging after 91360 examples to avoid logging too frequently
skipping logging after 91376 examples to avoid logging too frequently
train stats after 91392 examples: {'rewards_train/chosen': '-3.6807', 'rewards_train/rejected': '-12.571', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.8926', 'logps_train/rejected': '-279.54', 'logps_train/chosen': '-77.247', 'loss/train': '0.037849', 'examples_per_second': '5.8276', 'grad_norm': '5.8125', 'counters/examples': 91392, 'counters/updates': 5712}
skipping logging after 91408 examples to avoid logging too frequently
skipping logging after 91424 examples to avoid logging too frequently
skipping logging after 91440 examples to avoid logging too frequently
train stats after 91456 examples: {'rewards_train/chosen': '-3.5353', 'rewards_train/rejected': '-11.977', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.4419', 'logps_train/rejected': '-241.38', 'logps_train/chosen': '-76.6', 'loss/train': '0.029797', 'examples_per_second': '5.5037', 'grad_norm': '6.3125', 'counters/examples': 91456, 'counters/updates': 5716}
skipping logging after 91472 examples to avoid logging too frequently
skipping logging after 91488 examples to avoid logging too frequently
skipping logging after 91504 examples to avoid logging too frequently
train stats after 91520 examples: {'rewards_train/chosen': '-3.2986', 'rewards_train/rejected': '-11.483', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1816', 'logps_train/rejected': '-253.39', 'logps_train/chosen': '-75.855', 'loss/train': '0.099575', 'examples_per_second': '4.9432', 'grad_norm': '13.812', 'counters/examples': 91520, 'counters/updates': 5720}
skipping logging after 91536 examples to avoid logging too frequently
skipping logging after 91552 examples to avoid logging too frequently
skipping logging after 91568 examples to avoid logging too frequently
train stats after 91584 examples: {'rewards_train/chosen': '-3.0427', 'rewards_train/rejected': '-12.309', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.2607', 'logps_train/rejected': '-270.02', 'logps_train/chosen': '-67.518', 'loss/train': '0.067238', 'examples_per_second': '5.4894', 'grad_norm': '8.0625', 'counters/examples': 91584, 'counters/updates': 5724}
skipping logging after 91600 examples to avoid logging too frequently
skipping logging after 91616 examples to avoid logging too frequently
skipping logging after 91632 examples to avoid logging too frequently
train stats after 91648 examples: {'rewards_train/chosen': '-2.8813', 'rewards_train/rejected': '-11.79', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.9116', 'logps_train/rejected': '-267.3', 'logps_train/chosen': '-73.511', 'loss/train': '0.022567', 'examples_per_second': '5.3227', 'grad_norm': '4', 'counters/examples': 91648, 'counters/updates': 5728}
skipping logging after 91664 examples to avoid logging too frequently
skipping logging after 91680 examples to avoid logging too frequently
skipping logging after 91696 examples to avoid logging too frequently
train stats after 91712 examples: {'rewards_train/chosen': '-3.2046', 'rewards_train/rejected': '-11.367', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.1608', 'logps_train/rejected': '-248.55', 'logps_train/chosen': '-72.244', 'loss/train': '0.033066', 'examples_per_second': '5.15', 'grad_norm': '7.3125', 'counters/examples': 91712, 'counters/updates': 5732}
skipping logging after 91728 examples to avoid logging too frequently
skipping logging after 91744 examples to avoid logging too frequently
skipping logging after 91760 examples to avoid logging too frequently
train stats after 91776 examples: {'rewards_train/chosen': '-3.2306', 'rewards_train/rejected': '-11.739', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.5093', 'logps_train/rejected': '-273.75', 'logps_train/chosen': '-83.693', 'loss/train': '0.064295', 'examples_per_second': '5.5463', 'grad_norm': '12.562', 'counters/examples': 91776, 'counters/updates': 5736}
skipping logging after 91792 examples to avoid logging too frequently
skipping logging after 91808 examples to avoid logging too frequently
skipping logging after 91824 examples to avoid logging too frequently
train stats after 91840 examples: {'rewards_train/chosen': '-3.7878', 'rewards_train/rejected': '-13.15', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.365', 'logps_train/rejected': '-267.62', 'logps_train/chosen': '-79.242', 'loss/train': '0.09615', 'examples_per_second': '4.4418', 'grad_norm': '20.625', 'counters/examples': 91840, 'counters/updates': 5740}
skipping logging after 91856 examples to avoid logging too frequently
skipping logging after 91872 examples to avoid logging too frequently
skipping logging after 91888 examples to avoid logging too frequently
train stats after 91904 examples: {'rewards_train/chosen': '-3.4926', 'rewards_train/rejected': '-12.223', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.731', 'logps_train/rejected': '-265.25', 'logps_train/chosen': '-74.111', 'loss/train': '0.08656', 'examples_per_second': '4.8069', 'grad_norm': '10.938', 'counters/examples': 91904, 'counters/updates': 5744}
skipping logging after 91920 examples to avoid logging too frequently
skipping logging after 91936 examples to avoid logging too frequently
skipping logging after 91952 examples to avoid logging too frequently
train stats after 91968 examples: {'rewards_train/chosen': '-3.3135', 'rewards_train/rejected': '-11.93', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.6158', 'logps_train/rejected': '-264.73', 'logps_train/chosen': '-73.029', 'loss/train': '0.065332', 'examples_per_second': '4.552', 'grad_norm': '10.125', 'counters/examples': 91968, 'counters/updates': 5748}
skipping logging after 91984 examples to avoid logging too frequently
skipping logging after 92000 examples to avoid logging too frequently
Running evaluation after 92000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:08,  2.20s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:03,  2.12s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:55,  1.90s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.89s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.55s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.66s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.49s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:36,  1.57s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.50s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:22,  1.30s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.24s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.33s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.34s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.27s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:33<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.30s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.26s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:37<00:07,  1.30s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.48s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.41s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.62s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.42s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.42s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.44s/it]
eval after 92000: {'rewards_eval/chosen': '-11.89', 'rewards_eval/rejected': '-12.411', 'rewards_eval/accuracies': '0.54102', 'rewards_eval/margins': '0.52139', 'logps_eval/rejected': '-271.79', 'logps_eval/chosen': '-263.82', 'loss/eval': '2.0721'}
skipping logging after 92016 examples to avoid logging too frequently
train stats after 92032 examples: {'rewards_train/chosen': '-3.2309', 'rewards_train/rejected': '-11.41', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.179', 'logps_train/rejected': '-222.75', 'logps_train/chosen': '-67.469', 'loss/train': '0.089307', 'examples_per_second': '6.8591', 'grad_norm': '12.438', 'counters/examples': 92032, 'counters/updates': 5752}
skipping logging after 92048 examples to avoid logging too frequently
skipping logging after 92064 examples to avoid logging too frequently
skipping logging after 92080 examples to avoid logging too frequently
train stats after 92096 examples: {'rewards_train/chosen': '-4.2062', 'rewards_train/rejected': '-12.298', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.0925', 'logps_train/rejected': '-241.34', 'logps_train/chosen': '-77.879', 'loss/train': '0.10494', 'examples_per_second': '5.4201', 'grad_norm': '14.812', 'counters/examples': 92096, 'counters/updates': 5756}
skipping logging after 92112 examples to avoid logging too frequently
skipping logging after 92128 examples to avoid logging too frequently
skipping logging after 92144 examples to avoid logging too frequently
train stats after 92160 examples: {'rewards_train/chosen': '-4.0218', 'rewards_train/rejected': '-14.065', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '10.038', 'logps_train/rejected': '-303.24', 'logps_train/chosen': '-85.16', 'loss/train': '0.079408', 'examples_per_second': '6.3913', 'grad_norm': '8.625', 'counters/examples': 92160, 'counters/updates': 5760}
skipping logging after 92176 examples to avoid logging too frequently
skipping logging after 92192 examples to avoid logging too frequently
skipping logging after 92208 examples to avoid logging too frequently
train stats after 92224 examples: {'rewards_train/chosen': '-3.9321', 'rewards_train/rejected': '-13.917', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.9854', 'logps_train/rejected': '-281.5', 'logps_train/chosen': '-76.66', 'loss/train': '0.13705', 'examples_per_second': '5.2979', 'grad_norm': '14.438', 'counters/examples': 92224, 'counters/updates': 5764}
skipping logging after 92240 examples to avoid logging too frequently
skipping logging after 92256 examples to avoid logging too frequently
skipping logging after 92272 examples to avoid logging too frequently
train stats after 92288 examples: {'rewards_train/chosen': '-3.4695', 'rewards_train/rejected': '-11.939', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.4719', 'logps_train/rejected': '-247.7', 'logps_train/chosen': '-66.607', 'loss/train': '0.069951', 'examples_per_second': '4.6987', 'grad_norm': '10.75', 'counters/examples': 92288, 'counters/updates': 5768}
skipping logging after 92304 examples to avoid logging too frequently
skipping logging after 92320 examples to avoid logging too frequently
skipping logging after 92336 examples to avoid logging too frequently
train stats after 92352 examples: {'rewards_train/chosen': '-4.0243', 'rewards_train/rejected': '-12.611', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.5852', 'logps_train/rejected': '-254.6', 'logps_train/chosen': '-76.504', 'loss/train': '0.054257', 'examples_per_second': '5.3403', 'grad_norm': '9', 'counters/examples': 92352, 'counters/updates': 5772}
skipping logging after 92368 examples to avoid logging too frequently
skipping logging after 92384 examples to avoid logging too frequently
skipping logging after 92400 examples to avoid logging too frequently
train stats after 92416 examples: {'rewards_train/chosen': '-3.5236', 'rewards_train/rejected': '-12.038', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.5166', 'logps_train/rejected': '-271.48', 'logps_train/chosen': '-74.632', 'loss/train': '0.085183', 'examples_per_second': '4.2707', 'grad_norm': '16.625', 'counters/examples': 92416, 'counters/updates': 5776}
skipping logging after 92432 examples to avoid logging too frequently
skipping logging after 92448 examples to avoid logging too frequently
skipping logging after 92464 examples to avoid logging too frequently
train stats after 92480 examples: {'rewards_train/chosen': '-3.2796', 'rewards_train/rejected': '-12.913', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.6321', 'logps_train/rejected': '-286.19', 'logps_train/chosen': '-70.278', 'loss/train': '0.10673', 'examples_per_second': '4.6851', 'grad_norm': '8.9375', 'counters/examples': 92480, 'counters/updates': 5780}
skipping logging after 92496 examples to avoid logging too frequently
skipping logging after 92512 examples to avoid logging too frequently
skipping logging after 92528 examples to avoid logging too frequently
train stats after 92544 examples: {'rewards_train/chosen': '-3.1784', 'rewards_train/rejected': '-11.474', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.2908', 'logps_train/rejected': '-239.61', 'logps_train/chosen': '-66.866', 'loss/train': '0.072154', 'examples_per_second': '4.6469', 'grad_norm': '7', 'counters/examples': 92544, 'counters/updates': 5784}
skipping logging after 92560 examples to avoid logging too frequently
skipping logging after 92576 examples to avoid logging too frequently
skipping logging after 92592 examples to avoid logging too frequently
train stats after 92608 examples: {'rewards_train/chosen': '-3.5907', 'rewards_train/rejected': '-14.007', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '10.414', 'logps_train/rejected': '-304.99', 'logps_train/chosen': '-82.02', 'loss/train': '0.018882', 'examples_per_second': '4.3371', 'grad_norm': '2.75', 'counters/examples': 92608, 'counters/updates': 5788}
skipping logging after 92624 examples to avoid logging too frequently
skipping logging after 92640 examples to avoid logging too frequently
skipping logging after 92656 examples to avoid logging too frequently
train stats after 92672 examples: {'rewards_train/chosen': '-4.0021', 'rewards_train/rejected': '-11.199', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.1982', 'logps_train/rejected': '-242.7', 'logps_train/chosen': '-75.719', 'loss/train': '0.15477', 'examples_per_second': '3.9663', 'grad_norm': '28', 'counters/examples': 92672, 'counters/updates': 5792}
skipping logging after 92688 examples to avoid logging too frequently
skipping logging after 92704 examples to avoid logging too frequently
skipping logging after 92720 examples to avoid logging too frequently
train stats after 92736 examples: {'rewards_train/chosen': '-3.615', 'rewards_train/rejected': '-11.81', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.1919', 'logps_train/rejected': '-277.49', 'logps_train/chosen': '-81.098', 'loss/train': '0.09055', 'examples_per_second': '5.8314', 'grad_norm': '7.9688', 'counters/examples': 92736, 'counters/updates': 5796}
skipping logging after 92752 examples to avoid logging too frequently
skipping logging after 92768 examples to avoid logging too frequently
skipping logging after 92784 examples to avoid logging too frequently
train stats after 92800 examples: {'rewards_train/chosen': '-3.2022', 'rewards_train/rejected': '-12.394', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.1912', 'logps_train/rejected': '-255.57', 'logps_train/chosen': '-68.588', 'loss/train': '0.02096', 'examples_per_second': '5.3927', 'grad_norm': '4.25', 'counters/examples': 92800, 'counters/updates': 5800}
skipping logging after 92816 examples to avoid logging too frequently
skipping logging after 92832 examples to avoid logging too frequently
skipping logging after 92848 examples to avoid logging too frequently
train stats after 92864 examples: {'rewards_train/chosen': '-3.5243', 'rewards_train/rejected': '-12.118', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.5952', 'logps_train/rejected': '-259.74', 'logps_train/chosen': '-72.307', 'loss/train': '0.080465', 'examples_per_second': '5.0671', 'grad_norm': '15.188', 'counters/examples': 92864, 'counters/updates': 5804}
skipping logging after 92880 examples to avoid logging too frequently
skipping logging after 92896 examples to avoid logging too frequently
skipping logging after 92912 examples to avoid logging too frequently
train stats after 92928 examples: {'rewards_train/chosen': '-3.732', 'rewards_train/rejected': '-10.866', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.1357', 'logps_train/rejected': '-221.04', 'logps_train/chosen': '-74.293', 'loss/train': '0.14272', 'examples_per_second': '4.491', 'grad_norm': '13.125', 'counters/examples': 92928, 'counters/updates': 5808}
skipping logging after 92944 examples to avoid logging too frequently
skipping logging after 92960 examples to avoid logging too frequently
skipping logging after 92976 examples to avoid logging too frequently
train stats after 92992 examples: {'rewards_train/chosen': '-3.6265', 'rewards_train/rejected': '-11.502', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.8728', 'logps_train/rejected': '-263.31', 'logps_train/chosen': '-81.543', 'loss/train': '0.073052', 'examples_per_second': '5.0838', 'grad_norm': '7.25', 'counters/examples': 92992, 'counters/updates': 5812}
skipping logging after 93008 examples to avoid logging too frequently
skipping logging after 93024 examples to avoid logging too frequently
skipping logging after 93040 examples to avoid logging too frequently
train stats after 93056 examples: {'rewards_train/chosen': '-3.6219', 'rewards_train/rejected': '-11.045', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.4241', 'logps_train/rejected': '-231.78', 'logps_train/chosen': '-80.029', 'loss/train': '0.12011', 'examples_per_second': '5.4566', 'grad_norm': '16.875', 'counters/examples': 93056, 'counters/updates': 5816}
skipping logging after 93072 examples to avoid logging too frequently
skipping logging after 93088 examples to avoid logging too frequently
skipping logging after 93104 examples to avoid logging too frequently
train stats after 93120 examples: {'rewards_train/chosen': '-3.3307', 'rewards_train/rejected': '-11.35', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.0139', 'logps_train/rejected': '-244.88', 'logps_train/chosen': '-81.018', 'loss/train': '0.083558', 'examples_per_second': '4.9483', 'grad_norm': '14.938', 'counters/examples': 93120, 'counters/updates': 5820}
skipping logging after 93136 examples to avoid logging too frequently
skipping logging after 93152 examples to avoid logging too frequently
skipping logging after 93168 examples to avoid logging too frequently
train stats after 93184 examples: {'rewards_train/chosen': '-3.481', 'rewards_train/rejected': '-12.494', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.0146', 'logps_train/rejected': '-266.69', 'logps_train/chosen': '-78.365', 'loss/train': '0.052935', 'examples_per_second': '5.4628', 'grad_norm': '8.4375', 'counters/examples': 93184, 'counters/updates': 5824}
skipping logging after 93200 examples to avoid logging too frequently
skipping logging after 93216 examples to avoid logging too frequently
skipping logging after 93232 examples to avoid logging too frequently
train stats after 93248 examples: {'rewards_train/chosen': '-3.5168', 'rewards_train/rejected': '-14.151', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '10.628', 'logps_train/rejected': '-290.91', 'logps_train/chosen': '-92.301', 'loss/train': '0.038361', 'examples_per_second': '3.9702', 'grad_norm': '5.5938', 'counters/examples': 93248, 'counters/updates': 5828}
skipping logging after 93264 examples to avoid logging too frequently
skipping logging after 93280 examples to avoid logging too frequently
skipping logging after 93296 examples to avoid logging too frequently
train stats after 93312 examples: {'rewards_train/chosen': '-3.9629', 'rewards_train/rejected': '-11.582', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.6218', 'logps_train/rejected': '-237.68', 'logps_train/chosen': '-78.498', 'loss/train': '0.064649', 'examples_per_second': '4.8731', 'grad_norm': '10.188', 'counters/examples': 93312, 'counters/updates': 5832}
skipping logging after 93328 examples to avoid logging too frequently
skipping logging after 93344 examples to avoid logging too frequently
skipping logging after 93360 examples to avoid logging too frequently
train stats after 93376 examples: {'rewards_train/chosen': '-3.3578', 'rewards_train/rejected': '-11.783', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.4281', 'logps_train/rejected': '-246.68', 'logps_train/chosen': '-72.77', 'loss/train': '0.068929', 'examples_per_second': '5.849', 'grad_norm': '11.938', 'counters/examples': 93376, 'counters/updates': 5836}
skipping logging after 93392 examples to avoid logging too frequently
skipping logging after 93408 examples to avoid logging too frequently
skipping logging after 93424 examples to avoid logging too frequently
train stats after 93440 examples: {'rewards_train/chosen': '-3.5523', 'rewards_train/rejected': '-12.294', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.7397', 'logps_train/rejected': '-262.89', 'logps_train/chosen': '-72.104', 'loss/train': '0.034819', 'examples_per_second': '4.8131', 'grad_norm': '2.8906', 'counters/examples': 93440, 'counters/updates': 5840}
skipping logging after 93456 examples to avoid logging too frequently
skipping logging after 93472 examples to avoid logging too frequently
skipping logging after 93488 examples to avoid logging too frequently
train stats after 93504 examples: {'rewards_train/chosen': '-3.6612', 'rewards_train/rejected': '-13.817', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '10.156', 'logps_train/rejected': '-305.4', 'logps_train/chosen': '-80.094', 'loss/train': '0.052911', 'examples_per_second': '4.714', 'grad_norm': '11.688', 'counters/examples': 93504, 'counters/updates': 5844}
skipping logging after 93520 examples to avoid logging too frequently
skipping logging after 93536 examples to avoid logging too frequently
skipping logging after 93552 examples to avoid logging too frequently
train stats after 93568 examples: {'rewards_train/chosen': '-3.6839', 'rewards_train/rejected': '-13.102', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.4146', 'logps_train/rejected': '-288.93', 'logps_train/chosen': '-72.475', 'loss/train': '0.045181', 'examples_per_second': '6.2132', 'grad_norm': '10.938', 'counters/examples': 93568, 'counters/updates': 5848}
skipping logging after 93584 examples to avoid logging too frequently
skipping logging after 93600 examples to avoid logging too frequently
skipping logging after 93616 examples to avoid logging too frequently
train stats after 93632 examples: {'rewards_train/chosen': '-3.8588', 'rewards_train/rejected': '-12.382', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.5237', 'logps_train/rejected': '-253.18', 'logps_train/chosen': '-81.662', 'loss/train': '0.062622', 'examples_per_second': '6.9959', 'grad_norm': '11', 'counters/examples': 93632, 'counters/updates': 5852}
skipping logging after 93648 examples to avoid logging too frequently
skipping logging after 93664 examples to avoid logging too frequently
skipping logging after 93680 examples to avoid logging too frequently
train stats after 93696 examples: {'rewards_train/chosen': '-3.8185', 'rewards_train/rejected': '-12.356', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.5403', 'logps_train/rejected': '-268.92', 'logps_train/chosen': '-76.698', 'loss/train': '0.081218', 'examples_per_second': '4.7457', 'grad_norm': '5.4062', 'counters/examples': 93696, 'counters/updates': 5856}
skipping logging after 93712 examples to avoid logging too frequently
skipping logging after 93728 examples to avoid logging too frequently
skipping logging after 93744 examples to avoid logging too frequently
train stats after 93760 examples: {'rewards_train/chosen': '-4.0159', 'rewards_train/rejected': '-14.295', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '10.284', 'logps_train/rejected': '-316.58', 'logps_train/chosen': '-81.074', 'loss/train': '0.087178', 'examples_per_second': '5.4757', 'grad_norm': '12.062', 'counters/examples': 93760, 'counters/updates': 5860}
skipping logging after 93776 examples to avoid logging too frequently
skipping logging after 93792 examples to avoid logging too frequently
skipping logging after 93808 examples to avoid logging too frequently
train stats after 93824 examples: {'rewards_train/chosen': '-3.5205', 'rewards_train/rejected': '-13.023', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.5027', 'logps_train/rejected': '-305.25', 'logps_train/chosen': '-76.325', 'loss/train': '0.037175', 'examples_per_second': '4.4126', 'grad_norm': '6.8438', 'counters/examples': 93824, 'counters/updates': 5864}
skipping logging after 93840 examples to avoid logging too frequently
skipping logging after 93856 examples to avoid logging too frequently
skipping logging after 93872 examples to avoid logging too frequently
train stats after 93888 examples: {'rewards_train/chosen': '-3.8294', 'rewards_train/rejected': '-13.424', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.5933', 'logps_train/rejected': '-295.95', 'logps_train/chosen': '-74.77', 'loss/train': '0.1379', 'examples_per_second': '3.8718', 'grad_norm': '22.125', 'counters/examples': 93888, 'counters/updates': 5868}
skipping logging after 93904 examples to avoid logging too frequently
skipping logging after 93920 examples to avoid logging too frequently
skipping logging after 93936 examples to avoid logging too frequently
train stats after 93952 examples: {'rewards_train/chosen': '-3.2514', 'rewards_train/rejected': '-12.362', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.1088', 'logps_train/rejected': '-283.71', 'logps_train/chosen': '-75.614', 'loss/train': '0.068802', 'examples_per_second': '5.6568', 'grad_norm': '6.4375', 'counters/examples': 93952, 'counters/updates': 5872}
skipping logging after 93968 examples to avoid logging too frequently
skipping logging after 93984 examples to avoid logging too frequently
skipping logging after 94000 examples to avoid logging too frequently
train stats after 94016 examples: {'rewards_train/chosen': '-3.5667', 'rewards_train/rejected': '-12.231', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.6626', 'logps_train/rejected': '-274.16', 'logps_train/chosen': '-83.586', 'loss/train': '0.03398', 'examples_per_second': '4.8253', 'grad_norm': '8.5', 'counters/examples': 94016, 'counters/updates': 5876}
skipping logging after 94032 examples to avoid logging too frequently
skipping logging after 94048 examples to avoid logging too frequently
skipping logging after 94064 examples to avoid logging too frequently
train stats after 94080 examples: {'rewards_train/chosen': '-3.9149', 'rewards_train/rejected': '-10.481', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.5684', 'logps_train/rejected': '-216.19', 'logps_train/chosen': '-80.648', 'loss/train': '0.089625', 'examples_per_second': '5.0079', 'grad_norm': '14.062', 'counters/examples': 94080, 'counters/updates': 5880}
skipping logging after 94096 examples to avoid logging too frequently
skipping logging after 94112 examples to avoid logging too frequently
skipping logging after 94128 examples to avoid logging too frequently
train stats after 94144 examples: {'rewards_train/chosen': '-3.2817', 'rewards_train/rejected': '-11.197', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.9159', 'logps_train/rejected': '-269.07', 'logps_train/chosen': '-83.434', 'loss/train': '0.092315', 'examples_per_second': '5.7679', 'grad_norm': '10.75', 'counters/examples': 94144, 'counters/updates': 5884}
skipping logging after 94160 examples to avoid logging too frequently
skipping logging after 94176 examples to avoid logging too frequently
skipping logging after 94192 examples to avoid logging too frequently
train stats after 94208 examples: {'rewards_train/chosen': '-3.4621', 'rewards_train/rejected': '-11.317', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.8562', 'logps_train/rejected': '-229.74', 'logps_train/chosen': '-73.571', 'loss/train': '0.02762', 'examples_per_second': '6.1222', 'grad_norm': '3.4688', 'counters/examples': 94208, 'counters/updates': 5888}
skipping logging after 94224 examples to avoid logging too frequently
skipping logging after 94240 examples to avoid logging too frequently
skipping logging after 94256 examples to avoid logging too frequently
train stats after 94272 examples: {'rewards_train/chosen': '-3.2724', 'rewards_train/rejected': '-11.152', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.8792', 'logps_train/rejected': '-246.09', 'logps_train/chosen': '-70.225', 'loss/train': '0.099622', 'examples_per_second': '4.6655', 'grad_norm': '11.062', 'counters/examples': 94272, 'counters/updates': 5892}
skipping logging after 94288 examples to avoid logging too frequently
skipping logging after 94304 examples to avoid logging too frequently
skipping logging after 94320 examples to avoid logging too frequently
train stats after 94336 examples: {'rewards_train/chosen': '-3.5509', 'rewards_train/rejected': '-11.517', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.9683', 'logps_train/rejected': '-240.49', 'logps_train/chosen': '-79.729', 'loss/train': '0.069736', 'examples_per_second': '4.6628', 'grad_norm': '12', 'counters/examples': 94336, 'counters/updates': 5896}
skipping logging after 94352 examples to avoid logging too frequently
skipping logging after 94368 examples to avoid logging too frequently
skipping logging after 94384 examples to avoid logging too frequently
train stats after 94400 examples: {'rewards_train/chosen': '-4.6077', 'rewards_train/rejected': '-12.374', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.7684', 'logps_train/rejected': '-245.21', 'logps_train/chosen': '-88.326', 'loss/train': '0.12881', 'examples_per_second': '4.5447', 'grad_norm': '22.375', 'counters/examples': 94400, 'counters/updates': 5900}
skipping logging after 94416 examples to avoid logging too frequently
skipping logging after 94432 examples to avoid logging too frequently
skipping logging after 94448 examples to avoid logging too frequently
train stats after 94464 examples: {'rewards_train/chosen': '-3.0845', 'rewards_train/rejected': '-12.135', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.0496', 'logps_train/rejected': '-233.15', 'logps_train/chosen': '-66.52', 'loss/train': '0.012008', 'examples_per_second': '5.7683', 'grad_norm': '2.6875', 'counters/examples': 94464, 'counters/updates': 5904}
skipping logging after 94480 examples to avoid logging too frequently
skipping logging after 94496 examples to avoid logging too frequently
skipping logging after 94512 examples to avoid logging too frequently
train stats after 94528 examples: {'rewards_train/chosen': '-3.5808', 'rewards_train/rejected': '-14.276', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '10.703', 'logps_train/rejected': '-311.59', 'logps_train/chosen': '-72.858', 'loss/train': '0.098169', 'examples_per_second': '5.7921', 'grad_norm': '8.5', 'counters/examples': 94528, 'counters/updates': 5908}
skipping logging after 94544 examples to avoid logging too frequently
skipping logging after 94560 examples to avoid logging too frequently
skipping logging after 94576 examples to avoid logging too frequently
train stats after 94592 examples: {'rewards_train/chosen': '-4.0524', 'rewards_train/rejected': '-12.085', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.0327', 'logps_train/rejected': '-245.52', 'logps_train/chosen': '-85.709', 'loss/train': '0.047247', 'examples_per_second': '4.0589', 'grad_norm': '5.1562', 'counters/examples': 94592, 'counters/updates': 5912}
skipping logging after 94608 examples to avoid logging too frequently
skipping logging after 94624 examples to avoid logging too frequently
skipping logging after 94640 examples to avoid logging too frequently
train stats after 94656 examples: {'rewards_train/chosen': '-3.7862', 'rewards_train/rejected': '-13.066', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.2805', 'logps_train/rejected': '-301.71', 'logps_train/chosen': '-79.824', 'loss/train': '0.12661', 'examples_per_second': '4.0759', 'grad_norm': '8.5625', 'counters/examples': 94656, 'counters/updates': 5916}
skipping logging after 94672 examples to avoid logging too frequently
skipping logging after 94688 examples to avoid logging too frequently
skipping logging after 94704 examples to avoid logging too frequently
train stats after 94720 examples: {'rewards_train/chosen': '-3.6784', 'rewards_train/rejected': '-14.428', 'rewards_train/accuracies': '1', 'rewards_train/margins': '10.757', 'logps_train/rejected': '-323.04', 'logps_train/chosen': '-75.674', 'loss/train': '0.026694', 'examples_per_second': '5.5515', 'grad_norm': '4.0312', 'counters/examples': 94720, 'counters/updates': 5920}
skipping logging after 94736 examples to avoid logging too frequently
skipping logging after 94752 examples to avoid logging too frequently
skipping logging after 94768 examples to avoid logging too frequently
train stats after 94784 examples: {'rewards_train/chosen': '-4.0432', 'rewards_train/rejected': '-13.302', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.2605', 'logps_train/rejected': '-272.16', 'logps_train/chosen': '-89.375', 'loss/train': '0.023076', 'examples_per_second': '6.0462', 'grad_norm': '4.9375', 'counters/examples': 94784, 'counters/updates': 5924}
skipping logging after 94800 examples to avoid logging too frequently
skipping logging after 94816 examples to avoid logging too frequently
skipping logging after 94832 examples to avoid logging too frequently
train stats after 94848 examples: {'rewards_train/chosen': '-4.142', 'rewards_train/rejected': '-13.289', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.145', 'logps_train/rejected': '-293.46', 'logps_train/chosen': '-77.961', 'loss/train': '0.093843', 'examples_per_second': '5.3476', 'grad_norm': '11.375', 'counters/examples': 94848, 'counters/updates': 5928}
skipping logging after 94864 examples to avoid logging too frequently
skipping logging after 94880 examples to avoid logging too frequently
skipping logging after 94896 examples to avoid logging too frequently
train stats after 94912 examples: {'rewards_train/chosen': '-3.7599', 'rewards_train/rejected': '-12.166', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.4067', 'logps_train/rejected': '-249.08', 'logps_train/chosen': '-78.958', 'loss/train': '0.038441', 'examples_per_second': '4.5332', 'grad_norm': '3.7031', 'counters/examples': 94912, 'counters/updates': 5932}
skipping logging after 94928 examples to avoid logging too frequently
skipping logging after 94944 examples to avoid logging too frequently
skipping logging after 94960 examples to avoid logging too frequently
train stats after 94976 examples: {'rewards_train/chosen': '-3.3286', 'rewards_train/rejected': '-10.631', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.3015', 'logps_train/rejected': '-202.8', 'logps_train/chosen': '-67', 'loss/train': '0.090477', 'examples_per_second': '5.6138', 'grad_norm': '8.8125', 'counters/examples': 94976, 'counters/updates': 5936}
skipping logging after 94992 examples to avoid logging too frequently
skipping logging after 95008 examples to avoid logging too frequently
skipping logging after 95024 examples to avoid logging too frequently
train stats after 95040 examples: {'rewards_train/chosen': '-3.3928', 'rewards_train/rejected': '-12.807', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.4165', 'logps_train/rejected': '-292.3', 'logps_train/chosen': '-79.648', 'loss/train': '0.020476', 'examples_per_second': '6.2482', 'grad_norm': '4.4062', 'counters/examples': 95040, 'counters/updates': 5940}
skipping logging after 95056 examples to avoid logging too frequently
skipping logging after 95072 examples to avoid logging too frequently
skipping logging after 95088 examples to avoid logging too frequently
train stats after 95104 examples: {'rewards_train/chosen': '-3.8739', 'rewards_train/rejected': '-12.335', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.4602', 'logps_train/rejected': '-268.95', 'logps_train/chosen': '-76.619', 'loss/train': '0.094983', 'examples_per_second': '4.8076', 'grad_norm': '9.3125', 'counters/examples': 95104, 'counters/updates': 5944}
skipping logging after 95120 examples to avoid logging too frequently
skipping logging after 95136 examples to avoid logging too frequently
skipping logging after 95152 examples to avoid logging too frequently
train stats after 95168 examples: {'rewards_train/chosen': '-3.855', 'rewards_train/rejected': '-12.55', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.6948', 'logps_train/rejected': '-256.55', 'logps_train/chosen': '-90.461', 'loss/train': '0.10871', 'examples_per_second': '6.6139', 'grad_norm': '16', 'counters/examples': 95168, 'counters/updates': 5948}
skipping logging after 95184 examples to avoid logging too frequently
skipping logging after 95200 examples to avoid logging too frequently
skipping logging after 95216 examples to avoid logging too frequently
train stats after 95232 examples: {'rewards_train/chosen': '-2.9886', 'rewards_train/rejected': '-11.277', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.2896', 'logps_train/rejected': '-255', 'logps_train/chosen': '-72.084', 'loss/train': '0.079481', 'examples_per_second': '4.3341', 'grad_norm': '14.25', 'counters/examples': 95232, 'counters/updates': 5952}
skipping logging after 95248 examples to avoid logging too frequently
skipping logging after 95264 examples to avoid logging too frequently
skipping logging after 95280 examples to avoid logging too frequently
train stats after 95296 examples: {'rewards_train/chosen': '-3.458', 'rewards_train/rejected': '-11.792', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.3367', 'logps_train/rejected': '-263.93', 'logps_train/chosen': '-83.434', 'loss/train': '0.12832', 'examples_per_second': '3.8983', 'grad_norm': '23.25', 'counters/examples': 95296, 'counters/updates': 5956}
skipping logging after 95312 examples to avoid logging too frequently
skipping logging after 95328 examples to avoid logging too frequently
skipping logging after 95344 examples to avoid logging too frequently
train stats after 95360 examples: {'rewards_train/chosen': '-4.0075', 'rewards_train/rejected': '-12.1', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.0959', 'logps_train/rejected': '-244.15', 'logps_train/chosen': '-81.713', 'loss/train': '0.084855', 'examples_per_second': '3.9453', 'grad_norm': '12.312', 'counters/examples': 95360, 'counters/updates': 5960}
skipping logging after 95376 examples to avoid logging too frequently
skipping logging after 95392 examples to avoid logging too frequently
skipping logging after 95408 examples to avoid logging too frequently
train stats after 95424 examples: {'rewards_train/chosen': '-4.0654', 'rewards_train/rejected': '-12.438', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.374', 'logps_train/rejected': '-267.97', 'logps_train/chosen': '-79.386', 'loss/train': '0.097724', 'examples_per_second': '5.4682', 'grad_norm': '15.375', 'counters/examples': 95424, 'counters/updates': 5964}
skipping logging after 95440 examples to avoid logging too frequently
skipping logging after 95456 examples to avoid logging too frequently
skipping logging after 95472 examples to avoid logging too frequently
train stats after 95488 examples: {'rewards_train/chosen': '-3.2969', 'rewards_train/rejected': '-11.292', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.9954', 'logps_train/rejected': '-258.16', 'logps_train/chosen': '-68.693', 'loss/train': '0.10809', 'examples_per_second': '4.8871', 'grad_norm': '12.25', 'counters/examples': 95488, 'counters/updates': 5968}
skipping logging after 95504 examples to avoid logging too frequently
skipping logging after 95520 examples to avoid logging too frequently
skipping logging after 95536 examples to avoid logging too frequently
train stats after 95552 examples: {'rewards_train/chosen': '-3.2685', 'rewards_train/rejected': '-11.832', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.561', 'logps_train/rejected': '-275.57', 'logps_train/chosen': '-69.891', 'loss/train': '0.063611', 'examples_per_second': '4.6408', 'grad_norm': '8.75', 'counters/examples': 95552, 'counters/updates': 5972}
skipping logging after 95568 examples to avoid logging too frequently
skipping logging after 95584 examples to avoid logging too frequently
skipping logging after 95600 examples to avoid logging too frequently
train stats after 95616 examples: {'rewards_train/chosen': '-3.9368', 'rewards_train/rejected': '-10.928', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.9961', 'logps_train/rejected': '-216.91', 'logps_train/chosen': '-71.789', 'loss/train': '0.10821', 'examples_per_second': '4.7057', 'grad_norm': '19.625', 'counters/examples': 95616, 'counters/updates': 5976}
skipping logging after 95632 examples to avoid logging too frequently
skipping logging after 95648 examples to avoid logging too frequently
skipping logging after 95664 examples to avoid logging too frequently
train stats after 95680 examples: {'rewards_train/chosen': '-3.1203', 'rewards_train/rejected': '-11.309', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.1907', 'logps_train/rejected': '-235.52', 'logps_train/chosen': '-70.227', 'loss/train': '0.055943', 'examples_per_second': '4.7262', 'grad_norm': '8.8125', 'counters/examples': 95680, 'counters/updates': 5980}
skipping logging after 95696 examples to avoid logging too frequently
skipping logging after 95712 examples to avoid logging too frequently
skipping logging after 95728 examples to avoid logging too frequently
train stats after 95744 examples: {'rewards_train/chosen': '-3.3438', 'rewards_train/rejected': '-10.205', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.8638', 'logps_train/rejected': '-215.96', 'logps_train/chosen': '-75.391', 'loss/train': '0.12407', 'examples_per_second': '4.9967', 'grad_norm': '18.75', 'counters/examples': 95744, 'counters/updates': 5984}
skipping logging after 95760 examples to avoid logging too frequently
skipping logging after 95776 examples to avoid logging too frequently
skipping logging after 95792 examples to avoid logging too frequently
train stats after 95808 examples: {'rewards_train/chosen': '-3.4366', 'rewards_train/rejected': '-11.117', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.6809', 'logps_train/rejected': '-239.23', 'logps_train/chosen': '-71.408', 'loss/train': '0.049426', 'examples_per_second': '4.1869', 'grad_norm': '7.5938', 'counters/examples': 95808, 'counters/updates': 5988}
skipping logging after 95824 examples to avoid logging too frequently
skipping logging after 95840 examples to avoid logging too frequently
skipping logging after 95856 examples to avoid logging too frequently
train stats after 95872 examples: {'rewards_train/chosen': '-3.6144', 'rewards_train/rejected': '-11.657', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.0437', 'logps_train/rejected': '-244.68', 'logps_train/chosen': '-76.676', 'loss/train': '0.063034', 'examples_per_second': '4.3643', 'grad_norm': '7.9375', 'counters/examples': 95872, 'counters/updates': 5992}
skipping logging after 95888 examples to avoid logging too frequently
skipping logging after 95904 examples to avoid logging too frequently
skipping logging after 95920 examples to avoid logging too frequently
train stats after 95936 examples: {'rewards_train/chosen': '-4.0147', 'rewards_train/rejected': '-11.018', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.002', 'logps_train/rejected': '-217.39', 'logps_train/chosen': '-84.855', 'loss/train': '0.067708', 'examples_per_second': '4.8143', 'grad_norm': '11.438', 'counters/examples': 95936, 'counters/updates': 5996}
skipping logging after 95952 examples to avoid logging too frequently
skipping logging after 95968 examples to avoid logging too frequently
skipping logging after 95984 examples to avoid logging too frequently
train stats after 96000 examples: {'rewards_train/chosen': '-3.4065', 'rewards_train/rejected': '-12.998', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.5923', 'logps_train/rejected': '-312.91', 'logps_train/chosen': '-91.211', 'loss/train': '0.053816', 'examples_per_second': '4.9226', 'grad_norm': '10', 'counters/examples': 96000, 'counters/updates': 6000}
Running evaluation after 96000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<01:00,  1.95s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:00,  2.01s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:53,  1.84s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.86s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.52s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.50s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:22,  1.30s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.24s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.33s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.34s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.27s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.29s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.26s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.30s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.48s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.41s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.61s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.42s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.42s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 96000: {'rewards_eval/chosen': '-13.041', 'rewards_eval/rejected': '-13.646', 'rewards_eval/accuracies': '0.52344', 'rewards_eval/margins': '0.60532', 'logps_eval/rejected': '-284.13', 'logps_eval/chosen': '-275.32', 'loss/eval': '2.3745'}
skipping logging after 96016 examples to avoid logging too frequently
skipping logging after 96032 examples to avoid logging too frequently
skipping logging after 96048 examples to avoid logging too frequently
train stats after 96064 examples: {'rewards_train/chosen': '-4.017', 'rewards_train/rejected': '-14.39', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '10.374', 'logps_train/rejected': '-304.67', 'logps_train/chosen': '-83.477', 'loss/train': '0.09215', 'examples_per_second': '4.6367', 'grad_norm': '14', 'counters/examples': 96064, 'counters/updates': 6004}
skipping logging after 96080 examples to avoid logging too frequently
skipping logging after 96096 examples to avoid logging too frequently
skipping logging after 96112 examples to avoid logging too frequently
train stats after 96128 examples: {'rewards_train/chosen': '-3.5346', 'rewards_train/rejected': '-11.603', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.0679', 'logps_train/rejected': '-236.27', 'logps_train/chosen': '-73.49', 'loss/train': '0.049609', 'examples_per_second': '5.3199', 'grad_norm': '4.2188', 'counters/examples': 96128, 'counters/updates': 6008}
skipping logging after 96144 examples to avoid logging too frequently
skipping logging after 96160 examples to avoid logging too frequently
skipping logging after 96176 examples to avoid logging too frequently
train stats after 96192 examples: {'rewards_train/chosen': '-3.2867', 'rewards_train/rejected': '-11.596', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.3079', 'logps_train/rejected': '-247.63', 'logps_train/chosen': '-73.844', 'loss/train': '0.051364', 'examples_per_second': '5.1084', 'grad_norm': '5.375', 'counters/examples': 96192, 'counters/updates': 6012}
skipping logging after 96208 examples to avoid logging too frequently
skipping logging after 96224 examples to avoid logging too frequently
skipping logging after 96240 examples to avoid logging too frequently
train stats after 96256 examples: {'rewards_train/chosen': '-4.4124', 'rewards_train/rejected': '-12.725', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.3135', 'logps_train/rejected': '-283.73', 'logps_train/chosen': '-93.734', 'loss/train': '0.086941', 'examples_per_second': '5.4211', 'grad_norm': '22', 'counters/examples': 96256, 'counters/updates': 6016}
skipping logging after 96272 examples to avoid logging too frequently
skipping logging after 96288 examples to avoid logging too frequently
skipping logging after 96304 examples to avoid logging too frequently
train stats after 96320 examples: {'rewards_train/chosen': '-3.7939', 'rewards_train/rejected': '-13.39', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.5984', 'logps_train/rejected': '-280.28', 'logps_train/chosen': '-78.446', 'loss/train': '0.042974', 'examples_per_second': '4.9855', 'grad_norm': '7.375', 'counters/examples': 96320, 'counters/updates': 6020}
skipping logging after 96336 examples to avoid logging too frequently
skipping logging after 96352 examples to avoid logging too frequently
skipping logging after 96368 examples to avoid logging too frequently
train stats after 96384 examples: {'rewards_train/chosen': '-4.2799', 'rewards_train/rejected': '-13.268', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.988', 'logps_train/rejected': '-257.77', 'logps_train/chosen': '-82.998', 'loss/train': '0.084722', 'examples_per_second': '5.2429', 'grad_norm': '12.375', 'counters/examples': 96384, 'counters/updates': 6024}
skipping logging after 96400 examples to avoid logging too frequently
skipping logging after 96416 examples to avoid logging too frequently
skipping logging after 96432 examples to avoid logging too frequently
train stats after 96448 examples: {'rewards_train/chosen': '-3.7594', 'rewards_train/rejected': '-12.25', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.4895', 'logps_train/rejected': '-242.36', 'logps_train/chosen': '-81.174', 'loss/train': '0.064189', 'examples_per_second': '4.4577', 'grad_norm': '14.312', 'counters/examples': 96448, 'counters/updates': 6028}
skipping logging after 96464 examples to avoid logging too frequently
skipping logging after 96480 examples to avoid logging too frequently
skipping logging after 96496 examples to avoid logging too frequently
train stats after 96512 examples: {'rewards_train/chosen': '-3.3567', 'rewards_train/rejected': '-11.595', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.2361', 'logps_train/rejected': '-278.56', 'logps_train/chosen': '-73.1', 'loss/train': '0.13902', 'examples_per_second': '5.9272', 'grad_norm': '15.5', 'counters/examples': 96512, 'counters/updates': 6032}
skipping logging after 96528 examples to avoid logging too frequently
skipping logging after 96544 examples to avoid logging too frequently
skipping logging after 96560 examples to avoid logging too frequently
train stats after 96576 examples: {'rewards_train/chosen': '-3.5482', 'rewards_train/rejected': '-10.913', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.3606', 'logps_train/rejected': '-245.59', 'logps_train/chosen': '-77.815', 'loss/train': '0.12101', 'examples_per_second': '5.008', 'grad_norm': '14.375', 'counters/examples': 96576, 'counters/updates': 6036}
skipping logging after 96592 examples to avoid logging too frequently
skipping logging after 96608 examples to avoid logging too frequently
skipping logging after 96624 examples to avoid logging too frequently
train stats after 96640 examples: {'rewards_train/chosen': '-3.6971', 'rewards_train/rejected': '-11.061', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.3604', 'logps_train/rejected': '-228.59', 'logps_train/chosen': '-65.535', 'loss/train': '0.12585', 'examples_per_second': '5.2533', 'grad_norm': '9.875', 'counters/examples': 96640, 'counters/updates': 6040}
skipping logging after 96656 examples to avoid logging too frequently
skipping logging after 96672 examples to avoid logging too frequently
skipping logging after 96688 examples to avoid logging too frequently
train stats after 96704 examples: {'rewards_train/chosen': '-3.2372', 'rewards_train/rejected': '-12.079', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.842', 'logps_train/rejected': '-273.6', 'logps_train/chosen': '-67.786', 'loss/train': '0.037882', 'examples_per_second': '4.8969', 'grad_norm': '6.1562', 'counters/examples': 96704, 'counters/updates': 6044}
skipping logging after 96720 examples to avoid logging too frequently
skipping logging after 96736 examples to avoid logging too frequently
skipping logging after 96752 examples to avoid logging too frequently
train stats after 96768 examples: {'rewards_train/chosen': '-3.644', 'rewards_train/rejected': '-12.223', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.5806', 'logps_train/rejected': '-279.7', 'logps_train/chosen': '-75.346', 'loss/train': '0.069761', 'examples_per_second': '5.5331', 'grad_norm': '9.625', 'counters/examples': 96768, 'counters/updates': 6048}
skipping logging after 96784 examples to avoid logging too frequently
skipping logging after 96800 examples to avoid logging too frequently
skipping logging after 96816 examples to avoid logging too frequently
train stats after 96832 examples: {'rewards_train/chosen': '-3.7904', 'rewards_train/rejected': '-12.958', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.166', 'logps_train/rejected': '-277.07', 'logps_train/chosen': '-75.117', 'loss/train': '0.13172', 'examples_per_second': '5.0568', 'grad_norm': '13.375', 'counters/examples': 96832, 'counters/updates': 6052}
skipping logging after 96848 examples to avoid logging too frequently
skipping logging after 96864 examples to avoid logging too frequently
skipping logging after 96880 examples to avoid logging too frequently
train stats after 96896 examples: {'rewards_train/chosen': '-3.5376', 'rewards_train/rejected': '-12.366', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.8254', 'logps_train/rejected': '-299.68', 'logps_train/chosen': '-83.002', 'loss/train': '0.082274', 'examples_per_second': '4.8418', 'grad_norm': '8.6875', 'counters/examples': 96896, 'counters/updates': 6056}
skipping logging after 96912 examples to avoid logging too frequently
skipping logging after 96928 examples to avoid logging too frequently
skipping logging after 96944 examples to avoid logging too frequently
train stats after 96960 examples: {'rewards_train/chosen': '-3.4982', 'rewards_train/rejected': '-12.351', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.8542', 'logps_train/rejected': '-279.62', 'logps_train/chosen': '-76.906', 'loss/train': '0.037748', 'examples_per_second': '5.169', 'grad_norm': '5.9062', 'counters/examples': 96960, 'counters/updates': 6060}
skipping logging after 96976 examples to avoid logging too frequently
skipping logging after 96992 examples to avoid logging too frequently
skipping logging after 97008 examples to avoid logging too frequently
train stats after 97024 examples: {'rewards_train/chosen': '-3.7619', 'rewards_train/rejected': '-12.627', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.8677', 'logps_train/rejected': '-271.33', 'logps_train/chosen': '-80.721', 'loss/train': '0.056217', 'examples_per_second': '5.6179', 'grad_norm': '6.4688', 'counters/examples': 97024, 'counters/updates': 6064}
skipping logging after 97040 examples to avoid logging too frequently
skipping logging after 97056 examples to avoid logging too frequently
skipping logging after 97072 examples to avoid logging too frequently
train stats after 97088 examples: {'rewards_train/chosen': '-3.442', 'rewards_train/rejected': '-10.726', 'rewards_train/accuracies': '0.89062', 'rewards_train/margins': '7.2798', 'logps_train/rejected': '-216.09', 'logps_train/chosen': '-68.063', 'loss/train': '0.17188', 'examples_per_second': '5.9331', 'grad_norm': '7.6562', 'counters/examples': 97088, 'counters/updates': 6068}
skipping logging after 97104 examples to avoid logging too frequently
skipping logging after 97120 examples to avoid logging too frequently
skipping logging after 97136 examples to avoid logging too frequently
train stats after 97152 examples: {'rewards_train/chosen': '-3.2713', 'rewards_train/rejected': '-11.922', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.6506', 'logps_train/rejected': '-257.87', 'logps_train/chosen': '-78.295', 'loss/train': '0.025913', 'examples_per_second': '5.1485', 'grad_norm': '3.6562', 'counters/examples': 97152, 'counters/updates': 6072}
skipping logging after 97168 examples to avoid logging too frequently
skipping logging after 97184 examples to avoid logging too frequently
skipping logging after 97200 examples to avoid logging too frequently
train stats after 97216 examples: {'rewards_train/chosen': '-3.2886', 'rewards_train/rejected': '-11.673', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.3855', 'logps_train/rejected': '-249.25', 'logps_train/chosen': '-71.035', 'loss/train': '0.043407', 'examples_per_second': '5.3951', 'grad_norm': '8.5625', 'counters/examples': 97216, 'counters/updates': 6076}
skipping logging after 97232 examples to avoid logging too frequently
skipping logging after 97248 examples to avoid logging too frequently
skipping logging after 97264 examples to avoid logging too frequently
train stats after 97280 examples: {'rewards_train/chosen': '-2.6393', 'rewards_train/rejected': '-10.937', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.2957', 'logps_train/rejected': '-237.02', 'logps_train/chosen': '-72.484', 'loss/train': '0.054182', 'examples_per_second': '5.464', 'grad_norm': '5.75', 'counters/examples': 97280, 'counters/updates': 6080}
skipping logging after 97296 examples to avoid logging too frequently
skipping logging after 97312 examples to avoid logging too frequently
skipping logging after 97328 examples to avoid logging too frequently
train stats after 97344 examples: {'rewards_train/chosen': '-3.1784', 'rewards_train/rejected': '-12.776', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.5935', 'logps_train/rejected': '-286.31', 'logps_train/chosen': '-78.658', 'loss/train': '0.037571', 'examples_per_second': '4.7991', 'grad_norm': '4.5', 'counters/examples': 97344, 'counters/updates': 6084}
skipping logging after 97360 examples to avoid logging too frequently
skipping logging after 97376 examples to avoid logging too frequently
skipping logging after 97392 examples to avoid logging too frequently
train stats after 97408 examples: {'rewards_train/chosen': '-3.484', 'rewards_train/rejected': '-11.946', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.4618', 'logps_train/rejected': '-268.84', 'logps_train/chosen': '-77.574', 'loss/train': '0.10552', 'examples_per_second': '4.982', 'grad_norm': '14.688', 'counters/examples': 97408, 'counters/updates': 6088}
skipping logging after 97424 examples to avoid logging too frequently
skipping logging after 97440 examples to avoid logging too frequently
skipping logging after 97456 examples to avoid logging too frequently
train stats after 97472 examples: {'rewards_train/chosen': '-2.7661', 'rewards_train/rejected': '-10.412', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.6461', 'logps_train/rejected': '-267.73', 'logps_train/chosen': '-70.91', 'loss/train': '0.088012', 'examples_per_second': '4.4266', 'grad_norm': '8.375', 'counters/examples': 97472, 'counters/updates': 6092}
skipping logging after 97488 examples to avoid logging too frequently
skipping logging after 97504 examples to avoid logging too frequently
skipping logging after 97520 examples to avoid logging too frequently
train stats after 97536 examples: {'rewards_train/chosen': '-3.1301', 'rewards_train/rejected': '-11.562', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.4354', 'logps_train/rejected': '-270.34', 'logps_train/chosen': '-73.422', 'loss/train': '0.10455', 'examples_per_second': '4.7554', 'grad_norm': '14.625', 'counters/examples': 97536, 'counters/updates': 6096}
skipping logging after 97552 examples to avoid logging too frequently
skipping logging after 97568 examples to avoid logging too frequently
skipping logging after 97584 examples to avoid logging too frequently
train stats after 97600 examples: {'rewards_train/chosen': '-3.2103', 'rewards_train/rejected': '-11.088', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.8772', 'logps_train/rejected': '-265.77', 'logps_train/chosen': '-73.381', 'loss/train': '0.12071', 'examples_per_second': '4.708', 'grad_norm': '10.438', 'counters/examples': 97600, 'counters/updates': 6100}
skipping logging after 97616 examples to avoid logging too frequently
skipping logging after 97632 examples to avoid logging too frequently
skipping logging after 97648 examples to avoid logging too frequently
train stats after 97664 examples: {'rewards_train/chosen': '-2.7348', 'rewards_train/rejected': '-11.112', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.3782', 'logps_train/rejected': '-248.61', 'logps_train/chosen': '-74.243', 'loss/train': '0.032064', 'examples_per_second': '4.7292', 'grad_norm': '5.3125', 'counters/examples': 97664, 'counters/updates': 6104}
skipping logging after 97680 examples to avoid logging too frequently
skipping logging after 97696 examples to avoid logging too frequently
skipping logging after 97712 examples to avoid logging too frequently
train stats after 97728 examples: {'rewards_train/chosen': '-3.3486', 'rewards_train/rejected': '-11.75', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.4009', 'logps_train/rejected': '-253.28', 'logps_train/chosen': '-76.834', 'loss/train': '0.034164', 'examples_per_second': '4.8945', 'grad_norm': '4.6875', 'counters/examples': 97728, 'counters/updates': 6108}
skipping logging after 97744 examples to avoid logging too frequently
skipping logging after 97760 examples to avoid logging too frequently
skipping logging after 97776 examples to avoid logging too frequently
train stats after 97792 examples: {'rewards_train/chosen': '-3.5237', 'rewards_train/rejected': '-12.25', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.7283', 'logps_train/rejected': '-274.04', 'logps_train/chosen': '-75.111', 'loss/train': '0.091561', 'examples_per_second': '5.6783', 'grad_norm': '12.188', 'counters/examples': 97792, 'counters/updates': 6112}
skipping logging after 97808 examples to avoid logging too frequently
skipping logging after 97824 examples to avoid logging too frequently
skipping logging after 97840 examples to avoid logging too frequently
train stats after 97856 examples: {'rewards_train/chosen': '-3.2618', 'rewards_train/rejected': '-11.696', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.4321', 'logps_train/rejected': '-248.95', 'logps_train/chosen': '-67.475', 'loss/train': '0.091738', 'examples_per_second': '5.6696', 'grad_norm': '9.5625', 'counters/examples': 97856, 'counters/updates': 6116}
skipping logging after 97872 examples to avoid logging too frequently
skipping logging after 97888 examples to avoid logging too frequently
skipping logging after 97904 examples to avoid logging too frequently
train stats after 97920 examples: {'rewards_train/chosen': '-3.5827', 'rewards_train/rejected': '-12.837', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.2542', 'logps_train/rejected': '-290.57', 'logps_train/chosen': '-80.451', 'loss/train': '0.023089', 'examples_per_second': '5.648', 'grad_norm': '6.0625', 'counters/examples': 97920, 'counters/updates': 6120}
skipping logging after 97936 examples to avoid logging too frequently
skipping logging after 97952 examples to avoid logging too frequently
skipping logging after 97968 examples to avoid logging too frequently
train stats after 97984 examples: {'rewards_train/chosen': '-3.5582', 'rewards_train/rejected': '-12.042', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.4836', 'logps_train/rejected': '-258.34', 'logps_train/chosen': '-79.865', 'loss/train': '0.04395', 'examples_per_second': '5.4808', 'grad_norm': '6.9688', 'counters/examples': 97984, 'counters/updates': 6124}
skipping logging after 98000 examples to avoid logging too frequently
skipping logging after 98016 examples to avoid logging too frequently
skipping logging after 98032 examples to avoid logging too frequently
train stats after 98048 examples: {'rewards_train/chosen': '-3.8514', 'rewards_train/rejected': '-13.155', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.3015', 'logps_train/rejected': '-297.95', 'logps_train/chosen': '-85.061', 'loss/train': '0.052887', 'examples_per_second': '4.9521', 'grad_norm': '10.438', 'counters/examples': 98048, 'counters/updates': 6128}
skipping logging after 98064 examples to avoid logging too frequently
skipping logging after 98080 examples to avoid logging too frequently
skipping logging after 98096 examples to avoid logging too frequently
train stats after 98112 examples: {'rewards_train/chosen': '-3.207', 'rewards_train/rejected': '-12.612', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.4111', 'logps_train/rejected': '-287.07', 'logps_train/chosen': '-71.889', 'loss/train': '0.094662', 'examples_per_second': '4.3108', 'grad_norm': '11.625', 'counters/examples': 98112, 'counters/updates': 6132}
skipping logging after 98128 examples to avoid logging too frequently
skipping logging after 98144 examples to avoid logging too frequently
skipping logging after 98160 examples to avoid logging too frequently
train stats after 98176 examples: {'rewards_train/chosen': '-3.6599', 'rewards_train/rejected': '-12.58', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.9187', 'logps_train/rejected': '-247.9', 'logps_train/chosen': '-80.326', 'loss/train': '0.20223', 'examples_per_second': '3.9883', 'grad_norm': '18.25', 'counters/examples': 98176, 'counters/updates': 6136}
skipping logging after 98192 examples to avoid logging too frequently
skipping logging after 98208 examples to avoid logging too frequently
skipping logging after 98224 examples to avoid logging too frequently
train stats after 98240 examples: {'rewards_train/chosen': '-3.1728', 'rewards_train/rejected': '-10.516', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.3414', 'logps_train/rejected': '-252.25', 'logps_train/chosen': '-76.551', 'loss/train': '0.065284', 'examples_per_second': '5.0846', 'grad_norm': '5.0312', 'counters/examples': 98240, 'counters/updates': 6140}
skipping logging after 98256 examples to avoid logging too frequently
skipping logging after 98272 examples to avoid logging too frequently
skipping logging after 98288 examples to avoid logging too frequently
train stats after 98304 examples: {'rewards_train/chosen': '-3.6479', 'rewards_train/rejected': '-10.599', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.9507', 'logps_train/rejected': '-236.45', 'logps_train/chosen': '-76.617', 'loss/train': '0.089108', 'examples_per_second': '4.9585', 'grad_norm': '11.625', 'counters/examples': 98304, 'counters/updates': 6144}
skipping logging after 98320 examples to avoid logging too frequently
skipping logging after 98336 examples to avoid logging too frequently
skipping logging after 98352 examples to avoid logging too frequently
train stats after 98368 examples: {'rewards_train/chosen': '-3.0997', 'rewards_train/rejected': '-9.7933', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.694', 'logps_train/rejected': '-222.85', 'logps_train/chosen': '-67.256', 'loss/train': '0.11699', 'examples_per_second': '4.7068', 'grad_norm': '10', 'counters/examples': 98368, 'counters/updates': 6148}
skipping logging after 98384 examples to avoid logging too frequently
skipping logging after 98400 examples to avoid logging too frequently
skipping logging after 98416 examples to avoid logging too frequently
train stats after 98432 examples: {'rewards_train/chosen': '-3.4854', 'rewards_train/rejected': '-10.681', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.197', 'logps_train/rejected': '-239.37', 'logps_train/chosen': '-70.668', 'loss/train': '0.10583', 'examples_per_second': '5.0539', 'grad_norm': '13.562', 'counters/examples': 98432, 'counters/updates': 6152}
skipping logging after 98448 examples to avoid logging too frequently
skipping logging after 98464 examples to avoid logging too frequently
skipping logging after 98480 examples to avoid logging too frequently
train stats after 98496 examples: {'rewards_train/chosen': '-3.9967', 'rewards_train/rejected': '-12.112', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.1182', 'logps_train/rejected': '-244.07', 'logps_train/chosen': '-74.669', 'loss/train': '0.11643', 'examples_per_second': '5.7484', 'grad_norm': '9.9375', 'counters/examples': 98496, 'counters/updates': 6156}
skipping logging after 98512 examples to avoid logging too frequently
skipping logging after 98528 examples to avoid logging too frequently
skipping logging after 98544 examples to avoid logging too frequently
train stats after 98560 examples: {'rewards_train/chosen': '-3.3467', 'rewards_train/rejected': '-12.947', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.6033', 'logps_train/rejected': '-312.4', 'logps_train/chosen': '-75.471', 'loss/train': '0.11257', 'examples_per_second': '3.8765', 'grad_norm': '12.688', 'counters/examples': 98560, 'counters/updates': 6160}
skipping logging after 98576 examples to avoid logging too frequently
skipping logging after 98592 examples to avoid logging too frequently
skipping logging after 98608 examples to avoid logging too frequently
train stats after 98624 examples: {'rewards_train/chosen': '-3.5733', 'rewards_train/rejected': '-11.194', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.6213', 'logps_train/rejected': '-221.09', 'logps_train/chosen': '-74.631', 'loss/train': '0.040043', 'examples_per_second': '4.717', 'grad_norm': '3.7031', 'counters/examples': 98624, 'counters/updates': 6164}
skipping logging after 98640 examples to avoid logging too frequently
skipping logging after 98656 examples to avoid logging too frequently
skipping logging after 98672 examples to avoid logging too frequently
train stats after 98688 examples: {'rewards_train/chosen': '-3.361', 'rewards_train/rejected': '-11.913', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.5494', 'logps_train/rejected': '-255.85', 'logps_train/chosen': '-71.137', 'loss/train': '0.074962', 'examples_per_second': '6.021', 'grad_norm': '6.5938', 'counters/examples': 98688, 'counters/updates': 6168}
skipping logging after 98704 examples to avoid logging too frequently
skipping logging after 98720 examples to avoid logging too frequently
skipping logging after 98736 examples to avoid logging too frequently
train stats after 98752 examples: {'rewards_train/chosen': '-3.9734', 'rewards_train/rejected': '-11.961', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.9927', 'logps_train/rejected': '-249.79', 'logps_train/chosen': '-74.491', 'loss/train': '0.12666', 'examples_per_second': '5.6723', 'grad_norm': '14.062', 'counters/examples': 98752, 'counters/updates': 6172}
skipping logging after 98768 examples to avoid logging too frequently
skipping logging after 98784 examples to avoid logging too frequently
skipping logging after 98800 examples to avoid logging too frequently
train stats after 98816 examples: {'rewards_train/chosen': '-3.415', 'rewards_train/rejected': '-12.628', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '9.2136', 'logps_train/rejected': '-264.63', 'logps_train/chosen': '-73.453', 'loss/train': '0.095087', 'examples_per_second': '4.9198', 'grad_norm': '8.3125', 'counters/examples': 98816, 'counters/updates': 6176}
skipping logging after 98832 examples to avoid logging too frequently
skipping logging after 98848 examples to avoid logging too frequently
skipping logging after 98864 examples to avoid logging too frequently
train stats after 98880 examples: {'rewards_train/chosen': '-3.0732', 'rewards_train/rejected': '-12.099', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.0256', 'logps_train/rejected': '-259.96', 'logps_train/chosen': '-74.592', 'loss/train': '0.043599', 'examples_per_second': '4.522', 'grad_norm': '8.625', 'counters/examples': 98880, 'counters/updates': 6180}
skipping logging after 98896 examples to avoid logging too frequently
skipping logging after 98912 examples to avoid logging too frequently
skipping logging after 98928 examples to avoid logging too frequently
train stats after 98944 examples: {'rewards_train/chosen': '-3.3935', 'rewards_train/rejected': '-12.571', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.1782', 'logps_train/rejected': '-257.71', 'logps_train/chosen': '-77.069', 'loss/train': '0.025494', 'examples_per_second': '5.1468', 'grad_norm': '5.625', 'counters/examples': 98944, 'counters/updates': 6184}
skipping logging after 98960 examples to avoid logging too frequently
skipping logging after 98976 examples to avoid logging too frequently
skipping logging after 98992 examples to avoid logging too frequently
train stats after 99008 examples: {'rewards_train/chosen': '-3.6626', 'rewards_train/rejected': '-12.057', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.3945', 'logps_train/rejected': '-247.69', 'logps_train/chosen': '-79.131', 'loss/train': '0.11192', 'examples_per_second': '4.9841', 'grad_norm': '11.625', 'counters/examples': 99008, 'counters/updates': 6188}
skipping logging after 99024 examples to avoid logging too frequently
skipping logging after 99040 examples to avoid logging too frequently
skipping logging after 99056 examples to avoid logging too frequently
train stats after 99072 examples: {'rewards_train/chosen': '-2.9328', 'rewards_train/rejected': '-11.367', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.4321', 'logps_train/rejected': '-247.98', 'logps_train/chosen': '-72.494', 'loss/train': '0.090004', 'examples_per_second': '5.2974', 'grad_norm': '15.812', 'counters/examples': 99072, 'counters/updates': 6192}
skipping logging after 99088 examples to avoid logging too frequently
skipping logging after 99104 examples to avoid logging too frequently
skipping logging after 99120 examples to avoid logging too frequently
train stats after 99136 examples: {'rewards_train/chosen': '-3.1878', 'rewards_train/rejected': '-11.177', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.9916', 'logps_train/rejected': '-259.95', 'logps_train/chosen': '-71.506', 'loss/train': '0.072716', 'examples_per_second': '4.7878', 'grad_norm': '8.6875', 'counters/examples': 99136, 'counters/updates': 6196}
skipping logging after 99152 examples to avoid logging too frequently
skipping logging after 99168 examples to avoid logging too frequently
skipping logging after 99184 examples to avoid logging too frequently
train stats after 99200 examples: {'rewards_train/chosen': '-2.9691', 'rewards_train/rejected': '-11.556', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.583', 'logps_train/rejected': '-288.16', 'logps_train/chosen': '-75.508', 'loss/train': '0.04881', 'examples_per_second': '4.9461', 'grad_norm': '10.688', 'counters/examples': 99200, 'counters/updates': 6200}
skipping logging after 99216 examples to avoid logging too frequently
skipping logging after 99232 examples to avoid logging too frequently
skipping logging after 99248 examples to avoid logging too frequently
train stats after 99264 examples: {'rewards_train/chosen': '-2.7887', 'rewards_train/rejected': '-11.055', 'rewards_train/accuracies': '0.875', 'rewards_train/margins': '8.2631', 'logps_train/rejected': '-258.39', 'logps_train/chosen': '-68.778', 'loss/train': '0.095954', 'examples_per_second': '4.3844', 'grad_norm': '14.812', 'counters/examples': 99264, 'counters/updates': 6204}
skipping logging after 99280 examples to avoid logging too frequently
skipping logging after 99296 examples to avoid logging too frequently
skipping logging after 99312 examples to avoid logging too frequently
train stats after 99328 examples: {'rewards_train/chosen': '-2.7778', 'rewards_train/rejected': '-11.254', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.4734', 'logps_train/rejected': '-265.36', 'logps_train/chosen': '-60.989', 'loss/train': '0.077434', 'examples_per_second': '5.9', 'grad_norm': '14.312', 'counters/examples': 99328, 'counters/updates': 6208}
skipping logging after 99344 examples to avoid logging too frequently
skipping logging after 99360 examples to avoid logging too frequently
skipping logging after 99376 examples to avoid logging too frequently
train stats after 99392 examples: {'rewards_train/chosen': '-2.6665', 'rewards_train/rejected': '-11.02', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.3536', 'logps_train/rejected': '-263.84', 'logps_train/chosen': '-60.495', 'loss/train': '0.0387', 'examples_per_second': '5.0311', 'grad_norm': '5.0938', 'counters/examples': 99392, 'counters/updates': 6212}
skipping logging after 99408 examples to avoid logging too frequently
skipping logging after 99424 examples to avoid logging too frequently
skipping logging after 99440 examples to avoid logging too frequently
train stats after 99456 examples: {'rewards_train/chosen': '-2.9996', 'rewards_train/rejected': '-10.671', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.6719', 'logps_train/rejected': '-257.65', 'logps_train/chosen': '-67.727', 'loss/train': '0.10333', 'examples_per_second': '5.5318', 'grad_norm': '8.875', 'counters/examples': 99456, 'counters/updates': 6216}
skipping logging after 99472 examples to avoid logging too frequently
skipping logging after 99488 examples to avoid logging too frequently
skipping logging after 99504 examples to avoid logging too frequently
train stats after 99520 examples: {'rewards_train/chosen': '-3.2424', 'rewards_train/rejected': '-11.053', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.8099', 'logps_train/rejected': '-220.17', 'logps_train/chosen': '-61.742', 'loss/train': '0.055604', 'examples_per_second': '6.5177', 'grad_norm': '8.625', 'counters/examples': 99520, 'counters/updates': 6220}
skipping logging after 99536 examples to avoid logging too frequently
skipping logging after 99552 examples to avoid logging too frequently
skipping logging after 99568 examples to avoid logging too frequently
train stats after 99584 examples: {'rewards_train/chosen': '-3.7854', 'rewards_train/rejected': '-12.005', 'rewards_train/accuracies': '0.89062', 'rewards_train/margins': '8.219', 'logps_train/rejected': '-272.08', 'logps_train/chosen': '-86.134', 'loss/train': '0.22252', 'examples_per_second': '4.962', 'grad_norm': '23.125', 'counters/examples': 99584, 'counters/updates': 6224}
skipping logging after 99600 examples to avoid logging too frequently
skipping logging after 99616 examples to avoid logging too frequently
skipping logging after 99632 examples to avoid logging too frequently
train stats after 99648 examples: {'rewards_train/chosen': '-3.0592', 'rewards_train/rejected': '-11.185', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.1245', 'logps_train/rejected': '-268.35', 'logps_train/chosen': '-77.807', 'loss/train': '0.10278', 'examples_per_second': '4.9861', 'grad_norm': '17.25', 'counters/examples': 99648, 'counters/updates': 6228}
skipping logging after 99664 examples to avoid logging too frequently
skipping logging after 99680 examples to avoid logging too frequently
skipping logging after 99696 examples to avoid logging too frequently
train stats after 99712 examples: {'rewards_train/chosen': '-3.2367', 'rewards_train/rejected': '-11.413', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.1766', 'logps_train/rejected': '-270.84', 'logps_train/chosen': '-72.979', 'loss/train': '0.049732', 'examples_per_second': '5.0389', 'grad_norm': '6.8438', 'counters/examples': 99712, 'counters/updates': 6232}
skipping logging after 99728 examples to avoid logging too frequently
skipping logging after 99744 examples to avoid logging too frequently
skipping logging after 99760 examples to avoid logging too frequently
train stats after 99776 examples: {'rewards_train/chosen': '-2.9306', 'rewards_train/rejected': '-12.433', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.5024', 'logps_train/rejected': '-305.97', 'logps_train/chosen': '-66.014', 'loss/train': '0.049275', 'examples_per_second': '5.4744', 'grad_norm': '7.3125', 'counters/examples': 99776, 'counters/updates': 6236}
skipping logging after 99792 examples to avoid logging too frequently
skipping logging after 99808 examples to avoid logging too frequently
skipping logging after 99824 examples to avoid logging too frequently
train stats after 99840 examples: {'rewards_train/chosen': '-3.1124', 'rewards_train/rejected': '-10.383', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.2706', 'logps_train/rejected': '-220.55', 'logps_train/chosen': '-73.232', 'loss/train': '0.075709', 'examples_per_second': '5.2815', 'grad_norm': '12.938', 'counters/examples': 99840, 'counters/updates': 6240}
skipping logging after 99856 examples to avoid logging too frequently
skipping logging after 99872 examples to avoid logging too frequently
skipping logging after 99888 examples to avoid logging too frequently
train stats after 99904 examples: {'rewards_train/chosen': '-3.1946', 'rewards_train/rejected': '-11.21', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.0203', 'logps_train/rejected': '-236.84', 'logps_train/chosen': '-64.837', 'loss/train': '0.038728', 'examples_per_second': '6.0231', 'grad_norm': '4', 'counters/examples': 99904, 'counters/updates': 6244}
skipping logging after 99920 examples to avoid logging too frequently
skipping logging after 99936 examples to avoid logging too frequently
skipping logging after 99952 examples to avoid logging too frequently
train stats after 99968 examples: {'rewards_train/chosen': '-3.1969', 'rewards_train/rejected': '-11.676', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.4785', 'logps_train/rejected': '-260.79', 'logps_train/chosen': '-72.28', 'loss/train': '0.053093', 'examples_per_second': '4.8083', 'grad_norm': '13.375', 'counters/examples': 99968, 'counters/updates': 6248}
skipping logging after 99984 examples to avoid logging too frequently
skipping logging after 100000 examples to avoid logging too frequently
Running evaluation after 100000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:10,  2.29s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:04,  2.16s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:55,  1.92s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.90s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.55s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.66s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.49s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.57s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:36,  1.57s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:30,  1.50s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:22,  1.30s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.24s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.33s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.34s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.27s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:33<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.29s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.26s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:37<00:07,  1.30s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:39<00:07,  1.48s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.41s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.61s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.42s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.42s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.44s/it]
eval after 100000: {'rewards_eval/chosen': '-11.113', 'rewards_eval/rejected': '-11.696', 'rewards_eval/accuracies': '0.5332', 'rewards_eval/margins': '0.58252', 'logps_eval/rejected': '-264.6', 'logps_eval/chosen': '-256.04', 'loss/eval': '1.9679'}
skipping logging after 100016 examples to avoid logging too frequently
train stats after 100032 examples: {'rewards_train/chosen': '-3.1301', 'rewards_train/rejected': '-12.163', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.0354', 'logps_train/rejected': '-271.16', 'logps_train/chosen': '-66.592', 'loss/train': '0.098455', 'examples_per_second': '4.7477', 'grad_norm': '12', 'counters/examples': 100032, 'counters/updates': 6252}
skipping logging after 100048 examples to avoid logging too frequently
skipping logging after 100064 examples to avoid logging too frequently
skipping logging after 100080 examples to avoid logging too frequently
train stats after 100096 examples: {'rewards_train/chosen': '-3.1067', 'rewards_train/rejected': '-11.067', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.9609', 'logps_train/rejected': '-249.64', 'logps_train/chosen': '-81.408', 'loss/train': '0.029111', 'examples_per_second': '4.6642', 'grad_norm': '5.125', 'counters/examples': 100096, 'counters/updates': 6256}
skipping logging after 100112 examples to avoid logging too frequently
skipping logging after 100128 examples to avoid logging too frequently
skipping logging after 100144 examples to avoid logging too frequently
train stats after 100160 examples: {'rewards_train/chosen': '-3.1291', 'rewards_train/rejected': '-10.407', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.2765', 'logps_train/rejected': '-232.93', 'logps_train/chosen': '-65.877', 'loss/train': '0.087146', 'examples_per_second': '4.4266', 'grad_norm': '9.125', 'counters/examples': 100160, 'counters/updates': 6260}
skipping logging after 100176 examples to avoid logging too frequently
skipping logging after 100192 examples to avoid logging too frequently
skipping logging after 100208 examples to avoid logging too frequently
train stats after 100224 examples: {'rewards_train/chosen': '-4.0314', 'rewards_train/rejected': '-13.544', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '9.5107', 'logps_train/rejected': '-258.83', 'logps_train/chosen': '-83.617', 'loss/train': '0.16014', 'examples_per_second': '5.7737', 'grad_norm': '27.75', 'counters/examples': 100224, 'counters/updates': 6264}
skipping logging after 100240 examples to avoid logging too frequently
skipping logging after 100256 examples to avoid logging too frequently
skipping logging after 100272 examples to avoid logging too frequently
train stats after 100288 examples: {'rewards_train/chosen': '-3.6232', 'rewards_train/rejected': '-12.066', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.4443', 'logps_train/rejected': '-254.84', 'logps_train/chosen': '-76.312', 'loss/train': '0.083323', 'examples_per_second': '5.3767', 'grad_norm': '18.125', 'counters/examples': 100288, 'counters/updates': 6268}
skipping logging after 100304 examples to avoid logging too frequently
skipping logging after 100320 examples to avoid logging too frequently
skipping logging after 100336 examples to avoid logging too frequently
train stats after 100352 examples: {'rewards_train/chosen': '-3.0436', 'rewards_train/rejected': '-13.456', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '10.412', 'logps_train/rejected': '-303.14', 'logps_train/chosen': '-76.065', 'loss/train': '0.071992', 'examples_per_second': '4.5867', 'grad_norm': '14.75', 'counters/examples': 100352, 'counters/updates': 6272}
skipping logging after 100368 examples to avoid logging too frequently
skipping logging after 100384 examples to avoid logging too frequently
skipping logging after 100400 examples to avoid logging too frequently
train stats after 100416 examples: {'rewards_train/chosen': '-3.5108', 'rewards_train/rejected': '-12.018', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.5122', 'logps_train/rejected': '-249.82', 'logps_train/chosen': '-77.416', 'loss/train': '0.11398', 'examples_per_second': '5.6756', 'grad_norm': '7.875', 'counters/examples': 100416, 'counters/updates': 6276}
skipping logging after 100432 examples to avoid logging too frequently
skipping logging after 100448 examples to avoid logging too frequently
skipping logging after 100464 examples to avoid logging too frequently
train stats after 100480 examples: {'rewards_train/chosen': '-2.9282', 'rewards_train/rejected': '-10.816', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.8839', 'logps_train/rejected': '-243.82', 'logps_train/chosen': '-65.564', 'loss/train': '0.078035', 'examples_per_second': '5.742', 'grad_norm': '10.062', 'counters/examples': 100480, 'counters/updates': 6280}
skipping logging after 100496 examples to avoid logging too frequently
skipping logging after 100512 examples to avoid logging too frequently
skipping logging after 100528 examples to avoid logging too frequently
train stats after 100544 examples: {'rewards_train/chosen': '-3.268', 'rewards_train/rejected': '-12.052', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.7823', 'logps_train/rejected': '-269.18', 'logps_train/chosen': '-79.482', 'loss/train': '0.39547', 'examples_per_second': '4.0773', 'grad_norm': '27.125', 'counters/examples': 100544, 'counters/updates': 6284}
skipping logging after 100560 examples to avoid logging too frequently
skipping logging after 100576 examples to avoid logging too frequently
skipping logging after 100592 examples to avoid logging too frequently
train stats after 100608 examples: {'rewards_train/chosen': '-3.245', 'rewards_train/rejected': '-10.681', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.4384', 'logps_train/rejected': '-239.02', 'logps_train/chosen': '-73.312', 'loss/train': '0.045273', 'examples_per_second': '5.8926', 'grad_norm': '7.8125', 'counters/examples': 100608, 'counters/updates': 6288}
skipping logging after 100624 examples to avoid logging too frequently
skipping logging after 100640 examples to avoid logging too frequently
skipping logging after 100656 examples to avoid logging too frequently
train stats after 100672 examples: {'rewards_train/chosen': '-3.3294', 'rewards_train/rejected': '-11.848', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.5178', 'logps_train/rejected': '-269.25', 'logps_train/chosen': '-82.407', 'loss/train': '0.047792', 'examples_per_second': '5.0114', 'grad_norm': '8.4375', 'counters/examples': 100672, 'counters/updates': 6292}
skipping logging after 100688 examples to avoid logging too frequently
skipping logging after 100704 examples to avoid logging too frequently
skipping logging after 100720 examples to avoid logging too frequently
train stats after 100736 examples: {'rewards_train/chosen': '-3.3973', 'rewards_train/rejected': '-11.603', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.2043', 'logps_train/rejected': '-244.44', 'logps_train/chosen': '-67.859', 'loss/train': '0.066705', 'examples_per_second': '5.4687', 'grad_norm': '13.812', 'counters/examples': 100736, 'counters/updates': 6296}
skipping logging after 100752 examples to avoid logging too frequently
skipping logging after 100768 examples to avoid logging too frequently
skipping logging after 100784 examples to avoid logging too frequently
train stats after 100800 examples: {'rewards_train/chosen': '-3.1221', 'rewards_train/rejected': '-11.435', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.313', 'logps_train/rejected': '-241.22', 'logps_train/chosen': '-66.922', 'loss/train': '0.092546', 'examples_per_second': '5.7369', 'grad_norm': '9.125', 'counters/examples': 100800, 'counters/updates': 6300}
skipping logging after 100816 examples to avoid logging too frequently
skipping logging after 100832 examples to avoid logging too frequently
skipping logging after 100848 examples to avoid logging too frequently
train stats after 100864 examples: {'rewards_train/chosen': '-3.0233', 'rewards_train/rejected': '-12.123', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.0981', 'logps_train/rejected': '-264', 'logps_train/chosen': '-65.373', 'loss/train': '0.054046', 'examples_per_second': '5.7001', 'grad_norm': '5.7188', 'counters/examples': 100864, 'counters/updates': 6304}
skipping logging after 100880 examples to avoid logging too frequently
skipping logging after 100896 examples to avoid logging too frequently
skipping logging after 100912 examples to avoid logging too frequently
train stats after 100928 examples: {'rewards_train/chosen': '-3.9181', 'rewards_train/rejected': '-12.262', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.3425', 'logps_train/rejected': '-243.11', 'logps_train/chosen': '-76.574', 'loss/train': '0.091134', 'examples_per_second': '5.4418', 'grad_norm': '11', 'counters/examples': 100928, 'counters/updates': 6308}
skipping logging after 100944 examples to avoid logging too frequently
skipping logging after 100960 examples to avoid logging too frequently
skipping logging after 100976 examples to avoid logging too frequently
train stats after 100992 examples: {'rewards_train/chosen': '-3.3271', 'rewards_train/rejected': '-11.598', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.2683', 'logps_train/rejected': '-244.28', 'logps_train/chosen': '-70.764', 'loss/train': '0.10614', 'examples_per_second': '4.2646', 'grad_norm': '16.875', 'counters/examples': 100992, 'counters/updates': 6312}
skipping logging after 101008 examples to avoid logging too frequently
skipping logging after 101024 examples to avoid logging too frequently
skipping logging after 101040 examples to avoid logging too frequently
train stats after 101056 examples: {'rewards_train/chosen': '-3.6407', 'rewards_train/rejected': '-10.76', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.1199', 'logps_train/rejected': '-221.69', 'logps_train/chosen': '-69.064', 'loss/train': '0.077663', 'examples_per_second': '5.3044', 'grad_norm': '17.25', 'counters/examples': 101056, 'counters/updates': 6316}
skipping logging after 101072 examples to avoid logging too frequently
skipping logging after 101088 examples to avoid logging too frequently
skipping logging after 101104 examples to avoid logging too frequently
train stats after 101120 examples: {'rewards_train/chosen': '-3.1584', 'rewards_train/rejected': '-10.848', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.6902', 'logps_train/rejected': '-234', 'logps_train/chosen': '-71.38', 'loss/train': '0.12285', 'examples_per_second': '6.3409', 'grad_norm': '9.75', 'counters/examples': 101120, 'counters/updates': 6320}
skipping logging after 101136 examples to avoid logging too frequently
skipping logging after 101152 examples to avoid logging too frequently
skipping logging after 101168 examples to avoid logging too frequently
train stats after 101184 examples: {'rewards_train/chosen': '-2.824', 'rewards_train/rejected': '-12.294', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.465', 'logps_train/rejected': '-254.28', 'logps_train/chosen': '-76.385', 'loss/train': '0.093038', 'examples_per_second': '5.2126', 'grad_norm': '11.938', 'counters/examples': 101184, 'counters/updates': 6324}
skipping logging after 101200 examples to avoid logging too frequently
skipping logging after 101216 examples to avoid logging too frequently
skipping logging after 101232 examples to avoid logging too frequently
train stats after 101248 examples: {'rewards_train/chosen': '-2.9625', 'rewards_train/rejected': '-11.132', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1731', 'logps_train/rejected': '-241.89', 'logps_train/chosen': '-74.001', 'loss/train': '0.050044', 'examples_per_second': '5.6626', 'grad_norm': '9.75', 'counters/examples': 101248, 'counters/updates': 6328}
skipping logging after 101264 examples to avoid logging too frequently
skipping logging after 101280 examples to avoid logging too frequently
skipping logging after 101296 examples to avoid logging too frequently
train stats after 101312 examples: {'rewards_train/chosen': '-3.3855', 'rewards_train/rejected': '-10.883', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.4976', 'logps_train/rejected': '-206.58', 'logps_train/chosen': '-76.589', 'loss/train': '0.14169', 'examples_per_second': '5.9057', 'grad_norm': '17.625', 'counters/examples': 101312, 'counters/updates': 6332}
skipping logging after 101328 examples to avoid logging too frequently
skipping logging after 101344 examples to avoid logging too frequently
skipping logging after 101360 examples to avoid logging too frequently
train stats after 101376 examples: {'rewards_train/chosen': '-3.5469', 'rewards_train/rejected': '-11.672', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.1245', 'logps_train/rejected': '-275.78', 'logps_train/chosen': '-85.104', 'loss/train': '0.022415', 'examples_per_second': '5.2033', 'grad_norm': '3.1094', 'counters/examples': 101376, 'counters/updates': 6336}
skipping logging after 101392 examples to avoid logging too frequently
skipping logging after 101408 examples to avoid logging too frequently
skipping logging after 101424 examples to avoid logging too frequently
train stats after 101440 examples: {'rewards_train/chosen': '-3.2126', 'rewards_train/rejected': '-10.91', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.6982', 'logps_train/rejected': '-246.63', 'logps_train/chosen': '-78.064', 'loss/train': '0.032238', 'examples_per_second': '6.0067', 'grad_norm': '8', 'counters/examples': 101440, 'counters/updates': 6340}
skipping logging after 101456 examples to avoid logging too frequently
skipping logging after 101472 examples to avoid logging too frequently
skipping logging after 101488 examples to avoid logging too frequently
train stats after 101504 examples: {'rewards_train/chosen': '-3.624', 'rewards_train/rejected': '-12.741', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.1199', 'logps_train/rejected': '-290.03', 'logps_train/chosen': '-74.081', 'loss/train': '0.15621', 'examples_per_second': '5.3174', 'grad_norm': '23.875', 'counters/examples': 101504, 'counters/updates': 6344}
skipping logging after 101520 examples to avoid logging too frequently
skipping logging after 101536 examples to avoid logging too frequently
skipping logging after 101552 examples to avoid logging too frequently
train stats after 101568 examples: {'rewards_train/chosen': '-3.3439', 'rewards_train/rejected': '-12.434', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '9.0874', 'logps_train/rejected': '-264.23', 'logps_train/chosen': '-68.764', 'loss/train': '0.072293', 'examples_per_second': '4.9413', 'grad_norm': '8.75', 'counters/examples': 101568, 'counters/updates': 6348}
skipping logging after 101584 examples to avoid logging too frequently
skipping logging after 101600 examples to avoid logging too frequently
skipping logging after 101616 examples to avoid logging too frequently
train stats after 101632 examples: {'rewards_train/chosen': '-3.8978', 'rewards_train/rejected': '-11.609', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.7139', 'logps_train/rejected': '-254.2', 'logps_train/chosen': '-74.438', 'loss/train': '0.060086', 'examples_per_second': '5.1809', 'grad_norm': '13.188', 'counters/examples': 101632, 'counters/updates': 6352}
skipping logging after 101648 examples to avoid logging too frequently
skipping logging after 101664 examples to avoid logging too frequently
skipping logging after 101680 examples to avoid logging too frequently
train stats after 101696 examples: {'rewards_train/chosen': '-3.6143', 'rewards_train/rejected': '-12.998', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '9.3848', 'logps_train/rejected': '-284.67', 'logps_train/chosen': '-76.861', 'loss/train': '0.097204', 'examples_per_second': '4.6819', 'grad_norm': '16.125', 'counters/examples': 101696, 'counters/updates': 6356}
skipping logging after 101712 examples to avoid logging too frequently
skipping logging after 101728 examples to avoid logging too frequently
skipping logging after 101744 examples to avoid logging too frequently
train stats after 101760 examples: {'rewards_train/chosen': '-3.5254', 'rewards_train/rejected': '-12.609', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.0884', 'logps_train/rejected': '-273.37', 'logps_train/chosen': '-72.557', 'loss/train': '0.091726', 'examples_per_second': '5.5031', 'grad_norm': '14.562', 'counters/examples': 101760, 'counters/updates': 6360}
skipping logging after 101776 examples to avoid logging too frequently
skipping logging after 101792 examples to avoid logging too frequently
skipping logging after 101808 examples to avoid logging too frequently
train stats after 101824 examples: {'rewards_train/chosen': '-3.434', 'rewards_train/rejected': '-13.054', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.6204', 'logps_train/rejected': '-269.19', 'logps_train/chosen': '-73.411', 'loss/train': '0.072008', 'examples_per_second': '4.5598', 'grad_norm': '10.75', 'counters/examples': 101824, 'counters/updates': 6364}
skipping logging after 101840 examples to avoid logging too frequently
skipping logging after 101856 examples to avoid logging too frequently
skipping logging after 101872 examples to avoid logging too frequently
train stats after 101888 examples: {'rewards_train/chosen': '-4.1975', 'rewards_train/rejected': '-12.242', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.0449', 'logps_train/rejected': '-255.3', 'logps_train/chosen': '-82.789', 'loss/train': '0.11631', 'examples_per_second': '5.2186', 'grad_norm': '11.688', 'counters/examples': 101888, 'counters/updates': 6368}
skipping logging after 101904 examples to avoid logging too frequently
skipping logging after 101920 examples to avoid logging too frequently
skipping logging after 101936 examples to avoid logging too frequently
train stats after 101952 examples: {'rewards_train/chosen': '-4.0249', 'rewards_train/rejected': '-13.329', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.3037', 'logps_train/rejected': '-291.64', 'logps_train/chosen': '-73.496', 'loss/train': '0.13169', 'examples_per_second': '5.1143', 'grad_norm': '15.062', 'counters/examples': 101952, 'counters/updates': 6372}
skipping logging after 101968 examples to avoid logging too frequently
skipping logging after 101984 examples to avoid logging too frequently
skipping logging after 102000 examples to avoid logging too frequently
train stats after 102016 examples: {'rewards_train/chosen': '-3.9465', 'rewards_train/rejected': '-13.75', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.8049', 'logps_train/rejected': '-252.71', 'logps_train/chosen': '-76.92', 'loss/train': '0.067648', 'examples_per_second': '4.693', 'grad_norm': '8.4375', 'counters/examples': 102016, 'counters/updates': 6376}
skipping logging after 102032 examples to avoid logging too frequently
skipping logging after 102048 examples to avoid logging too frequently
skipping logging after 102064 examples to avoid logging too frequently
train stats after 102080 examples: {'rewards_train/chosen': '-3.5979', 'rewards_train/rejected': '-13.807', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '10.208', 'logps_train/rejected': '-284.19', 'logps_train/chosen': '-77.404', 'loss/train': '0.037307', 'examples_per_second': '4.4693', 'grad_norm': '10', 'counters/examples': 102080, 'counters/updates': 6380}
skipping logging after 102096 examples to avoid logging too frequently
skipping logging after 102112 examples to avoid logging too frequently
skipping logging after 102128 examples to avoid logging too frequently
train stats after 102144 examples: {'rewards_train/chosen': '-3.189', 'rewards_train/rejected': '-12.602', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.4133', 'logps_train/rejected': '-271.15', 'logps_train/chosen': '-72.416', 'loss/train': '0.035889', 'examples_per_second': '4.136', 'grad_norm': '7.0938', 'counters/examples': 102144, 'counters/updates': 6384}
skipping logging after 102160 examples to avoid logging too frequently
skipping logging after 102176 examples to avoid logging too frequently
skipping logging after 102192 examples to avoid logging too frequently
train stats after 102208 examples: {'rewards_train/chosen': '-3.6785', 'rewards_train/rejected': '-12.496', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.8193', 'logps_train/rejected': '-243.42', 'logps_train/chosen': '-79.191', 'loss/train': '0.068204', 'examples_per_second': '5.3588', 'grad_norm': '10.125', 'counters/examples': 102208, 'counters/updates': 6388}
skipping logging after 102224 examples to avoid logging too frequently
skipping logging after 102240 examples to avoid logging too frequently
skipping logging after 102256 examples to avoid logging too frequently
train stats after 102272 examples: {'rewards_train/chosen': '-3.3242', 'rewards_train/rejected': '-13.605', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '10.284', 'logps_train/rejected': '-291.2', 'logps_train/chosen': '-73.322', 'loss/train': '0.11391', 'examples_per_second': '6.0467', 'grad_norm': '12.438', 'counters/examples': 102272, 'counters/updates': 6392}
skipping logging after 102288 examples to avoid logging too frequently
skipping logging after 102304 examples to avoid logging too frequently
skipping logging after 102320 examples to avoid logging too frequently
train stats after 102336 examples: {'rewards_train/chosen': '-3.513', 'rewards_train/rejected': '-10.77', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.26', 'logps_train/rejected': '-239.59', 'logps_train/chosen': '-70.514', 'loss/train': '0.1031', 'examples_per_second': '4.7955', 'grad_norm': '9.9375', 'counters/examples': 102336, 'counters/updates': 6396}
skipping logging after 102352 examples to avoid logging too frequently
skipping logging after 102368 examples to avoid logging too frequently
skipping logging after 102384 examples to avoid logging too frequently
train stats after 102400 examples: {'rewards_train/chosen': '-3.4306', 'rewards_train/rejected': '-11.615', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.1826', 'logps_train/rejected': '-272.47', 'logps_train/chosen': '-78.237', 'loss/train': '0.065952', 'examples_per_second': '4.7982', 'grad_norm': '8.125', 'counters/examples': 102400, 'counters/updates': 6400}
skipping logging after 102416 examples to avoid logging too frequently
skipping logging after 102432 examples to avoid logging too frequently
skipping logging after 102448 examples to avoid logging too frequently
train stats after 102464 examples: {'rewards_train/chosen': '-3.4789', 'rewards_train/rejected': '-12.64', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.1621', 'logps_train/rejected': '-301.87', 'logps_train/chosen': '-71.506', 'loss/train': '0.14856', 'examples_per_second': '5.2773', 'grad_norm': '20.125', 'counters/examples': 102464, 'counters/updates': 6404}
skipping logging after 102480 examples to avoid logging too frequently
skipping logging after 102496 examples to avoid logging too frequently
skipping logging after 102512 examples to avoid logging too frequently
train stats after 102528 examples: {'rewards_train/chosen': '-3.2366', 'rewards_train/rejected': '-12.499', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.2615', 'logps_train/rejected': '-306.87', 'logps_train/chosen': '-84.998', 'loss/train': '0.13267', 'examples_per_second': '4.6409', 'grad_norm': '24.625', 'counters/examples': 102528, 'counters/updates': 6408}
skipping logging after 102544 examples to avoid logging too frequently
skipping logging after 102560 examples to avoid logging too frequently
skipping logging after 102576 examples to avoid logging too frequently
train stats after 102592 examples: {'rewards_train/chosen': '-3.0878', 'rewards_train/rejected': '-11.893', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.8047', 'logps_train/rejected': '-264.07', 'logps_train/chosen': '-76.062', 'loss/train': '0.043197', 'examples_per_second': '4.8847', 'grad_norm': '8.3125', 'counters/examples': 102592, 'counters/updates': 6412}
skipping logging after 102608 examples to avoid logging too frequently
skipping logging after 102624 examples to avoid logging too frequently
skipping logging after 102640 examples to avoid logging too frequently
train stats after 102656 examples: {'rewards_train/chosen': '-3.0052', 'rewards_train/rejected': '-9.4894', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.4838', 'logps_train/rejected': '-213.24', 'logps_train/chosen': '-83.637', 'loss/train': '0.25667', 'examples_per_second': '5.3945', 'grad_norm': '27.75', 'counters/examples': 102656, 'counters/updates': 6416}
skipping logging after 102672 examples to avoid logging too frequently
skipping logging after 102688 examples to avoid logging too frequently
skipping logging after 102704 examples to avoid logging too frequently
train stats after 102720 examples: {'rewards_train/chosen': '-2.6379', 'rewards_train/rejected': '-10.481', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.8444', 'logps_train/rejected': '-284.31', 'logps_train/chosen': '-68.586', 'loss/train': '0.063713', 'examples_per_second': '4.4983', 'grad_norm': '9.125', 'counters/examples': 102720, 'counters/updates': 6420}
skipping logging after 102736 examples to avoid logging too frequently
skipping logging after 102752 examples to avoid logging too frequently
skipping logging after 102768 examples to avoid logging too frequently
train stats after 102784 examples: {'rewards_train/chosen': '-3.0612', 'rewards_train/rejected': '-10.743', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.6792', 'logps_train/rejected': '-225.65', 'logps_train/chosen': '-64.586', 'loss/train': '0.075798', 'examples_per_second': '5.5857', 'grad_norm': '11.375', 'counters/examples': 102784, 'counters/updates': 6424}
skipping logging after 102800 examples to avoid logging too frequently
skipping logging after 102816 examples to avoid logging too frequently
skipping logging after 102832 examples to avoid logging too frequently
train stats after 102848 examples: {'rewards_train/chosen': '-3.3126', 'rewards_train/rejected': '-10.515', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.2031', 'logps_train/rejected': '-223.65', 'logps_train/chosen': '-69.488', 'loss/train': '0.040718', 'examples_per_second': '5.6785', 'grad_norm': '5.75', 'counters/examples': 102848, 'counters/updates': 6428}
skipping logging after 102864 examples to avoid logging too frequently
skipping logging after 102880 examples to avoid logging too frequently
skipping logging after 102896 examples to avoid logging too frequently
train stats after 102912 examples: {'rewards_train/chosen': '-3.4958', 'rewards_train/rejected': '-12.096', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.5996', 'logps_train/rejected': '-252.21', 'logps_train/chosen': '-74.181', 'loss/train': '0.10538', 'examples_per_second': '4.6855', 'grad_norm': '17.25', 'counters/examples': 102912, 'counters/updates': 6432}
skipping logging after 102928 examples to avoid logging too frequently
skipping logging after 102944 examples to avoid logging too frequently
skipping logging after 102960 examples to avoid logging too frequently
train stats after 102976 examples: {'rewards_train/chosen': '-3.5747', 'rewards_train/rejected': '-12.119', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.5415', 'logps_train/rejected': '-258.71', 'logps_train/chosen': '-67.384', 'loss/train': '0.11621', 'examples_per_second': '5.2144', 'grad_norm': '20.125', 'counters/examples': 102976, 'counters/updates': 6436}
skipping logging after 102992 examples to avoid logging too frequently
skipping logging after 103008 examples to avoid logging too frequently
skipping logging after 103024 examples to avoid logging too frequently
train stats after 103040 examples: {'rewards_train/chosen': '-3.3845', 'rewards_train/rejected': '-12.44', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.0569', 'logps_train/rejected': '-283.44', 'logps_train/chosen': '-74.066', 'loss/train': '0.034683', 'examples_per_second': '4.6327', 'grad_norm': '5.9375', 'counters/examples': 103040, 'counters/updates': 6440}
skipping logging after 103056 examples to avoid logging too frequently
skipping logging after 103072 examples to avoid logging too frequently
skipping logging after 103088 examples to avoid logging too frequently
train stats after 103104 examples: {'rewards_train/chosen': '-3.1497', 'rewards_train/rejected': '-11.747', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.6001', 'logps_train/rejected': '-243.52', 'logps_train/chosen': '-68.566', 'loss/train': '0.059347', 'examples_per_second': '6.4447', 'grad_norm': '10.75', 'counters/examples': 103104, 'counters/updates': 6444}
skipping logging after 103120 examples to avoid logging too frequently
skipping logging after 103136 examples to avoid logging too frequently
skipping logging after 103152 examples to avoid logging too frequently
train stats after 103168 examples: {'rewards_train/chosen': '-3.722', 'rewards_train/rejected': '-14.781', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '11.059', 'logps_train/rejected': '-323.06', 'logps_train/chosen': '-82.27', 'loss/train': '0.050377', 'examples_per_second': '4.6191', 'grad_norm': '11.125', 'counters/examples': 103168, 'counters/updates': 6448}
skipping logging after 103184 examples to avoid logging too frequently
skipping logging after 103200 examples to avoid logging too frequently
skipping logging after 103216 examples to avoid logging too frequently
train stats after 103232 examples: {'rewards_train/chosen': '-3.913', 'rewards_train/rejected': '-12.299', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '8.3867', 'logps_train/rejected': '-259.26', 'logps_train/chosen': '-74.354', 'loss/train': '0.31908', 'examples_per_second': '4.5295', 'grad_norm': '25.75', 'counters/examples': 103232, 'counters/updates': 6452}
skipping logging after 103248 examples to avoid logging too frequently
skipping logging after 103264 examples to avoid logging too frequently
skipping logging after 103280 examples to avoid logging too frequently
train stats after 103296 examples: {'rewards_train/chosen': '-3.2877', 'rewards_train/rejected': '-11.433', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.1433', 'logps_train/rejected': '-234.23', 'logps_train/chosen': '-82.318', 'loss/train': '0.044315', 'examples_per_second': '6.0753', 'grad_norm': '4', 'counters/examples': 103296, 'counters/updates': 6456}
skipping logging after 103312 examples to avoid logging too frequently
skipping logging after 103328 examples to avoid logging too frequently
skipping logging after 103344 examples to avoid logging too frequently
train stats after 103360 examples: {'rewards_train/chosen': '-3.6346', 'rewards_train/rejected': '-12.746', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.113', 'logps_train/rejected': '-272.88', 'logps_train/chosen': '-84.631', 'loss/train': '0.033274', 'examples_per_second': '4.2578', 'grad_norm': '10.25', 'counters/examples': 103360, 'counters/updates': 6460}
skipping logging after 103376 examples to avoid logging too frequently
skipping logging after 103392 examples to avoid logging too frequently
skipping logging after 103408 examples to avoid logging too frequently
train stats after 103424 examples: {'rewards_train/chosen': '-3.4763', 'rewards_train/rejected': '-12.395', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.9194', 'logps_train/rejected': '-269.96', 'logps_train/chosen': '-75.1', 'loss/train': '0.025435', 'examples_per_second': '3.9126', 'grad_norm': '5.4375', 'counters/examples': 103424, 'counters/updates': 6464}
skipping logging after 103440 examples to avoid logging too frequently
skipping logging after 103456 examples to avoid logging too frequently
skipping logging after 103472 examples to avoid logging too frequently
train stats after 103488 examples: {'rewards_train/chosen': '-3.0942', 'rewards_train/rejected': '-13.257', 'rewards_train/accuracies': '1', 'rewards_train/margins': '10.157', 'logps_train/rejected': '-305.23', 'logps_train/chosen': '-76.859', 'loss/train': '0.032566', 'examples_per_second': '5.5316', 'grad_norm': '6', 'counters/examples': 103488, 'counters/updates': 6468}
skipping logging after 103504 examples to avoid logging too frequently
skipping logging after 103520 examples to avoid logging too frequently
skipping logging after 103536 examples to avoid logging too frequently
train stats after 103552 examples: {'rewards_train/chosen': '-3.7419', 'rewards_train/rejected': '-10.957', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.2148', 'logps_train/rejected': '-222.45', 'logps_train/chosen': '-71.755', 'loss/train': '0.12612', 'examples_per_second': '6.0389', 'grad_norm': '16.125', 'counters/examples': 103552, 'counters/updates': 6472}
skipping logging after 103568 examples to avoid logging too frequently
skipping logging after 103584 examples to avoid logging too frequently
skipping logging after 103600 examples to avoid logging too frequently
train stats after 103616 examples: {'rewards_train/chosen': '-3.4798', 'rewards_train/rejected': '-10.719', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.2378', 'logps_train/rejected': '-218.82', 'logps_train/chosen': '-72.856', 'loss/train': '0.046046', 'examples_per_second': '4.9153', 'grad_norm': '7.375', 'counters/examples': 103616, 'counters/updates': 6476}
skipping logging after 103632 examples to avoid logging too frequently
skipping logging after 103648 examples to avoid logging too frequently
skipping logging after 103664 examples to avoid logging too frequently
train stats after 103680 examples: {'rewards_train/chosen': '-3.3724', 'rewards_train/rejected': '-13.13', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.7539', 'logps_train/rejected': '-290.93', 'logps_train/chosen': '-77.994', 'loss/train': '0.066097', 'examples_per_second': '5.8706', 'grad_norm': '17', 'counters/examples': 103680, 'counters/updates': 6480}
skipping logging after 103696 examples to avoid logging too frequently
skipping logging after 103712 examples to avoid logging too frequently
skipping logging after 103728 examples to avoid logging too frequently
train stats after 103744 examples: {'rewards_train/chosen': '-3.7684', 'rewards_train/rejected': '-11.713', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.9412', 'logps_train/rejected': '-274.96', 'logps_train/chosen': '-84.44', 'loss/train': '0.15447', 'examples_per_second': '4.1355', 'grad_norm': '17.25', 'counters/examples': 103744, 'counters/updates': 6484}
skipping logging after 103760 examples to avoid logging too frequently
skipping logging after 103776 examples to avoid logging too frequently
skipping logging after 103792 examples to avoid logging too frequently
train stats after 103808 examples: {'rewards_train/chosen': '-2.8443', 'rewards_train/rejected': '-10.241', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.394', 'logps_train/rejected': '-214.56', 'logps_train/chosen': '-67.251', 'loss/train': '0.06621', 'examples_per_second': '5.8508', 'grad_norm': '8.9375', 'counters/examples': 103808, 'counters/updates': 6488}
skipping logging after 103824 examples to avoid logging too frequently
skipping logging after 103840 examples to avoid logging too frequently
skipping logging after 103856 examples to avoid logging too frequently
train stats after 103872 examples: {'rewards_train/chosen': '-4.0597', 'rewards_train/rejected': '-11.129', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.0691', 'logps_train/rejected': '-244.4', 'logps_train/chosen': '-81.17', 'loss/train': '0.14179', 'examples_per_second': '5.8742', 'grad_norm': '25.25', 'counters/examples': 103872, 'counters/updates': 6492}
skipping logging after 103888 examples to avoid logging too frequently
skipping logging after 103904 examples to avoid logging too frequently
skipping logging after 103920 examples to avoid logging too frequently
train stats after 103936 examples: {'rewards_train/chosen': '-3.3799', 'rewards_train/rejected': '-11.093', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.7124', 'logps_train/rejected': '-252.58', 'logps_train/chosen': '-69.661', 'loss/train': '0.096971', 'examples_per_second': '4.8639', 'grad_norm': '14', 'counters/examples': 103936, 'counters/updates': 6496}
skipping logging after 103952 examples to avoid logging too frequently
skipping logging after 103968 examples to avoid logging too frequently
skipping logging after 103984 examples to avoid logging too frequently
train stats after 104000 examples: {'rewards_train/chosen': '-4.2203', 'rewards_train/rejected': '-13.346', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '9.125', 'logps_train/rejected': '-273.71', 'logps_train/chosen': '-81.488', 'loss/train': '0.040841', 'examples_per_second': '4.4121', 'grad_norm': '7.5', 'counters/examples': 104000, 'counters/updates': 6500}
Running evaluation after 104000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<01:00,  1.94s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:00,  2.01s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:53,  1.84s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.86s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.52s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.50s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:22,  1.30s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.24s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.33s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.34s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:14,  1.27s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.30s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.26s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.30s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.48s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.42s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.62s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.42s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.42s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 104000: {'rewards_eval/chosen': '-12.927', 'rewards_eval/rejected': '-13.505', 'rewards_eval/accuracies': '0.50977', 'rewards_eval/margins': '0.57761', 'logps_eval/rejected': '-282.71', 'logps_eval/chosen': '-274.2', 'loss/eval': '2.1648'}
skipping logging after 104016 examples to avoid logging too frequently
skipping logging after 104032 examples to avoid logging too frequently
skipping logging after 104048 examples to avoid logging too frequently
train stats after 104064 examples: {'rewards_train/chosen': '-3.9495', 'rewards_train/rejected': '-13.871', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.9229', 'logps_train/rejected': '-331.67', 'logps_train/chosen': '-77.818', 'loss/train': '0.073888', 'examples_per_second': '4.8841', 'grad_norm': '13.625', 'counters/examples': 104064, 'counters/updates': 6504}
skipping logging after 104080 examples to avoid logging too frequently
skipping logging after 104096 examples to avoid logging too frequently
skipping logging after 104112 examples to avoid logging too frequently
train stats after 104128 examples: {'rewards_train/chosen': '-3.82', 'rewards_train/rejected': '-12.859', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '9.0364', 'logps_train/rejected': '-273.4', 'logps_train/chosen': '-78.2', 'loss/train': '0.045595', 'examples_per_second': '5.3856', 'grad_norm': '5.375', 'counters/examples': 104128, 'counters/updates': 6508}
skipping logging after 104144 examples to avoid logging too frequently
skipping logging after 104160 examples to avoid logging too frequently
skipping logging after 104176 examples to avoid logging too frequently
train stats after 104192 examples: {'rewards_train/chosen': '-3.867', 'rewards_train/rejected': '-12.207', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.339', 'logps_train/rejected': '-268.31', 'logps_train/chosen': '-81.688', 'loss/train': '0.030468', 'examples_per_second': '4.824', 'grad_norm': '3.5156', 'counters/examples': 104192, 'counters/updates': 6512}
skipping logging after 104208 examples to avoid logging too frequently
skipping logging after 104224 examples to avoid logging too frequently
skipping logging after 104240 examples to avoid logging too frequently
train stats after 104256 examples: {'rewards_train/chosen': '-3.9497', 'rewards_train/rejected': '-12.176', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.2256', 'logps_train/rejected': '-271.32', 'logps_train/chosen': '-80.398', 'loss/train': '0.067264', 'examples_per_second': '5.2972', 'grad_norm': '7.6562', 'counters/examples': 104256, 'counters/updates': 6516}
skipping logging after 104272 examples to avoid logging too frequently
skipping logging after 104288 examples to avoid logging too frequently
skipping logging after 104304 examples to avoid logging too frequently
train stats after 104320 examples: {'rewards_train/chosen': '-3.5584', 'rewards_train/rejected': '-12.624', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.063', 'logps_train/rejected': '-269.96', 'logps_train/chosen': '-78.241', 'loss/train': '0.094785', 'examples_per_second': '5.0322', 'grad_norm': '14.562', 'counters/examples': 104320, 'counters/updates': 6520}
skipping logging after 104336 examples to avoid logging too frequently
skipping logging after 104352 examples to avoid logging too frequently
skipping logging after 104368 examples to avoid logging too frequently
train stats after 104384 examples: {'rewards_train/chosen': '-3.5128', 'rewards_train/rejected': '-12.186', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.6738', 'logps_train/rejected': '-257.86', 'logps_train/chosen': '-74.031', 'loss/train': '0.07563', 'examples_per_second': '5.6331', 'grad_norm': '11', 'counters/examples': 104384, 'counters/updates': 6524}
skipping logging after 104400 examples to avoid logging too frequently
skipping logging after 104416 examples to avoid logging too frequently
skipping logging after 104432 examples to avoid logging too frequently
train stats after 104448 examples: {'rewards_train/chosen': '-3.6181', 'rewards_train/rejected': '-12.105', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.4829', 'logps_train/rejected': '-243.76', 'logps_train/chosen': '-81.126', 'loss/train': '0.034589', 'examples_per_second': '5.4342', 'grad_norm': '8.375', 'counters/examples': 104448, 'counters/updates': 6528}
skipping logging after 104464 examples to avoid logging too frequently
skipping logging after 104480 examples to avoid logging too frequently
skipping logging after 104496 examples to avoid logging too frequently
train stats after 104512 examples: {'rewards_train/chosen': '-4.0846', 'rewards_train/rejected': '-12.284', 'rewards_train/accuracies': '0.89062', 'rewards_train/margins': '8.1982', 'logps_train/rejected': '-251.08', 'logps_train/chosen': '-80.01', 'loss/train': '0.17999', 'examples_per_second': '4.9043', 'grad_norm': '14.75', 'counters/examples': 104512, 'counters/updates': 6532}
skipping logging after 104528 examples to avoid logging too frequently
skipping logging after 104544 examples to avoid logging too frequently
skipping logging after 104560 examples to avoid logging too frequently
train stats after 104576 examples: {'rewards_train/chosen': '-3.8817', 'rewards_train/rejected': '-11.509', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.6272', 'logps_train/rejected': '-242.8', 'logps_train/chosen': '-74.984', 'loss/train': '0.12158', 'examples_per_second': '5.4502', 'grad_norm': '20.75', 'counters/examples': 104576, 'counters/updates': 6536}
skipping logging after 104592 examples to avoid logging too frequently
skipping logging after 104608 examples to avoid logging too frequently
skipping logging after 104624 examples to avoid logging too frequently
train stats after 104640 examples: {'rewards_train/chosen': '-3.011', 'rewards_train/rejected': '-11.38', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.3662', 'logps_train/rejected': '-252.21', 'logps_train/chosen': '-83.699', 'loss/train': '0.037377', 'examples_per_second': '5.6141', 'grad_norm': '3.2344', 'counters/examples': 104640, 'counters/updates': 6540}
skipping logging after 104656 examples to avoid logging too frequently
skipping logging after 104672 examples to avoid logging too frequently
skipping logging after 104688 examples to avoid logging too frequently
train stats after 104704 examples: {'rewards_train/chosen': '-3.2902', 'rewards_train/rejected': '-11.335', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.0432', 'logps_train/rejected': '-268.21', 'logps_train/chosen': '-77.955', 'loss/train': '0.10437', 'examples_per_second': '5.1047', 'grad_norm': '14.438', 'counters/examples': 104704, 'counters/updates': 6544}
skipping logging after 104720 examples to avoid logging too frequently
skipping logging after 104736 examples to avoid logging too frequently
skipping logging after 104752 examples to avoid logging too frequently
train stats after 104768 examples: {'rewards_train/chosen': '-3.8104', 'rewards_train/rejected': '-12.132', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '8.3225', 'logps_train/rejected': '-268.19', 'logps_train/chosen': '-76.537', 'loss/train': '0.11413', 'examples_per_second': '4.9448', 'grad_norm': '12', 'counters/examples': 104768, 'counters/updates': 6548}
skipping logging after 104784 examples to avoid logging too frequently
skipping logging after 104800 examples to avoid logging too frequently
skipping logging after 104816 examples to avoid logging too frequently
train stats after 104832 examples: {'rewards_train/chosen': '-3.2637', 'rewards_train/rejected': '-10.896', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.6293', 'logps_train/rejected': '-257.41', 'logps_train/chosen': '-72.986', 'loss/train': '0.067623', 'examples_per_second': '5.2032', 'grad_norm': '10.75', 'counters/examples': 104832, 'counters/updates': 6552}
skipping logging after 104848 examples to avoid logging too frequently
skipping logging after 104864 examples to avoid logging too frequently
skipping logging after 104880 examples to avoid logging too frequently
train stats after 104896 examples: {'rewards_train/chosen': '-3.9588', 'rewards_train/rejected': '-13.721', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.7651', 'logps_train/rejected': '-284.42', 'logps_train/chosen': '-78.404', 'loss/train': '0.044373', 'examples_per_second': '5.0896', 'grad_norm': '8.9375', 'counters/examples': 104896, 'counters/updates': 6556}
skipping logging after 104912 examples to avoid logging too frequently
skipping logging after 104928 examples to avoid logging too frequently
skipping logging after 104944 examples to avoid logging too frequently
train stats after 104960 examples: {'rewards_train/chosen': '-4.1254', 'rewards_train/rejected': '-12.479', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.356', 'logps_train/rejected': '-241.93', 'logps_train/chosen': '-82.951', 'loss/train': '0.080641', 'examples_per_second': '5.5585', 'grad_norm': '14.938', 'counters/examples': 104960, 'counters/updates': 6560}
skipping logging after 104976 examples to avoid logging too frequently
skipping logging after 104992 examples to avoid logging too frequently
skipping logging after 105008 examples to avoid logging too frequently
train stats after 105024 examples: {'rewards_train/chosen': '-3.731', 'rewards_train/rejected': '-14.188', 'rewards_train/accuracies': '1', 'rewards_train/margins': '10.46', 'logps_train/rejected': '-332.71', 'logps_train/chosen': '-82.33', 'loss/train': '0.01688', 'examples_per_second': '4.4399', 'grad_norm': '3.9844', 'counters/examples': 105024, 'counters/updates': 6564}
skipping logging after 105040 examples to avoid logging too frequently
skipping logging after 105056 examples to avoid logging too frequently
skipping logging after 105072 examples to avoid logging too frequently
train stats after 105088 examples: {'rewards_train/chosen': '-4.077', 'rewards_train/rejected': '-13.142', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.0635', 'logps_train/rejected': '-273.62', 'logps_train/chosen': '-74.744', 'loss/train': '0.1288', 'examples_per_second': '5.4984', 'grad_norm': '23.5', 'counters/examples': 105088, 'counters/updates': 6568}
skipping logging after 105104 examples to avoid logging too frequently
skipping logging after 105120 examples to avoid logging too frequently
skipping logging after 105136 examples to avoid logging too frequently
train stats after 105152 examples: {'rewards_train/chosen': '-3.7905', 'rewards_train/rejected': '-12.953', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.1636', 'logps_train/rejected': '-267.38', 'logps_train/chosen': '-81.475', 'loss/train': '0.046572', 'examples_per_second': '4.2179', 'grad_norm': '10.438', 'counters/examples': 105152, 'counters/updates': 6572}
skipping logging after 105168 examples to avoid logging too frequently
skipping logging after 105184 examples to avoid logging too frequently
skipping logging after 105200 examples to avoid logging too frequently
train stats after 105216 examples: {'rewards_train/chosen': '-3.2182', 'rewards_train/rejected': '-11.335', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1189', 'logps_train/rejected': '-250.41', 'logps_train/chosen': '-70.65', 'loss/train': '0.073046', 'examples_per_second': '4.3928', 'grad_norm': '13.562', 'counters/examples': 105216, 'counters/updates': 6576}
skipping logging after 105232 examples to avoid logging too frequently
skipping logging after 105248 examples to avoid logging too frequently
skipping logging after 105264 examples to avoid logging too frequently
train stats after 105280 examples: {'rewards_train/chosen': '-3.27', 'rewards_train/rejected': '-11.941', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.673', 'logps_train/rejected': '-252.57', 'logps_train/chosen': '-80.861', 'loss/train': '0.066874', 'examples_per_second': '5.4424', 'grad_norm': '8', 'counters/examples': 105280, 'counters/updates': 6580}
skipping logging after 105296 examples to avoid logging too frequently
skipping logging after 105312 examples to avoid logging too frequently
skipping logging after 105328 examples to avoid logging too frequently
train stats after 105344 examples: {'rewards_train/chosen': '-2.9557', 'rewards_train/rejected': '-11.132', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.1775', 'logps_train/rejected': '-232.65', 'logps_train/chosen': '-69.037', 'loss/train': '0.049963', 'examples_per_second': '4.5574', 'grad_norm': '4', 'counters/examples': 105344, 'counters/updates': 6584}
skipping logging after 105360 examples to avoid logging too frequently
skipping logging after 105376 examples to avoid logging too frequently
skipping logging after 105392 examples to avoid logging too frequently
train stats after 105408 examples: {'rewards_train/chosen': '-3.4159', 'rewards_train/rejected': '-11.08', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.6658', 'logps_train/rejected': '-229.7', 'logps_train/chosen': '-75.256', 'loss/train': '0.075754', 'examples_per_second': '4.4552', 'grad_norm': '7.8125', 'counters/examples': 105408, 'counters/updates': 6588}
skipping logging after 105424 examples to avoid logging too frequently
skipping logging after 105440 examples to avoid logging too frequently
skipping logging after 105456 examples to avoid logging too frequently
train stats after 105472 examples: {'rewards_train/chosen': '-3.2118', 'rewards_train/rejected': '-12.545', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.3352', 'logps_train/rejected': '-278.39', 'logps_train/chosen': '-80.136', 'loss/train': '0.030751', 'examples_per_second': '5.8455', 'grad_norm': '7.7812', 'counters/examples': 105472, 'counters/updates': 6592}
skipping logging after 105488 examples to avoid logging too frequently
skipping logging after 105504 examples to avoid logging too frequently
skipping logging after 105520 examples to avoid logging too frequently
train stats after 105536 examples: {'rewards_train/chosen': '-3.5738', 'rewards_train/rejected': '-11.873', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.2949', 'logps_train/rejected': '-263.62', 'logps_train/chosen': '-69.434', 'loss/train': '0.082053', 'examples_per_second': '5.2801', 'grad_norm': '10.75', 'counters/examples': 105536, 'counters/updates': 6596}
skipping logging after 105552 examples to avoid logging too frequently
skipping logging after 105568 examples to avoid logging too frequently
skipping logging after 105584 examples to avoid logging too frequently
train stats after 105600 examples: {'rewards_train/chosen': '-3.5635', 'rewards_train/rejected': '-12.606', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.0427', 'logps_train/rejected': '-256.16', 'logps_train/chosen': '-80.26', 'loss/train': '0.035902', 'examples_per_second': '5.1783', 'grad_norm': '3.4531', 'counters/examples': 105600, 'counters/updates': 6600}
skipping logging after 105616 examples to avoid logging too frequently
skipping logging after 105632 examples to avoid logging too frequently
skipping logging after 105648 examples to avoid logging too frequently
train stats after 105664 examples: {'rewards_train/chosen': '-4.0164', 'rewards_train/rejected': '-11.916', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '7.9001', 'logps_train/rejected': '-276.3', 'logps_train/chosen': '-89.676', 'loss/train': '0.16265', 'examples_per_second': '4.8118', 'grad_norm': '15.75', 'counters/examples': 105664, 'counters/updates': 6604}
skipping logging after 105680 examples to avoid logging too frequently
skipping logging after 105696 examples to avoid logging too frequently
skipping logging after 105712 examples to avoid logging too frequently
train stats after 105728 examples: {'rewards_train/chosen': '-3.0896', 'rewards_train/rejected': '-11.092', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.0039', 'logps_train/rejected': '-219.93', 'logps_train/chosen': '-70.871', 'loss/train': '0.10642', 'examples_per_second': '5.4375', 'grad_norm': '9.875', 'counters/examples': 105728, 'counters/updates': 6608}
skipping logging after 105744 examples to avoid logging too frequently
skipping logging after 105760 examples to avoid logging too frequently
skipping logging after 105776 examples to avoid logging too frequently
train stats after 105792 examples: {'rewards_train/chosen': '-3.3186', 'rewards_train/rejected': '-11.745', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.4243', 'logps_train/rejected': '-247.02', 'logps_train/chosen': '-70.753', 'loss/train': '0.041496', 'examples_per_second': '5.5432', 'grad_norm': '8.25', 'counters/examples': 105792, 'counters/updates': 6612}
skipping logging after 105808 examples to avoid logging too frequently
skipping logging after 105824 examples to avoid logging too frequently
skipping logging after 105840 examples to avoid logging too frequently
train stats after 105856 examples: {'rewards_train/chosen': '-3.1884', 'rewards_train/rejected': '-12.454', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.2678', 'logps_train/rejected': '-258.94', 'logps_train/chosen': '-67.672', 'loss/train': '0.066333', 'examples_per_second': '4.8019', 'grad_norm': '7.375', 'counters/examples': 105856, 'counters/updates': 6616}
skipping logging after 105872 examples to avoid logging too frequently
skipping logging after 105888 examples to avoid logging too frequently
skipping logging after 105904 examples to avoid logging too frequently
train stats after 105920 examples: {'rewards_train/chosen': '-3.1864', 'rewards_train/rejected': '-11.282', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.0952', 'logps_train/rejected': '-259.5', 'logps_train/chosen': '-76.713', 'loss/train': '0.053111', 'examples_per_second': '4.8365', 'grad_norm': '9.625', 'counters/examples': 105920, 'counters/updates': 6620}
skipping logging after 105936 examples to avoid logging too frequently
skipping logging after 105952 examples to avoid logging too frequently
skipping logging after 105968 examples to avoid logging too frequently
train stats after 105984 examples: {'rewards_train/chosen': '-3.5345', 'rewards_train/rejected': '-12.65', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '9.1174', 'logps_train/rejected': '-261.63', 'logps_train/chosen': '-74.035', 'loss/train': '0.08204', 'examples_per_second': '4.4489', 'grad_norm': '9.375', 'counters/examples': 105984, 'counters/updates': 6624}
skipping logging after 106000 examples to avoid logging too frequently
skipping logging after 106016 examples to avoid logging too frequently
skipping logging after 106032 examples to avoid logging too frequently
train stats after 106048 examples: {'rewards_train/chosen': '-3.2501', 'rewards_train/rejected': '-12.368', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.1135', 'logps_train/rejected': '-244.16', 'logps_train/chosen': '-73.686', 'loss/train': '0.058895', 'examples_per_second': '5.0689', 'grad_norm': '9.875', 'counters/examples': 106048, 'counters/updates': 6628}
skipping logging after 106064 examples to avoid logging too frequently
skipping logging after 106080 examples to avoid logging too frequently
skipping logging after 106096 examples to avoid logging too frequently
train stats after 106112 examples: {'rewards_train/chosen': '-3.3419', 'rewards_train/rejected': '-11.55', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.2036', 'logps_train/rejected': '-245.18', 'logps_train/chosen': '-71.808', 'loss/train': '0.17159', 'examples_per_second': '4.983', 'grad_norm': '21.25', 'counters/examples': 106112, 'counters/updates': 6632}
skipping logging after 106128 examples to avoid logging too frequently
skipping logging after 106144 examples to avoid logging too frequently
skipping logging after 106160 examples to avoid logging too frequently
train stats after 106176 examples: {'rewards_train/chosen': '-3.2702', 'rewards_train/rejected': '-13.999', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '10.728', 'logps_train/rejected': '-284.33', 'logps_train/chosen': '-68.47', 'loss/train': '0.11588', 'examples_per_second': '4.7576', 'grad_norm': '17', 'counters/examples': 106176, 'counters/updates': 6636}
skipping logging after 106192 examples to avoid logging too frequently
skipping logging after 106208 examples to avoid logging too frequently
skipping logging after 106224 examples to avoid logging too frequently
train stats after 106240 examples: {'rewards_train/chosen': '-3.1806', 'rewards_train/rejected': '-11.665', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.4856', 'logps_train/rejected': '-264.21', 'logps_train/chosen': '-70.667', 'loss/train': '0.062445', 'examples_per_second': '4.4383', 'grad_norm': '11.688', 'counters/examples': 106240, 'counters/updates': 6640}
skipping logging after 106256 examples to avoid logging too frequently
skipping logging after 106272 examples to avoid logging too frequently
skipping logging after 106288 examples to avoid logging too frequently
train stats after 106304 examples: {'rewards_train/chosen': '-3.6011', 'rewards_train/rejected': '-11.838', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.2378', 'logps_train/rejected': '-241.27', 'logps_train/chosen': '-68.639', 'loss/train': '0.058636', 'examples_per_second': '5.6612', 'grad_norm': '13.688', 'counters/examples': 106304, 'counters/updates': 6644}
skipping logging after 106320 examples to avoid logging too frequently
skipping logging after 106336 examples to avoid logging too frequently
skipping logging after 106352 examples to avoid logging too frequently
train stats after 106368 examples: {'rewards_train/chosen': '-3.4861', 'rewards_train/rejected': '-11.77', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.2869', 'logps_train/rejected': '-259.47', 'logps_train/chosen': '-73.32', 'loss/train': '0.13269', 'examples_per_second': '4.2534', 'grad_norm': '14', 'counters/examples': 106368, 'counters/updates': 6648}
skipping logging after 106384 examples to avoid logging too frequently
skipping logging after 106400 examples to avoid logging too frequently
skipping logging after 106416 examples to avoid logging too frequently
train stats after 106432 examples: {'rewards_train/chosen': '-3.0201', 'rewards_train/rejected': '-13.309', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '10.29', 'logps_train/rejected': '-289.48', 'logps_train/chosen': '-62.115', 'loss/train': '0.058159', 'examples_per_second': '5.532', 'grad_norm': '13.25', 'counters/examples': 106432, 'counters/updates': 6652}
skipping logging after 106448 examples to avoid logging too frequently
skipping logging after 106464 examples to avoid logging too frequently
skipping logging after 106480 examples to avoid logging too frequently
train stats after 106496 examples: {'rewards_train/chosen': '-3.0719', 'rewards_train/rejected': '-11.165', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.0967', 'logps_train/rejected': '-244.02', 'logps_train/chosen': '-72.704', 'loss/train': '0.21303', 'examples_per_second': '4.6381', 'grad_norm': '20.375', 'counters/examples': 106496, 'counters/updates': 6656}
skipping logging after 106512 examples to avoid logging too frequently
skipping logging after 106528 examples to avoid logging too frequently
skipping logging after 106544 examples to avoid logging too frequently
train stats after 106560 examples: {'rewards_train/chosen': '-3.403', 'rewards_train/rejected': '-11.398', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.9972', 'logps_train/rejected': '-257.46', 'logps_train/chosen': '-67.627', 'loss/train': '0.066595', 'examples_per_second': '5.4695', 'grad_norm': '7.4688', 'counters/examples': 106560, 'counters/updates': 6660}
