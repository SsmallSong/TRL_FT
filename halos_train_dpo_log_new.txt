4
/home/wxt/.conda/envs/halos3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Making experiment directory /home/wxt/.cache/huggingface/hub/llama2_7b_dpo_halos_2
no FSDP port specified; using open port for FSDP: 52167
seed: 1
exp_name: llama2_7b_dpo_halos_2
datasets:
- hh
mode: train
debug: false
use_fsdp: true
fsdp_port: 52167
wandb:
  enabled: true
  entity: null
  project: archangel
cache_dir: /home/wxt/.cache/huggingface/hub
local_run_dir: /home/wxt/.cache/huggingface/hub/llama2_7b_dpo_halos_2
do_first_eval: true
minimum_log_interval_secs: 1.0
intermediate_checkpoints: false
trainer: DPOTrainer
lr: 1.0e-05
n_epochs: 1
n_examples: null
optimizer: RMSprop
warmup_steps: 150
eval_every: 4000
n_samples: 128
samples_dir: samples/
n_eval_examples: 512
saved_policy: /home/wxt/.cache/huggingface/hub/llama2_7b_dpo_halos_2/LATEST/policy.pt
top_p: 0.95
human_prefix: '

  <|user|>

  '
assistant_prefix: '

  <|assistant|>

  '
human_suffix: ''
assistant_suffix: ''
frac_unique_desirable: 1.0
frac_unique_undesirable: 1.0
model:
  name_or_path: daryl149/llama-2-7b-hf
  tokenizer_name_or_path: null
  load_from: /home/wxt/.cache/huggingface/hub/llama2_7b_sft_halos_2_3/LATEST/policy.pt
  block_name: LlamaDecoderLayer
  policy_dtype: bfloat16
  fsdp_policy_mp: null
  reference_dtype: bfloat16
  max_grad_norm: 10.0
  v_head_max_grad_norm: 0.1
  max_length: 1024
  max_prompt_length: 512
  activation_checkpointing: true
  batch_size: 16
  gradient_accumulation_steps: 4
  eval_batch_size: 16
  use_flash_attention: false
loss:
  name: dpo
  beta: 0.1
  trainer: DPOTrainer
  dataloader: PairedPreferenceDataLoader
  use_reference_model: true

================================================================================
Writing to design-agent-09:/home/wxt/.cache/huggingface/hub/llama2_7b_dpo_halos_2
================================================================================
building policy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.68s/it]
building reference model
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]
loading pre-trained weights at step 159968 from /home/wxt/.cache/huggingface/hub/llama2_7b_sft_halos_2_3/LATEST/policy.pt with metrics {}
loaded pre-trained weights
Loading tokenizer daryl149/llama-2-7b-hf
0 special tokens added
Loading HH dataset (train split) from Huggingface...
Processing HH:   0%|          | 0/160800 [00:00<?, ?it/s]Processing HH:   1%|          | 1484/160800 [00:00<00:10, 14836.76it/s]Processing HH:   2%|▏         | 2968/160800 [00:00<00:10, 14432.00it/s]Processing HH:   3%|▎         | 4506/160800 [00:00<00:10, 14857.33it/s]Processing HH:   4%|▎         | 6025/160800 [00:00<00:10, 14982.36it/s]Processing HH:   5%|▍         | 7524/160800 [00:00<00:10, 14962.71it/s]Processing HH:   6%|▌         | 9021/160800 [00:00<00:10, 14940.31it/s]Processing HH:   7%|▋         | 10530/160800 [00:00<00:10, 14988.66it/s]Processing HH:   7%|▋         | 12034/160800 [00:00<00:09, 15004.42it/s]Processing HH:   8%|▊         | 13567/160800 [00:00<00:09, 15105.82it/s]Processing HH:   9%|▉         | 15078/160800 [00:01<00:14, 9755.95it/s] Processing HH:  10%|█         | 16616/160800 [00:01<00:13, 10999.60it/s]Processing HH:  11%|█▏        | 18116/160800 [00:01<00:11, 11959.52it/s]Processing HH:  12%|█▏        | 19558/160800 [00:01<00:11, 12586.76it/s]Processing HH:  13%|█▎        | 21064/160800 [00:01<00:10, 13246.64it/s]Processing HH:  14%|█▍        | 22546/160800 [00:01<00:10, 13679.77it/s]Processing HH:  15%|█▍        | 24036/160800 [00:01<00:09, 14024.08it/s]Processing HH:  16%|█▌        | 25498/160800 [00:01<00:09, 14194.28it/s]Processing HH:  17%|█▋        | 27022/160800 [00:01<00:09, 14497.02it/s]Processing HH:  18%|█▊        | 28500/160800 [00:02<00:09, 14558.63it/s]Processing HH:  19%|█▊        | 29976/160800 [00:02<00:09, 14414.01it/s]Processing HH:  20%|█▉        | 31448/160800 [00:02<00:08, 14503.08it/s]Processing HH:  20%|██        | 32944/160800 [00:02<00:08, 14635.37it/s]Processing HH:  21%|██▏       | 34415/160800 [00:02<00:13, 9208.35it/s] Processing HH:  22%|██▏       | 35920/160800 [00:02<00:11, 10436.16it/s]Processing HH:  23%|██▎       | 37340/160800 [00:02<00:10, 11303.15it/s]Processing HH:  24%|██▍       | 38710/160800 [00:02<00:10, 11896.81it/s]Processing HH:  25%|██▍       | 40188/160800 [00:03<00:09, 12650.14it/s]Processing HH:  26%|██▌       | 41588/160800 [00:03<00:09, 13015.54it/s]Processing HH:  27%|██▋       | 43047/160800 [00:03<00:08, 13454.84it/s]Processing HH:  28%|██▊       | 44453/160800 [00:03<00:08, 13596.55it/s]Processing HH:  29%|██▊       | 45864/160800 [00:03<00:08, 13743.59it/s]Processing HH:  29%|██▉       | 47269/160800 [00:03<00:08, 13733.17it/s]Processing HH:  30%|███       | 48664/160800 [00:03<00:08, 13779.85it/s]Processing HH:  31%|███       | 50058/160800 [00:03<00:08, 13709.28it/s]Processing HH:  32%|███▏      | 51443/160800 [00:03<00:07, 13750.30it/s]Processing HH:  33%|███▎      | 52857/160800 [00:03<00:07, 13861.89it/s]Processing HH:  34%|███▍      | 54276/160800 [00:04<00:07, 13956.47it/s]Processing HH:  35%|███▍      | 55676/160800 [00:04<00:07, 13752.89it/s]Processing HH:  35%|███▌      | 57069/160800 [00:04<00:07, 13800.94it/s]Processing HH:  36%|███▋      | 58452/160800 [00:04<00:13, 7325.23it/s] Processing HH:  37%|███▋      | 59849/160800 [00:04<00:11, 8544.02it/s]Processing HH:  38%|███▊      | 61203/160800 [00:04<00:10, 9581.25it/s]Processing HH:  39%|███▉      | 62585/160800 [00:04<00:09, 10550.25it/s]Processing HH:  40%|███▉      | 63952/160800 [00:05<00:08, 11317.68it/s]Processing HH:  41%|████      | 65253/160800 [00:05<00:08, 11748.76it/s]Processing HH:  41%|████▏     | 66666/160800 [00:05<00:07, 12391.80it/s]Processing HH:  42%|████▏     | 68042/160800 [00:05<00:07, 12773.11it/s]Processing HH:  43%|████▎     | 69420/160800 [00:05<00:06, 13057.13it/s]Processing HH:  44%|████▍     | 70796/160800 [00:05<00:06, 13260.08it/s]Processing HH:  45%|████▍     | 72210/160800 [00:05<00:06, 13515.90it/s]Processing HH:  46%|████▌     | 73615/160800 [00:05<00:06, 13668.43it/s]Processing HH:  47%|████▋     | 75000/160800 [00:05<00:06, 13613.83it/s]Processing HH:  47%|████▋     | 76375/160800 [00:06<00:06, 13615.38it/s]Processing HH:  48%|████▊     | 77773/160800 [00:06<00:06, 13722.34it/s]Processing HH:  49%|████▉     | 79152/160800 [00:06<00:06, 13340.41it/s]Processing HH:  50%|█████     | 80545/160800 [00:06<00:05, 13510.30it/s]Processing HH:  51%|█████     | 81943/160800 [00:06<00:05, 13647.59it/s]Processing HH:  52%|█████▏    | 83347/160800 [00:06<00:05, 13762.88it/s]Processing HH:  53%|█████▎    | 84738/160800 [00:06<00:05, 13804.55it/s]Processing HH:  54%|█████▎    | 86139/160800 [00:06<00:05, 13863.77it/s]Processing HH:  54%|█████▍    | 87527/160800 [00:07<00:08, 8351.05it/s] Processing HH:  55%|█████▌    | 88629/160800 [00:07<00:08, 8249.82it/s]Processing HH:  56%|█████▌    | 89639/160800 [00:07<00:08, 8273.75it/s]Processing HH:  56%|█████▋    | 90597/160800 [00:07<00:08, 8258.80it/s]Processing HH:  57%|█████▋    | 91514/160800 [00:07<00:08, 8264.04it/s]Processing HH:  57%|█████▋    | 92404/160800 [00:07<00:08, 8360.82it/s]Processing HH:  58%|█████▊    | 93287/160800 [00:07<00:08, 8325.79it/s]Processing HH:  59%|█████▊    | 94152/160800 [00:07<00:07, 8334.19it/s]Processing HH:  59%|█████▉    | 95008/160800 [00:07<00:07, 8330.41it/s]Processing HH:  60%|█████▉    | 95857/160800 [00:08<00:07, 8253.38it/s]Processing HH:  60%|██████    | 96694/160800 [00:08<00:07, 8285.39it/s]Processing HH:  61%|██████    | 97531/160800 [00:08<00:07, 8295.34it/s]Processing HH:  61%|██████    | 98366/160800 [00:08<00:07, 8243.72it/s]Processing HH:  62%|██████▏   | 99195/160800 [00:08<00:07, 8178.33it/s]Processing HH:  62%|██████▏   | 100016/160800 [00:08<00:07, 8147.75it/s]Processing HH:  63%|██████▎   | 100833/160800 [00:08<00:07, 8124.75it/s]Processing HH:  63%|██████▎   | 101652/160800 [00:08<00:07, 8142.66it/s]Processing HH:  64%|██████▍   | 102518/160800 [00:08<00:07, 8293.73it/s]Processing HH:  64%|██████▍   | 103357/160800 [00:08<00:06, 8321.27it/s]Processing HH:  65%|██████▍   | 104196/160800 [00:09<00:06, 8340.35it/s]Processing HH:  65%|██████▌   | 105031/160800 [00:09<00:06, 8125.93it/s]Processing HH:  66%|██████▌   | 105887/160800 [00:09<00:06, 8249.38it/s]Processing HH:  66%|██████▋   | 106714/160800 [00:09<00:06, 8188.25it/s]Processing HH:  67%|██████▋   | 107534/160800 [00:09<00:06, 8155.54it/s]Processing HH:  67%|██████▋   | 108358/160800 [00:09<00:06, 8176.51it/s]Processing HH:  68%|██████▊   | 109584/160800 [00:09<00:05, 9388.21it/s]Processing HH:  69%|██████▉   | 110815/160800 [00:09<00:04, 10256.66it/s]Processing HH:  70%|██████▉   | 112035/160800 [00:09<00:04, 10830.41it/s]Processing HH:  70%|███████   | 113225/160800 [00:09<00:04, 11148.76it/s]Processing HH:  71%|███████   | 114409/160800 [00:10<00:04, 11351.56it/s]Processing HH:  72%|███████▏  | 115617/160800 [00:10<00:03, 11567.21it/s]Processing HH:  73%|███████▎  | 116836/160800 [00:10<00:03, 11751.18it/s]Processing HH:  73%|███████▎  | 118081/160800 [00:10<00:03, 11958.18it/s]Processing HH:  74%|███████▍  | 119295/160800 [00:10<00:03, 12007.27it/s]Processing HH:  75%|███████▍  | 120538/160800 [00:10<00:03, 12133.25it/s]Processing HH:  76%|███████▌  | 121770/160800 [00:10<00:03, 12188.16it/s]Processing HH:  76%|███████▋  | 122989/160800 [00:10<00:04, 7769.43it/s] Processing HH:  77%|███████▋  | 124184/160800 [00:11<00:04, 8662.72it/s]Processing HH:  78%|███████▊  | 125366/160800 [00:11<00:03, 9400.44it/s]Processing HH:  79%|███████▊  | 126558/160800 [00:11<00:03, 10031.62it/s]Processing HH:  79%|███████▉  | 127782/160800 [00:11<00:03, 10613.54it/s]Processing HH:  80%|████████  | 129038/160800 [00:11<00:02, 11141.69it/s]Processing HH:  81%|████████  | 130274/160800 [00:11<00:02, 11483.91it/s]Processing HH:  82%|████████▏ | 131515/160800 [00:11<00:02, 11748.44it/s]Processing HH:  83%|████████▎ | 132731/160800 [00:11<00:02, 11864.63it/s]Processing HH:  83%|████████▎ | 133959/160800 [00:11<00:02, 11984.32it/s]Processing HH:  84%|████████▍ | 135188/160800 [00:11<00:02, 12071.51it/s]Processing HH:  85%|████████▍ | 136408/160800 [00:12<00:02, 12102.47it/s]Processing HH:  86%|████████▌ | 137628/160800 [00:12<00:01, 12049.43it/s]Processing HH:  86%|████████▋ | 138840/160800 [00:12<00:01, 11917.92it/s]Processing HH:  87%|████████▋ | 140043/160800 [00:12<00:01, 11950.45it/s]Processing HH:  88%|████████▊ | 141242/160800 [00:12<00:01, 11946.93it/s]Processing HH:  89%|████████▊ | 142464/160800 [00:12<00:01, 12026.57it/s]Processing HH:  89%|████████▉ | 143701/160800 [00:12<00:01, 12126.68it/s]Processing HH:  90%|█████████ | 144915/160800 [00:12<00:01, 12115.98it/s]Processing HH:  91%|█████████ | 146139/160800 [00:12<00:01, 12152.90it/s]Processing HH:  92%|█████████▏| 147355/160800 [00:12<00:01, 12000.95it/s]Processing HH:  92%|█████████▏| 148579/160800 [00:13<00:01, 12070.42it/s]Processing HH:  93%|█████████▎| 149787/160800 [00:13<00:00, 11923.43it/s]Processing HH:  94%|█████████▍| 150981/160800 [00:13<00:00, 11870.82it/s]Processing HH:  95%|█████████▍| 152184/160800 [00:13<00:00, 11916.73it/s]Processing HH:  95%|█████████▌| 153377/160800 [00:13<00:00, 11875.48it/s]Processing HH:  96%|█████████▌| 154593/160800 [00:13<00:00, 11957.04it/s]Processing HH:  97%|█████████▋| 155794/160800 [00:13<00:00, 11968.72it/s]Processing HH:  98%|█████████▊| 157020/160800 [00:13<00:00, 12055.37it/s]Processing HH:  98%|█████████▊| 158226/160800 [00:13<00:00, 12016.18it/s]Processing HH:  99%|█████████▉| 159465/160800 [00:13<00:00, 12126.59it/s]Processing HH: 100%|█████████▉| 160680/160800 [00:14<00:00, 12129.81it/s]Processing HH: 100%|██████████| 160800/160800 [00:14<00:00, 11411.68it/s]
Loading HH dataset (test split) from Huggingface...
Processing HH:   0%|          | 0/8552 [00:00<?, ?it/s]Processing HH:  17%|█▋        | 1436/8552 [00:00<00:00, 14355.36it/s]Processing HH:  34%|███▎      | 2872/8552 [00:00<00:00, 14329.70it/s]Processing HH:  50%|█████     | 4305/8552 [00:00<00:00, 14108.82it/s]Processing HH:  67%|██████▋   | 5717/8552 [00:00<00:00, 11655.19it/s]Processing HH:  81%|████████  | 6934/8552 [00:00<00:00, 11568.15it/s]Processing HH:  95%|█████████▍| 8123/8552 [00:01<00:00, 4749.55it/s] Processing HH: 100%|██████████| 8552/8552 [00:01<00:00, 7262.63it/s]
starting 4 processes for FSDP training
setting RLIMIT_NOFILE soft limit to 1048576 from 1024
4
0 initializing distributed
Creating trainer on process 0 with world size 4
Finished 512 examples on test split
Loaded 32 eval batches of size 16
Sharding models...
Attempting to enable activation checkpointing...
Applying activation checkpointing wrapper to policy...
FSDP activation checkpointing enabled!
Loaded model on rank 0
Using RMSprop optimizer with learning rate 1e-05
Running evaluation after 0 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]/home/wxt/.conda/envs/halos3/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/wxt/.conda/envs/halos3/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/wxt/.conda/envs/halos3/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/wxt/.conda/envs/halos3/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Computing eval metrics:   3%|▎         | 1/32 [00:02<01:13,  2.36s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:04,  2.14s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:54,  1.89s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.86s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.52s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.62s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.46s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.53s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:31,  1.45s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:31,  1.52s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.46s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:26,  1.41s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.40s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.27s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.21s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.30s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.31s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:27<00:16,  1.26s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:28<00:14,  1.21s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.24s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.13s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.19s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:10,  1.27s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.24s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.28s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.45s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.39s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:41<00:04,  1.59s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:42<00:02,  1.40s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:43<00:01,  1.39s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.38s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]
eval after 0: {'rewards_eval/chosen': '0', 'rewards_eval/rejected': '0', 'rewards_eval/accuracies': '0', 'rewards_eval/margins': '0', 'logps_eval/rejected': '-147.66', 'logps_eval/chosen': '-144.92', 'loss/eval': '0.69141'}
skipping logging after 16 examples to avoid logging too frequently
skipping logging after 32 examples to avoid logging too frequently
skipping logging after 48 examples to avoid logging too frequently
train stats after 64 examples: {'rewards_train/chosen': '0', 'rewards_train/rejected': '0', 'rewards_train/accuracies': '0', 'rewards_train/margins': '0', 'logps_train/rejected': '-139.07', 'logps_train/chosen': '-44.217', 'loss/train': '0.69141', 'examples_per_second': '6.1593', 'grad_norm': '30', 'counters/examples': 64, 'counters/updates': 4}
skipping logging after 80 examples to avoid logging too frequently
skipping logging after 96 examples to avoid logging too frequently
skipping logging after 112 examples to avoid logging too frequently
train stats after 128 examples: {'rewards_train/chosen': '-0.0042536', 'rewards_train/rejected': '-0.0052786', 'rewards_train/accuracies': '0.45312', 'rewards_train/margins': '0.001018', 'logps_train/rejected': '-128.19', 'logps_train/chosen': '-45.8', 'loss/train': '0.69446', 'examples_per_second': '4.7602', 'grad_norm': '30.875', 'counters/examples': 128, 'counters/updates': 8}
skipping logging after 144 examples to avoid logging too frequently
skipping logging after 160 examples to avoid logging too frequently
skipping logging after 176 examples to avoid logging too frequently
train stats after 192 examples: {'rewards_train/chosen': '0.0074526', 'rewards_train/rejected': '-0.015763', 'rewards_train/accuracies': '0.46875', 'rewards_train/margins': '0.023227', 'logps_train/rejected': '-156.14', 'logps_train/chosen': '-43.075', 'loss/train': '0.68134', 'examples_per_second': '3.7196', 'grad_norm': '33', 'counters/examples': 192, 'counters/updates': 12}
skipping logging after 208 examples to avoid logging too frequently
skipping logging after 224 examples to avoid logging too frequently
skipping logging after 240 examples to avoid logging too frequently
train stats after 256 examples: {'rewards_train/chosen': '0.0053277', 'rewards_train/rejected': '0.0058496', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '-0.00052238', 'logps_train/rejected': '-131.87', 'logps_train/chosen': '-39.911', 'loss/train': '0.69263', 'examples_per_second': '5.9965', 'grad_norm': '30.75', 'counters/examples': 256, 'counters/updates': 16}
skipping logging after 272 examples to avoid logging too frequently
skipping logging after 288 examples to avoid logging too frequently
skipping logging after 304 examples to avoid logging too frequently
train stats after 320 examples: {'rewards_train/chosen': '0.0058386', 'rewards_train/rejected': '-0.011779', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '0.0176', 'logps_train/rejected': '-149.92', 'logps_train/chosen': '-34.727', 'loss/train': '0.68719', 'examples_per_second': '5.2752', 'grad_norm': '31.75', 'counters/examples': 320, 'counters/updates': 20}
skipping logging after 336 examples to avoid logging too frequently
skipping logging after 352 examples to avoid logging too frequently
skipping logging after 368 examples to avoid logging too frequently
train stats after 384 examples: {'rewards_train/chosen': '0.017979', 'rewards_train/rejected': '-0.022092', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.040102', 'logps_train/rejected': '-146.41', 'logps_train/chosen': '-34.571', 'loss/train': '0.67242', 'examples_per_second': '6.2627', 'grad_norm': '31', 'counters/examples': 384, 'counters/updates': 24}
skipping logging after 400 examples to avoid logging too frequently
skipping logging after 416 examples to avoid logging too frequently
skipping logging after 432 examples to avoid logging too frequently
train stats after 448 examples: {'rewards_train/chosen': '0.0094156', 'rewards_train/rejected': '-0.017982', 'rewards_train/accuracies': '0.73438', 'rewards_train/margins': '0.027415', 'logps_train/rejected': '-114.86', 'logps_train/chosen': '-26.756', 'loss/train': '0.68121', 'examples_per_second': '5.3898', 'grad_norm': '25.625', 'counters/examples': 448, 'counters/updates': 28}
skipping logging after 464 examples to avoid logging too frequently
skipping logging after 480 examples to avoid logging too frequently
skipping logging after 496 examples to avoid logging too frequently
train stats after 512 examples: {'rewards_train/chosen': '0.0082018', 'rewards_train/rejected': '-0.035342', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.043544', 'logps_train/rejected': '-109.55', 'logps_train/chosen': '-35.459', 'loss/train': '0.67444', 'examples_per_second': '5.7896', 'grad_norm': '24.375', 'counters/examples': 512, 'counters/updates': 32}
skipping logging after 528 examples to avoid logging too frequently
skipping logging after 544 examples to avoid logging too frequently
skipping logging after 560 examples to avoid logging too frequently
train stats after 576 examples: {'rewards_train/chosen': '0.030716', 'rewards_train/rejected': '-0.055039', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '0.085735', 'logps_train/rejected': '-120.31', 'logps_train/chosen': '-40.451', 'loss/train': '0.65253', 'examples_per_second': '4.9132', 'grad_norm': '27.125', 'counters/examples': 576, 'counters/updates': 36}
skipping logging after 592 examples to avoid logging too frequently
skipping logging after 608 examples to avoid logging too frequently
skipping logging after 624 examples to avoid logging too frequently
train stats after 640 examples: {'rewards_train/chosen': '0.021042', 'rewards_train/rejected': '-0.079561', 'rewards_train/accuracies': '0.8125', 'rewards_train/margins': '0.10063', 'logps_train/rejected': '-140.75', 'logps_train/chosen': '-37.561', 'loss/train': '0.6438', 'examples_per_second': '4.7458', 'grad_norm': '26.625', 'counters/examples': 640, 'counters/updates': 40}
skipping logging after 656 examples to avoid logging too frequently
skipping logging after 672 examples to avoid logging too frequently
skipping logging after 688 examples to avoid logging too frequently
train stats after 704 examples: {'rewards_train/chosen': '0.052602', 'rewards_train/rejected': '-0.099818', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '0.15242', 'logps_train/rejected': '-148.52', 'logps_train/chosen': '-47.873', 'loss/train': '0.62073', 'examples_per_second': '4.941', 'grad_norm': '29.625', 'counters/examples': 704, 'counters/updates': 44}
skipping logging after 720 examples to avoid logging too frequently
skipping logging after 736 examples to avoid logging too frequently
skipping logging after 752 examples to avoid logging too frequently
train stats after 768 examples: {'rewards_train/chosen': '0.052826', 'rewards_train/rejected': '-0.11997', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '0.17275', 'logps_train/rejected': '-122.23', 'logps_train/chosen': '-43.385', 'loss/train': '0.61145', 'examples_per_second': '5.3574', 'grad_norm': '25.25', 'counters/examples': 768, 'counters/updates': 48}
skipping logging after 784 examples to avoid logging too frequently
skipping logging after 800 examples to avoid logging too frequently
skipping logging after 816 examples to avoid logging too frequently
train stats after 832 examples: {'rewards_train/chosen': '0.052069', 'rewards_train/rejected': '-0.12616', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '0.17833', 'logps_train/rejected': '-114.33', 'logps_train/chosen': '-42.113', 'loss/train': '0.61548', 'examples_per_second': '6.4415', 'grad_norm': '24.375', 'counters/examples': 832, 'counters/updates': 52}
skipping logging after 848 examples to avoid logging too frequently
skipping logging after 864 examples to avoid logging too frequently
skipping logging after 880 examples to avoid logging too frequently
train stats after 896 examples: {'rewards_train/chosen': '0.057083', 'rewards_train/rejected': '-0.15545', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '0.21253', 'logps_train/rejected': '-137.91', 'logps_train/chosen': '-33.467', 'loss/train': '0.59717', 'examples_per_second': '3.6778', 'grad_norm': '25.375', 'counters/examples': 896, 'counters/updates': 56}
skipping logging after 912 examples to avoid logging too frequently
skipping logging after 928 examples to avoid logging too frequently
skipping logging after 944 examples to avoid logging too frequently
train stats after 960 examples: {'rewards_train/chosen': '0.064645', 'rewards_train/rejected': '-0.20045', 'rewards_train/accuracies': '1', 'rewards_train/margins': '0.26509', 'logps_train/rejected': '-152.47', 'logps_train/chosen': '-38.572', 'loss/train': '0.57941', 'examples_per_second': '5.8172', 'grad_norm': '25.625', 'counters/examples': 960, 'counters/updates': 60}
skipping logging after 976 examples to avoid logging too frequently
skipping logging after 992 examples to avoid logging too frequently
skipping logging after 1008 examples to avoid logging too frequently
train stats after 1024 examples: {'rewards_train/chosen': '0.08511', 'rewards_train/rejected': '-0.18772', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '0.27268', 'logps_train/rejected': '-122.25', 'logps_train/chosen': '-43.985', 'loss/train': '0.57114', 'examples_per_second': '4.8444', 'grad_norm': '21.5', 'counters/examples': 1024, 'counters/updates': 64}
skipping logging after 1040 examples to avoid logging too frequently
skipping logging after 1056 examples to avoid logging too frequently
skipping logging after 1072 examples to avoid logging too frequently
train stats after 1088 examples: {'rewards_train/chosen': '0.081467', 'rewards_train/rejected': '-0.20914', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '0.29062', 'logps_train/rejected': '-114', 'logps_train/chosen': '-37.088', 'loss/train': '0.565', 'examples_per_second': '5.8952', 'grad_norm': '20.125', 'counters/examples': 1088, 'counters/updates': 68}
skipping logging after 1104 examples to avoid logging too frequently
skipping logging after 1120 examples to avoid logging too frequently
skipping logging after 1136 examples to avoid logging too frequently
train stats after 1152 examples: {'rewards_train/chosen': '0.10909', 'rewards_train/rejected': '-0.26365', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '0.37254', 'logps_train/rejected': '-122.12', 'logps_train/chosen': '-39.639', 'loss/train': '0.53955', 'examples_per_second': '5.9215', 'grad_norm': '19.5', 'counters/examples': 1152, 'counters/updates': 72}
skipping logging after 1168 examples to avoid logging too frequently
skipping logging after 1184 examples to avoid logging too frequently
skipping logging after 1200 examples to avoid logging too frequently
train stats after 1216 examples: {'rewards_train/chosen': '0.11325', 'rewards_train/rejected': '-0.31848', 'rewards_train/accuracies': '1', 'rewards_train/margins': '0.43175', 'logps_train/rejected': '-143.84', 'logps_train/chosen': '-37.472', 'loss/train': '0.51547', 'examples_per_second': '4.5074', 'grad_norm': '21', 'counters/examples': 1216, 'counters/updates': 76}
skipping logging after 1232 examples to avoid logging too frequently
skipping logging after 1248 examples to avoid logging too frequently
skipping logging after 1264 examples to avoid logging too frequently
train stats after 1280 examples: {'rewards_train/chosen': '0.14504', 'rewards_train/rejected': '-0.39376', 'rewards_train/accuracies': '1', 'rewards_train/margins': '0.53873', 'logps_train/rejected': '-152.82', 'logps_train/chosen': '-39.885', 'loss/train': '0.48047', 'examples_per_second': '4.4434', 'grad_norm': '20.125', 'counters/examples': 1280, 'counters/updates': 80}
skipping logging after 1296 examples to avoid logging too frequently
skipping logging after 1312 examples to avoid logging too frequently
skipping logging after 1328 examples to avoid logging too frequently
train stats after 1344 examples: {'rewards_train/chosen': '0.13726', 'rewards_train/rejected': '-0.41318', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '0.55042', 'logps_train/rejected': '-145.74', 'logps_train/chosen': '-37.414', 'loss/train': '0.47894', 'examples_per_second': '6.0491', 'grad_norm': '20.25', 'counters/examples': 1344, 'counters/updates': 84}
skipping logging after 1360 examples to avoid logging too frequently
skipping logging after 1376 examples to avoid logging too frequently
skipping logging after 1392 examples to avoid logging too frequently
train stats after 1408 examples: {'rewards_train/chosen': '0.14689', 'rewards_train/rejected': '-0.50485', 'rewards_train/accuracies': '1', 'rewards_train/margins': '0.65145', 'logps_train/rejected': '-168.57', 'logps_train/chosen': '-37.949', 'loss/train': '0.45234', 'examples_per_second': '4.6295', 'grad_norm': '20', 'counters/examples': 1408, 'counters/updates': 88}
skipping logging after 1424 examples to avoid logging too frequently
skipping logging after 1440 examples to avoid logging too frequently
skipping logging after 1456 examples to avoid logging too frequently
train stats after 1472 examples: {'rewards_train/chosen': '0.16626', 'rewards_train/rejected': '-0.53938', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '0.70582', 'logps_train/rejected': '-143', 'logps_train/chosen': '-35.948', 'loss/train': '0.43353', 'examples_per_second': '3.9217', 'grad_norm': '17.625', 'counters/examples': 1472, 'counters/updates': 92}
skipping logging after 1488 examples to avoid logging too frequently
skipping logging after 1504 examples to avoid logging too frequently
skipping logging after 1520 examples to avoid logging too frequently
train stats after 1536 examples: {'rewards_train/chosen': '0.16135', 'rewards_train/rejected': '-0.5937', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '0.7553', 'logps_train/rejected': '-159.05', 'logps_train/chosen': '-35.421', 'loss/train': '0.42294', 'examples_per_second': '4.8955', 'grad_norm': '18.375', 'counters/examples': 1536, 'counters/updates': 96}
skipping logging after 1552 examples to avoid logging too frequently
skipping logging after 1568 examples to avoid logging too frequently
skipping logging after 1584 examples to avoid logging too frequently
train stats after 1600 examples: {'rewards_train/chosen': '0.21023', 'rewards_train/rejected': '-0.60562', 'rewards_train/accuracies': '1', 'rewards_train/margins': '0.81515', 'logps_train/rejected': '-139.27', 'logps_train/chosen': '-32.406', 'loss/train': '0.40936', 'examples_per_second': '5.4467', 'grad_norm': '15.25', 'counters/examples': 1600, 'counters/updates': 100}
skipping logging after 1616 examples to avoid logging too frequently
skipping logging after 1632 examples to avoid logging too frequently
skipping logging after 1648 examples to avoid logging too frequently
train stats after 1664 examples: {'rewards_train/chosen': '0.23613', 'rewards_train/rejected': '-0.78855', 'rewards_train/accuracies': '1', 'rewards_train/margins': '1.0246', 'logps_train/rejected': '-166.51', 'logps_train/chosen': '-39.989', 'loss/train': '0.36551', 'examples_per_second': '5.723', 'grad_norm': '15.438', 'counters/examples': 1664, 'counters/updates': 104}
skipping logging after 1680 examples to avoid logging too frequently
skipping logging after 1696 examples to avoid logging too frequently
skipping logging after 1712 examples to avoid logging too frequently
train stats after 1728 examples: {'rewards_train/chosen': '0.22556', 'rewards_train/rejected': '-0.85432', 'rewards_train/accuracies': '1', 'rewards_train/margins': '1.0798', 'logps_train/rejected': '-177.37', 'logps_train/chosen': '-37.766', 'loss/train': '0.35152', 'examples_per_second': '6.5795', 'grad_norm': '16', 'counters/examples': 1728, 'counters/updates': 108}
skipping logging after 1744 examples to avoid logging too frequently
skipping logging after 1760 examples to avoid logging too frequently
skipping logging after 1776 examples to avoid logging too frequently
train stats after 1792 examples: {'rewards_train/chosen': '0.18338', 'rewards_train/rejected': '-0.74494', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '0.92832', 'logps_train/rejected': '-139.57', 'logps_train/chosen': '-33.863', 'loss/train': '0.41227', 'examples_per_second': '4.3565', 'grad_norm': '13', 'counters/examples': 1792, 'counters/updates': 112}
skipping logging after 1808 examples to avoid logging too frequently
skipping logging after 1824 examples to avoid logging too frequently
skipping logging after 1840 examples to avoid logging too frequently
train stats after 1856 examples: {'rewards_train/chosen': '0.27229', 'rewards_train/rejected': '-0.75456', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '1.027', 'logps_train/rejected': '-114.91', 'logps_train/chosen': '-36.968', 'loss/train': '0.36606', 'examples_per_second': '4.9643', 'grad_norm': '13.25', 'counters/examples': 1856, 'counters/updates': 116}
skipping logging after 1872 examples to avoid logging too frequently
skipping logging after 1888 examples to avoid logging too frequently
skipping logging after 1904 examples to avoid logging too frequently
train stats after 1920 examples: {'rewards_train/chosen': '0.21878', 'rewards_train/rejected': '-0.77257', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '0.99109', 'logps_train/rejected': '-117.5', 'logps_train/chosen': '-30.199', 'loss/train': '0.37163', 'examples_per_second': '4.9984', 'grad_norm': '12.938', 'counters/examples': 1920, 'counters/updates': 120}
skipping logging after 1936 examples to avoid logging too frequently
skipping logging after 1952 examples to avoid logging too frequently
skipping logging after 1968 examples to avoid logging too frequently
train stats after 1984 examples: {'rewards_train/chosen': '0.29107', 'rewards_train/rejected': '-1.1802', 'rewards_train/accuracies': '1', 'rewards_train/margins': '1.4708', 'logps_train/rejected': '-170.67', 'logps_train/chosen': '-35.73', 'loss/train': '0.3014', 'examples_per_second': '4.9956', 'grad_norm': '11.375', 'counters/examples': 1984, 'counters/updates': 124}
skipping logging after 2000 examples to avoid logging too frequently
skipping logging after 2016 examples to avoid logging too frequently
skipping logging after 2032 examples to avoid logging too frequently
train stats after 2048 examples: {'rewards_train/chosen': '0.25902', 'rewards_train/rejected': '-0.96529', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '1.2243', 'logps_train/rejected': '-138.18', 'logps_train/chosen': '-35.499', 'loss/train': '0.33237', 'examples_per_second': '5.04', 'grad_norm': '12.125', 'counters/examples': 2048, 'counters/updates': 128}
skipping logging after 2064 examples to avoid logging too frequently
skipping logging after 2080 examples to avoid logging too frequently
skipping logging after 2096 examples to avoid logging too frequently
train stats after 2112 examples: {'rewards_train/chosen': '0.34972', 'rewards_train/rejected': '-1.1443', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '1.4939', 'logps_train/rejected': '-143.75', 'logps_train/chosen': '-43.353', 'loss/train': '0.29067', 'examples_per_second': '5.0509', 'grad_norm': '10.875', 'counters/examples': 2112, 'counters/updates': 132}
skipping logging after 2128 examples to avoid logging too frequently
skipping logging after 2144 examples to avoid logging too frequently
skipping logging after 2160 examples to avoid logging too frequently
train stats after 2176 examples: {'rewards_train/chosen': '0.23955', 'rewards_train/rejected': '-1.1419', 'rewards_train/accuracies': '1', 'rewards_train/margins': '1.3819', 'logps_train/rejected': '-131.26', 'logps_train/chosen': '-28.773', 'loss/train': '0.34721', 'examples_per_second': '5.8711', 'grad_norm': '10.188', 'counters/examples': 2176, 'counters/updates': 136}
skipping logging after 2192 examples to avoid logging too frequently
skipping logging after 2208 examples to avoid logging too frequently
skipping logging after 2224 examples to avoid logging too frequently
train stats after 2240 examples: {'rewards_train/chosen': '0.32823', 'rewards_train/rejected': '-1.2927', 'rewards_train/accuracies': '1', 'rewards_train/margins': '1.6213', 'logps_train/rejected': '-145.85', 'logps_train/chosen': '-33.442', 'loss/train': '0.26501', 'examples_per_second': '5.9711', 'grad_norm': '11.062', 'counters/examples': 2240, 'counters/updates': 140}
skipping logging after 2256 examples to avoid logging too frequently
skipping logging after 2272 examples to avoid logging too frequently
skipping logging after 2288 examples to avoid logging too frequently
train stats after 2304 examples: {'rewards_train/chosen': '0.34989', 'rewards_train/rejected': '-1.6493', 'rewards_train/accuracies': '1', 'rewards_train/margins': '1.999', 'logps_train/rejected': '-173.72', 'logps_train/chosen': '-31.734', 'loss/train': '0.2453', 'examples_per_second': '4.3971', 'grad_norm': '9.4375', 'counters/examples': 2304, 'counters/updates': 144}
skipping logging after 2320 examples to avoid logging too frequently
skipping logging after 2336 examples to avoid logging too frequently
skipping logging after 2352 examples to avoid logging too frequently
train stats after 2368 examples: {'rewards_train/chosen': '0.33212', 'rewards_train/rejected': '-1.3073', 'rewards_train/accuracies': '1', 'rewards_train/margins': '1.6391', 'logps_train/rejected': '-125.95', 'logps_train/chosen': '-32.641', 'loss/train': '0.27018', 'examples_per_second': '5.6643', 'grad_norm': '10.25', 'counters/examples': 2368, 'counters/updates': 148}
skipping logging after 2384 examples to avoid logging too frequently
skipping logging after 2400 examples to avoid logging too frequently
skipping logging after 2416 examples to avoid logging too frequently
train stats after 2432 examples: {'rewards_train/chosen': '0.37399', 'rewards_train/rejected': '-1.581', 'rewards_train/accuracies': '1', 'rewards_train/margins': '1.9543', 'logps_train/rejected': '-147.62', 'logps_train/chosen': '-35.096', 'loss/train': '0.21855', 'examples_per_second': '5.3836', 'grad_norm': '9.25', 'counters/examples': 2432, 'counters/updates': 152}
skipping logging after 2448 examples to avoid logging too frequently
skipping logging after 2464 examples to avoid logging too frequently
skipping logging after 2480 examples to avoid logging too frequently
train stats after 2496 examples: {'rewards_train/chosen': '0.29948', 'rewards_train/rejected': '-1.7204', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '2.0203', 'logps_train/rejected': '-158.36', 'logps_train/chosen': '-37.555', 'loss/train': '0.2354', 'examples_per_second': '6.8376', 'grad_norm': '9.125', 'counters/examples': 2496, 'counters/updates': 156}
skipping logging after 2512 examples to avoid logging too frequently
skipping logging after 2528 examples to avoid logging too frequently
skipping logging after 2544 examples to avoid logging too frequently
train stats after 2560 examples: {'rewards_train/chosen': '0.37893', 'rewards_train/rejected': '-2.1202', 'rewards_train/accuracies': '1', 'rewards_train/margins': '2.4996', 'logps_train/rejected': '-175.48', 'logps_train/chosen': '-31.269', 'loss/train': '0.20633', 'examples_per_second': '4.8576', 'grad_norm': '7.6562', 'counters/examples': 2560, 'counters/updates': 160}
skipping logging after 2576 examples to avoid logging too frequently
skipping logging after 2592 examples to avoid logging too frequently
skipping logging after 2608 examples to avoid logging too frequently
train stats after 2624 examples: {'rewards_train/chosen': '0.46689', 'rewards_train/rejected': '-1.9815', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '2.4497', 'logps_train/rejected': '-163.59', 'logps_train/chosen': '-41.178', 'loss/train': '0.21424', 'examples_per_second': '4.5052', 'grad_norm': '9', 'counters/examples': 2624, 'counters/updates': 164}
skipping logging after 2640 examples to avoid logging too frequently
skipping logging after 2656 examples to avoid logging too frequently
skipping logging after 2672 examples to avoid logging too frequently
train stats after 2688 examples: {'rewards_train/chosen': '0.35334', 'rewards_train/rejected': '-1.7136', 'rewards_train/accuracies': '1', 'rewards_train/margins': '2.067', 'logps_train/rejected': '-133.75', 'logps_train/chosen': '-37.673', 'loss/train': '0.24341', 'examples_per_second': '5.6617', 'grad_norm': '8.0625', 'counters/examples': 2688, 'counters/updates': 168}
skipping logging after 2704 examples to avoid logging too frequently
skipping logging after 2720 examples to avoid logging too frequently
skipping logging after 2736 examples to avoid logging too frequently
train stats after 2752 examples: {'rewards_train/chosen': '0.10791', 'rewards_train/rejected': '-1.7203', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '1.8284', 'logps_train/rejected': '-121.28', 'logps_train/chosen': '-30.546', 'loss/train': '0.27646', 'examples_per_second': '5.5835', 'grad_norm': '15.75', 'counters/examples': 2752, 'counters/updates': 172}
skipping logging after 2768 examples to avoid logging too frequently
skipping logging after 2784 examples to avoid logging too frequently
skipping logging after 2800 examples to avoid logging too frequently
train stats after 2816 examples: {'rewards_train/chosen': '0.25561', 'rewards_train/rejected': '-2.0792', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '2.335', 'logps_train/rejected': '-148.69', 'logps_train/chosen': '-28.146', 'loss/train': '0.23127', 'examples_per_second': '5.5966', 'grad_norm': '7.625', 'counters/examples': 2816, 'counters/updates': 176}
skipping logging after 2832 examples to avoid logging too frequently
skipping logging after 2848 examples to avoid logging too frequently
skipping logging after 2864 examples to avoid logging too frequently
train stats after 2880 examples: {'rewards_train/chosen': '0.3496', 'rewards_train/rejected': '-1.9054', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '2.2553', 'logps_train/rejected': '-139.25', 'logps_train/chosen': '-35.928', 'loss/train': '0.21493', 'examples_per_second': '4.9995', 'grad_norm': '8.1875', 'counters/examples': 2880, 'counters/updates': 180}
skipping logging after 2896 examples to avoid logging too frequently
skipping logging after 2912 examples to avoid logging too frequently
skipping logging after 2928 examples to avoid logging too frequently
train stats after 2944 examples: {'rewards_train/chosen': '0.3322', 'rewards_train/rejected': '-2.1652', 'rewards_train/accuracies': '1', 'rewards_train/margins': '2.497', 'logps_train/rejected': '-148.62', 'logps_train/chosen': '-33.374', 'loss/train': '0.21721', 'examples_per_second': '5.8435', 'grad_norm': '7.0938', 'counters/examples': 2944, 'counters/updates': 184}
skipping logging after 2960 examples to avoid logging too frequently
skipping logging after 2976 examples to avoid logging too frequently
skipping logging after 2992 examples to avoid logging too frequently
train stats after 3008 examples: {'rewards_train/chosen': '0.3094', 'rewards_train/rejected': '-2.0145', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '2.3244', 'logps_train/rejected': '-129.85', 'logps_train/chosen': '-29.428', 'loss/train': '0.22725', 'examples_per_second': '4.68', 'grad_norm': '8.125', 'counters/examples': 3008, 'counters/updates': 188}
skipping logging after 3024 examples to avoid logging too frequently
skipping logging after 3040 examples to avoid logging too frequently
skipping logging after 3056 examples to avoid logging too frequently
train stats after 3072 examples: {'rewards_train/chosen': '0.42778', 'rewards_train/rejected': '-2.8661', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '3.2932', 'logps_train/rejected': '-201.03', 'logps_train/chosen': '-41.686', 'loss/train': '0.13855', 'examples_per_second': '5.172', 'grad_norm': '6.25', 'counters/examples': 3072, 'counters/updates': 192}
skipping logging after 3088 examples to avoid logging too frequently
skipping logging after 3104 examples to avoid logging too frequently
skipping logging after 3120 examples to avoid logging too frequently
train stats after 3136 examples: {'rewards_train/chosen': '0.48455', 'rewards_train/rejected': '-2.6647', 'rewards_train/accuracies': '1', 'rewards_train/margins': '3.1498', 'logps_train/rejected': '-180.29', 'logps_train/chosen': '-39.123', 'loss/train': '0.16762', 'examples_per_second': '5.1757', 'grad_norm': '6.4375', 'counters/examples': 3136, 'counters/updates': 196}
skipping logging after 3152 examples to avoid logging too frequently
skipping logging after 3168 examples to avoid logging too frequently
skipping logging after 3184 examples to avoid logging too frequently
train stats after 3200 examples: {'rewards_train/chosen': '0.44407', 'rewards_train/rejected': '-3.0699', 'rewards_train/accuracies': '1', 'rewards_train/margins': '3.5143', 'logps_train/rejected': '-211.04', 'logps_train/chosen': '-38.997', 'loss/train': '0.12984', 'examples_per_second': '4.6834', 'grad_norm': '6.6562', 'counters/examples': 3200, 'counters/updates': 200}
skipping logging after 3216 examples to avoid logging too frequently
skipping logging after 3232 examples to avoid logging too frequently
skipping logging after 3248 examples to avoid logging too frequently
train stats after 3264 examples: {'rewards_train/chosen': '0.36774', 'rewards_train/rejected': '-2.3716', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '2.7404', 'logps_train/rejected': '-147.82', 'logps_train/chosen': '-39.577', 'loss/train': '0.19198', 'examples_per_second': '5.6022', 'grad_norm': '8.25', 'counters/examples': 3264, 'counters/updates': 204}
skipping logging after 3280 examples to avoid logging too frequently
skipping logging after 3296 examples to avoid logging too frequently
skipping logging after 3312 examples to avoid logging too frequently
train stats after 3328 examples: {'rewards_train/chosen': '0.21314', 'rewards_train/rejected': '-3.5173', 'rewards_train/accuracies': '1', 'rewards_train/margins': '3.7306', 'logps_train/rejected': '-208.92', 'logps_train/chosen': '-36.058', 'loss/train': '0.16955', 'examples_per_second': '5.226', 'grad_norm': '9.5', 'counters/examples': 3328, 'counters/updates': 208}
skipping logging after 3344 examples to avoid logging too frequently
skipping logging after 3360 examples to avoid logging too frequently
skipping logging after 3376 examples to avoid logging too frequently
train stats after 3392 examples: {'rewards_train/chosen': '0.35324', 'rewards_train/rejected': '-2.6507', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '3.0043', 'logps_train/rejected': '-150.93', 'logps_train/chosen': '-43.749', 'loss/train': '0.20007', 'examples_per_second': '4.9361', 'grad_norm': '9.125', 'counters/examples': 3392, 'counters/updates': 212}
skipping logging after 3408 examples to avoid logging too frequently
skipping logging after 3424 examples to avoid logging too frequently
skipping logging after 3440 examples to avoid logging too frequently
train stats after 3456 examples: {'rewards_train/chosen': '0.25379', 'rewards_train/rejected': '-2.6866', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '2.9409', 'logps_train/rejected': '-152.94', 'logps_train/chosen': '-32.335', 'loss/train': '0.19515', 'examples_per_second': '4.7792', 'grad_norm': '7.2188', 'counters/examples': 3456, 'counters/updates': 216}
skipping logging after 3472 examples to avoid logging too frequently
skipping logging after 3488 examples to avoid logging too frequently
skipping logging after 3504 examples to avoid logging too frequently
train stats after 3520 examples: {'rewards_train/chosen': '0.14599', 'rewards_train/rejected': '-3.2357', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '3.3814', 'logps_train/rejected': '-178.78', 'logps_train/chosen': '-41.474', 'loss/train': '0.20113', 'examples_per_second': '5.3875', 'grad_norm': '9.375', 'counters/examples': 3520, 'counters/updates': 220}
skipping logging after 3536 examples to avoid logging too frequently
skipping logging after 3552 examples to avoid logging too frequently
skipping logging after 3568 examples to avoid logging too frequently
train stats after 3584 examples: {'rewards_train/chosen': '0.42216', 'rewards_train/rejected': '-3.5775', 'rewards_train/accuracies': '1', 'rewards_train/margins': '3.9997', 'logps_train/rejected': '-198.94', 'logps_train/chosen': '-36.347', 'loss/train': '0.12865', 'examples_per_second': '4.6272', 'grad_norm': '5.9688', 'counters/examples': 3584, 'counters/updates': 224}
skipping logging after 3600 examples to avoid logging too frequently
skipping logging after 3616 examples to avoid logging too frequently
skipping logging after 3632 examples to avoid logging too frequently
train stats after 3648 examples: {'rewards_train/chosen': '0.44294', 'rewards_train/rejected': '-3.0738', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '3.5165', 'logps_train/rejected': '-154.33', 'logps_train/chosen': '-42.189', 'loss/train': '0.14108', 'examples_per_second': '6.2975', 'grad_norm': '5.9062', 'counters/examples': 3648, 'counters/updates': 228}
skipping logging after 3664 examples to avoid logging too frequently
skipping logging after 3680 examples to avoid logging too frequently
skipping logging after 3696 examples to avoid logging too frequently
train stats after 3712 examples: {'rewards_train/chosen': '0.45728', 'rewards_train/rejected': '-3.1792', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '3.6354', 'logps_train/rejected': '-158.92', 'logps_train/chosen': '-33.958', 'loss/train': '0.12423', 'examples_per_second': '5.2318', 'grad_norm': '5.875', 'counters/examples': 3712, 'counters/updates': 232}
skipping logging after 3728 examples to avoid logging too frequently
skipping logging after 3744 examples to avoid logging too frequently
skipping logging after 3760 examples to avoid logging too frequently
train stats after 3776 examples: {'rewards_train/chosen': '0.36168', 'rewards_train/rejected': '-3.4434', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '3.8036', 'logps_train/rejected': '-176.84', 'logps_train/chosen': '-34.776', 'loss/train': '0.15707', 'examples_per_second': '4.8975', 'grad_norm': '5.9688', 'counters/examples': 3776, 'counters/updates': 236}
skipping logging after 3792 examples to avoid logging too frequently
skipping logging after 3808 examples to avoid logging too frequently
skipping logging after 3824 examples to avoid logging too frequently
train stats after 3840 examples: {'rewards_train/chosen': '0.28629', 'rewards_train/rejected': '-3.361', 'rewards_train/accuracies': '1', 'rewards_train/margins': '3.6467', 'logps_train/rejected': '-157.86', 'logps_train/chosen': '-39.799', 'loss/train': '0.13803', 'examples_per_second': '5.5555', 'grad_norm': '6.5938', 'counters/examples': 3840, 'counters/updates': 240}
skipping logging after 3856 examples to avoid logging too frequently
skipping logging after 3872 examples to avoid logging too frequently
skipping logging after 3888 examples to avoid logging too frequently
train stats after 3904 examples: {'rewards_train/chosen': '0.34319', 'rewards_train/rejected': '-3.4996', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '3.8431', 'logps_train/rejected': '-167.93', 'logps_train/chosen': '-40.073', 'loss/train': '0.11975', 'examples_per_second': '5.8151', 'grad_norm': '4.8125', 'counters/examples': 3904, 'counters/updates': 244}
skipping logging after 3920 examples to avoid logging too frequently
skipping logging after 3936 examples to avoid logging too frequently
skipping logging after 3952 examples to avoid logging too frequently
train stats after 3968 examples: {'rewards_train/chosen': '0.26325', 'rewards_train/rejected': '-3.8285', 'rewards_train/accuracies': '1', 'rewards_train/margins': '4.0909', 'logps_train/rejected': '-170.88', 'logps_train/chosen': '-34.616', 'loss/train': '0.10568', 'examples_per_second': '4.6083', 'grad_norm': '5.4688', 'counters/examples': 3968, 'counters/updates': 248}
skipping logging after 3984 examples to avoid logging too frequently
skipping logging after 4000 examples to avoid logging too frequently
Running evaluation after 4000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:10,  2.26s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:04,  2.15s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:55,  1.91s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.90s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.55s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.66s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.50s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.57s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:36,  1.57s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.50s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.57s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:30,  1.51s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.46s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:26,  1.45s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:22,  1.31s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:20,  1.25s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:20,  1.34s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.35s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:14,  1.28s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:33<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.30s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.27s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:37<00:07,  1.31s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:39<00:07,  1.49s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.42s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.62s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.43s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.42s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.41s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.45s/it]
eval after 4000: {'rewards_eval/chosen': '-3.912', 'rewards_eval/rejected': '-3.9723', 'rewards_eval/accuracies': '0.50977', 'rewards_eval/margins': '0.060241', 'logps_eval/rejected': '-187.39', 'logps_eval/chosen': '-184.03', 'loss/eval': '1.5485'}
skipping logging after 4016 examples to avoid logging too frequently
train stats after 4032 examples: {'rewards_train/chosen': '0.28424', 'rewards_train/rejected': '-3.5873', 'rewards_train/accuracies': '1', 'rewards_train/margins': '3.8719', 'logps_train/rejected': '-171.88', 'logps_train/chosen': '-43.423', 'loss/train': '0.14239', 'examples_per_second': '4.6854', 'grad_norm': '7.9688', 'counters/examples': 4032, 'counters/updates': 252}
skipping logging after 4048 examples to avoid logging too frequently
skipping logging after 4064 examples to avoid logging too frequently
skipping logging after 4080 examples to avoid logging too frequently
train stats after 4096 examples: {'rewards_train/chosen': '0.24419', 'rewards_train/rejected': '-3.7622', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '4.0053', 'logps_train/rejected': '-174.13', 'logps_train/chosen': '-34.535', 'loss/train': '0.15039', 'examples_per_second': '4.5078', 'grad_norm': '5.8125', 'counters/examples': 4096, 'counters/updates': 256}
skipping logging after 4112 examples to avoid logging too frequently
skipping logging after 4128 examples to avoid logging too frequently
skipping logging after 4144 examples to avoid logging too frequently
train stats after 4160 examples: {'rewards_train/chosen': '0.22711', 'rewards_train/rejected': '-3.6728', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '3.9018', 'logps_train/rejected': '-168.41', 'logps_train/chosen': '-37.133', 'loss/train': '0.15056', 'examples_per_second': '5.0641', 'grad_norm': '6.0312', 'counters/examples': 4160, 'counters/updates': 260}
skipping logging after 4176 examples to avoid logging too frequently
skipping logging after 4192 examples to avoid logging too frequently
skipping logging after 4208 examples to avoid logging too frequently
train stats after 4224 examples: {'rewards_train/chosen': '0.14789', 'rewards_train/rejected': '-3.9585', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '4.1066', 'logps_train/rejected': '-167.82', 'logps_train/chosen': '-40.303', 'loss/train': '0.16028', 'examples_per_second': '4.9192', 'grad_norm': '9.3125', 'counters/examples': 4224, 'counters/updates': 264}
skipping logging after 4240 examples to avoid logging too frequently
skipping logging after 4256 examples to avoid logging too frequently
skipping logging after 4272 examples to avoid logging too frequently
train stats after 4288 examples: {'rewards_train/chosen': '0.40104', 'rewards_train/rejected': '-4.1429', 'rewards_train/accuracies': '1', 'rewards_train/margins': '4.5418', 'logps_train/rejected': '-197.29', 'logps_train/chosen': '-46.818', 'loss/train': '0.10954', 'examples_per_second': '5.6691', 'grad_norm': '6.0312', 'counters/examples': 4288, 'counters/updates': 268}
skipping logging after 4304 examples to avoid logging too frequently
skipping logging after 4320 examples to avoid logging too frequently
skipping logging after 4336 examples to avoid logging too frequently
train stats after 4352 examples: {'rewards_train/chosen': '0.31034', 'rewards_train/rejected': '-3.4073', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '3.7164', 'logps_train/rejected': '-152.14', 'logps_train/chosen': '-33.931', 'loss/train': '0.14873', 'examples_per_second': '5.644', 'grad_norm': '5.4062', 'counters/examples': 4352, 'counters/updates': 272}
skipping logging after 4368 examples to avoid logging too frequently
skipping logging after 4384 examples to avoid logging too frequently
skipping logging after 4400 examples to avoid logging too frequently
train stats after 4416 examples: {'rewards_train/chosen': '0.36105', 'rewards_train/rejected': '-3.9017', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '4.2634', 'logps_train/rejected': '-181.36', 'logps_train/chosen': '-39.404', 'loss/train': '0.12656', 'examples_per_second': '4.8461', 'grad_norm': '6.0938', 'counters/examples': 4416, 'counters/updates': 276}
skipping logging after 4432 examples to avoid logging too frequently
skipping logging after 4448 examples to avoid logging too frequently
skipping logging after 4464 examples to avoid logging too frequently
train stats after 4480 examples: {'rewards_train/chosen': '0.25246', 'rewards_train/rejected': '-4.599', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '4.8515', 'logps_train/rejected': '-178.78', 'logps_train/chosen': '-43.473', 'loss/train': '0.117', 'examples_per_second': '5.5842', 'grad_norm': '6.5938', 'counters/examples': 4480, 'counters/updates': 280}
skipping logging after 4496 examples to avoid logging too frequently
skipping logging after 4512 examples to avoid logging too frequently
skipping logging after 4528 examples to avoid logging too frequently
train stats after 4544 examples: {'rewards_train/chosen': '0.20508', 'rewards_train/rejected': '-4.3539', 'rewards_train/accuracies': '1', 'rewards_train/margins': '4.5604', 'logps_train/rejected': '-169.71', 'logps_train/chosen': '-36.376', 'loss/train': '0.14739', 'examples_per_second': '5.4997', 'grad_norm': '8.0625', 'counters/examples': 4544, 'counters/updates': 284}
skipping logging after 4560 examples to avoid logging too frequently
skipping logging after 4576 examples to avoid logging too frequently
skipping logging after 4592 examples to avoid logging too frequently
train stats after 4608 examples: {'rewards_train/chosen': '0.17557', 'rewards_train/rejected': '-4.1005', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '4.2761', 'logps_train/rejected': '-168.76', 'logps_train/chosen': '-32.309', 'loss/train': '0.14256', 'examples_per_second': '5.789', 'grad_norm': '6.4375', 'counters/examples': 4608, 'counters/updates': 288}
skipping logging after 4624 examples to avoid logging too frequently
skipping logging after 4640 examples to avoid logging too frequently
skipping logging after 4656 examples to avoid logging too frequently
train stats after 4672 examples: {'rewards_train/chosen': '0.27451', 'rewards_train/rejected': '-4.2602', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '4.536', 'logps_train/rejected': '-168.45', 'logps_train/chosen': '-43.321', 'loss/train': '0.11616', 'examples_per_second': '3.7818', 'grad_norm': '5.2812', 'counters/examples': 4672, 'counters/updates': 292}
skipping logging after 4688 examples to avoid logging too frequently
skipping logging after 4704 examples to avoid logging too frequently
skipping logging after 4720 examples to avoid logging too frequently
train stats after 4736 examples: {'rewards_train/chosen': '0.27241', 'rewards_train/rejected': '-4.8047', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '5.0753', 'logps_train/rejected': '-196.57', 'logps_train/chosen': '-41.893', 'loss/train': '0.11794', 'examples_per_second': '4.8663', 'grad_norm': '7.1562', 'counters/examples': 4736, 'counters/updates': 296}
skipping logging after 4752 examples to avoid logging too frequently
skipping logging after 4768 examples to avoid logging too frequently
skipping logging after 4784 examples to avoid logging too frequently
train stats after 4800 examples: {'rewards_train/chosen': '0.14929', 'rewards_train/rejected': '-4.3173', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '4.4682', 'logps_train/rejected': '-170.44', 'logps_train/chosen': '-39.179', 'loss/train': '0.18277', 'examples_per_second': '4.6956', 'grad_norm': '15', 'counters/examples': 4800, 'counters/updates': 300}
skipping logging after 4816 examples to avoid logging too frequently
skipping logging after 4832 examples to avoid logging too frequently
skipping logging after 4848 examples to avoid logging too frequently
train stats after 4864 examples: {'rewards_train/chosen': '0.21153', 'rewards_train/rejected': '-4.8398', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '5.0533', 'logps_train/rejected': '-190.77', 'logps_train/chosen': '-43.866', 'loss/train': '0.11182', 'examples_per_second': '5.408', 'grad_norm': '6.5938', 'counters/examples': 4864, 'counters/updates': 304}
skipping logging after 4880 examples to avoid logging too frequently
skipping logging after 4896 examples to avoid logging too frequently
skipping logging after 4912 examples to avoid logging too frequently
train stats after 4928 examples: {'rewards_train/chosen': '0.072138', 'rewards_train/rejected': '-4.6151', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '4.6872', 'logps_train/rejected': '-182.85', 'logps_train/chosen': '-40.96', 'loss/train': '0.11191', 'examples_per_second': '5.3129', 'grad_norm': '8.0625', 'counters/examples': 4928, 'counters/updates': 308}
skipping logging after 4944 examples to avoid logging too frequently
skipping logging after 4960 examples to avoid logging too frequently
skipping logging after 4976 examples to avoid logging too frequently
train stats after 4992 examples: {'rewards_train/chosen': '0.10041', 'rewards_train/rejected': '-4.7687', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '4.8673', 'logps_train/rejected': '-177.85', 'logps_train/chosen': '-39.321', 'loss/train': '0.13061', 'examples_per_second': '4.8696', 'grad_norm': '10.688', 'counters/examples': 4992, 'counters/updates': 312}
skipping logging after 5008 examples to avoid logging too frequently
skipping logging after 5024 examples to avoid logging too frequently
skipping logging after 5040 examples to avoid logging too frequently
train stats after 5056 examples: {'rewards_train/chosen': '0.10634', 'rewards_train/rejected': '-4.8327', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '4.9392', 'logps_train/rejected': '-183.57', 'logps_train/chosen': '-33.643', 'loss/train': '0.10578', 'examples_per_second': '4.8588', 'grad_norm': '6.25', 'counters/examples': 5056, 'counters/updates': 316}
skipping logging after 5072 examples to avoid logging too frequently
skipping logging after 5088 examples to avoid logging too frequently
skipping logging after 5104 examples to avoid logging too frequently
train stats after 5120 examples: {'rewards_train/chosen': '0.21666', 'rewards_train/rejected': '-4.9035', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '5.1211', 'logps_train/rejected': '-197.03', 'logps_train/chosen': '-43.915', 'loss/train': '0.11681', 'examples_per_second': '5.1502', 'grad_norm': '9.1875', 'counters/examples': 5120, 'counters/updates': 320}
skipping logging after 5136 examples to avoid logging too frequently
skipping logging after 5152 examples to avoid logging too frequently
skipping logging after 5168 examples to avoid logging too frequently
train stats after 5184 examples: {'rewards_train/chosen': '0.03977', 'rewards_train/rejected': '-4.8622', 'rewards_train/accuracies': '1', 'rewards_train/margins': '4.9019', 'logps_train/rejected': '-184.05', 'logps_train/chosen': '-43.57', 'loss/train': '0.1601', 'examples_per_second': '5.3177', 'grad_norm': '11.75', 'counters/examples': 5184, 'counters/updates': 324}
skipping logging after 5200 examples to avoid logging too frequently
skipping logging after 5216 examples to avoid logging too frequently
skipping logging after 5232 examples to avoid logging too frequently
train stats after 5248 examples: {'rewards_train/chosen': '0.083802', 'rewards_train/rejected': '-4.5182', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '4.6014', 'logps_train/rejected': '-152.68', 'logps_train/chosen': '-41.674', 'loss/train': '0.10212', 'examples_per_second': '6.9838', 'grad_norm': '5.75', 'counters/examples': 5248, 'counters/updates': 328}
skipping logging after 5264 examples to avoid logging too frequently
skipping logging after 5280 examples to avoid logging too frequently
skipping logging after 5296 examples to avoid logging too frequently
train stats after 5312 examples: {'rewards_train/chosen': '0.086168', 'rewards_train/rejected': '-4.037', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '4.1232', 'logps_train/rejected': '-149.56', 'logps_train/chosen': '-45.217', 'loss/train': '0.15152', 'examples_per_second': '5.6219', 'grad_norm': '10.938', 'counters/examples': 5312, 'counters/updates': 332}
skipping logging after 5328 examples to avoid logging too frequently
skipping logging after 5344 examples to avoid logging too frequently
skipping logging after 5360 examples to avoid logging too frequently
train stats after 5376 examples: {'rewards_train/chosen': '0.17299', 'rewards_train/rejected': '-5.4266', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '5.601', 'logps_train/rejected': '-204.28', 'logps_train/chosen': '-44.191', 'loss/train': '0.073163', 'examples_per_second': '5.4765', 'grad_norm': '5.3125', 'counters/examples': 5376, 'counters/updates': 336}
skipping logging after 5392 examples to avoid logging too frequently
skipping logging after 5408 examples to avoid logging too frequently
skipping logging after 5424 examples to avoid logging too frequently
train stats after 5440 examples: {'rewards_train/chosen': '-0.07645', 'rewards_train/rejected': '-5.0635', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '4.9869', 'logps_train/rejected': '-178.95', 'logps_train/chosen': '-39.832', 'loss/train': '0.12009', 'examples_per_second': '4.2022', 'grad_norm': '6.4375', 'counters/examples': 5440, 'counters/updates': 340}
skipping logging after 5456 examples to avoid logging too frequently
skipping logging after 5472 examples to avoid logging too frequently
skipping logging after 5488 examples to avoid logging too frequently
train stats after 5504 examples: {'rewards_train/chosen': '-0.23896', 'rewards_train/rejected': '-4.941', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '4.7006', 'logps_train/rejected': '-165.99', 'logps_train/chosen': '-40.744', 'loss/train': '0.10612', 'examples_per_second': '5.3021', 'grad_norm': '8.5', 'counters/examples': 5504, 'counters/updates': 344}
skipping logging after 5520 examples to avoid logging too frequently
skipping logging after 5536 examples to avoid logging too frequently
skipping logging after 5552 examples to avoid logging too frequently
train stats after 5568 examples: {'rewards_train/chosen': '-0.046161', 'rewards_train/rejected': '-5.0182', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '4.9706', 'logps_train/rejected': '-160.84', 'logps_train/chosen': '-46.004', 'loss/train': '0.12935', 'examples_per_second': '4.7529', 'grad_norm': '11.25', 'counters/examples': 5568, 'counters/updates': 348}
skipping logging after 5584 examples to avoid logging too frequently
skipping logging after 5600 examples to avoid logging too frequently
skipping logging after 5616 examples to avoid logging too frequently
train stats after 5632 examples: {'rewards_train/chosen': '-0.27693', 'rewards_train/rejected': '-5.7205', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '5.4442', 'logps_train/rejected': '-190.99', 'logps_train/chosen': '-39.794', 'loss/train': '0.12392', 'examples_per_second': '5.6486', 'grad_norm': '7.9688', 'counters/examples': 5632, 'counters/updates': 352}
skipping logging after 5648 examples to avoid logging too frequently
skipping logging after 5664 examples to avoid logging too frequently
skipping logging after 5680 examples to avoid logging too frequently
train stats after 5696 examples: {'rewards_train/chosen': '-0.038074', 'rewards_train/rejected': '-5.684', 'rewards_train/accuracies': '1', 'rewards_train/margins': '5.6458', 'logps_train/rejected': '-200.7', 'logps_train/chosen': '-46.015', 'loss/train': '0.085242', 'examples_per_second': '5.3498', 'grad_norm': '5', 'counters/examples': 5696, 'counters/updates': 356}
skipping logging after 5712 examples to avoid logging too frequently
skipping logging after 5728 examples to avoid logging too frequently
skipping logging after 5744 examples to avoid logging too frequently
train stats after 5760 examples: {'rewards_train/chosen': '-0.27868', 'rewards_train/rejected': '-6.6365', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.3578', 'logps_train/rejected': '-234.65', 'logps_train/chosen': '-45.367', 'loss/train': '0.15686', 'examples_per_second': '5.0946', 'grad_norm': '11.938', 'counters/examples': 5760, 'counters/updates': 360}
skipping logging after 5776 examples to avoid logging too frequently
skipping logging after 5792 examples to avoid logging too frequently
skipping logging after 5808 examples to avoid logging too frequently
train stats after 5824 examples: {'rewards_train/chosen': '-0.060495', 'rewards_train/rejected': '-5.4743', 'rewards_train/accuracies': '1', 'rewards_train/margins': '5.4156', 'logps_train/rejected': '-189.72', 'logps_train/chosen': '-35.623', 'loss/train': '0.070773', 'examples_per_second': '5.1922', 'grad_norm': '4.75', 'counters/examples': 5824, 'counters/updates': 364}
skipping logging after 5840 examples to avoid logging too frequently
skipping logging after 5856 examples to avoid logging too frequently
skipping logging after 5872 examples to avoid logging too frequently
train stats after 5888 examples: {'rewards_train/chosen': '-0.26619', 'rewards_train/rejected': '-5.3335', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '5.0657', 'logps_train/rejected': '-188.93', 'logps_train/chosen': '-36.231', 'loss/train': '0.090544', 'examples_per_second': '5.7397', 'grad_norm': '6.4688', 'counters/examples': 5888, 'counters/updates': 368}
skipping logging after 5904 examples to avoid logging too frequently
skipping logging after 5920 examples to avoid logging too frequently
skipping logging after 5936 examples to avoid logging too frequently
train stats after 5952 examples: {'rewards_train/chosen': '0.092615', 'rewards_train/rejected': '-6.2231', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.3151', 'logps_train/rejected': '-212.43', 'logps_train/chosen': '-45.375', 'loss/train': '0.09968', 'examples_per_second': '4.9352', 'grad_norm': '8.25', 'counters/examples': 5952, 'counters/updates': 372}
skipping logging after 5968 examples to avoid logging too frequently
skipping logging after 5984 examples to avoid logging too frequently
skipping logging after 6000 examples to avoid logging too frequently
train stats after 6016 examples: {'rewards_train/chosen': '-0.087413', 'rewards_train/rejected': '-6.0782', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '5.9924', 'logps_train/rejected': '-218.16', 'logps_train/chosen': '-44.422', 'loss/train': '0.082403', 'examples_per_second': '4.9665', 'grad_norm': '6.4688', 'counters/examples': 6016, 'counters/updates': 376}
skipping logging after 6032 examples to avoid logging too frequently
skipping logging after 6048 examples to avoid logging too frequently
skipping logging after 6064 examples to avoid logging too frequently
train stats after 6080 examples: {'rewards_train/chosen': '-0.51575', 'rewards_train/rejected': '-4.9618', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '4.4452', 'logps_train/rejected': '-154.64', 'logps_train/chosen': '-41.835', 'loss/train': '0.22409', 'examples_per_second': '6.9244', 'grad_norm': '16.875', 'counters/examples': 6080, 'counters/updates': 380}
skipping logging after 6096 examples to avoid logging too frequently
skipping logging after 6112 examples to avoid logging too frequently
skipping logging after 6128 examples to avoid logging too frequently
train stats after 6144 examples: {'rewards_train/chosen': '-0.16876', 'rewards_train/rejected': '-5.7353', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '5.5665', 'logps_train/rejected': '-205.28', 'logps_train/chosen': '-45.597', 'loss/train': '0.1243', 'examples_per_second': '4.5729', 'grad_norm': '8.8125', 'counters/examples': 6144, 'counters/updates': 384}
skipping logging after 6160 examples to avoid logging too frequently
skipping logging after 6176 examples to avoid logging too frequently
skipping logging after 6192 examples to avoid logging too frequently
train stats after 6208 examples: {'rewards_train/chosen': '-0.1773', 'rewards_train/rejected': '-5.6403', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '5.4617', 'logps_train/rejected': '-195.18', 'logps_train/chosen': '-47.846', 'loss/train': '0.099391', 'examples_per_second': '5.3842', 'grad_norm': '5.5625', 'counters/examples': 6208, 'counters/updates': 388}
skipping logging after 6224 examples to avoid logging too frequently
skipping logging after 6240 examples to avoid logging too frequently
skipping logging after 6256 examples to avoid logging too frequently
train stats after 6272 examples: {'rewards_train/chosen': '-0.097704', 'rewards_train/rejected': '-5.1681', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '5.0712', 'logps_train/rejected': '-159.71', 'logps_train/chosen': '-49.327', 'loss/train': '0.11388', 'examples_per_second': '5.342', 'grad_norm': '8.6875', 'counters/examples': 6272, 'counters/updates': 392}
skipping logging after 6288 examples to avoid logging too frequently
skipping logging after 6304 examples to avoid logging too frequently
skipping logging after 6320 examples to avoid logging too frequently
train stats after 6336 examples: {'rewards_train/chosen': '-0.35936', 'rewards_train/rejected': '-6.2449', 'rewards_train/accuracies': '1', 'rewards_train/margins': '5.8871', 'logps_train/rejected': '-200.74', 'logps_train/chosen': '-41.005', 'loss/train': '0.062202', 'examples_per_second': '4.7886', 'grad_norm': '5.2812', 'counters/examples': 6336, 'counters/updates': 396}
skipping logging after 6352 examples to avoid logging too frequently
skipping logging after 6368 examples to avoid logging too frequently
skipping logging after 6384 examples to avoid logging too frequently
train stats after 6400 examples: {'rewards_train/chosen': '-0.44247', 'rewards_train/rejected': '-5.8337', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '5.3906', 'logps_train/rejected': '-183.67', 'logps_train/chosen': '-39.875', 'loss/train': '0.12035', 'examples_per_second': '5.3118', 'grad_norm': '6.9688', 'counters/examples': 6400, 'counters/updates': 400}
skipping logging after 6416 examples to avoid logging too frequently
skipping logging after 6432 examples to avoid logging too frequently
skipping logging after 6448 examples to avoid logging too frequently
train stats after 6464 examples: {'rewards_train/chosen': '-0.5513', 'rewards_train/rejected': '-5.3566', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '4.8066', 'logps_train/rejected': '-162.25', 'logps_train/chosen': '-39.925', 'loss/train': '0.13146', 'examples_per_second': '5.3801', 'grad_norm': '11', 'counters/examples': 6464, 'counters/updates': 404}
skipping logging after 6480 examples to avoid logging too frequently
skipping logging after 6496 examples to avoid logging too frequently
skipping logging after 6512 examples to avoid logging too frequently
train stats after 6528 examples: {'rewards_train/chosen': '-0.3197', 'rewards_train/rejected': '-7.0417', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.7207', 'logps_train/rejected': '-227.35', 'logps_train/chosen': '-48.296', 'loss/train': '0.063393', 'examples_per_second': '4.9578', 'grad_norm': '5.8125', 'counters/examples': 6528, 'counters/updates': 408}
skipping logging after 6544 examples to avoid logging too frequently
skipping logging after 6560 examples to avoid logging too frequently
skipping logging after 6576 examples to avoid logging too frequently
train stats after 6592 examples: {'rewards_train/chosen': '-0.34748', 'rewards_train/rejected': '-5.9966', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '5.6494', 'logps_train/rejected': '-186.89', 'logps_train/chosen': '-39.704', 'loss/train': '0.067492', 'examples_per_second': '5.117', 'grad_norm': '5.875', 'counters/examples': 6592, 'counters/updates': 412}
skipping logging after 6608 examples to avoid logging too frequently
skipping logging after 6624 examples to avoid logging too frequently
skipping logging after 6640 examples to avoid logging too frequently
train stats after 6656 examples: {'rewards_train/chosen': '-0.45848', 'rewards_train/rejected': '-6.8866', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.4285', 'logps_train/rejected': '-212.76', 'logps_train/chosen': '-61.661', 'loss/train': '0.099318', 'examples_per_second': '5.3984', 'grad_norm': '8.75', 'counters/examples': 6656, 'counters/updates': 416}
skipping logging after 6672 examples to avoid logging too frequently
skipping logging after 6688 examples to avoid logging too frequently
skipping logging after 6704 examples to avoid logging too frequently
train stats after 6720 examples: {'rewards_train/chosen': '-0.29233', 'rewards_train/rejected': '-6.7937', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.5024', 'logps_train/rejected': '-199.34', 'logps_train/chosen': '-49.894', 'loss/train': '0.038236', 'examples_per_second': '5.499', 'grad_norm': '4.3438', 'counters/examples': 6720, 'counters/updates': 420}
skipping logging after 6736 examples to avoid logging too frequently
skipping logging after 6752 examples to avoid logging too frequently
skipping logging after 6768 examples to avoid logging too frequently
train stats after 6784 examples: {'rewards_train/chosen': '-0.40501', 'rewards_train/rejected': '-8.4058', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.0016', 'logps_train/rejected': '-260.19', 'logps_train/chosen': '-51.893', 'loss/train': '0.049052', 'examples_per_second': '3.5234', 'grad_norm': '4.5625', 'counters/examples': 6784, 'counters/updates': 424}
skipping logging after 6800 examples to avoid logging too frequently
skipping logging after 6816 examples to avoid logging too frequently
skipping logging after 6832 examples to avoid logging too frequently
train stats after 6848 examples: {'rewards_train/chosen': '-0.52729', 'rewards_train/rejected': '-7.5293', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.0004', 'logps_train/rejected': '-224.52', 'logps_train/chosen': '-47.223', 'loss/train': '0.055841', 'examples_per_second': '5.7201', 'grad_norm': '6.375', 'counters/examples': 6848, 'counters/updates': 428}
skipping logging after 6864 examples to avoid logging too frequently
skipping logging after 6880 examples to avoid logging too frequently
skipping logging after 6896 examples to avoid logging too frequently
train stats after 6912 examples: {'rewards_train/chosen': '-0.74722', 'rewards_train/rejected': '-7.2834', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.5367', 'logps_train/rejected': '-219.8', 'logps_train/chosen': '-44.511', 'loss/train': '0.11542', 'examples_per_second': '4.5372', 'grad_norm': '12.875', 'counters/examples': 6912, 'counters/updates': 432}
skipping logging after 6928 examples to avoid logging too frequently
skipping logging after 6944 examples to avoid logging too frequently
skipping logging after 6960 examples to avoid logging too frequently
train stats after 6976 examples: {'rewards_train/chosen': '-0.6035', 'rewards_train/rejected': '-6.4082', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '5.8049', 'logps_train/rejected': '-202.92', 'logps_train/chosen': '-44.327', 'loss/train': '0.15885', 'examples_per_second': '5.4841', 'grad_norm': '15.312', 'counters/examples': 6976, 'counters/updates': 436}
skipping logging after 6992 examples to avoid logging too frequently
skipping logging after 7008 examples to avoid logging too frequently
skipping logging after 7024 examples to avoid logging too frequently
train stats after 7040 examples: {'rewards_train/chosen': '-0.83582', 'rewards_train/rejected': '-6.0092', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '5.1741', 'logps_train/rejected': '-167.05', 'logps_train/chosen': '-44.252', 'loss/train': '0.14258', 'examples_per_second': '4.5851', 'grad_norm': '13.938', 'counters/examples': 7040, 'counters/updates': 440}
skipping logging after 7056 examples to avoid logging too frequently
skipping logging after 7072 examples to avoid logging too frequently
skipping logging after 7088 examples to avoid logging too frequently
train stats after 7104 examples: {'rewards_train/chosen': '-0.80292', 'rewards_train/rejected': '-6.1676', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '5.3669', 'logps_train/rejected': '-180.13', 'logps_train/chosen': '-37.891', 'loss/train': '0.1363', 'examples_per_second': '5.5544', 'grad_norm': '15.375', 'counters/examples': 7104, 'counters/updates': 444}
skipping logging after 7120 examples to avoid logging too frequently
skipping logging after 7136 examples to avoid logging too frequently
skipping logging after 7152 examples to avoid logging too frequently
train stats after 7168 examples: {'rewards_train/chosen': '-0.58759', 'rewards_train/rejected': '-6.1368', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '5.5533', 'logps_train/rejected': '-179.16', 'logps_train/chosen': '-45.083', 'loss/train': '0.089145', 'examples_per_second': '5.3805', 'grad_norm': '7.5', 'counters/examples': 7168, 'counters/updates': 448}
skipping logging after 7184 examples to avoid logging too frequently
skipping logging after 7200 examples to avoid logging too frequently
skipping logging after 7216 examples to avoid logging too frequently
train stats after 7232 examples: {'rewards_train/chosen': '-0.85706', 'rewards_train/rejected': '-6.9598', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.1033', 'logps_train/rejected': '-213.56', 'logps_train/chosen': '-54.464', 'loss/train': '0.17622', 'examples_per_second': '5.3904', 'grad_norm': '14.375', 'counters/examples': 7232, 'counters/updates': 452}
skipping logging after 7248 examples to avoid logging too frequently
skipping logging after 7264 examples to avoid logging too frequently
skipping logging after 7280 examples to avoid logging too frequently
train stats after 7296 examples: {'rewards_train/chosen': '-0.57523', 'rewards_train/rejected': '-7.8826', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.3091', 'logps_train/rejected': '-260.96', 'logps_train/chosen': '-55.465', 'loss/train': '0.068053', 'examples_per_second': '4.6774', 'grad_norm': '6.4375', 'counters/examples': 7296, 'counters/updates': 456}
skipping logging after 7312 examples to avoid logging too frequently
skipping logging after 7328 examples to avoid logging too frequently
skipping logging after 7344 examples to avoid logging too frequently
train stats after 7360 examples: {'rewards_train/chosen': '-0.27014', 'rewards_train/rejected': '-6.3096', 'rewards_train/accuracies': '1', 'rewards_train/margins': '6.0398', 'logps_train/rejected': '-199.44', 'logps_train/chosen': '-40.318', 'loss/train': '0.08459', 'examples_per_second': '5.4513', 'grad_norm': '6.6875', 'counters/examples': 7360, 'counters/updates': 460}
skipping logging after 7376 examples to avoid logging too frequently
skipping logging after 7392 examples to avoid logging too frequently
skipping logging after 7408 examples to avoid logging too frequently
train stats after 7424 examples: {'rewards_train/chosen': '-0.7637', 'rewards_train/rejected': '-6.9939', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.2299', 'logps_train/rejected': '-203.05', 'logps_train/chosen': '-48.223', 'loss/train': '0.091144', 'examples_per_second': '5.1953', 'grad_norm': '7.4688', 'counters/examples': 7424, 'counters/updates': 464}
skipping logging after 7440 examples to avoid logging too frequently
skipping logging after 7456 examples to avoid logging too frequently
skipping logging after 7472 examples to avoid logging too frequently
train stats after 7488 examples: {'rewards_train/chosen': '-0.091644', 'rewards_train/rejected': '-6.3419', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.2487', 'logps_train/rejected': '-193.14', 'logps_train/chosen': '-45.396', 'loss/train': '0.053938', 'examples_per_second': '4.7341', 'grad_norm': '4.0938', 'counters/examples': 7488, 'counters/updates': 468}
skipping logging after 7504 examples to avoid logging too frequently
skipping logging after 7520 examples to avoid logging too frequently
skipping logging after 7536 examples to avoid logging too frequently
train stats after 7552 examples: {'rewards_train/chosen': '-0.72753', 'rewards_train/rejected': '-5.9826', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '5.254', 'logps_train/rejected': '-176.35', 'logps_train/chosen': '-45.824', 'loss/train': '0.16583', 'examples_per_second': '5.978', 'grad_norm': '15', 'counters/examples': 7552, 'counters/updates': 472}
skipping logging after 7568 examples to avoid logging too frequently
skipping logging after 7584 examples to avoid logging too frequently
skipping logging after 7600 examples to avoid logging too frequently
train stats after 7616 examples: {'rewards_train/chosen': '-0.29013', 'rewards_train/rejected': '-6.5764', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.2842', 'logps_train/rejected': '-209.12', 'logps_train/chosen': '-45.779', 'loss/train': '0.10115', 'examples_per_second': '4.5064', 'grad_norm': '8.125', 'counters/examples': 7616, 'counters/updates': 476}
skipping logging after 7632 examples to avoid logging too frequently
skipping logging after 7648 examples to avoid logging too frequently
skipping logging after 7664 examples to avoid logging too frequently
train stats after 7680 examples: {'rewards_train/chosen': '-0.36066', 'rewards_train/rejected': '-6.6178', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.2562', 'logps_train/rejected': '-222.79', 'logps_train/chosen': '-46.204', 'loss/train': '0.08604', 'examples_per_second': '4.2287', 'grad_norm': '8.1875', 'counters/examples': 7680, 'counters/updates': 480}
skipping logging after 7696 examples to avoid logging too frequently
skipping logging after 7712 examples to avoid logging too frequently
skipping logging after 7728 examples to avoid logging too frequently
train stats after 7744 examples: {'rewards_train/chosen': '-0.62817', 'rewards_train/rejected': '-6.8499', 'rewards_train/accuracies': '1', 'rewards_train/margins': '6.2225', 'logps_train/rejected': '-209.21', 'logps_train/chosen': '-44.794', 'loss/train': '0.08142', 'examples_per_second': '4.8954', 'grad_norm': '7.0312', 'counters/examples': 7744, 'counters/updates': 484}
skipping logging after 7760 examples to avoid logging too frequently
skipping logging after 7776 examples to avoid logging too frequently
skipping logging after 7792 examples to avoid logging too frequently
train stats after 7808 examples: {'rewards_train/chosen': '-0.56283', 'rewards_train/rejected': '-6.7037', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.1403', 'logps_train/rejected': '-202.87', 'logps_train/chosen': '-40.561', 'loss/train': '0.12251', 'examples_per_second': '4.9582', 'grad_norm': '9.4375', 'counters/examples': 7808, 'counters/updates': 488}
skipping logging after 7824 examples to avoid logging too frequently
skipping logging after 7840 examples to avoid logging too frequently
skipping logging after 7856 examples to avoid logging too frequently
train stats after 7872 examples: {'rewards_train/chosen': '-0.45443', 'rewards_train/rejected': '-7.4472', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.995', 'logps_train/rejected': '-225.03', 'logps_train/chosen': '-54.06', 'loss/train': '0.19631', 'examples_per_second': '5.4327', 'grad_norm': '16.75', 'counters/examples': 7872, 'counters/updates': 492}
skipping logging after 7888 examples to avoid logging too frequently
skipping logging after 7904 examples to avoid logging too frequently
skipping logging after 7920 examples to avoid logging too frequently
train stats after 7936 examples: {'rewards_train/chosen': '-0.3566', 'rewards_train/rejected': '-5.5671', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '5.2096', 'logps_train/rejected': '-170.99', 'logps_train/chosen': '-38.203', 'loss/train': '0.13604', 'examples_per_second': '5.2039', 'grad_norm': '8.5625', 'counters/examples': 7936, 'counters/updates': 496}
skipping logging after 7952 examples to avoid logging too frequently
skipping logging after 7968 examples to avoid logging too frequently
skipping logging after 7984 examples to avoid logging too frequently
train stats after 8000 examples: {'rewards_train/chosen': '-0.55137', 'rewards_train/rejected': '-6.031', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '5.4789', 'logps_train/rejected': '-190.8', 'logps_train/chosen': '-51.55', 'loss/train': '0.16812', 'examples_per_second': '4.5119', 'grad_norm': '20.875', 'counters/examples': 8000, 'counters/updates': 500}
Running evaluation after 8000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<01:00,  1.95s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:00,  2.02s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:53,  1.84s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.86s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.53s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.65s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:36,  1.57s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.50s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:22,  1.30s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.25s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:20,  1.34s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.35s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:14,  1.28s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.30s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.27s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.31s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.49s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.42s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.62s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.43s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.42s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.44s/it]
eval after 8000: {'rewards_eval/chosen': '-6.1533', 'rewards_eval/rejected': '-6.2915', 'rewards_eval/accuracies': '0.50195', 'rewards_eval/margins': '0.13869', 'logps_eval/rejected': '-210.58', 'logps_eval/chosen': '-206.45', 'loss/eval': '1.8877'}
skipping logging after 8016 examples to avoid logging too frequently
skipping logging after 8032 examples to avoid logging too frequently
skipping logging after 8048 examples to avoid logging too frequently
train stats after 8064 examples: {'rewards_train/chosen': '-0.30292', 'rewards_train/rejected': '-6.2753', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '5.9736', 'logps_train/rejected': '-209.14', 'logps_train/chosen': '-40.72', 'loss/train': '0.063348', 'examples_per_second': '4.9834', 'grad_norm': '4.7188', 'counters/examples': 8064, 'counters/updates': 504}
skipping logging after 8080 examples to avoid logging too frequently
skipping logging after 8096 examples to avoid logging too frequently
skipping logging after 8112 examples to avoid logging too frequently
train stats after 8128 examples: {'rewards_train/chosen': '-0.3334', 'rewards_train/rejected': '-5.6655', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '5.3324', 'logps_train/rejected': '-178.77', 'logps_train/chosen': '-45.543', 'loss/train': '0.08651', 'examples_per_second': '5.4691', 'grad_norm': '9.875', 'counters/examples': 8128, 'counters/updates': 508}
skipping logging after 8144 examples to avoid logging too frequently
skipping logging after 8160 examples to avoid logging too frequently
skipping logging after 8176 examples to avoid logging too frequently
train stats after 8192 examples: {'rewards_train/chosen': '-0.63203', 'rewards_train/rejected': '-7.6465', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.0151', 'logps_train/rejected': '-235.75', 'logps_train/chosen': '-43.981', 'loss/train': '0.082874', 'examples_per_second': '5.2042', 'grad_norm': '11.25', 'counters/examples': 8192, 'counters/updates': 512}
skipping logging after 8208 examples to avoid logging too frequently
skipping logging after 8224 examples to avoid logging too frequently
skipping logging after 8240 examples to avoid logging too frequently
train stats after 8256 examples: {'rewards_train/chosen': '-0.43615', 'rewards_train/rejected': '-5.8104', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '5.3749', 'logps_train/rejected': '-183.99', 'logps_train/chosen': '-46.428', 'loss/train': '0.092558', 'examples_per_second': '5.7779', 'grad_norm': '7.0625', 'counters/examples': 8256, 'counters/updates': 516}
skipping logging after 8272 examples to avoid logging too frequently
skipping logging after 8288 examples to avoid logging too frequently
skipping logging after 8304 examples to avoid logging too frequently
train stats after 8320 examples: {'rewards_train/chosen': '-0.16696', 'rewards_train/rejected': '-7.1653', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.9979', 'logps_train/rejected': '-229.49', 'logps_train/chosen': '-50.568', 'loss/train': '0.090579', 'examples_per_second': '4.4781', 'grad_norm': '11.562', 'counters/examples': 8320, 'counters/updates': 520}
skipping logging after 8336 examples to avoid logging too frequently
skipping logging after 8352 examples to avoid logging too frequently
skipping logging after 8368 examples to avoid logging too frequently
train stats after 8384 examples: {'rewards_train/chosen': '-0.41594', 'rewards_train/rejected': '-7.0507', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.6342', 'logps_train/rejected': '-209.88', 'logps_train/chosen': '-43.706', 'loss/train': '0.061046', 'examples_per_second': '5.9217', 'grad_norm': '5.0625', 'counters/examples': 8384, 'counters/updates': 524}
skipping logging after 8400 examples to avoid logging too frequently
skipping logging after 8416 examples to avoid logging too frequently
skipping logging after 8432 examples to avoid logging too frequently
train stats after 8448 examples: {'rewards_train/chosen': '-0.5446', 'rewards_train/rejected': '-6.5913', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.0496', 'logps_train/rejected': '-205.54', 'logps_train/chosen': '-47.55', 'loss/train': '0.13224', 'examples_per_second': '4.3599', 'grad_norm': '9.5', 'counters/examples': 8448, 'counters/updates': 528}
skipping logging after 8464 examples to avoid logging too frequently
skipping logging after 8480 examples to avoid logging too frequently
skipping logging after 8496 examples to avoid logging too frequently
train stats after 8512 examples: {'rewards_train/chosen': '-0.4375', 'rewards_train/rejected': '-6.9506', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.5132', 'logps_train/rejected': '-209.47', 'logps_train/chosen': '-44.826', 'loss/train': '0.073084', 'examples_per_second': '5.034', 'grad_norm': '8.3125', 'counters/examples': 8512, 'counters/updates': 532}
skipping logging after 8528 examples to avoid logging too frequently
skipping logging after 8544 examples to avoid logging too frequently
skipping logging after 8560 examples to avoid logging too frequently
train stats after 8576 examples: {'rewards_train/chosen': '-0.64372', 'rewards_train/rejected': '-7.1122', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.4651', 'logps_train/rejected': '-225.94', 'logps_train/chosen': '-48.037', 'loss/train': '0.070862', 'examples_per_second': '5.2405', 'grad_norm': '7.0312', 'counters/examples': 8576, 'counters/updates': 536}
skipping logging after 8592 examples to avoid logging too frequently
skipping logging after 8608 examples to avoid logging too frequently
skipping logging after 8624 examples to avoid logging too frequently
train stats after 8640 examples: {'rewards_train/chosen': '-0.48564', 'rewards_train/rejected': '-5.957', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '5.4685', 'logps_train/rejected': '-166.02', 'logps_train/chosen': '-47.451', 'loss/train': '0.071874', 'examples_per_second': '4.798', 'grad_norm': '5.8125', 'counters/examples': 8640, 'counters/updates': 540}
skipping logging after 8656 examples to avoid logging too frequently
skipping logging after 8672 examples to avoid logging too frequently
skipping logging after 8688 examples to avoid logging too frequently
train stats after 8704 examples: {'rewards_train/chosen': '-0.65767', 'rewards_train/rejected': '-8.0349', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.3792', 'logps_train/rejected': '-230.03', 'logps_train/chosen': '-45.793', 'loss/train': '0.062267', 'examples_per_second': '5.8233', 'grad_norm': '5.875', 'counters/examples': 8704, 'counters/updates': 544}
skipping logging after 8720 examples to avoid logging too frequently
skipping logging after 8736 examples to avoid logging too frequently
skipping logging after 8752 examples to avoid logging too frequently
train stats after 8768 examples: {'rewards_train/chosen': '-0.398', 'rewards_train/rejected': '-8.4069', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.0094', 'logps_train/rejected': '-274.66', 'logps_train/chosen': '-47.19', 'loss/train': '0.040561', 'examples_per_second': '4.3384', 'grad_norm': '3.3906', 'counters/examples': 8768, 'counters/updates': 548}
skipping logging after 8784 examples to avoid logging too frequently
skipping logging after 8800 examples to avoid logging too frequently
skipping logging after 8816 examples to avoid logging too frequently
train stats after 8832 examples: {'rewards_train/chosen': '-0.80182', 'rewards_train/rejected': '-7.5014', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '6.7003', 'logps_train/rejected': '-213.38', 'logps_train/chosen': '-50.945', 'loss/train': '0.11144', 'examples_per_second': '4.9749', 'grad_norm': '8.875', 'counters/examples': 8832, 'counters/updates': 552}
skipping logging after 8848 examples to avoid logging too frequently
skipping logging after 8864 examples to avoid logging too frequently
skipping logging after 8880 examples to avoid logging too frequently
train stats after 8896 examples: {'rewards_train/chosen': '-0.83987', 'rewards_train/rejected': '-6.7512', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '5.9099', 'logps_train/rejected': '-182.94', 'logps_train/chosen': '-43.714', 'loss/train': '0.10786', 'examples_per_second': '4.4816', 'grad_norm': '13.688', 'counters/examples': 8896, 'counters/updates': 556}
skipping logging after 8912 examples to avoid logging too frequently
skipping logging after 8928 examples to avoid logging too frequently
skipping logging after 8944 examples to avoid logging too frequently
train stats after 8960 examples: {'rewards_train/chosen': '-0.34686', 'rewards_train/rejected': '-7.1681', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.8205', 'logps_train/rejected': '-223.57', 'logps_train/chosen': '-40.531', 'loss/train': '0.075977', 'examples_per_second': '5.0695', 'grad_norm': '5.9688', 'counters/examples': 8960, 'counters/updates': 560}
skipping logging after 8976 examples to avoid logging too frequently
skipping logging after 8992 examples to avoid logging too frequently
skipping logging after 9008 examples to avoid logging too frequently
train stats after 9024 examples: {'rewards_train/chosen': '-0.50386', 'rewards_train/rejected': '-7.2524', 'rewards_train/accuracies': '1', 'rewards_train/margins': '6.7462', 'logps_train/rejected': '-202.92', 'logps_train/chosen': '-53.91', 'loss/train': '0.043217', 'examples_per_second': '5.8025', 'grad_norm': '4.7812', 'counters/examples': 9024, 'counters/updates': 564}
skipping logging after 9040 examples to avoid logging too frequently
skipping logging after 9056 examples to avoid logging too frequently
skipping logging after 9072 examples to avoid logging too frequently
train stats after 9088 examples: {'rewards_train/chosen': '-0.65037', 'rewards_train/rejected': '-7.0125', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.363', 'logps_train/rejected': '-186.61', 'logps_train/chosen': '-37.611', 'loss/train': '0.10391', 'examples_per_second': '4.9183', 'grad_norm': '8.9375', 'counters/examples': 9088, 'counters/updates': 568}
skipping logging after 9104 examples to avoid logging too frequently
skipping logging after 9120 examples to avoid logging too frequently
skipping logging after 9136 examples to avoid logging too frequently
train stats after 9152 examples: {'rewards_train/chosen': '-0.73116', 'rewards_train/rejected': '-8.0501', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.3224', 'logps_train/rejected': '-238.26', 'logps_train/chosen': '-54.887', 'loss/train': '0.095492', 'examples_per_second': '5.3832', 'grad_norm': '10.312', 'counters/examples': 9152, 'counters/updates': 572}
skipping logging after 9168 examples to avoid logging too frequently
skipping logging after 9184 examples to avoid logging too frequently
skipping logging after 9200 examples to avoid logging too frequently
train stats after 9216 examples: {'rewards_train/chosen': '-0.66252', 'rewards_train/rejected': '-7.2383', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.5776', 'logps_train/rejected': '-214.15', 'logps_train/chosen': '-44.379', 'loss/train': '0.059447', 'examples_per_second': '5.0567', 'grad_norm': '7.25', 'counters/examples': 9216, 'counters/updates': 576}
skipping logging after 9232 examples to avoid logging too frequently
skipping logging after 9248 examples to avoid logging too frequently
skipping logging after 9264 examples to avoid logging too frequently
train stats after 9280 examples: {'rewards_train/chosen': '-1.007', 'rewards_train/rejected': '-7.4316', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.4255', 'logps_train/rejected': '-201.35', 'logps_train/chosen': '-53.642', 'loss/train': '0.097357', 'examples_per_second': '6.4789', 'grad_norm': '9.5625', 'counters/examples': 9280, 'counters/updates': 580}
skipping logging after 9296 examples to avoid logging too frequently
skipping logging after 9312 examples to avoid logging too frequently
skipping logging after 9328 examples to avoid logging too frequently
train stats after 9344 examples: {'rewards_train/chosen': '-0.67945', 'rewards_train/rejected': '-8.9383', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.2597', 'logps_train/rejected': '-242.54', 'logps_train/chosen': '-40.757', 'loss/train': '0.079626', 'examples_per_second': '4.152', 'grad_norm': '5.75', 'counters/examples': 9344, 'counters/updates': 584}
skipping logging after 9360 examples to avoid logging too frequently
skipping logging after 9376 examples to avoid logging too frequently
skipping logging after 9392 examples to avoid logging too frequently
train stats after 9408 examples: {'rewards_train/chosen': '-0.80255', 'rewards_train/rejected': '-7.6973', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.8944', 'logps_train/rejected': '-181.65', 'logps_train/chosen': '-37.669', 'loss/train': '0.098939', 'examples_per_second': '5.9249', 'grad_norm': '9.125', 'counters/examples': 9408, 'counters/updates': 588}
skipping logging after 9424 examples to avoid logging too frequently
skipping logging after 9440 examples to avoid logging too frequently
skipping logging after 9456 examples to avoid logging too frequently
train stats after 9472 examples: {'rewards_train/chosen': '-0.62519', 'rewards_train/rejected': '-8.2885', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.6619', 'logps_train/rejected': '-232.72', 'logps_train/chosen': '-45.626', 'loss/train': '0.081708', 'examples_per_second': '4.4803', 'grad_norm': '7.4375', 'counters/examples': 9472, 'counters/updates': 592}
skipping logging after 9488 examples to avoid logging too frequently
skipping logging after 9504 examples to avoid logging too frequently
skipping logging after 9520 examples to avoid logging too frequently
train stats after 9536 examples: {'rewards_train/chosen': '-0.64766', 'rewards_train/rejected': '-8.9755', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.3264', 'logps_train/rejected': '-242.4', 'logps_train/chosen': '-53.313', 'loss/train': '0.042702', 'examples_per_second': '4.7718', 'grad_norm': '4.125', 'counters/examples': 9536, 'counters/updates': 596}
skipping logging after 9552 examples to avoid logging too frequently
skipping logging after 9568 examples to avoid logging too frequently
skipping logging after 9584 examples to avoid logging too frequently
train stats after 9600 examples: {'rewards_train/chosen': '-0.73855', 'rewards_train/rejected': '-8.1458', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.4062', 'logps_train/rejected': '-216.58', 'logps_train/chosen': '-47.911', 'loss/train': '0.1464', 'examples_per_second': '5.0259', 'grad_norm': '11.75', 'counters/examples': 9600, 'counters/updates': 600}
skipping logging after 9616 examples to avoid logging too frequently
skipping logging after 9632 examples to avoid logging too frequently
skipping logging after 9648 examples to avoid logging too frequently
train stats after 9664 examples: {'rewards_train/chosen': '-0.32817', 'rewards_train/rejected': '-6.9007', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.5763', 'logps_train/rejected': '-206.25', 'logps_train/chosen': '-38.728', 'loss/train': '0.13703', 'examples_per_second': '6.0278', 'grad_norm': '13.688', 'counters/examples': 9664, 'counters/updates': 604}
skipping logging after 9680 examples to avoid logging too frequently
skipping logging after 9696 examples to avoid logging too frequently
skipping logging after 9712 examples to avoid logging too frequently
train stats after 9728 examples: {'rewards_train/chosen': '-0.17727', 'rewards_train/rejected': '-6.9005', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.7252', 'logps_train/rejected': '-225.36', 'logps_train/chosen': '-47.113', 'loss/train': '0.093448', 'examples_per_second': '4.8401', 'grad_norm': '8.625', 'counters/examples': 9728, 'counters/updates': 608}
skipping logging after 9744 examples to avoid logging too frequently
skipping logging after 9760 examples to avoid logging too frequently
skipping logging after 9776 examples to avoid logging too frequently
train stats after 9792 examples: {'rewards_train/chosen': '-0.21872', 'rewards_train/rejected': '-6.4092', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.1915', 'logps_train/rejected': '-200.29', 'logps_train/chosen': '-52.28', 'loss/train': '0.11256', 'examples_per_second': '5.2566', 'grad_norm': '12.562', 'counters/examples': 9792, 'counters/updates': 612}
skipping logging after 9808 examples to avoid logging too frequently
skipping logging after 9824 examples to avoid logging too frequently
skipping logging after 9840 examples to avoid logging too frequently
train stats after 9856 examples: {'rewards_train/chosen': '-0.18763', 'rewards_train/rejected': '-6.7428', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.5571', 'logps_train/rejected': '-192.72', 'logps_train/chosen': '-39.57', 'loss/train': '0.063167', 'examples_per_second': '4.5307', 'grad_norm': '5.6562', 'counters/examples': 9856, 'counters/updates': 616}
skipping logging after 9872 examples to avoid logging too frequently
skipping logging after 9888 examples to avoid logging too frequently
skipping logging after 9904 examples to avoid logging too frequently
train stats after 9920 examples: {'rewards_train/chosen': '-0.37027', 'rewards_train/rejected': '-6.4085', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.0376', 'logps_train/rejected': '-190.37', 'logps_train/chosen': '-53.34', 'loss/train': '0.072284', 'examples_per_second': '5.5871', 'grad_norm': '6.875', 'counters/examples': 9920, 'counters/updates': 620}
skipping logging after 9936 examples to avoid logging too frequently
skipping logging after 9952 examples to avoid logging too frequently
skipping logging after 9968 examples to avoid logging too frequently
train stats after 9984 examples: {'rewards_train/chosen': '-0.77597', 'rewards_train/rejected': '-7.2821', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '6.5055', 'logps_train/rejected': '-210.74', 'logps_train/chosen': '-46.163', 'loss/train': '0.36013', 'examples_per_second': '6.2465', 'grad_norm': '22.625', 'counters/examples': 9984, 'counters/updates': 624}
skipping logging after 10000 examples to avoid logging too frequently
skipping logging after 10016 examples to avoid logging too frequently
skipping logging after 10032 examples to avoid logging too frequently
train stats after 10048 examples: {'rewards_train/chosen': '-0.16842', 'rewards_train/rejected': '-5.9144', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '5.7433', 'logps_train/rejected': '-183.93', 'logps_train/chosen': '-36.356', 'loss/train': '0.057511', 'examples_per_second': '5.2105', 'grad_norm': '3.7969', 'counters/examples': 10048, 'counters/updates': 628}
skipping logging after 10064 examples to avoid logging too frequently
skipping logging after 10080 examples to avoid logging too frequently
skipping logging after 10096 examples to avoid logging too frequently
train stats after 10112 examples: {'rewards_train/chosen': '-0.26908', 'rewards_train/rejected': '-6.751', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.4827', 'logps_train/rejected': '-207.17', 'logps_train/chosen': '-44.792', 'loss/train': '0.059447', 'examples_per_second': '5.215', 'grad_norm': '7', 'counters/examples': 10112, 'counters/updates': 632}
skipping logging after 10128 examples to avoid logging too frequently
skipping logging after 10144 examples to avoid logging too frequently
skipping logging after 10160 examples to avoid logging too frequently
train stats after 10176 examples: {'rewards_train/chosen': '-0.10558', 'rewards_train/rejected': '-6.1027', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '5.998', 'logps_train/rejected': '-194.99', 'logps_train/chosen': '-46.535', 'loss/train': '0.069052', 'examples_per_second': '5.2277', 'grad_norm': '6.3438', 'counters/examples': 10176, 'counters/updates': 636}
skipping logging after 10192 examples to avoid logging too frequently
skipping logging after 10208 examples to avoid logging too frequently
skipping logging after 10224 examples to avoid logging too frequently
train stats after 10240 examples: {'rewards_train/chosen': '-0.34597', 'rewards_train/rejected': '-6.3411', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '5.9925', 'logps_train/rejected': '-202.29', 'logps_train/chosen': '-51.205', 'loss/train': '0.12927', 'examples_per_second': '5.9163', 'grad_norm': '8.875', 'counters/examples': 10240, 'counters/updates': 640}
skipping logging after 10256 examples to avoid logging too frequently
skipping logging after 10272 examples to avoid logging too frequently
skipping logging after 10288 examples to avoid logging too frequently
train stats after 10304 examples: {'rewards_train/chosen': '-0.49851', 'rewards_train/rejected': '-6.2932', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '5.7958', 'logps_train/rejected': '-195.5', 'logps_train/chosen': '-47.431', 'loss/train': '0.10095', 'examples_per_second': '4.8995', 'grad_norm': '12.375', 'counters/examples': 10304, 'counters/updates': 644}
skipping logging after 10320 examples to avoid logging too frequently
skipping logging after 10336 examples to avoid logging too frequently
skipping logging after 10352 examples to avoid logging too frequently
train stats after 10368 examples: {'rewards_train/chosen': '-0.26949', 'rewards_train/rejected': '-6.2388', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '5.9708', 'logps_train/rejected': '-192.32', 'logps_train/chosen': '-39.839', 'loss/train': '0.070463', 'examples_per_second': '5.3194', 'grad_norm': '5.3125', 'counters/examples': 10368, 'counters/updates': 648}
skipping logging after 10384 examples to avoid logging too frequently
skipping logging after 10400 examples to avoid logging too frequently
skipping logging after 10416 examples to avoid logging too frequently
train stats after 10432 examples: {'rewards_train/chosen': '-0.45518', 'rewards_train/rejected': '-7.2977', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.8413', 'logps_train/rejected': '-212.89', 'logps_train/chosen': '-46.479', 'loss/train': '0.15836', 'examples_per_second': '5.0439', 'grad_norm': '14.25', 'counters/examples': 10432, 'counters/updates': 652}
skipping logging after 10448 examples to avoid logging too frequently
skipping logging after 10464 examples to avoid logging too frequently
skipping logging after 10480 examples to avoid logging too frequently
train stats after 10496 examples: {'rewards_train/chosen': '-0.54725', 'rewards_train/rejected': '-7.8091', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.2624', 'logps_train/rejected': '-226.19', 'logps_train/chosen': '-54.137', 'loss/train': '0.086205', 'examples_per_second': '4.5647', 'grad_norm': '10.062', 'counters/examples': 10496, 'counters/updates': 656}
skipping logging after 10512 examples to avoid logging too frequently
skipping logging after 10528 examples to avoid logging too frequently
skipping logging after 10544 examples to avoid logging too frequently
train stats after 10560 examples: {'rewards_train/chosen': '-0.43156', 'rewards_train/rejected': '-6.4186', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '5.9865', 'logps_train/rejected': '-193.28', 'logps_train/chosen': '-45.983', 'loss/train': '0.068225', 'examples_per_second': '5.6103', 'grad_norm': '4.6562', 'counters/examples': 10560, 'counters/updates': 660}
skipping logging after 10576 examples to avoid logging too frequently
skipping logging after 10592 examples to avoid logging too frequently
skipping logging after 10608 examples to avoid logging too frequently
train stats after 10624 examples: {'rewards_train/chosen': '-0.51376', 'rewards_train/rejected': '-6.0005', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '5.4858', 'logps_train/rejected': '-181.46', 'logps_train/chosen': '-45.58', 'loss/train': '0.12594', 'examples_per_second': '4.8199', 'grad_norm': '9.1875', 'counters/examples': 10624, 'counters/updates': 664}
skipping logging after 10640 examples to avoid logging too frequently
skipping logging after 10656 examples to avoid logging too frequently
skipping logging after 10672 examples to avoid logging too frequently
train stats after 10688 examples: {'rewards_train/chosen': '-0.71955', 'rewards_train/rejected': '-7.8875', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.1692', 'logps_train/rejected': '-229.23', 'logps_train/chosen': '-48.443', 'loss/train': '0.041615', 'examples_per_second': '5.2435', 'grad_norm': '4.0312', 'counters/examples': 10688, 'counters/updates': 668}
skipping logging after 10704 examples to avoid logging too frequently
skipping logging after 10720 examples to avoid logging too frequently
skipping logging after 10736 examples to avoid logging too frequently
train stats after 10752 examples: {'rewards_train/chosen': '-1.004', 'rewards_train/rejected': '-7.2372', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.2339', 'logps_train/rejected': '-212.31', 'logps_train/chosen': '-53.226', 'loss/train': '0.068717', 'examples_per_second': '4.5147', 'grad_norm': '7.4688', 'counters/examples': 10752, 'counters/updates': 672}
skipping logging after 10768 examples to avoid logging too frequently
skipping logging after 10784 examples to avoid logging too frequently
skipping logging after 10800 examples to avoid logging too frequently
train stats after 10816 examples: {'rewards_train/chosen': '-1.0534', 'rewards_train/rejected': '-8.6642', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.611', 'logps_train/rejected': '-221.23', 'logps_train/chosen': '-53.155', 'loss/train': '0.051131', 'examples_per_second': '4.8644', 'grad_norm': '8.25', 'counters/examples': 10816, 'counters/updates': 676}
skipping logging after 10832 examples to avoid logging too frequently
skipping logging after 10848 examples to avoid logging too frequently
skipping logging after 10864 examples to avoid logging too frequently
train stats after 10880 examples: {'rewards_train/chosen': '-0.92469', 'rewards_train/rejected': '-7.8556', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.9283', 'logps_train/rejected': '-222.53', 'logps_train/chosen': '-52.08', 'loss/train': '0.084879', 'examples_per_second': '4.3492', 'grad_norm': '10.438', 'counters/examples': 10880, 'counters/updates': 680}
skipping logging after 10896 examples to avoid logging too frequently
skipping logging after 10912 examples to avoid logging too frequently
skipping logging after 10928 examples to avoid logging too frequently
train stats after 10944 examples: {'rewards_train/chosen': '-0.73059', 'rewards_train/rejected': '-6.4688', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '5.7389', 'logps_train/rejected': '-184.82', 'logps_train/chosen': '-47.996', 'loss/train': '0.11725', 'examples_per_second': '4.2547', 'grad_norm': '12', 'counters/examples': 10944, 'counters/updates': 684}
skipping logging after 10960 examples to avoid logging too frequently
skipping logging after 10976 examples to avoid logging too frequently
skipping logging after 10992 examples to avoid logging too frequently
train stats after 11008 examples: {'rewards_train/chosen': '-0.53265', 'rewards_train/rejected': '-7.5867', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.0547', 'logps_train/rejected': '-260.88', 'logps_train/chosen': '-53.926', 'loss/train': '0.053374', 'examples_per_second': '4.7074', 'grad_norm': '6.8125', 'counters/examples': 11008, 'counters/updates': 688}
skipping logging after 11024 examples to avoid logging too frequently
skipping logging after 11040 examples to avoid logging too frequently
skipping logging after 11056 examples to avoid logging too frequently
train stats after 11072 examples: {'rewards_train/chosen': '-0.68154', 'rewards_train/rejected': '-7.4461', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.767', 'logps_train/rejected': '-230.73', 'logps_train/chosen': '-48.592', 'loss/train': '0.059968', 'examples_per_second': '4.6301', 'grad_norm': '6.4375', 'counters/examples': 11072, 'counters/updates': 692}
skipping logging after 11088 examples to avoid logging too frequently
skipping logging after 11104 examples to avoid logging too frequently
skipping logging after 11120 examples to avoid logging too frequently
train stats after 11136 examples: {'rewards_train/chosen': '-0.86107', 'rewards_train/rejected': '-7.2557', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.3948', 'logps_train/rejected': '-207.57', 'logps_train/chosen': '-50.102', 'loss/train': '0.082717', 'examples_per_second': '4.6474', 'grad_norm': '9.875', 'counters/examples': 11136, 'counters/updates': 696}
skipping logging after 11152 examples to avoid logging too frequently
skipping logging after 11168 examples to avoid logging too frequently
skipping logging after 11184 examples to avoid logging too frequently
train stats after 11200 examples: {'rewards_train/chosen': '-0.94955', 'rewards_train/rejected': '-6.7515', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '5.8005', 'logps_train/rejected': '-179.15', 'logps_train/chosen': '-37.795', 'loss/train': '0.098115', 'examples_per_second': '5.919', 'grad_norm': '7.625', 'counters/examples': 11200, 'counters/updates': 700}
skipping logging after 11216 examples to avoid logging too frequently
skipping logging after 11232 examples to avoid logging too frequently
skipping logging after 11248 examples to avoid logging too frequently
train stats after 11264 examples: {'rewards_train/chosen': '-0.85816', 'rewards_train/rejected': '-7.7038', 'rewards_train/accuracies': '1', 'rewards_train/margins': '6.847', 'logps_train/rejected': '-208.4', 'logps_train/chosen': '-43.11', 'loss/train': '0.047267', 'examples_per_second': '5.1691', 'grad_norm': '4.0938', 'counters/examples': 11264, 'counters/updates': 704}
skipping logging after 11280 examples to avoid logging too frequently
skipping logging after 11296 examples to avoid logging too frequently
skipping logging after 11312 examples to avoid logging too frequently
train stats after 11328 examples: {'rewards_train/chosen': '-0.80951', 'rewards_train/rejected': '-8.7003', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.8899', 'logps_train/rejected': '-260.89', 'logps_train/chosen': '-59.561', 'loss/train': '0.043345', 'examples_per_second': '4.6243', 'grad_norm': '4.7812', 'counters/examples': 11328, 'counters/updates': 708}
skipping logging after 11344 examples to avoid logging too frequently
skipping logging after 11360 examples to avoid logging too frequently
skipping logging after 11376 examples to avoid logging too frequently
train stats after 11392 examples: {'rewards_train/chosen': '-0.71279', 'rewards_train/rejected': '-7.977', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.2626', 'logps_train/rejected': '-214.98', 'logps_train/chosen': '-49.486', 'loss/train': '0.038628', 'examples_per_second': '6.0296', 'grad_norm': '4.5938', 'counters/examples': 11392, 'counters/updates': 712}
skipping logging after 11408 examples to avoid logging too frequently
skipping logging after 11424 examples to avoid logging too frequently
skipping logging after 11440 examples to avoid logging too frequently
train stats after 11456 examples: {'rewards_train/chosen': '-1.1474', 'rewards_train/rejected': '-8.9763', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.8303', 'logps_train/rejected': '-239.16', 'logps_train/chosen': '-51.738', 'loss/train': '0.082175', 'examples_per_second': '4.4086', 'grad_norm': '11.75', 'counters/examples': 11456, 'counters/updates': 716}
skipping logging after 11472 examples to avoid logging too frequently
skipping logging after 11488 examples to avoid logging too frequently
skipping logging after 11504 examples to avoid logging too frequently
train stats after 11520 examples: {'rewards_train/chosen': '-1.0171', 'rewards_train/rejected': '-7.7559', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.7369', 'logps_train/rejected': '-200.58', 'logps_train/chosen': '-44.186', 'loss/train': '0.067733', 'examples_per_second': '6.3686', 'grad_norm': '7.5625', 'counters/examples': 11520, 'counters/updates': 720}
skipping logging after 11536 examples to avoid logging too frequently
skipping logging after 11552 examples to avoid logging too frequently
skipping logging after 11568 examples to avoid logging too frequently
train stats after 11584 examples: {'rewards_train/chosen': '-1.1662', 'rewards_train/rejected': '-8.8549', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.6881', 'logps_train/rejected': '-230.33', 'logps_train/chosen': '-53.269', 'loss/train': '0.052346', 'examples_per_second': '4.6802', 'grad_norm': '11.625', 'counters/examples': 11584, 'counters/updates': 724}
skipping logging after 11600 examples to avoid logging too frequently
skipping logging after 11616 examples to avoid logging too frequently
skipping logging after 11632 examples to avoid logging too frequently
train stats after 11648 examples: {'rewards_train/chosen': '-1.3777', 'rewards_train/rejected': '-8.2541', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.8737', 'logps_train/rejected': '-220.77', 'logps_train/chosen': '-51.606', 'loss/train': '0.1077', 'examples_per_second': '4.6642', 'grad_norm': '10.125', 'counters/examples': 11648, 'counters/updates': 728}
skipping logging after 11664 examples to avoid logging too frequently
skipping logging after 11680 examples to avoid logging too frequently
skipping logging after 11696 examples to avoid logging too frequently
train stats after 11712 examples: {'rewards_train/chosen': '-0.89998', 'rewards_train/rejected': '-8.2886', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.3856', 'logps_train/rejected': '-248.05', 'logps_train/chosen': '-54.119', 'loss/train': '0.11627', 'examples_per_second': '5.3873', 'grad_norm': '9', 'counters/examples': 11712, 'counters/updates': 732}
skipping logging after 11728 examples to avoid logging too frequently
skipping logging after 11744 examples to avoid logging too frequently
skipping logging after 11760 examples to avoid logging too frequently
train stats after 11776 examples: {'rewards_train/chosen': '-1.2576', 'rewards_train/rejected': '-7.3633', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.1052', 'logps_train/rejected': '-196.85', 'logps_train/chosen': '-47.507', 'loss/train': '0.11863', 'examples_per_second': '5.6199', 'grad_norm': '12.312', 'counters/examples': 11776, 'counters/updates': 736}
skipping logging after 11792 examples to avoid logging too frequently
skipping logging after 11808 examples to avoid logging too frequently
skipping logging after 11824 examples to avoid logging too frequently
train stats after 11840 examples: {'rewards_train/chosen': '-1.0284', 'rewards_train/rejected': '-9.4799', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.4508', 'logps_train/rejected': '-259.43', 'logps_train/chosen': '-51.992', 'loss/train': '0.024961', 'examples_per_second': '4.8452', 'grad_norm': '3.75', 'counters/examples': 11840, 'counters/updates': 740}
skipping logging after 11856 examples to avoid logging too frequently
skipping logging after 11872 examples to avoid logging too frequently
skipping logging after 11888 examples to avoid logging too frequently
train stats after 11904 examples: {'rewards_train/chosen': '-1.1318', 'rewards_train/rejected': '-9.1458', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.0131', 'logps_train/rejected': '-245.08', 'logps_train/chosen': '-58.322', 'loss/train': '0.05308', 'examples_per_second': '4.8448', 'grad_norm': '6.9375', 'counters/examples': 11904, 'counters/updates': 744}
skipping logging after 11920 examples to avoid logging too frequently
skipping logging after 11936 examples to avoid logging too frequently
skipping logging after 11952 examples to avoid logging too frequently
train stats after 11968 examples: {'rewards_train/chosen': '-1.228', 'rewards_train/rejected': '-8.7149', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.4872', 'logps_train/rejected': '-216.29', 'logps_train/chosen': '-60.032', 'loss/train': '0.076343', 'examples_per_second': '4.9642', 'grad_norm': '7.4062', 'counters/examples': 11968, 'counters/updates': 748}
skipping logging after 11984 examples to avoid logging too frequently
skipping logging after 12000 examples to avoid logging too frequently
Running evaluation after 12000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:14,  2.41s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:06,  2.21s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:56,  1.95s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.92s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:42,  1.56s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.67s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.49s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.57s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:36,  1.57s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.50s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.43s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:22,  1.29s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.24s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.33s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.34s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.27s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:33<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.29s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.26s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:37<00:07,  1.30s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:39<00:07,  1.48s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.41s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.62s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.42s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.42s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.45s/it]
eval after 12000: {'rewards_eval/chosen': '-9.4794', 'rewards_eval/rejected': '-9.6485', 'rewards_eval/accuracies': '0.50195', 'rewards_eval/margins': '0.16978', 'logps_eval/rejected': '-244.14', 'logps_eval/chosen': '-239.71', 'loss/eval': '2.4611'}
skipping logging after 12016 examples to avoid logging too frequently
train stats after 12032 examples: {'rewards_train/chosen': '-1.542', 'rewards_train/rejected': '-10.203', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.6624', 'logps_train/rejected': '-262.31', 'logps_train/chosen': '-71.29', 'loss/train': '0.10635', 'examples_per_second': '5.2292', 'grad_norm': '15.625', 'counters/examples': 12032, 'counters/updates': 752}
skipping logging after 12048 examples to avoid logging too frequently
skipping logging after 12064 examples to avoid logging too frequently
skipping logging after 12080 examples to avoid logging too frequently
train stats after 12096 examples: {'rewards_train/chosen': '-1.1834', 'rewards_train/rejected': '-8.002', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.8192', 'logps_train/rejected': '-217.57', 'logps_train/chosen': '-50.603', 'loss/train': '0.065201', 'examples_per_second': '5.5592', 'grad_norm': '7.875', 'counters/examples': 12096, 'counters/updates': 756}
skipping logging after 12112 examples to avoid logging too frequently
skipping logging after 12128 examples to avoid logging too frequently
skipping logging after 12144 examples to avoid logging too frequently
train stats after 12160 examples: {'rewards_train/chosen': '-1.1406', 'rewards_train/rejected': '-7.9364', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.7957', 'logps_train/rejected': '-215.53', 'logps_train/chosen': '-57.614', 'loss/train': '0.070071', 'examples_per_second': '4.9514', 'grad_norm': '5.0938', 'counters/examples': 12160, 'counters/updates': 760}
skipping logging after 12176 examples to avoid logging too frequently
skipping logging after 12192 examples to avoid logging too frequently
skipping logging after 12208 examples to avoid logging too frequently
train stats after 12224 examples: {'rewards_train/chosen': '-1.589', 'rewards_train/rejected': '-9.9316', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.3401', 'logps_train/rejected': '-242.43', 'logps_train/chosen': '-49.322', 'loss/train': '0.073936', 'examples_per_second': '5.5951', 'grad_norm': '13.875', 'counters/examples': 12224, 'counters/updates': 764}
skipping logging after 12240 examples to avoid logging too frequently
skipping logging after 12256 examples to avoid logging too frequently
skipping logging after 12272 examples to avoid logging too frequently
train stats after 12288 examples: {'rewards_train/chosen': '-1.1707', 'rewards_train/rejected': '-9.0887', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.9188', 'logps_train/rejected': '-228.43', 'logps_train/chosen': '-52.195', 'loss/train': '0.065997', 'examples_per_second': '5.1632', 'grad_norm': '7.9375', 'counters/examples': 12288, 'counters/updates': 768}
skipping logging after 12304 examples to avoid logging too frequently
skipping logging after 12320 examples to avoid logging too frequently
skipping logging after 12336 examples to avoid logging too frequently
train stats after 12352 examples: {'rewards_train/chosen': '-1.1609', 'rewards_train/rejected': '-9.3237', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.1636', 'logps_train/rejected': '-277.54', 'logps_train/chosen': '-61.436', 'loss/train': '0.06467', 'examples_per_second': '4.4312', 'grad_norm': '6.0938', 'counters/examples': 12352, 'counters/updates': 772}
skipping logging after 12368 examples to avoid logging too frequently
skipping logging after 12384 examples to avoid logging too frequently
skipping logging after 12400 examples to avoid logging too frequently
train stats after 12416 examples: {'rewards_train/chosen': '-1.6433', 'rewards_train/rejected': '-9.4058', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.7614', 'logps_train/rejected': '-235.96', 'logps_train/chosen': '-64.147', 'loss/train': '0.1548', 'examples_per_second': '4.2153', 'grad_norm': '16.25', 'counters/examples': 12416, 'counters/updates': 776}
skipping logging after 12432 examples to avoid logging too frequently
skipping logging after 12448 examples to avoid logging too frequently
skipping logging after 12464 examples to avoid logging too frequently
train stats after 12480 examples: {'rewards_train/chosen': '-1.1171', 'rewards_train/rejected': '-7.3126', 'rewards_train/accuracies': '1', 'rewards_train/margins': '6.198', 'logps_train/rejected': '-220.1', 'logps_train/chosen': '-53.111', 'loss/train': '0.083392', 'examples_per_second': '4.1044', 'grad_norm': '10.625', 'counters/examples': 12480, 'counters/updates': 780}
skipping logging after 12496 examples to avoid logging too frequently
skipping logging after 12512 examples to avoid logging too frequently
skipping logging after 12528 examples to avoid logging too frequently
train stats after 12544 examples: {'rewards_train/chosen': '-1.2047', 'rewards_train/rejected': '-9.6674', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.4648', 'logps_train/rejected': '-262.16', 'logps_train/chosen': '-48.065', 'loss/train': '0.03347', 'examples_per_second': '4.6351', 'grad_norm': '4.25', 'counters/examples': 12544, 'counters/updates': 784}
skipping logging after 12560 examples to avoid logging too frequently
skipping logging after 12576 examples to avoid logging too frequently
skipping logging after 12592 examples to avoid logging too frequently
train stats after 12608 examples: {'rewards_train/chosen': '-1.5156', 'rewards_train/rejected': '-9.7939', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.2806', 'logps_train/rejected': '-255.27', 'logps_train/chosen': '-52.542', 'loss/train': '0.1224', 'examples_per_second': '4.7701', 'grad_norm': '14.625', 'counters/examples': 12608, 'counters/updates': 788}
skipping logging after 12624 examples to avoid logging too frequently
skipping logging after 12640 examples to avoid logging too frequently
skipping logging after 12656 examples to avoid logging too frequently
train stats after 12672 examples: {'rewards_train/chosen': '-1.6', 'rewards_train/rejected': '-9.9152', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.3168', 'logps_train/rejected': '-254.87', 'logps_train/chosen': '-58.328', 'loss/train': '0.04213', 'examples_per_second': '4.5013', 'grad_norm': '9', 'counters/examples': 12672, 'counters/updates': 792}
skipping logging after 12688 examples to avoid logging too frequently
skipping logging after 12704 examples to avoid logging too frequently
skipping logging after 12720 examples to avoid logging too frequently
train stats after 12736 examples: {'rewards_train/chosen': '-1.6186', 'rewards_train/rejected': '-8.6679', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.0472', 'logps_train/rejected': '-218.38', 'logps_train/chosen': '-62.1', 'loss/train': '0.067422', 'examples_per_second': '4.5604', 'grad_norm': '5.9688', 'counters/examples': 12736, 'counters/updates': 796}
skipping logging after 12752 examples to avoid logging too frequently
skipping logging after 12768 examples to avoid logging too frequently
skipping logging after 12784 examples to avoid logging too frequently
train stats after 12800 examples: {'rewards_train/chosen': '-1.575', 'rewards_train/rejected': '-9.6445', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.0696', 'logps_train/rejected': '-239.21', 'logps_train/chosen': '-59.618', 'loss/train': '0.10956', 'examples_per_second': '5.3991', 'grad_norm': '15.125', 'counters/examples': 12800, 'counters/updates': 800}
skipping logging after 12816 examples to avoid logging too frequently
skipping logging after 12832 examples to avoid logging too frequently
skipping logging after 12848 examples to avoid logging too frequently
train stats after 12864 examples: {'rewards_train/chosen': '-0.88692', 'rewards_train/rejected': '-7.8827', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.9964', 'logps_train/rejected': '-214.66', 'logps_train/chosen': '-53.055', 'loss/train': '0.086754', 'examples_per_second': '4.4816', 'grad_norm': '9', 'counters/examples': 12864, 'counters/updates': 804}
skipping logging after 12880 examples to avoid logging too frequently
skipping logging after 12896 examples to avoid logging too frequently
skipping logging after 12912 examples to avoid logging too frequently
train stats after 12928 examples: {'rewards_train/chosen': '-0.89689', 'rewards_train/rejected': '-7.0227', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.125', 'logps_train/rejected': '-204.74', 'logps_train/chosen': '-51.438', 'loss/train': '0.079005', 'examples_per_second': '5.1717', 'grad_norm': '7', 'counters/examples': 12928, 'counters/updates': 808}
skipping logging after 12944 examples to avoid logging too frequently
skipping logging after 12960 examples to avoid logging too frequently
skipping logging after 12976 examples to avoid logging too frequently
train stats after 12992 examples: {'rewards_train/chosen': '-1.3772', 'rewards_train/rejected': '-7.2238', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '5.8463', 'logps_train/rejected': '-195.24', 'logps_train/chosen': '-55.323', 'loss/train': '0.087743', 'examples_per_second': '5.0685', 'grad_norm': '12', 'counters/examples': 12992, 'counters/updates': 812}
skipping logging after 13008 examples to avoid logging too frequently
skipping logging after 13024 examples to avoid logging too frequently
skipping logging after 13040 examples to avoid logging too frequently
train stats after 13056 examples: {'rewards_train/chosen': '-1.1139', 'rewards_train/rejected': '-6.5752', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '5.46', 'logps_train/rejected': '-184.49', 'logps_train/chosen': '-48.684', 'loss/train': '0.12122', 'examples_per_second': '5.6416', 'grad_norm': '8.5', 'counters/examples': 13056, 'counters/updates': 816}
skipping logging after 13072 examples to avoid logging too frequently
skipping logging after 13088 examples to avoid logging too frequently
skipping logging after 13104 examples to avoid logging too frequently
train stats after 13120 examples: {'rewards_train/chosen': '-1.0386', 'rewards_train/rejected': '-7.2155', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.1747', 'logps_train/rejected': '-202.48', 'logps_train/chosen': '-48.088', 'loss/train': '0.10099', 'examples_per_second': '4.8444', 'grad_norm': '12.812', 'counters/examples': 13120, 'counters/updates': 820}
skipping logging after 13136 examples to avoid logging too frequently
skipping logging after 13152 examples to avoid logging too frequently
skipping logging after 13168 examples to avoid logging too frequently
train stats after 13184 examples: {'rewards_train/chosen': '-0.88922', 'rewards_train/rejected': '-7.6302', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.7395', 'logps_train/rejected': '-225.98', 'logps_train/chosen': '-43.796', 'loss/train': '0.075516', 'examples_per_second': '4.4635', 'grad_norm': '7.8438', 'counters/examples': 13184, 'counters/updates': 824}
skipping logging after 13200 examples to avoid logging too frequently
skipping logging after 13216 examples to avoid logging too frequently
skipping logging after 13232 examples to avoid logging too frequently
train stats after 13248 examples: {'rewards_train/chosen': '-0.89369', 'rewards_train/rejected': '-7.6792', 'rewards_train/accuracies': '1', 'rewards_train/margins': '6.7867', 'logps_train/rejected': '-212.49', 'logps_train/chosen': '-49.407', 'loss/train': '0.069917', 'examples_per_second': '4.8677', 'grad_norm': '8.1875', 'counters/examples': 13248, 'counters/updates': 828}
skipping logging after 13264 examples to avoid logging too frequently
skipping logging after 13280 examples to avoid logging too frequently
skipping logging after 13296 examples to avoid logging too frequently
train stats after 13312 examples: {'rewards_train/chosen': '-0.95146', 'rewards_train/rejected': '-8.2456', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.2927', 'logps_train/rejected': '-230.11', 'logps_train/chosen': '-46.433', 'loss/train': '0.097898', 'examples_per_second': '5.8087', 'grad_norm': '9.9375', 'counters/examples': 13312, 'counters/updates': 832}
skipping logging after 13328 examples to avoid logging too frequently
skipping logging after 13344 examples to avoid logging too frequently
skipping logging after 13360 examples to avoid logging too frequently
train stats after 13376 examples: {'rewards_train/chosen': '-1.0844', 'rewards_train/rejected': '-7.3078', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.2213', 'logps_train/rejected': '-192.24', 'logps_train/chosen': '-48.853', 'loss/train': '0.11057', 'examples_per_second': '5.9338', 'grad_norm': '11.625', 'counters/examples': 13376, 'counters/updates': 836}
skipping logging after 13392 examples to avoid logging too frequently
skipping logging after 13408 examples to avoid logging too frequently
skipping logging after 13424 examples to avoid logging too frequently
train stats after 13440 examples: {'rewards_train/chosen': '-0.91305', 'rewards_train/rejected': '-8.3156', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.3975', 'logps_train/rejected': '-257.39', 'logps_train/chosen': '-55.924', 'loss/train': '0.094197', 'examples_per_second': '4.3596', 'grad_norm': '10.375', 'counters/examples': 13440, 'counters/updates': 840}
skipping logging after 13456 examples to avoid logging too frequently
skipping logging after 13472 examples to avoid logging too frequently
skipping logging after 13488 examples to avoid logging too frequently
train stats after 13504 examples: {'rewards_train/chosen': '-1.2861', 'rewards_train/rejected': '-8.1409', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.8534', 'logps_train/rejected': '-220.34', 'logps_train/chosen': '-58.293', 'loss/train': '0.10471', 'examples_per_second': '4.5041', 'grad_norm': '10.438', 'counters/examples': 13504, 'counters/updates': 844}
skipping logging after 13520 examples to avoid logging too frequently
skipping logging after 13536 examples to avoid logging too frequently
skipping logging after 13552 examples to avoid logging too frequently
train stats after 13568 examples: {'rewards_train/chosen': '-1.4909', 'rewards_train/rejected': '-10.111', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.6187', 'logps_train/rejected': '-273.16', 'logps_train/chosen': '-56.29', 'loss/train': '0.049853', 'examples_per_second': '5.4693', 'grad_norm': '8.875', 'counters/examples': 13568, 'counters/updates': 848}
skipping logging after 13584 examples to avoid logging too frequently
skipping logging after 13600 examples to avoid logging too frequently
skipping logging after 13616 examples to avoid logging too frequently
train stats after 13632 examples: {'rewards_train/chosen': '-1.4298', 'rewards_train/rejected': '-9.0102', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.5817', 'logps_train/rejected': '-222.37', 'logps_train/chosen': '-47.748', 'loss/train': '0.10231', 'examples_per_second': '4.816', 'grad_norm': '9.875', 'counters/examples': 13632, 'counters/updates': 852}
skipping logging after 13648 examples to avoid logging too frequently
skipping logging after 13664 examples to avoid logging too frequently
skipping logging after 13680 examples to avoid logging too frequently
train stats after 13696 examples: {'rewards_train/chosen': '-1.4235', 'rewards_train/rejected': '-10.479', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.0536', 'logps_train/rejected': '-277.15', 'logps_train/chosen': '-63.812', 'loss/train': '0.067864', 'examples_per_second': '4.5837', 'grad_norm': '16.25', 'counters/examples': 13696, 'counters/updates': 856}
skipping logging after 13712 examples to avoid logging too frequently
skipping logging after 13728 examples to avoid logging too frequently
skipping logging after 13744 examples to avoid logging too frequently
train stats after 13760 examples: {'rewards_train/chosen': '-1.4505', 'rewards_train/rejected': '-9.4746', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.0207', 'logps_train/rejected': '-237.54', 'logps_train/chosen': '-67.531', 'loss/train': '0.19999', 'examples_per_second': '4.9916', 'grad_norm': '25.125', 'counters/examples': 13760, 'counters/updates': 860}
skipping logging after 13776 examples to avoid logging too frequently
skipping logging after 13792 examples to avoid logging too frequently
skipping logging after 13808 examples to avoid logging too frequently
train stats after 13824 examples: {'rewards_train/chosen': '-1.4042', 'rewards_train/rejected': '-7.8446', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '6.4389', 'logps_train/rejected': '-208.01', 'logps_train/chosen': '-56.14', 'loss/train': '0.14805', 'examples_per_second': '5.4713', 'grad_norm': '15.438', 'counters/examples': 13824, 'counters/updates': 864}
skipping logging after 13840 examples to avoid logging too frequently
skipping logging after 13856 examples to avoid logging too frequently
skipping logging after 13872 examples to avoid logging too frequently
train stats after 13888 examples: {'rewards_train/chosen': '-0.9889', 'rewards_train/rejected': '-8.6388', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.6503', 'logps_train/rejected': '-247.13', 'logps_train/chosen': '-53.71', 'loss/train': '0.066232', 'examples_per_second': '5.866', 'grad_norm': '7.8438', 'counters/examples': 13888, 'counters/updates': 868}
skipping logging after 13904 examples to avoid logging too frequently
skipping logging after 13920 examples to avoid logging too frequently
skipping logging after 13936 examples to avoid logging too frequently
train stats after 13952 examples: {'rewards_train/chosen': '-1.2048', 'rewards_train/rejected': '-7.6829', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.4775', 'logps_train/rejected': '-203.37', 'logps_train/chosen': '-47.175', 'loss/train': '0.13614', 'examples_per_second': '5.0463', 'grad_norm': '10.062', 'counters/examples': 13952, 'counters/updates': 872}
skipping logging after 13968 examples to avoid logging too frequently
skipping logging after 13984 examples to avoid logging too frequently
skipping logging after 14000 examples to avoid logging too frequently
train stats after 14016 examples: {'rewards_train/chosen': '-1.1069', 'rewards_train/rejected': '-8.5586', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.4521', 'logps_train/rejected': '-253.58', 'logps_train/chosen': '-61.646', 'loss/train': '0.087946', 'examples_per_second': '4.6591', 'grad_norm': '4.75', 'counters/examples': 14016, 'counters/updates': 876}
skipping logging after 14032 examples to avoid logging too frequently
skipping logging after 14048 examples to avoid logging too frequently
skipping logging after 14064 examples to avoid logging too frequently
train stats after 14080 examples: {'rewards_train/chosen': '-1.286', 'rewards_train/rejected': '-7.9399', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.6512', 'logps_train/rejected': '-208.38', 'logps_train/chosen': '-54.692', 'loss/train': '0.16762', 'examples_per_second': '4.8843', 'grad_norm': '15.375', 'counters/examples': 14080, 'counters/updates': 880}
skipping logging after 14096 examples to avoid logging too frequently
skipping logging after 14112 examples to avoid logging too frequently
skipping logging after 14128 examples to avoid logging too frequently
train stats after 14144 examples: {'rewards_train/chosen': '-1.1107', 'rewards_train/rejected': '-7.9487', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.8376', 'logps_train/rejected': '-209.38', 'logps_train/chosen': '-52.011', 'loss/train': '0.084236', 'examples_per_second': '4.6058', 'grad_norm': '9.5625', 'counters/examples': 14144, 'counters/updates': 884}
skipping logging after 14160 examples to avoid logging too frequently
skipping logging after 14176 examples to avoid logging too frequently
skipping logging after 14192 examples to avoid logging too frequently
train stats after 14208 examples: {'rewards_train/chosen': '-1.1711', 'rewards_train/rejected': '-7.3841', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.2144', 'logps_train/rejected': '-200.48', 'logps_train/chosen': '-49.984', 'loss/train': '0.21876', 'examples_per_second': '4.9654', 'grad_norm': '11.375', 'counters/examples': 14208, 'counters/updates': 888}
skipping logging after 14224 examples to avoid logging too frequently
skipping logging after 14240 examples to avoid logging too frequently
skipping logging after 14256 examples to avoid logging too frequently
train stats after 14272 examples: {'rewards_train/chosen': '-0.88418', 'rewards_train/rejected': '-7.3037', 'rewards_train/accuracies': '1', 'rewards_train/margins': '6.4192', 'logps_train/rejected': '-214.98', 'logps_train/chosen': '-46.125', 'loss/train': '0.056456', 'examples_per_second': '5.1805', 'grad_norm': '7.0312', 'counters/examples': 14272, 'counters/updates': 892}
skipping logging after 14288 examples to avoid logging too frequently
skipping logging after 14304 examples to avoid logging too frequently
skipping logging after 14320 examples to avoid logging too frequently
train stats after 14336 examples: {'rewards_train/chosen': '-1.4166', 'rewards_train/rejected': '-7.3326', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '5.9142', 'logps_train/rejected': '-187.45', 'logps_train/chosen': '-46.997', 'loss/train': '0.11548', 'examples_per_second': '5.3983', 'grad_norm': '9.5', 'counters/examples': 14336, 'counters/updates': 896}
skipping logging after 14352 examples to avoid logging too frequently
skipping logging after 14368 examples to avoid logging too frequently
skipping logging after 14384 examples to avoid logging too frequently
train stats after 14400 examples: {'rewards_train/chosen': '-0.93419', 'rewards_train/rejected': '-7.1672', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.2341', 'logps_train/rejected': '-209.02', 'logps_train/chosen': '-46.283', 'loss/train': '0.08053', 'examples_per_second': '4.4434', 'grad_norm': '6.7188', 'counters/examples': 14400, 'counters/updates': 900}
skipping logging after 14416 examples to avoid logging too frequently
skipping logging after 14432 examples to avoid logging too frequently
skipping logging after 14448 examples to avoid logging too frequently
train stats after 14464 examples: {'rewards_train/chosen': '-0.9972', 'rewards_train/rejected': '-7.1704', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.1726', 'logps_train/rejected': '-190.69', 'logps_train/chosen': '-52.293', 'loss/train': '0.11756', 'examples_per_second': '5.0063', 'grad_norm': '7.0625', 'counters/examples': 14464, 'counters/updates': 904}
skipping logging after 14480 examples to avoid logging too frequently
skipping logging after 14496 examples to avoid logging too frequently
skipping logging after 14512 examples to avoid logging too frequently
train stats after 14528 examples: {'rewards_train/chosen': '-0.83742', 'rewards_train/rejected': '-8.7544', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.9155', 'logps_train/rejected': '-256.59', 'logps_train/chosen': '-57.346', 'loss/train': '0.077235', 'examples_per_second': '5.463', 'grad_norm': '13.062', 'counters/examples': 14528, 'counters/updates': 908}
skipping logging after 14544 examples to avoid logging too frequently
skipping logging after 14560 examples to avoid logging too frequently
skipping logging after 14576 examples to avoid logging too frequently
train stats after 14592 examples: {'rewards_train/chosen': '-1.0935', 'rewards_train/rejected': '-6.9357', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '5.8414', 'logps_train/rejected': '-218.42', 'logps_train/chosen': '-51.171', 'loss/train': '0.1238', 'examples_per_second': '4.9823', 'grad_norm': '7.625', 'counters/examples': 14592, 'counters/updates': 912}
skipping logging after 14608 examples to avoid logging too frequently
skipping logging after 14624 examples to avoid logging too frequently
skipping logging after 14640 examples to avoid logging too frequently
train stats after 14656 examples: {'rewards_train/chosen': '-0.8165', 'rewards_train/rejected': '-7.1289', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.314', 'logps_train/rejected': '-213.93', 'logps_train/chosen': '-55.805', 'loss/train': '0.099455', 'examples_per_second': '4.7757', 'grad_norm': '9.9375', 'counters/examples': 14656, 'counters/updates': 916}
skipping logging after 14672 examples to avoid logging too frequently
skipping logging after 14688 examples to avoid logging too frequently
skipping logging after 14704 examples to avoid logging too frequently
train stats after 14720 examples: {'rewards_train/chosen': '-0.90276', 'rewards_train/rejected': '-6.9288', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.0253', 'logps_train/rejected': '-208.53', 'logps_train/chosen': '-51.856', 'loss/train': '0.064225', 'examples_per_second': '5.3825', 'grad_norm': '6.375', 'counters/examples': 14720, 'counters/updates': 920}
skipping logging after 14736 examples to avoid logging too frequently
skipping logging after 14752 examples to avoid logging too frequently
skipping logging after 14768 examples to avoid logging too frequently
train stats after 14784 examples: {'rewards_train/chosen': '-1.1366', 'rewards_train/rejected': '-7.2355', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.0977', 'logps_train/rejected': '-206.78', 'logps_train/chosen': '-59.222', 'loss/train': '0.15548', 'examples_per_second': '5.2714', 'grad_norm': '18', 'counters/examples': 14784, 'counters/updates': 924}
skipping logging after 14800 examples to avoid logging too frequently
skipping logging after 14816 examples to avoid logging too frequently
skipping logging after 14832 examples to avoid logging too frequently
train stats after 14848 examples: {'rewards_train/chosen': '-0.8844', 'rewards_train/rejected': '-7.0256', 'rewards_train/accuracies': '1', 'rewards_train/margins': '6.1434', 'logps_train/rejected': '-195.25', 'logps_train/chosen': '-51.308', 'loss/train': '0.056495', 'examples_per_second': '4.6979', 'grad_norm': '5.9375', 'counters/examples': 14848, 'counters/updates': 928}
skipping logging after 14864 examples to avoid logging too frequently
skipping logging after 14880 examples to avoid logging too frequently
skipping logging after 14896 examples to avoid logging too frequently
train stats after 14912 examples: {'rewards_train/chosen': '-1.0876', 'rewards_train/rejected': '-7.2583', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.1708', 'logps_train/rejected': '-222.26', 'logps_train/chosen': '-51.416', 'loss/train': '0.1078', 'examples_per_second': '5.0915', 'grad_norm': '8.3125', 'counters/examples': 14912, 'counters/updates': 932}
skipping logging after 14928 examples to avoid logging too frequently
skipping logging after 14944 examples to avoid logging too frequently
skipping logging after 14960 examples to avoid logging too frequently
train stats after 14976 examples: {'rewards_train/chosen': '-1.2289', 'rewards_train/rejected': '-7.4726', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '6.2428', 'logps_train/rejected': '-222.07', 'logps_train/chosen': '-55.795', 'loss/train': '0.14808', 'examples_per_second': '4.3857', 'grad_norm': '12.5', 'counters/examples': 14976, 'counters/updates': 936}
skipping logging after 14992 examples to avoid logging too frequently
skipping logging after 15008 examples to avoid logging too frequently
skipping logging after 15024 examples to avoid logging too frequently
train stats after 15040 examples: {'rewards_train/chosen': '-1.2927', 'rewards_train/rejected': '-8.1326', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.8384', 'logps_train/rejected': '-218.93', 'logps_train/chosen': '-59.63', 'loss/train': '0.046184', 'examples_per_second': '5.9332', 'grad_norm': '7.8438', 'counters/examples': 15040, 'counters/updates': 940}
skipping logging after 15056 examples to avoid logging too frequently
skipping logging after 15072 examples to avoid logging too frequently
skipping logging after 15088 examples to avoid logging too frequently
train stats after 15104 examples: {'rewards_train/chosen': '-1.5632', 'rewards_train/rejected': '-7.9182', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.3535', 'logps_train/rejected': '-210.97', 'logps_train/chosen': '-54.076', 'loss/train': '0.24457', 'examples_per_second': '6.1942', 'grad_norm': '23.25', 'counters/examples': 15104, 'counters/updates': 944}
skipping logging after 15120 examples to avoid logging too frequently
skipping logging after 15136 examples to avoid logging too frequently
skipping logging after 15152 examples to avoid logging too frequently
train stats after 15168 examples: {'rewards_train/chosen': '-1.1828', 'rewards_train/rejected': '-7.8049', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.6232', 'logps_train/rejected': '-195.21', 'logps_train/chosen': '-54.013', 'loss/train': '0.085924', 'examples_per_second': '4.7695', 'grad_norm': '7.7812', 'counters/examples': 15168, 'counters/updates': 948}
skipping logging after 15184 examples to avoid logging too frequently
skipping logging after 15200 examples to avoid logging too frequently
skipping logging after 15216 examples to avoid logging too frequently
train stats after 15232 examples: {'rewards_train/chosen': '-1.182', 'rewards_train/rejected': '-8.265', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.0828', 'logps_train/rejected': '-249.33', 'logps_train/chosen': '-52.256', 'loss/train': '0.042714', 'examples_per_second': '4.7804', 'grad_norm': '4.375', 'counters/examples': 15232, 'counters/updates': 952}
skipping logging after 15248 examples to avoid logging too frequently
skipping logging after 15264 examples to avoid logging too frequently
skipping logging after 15280 examples to avoid logging too frequently
train stats after 15296 examples: {'rewards_train/chosen': '-1.217', 'rewards_train/rejected': '-7.7264', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.5106', 'logps_train/rejected': '-194.87', 'logps_train/chosen': '-51.699', 'loss/train': '0.10972', 'examples_per_second': '4.9792', 'grad_norm': '11.875', 'counters/examples': 15296, 'counters/updates': 956}
skipping logging after 15312 examples to avoid logging too frequently
skipping logging after 15328 examples to avoid logging too frequently
skipping logging after 15344 examples to avoid logging too frequently
train stats after 15360 examples: {'rewards_train/chosen': '-0.88973', 'rewards_train/rejected': '-6.9731', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.0811', 'logps_train/rejected': '-203.11', 'logps_train/chosen': '-51.775', 'loss/train': '0.1052', 'examples_per_second': '5.2254', 'grad_norm': '12.688', 'counters/examples': 15360, 'counters/updates': 960}
skipping logging after 15376 examples to avoid logging too frequently
skipping logging after 15392 examples to avoid logging too frequently
skipping logging after 15408 examples to avoid logging too frequently
train stats after 15424 examples: {'rewards_train/chosen': '-1.0397', 'rewards_train/rejected': '-7.2053', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.1654', 'logps_train/rejected': '-196.18', 'logps_train/chosen': '-49.133', 'loss/train': '0.088868', 'examples_per_second': '4.5068', 'grad_norm': '6.8438', 'counters/examples': 15424, 'counters/updates': 964}
skipping logging after 15440 examples to avoid logging too frequently
skipping logging after 15456 examples to avoid logging too frequently
skipping logging after 15472 examples to avoid logging too frequently
train stats after 15488 examples: {'rewards_train/chosen': '-1.3737', 'rewards_train/rejected': '-8.1792', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.8033', 'logps_train/rejected': '-231.2', 'logps_train/chosen': '-60.231', 'loss/train': '0.075975', 'examples_per_second': '4.5694', 'grad_norm': '13.25', 'counters/examples': 15488, 'counters/updates': 968}
skipping logging after 15504 examples to avoid logging too frequently
skipping logging after 15520 examples to avoid logging too frequently
skipping logging after 15536 examples to avoid logging too frequently
train stats after 15552 examples: {'rewards_train/chosen': '-0.7989', 'rewards_train/rejected': '-8.1888', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.3917', 'logps_train/rejected': '-250.32', 'logps_train/chosen': '-49.004', 'loss/train': '0.057879', 'examples_per_second': '5.9525', 'grad_norm': '7.0938', 'counters/examples': 15552, 'counters/updates': 972}
skipping logging after 15568 examples to avoid logging too frequently
skipping logging after 15584 examples to avoid logging too frequently
skipping logging after 15600 examples to avoid logging too frequently
train stats after 15616 examples: {'rewards_train/chosen': '-1.241', 'rewards_train/rejected': '-7.7212', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.4819', 'logps_train/rejected': '-219.04', 'logps_train/chosen': '-49.863', 'loss/train': '0.095656', 'examples_per_second': '5.1465', 'grad_norm': '10.625', 'counters/examples': 15616, 'counters/updates': 976}
skipping logging after 15632 examples to avoid logging too frequently
skipping logging after 15648 examples to avoid logging too frequently
skipping logging after 15664 examples to avoid logging too frequently
train stats after 15680 examples: {'rewards_train/chosen': '-0.98194', 'rewards_train/rejected': '-7.4803', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.498', 'logps_train/rejected': '-215.7', 'logps_train/chosen': '-44.93', 'loss/train': '0.084981', 'examples_per_second': '5.3836', 'grad_norm': '6.375', 'counters/examples': 15680, 'counters/updates': 980}
skipping logging after 15696 examples to avoid logging too frequently
skipping logging after 15712 examples to avoid logging too frequently
skipping logging after 15728 examples to avoid logging too frequently
train stats after 15744 examples: {'rewards_train/chosen': '-1.5137', 'rewards_train/rejected': '-8.1738', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.6594', 'logps_train/rejected': '-213.28', 'logps_train/chosen': '-68.706', 'loss/train': '0.26542', 'examples_per_second': '4.9594', 'grad_norm': '22.5', 'counters/examples': 15744, 'counters/updates': 984}
skipping logging after 15760 examples to avoid logging too frequently
skipping logging after 15776 examples to avoid logging too frequently
skipping logging after 15792 examples to avoid logging too frequently
train stats after 15808 examples: {'rewards_train/chosen': '-1.3851', 'rewards_train/rejected': '-6.4719', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '5.0876', 'logps_train/rejected': '-180.67', 'logps_train/chosen': '-45.763', 'loss/train': '0.11506', 'examples_per_second': '6.2614', 'grad_norm': '15.125', 'counters/examples': 15808, 'counters/updates': 988}
skipping logging after 15824 examples to avoid logging too frequently
skipping logging after 15840 examples to avoid logging too frequently
skipping logging after 15856 examples to avoid logging too frequently
train stats after 15872 examples: {'rewards_train/chosen': '-1.169', 'rewards_train/rejected': '-8.2776', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.1089', 'logps_train/rejected': '-262.4', 'logps_train/chosen': '-51.646', 'loss/train': '0.046969', 'examples_per_second': '4.7511', 'grad_norm': '5.9688', 'counters/examples': 15872, 'counters/updates': 992}
skipping logging after 15888 examples to avoid logging too frequently
skipping logging after 15904 examples to avoid logging too frequently
skipping logging after 15920 examples to avoid logging too frequently
train stats after 15936 examples: {'rewards_train/chosen': '-1.4961', 'rewards_train/rejected': '-8.9987', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.5049', 'logps_train/rejected': '-272.04', 'logps_train/chosen': '-56.6', 'loss/train': '0.062946', 'examples_per_second': '3.9635', 'grad_norm': '9.8125', 'counters/examples': 15936, 'counters/updates': 996}
skipping logging after 15952 examples to avoid logging too frequently
skipping logging after 15968 examples to avoid logging too frequently
skipping logging after 15984 examples to avoid logging too frequently
train stats after 16000 examples: {'rewards_train/chosen': '-1.7404', 'rewards_train/rejected': '-8.0249', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.2845', 'logps_train/rejected': '-214.53', 'logps_train/chosen': '-67.592', 'loss/train': '0.16597', 'examples_per_second': '5.3487', 'grad_norm': '8.3125', 'counters/examples': 16000, 'counters/updates': 1000}
Running evaluation after 16000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<01:00,  1.95s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:00,  2.02s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:53,  1.84s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.86s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.52s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.50s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:21,  1.29s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.24s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.33s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.34s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.27s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.29s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.26s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.30s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.48s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.41s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.61s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.42s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.41s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 16000: {'rewards_eval/chosen': '-7.6078', 'rewards_eval/rejected': '-7.8576', 'rewards_eval/accuracies': '0.50586', 'rewards_eval/margins': '0.25', 'logps_eval/rejected': '-226.23', 'logps_eval/chosen': '-221', 'loss/eval': '1.8149'}
skipping logging after 16016 examples to avoid logging too frequently
skipping logging after 16032 examples to avoid logging too frequently
skipping logging after 16048 examples to avoid logging too frequently
train stats after 16064 examples: {'rewards_train/chosen': '-1.193', 'rewards_train/rejected': '-7.1941', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '5.9997', 'logps_train/rejected': '-189.85', 'logps_train/chosen': '-50.445', 'loss/train': '0.083782', 'examples_per_second': '5.4981', 'grad_norm': '5.1875', 'counters/examples': 16064, 'counters/updates': 1004}
skipping logging after 16080 examples to avoid logging too frequently
skipping logging after 16096 examples to avoid logging too frequently
skipping logging after 16112 examples to avoid logging too frequently
train stats after 16128 examples: {'rewards_train/chosen': '-1.3425', 'rewards_train/rejected': '-6.7875', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '5.4474', 'logps_train/rejected': '-183.21', 'logps_train/chosen': '-56.058', 'loss/train': '0.084847', 'examples_per_second': '5.0775', 'grad_norm': '6.4688', 'counters/examples': 16128, 'counters/updates': 1008}
skipping logging after 16144 examples to avoid logging too frequently
skipping logging after 16160 examples to avoid logging too frequently
skipping logging after 16176 examples to avoid logging too frequently
train stats after 16192 examples: {'rewards_train/chosen': '-1.5483', 'rewards_train/rejected': '-8.8903', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.3419', 'logps_train/rejected': '-226.38', 'logps_train/chosen': '-54.023', 'loss/train': '0.082095', 'examples_per_second': '4.2099', 'grad_norm': '8.25', 'counters/examples': 16192, 'counters/updates': 1012}
skipping logging after 16208 examples to avoid logging too frequently
skipping logging after 16224 examples to avoid logging too frequently
skipping logging after 16240 examples to avoid logging too frequently
train stats after 16256 examples: {'rewards_train/chosen': '-1.4217', 'rewards_train/rejected': '-9.2066', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.7841', 'logps_train/rejected': '-256.16', 'logps_train/chosen': '-56.373', 'loss/train': '0.11015', 'examples_per_second': '4.1373', 'grad_norm': '15.812', 'counters/examples': 16256, 'counters/updates': 1016}
skipping logging after 16272 examples to avoid logging too frequently
skipping logging after 16288 examples to avoid logging too frequently
skipping logging after 16304 examples to avoid logging too frequently
train stats after 16320 examples: {'rewards_train/chosen': '-1.2428', 'rewards_train/rejected': '-7.1084', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '5.8657', 'logps_train/rejected': '-192.13', 'logps_train/chosen': '-51.092', 'loss/train': '0.11726', 'examples_per_second': '5.987', 'grad_norm': '10.062', 'counters/examples': 16320, 'counters/updates': 1020}
skipping logging after 16336 examples to avoid logging too frequently
skipping logging after 16352 examples to avoid logging too frequently
skipping logging after 16368 examples to avoid logging too frequently
train stats after 16384 examples: {'rewards_train/chosen': '-1.3619', 'rewards_train/rejected': '-7.0587', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '5.6973', 'logps_train/rejected': '-198.25', 'logps_train/chosen': '-47.391', 'loss/train': '0.14356', 'examples_per_second': '5.518', 'grad_norm': '9.25', 'counters/examples': 16384, 'counters/updates': 1024}
skipping logging after 16400 examples to avoid logging too frequently
skipping logging after 16416 examples to avoid logging too frequently
skipping logging after 16432 examples to avoid logging too frequently
train stats after 16448 examples: {'rewards_train/chosen': '-1.1184', 'rewards_train/rejected': '-7.6067', 'rewards_train/accuracies': '1', 'rewards_train/margins': '6.488', 'logps_train/rejected': '-210.94', 'logps_train/chosen': '-59.241', 'loss/train': '0.033413', 'examples_per_second': '6.3139', 'grad_norm': '4.5312', 'counters/examples': 16448, 'counters/updates': 1028}
skipping logging after 16464 examples to avoid logging too frequently
skipping logging after 16480 examples to avoid logging too frequently
skipping logging after 16496 examples to avoid logging too frequently
train stats after 16512 examples: {'rewards_train/chosen': '-1.257', 'rewards_train/rejected': '-8.5808', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.3254', 'logps_train/rejected': '-237.8', 'logps_train/chosen': '-52.528', 'loss/train': '0.035329', 'examples_per_second': '4.7331', 'grad_norm': '4.4062', 'counters/examples': 16512, 'counters/updates': 1032}
skipping logging after 16528 examples to avoid logging too frequently
skipping logging after 16544 examples to avoid logging too frequently
skipping logging after 16560 examples to avoid logging too frequently
train stats after 16576 examples: {'rewards_train/chosen': '-1.2914', 'rewards_train/rejected': '-8.8886', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.5992', 'logps_train/rejected': '-232.25', 'logps_train/chosen': '-54.719', 'loss/train': '0.099143', 'examples_per_second': '4.7693', 'grad_norm': '8.625', 'counters/examples': 16576, 'counters/updates': 1036}
skipping logging after 16592 examples to avoid logging too frequently
skipping logging after 16608 examples to avoid logging too frequently
skipping logging after 16624 examples to avoid logging too frequently
train stats after 16640 examples: {'rewards_train/chosen': '-1.6465', 'rewards_train/rejected': '-7.7039', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.0574', 'logps_train/rejected': '-202.84', 'logps_train/chosen': '-56.33', 'loss/train': '0.077747', 'examples_per_second': '5.9666', 'grad_norm': '8.875', 'counters/examples': 16640, 'counters/updates': 1040}
skipping logging after 16656 examples to avoid logging too frequently
skipping logging after 16672 examples to avoid logging too frequently
skipping logging after 16688 examples to avoid logging too frequently
train stats after 16704 examples: {'rewards_train/chosen': '-1.4354', 'rewards_train/rejected': '-10.302', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.8665', 'logps_train/rejected': '-248.83', 'logps_train/chosen': '-55.178', 'loss/train': '0.070494', 'examples_per_second': '4.6784', 'grad_norm': '12.188', 'counters/examples': 16704, 'counters/updates': 1044}
skipping logging after 16720 examples to avoid logging too frequently
skipping logging after 16736 examples to avoid logging too frequently
skipping logging after 16752 examples to avoid logging too frequently
train stats after 16768 examples: {'rewards_train/chosen': '-1.8848', 'rewards_train/rejected': '-8.7456', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '6.8595', 'logps_train/rejected': '-221.68', 'logps_train/chosen': '-60.06', 'loss/train': '0.23786', 'examples_per_second': '5.4781', 'grad_norm': '20.125', 'counters/examples': 16768, 'counters/updates': 1048}
skipping logging after 16784 examples to avoid logging too frequently
skipping logging after 16800 examples to avoid logging too frequently
skipping logging after 16816 examples to avoid logging too frequently
train stats after 16832 examples: {'rewards_train/chosen': '-1.3433', 'rewards_train/rejected': '-7.3041', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '5.9606', 'logps_train/rejected': '-189.58', 'logps_train/chosen': '-52.081', 'loss/train': '0.13165', 'examples_per_second': '5.4484', 'grad_norm': '13.562', 'counters/examples': 16832, 'counters/updates': 1052}
skipping logging after 16848 examples to avoid logging too frequently
skipping logging after 16864 examples to avoid logging too frequently
skipping logging after 16880 examples to avoid logging too frequently
train stats after 16896 examples: {'rewards_train/chosen': '-0.93797', 'rewards_train/rejected': '-8.4445', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.5073', 'logps_train/rejected': '-268.01', 'logps_train/chosen': '-46.72', 'loss/train': '0.030497', 'examples_per_second': '4.4222', 'grad_norm': '2.8906', 'counters/examples': 16896, 'counters/updates': 1056}
skipping logging after 16912 examples to avoid logging too frequently
skipping logging after 16928 examples to avoid logging too frequently
skipping logging after 16944 examples to avoid logging too frequently
train stats after 16960 examples: {'rewards_train/chosen': '-1.2911', 'rewards_train/rejected': '-8.4264', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.1348', 'logps_train/rejected': '-224.96', 'logps_train/chosen': '-47.506', 'loss/train': '0.049937', 'examples_per_second': '6.0048', 'grad_norm': '3.9375', 'counters/examples': 16960, 'counters/updates': 1060}
skipping logging after 16976 examples to avoid logging too frequently
skipping logging after 16992 examples to avoid logging too frequently
skipping logging after 17008 examples to avoid logging too frequently
train stats after 17024 examples: {'rewards_train/chosen': '-1.2831', 'rewards_train/rejected': '-8.6709', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.3882', 'logps_train/rejected': '-253.83', 'logps_train/chosen': '-51.189', 'loss/train': '0.033981', 'examples_per_second': '5.3408', 'grad_norm': '4.0312', 'counters/examples': 17024, 'counters/updates': 1064}
skipping logging after 17040 examples to avoid logging too frequently
skipping logging after 17056 examples to avoid logging too frequently
skipping logging after 17072 examples to avoid logging too frequently
train stats after 17088 examples: {'rewards_train/chosen': '-1.4925', 'rewards_train/rejected': '-7.8435', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.3489', 'logps_train/rejected': '-219.15', 'logps_train/chosen': '-61.553', 'loss/train': '0.19025', 'examples_per_second': '4.1193', 'grad_norm': '22.625', 'counters/examples': 17088, 'counters/updates': 1068}
skipping logging after 17104 examples to avoid logging too frequently
skipping logging after 17120 examples to avoid logging too frequently
skipping logging after 17136 examples to avoid logging too frequently
train stats after 17152 examples: {'rewards_train/chosen': '-1.6883', 'rewards_train/rejected': '-7.9625', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.2766', 'logps_train/rejected': '-188.73', 'logps_train/chosen': '-54.33', 'loss/train': '0.13898', 'examples_per_second': '5.9029', 'grad_norm': '12.75', 'counters/examples': 17152, 'counters/updates': 1072}
skipping logging after 17168 examples to avoid logging too frequently
skipping logging after 17184 examples to avoid logging too frequently
skipping logging after 17200 examples to avoid logging too frequently
train stats after 17216 examples: {'rewards_train/chosen': '-1.5565', 'rewards_train/rejected': '-9.6036', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.0491', 'logps_train/rejected': '-249.46', 'logps_train/chosen': '-46.998', 'loss/train': '0.054399', 'examples_per_second': '5.5809', 'grad_norm': '6.125', 'counters/examples': 17216, 'counters/updates': 1076}
skipping logging after 17232 examples to avoid logging too frequently
skipping logging after 17248 examples to avoid logging too frequently
skipping logging after 17264 examples to avoid logging too frequently
train stats after 17280 examples: {'rewards_train/chosen': '-1.3248', 'rewards_train/rejected': '-9.8143', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.4874', 'logps_train/rejected': '-251', 'logps_train/chosen': '-52.342', 'loss/train': '0.061225', 'examples_per_second': '4.9712', 'grad_norm': '8.0625', 'counters/examples': 17280, 'counters/updates': 1080}
skipping logging after 17296 examples to avoid logging too frequently
skipping logging after 17312 examples to avoid logging too frequently
skipping logging after 17328 examples to avoid logging too frequently
train stats after 17344 examples: {'rewards_train/chosen': '-1.5099', 'rewards_train/rejected': '-8.7637', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.2518', 'logps_train/rejected': '-204.91', 'logps_train/chosen': '-53.142', 'loss/train': '0.12123', 'examples_per_second': '6.0136', 'grad_norm': '13.812', 'counters/examples': 17344, 'counters/updates': 1084}
skipping logging after 17360 examples to avoid logging too frequently
skipping logging after 17376 examples to avoid logging too frequently
skipping logging after 17392 examples to avoid logging too frequently
train stats after 17408 examples: {'rewards_train/chosen': '-1.3211', 'rewards_train/rejected': '-8.9635', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.642', 'logps_train/rejected': '-236.07', 'logps_train/chosen': '-55.326', 'loss/train': '0.066109', 'examples_per_second': '5.2784', 'grad_norm': '7.75', 'counters/examples': 17408, 'counters/updates': 1088}
skipping logging after 17424 examples to avoid logging too frequently
skipping logging after 17440 examples to avoid logging too frequently
skipping logging after 17456 examples to avoid logging too frequently
train stats after 17472 examples: {'rewards_train/chosen': '-1.3923', 'rewards_train/rejected': '-7.8638', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.4714', 'logps_train/rejected': '-195.85', 'logps_train/chosen': '-57.134', 'loss/train': '0.076321', 'examples_per_second': '5.2656', 'grad_norm': '7.8438', 'counters/examples': 17472, 'counters/updates': 1092}
skipping logging after 17488 examples to avoid logging too frequently
skipping logging after 17504 examples to avoid logging too frequently
skipping logging after 17520 examples to avoid logging too frequently
train stats after 17536 examples: {'rewards_train/chosen': '-1.5631', 'rewards_train/rejected': '-8.494', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.9309', 'logps_train/rejected': '-210.71', 'logps_train/chosen': '-55.301', 'loss/train': '0.097224', 'examples_per_second': '5.3747', 'grad_norm': '11', 'counters/examples': 17536, 'counters/updates': 1096}
skipping logging after 17552 examples to avoid logging too frequently
skipping logging after 17568 examples to avoid logging too frequently
skipping logging after 17584 examples to avoid logging too frequently
train stats after 17600 examples: {'rewards_train/chosen': '-1.7058', 'rewards_train/rejected': '-8.9403', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.2354', 'logps_train/rejected': '-223.98', 'logps_train/chosen': '-56.526', 'loss/train': '0.084232', 'examples_per_second': '5.8722', 'grad_norm': '9', 'counters/examples': 17600, 'counters/updates': 1100}
skipping logging after 17616 examples to avoid logging too frequently
skipping logging after 17632 examples to avoid logging too frequently
skipping logging after 17648 examples to avoid logging too frequently
train stats after 17664 examples: {'rewards_train/chosen': '-1.9099', 'rewards_train/rejected': '-10.309', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.3977', 'logps_train/rejected': '-236.4', 'logps_train/chosen': '-57.843', 'loss/train': '0.096721', 'examples_per_second': '4.444', 'grad_norm': '13.875', 'counters/examples': 17664, 'counters/updates': 1104}
skipping logging after 17680 examples to avoid logging too frequently
skipping logging after 17696 examples to avoid logging too frequently
skipping logging after 17712 examples to avoid logging too frequently
train stats after 17728 examples: {'rewards_train/chosen': '-1.5972', 'rewards_train/rejected': '-8.7466', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.1501', 'logps_train/rejected': '-217.79', 'logps_train/chosen': '-54.998', 'loss/train': '0.056273', 'examples_per_second': '4.723', 'grad_norm': '6.125', 'counters/examples': 17728, 'counters/updates': 1108}
skipping logging after 17744 examples to avoid logging too frequently
skipping logging after 17760 examples to avoid logging too frequently
skipping logging after 17776 examples to avoid logging too frequently
train stats after 17792 examples: {'rewards_train/chosen': '-1.3128', 'rewards_train/rejected': '-9.7416', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.4249', 'logps_train/rejected': '-249.89', 'logps_train/chosen': '-55.214', 'loss/train': '0.055748', 'examples_per_second': '5.213', 'grad_norm': '9.375', 'counters/examples': 17792, 'counters/updates': 1112}
skipping logging after 17808 examples to avoid logging too frequently
skipping logging after 17824 examples to avoid logging too frequently
skipping logging after 17840 examples to avoid logging too frequently
train stats after 17856 examples: {'rewards_train/chosen': '-1.5754', 'rewards_train/rejected': '-8.1968', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.6232', 'logps_train/rejected': '-193.3', 'logps_train/chosen': '-52.97', 'loss/train': '0.084299', 'examples_per_second': '5.1253', 'grad_norm': '12.938', 'counters/examples': 17856, 'counters/updates': 1116}
skipping logging after 17872 examples to avoid logging too frequently
skipping logging after 17888 examples to avoid logging too frequently
skipping logging after 17904 examples to avoid logging too frequently
train stats after 17920 examples: {'rewards_train/chosen': '-1.4545', 'rewards_train/rejected': '-8.2689', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.8102', 'logps_train/rejected': '-216.16', 'logps_train/chosen': '-48.063', 'loss/train': '0.11983', 'examples_per_second': '5.842', 'grad_norm': '11.688', 'counters/examples': 17920, 'counters/updates': 1120}
skipping logging after 17936 examples to avoid logging too frequently
skipping logging after 17952 examples to avoid logging too frequently
skipping logging after 17968 examples to avoid logging too frequently
train stats after 17984 examples: {'rewards_train/chosen': '-1.6525', 'rewards_train/rejected': '-9.2234', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.5679', 'logps_train/rejected': '-227.06', 'logps_train/chosen': '-57.445', 'loss/train': '0.075777', 'examples_per_second': '4.6453', 'grad_norm': '10.625', 'counters/examples': 17984, 'counters/updates': 1124}
skipping logging after 18000 examples to avoid logging too frequently
skipping logging after 18016 examples to avoid logging too frequently
skipping logging after 18032 examples to avoid logging too frequently
train stats after 18048 examples: {'rewards_train/chosen': '-1.2161', 'rewards_train/rejected': '-8.5239', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.308', 'logps_train/rejected': '-242.84', 'logps_train/chosen': '-60.442', 'loss/train': '0.072983', 'examples_per_second': '5.5874', 'grad_norm': '11.062', 'counters/examples': 18048, 'counters/updates': 1128}
skipping logging after 18064 examples to avoid logging too frequently
skipping logging after 18080 examples to avoid logging too frequently
skipping logging after 18096 examples to avoid logging too frequently
train stats after 18112 examples: {'rewards_train/chosen': '-1.2102', 'rewards_train/rejected': '-7.9362', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.7287', 'logps_train/rejected': '-198.62', 'logps_train/chosen': '-44.925', 'loss/train': '0.09086', 'examples_per_second': '5.3409', 'grad_norm': '9.0625', 'counters/examples': 18112, 'counters/updates': 1132}
skipping logging after 18128 examples to avoid logging too frequently
skipping logging after 18144 examples to avoid logging too frequently
skipping logging after 18160 examples to avoid logging too frequently
train stats after 18176 examples: {'rewards_train/chosen': '-0.86107', 'rewards_train/rejected': '-6.5071', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '5.647', 'logps_train/rejected': '-173.43', 'logps_train/chosen': '-39.885', 'loss/train': '0.048351', 'examples_per_second': '5.6425', 'grad_norm': '5.9375', 'counters/examples': 18176, 'counters/updates': 1136}
skipping logging after 18192 examples to avoid logging too frequently
skipping logging after 18208 examples to avoid logging too frequently
skipping logging after 18224 examples to avoid logging too frequently
train stats after 18240 examples: {'rewards_train/chosen': '-1.2001', 'rewards_train/rejected': '-8.5107', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.3075', 'logps_train/rejected': '-214.64', 'logps_train/chosen': '-50.391', 'loss/train': '0.088668', 'examples_per_second': '5.2866', 'grad_norm': '8.5625', 'counters/examples': 18240, 'counters/updates': 1140}
skipping logging after 18256 examples to avoid logging too frequently
skipping logging after 18272 examples to avoid logging too frequently
skipping logging after 18288 examples to avoid logging too frequently
train stats after 18304 examples: {'rewards_train/chosen': '-0.98761', 'rewards_train/rejected': '-7.8511', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.8627', 'logps_train/rejected': '-210.51', 'logps_train/chosen': '-51.874', 'loss/train': '0.11666', 'examples_per_second': '5.5118', 'grad_norm': '11.75', 'counters/examples': 18304, 'counters/updates': 1144}
skipping logging after 18320 examples to avoid logging too frequently
skipping logging after 18336 examples to avoid logging too frequently
skipping logging after 18352 examples to avoid logging too frequently
train stats after 18368 examples: {'rewards_train/chosen': '-1.276', 'rewards_train/rejected': '-7.903', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.6278', 'logps_train/rejected': '-205.55', 'logps_train/chosen': '-52.601', 'loss/train': '0.074812', 'examples_per_second': '5.7871', 'grad_norm': '14.875', 'counters/examples': 18368, 'counters/updates': 1148}
skipping logging after 18384 examples to avoid logging too frequently
skipping logging after 18400 examples to avoid logging too frequently
skipping logging after 18416 examples to avoid logging too frequently
train stats after 18432 examples: {'rewards_train/chosen': '-1.1934', 'rewards_train/rejected': '-7.9473', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.7536', 'logps_train/rejected': '-224.7', 'logps_train/chosen': '-53.24', 'loss/train': '0.14264', 'examples_per_second': '4.8224', 'grad_norm': '13.438', 'counters/examples': 18432, 'counters/updates': 1152}
skipping logging after 18448 examples to avoid logging too frequently
skipping logging after 18464 examples to avoid logging too frequently
skipping logging after 18480 examples to avoid logging too frequently
train stats after 18496 examples: {'rewards_train/chosen': '-0.68301', 'rewards_train/rejected': '-7.4244', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.7416', 'logps_train/rejected': '-221.8', 'logps_train/chosen': '-48.992', 'loss/train': '0.088967', 'examples_per_second': '5.7084', 'grad_norm': '7.9375', 'counters/examples': 18496, 'counters/updates': 1156}
skipping logging after 18512 examples to avoid logging too frequently
skipping logging after 18528 examples to avoid logging too frequently
skipping logging after 18544 examples to avoid logging too frequently
train stats after 18560 examples: {'rewards_train/chosen': '-0.93891', 'rewards_train/rejected': '-8.3518', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.4143', 'logps_train/rejected': '-235.84', 'logps_train/chosen': '-56.637', 'loss/train': '0.094358', 'examples_per_second': '5.1032', 'grad_norm': '13.25', 'counters/examples': 18560, 'counters/updates': 1160}
skipping logging after 18576 examples to avoid logging too frequently
skipping logging after 18592 examples to avoid logging too frequently
skipping logging after 18608 examples to avoid logging too frequently
train stats after 18624 examples: {'rewards_train/chosen': '-0.95893', 'rewards_train/rejected': '-7.2625', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.302', 'logps_train/rejected': '-203.64', 'logps_train/chosen': '-39.952', 'loss/train': '0.07762', 'examples_per_second': '5.2606', 'grad_norm': '9.125', 'counters/examples': 18624, 'counters/updates': 1164}
skipping logging after 18640 examples to avoid logging too frequently
skipping logging after 18656 examples to avoid logging too frequently
skipping logging after 18672 examples to avoid logging too frequently
train stats after 18688 examples: {'rewards_train/chosen': '-1.0976', 'rewards_train/rejected': '-8.1294', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.0332', 'logps_train/rejected': '-215.72', 'logps_train/chosen': '-49.331', 'loss/train': '0.054182', 'examples_per_second': '5.3741', 'grad_norm': '5.5625', 'counters/examples': 18688, 'counters/updates': 1168}
skipping logging after 18704 examples to avoid logging too frequently
skipping logging after 18720 examples to avoid logging too frequently
skipping logging after 18736 examples to avoid logging too frequently
train stats after 18752 examples: {'rewards_train/chosen': '-1.3087', 'rewards_train/rejected': '-8.6412', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '7.3358', 'logps_train/rejected': '-237.8', 'logps_train/chosen': '-53.04', 'loss/train': '0.12839', 'examples_per_second': '4.377', 'grad_norm': '7.9375', 'counters/examples': 18752, 'counters/updates': 1172}
skipping logging after 18768 examples to avoid logging too frequently
skipping logging after 18784 examples to avoid logging too frequently
skipping logging after 18800 examples to avoid logging too frequently
train stats after 18816 examples: {'rewards_train/chosen': '-1.2276', 'rewards_train/rejected': '-7.9553', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.7256', 'logps_train/rejected': '-225.28', 'logps_train/chosen': '-60.439', 'loss/train': '0.086832', 'examples_per_second': '4.3202', 'grad_norm': '7.4375', 'counters/examples': 18816, 'counters/updates': 1176}
skipping logging after 18832 examples to avoid logging too frequently
skipping logging after 18848 examples to avoid logging too frequently
skipping logging after 18864 examples to avoid logging too frequently
train stats after 18880 examples: {'rewards_train/chosen': '-1.0663', 'rewards_train/rejected': '-8.6954', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.6302', 'logps_train/rejected': '-218.47', 'logps_train/chosen': '-44.923', 'loss/train': '0.070176', 'examples_per_second': '4.518', 'grad_norm': '4.125', 'counters/examples': 18880, 'counters/updates': 1180}
skipping logging after 18896 examples to avoid logging too frequently
skipping logging after 18912 examples to avoid logging too frequently
skipping logging after 18928 examples to avoid logging too frequently
train stats after 18944 examples: {'rewards_train/chosen': '-1.2457', 'rewards_train/rejected': '-8.9686', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.7217', 'logps_train/rejected': '-245.09', 'logps_train/chosen': '-55.944', 'loss/train': '0.066792', 'examples_per_second': '5.0467', 'grad_norm': '6.2812', 'counters/examples': 18944, 'counters/updates': 1184}
skipping logging after 18960 examples to avoid logging too frequently
skipping logging after 18976 examples to avoid logging too frequently
skipping logging after 18992 examples to avoid logging too frequently
train stats after 19008 examples: {'rewards_train/chosen': '-1.3236', 'rewards_train/rejected': '-8.784', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.462', 'logps_train/rejected': '-229.32', 'logps_train/chosen': '-53.905', 'loss/train': '0.094494', 'examples_per_second': '5.0756', 'grad_norm': '6.4688', 'counters/examples': 19008, 'counters/updates': 1188}
skipping logging after 19024 examples to avoid logging too frequently
skipping logging after 19040 examples to avoid logging too frequently
skipping logging after 19056 examples to avoid logging too frequently
train stats after 19072 examples: {'rewards_train/chosen': '-1.3891', 'rewards_train/rejected': '-9.5219', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1332', 'logps_train/rejected': '-244.97', 'logps_train/chosen': '-56.361', 'loss/train': '0.046632', 'examples_per_second': '4.7681', 'grad_norm': '6.5', 'counters/examples': 19072, 'counters/updates': 1192}
skipping logging after 19088 examples to avoid logging too frequently
skipping logging after 19104 examples to avoid logging too frequently
skipping logging after 19120 examples to avoid logging too frequently
train stats after 19136 examples: {'rewards_train/chosen': '-1.209', 'rewards_train/rejected': '-8.7399', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.5299', 'logps_train/rejected': '-226.67', 'logps_train/chosen': '-49.11', 'loss/train': '0.082408', 'examples_per_second': '4.7521', 'grad_norm': '7.3438', 'counters/examples': 19136, 'counters/updates': 1196}
skipping logging after 19152 examples to avoid logging too frequently
skipping logging after 19168 examples to avoid logging too frequently
skipping logging after 19184 examples to avoid logging too frequently
train stats after 19200 examples: {'rewards_train/chosen': '-1.6735', 'rewards_train/rejected': '-9.1872', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.5142', 'logps_train/rejected': '-225.57', 'logps_train/chosen': '-55.804', 'loss/train': '0.088968', 'examples_per_second': '4.8625', 'grad_norm': '7.2188', 'counters/examples': 19200, 'counters/updates': 1200}
skipping logging after 19216 examples to avoid logging too frequently
skipping logging after 19232 examples to avoid logging too frequently
skipping logging after 19248 examples to avoid logging too frequently
train stats after 19264 examples: {'rewards_train/chosen': '-1.7004', 'rewards_train/rejected': '-10.591', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.891', 'logps_train/rejected': '-247.16', 'logps_train/chosen': '-51.077', 'loss/train': '0.067195', 'examples_per_second': '5.1528', 'grad_norm': '6.3125', 'counters/examples': 19264, 'counters/updates': 1204}
skipping logging after 19280 examples to avoid logging too frequently
skipping logging after 19296 examples to avoid logging too frequently
skipping logging after 19312 examples to avoid logging too frequently
train stats after 19328 examples: {'rewards_train/chosen': '-1.6647', 'rewards_train/rejected': '-10.577', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.9114', 'logps_train/rejected': '-260.81', 'logps_train/chosen': '-62.524', 'loss/train': '0.057076', 'examples_per_second': '5.1758', 'grad_norm': '9.5625', 'counters/examples': 19328, 'counters/updates': 1208}
skipping logging after 19344 examples to avoid logging too frequently
skipping logging after 19360 examples to avoid logging too frequently
skipping logging after 19376 examples to avoid logging too frequently
train stats after 19392 examples: {'rewards_train/chosen': '-1.598', 'rewards_train/rejected': '-9.619', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.0201', 'logps_train/rejected': '-243.69', 'logps_train/chosen': '-55.51', 'loss/train': '0.11225', 'examples_per_second': '4.3496', 'grad_norm': '11.938', 'counters/examples': 19392, 'counters/updates': 1212}
skipping logging after 19408 examples to avoid logging too frequently
skipping logging after 19424 examples to avoid logging too frequently
skipping logging after 19440 examples to avoid logging too frequently
train stats after 19456 examples: {'rewards_train/chosen': '-1.3504', 'rewards_train/rejected': '-9.4824', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1284', 'logps_train/rejected': '-230.65', 'logps_train/chosen': '-51.561', 'loss/train': '0.023628', 'examples_per_second': '5.3653', 'grad_norm': '4.8125', 'counters/examples': 19456, 'counters/updates': 1216}
skipping logging after 19472 examples to avoid logging too frequently
skipping logging after 19488 examples to avoid logging too frequently
skipping logging after 19504 examples to avoid logging too frequently
train stats after 19520 examples: {'rewards_train/chosen': '-1.8205', 'rewards_train/rejected': '-9.4155', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.5963', 'logps_train/rejected': '-228.89', 'logps_train/chosen': '-56.475', 'loss/train': '0.069952', 'examples_per_second': '4.9224', 'grad_norm': '7.0312', 'counters/examples': 19520, 'counters/updates': 1220}
skipping logging after 19536 examples to avoid logging too frequently
skipping logging after 19552 examples to avoid logging too frequently
skipping logging after 19568 examples to avoid logging too frequently
train stats after 19584 examples: {'rewards_train/chosen': '-1.6094', 'rewards_train/rejected': '-10.027', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.4185', 'logps_train/rejected': '-250', 'logps_train/chosen': '-60.514', 'loss/train': '0.060338', 'examples_per_second': '4.8819', 'grad_norm': '11.438', 'counters/examples': 19584, 'counters/updates': 1224}
skipping logging after 19600 examples to avoid logging too frequently
skipping logging after 19616 examples to avoid logging too frequently
skipping logging after 19632 examples to avoid logging too frequently
train stats after 19648 examples: {'rewards_train/chosen': '-1.2836', 'rewards_train/rejected': '-9.1691', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.8838', 'logps_train/rejected': '-258.61', 'logps_train/chosen': '-60.491', 'loss/train': '0.070779', 'examples_per_second': '5.6968', 'grad_norm': '8', 'counters/examples': 19648, 'counters/updates': 1228}
skipping logging after 19664 examples to avoid logging too frequently
skipping logging after 19680 examples to avoid logging too frequently
skipping logging after 19696 examples to avoid logging too frequently
train stats after 19712 examples: {'rewards_train/chosen': '-1.3931', 'rewards_train/rejected': '-8.89', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.4989', 'logps_train/rejected': '-216.71', 'logps_train/chosen': '-51.72', 'loss/train': '0.14264', 'examples_per_second': '5.2773', 'grad_norm': '19.375', 'counters/examples': 19712, 'counters/updates': 1232}
skipping logging after 19728 examples to avoid logging too frequently
skipping logging after 19744 examples to avoid logging too frequently
skipping logging after 19760 examples to avoid logging too frequently
train stats after 19776 examples: {'rewards_train/chosen': '-1.2561', 'rewards_train/rejected': '-8.8872', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.6298', 'logps_train/rejected': '-227.26', 'logps_train/chosen': '-49.122', 'loss/train': '0.090957', 'examples_per_second': '4.5255', 'grad_norm': '11', 'counters/examples': 19776, 'counters/updates': 1236}
skipping logging after 19792 examples to avoid logging too frequently
skipping logging after 19808 examples to avoid logging too frequently
skipping logging after 19824 examples to avoid logging too frequently
train stats after 19840 examples: {'rewards_train/chosen': '-1.3052', 'rewards_train/rejected': '-8.0842', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.7794', 'logps_train/rejected': '-215.57', 'logps_train/chosen': '-60.923', 'loss/train': '0.075244', 'examples_per_second': '4.8939', 'grad_norm': '10.188', 'counters/examples': 19840, 'counters/updates': 1240}
skipping logging after 19856 examples to avoid logging too frequently
skipping logging after 19872 examples to avoid logging too frequently
skipping logging after 19888 examples to avoid logging too frequently
train stats after 19904 examples: {'rewards_train/chosen': '-0.88139', 'rewards_train/rejected': '-9.8162', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.9327', 'logps_train/rejected': '-277.32', 'logps_train/chosen': '-55.003', 'loss/train': '0.022944', 'examples_per_second': '4.627', 'grad_norm': '4.0938', 'counters/examples': 19904, 'counters/updates': 1244}
skipping logging after 19920 examples to avoid logging too frequently
skipping logging after 19936 examples to avoid logging too frequently
skipping logging after 19952 examples to avoid logging too frequently
train stats after 19968 examples: {'rewards_train/chosen': '-1.5839', 'rewards_train/rejected': '-7.9651', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '6.3828', 'logps_train/rejected': '-188.89', 'logps_train/chosen': '-50.514', 'loss/train': '0.09408', 'examples_per_second': '4.9334', 'grad_norm': '10.938', 'counters/examples': 19968, 'counters/updates': 1248}
skipping logging after 19984 examples to avoid logging too frequently
skipping logging after 20000 examples to avoid logging too frequently
Running evaluation after 20000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:15,  2.42s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:06,  2.22s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:56,  1.95s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:08<00:53,  1.93s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:42,  1.57s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.68s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:12<00:37,  1.51s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.58s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:36,  1.58s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:33,  1.50s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:33,  1.57s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:30,  1.51s/it]Computing eval metrics:  41%|████      | 13/32 [00:21<00:27,  1.46s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:22,  1.30s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.25s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:26<00:20,  1.33s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.35s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:31<00:14,  1.28s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:32<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:33<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.30s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:36<00:08,  1.27s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:37<00:07,  1.31s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:39<00:07,  1.48s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.42s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.62s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.43s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:45<00:01,  1.43s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.41s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.45s/it]
eval after 20000: {'rewards_eval/chosen': '-8.8462', 'rewards_eval/rejected': '-9.2559', 'rewards_eval/accuracies': '0.49609', 'rewards_eval/margins': '0.40989', 'logps_eval/rejected': '-240.23', 'logps_eval/chosen': '-233.38', 'loss/eval': '2.1556'}
skipping logging after 20016 examples to avoid logging too frequently
train stats after 20032 examples: {'rewards_train/chosen': '-1.2165', 'rewards_train/rejected': '-9.4031', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.1881', 'logps_train/rejected': '-241.19', 'logps_train/chosen': '-52.362', 'loss/train': '0.070038', 'examples_per_second': '6.1727', 'grad_norm': '9.8125', 'counters/examples': 20032, 'counters/updates': 1252}
skipping logging after 20048 examples to avoid logging too frequently
skipping logging after 20064 examples to avoid logging too frequently
skipping logging after 20080 examples to avoid logging too frequently
train stats after 20096 examples: {'rewards_train/chosen': '-1.7933', 'rewards_train/rejected': '-10.321', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.5289', 'logps_train/rejected': '-252.2', 'logps_train/chosen': '-63.937', 'loss/train': '0.043848', 'examples_per_second': '5.462', 'grad_norm': '6.5312', 'counters/examples': 20096, 'counters/updates': 1256}
skipping logging after 20112 examples to avoid logging too frequently
skipping logging after 20128 examples to avoid logging too frequently
skipping logging after 20144 examples to avoid logging too frequently
train stats after 20160 examples: {'rewards_train/chosen': '-1.649', 'rewards_train/rejected': '-10.177', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.527', 'logps_train/rejected': '-227.74', 'logps_train/chosen': '-64.27', 'loss/train': '0.029991', 'examples_per_second': '5.4729', 'grad_norm': '5.3438', 'counters/examples': 20160, 'counters/updates': 1260}
skipping logging after 20176 examples to avoid logging too frequently
skipping logging after 20192 examples to avoid logging too frequently
skipping logging after 20208 examples to avoid logging too frequently
train stats after 20224 examples: {'rewards_train/chosen': '-1.6949', 'rewards_train/rejected': '-12.25', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '10.556', 'logps_train/rejected': '-302.85', 'logps_train/chosen': '-60.075', 'loss/train': '0.043454', 'examples_per_second': '4.9412', 'grad_norm': '7.1562', 'counters/examples': 20224, 'counters/updates': 1264}
skipping logging after 20240 examples to avoid logging too frequently
skipping logging after 20256 examples to avoid logging too frequently
skipping logging after 20272 examples to avoid logging too frequently
train stats after 20288 examples: {'rewards_train/chosen': '-1.658', 'rewards_train/rejected': '-11.168', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '9.5168', 'logps_train/rejected': '-265.07', 'logps_train/chosen': '-57.463', 'loss/train': '0.12287', 'examples_per_second': '4.19', 'grad_norm': '13.188', 'counters/examples': 20288, 'counters/updates': 1268}
skipping logging after 20304 examples to avoid logging too frequently
skipping logging after 20320 examples to avoid logging too frequently
skipping logging after 20336 examples to avoid logging too frequently
train stats after 20352 examples: {'rewards_train/chosen': '-1.6429', 'rewards_train/rejected': '-9.0242', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '7.382', 'logps_train/rejected': '-197.22', 'logps_train/chosen': '-48.956', 'loss/train': '0.14171', 'examples_per_second': '5.7998', 'grad_norm': '12.812', 'counters/examples': 20352, 'counters/updates': 1272}
skipping logging after 20368 examples to avoid logging too frequently
skipping logging after 20384 examples to avoid logging too frequently
skipping logging after 20400 examples to avoid logging too frequently
train stats after 20416 examples: {'rewards_train/chosen': '-1.8315', 'rewards_train/rejected': '-8.7993', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.9692', 'logps_train/rejected': '-208.61', 'logps_train/chosen': '-65.309', 'loss/train': '0.14406', 'examples_per_second': '3.9906', 'grad_norm': '19.125', 'counters/examples': 20416, 'counters/updates': 1276}
skipping logging after 20432 examples to avoid logging too frequently
skipping logging after 20448 examples to avoid logging too frequently
skipping logging after 20464 examples to avoid logging too frequently
train stats after 20480 examples: {'rewards_train/chosen': '-1.4853', 'rewards_train/rejected': '-9.9635', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.4806', 'logps_train/rejected': '-258.28', 'logps_train/chosen': '-59.713', 'loss/train': '0.079322', 'examples_per_second': '4.6192', 'grad_norm': '6.4375', 'counters/examples': 20480, 'counters/updates': 1280}
skipping logging after 20496 examples to avoid logging too frequently
skipping logging after 20512 examples to avoid logging too frequently
skipping logging after 20528 examples to avoid logging too frequently
train stats after 20544 examples: {'rewards_train/chosen': '-1.5736', 'rewards_train/rejected': '-9.9893', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.4155', 'logps_train/rejected': '-269.57', 'logps_train/chosen': '-63.512', 'loss/train': '0.060567', 'examples_per_second': '4.8347', 'grad_norm': '11.188', 'counters/examples': 20544, 'counters/updates': 1284}
skipping logging after 20560 examples to avoid logging too frequently
skipping logging after 20576 examples to avoid logging too frequently
skipping logging after 20592 examples to avoid logging too frequently
train stats after 20608 examples: {'rewards_train/chosen': '-1.3775', 'rewards_train/rejected': '-9.4891', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1078', 'logps_train/rejected': '-247.47', 'logps_train/chosen': '-54.045', 'loss/train': '0.06783', 'examples_per_second': '4.8374', 'grad_norm': '7.6562', 'counters/examples': 20608, 'counters/updates': 1288}
skipping logging after 20624 examples to avoid logging too frequently
skipping logging after 20640 examples to avoid logging too frequently
skipping logging after 20656 examples to avoid logging too frequently
train stats after 20672 examples: {'rewards_train/chosen': '-1.7013', 'rewards_train/rejected': '-9.1918', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.4871', 'logps_train/rejected': '-219.03', 'logps_train/chosen': '-55.303', 'loss/train': '0.081633', 'examples_per_second': '4.2469', 'grad_norm': '7.8438', 'counters/examples': 20672, 'counters/updates': 1292}
skipping logging after 20688 examples to avoid logging too frequently
skipping logging after 20704 examples to avoid logging too frequently
skipping logging after 20720 examples to avoid logging too frequently
train stats after 20736 examples: {'rewards_train/chosen': '-1.4683', 'rewards_train/rejected': '-9.657', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.189', 'logps_train/rejected': '-237.13', 'logps_train/chosen': '-58.73', 'loss/train': '0.067104', 'examples_per_second': '5.3189', 'grad_norm': '6.4688', 'counters/examples': 20736, 'counters/updates': 1296}
skipping logging after 20752 examples to avoid logging too frequently
skipping logging after 20768 examples to avoid logging too frequently
skipping logging after 20784 examples to avoid logging too frequently
train stats after 20800 examples: {'rewards_train/chosen': '-1.655', 'rewards_train/rejected': '-10.09', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.4355', 'logps_train/rejected': '-239.67', 'logps_train/chosen': '-60.079', 'loss/train': '0.056498', 'examples_per_second': '4.4914', 'grad_norm': '9.875', 'counters/examples': 20800, 'counters/updates': 1300}
skipping logging after 20816 examples to avoid logging too frequently
skipping logging after 20832 examples to avoid logging too frequently
skipping logging after 20848 examples to avoid logging too frequently
train stats after 20864 examples: {'rewards_train/chosen': '-1.8856', 'rewards_train/rejected': '-10.581', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.6927', 'logps_train/rejected': '-248.46', 'logps_train/chosen': '-61.009', 'loss/train': '0.1072', 'examples_per_second': '4.4586', 'grad_norm': '17.125', 'counters/examples': 20864, 'counters/updates': 1304}
skipping logging after 20880 examples to avoid logging too frequently
skipping logging after 20896 examples to avoid logging too frequently
skipping logging after 20912 examples to avoid logging too frequently
train stats after 20928 examples: {'rewards_train/chosen': '-1.2769', 'rewards_train/rejected': '-8.6492', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.3754', 'logps_train/rejected': '-219.63', 'logps_train/chosen': '-57.689', 'loss/train': '0.04608', 'examples_per_second': '4.4629', 'grad_norm': '6', 'counters/examples': 20928, 'counters/updates': 1308}
skipping logging after 20944 examples to avoid logging too frequently
skipping logging after 20960 examples to avoid logging too frequently
skipping logging after 20976 examples to avoid logging too frequently
train stats after 20992 examples: {'rewards_train/chosen': '-1.3823', 'rewards_train/rejected': '-9.5061', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1233', 'logps_train/rejected': '-249.88', 'logps_train/chosen': '-51.47', 'loss/train': '0.065449', 'examples_per_second': '5.5056', 'grad_norm': '9', 'counters/examples': 20992, 'counters/updates': 1312}
skipping logging after 21008 examples to avoid logging too frequently
skipping logging after 21024 examples to avoid logging too frequently
skipping logging after 21040 examples to avoid logging too frequently
train stats after 21056 examples: {'rewards_train/chosen': '-1.543', 'rewards_train/rejected': '-8.9891', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.4476', 'logps_train/rejected': '-200.91', 'logps_train/chosen': '-52.44', 'loss/train': '0.04789', 'examples_per_second': '5.0583', 'grad_norm': '9.125', 'counters/examples': 21056, 'counters/updates': 1316}
skipping logging after 21072 examples to avoid logging too frequently
skipping logging after 21088 examples to avoid logging too frequently
skipping logging after 21104 examples to avoid logging too frequently
train stats after 21120 examples: {'rewards_train/chosen': '-1.5456', 'rewards_train/rejected': '-9.012', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.4673', 'logps_train/rejected': '-222.73', 'logps_train/chosen': '-49.755', 'loss/train': '0.062249', 'examples_per_second': '5.0778', 'grad_norm': '10.312', 'counters/examples': 21120, 'counters/updates': 1320}
skipping logging after 21136 examples to avoid logging too frequently
skipping logging after 21152 examples to avoid logging too frequently
skipping logging after 21168 examples to avoid logging too frequently
train stats after 21184 examples: {'rewards_train/chosen': '-1.5905', 'rewards_train/rejected': '-12.038', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '10.45', 'logps_train/rejected': '-272.31', 'logps_train/chosen': '-64.082', 'loss/train': '0.033013', 'examples_per_second': '6.119', 'grad_norm': '5.6562', 'counters/examples': 21184, 'counters/updates': 1324}
skipping logging after 21200 examples to avoid logging too frequently
skipping logging after 21216 examples to avoid logging too frequently
skipping logging after 21232 examples to avoid logging too frequently
train stats after 21248 examples: {'rewards_train/chosen': '-1.3715', 'rewards_train/rejected': '-10.265', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.89', 'logps_train/rejected': '-262.55', 'logps_train/chosen': '-53.406', 'loss/train': '0.066694', 'examples_per_second': '4.3018', 'grad_norm': '8.4375', 'counters/examples': 21248, 'counters/updates': 1328}
skipping logging after 21264 examples to avoid logging too frequently
skipping logging after 21280 examples to avoid logging too frequently
skipping logging after 21296 examples to avoid logging too frequently
train stats after 21312 examples: {'rewards_train/chosen': '-1.5897', 'rewards_train/rejected': '-11.071', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.4818', 'logps_train/rejected': '-267.06', 'logps_train/chosen': '-51.985', 'loss/train': '0.026057', 'examples_per_second': '4.7819', 'grad_norm': '4.75', 'counters/examples': 21312, 'counters/updates': 1332}
skipping logging after 21328 examples to avoid logging too frequently
skipping logging after 21344 examples to avoid logging too frequently
skipping logging after 21360 examples to avoid logging too frequently
train stats after 21376 examples: {'rewards_train/chosen': '-1.5675', 'rewards_train/rejected': '-9.6648', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.1027', 'logps_train/rejected': '-238.88', 'logps_train/chosen': '-58.931', 'loss/train': '0.0557', 'examples_per_second': '5.497', 'grad_norm': '8.0625', 'counters/examples': 21376, 'counters/updates': 1336}
skipping logging after 21392 examples to avoid logging too frequently
skipping logging after 21408 examples to avoid logging too frequently
skipping logging after 21424 examples to avoid logging too frequently
train stats after 21440 examples: {'rewards_train/chosen': '-1.5761', 'rewards_train/rejected': '-8.8156', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.2404', 'logps_train/rejected': '-202.17', 'logps_train/chosen': '-62.52', 'loss/train': '0.10192', 'examples_per_second': '4.6552', 'grad_norm': '13.438', 'counters/examples': 21440, 'counters/updates': 1340}
skipping logging after 21456 examples to avoid logging too frequently
skipping logging after 21472 examples to avoid logging too frequently
skipping logging after 21488 examples to avoid logging too frequently
train stats after 21504 examples: {'rewards_train/chosen': '-1.583', 'rewards_train/rejected': '-9.1301', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.5433', 'logps_train/rejected': '-216.85', 'logps_train/chosen': '-56.917', 'loss/train': '0.053547', 'examples_per_second': '4.9658', 'grad_norm': '7.0312', 'counters/examples': 21504, 'counters/updates': 1344}
skipping logging after 21520 examples to avoid logging too frequently
skipping logging after 21536 examples to avoid logging too frequently
skipping logging after 21552 examples to avoid logging too frequently
train stats after 21568 examples: {'rewards_train/chosen': '-1.578', 'rewards_train/rejected': '-9.2294', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.6443', 'logps_train/rejected': '-214.96', 'logps_train/chosen': '-53.129', 'loss/train': '0.096527', 'examples_per_second': '6.4528', 'grad_norm': '9.375', 'counters/examples': 21568, 'counters/updates': 1348}
skipping logging after 21584 examples to avoid logging too frequently
skipping logging after 21600 examples to avoid logging too frequently
skipping logging after 21616 examples to avoid logging too frequently
train stats after 21632 examples: {'rewards_train/chosen': '-1.3408', 'rewards_train/rejected': '-8.9795', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.6365', 'logps_train/rejected': '-222.4', 'logps_train/chosen': '-50.691', 'loss/train': '0.068337', 'examples_per_second': '4.4616', 'grad_norm': '9', 'counters/examples': 21632, 'counters/updates': 1352}
skipping logging after 21648 examples to avoid logging too frequently
skipping logging after 21664 examples to avoid logging too frequently
skipping logging after 21680 examples to avoid logging too frequently
train stats after 21696 examples: {'rewards_train/chosen': '-1.8537', 'rewards_train/rejected': '-10.71', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.8547', 'logps_train/rejected': '-259.85', 'logps_train/chosen': '-55.198', 'loss/train': '0.062694', 'examples_per_second': '4.3792', 'grad_norm': '8.4375', 'counters/examples': 21696, 'counters/updates': 1356}
skipping logging after 21712 examples to avoid logging too frequently
skipping logging after 21728 examples to avoid logging too frequently
skipping logging after 21744 examples to avoid logging too frequently
train stats after 21760 examples: {'rewards_train/chosen': '-1.719', 'rewards_train/rejected': '-10.493', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.7739', 'logps_train/rejected': '-263.89', 'logps_train/chosen': '-58.242', 'loss/train': '0.12701', 'examples_per_second': '5.3277', 'grad_norm': '18.75', 'counters/examples': 21760, 'counters/updates': 1360}
skipping logging after 21776 examples to avoid logging too frequently
skipping logging after 21792 examples to avoid logging too frequently
skipping logging after 21808 examples to avoid logging too frequently
train stats after 21824 examples: {'rewards_train/chosen': '-1.4349', 'rewards_train/rejected': '-9.9046', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.4714', 'logps_train/rejected': '-252.32', 'logps_train/chosen': '-56.525', 'loss/train': '0.10081', 'examples_per_second': '5.0465', 'grad_norm': '8.25', 'counters/examples': 21824, 'counters/updates': 1364}
skipping logging after 21840 examples to avoid logging too frequently
skipping logging after 21856 examples to avoid logging too frequently
skipping logging after 21872 examples to avoid logging too frequently
train stats after 21888 examples: {'rewards_train/chosen': '-1.6095', 'rewards_train/rejected': '-8.1962', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.5865', 'logps_train/rejected': '-208.41', 'logps_train/chosen': '-51.958', 'loss/train': '0.080419', 'examples_per_second': '4.9526', 'grad_norm': '9.25', 'counters/examples': 21888, 'counters/updates': 1368}
skipping logging after 21904 examples to avoid logging too frequently
skipping logging after 21920 examples to avoid logging too frequently
skipping logging after 21936 examples to avoid logging too frequently
train stats after 21952 examples: {'rewards_train/chosen': '-1.6095', 'rewards_train/rejected': '-8.8325', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.2224', 'logps_train/rejected': '-216.42', 'logps_train/chosen': '-64.174', 'loss/train': '0.041912', 'examples_per_second': '6.3526', 'grad_norm': '11.125', 'counters/examples': 21952, 'counters/updates': 1372}
skipping logging after 21968 examples to avoid logging too frequently
skipping logging after 21984 examples to avoid logging too frequently
skipping logging after 22000 examples to avoid logging too frequently
train stats after 22016 examples: {'rewards_train/chosen': '-2.0331', 'rewards_train/rejected': '-10.078', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.0442', 'logps_train/rejected': '-231.54', 'logps_train/chosen': '-66.852', 'loss/train': '0.088985', 'examples_per_second': '5.0091', 'grad_norm': '20.25', 'counters/examples': 22016, 'counters/updates': 1376}
skipping logging after 22032 examples to avoid logging too frequently
skipping logging after 22048 examples to avoid logging too frequently
skipping logging after 22064 examples to avoid logging too frequently
train stats after 22080 examples: {'rewards_train/chosen': '-1.2993', 'rewards_train/rejected': '-9.0608', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.7634', 'logps_train/rejected': '-232.89', 'logps_train/chosen': '-48.815', 'loss/train': '0.035629', 'examples_per_second': '5.4502', 'grad_norm': '7.25', 'counters/examples': 22080, 'counters/updates': 1380}
skipping logging after 22096 examples to avoid logging too frequently
skipping logging after 22112 examples to avoid logging too frequently
skipping logging after 22128 examples to avoid logging too frequently
train stats after 22144 examples: {'rewards_train/chosen': '-1.8142', 'rewards_train/rejected': '-9.0125', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.1978', 'logps_train/rejected': '-224', 'logps_train/chosen': '-57.319', 'loss/train': '0.058545', 'examples_per_second': '5.7923', 'grad_norm': '10.5', 'counters/examples': 22144, 'counters/updates': 1384}
skipping logging after 22160 examples to avoid logging too frequently
skipping logging after 22176 examples to avoid logging too frequently
skipping logging after 22192 examples to avoid logging too frequently
train stats after 22208 examples: {'rewards_train/chosen': '-1.8079', 'rewards_train/rejected': '-9.4489', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.6407', 'logps_train/rejected': '-204.01', 'logps_train/chosen': '-54.179', 'loss/train': '0.095888', 'examples_per_second': '5.0748', 'grad_norm': '14.438', 'counters/examples': 22208, 'counters/updates': 1388}
skipping logging after 22224 examples to avoid logging too frequently
skipping logging after 22240 examples to avoid logging too frequently
skipping logging after 22256 examples to avoid logging too frequently
train stats after 22272 examples: {'rewards_train/chosen': '-1.6895', 'rewards_train/rejected': '-10.478', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.7876', 'logps_train/rejected': '-253.79', 'logps_train/chosen': '-60.398', 'loss/train': '0.06485', 'examples_per_second': '5.0476', 'grad_norm': '13.938', 'counters/examples': 22272, 'counters/updates': 1392}
skipping logging after 22288 examples to avoid logging too frequently
skipping logging after 22304 examples to avoid logging too frequently
skipping logging after 22320 examples to avoid logging too frequently
train stats after 22336 examples: {'rewards_train/chosen': '-1.7543', 'rewards_train/rejected': '-9.0132', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.2589', 'logps_train/rejected': '-215.96', 'logps_train/chosen': '-64.735', 'loss/train': '0.25296', 'examples_per_second': '4.107', 'grad_norm': '21.375', 'counters/examples': 22336, 'counters/updates': 1396}
skipping logging after 22352 examples to avoid logging too frequently
skipping logging after 22368 examples to avoid logging too frequently
skipping logging after 22384 examples to avoid logging too frequently
train stats after 22400 examples: {'rewards_train/chosen': '-1.5035', 'rewards_train/rejected': '-8.2501', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.7458', 'logps_train/rejected': '-187.93', 'logps_train/chosen': '-55.218', 'loss/train': '0.078874', 'examples_per_second': '5.1828', 'grad_norm': '6.5', 'counters/examples': 22400, 'counters/updates': 1400}
skipping logging after 22416 examples to avoid logging too frequently
skipping logging after 22432 examples to avoid logging too frequently
skipping logging after 22448 examples to avoid logging too frequently
train stats after 22464 examples: {'rewards_train/chosen': '-1.3419', 'rewards_train/rejected': '-8.1776', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.8352', 'logps_train/rejected': '-223.62', 'logps_train/chosen': '-53.505', 'loss/train': '0.1035', 'examples_per_second': '5.6662', 'grad_norm': '9.5625', 'counters/examples': 22464, 'counters/updates': 1404}
skipping logging after 22480 examples to avoid logging too frequently
skipping logging after 22496 examples to avoid logging too frequently
skipping logging after 22512 examples to avoid logging too frequently
train stats after 22528 examples: {'rewards_train/chosen': '-1.4168', 'rewards_train/rejected': '-8.2762', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.8588', 'logps_train/rejected': '-233.14', 'logps_train/chosen': '-58.63', 'loss/train': '0.081446', 'examples_per_second': '4.3193', 'grad_norm': '7.4688', 'counters/examples': 22528, 'counters/updates': 1408}
skipping logging after 22544 examples to avoid logging too frequently
skipping logging after 22560 examples to avoid logging too frequently
skipping logging after 22576 examples to avoid logging too frequently
train stats after 22592 examples: {'rewards_train/chosen': '-1.5918', 'rewards_train/rejected': '-8.7776', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.1897', 'logps_train/rejected': '-233.2', 'logps_train/chosen': '-60.926', 'loss/train': '0.10025', 'examples_per_second': '6.1296', 'grad_norm': '16.25', 'counters/examples': 22592, 'counters/updates': 1412}
skipping logging after 22608 examples to avoid logging too frequently
skipping logging after 22624 examples to avoid logging too frequently
skipping logging after 22640 examples to avoid logging too frequently
train stats after 22656 examples: {'rewards_train/chosen': '-1.2791', 'rewards_train/rejected': '-8.8227', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.5417', 'logps_train/rejected': '-214.23', 'logps_train/chosen': '-47.196', 'loss/train': '0.067568', 'examples_per_second': '4.1907', 'grad_norm': '6.0312', 'counters/examples': 22656, 'counters/updates': 1416}
skipping logging after 22672 examples to avoid logging too frequently
skipping logging after 22688 examples to avoid logging too frequently
skipping logging after 22704 examples to avoid logging too frequently
train stats after 22720 examples: {'rewards_train/chosen': '-1.9315', 'rewards_train/rejected': '-7.6658', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '5.7333', 'logps_train/rejected': '-196.55', 'logps_train/chosen': '-60.787', 'loss/train': '0.11361', 'examples_per_second': '6.5792', 'grad_norm': '11.25', 'counters/examples': 22720, 'counters/updates': 1420}
skipping logging after 22736 examples to avoid logging too frequently
skipping logging after 22752 examples to avoid logging too frequently
skipping logging after 22768 examples to avoid logging too frequently
train stats after 22784 examples: {'rewards_train/chosen': '-1.6033', 'rewards_train/rejected': '-10.504', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.8977', 'logps_train/rejected': '-281.45', 'logps_train/chosen': '-52.637', 'loss/train': '0.03473', 'examples_per_second': '5.0636', 'grad_norm': '4.3125', 'counters/examples': 22784, 'counters/updates': 1424}
skipping logging after 22800 examples to avoid logging too frequently
skipping logging after 22816 examples to avoid logging too frequently
skipping logging after 22832 examples to avoid logging too frequently
train stats after 22848 examples: {'rewards_train/chosen': '-2.05', 'rewards_train/rejected': '-9.2334', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.1814', 'logps_train/rejected': '-208.39', 'logps_train/chosen': '-59.44', 'loss/train': '0.15592', 'examples_per_second': '3.9157', 'grad_norm': '10.625', 'counters/examples': 22848, 'counters/updates': 1428}
skipping logging after 22864 examples to avoid logging too frequently
skipping logging after 22880 examples to avoid logging too frequently
skipping logging after 22896 examples to avoid logging too frequently
train stats after 22912 examples: {'rewards_train/chosen': '-1.2816', 'rewards_train/rejected': '-9.1859', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.9049', 'logps_train/rejected': '-235.87', 'logps_train/chosen': '-59.09', 'loss/train': '0.066081', 'examples_per_second': '4.1032', 'grad_norm': '6.75', 'counters/examples': 22912, 'counters/updates': 1432}
skipping logging after 22928 examples to avoid logging too frequently
skipping logging after 22944 examples to avoid logging too frequently
skipping logging after 22960 examples to avoid logging too frequently
train stats after 22976 examples: {'rewards_train/chosen': '-1.2988', 'rewards_train/rejected': '-8.881', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.5827', 'logps_train/rejected': '-220.15', 'logps_train/chosen': '-58.424', 'loss/train': '0.049453', 'examples_per_second': '4.9355', 'grad_norm': '4.9375', 'counters/examples': 22976, 'counters/updates': 1436}
skipping logging after 22992 examples to avoid logging too frequently
skipping logging after 23008 examples to avoid logging too frequently
skipping logging after 23024 examples to avoid logging too frequently
train stats after 23040 examples: {'rewards_train/chosen': '-1.7956', 'rewards_train/rejected': '-8.7892', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.9961', 'logps_train/rejected': '-213.91', 'logps_train/chosen': '-55.981', 'loss/train': '0.10037', 'examples_per_second': '4.4408', 'grad_norm': '10.5', 'counters/examples': 23040, 'counters/updates': 1440}
skipping logging after 23056 examples to avoid logging too frequently
skipping logging after 23072 examples to avoid logging too frequently
skipping logging after 23088 examples to avoid logging too frequently
train stats after 23104 examples: {'rewards_train/chosen': '-1.8028', 'rewards_train/rejected': '-8.6911', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.8878', 'logps_train/rejected': '-198.16', 'logps_train/chosen': '-54.258', 'loss/train': '0.074813', 'examples_per_second': '6.3233', 'grad_norm': '7.0312', 'counters/examples': 23104, 'counters/updates': 1444}
skipping logging after 23120 examples to avoid logging too frequently
skipping logging after 23136 examples to avoid logging too frequently
skipping logging after 23152 examples to avoid logging too frequently
train stats after 23168 examples: {'rewards_train/chosen': '-1.5137', 'rewards_train/rejected': '-8.4441', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.9288', 'logps_train/rejected': '-196.63', 'logps_train/chosen': '-56.505', 'loss/train': '0.10987', 'examples_per_second': '5.6986', 'grad_norm': '9.375', 'counters/examples': 23168, 'counters/updates': 1448}
skipping logging after 23184 examples to avoid logging too frequently
skipping logging after 23200 examples to avoid logging too frequently
skipping logging after 23216 examples to avoid logging too frequently
train stats after 23232 examples: {'rewards_train/chosen': '-1.6374', 'rewards_train/rejected': '-10.458', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.8231', 'logps_train/rejected': '-262.24', 'logps_train/chosen': '-55.619', 'loss/train': '0.041198', 'examples_per_second': '4.2981', 'grad_norm': '5.1875', 'counters/examples': 23232, 'counters/updates': 1452}
skipping logging after 23248 examples to avoid logging too frequently
skipping logging after 23264 examples to avoid logging too frequently
skipping logging after 23280 examples to avoid logging too frequently
train stats after 23296 examples: {'rewards_train/chosen': '-1.6167', 'rewards_train/rejected': '-10.114', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.4996', 'logps_train/rejected': '-240.47', 'logps_train/chosen': '-56.932', 'loss/train': '0.078649', 'examples_per_second': '5.5673', 'grad_norm': '11.562', 'counters/examples': 23296, 'counters/updates': 1456}
skipping logging after 23312 examples to avoid logging too frequently
skipping logging after 23328 examples to avoid logging too frequently
skipping logging after 23344 examples to avoid logging too frequently
train stats after 23360 examples: {'rewards_train/chosen': '-1.8068', 'rewards_train/rejected': '-11.736', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '9.9298', 'logps_train/rejected': '-287.69', 'logps_train/chosen': '-70.845', 'loss/train': '0.12762', 'examples_per_second': '5.0621', 'grad_norm': '13.938', 'counters/examples': 23360, 'counters/updates': 1460}
skipping logging after 23376 examples to avoid logging too frequently
skipping logging after 23392 examples to avoid logging too frequently
skipping logging after 23408 examples to avoid logging too frequently
train stats after 23424 examples: {'rewards_train/chosen': '-1.3933', 'rewards_train/rejected': '-9.0815', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.6887', 'logps_train/rejected': '-236.48', 'logps_train/chosen': '-57.481', 'loss/train': '0.16846', 'examples_per_second': '3.9693', 'grad_norm': '13', 'counters/examples': 23424, 'counters/updates': 1464}
skipping logging after 23440 examples to avoid logging too frequently
skipping logging after 23456 examples to avoid logging too frequently
skipping logging after 23472 examples to avoid logging too frequently
train stats after 23488 examples: {'rewards_train/chosen': '-1.5776', 'rewards_train/rejected': '-7.5135', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '5.9374', 'logps_train/rejected': '-177.37', 'logps_train/chosen': '-60.436', 'loss/train': '0.11174', 'examples_per_second': '6.604', 'grad_norm': '15.875', 'counters/examples': 23488, 'counters/updates': 1468}
skipping logging after 23504 examples to avoid logging too frequently
skipping logging after 23520 examples to avoid logging too frequently
skipping logging after 23536 examples to avoid logging too frequently
train stats after 23552 examples: {'rewards_train/chosen': '-1.3893', 'rewards_train/rejected': '-9.0444', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.6561', 'logps_train/rejected': '-263.54', 'logps_train/chosen': '-54.42', 'loss/train': '0.11683', 'examples_per_second': '4.3475', 'grad_norm': '12.312', 'counters/examples': 23552, 'counters/updates': 1472}
skipping logging after 23568 examples to avoid logging too frequently
skipping logging after 23584 examples to avoid logging too frequently
skipping logging after 23600 examples to avoid logging too frequently
train stats after 23616 examples: {'rewards_train/chosen': '-1.1778', 'rewards_train/rejected': '-7.7634', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.5884', 'logps_train/rejected': '-196.71', 'logps_train/chosen': '-46.301', 'loss/train': '0.050153', 'examples_per_second': '5.9699', 'grad_norm': '4.8125', 'counters/examples': 23616, 'counters/updates': 1476}
skipping logging after 23632 examples to avoid logging too frequently
skipping logging after 23648 examples to avoid logging too frequently
skipping logging after 23664 examples to avoid logging too frequently
train stats after 23680 examples: {'rewards_train/chosen': '-1.008', 'rewards_train/rejected': '-7.9987', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.9932', 'logps_train/rejected': '-224.59', 'logps_train/chosen': '-46.072', 'loss/train': '0.1061', 'examples_per_second': '5.1323', 'grad_norm': '6.1875', 'counters/examples': 23680, 'counters/updates': 1480}
skipping logging after 23696 examples to avoid logging too frequently
skipping logging after 23712 examples to avoid logging too frequently
skipping logging after 23728 examples to avoid logging too frequently
train stats after 23744 examples: {'rewards_train/chosen': '-1.2789', 'rewards_train/rejected': '-7.9767', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.6994', 'logps_train/rejected': '-223.29', 'logps_train/chosen': '-56.25', 'loss/train': '0.076233', 'examples_per_second': '5.1536', 'grad_norm': '7.9062', 'counters/examples': 23744, 'counters/updates': 1484}
skipping logging after 23760 examples to avoid logging too frequently
skipping logging after 23776 examples to avoid logging too frequently
skipping logging after 23792 examples to avoid logging too frequently
train stats after 23808 examples: {'rewards_train/chosen': '-1.5266', 'rewards_train/rejected': '-10.42', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.8966', 'logps_train/rejected': '-260.48', 'logps_train/chosen': '-54.931', 'loss/train': '0.074093', 'examples_per_second': '4.4503', 'grad_norm': '6.9375', 'counters/examples': 23808, 'counters/updates': 1488}
skipping logging after 23824 examples to avoid logging too frequently
skipping logging after 23840 examples to avoid logging too frequently
skipping logging after 23856 examples to avoid logging too frequently
train stats after 23872 examples: {'rewards_train/chosen': '-1.3386', 'rewards_train/rejected': '-8.7103', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.3726', 'logps_train/rejected': '-209.54', 'logps_train/chosen': '-46.512', 'loss/train': '0.044278', 'examples_per_second': '4.5478', 'grad_norm': '7.4375', 'counters/examples': 23872, 'counters/updates': 1492}
skipping logging after 23888 examples to avoid logging too frequently
skipping logging after 23904 examples to avoid logging too frequently
skipping logging after 23920 examples to avoid logging too frequently
train stats after 23936 examples: {'rewards_train/chosen': '-1.1881', 'rewards_train/rejected': '-9.4578', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.2704', 'logps_train/rejected': '-239.93', 'logps_train/chosen': '-53.041', 'loss/train': '0.038487', 'examples_per_second': '5.4455', 'grad_norm': '5.875', 'counters/examples': 23936, 'counters/updates': 1496}
skipping logging after 23952 examples to avoid logging too frequently
skipping logging after 23968 examples to avoid logging too frequently
skipping logging after 23984 examples to avoid logging too frequently
train stats after 24000 examples: {'rewards_train/chosen': '-1.5391', 'rewards_train/rejected': '-9.0688', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.5278', 'logps_train/rejected': '-230.91', 'logps_train/chosen': '-54.03', 'loss/train': '0.060857', 'examples_per_second': '4.5023', 'grad_norm': '8.1875', 'counters/examples': 24000, 'counters/updates': 1500}
Running evaluation after 24000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<01:00,  1.94s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:00,  2.01s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:53,  1.84s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.85s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.52s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.49s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:22,  1.30s/it]Computing eval metrics:  50%|█████     | 16/32 [00:23<00:19,  1.24s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.33s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.34s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.27s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.29s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.26s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.30s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.48s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:39<00:05,  1.41s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.61s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.42s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.41s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 24000: {'rewards_eval/chosen': '-9.3381', 'rewards_eval/rejected': '-9.6803', 'rewards_eval/accuracies': '0.50586', 'rewards_eval/margins': '0.34171', 'logps_eval/rejected': '-244.47', 'logps_eval/chosen': '-238.31', 'loss/eval': '2.1747'}
skipping logging after 24016 examples to avoid logging too frequently
skipping logging after 24032 examples to avoid logging too frequently
skipping logging after 24048 examples to avoid logging too frequently
train stats after 24064 examples: {'rewards_train/chosen': '-1.5777', 'rewards_train/rejected': '-8.1665', 'rewards_train/accuracies': '1', 'rewards_train/margins': '6.5875', 'logps_train/rejected': '-198.41', 'logps_train/chosen': '-46.818', 'loss/train': '0.054339', 'examples_per_second': '5.8875', 'grad_norm': '7.5625', 'counters/examples': 24064, 'counters/updates': 1504}
skipping logging after 24080 examples to avoid logging too frequently
skipping logging after 24096 examples to avoid logging too frequently
skipping logging after 24112 examples to avoid logging too frequently
train stats after 24128 examples: {'rewards_train/chosen': '-1.9433', 'rewards_train/rejected': '-9.1287', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.1857', 'logps_train/rejected': '-230.86', 'logps_train/chosen': '-55.276', 'loss/train': '0.078443', 'examples_per_second': '5.0869', 'grad_norm': '10.125', 'counters/examples': 24128, 'counters/updates': 1508}
skipping logging after 24144 examples to avoid logging too frequently
skipping logging after 24160 examples to avoid logging too frequently
skipping logging after 24176 examples to avoid logging too frequently
train stats after 24192 examples: {'rewards_train/chosen': '-1.722', 'rewards_train/rejected': '-9.5232', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.7996', 'logps_train/rejected': '-230.29', 'logps_train/chosen': '-65.502', 'loss/train': '0.038622', 'examples_per_second': '4.9644', 'grad_norm': '6.625', 'counters/examples': 24192, 'counters/updates': 1512}
skipping logging after 24208 examples to avoid logging too frequently
skipping logging after 24224 examples to avoid logging too frequently
skipping logging after 24240 examples to avoid logging too frequently
train stats after 24256 examples: {'rewards_train/chosen': '-1.6415', 'rewards_train/rejected': '-9.6162', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.9771', 'logps_train/rejected': '-223.66', 'logps_train/chosen': '-49.877', 'loss/train': '0.037198', 'examples_per_second': '5.0461', 'grad_norm': '4.0312', 'counters/examples': 24256, 'counters/updates': 1516}
skipping logging after 24272 examples to avoid logging too frequently
skipping logging after 24288 examples to avoid logging too frequently
skipping logging after 24304 examples to avoid logging too frequently
train stats after 24320 examples: {'rewards_train/chosen': '-1.7754', 'rewards_train/rejected': '-8.3548', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.5769', 'logps_train/rejected': '-185.47', 'logps_train/chosen': '-50.551', 'loss/train': '0.11085', 'examples_per_second': '6.5767', 'grad_norm': '8.25', 'counters/examples': 24320, 'counters/updates': 1520}
skipping logging after 24336 examples to avoid logging too frequently
skipping logging after 24352 examples to avoid logging too frequently
skipping logging after 24368 examples to avoid logging too frequently
train stats after 24384 examples: {'rewards_train/chosen': '-2.1308', 'rewards_train/rejected': '-9.9598', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.8296', 'logps_train/rejected': '-229.86', 'logps_train/chosen': '-57.28', 'loss/train': '0.10058', 'examples_per_second': '5.9552', 'grad_norm': '9.125', 'counters/examples': 24384, 'counters/updates': 1524}
skipping logging after 24400 examples to avoid logging too frequently
skipping logging after 24416 examples to avoid logging too frequently
skipping logging after 24432 examples to avoid logging too frequently
train stats after 24448 examples: {'rewards_train/chosen': '-1.8151', 'rewards_train/rejected': '-10.13', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.3177', 'logps_train/rejected': '-243.16', 'logps_train/chosen': '-51.177', 'loss/train': '0.073433', 'examples_per_second': '4.3204', 'grad_norm': '8.8125', 'counters/examples': 24448, 'counters/updates': 1528}
skipping logging after 24464 examples to avoid logging too frequently
skipping logging after 24480 examples to avoid logging too frequently
skipping logging after 24496 examples to avoid logging too frequently
train stats after 24512 examples: {'rewards_train/chosen': '-1.852', 'rewards_train/rejected': '-10.265', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.4108', 'logps_train/rejected': '-240.96', 'logps_train/chosen': '-57.562', 'loss/train': '0.066936', 'examples_per_second': '5.4614', 'grad_norm': '9.6875', 'counters/examples': 24512, 'counters/updates': 1532}
skipping logging after 24528 examples to avoid logging too frequently
skipping logging after 24544 examples to avoid logging too frequently
skipping logging after 24560 examples to avoid logging too frequently
train stats after 24576 examples: {'rewards_train/chosen': '-1.793', 'rewards_train/rejected': '-9.5344', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.7439', 'logps_train/rejected': '-219.02', 'logps_train/chosen': '-58.551', 'loss/train': '0.066697', 'examples_per_second': '5.5828', 'grad_norm': '6.5', 'counters/examples': 24576, 'counters/updates': 1536}
skipping logging after 24592 examples to avoid logging too frequently
skipping logging after 24608 examples to avoid logging too frequently
skipping logging after 24624 examples to avoid logging too frequently
train stats after 24640 examples: {'rewards_train/chosen': '-1.4431', 'rewards_train/rejected': '-11.091', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.6467', 'logps_train/rejected': '-284.7', 'logps_train/chosen': '-63.694', 'loss/train': '0.048783', 'examples_per_second': '3.9479', 'grad_norm': '6.4688', 'counters/examples': 24640, 'counters/updates': 1540}
skipping logging after 24656 examples to avoid logging too frequently
skipping logging after 24672 examples to avoid logging too frequently
skipping logging after 24688 examples to avoid logging too frequently
train stats after 24704 examples: {'rewards_train/chosen': '-1.8457', 'rewards_train/rejected': '-10.614', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.7708', 'logps_train/rejected': '-266.75', 'logps_train/chosen': '-63.122', 'loss/train': '0.037038', 'examples_per_second': '5.2962', 'grad_norm': '4.4688', 'counters/examples': 24704, 'counters/updates': 1544}
skipping logging after 24720 examples to avoid logging too frequently
skipping logging after 24736 examples to avoid logging too frequently
skipping logging after 24752 examples to avoid logging too frequently
train stats after 24768 examples: {'rewards_train/chosen': '-2.1495', 'rewards_train/rejected': '-9.5776', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.4324', 'logps_train/rejected': '-208.22', 'logps_train/chosen': '-56.23', 'loss/train': '0.1043', 'examples_per_second': '4.788', 'grad_norm': '9.25', 'counters/examples': 24768, 'counters/updates': 1548}
skipping logging after 24784 examples to avoid logging too frequently
skipping logging after 24800 examples to avoid logging too frequently
skipping logging after 24816 examples to avoid logging too frequently
train stats after 24832 examples: {'rewards_train/chosen': '-2.3009', 'rewards_train/rejected': '-11.845', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.5464', 'logps_train/rejected': '-278.56', 'logps_train/chosen': '-71.536', 'loss/train': '0.087191', 'examples_per_second': '4.9254', 'grad_norm': '13.5', 'counters/examples': 24832, 'counters/updates': 1552}
skipping logging after 24848 examples to avoid logging too frequently
skipping logging after 24864 examples to avoid logging too frequently
skipping logging after 24880 examples to avoid logging too frequently
train stats after 24896 examples: {'rewards_train/chosen': '-1.5598', 'rewards_train/rejected': '-10.755', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.1945', 'logps_train/rejected': '-264.45', 'logps_train/chosen': '-59.215', 'loss/train': '0.085427', 'examples_per_second': '4.7189', 'grad_norm': '10.062', 'counters/examples': 24896, 'counters/updates': 1556}
skipping logging after 24912 examples to avoid logging too frequently
skipping logging after 24928 examples to avoid logging too frequently
skipping logging after 24944 examples to avoid logging too frequently
train stats after 24960 examples: {'rewards_train/chosen': '-1.6803', 'rewards_train/rejected': '-9.6098', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.9281', 'logps_train/rejected': '-226.93', 'logps_train/chosen': '-55.372', 'loss/train': '0.13026', 'examples_per_second': '5.3115', 'grad_norm': '13.438', 'counters/examples': 24960, 'counters/updates': 1560}
skipping logging after 24976 examples to avoid logging too frequently
skipping logging after 24992 examples to avoid logging too frequently
skipping logging after 25008 examples to avoid logging too frequently
train stats after 25024 examples: {'rewards_train/chosen': '-1.1303', 'rewards_train/rejected': '-9.7668', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.6365', 'logps_train/rejected': '-267.64', 'logps_train/chosen': '-62.406', 'loss/train': '0.1145', 'examples_per_second': '4.378', 'grad_norm': '9.5625', 'counters/examples': 25024, 'counters/updates': 1564}
skipping logging after 25040 examples to avoid logging too frequently
skipping logging after 25056 examples to avoid logging too frequently
skipping logging after 25072 examples to avoid logging too frequently
train stats after 25088 examples: {'rewards_train/chosen': '-1.3455', 'rewards_train/rejected': '-8.8567', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.5089', 'logps_train/rejected': '-240.57', 'logps_train/chosen': '-56.106', 'loss/train': '0.044256', 'examples_per_second': '5.3287', 'grad_norm': '7.0312', 'counters/examples': 25088, 'counters/updates': 1568}
skipping logging after 25104 examples to avoid logging too frequently
skipping logging after 25120 examples to avoid logging too frequently
skipping logging after 25136 examples to avoid logging too frequently
train stats after 25152 examples: {'rewards_train/chosen': '-1.3149', 'rewards_train/rejected': '-9.833', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.5155', 'logps_train/rejected': '-268.59', 'logps_train/chosen': '-53.477', 'loss/train': '0.049914', 'examples_per_second': '4.1053', 'grad_norm': '5.5938', 'counters/examples': 25152, 'counters/updates': 1572}
skipping logging after 25168 examples to avoid logging too frequently
skipping logging after 25184 examples to avoid logging too frequently
skipping logging after 25200 examples to avoid logging too frequently
train stats after 25216 examples: {'rewards_train/chosen': '-1.638', 'rewards_train/rejected': '-8.342', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.7028', 'logps_train/rejected': '-187.61', 'logps_train/chosen': '-60.425', 'loss/train': '0.0493', 'examples_per_second': '5.9193', 'grad_norm': '7.8125', 'counters/examples': 25216, 'counters/updates': 1576}
skipping logging after 25232 examples to avoid logging too frequently
skipping logging after 25248 examples to avoid logging too frequently
skipping logging after 25264 examples to avoid logging too frequently
train stats after 25280 examples: {'rewards_train/chosen': '-1.617', 'rewards_train/rejected': '-9.8802', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.2666', 'logps_train/rejected': '-247.91', 'logps_train/chosen': '-58.875', 'loss/train': '0.073341', 'examples_per_second': '4.877', 'grad_norm': '10.5', 'counters/examples': 25280, 'counters/updates': 1580}
skipping logging after 25296 examples to avoid logging too frequently
skipping logging after 25312 examples to avoid logging too frequently
skipping logging after 25328 examples to avoid logging too frequently
train stats after 25344 examples: {'rewards_train/chosen': '-1.9756', 'rewards_train/rejected': '-8.901', 'rewards_train/accuracies': '1', 'rewards_train/margins': '6.9243', 'logps_train/rejected': '-201.25', 'logps_train/chosen': '-55.323', 'loss/train': '0.14844', 'examples_per_second': '5.0154', 'grad_norm': '22.375', 'counters/examples': 25344, 'counters/updates': 1584}
skipping logging after 25360 examples to avoid logging too frequently
skipping logging after 25376 examples to avoid logging too frequently
skipping logging after 25392 examples to avoid logging too frequently
train stats after 25408 examples: {'rewards_train/chosen': '-1.6961', 'rewards_train/rejected': '-8.3032', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.6053', 'logps_train/rejected': '-213.18', 'logps_train/chosen': '-54.098', 'loss/train': '0.091493', 'examples_per_second': '5.3037', 'grad_norm': '7.8125', 'counters/examples': 25408, 'counters/updates': 1588}
skipping logging after 25424 examples to avoid logging too frequently
skipping logging after 25440 examples to avoid logging too frequently
skipping logging after 25456 examples to avoid logging too frequently
train stats after 25472 examples: {'rewards_train/chosen': '-2.1007', 'rewards_train/rejected': '-9.7004', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.5978', 'logps_train/rejected': '-223.64', 'logps_train/chosen': '-55.5', 'loss/train': '0.13562', 'examples_per_second': '5.0513', 'grad_norm': '18.125', 'counters/examples': 25472, 'counters/updates': 1592}
skipping logging after 25488 examples to avoid logging too frequently
skipping logging after 25504 examples to avoid logging too frequently
skipping logging after 25520 examples to avoid logging too frequently
train stats after 25536 examples: {'rewards_train/chosen': '-1.6459', 'rewards_train/rejected': '-7.7994', 'rewards_train/accuracies': '0.89062', 'rewards_train/margins': '6.1536', 'logps_train/rejected': '-195.34', 'logps_train/chosen': '-51.747', 'loss/train': '0.15084', 'examples_per_second': '5.6212', 'grad_norm': '10.75', 'counters/examples': 25536, 'counters/updates': 1596}
skipping logging after 25552 examples to avoid logging too frequently
skipping logging after 25568 examples to avoid logging too frequently
skipping logging after 25584 examples to avoid logging too frequently
train stats after 25600 examples: {'rewards_train/chosen': '-1.6424', 'rewards_train/rejected': '-9.2844', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.6453', 'logps_train/rejected': '-241.59', 'logps_train/chosen': '-61.071', 'loss/train': '0.051585', 'examples_per_second': '4.2378', 'grad_norm': '6.9375', 'counters/examples': 25600, 'counters/updates': 1600}
skipping logging after 25616 examples to avoid logging too frequently
skipping logging after 25632 examples to avoid logging too frequently
skipping logging after 25648 examples to avoid logging too frequently
train stats after 25664 examples: {'rewards_train/chosen': '-1.4925', 'rewards_train/rejected': '-9.645', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.155', 'logps_train/rejected': '-223.2', 'logps_train/chosen': '-61.168', 'loss/train': '0.016436', 'examples_per_second': '4.1945', 'grad_norm': '3.0938', 'counters/examples': 25664, 'counters/updates': 1604}
skipping logging after 25680 examples to avoid logging too frequently
skipping logging after 25696 examples to avoid logging too frequently
skipping logging after 25712 examples to avoid logging too frequently
train stats after 25728 examples: {'rewards_train/chosen': '-1.5861', 'rewards_train/rejected': '-9.9259', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.3405', 'logps_train/rejected': '-238.96', 'logps_train/chosen': '-61.913', 'loss/train': '0.054064', 'examples_per_second': '5.6327', 'grad_norm': '9.6875', 'counters/examples': 25728, 'counters/updates': 1608}
skipping logging after 25744 examples to avoid logging too frequently
skipping logging after 25760 examples to avoid logging too frequently
skipping logging after 25776 examples to avoid logging too frequently
train stats after 25792 examples: {'rewards_train/chosen': '-1.6963', 'rewards_train/rejected': '-9.7324', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.0354', 'logps_train/rejected': '-262.04', 'logps_train/chosen': '-66.744', 'loss/train': '0.051608', 'examples_per_second': '4.2104', 'grad_norm': '6.4688', 'counters/examples': 25792, 'counters/updates': 1612}
skipping logging after 25808 examples to avoid logging too frequently
skipping logging after 25824 examples to avoid logging too frequently
skipping logging after 25840 examples to avoid logging too frequently
train stats after 25856 examples: {'rewards_train/chosen': '-1.786', 'rewards_train/rejected': '-9.4279', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.6401', 'logps_train/rejected': '-216.36', 'logps_train/chosen': '-57.459', 'loss/train': '0.19229', 'examples_per_second': '4.9484', 'grad_norm': '19.75', 'counters/examples': 25856, 'counters/updates': 1616}
skipping logging after 25872 examples to avoid logging too frequently
skipping logging after 25888 examples to avoid logging too frequently
skipping logging after 25904 examples to avoid logging too frequently
train stats after 25920 examples: {'rewards_train/chosen': '-1.8247', 'rewards_train/rejected': '-10.71', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.8846', 'logps_train/rejected': '-271.21', 'logps_train/chosen': '-68.953', 'loss/train': '0.19177', 'examples_per_second': '4.5253', 'grad_norm': '22', 'counters/examples': 25920, 'counters/updates': 1620}
skipping logging after 25936 examples to avoid logging too frequently
skipping logging after 25952 examples to avoid logging too frequently
skipping logging after 25968 examples to avoid logging too frequently
train stats after 25984 examples: {'rewards_train/chosen': '-1.5434', 'rewards_train/rejected': '-9.2404', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.6967', 'logps_train/rejected': '-228.26', 'logps_train/chosen': '-59.614', 'loss/train': '0.048402', 'examples_per_second': '5.9588', 'grad_norm': '4.75', 'counters/examples': 25984, 'counters/updates': 1624}
skipping logging after 26000 examples to avoid logging too frequently
skipping logging after 26016 examples to avoid logging too frequently
skipping logging after 26032 examples to avoid logging too frequently
train stats after 26048 examples: {'rewards_train/chosen': '-1.7641', 'rewards_train/rejected': '-8.8496', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.0856', 'logps_train/rejected': '-202.78', 'logps_train/chosen': '-56.891', 'loss/train': '0.074712', 'examples_per_second': '4.74', 'grad_norm': '10.25', 'counters/examples': 26048, 'counters/updates': 1628}
skipping logging after 26064 examples to avoid logging too frequently
skipping logging after 26080 examples to avoid logging too frequently
skipping logging after 26096 examples to avoid logging too frequently
train stats after 26112 examples: {'rewards_train/chosen': '-2.0686', 'rewards_train/rejected': '-10.261', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1914', 'logps_train/rejected': '-239.67', 'logps_train/chosen': '-56.601', 'loss/train': '0.05791', 'examples_per_second': '5.0266', 'grad_norm': '9.0625', 'counters/examples': 26112, 'counters/updates': 1632}
skipping logging after 26128 examples to avoid logging too frequently
skipping logging after 26144 examples to avoid logging too frequently
skipping logging after 26160 examples to avoid logging too frequently
train stats after 26176 examples: {'rewards_train/chosen': '-1.9185', 'rewards_train/rejected': '-10.784', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.8673', 'logps_train/rejected': '-259.79', 'logps_train/chosen': '-60.262', 'loss/train': '0.060496', 'examples_per_second': '5.9989', 'grad_norm': '6.875', 'counters/examples': 26176, 'counters/updates': 1636}
skipping logging after 26192 examples to avoid logging too frequently
skipping logging after 26208 examples to avoid logging too frequently
skipping logging after 26224 examples to avoid logging too frequently
train stats after 26240 examples: {'rewards_train/chosen': '-2.0946', 'rewards_train/rejected': '-11.426', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.3345', 'logps_train/rejected': '-286.28', 'logps_train/chosen': '-69.85', 'loss/train': '0.063037', 'examples_per_second': '5.2999', 'grad_norm': '10.75', 'counters/examples': 26240, 'counters/updates': 1640}
skipping logging after 26256 examples to avoid logging too frequently
skipping logging after 26272 examples to avoid logging too frequently
skipping logging after 26288 examples to avoid logging too frequently
train stats after 26304 examples: {'rewards_train/chosen': '-2.6241', 'rewards_train/rejected': '-10.308', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.6821', 'logps_train/rejected': '-241', 'logps_train/chosen': '-68.037', 'loss/train': '0.059905', 'examples_per_second': '5.4535', 'grad_norm': '8.0625', 'counters/examples': 26304, 'counters/updates': 1644}
skipping logging after 26320 examples to avoid logging too frequently
skipping logging after 26336 examples to avoid logging too frequently
skipping logging after 26352 examples to avoid logging too frequently
train stats after 26368 examples: {'rewards_train/chosen': '-2.3226', 'rewards_train/rejected': '-10.409', 'rewards_train/accuracies': '0.89062', 'rewards_train/margins': '8.088', 'logps_train/rejected': '-209.09', 'logps_train/chosen': '-63.138', 'loss/train': '0.13993', 'examples_per_second': '4.4252', 'grad_norm': '15', 'counters/examples': 26368, 'counters/updates': 1648}
skipping logging after 26384 examples to avoid logging too frequently
skipping logging after 26400 examples to avoid logging too frequently
skipping logging after 26416 examples to avoid logging too frequently
train stats after 26432 examples: {'rewards_train/chosen': '-2.2502', 'rewards_train/rejected': '-9.8684', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.6173', 'logps_train/rejected': '-222.53', 'logps_train/chosen': '-62.28', 'loss/train': '0.064802', 'examples_per_second': '5.6516', 'grad_norm': '7.9375', 'counters/examples': 26432, 'counters/updates': 1652}
skipping logging after 26448 examples to avoid logging too frequently
skipping logging after 26464 examples to avoid logging too frequently
skipping logging after 26480 examples to avoid logging too frequently
train stats after 26496 examples: {'rewards_train/chosen': '-2.2299', 'rewards_train/rejected': '-11.655', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.4221', 'logps_train/rejected': '-259.71', 'logps_train/chosen': '-59.697', 'loss/train': '0.040823', 'examples_per_second': '5.5369', 'grad_norm': '10.75', 'counters/examples': 26496, 'counters/updates': 1656}
skipping logging after 26512 examples to avoid logging too frequently
skipping logging after 26528 examples to avoid logging too frequently
skipping logging after 26544 examples to avoid logging too frequently
train stats after 26560 examples: {'rewards_train/chosen': '-2.1315', 'rewards_train/rejected': '-9.8232', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.6895', 'logps_train/rejected': '-206.58', 'logps_train/chosen': '-65.265', 'loss/train': '0.09267', 'examples_per_second': '5.0542', 'grad_norm': '6.8125', 'counters/examples': 26560, 'counters/updates': 1660}
skipping logging after 26576 examples to avoid logging too frequently
skipping logging after 26592 examples to avoid logging too frequently
skipping logging after 26608 examples to avoid logging too frequently
train stats after 26624 examples: {'rewards_train/chosen': '-2.1105', 'rewards_train/rejected': '-10.117', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.0073', 'logps_train/rejected': '-230.18', 'logps_train/chosen': '-53.885', 'loss/train': '0.027288', 'examples_per_second': '6.845', 'grad_norm': '4.5938', 'counters/examples': 26624, 'counters/updates': 1664}
skipping logging after 26640 examples to avoid logging too frequently
skipping logging after 26656 examples to avoid logging too frequently
skipping logging after 26672 examples to avoid logging too frequently
train stats after 26688 examples: {'rewards_train/chosen': '-2.2777', 'rewards_train/rejected': '-10.88', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.6006', 'logps_train/rejected': '-248.95', 'logps_train/chosen': '-67.268', 'loss/train': '0.010963', 'examples_per_second': '5.0978', 'grad_norm': '2.3125', 'counters/examples': 26688, 'counters/updates': 1668}
skipping logging after 26704 examples to avoid logging too frequently
skipping logging after 26720 examples to avoid logging too frequently
skipping logging after 26736 examples to avoid logging too frequently
train stats after 26752 examples: {'rewards_train/chosen': '-2.2666', 'rewards_train/rejected': '-10.388', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1196', 'logps_train/rejected': '-254.44', 'logps_train/chosen': '-57.307', 'loss/train': '0.05198', 'examples_per_second': '4.6521', 'grad_norm': '12.875', 'counters/examples': 26752, 'counters/updates': 1672}
skipping logging after 26768 examples to avoid logging too frequently
skipping logging after 26784 examples to avoid logging too frequently
skipping logging after 26800 examples to avoid logging too frequently
train stats after 26816 examples: {'rewards_train/chosen': '-2.3013', 'rewards_train/rejected': '-9.2803', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '6.9786', 'logps_train/rejected': '-216.83', 'logps_train/chosen': '-59.299', 'loss/train': '0.15109', 'examples_per_second': '4.508', 'grad_norm': '17.375', 'counters/examples': 26816, 'counters/updates': 1676}
skipping logging after 26832 examples to avoid logging too frequently
skipping logging after 26848 examples to avoid logging too frequently
skipping logging after 26864 examples to avoid logging too frequently
train stats after 26880 examples: {'rewards_train/chosen': '-2.0752', 'rewards_train/rejected': '-10.022', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.9479', 'logps_train/rejected': '-225.54', 'logps_train/chosen': '-57.314', 'loss/train': '0.084977', 'examples_per_second': '4.3922', 'grad_norm': '8.8125', 'counters/examples': 26880, 'counters/updates': 1680}
skipping logging after 26896 examples to avoid logging too frequently
skipping logging after 26912 examples to avoid logging too frequently
skipping logging after 26928 examples to avoid logging too frequently
train stats after 26944 examples: {'rewards_train/chosen': '-2.0412', 'rewards_train/rejected': '-10.784', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.743', 'logps_train/rejected': '-259.81', 'logps_train/chosen': '-68.336', 'loss/train': '0.05632', 'examples_per_second': '4.7183', 'grad_norm': '9.875', 'counters/examples': 26944, 'counters/updates': 1684}
skipping logging after 26960 examples to avoid logging too frequently
skipping logging after 26976 examples to avoid logging too frequently
skipping logging after 26992 examples to avoid logging too frequently
train stats after 27008 examples: {'rewards_train/chosen': '-2.209', 'rewards_train/rejected': '-11.214', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.0052', 'logps_train/rejected': '-257.63', 'logps_train/chosen': '-69.04', 'loss/train': '0.053459', 'examples_per_second': '4.5582', 'grad_norm': '4.9062', 'counters/examples': 27008, 'counters/updates': 1688}
skipping logging after 27024 examples to avoid logging too frequently
skipping logging after 27040 examples to avoid logging too frequently
skipping logging after 27056 examples to avoid logging too frequently
train stats after 27072 examples: {'rewards_train/chosen': '-2.0624', 'rewards_train/rejected': '-10.727', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.6628', 'logps_train/rejected': '-256.75', 'logps_train/chosen': '-62.976', 'loss/train': '0.086578', 'examples_per_second': '4.4591', 'grad_norm': '12.312', 'counters/examples': 27072, 'counters/updates': 1692}
skipping logging after 27088 examples to avoid logging too frequently
skipping logging after 27104 examples to avoid logging too frequently
skipping logging after 27120 examples to avoid logging too frequently
train stats after 27136 examples: {'rewards_train/chosen': '-2.442', 'rewards_train/rejected': '-9.2627', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.8186', 'logps_train/rejected': '-222.48', 'logps_train/chosen': '-62.939', 'loss/train': '0.17552', 'examples_per_second': '5.1965', 'grad_norm': '25.25', 'counters/examples': 27136, 'counters/updates': 1696}
skipping logging after 27152 examples to avoid logging too frequently
skipping logging after 27168 examples to avoid logging too frequently
skipping logging after 27184 examples to avoid logging too frequently
train stats after 27200 examples: {'rewards_train/chosen': '-2.0309', 'rewards_train/rejected': '-9.0257', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.9956', 'logps_train/rejected': '-241.44', 'logps_train/chosen': '-68.861', 'loss/train': '0.079244', 'examples_per_second': '4.3789', 'grad_norm': '10.062', 'counters/examples': 27200, 'counters/updates': 1700}
skipping logging after 27216 examples to avoid logging too frequently
skipping logging after 27232 examples to avoid logging too frequently
skipping logging after 27248 examples to avoid logging too frequently
train stats after 27264 examples: {'rewards_train/chosen': '-2.0487', 'rewards_train/rejected': '-10.473', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.4231', 'logps_train/rejected': '-254.05', 'logps_train/chosen': '-65.027', 'loss/train': '0.0537', 'examples_per_second': '5.4302', 'grad_norm': '8.125', 'counters/examples': 27264, 'counters/updates': 1704}
skipping logging after 27280 examples to avoid logging too frequently
skipping logging after 27296 examples to avoid logging too frequently
skipping logging after 27312 examples to avoid logging too frequently
train stats after 27328 examples: {'rewards_train/chosen': '-2.1248', 'rewards_train/rejected': '-11.537', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.4088', 'logps_train/rejected': '-287.48', 'logps_train/chosen': '-63.137', 'loss/train': '0.068024', 'examples_per_second': '4.304', 'grad_norm': '6.625', 'counters/examples': 27328, 'counters/updates': 1708}
skipping logging after 27344 examples to avoid logging too frequently
skipping logging after 27360 examples to avoid logging too frequently
skipping logging after 27376 examples to avoid logging too frequently
train stats after 27392 examples: {'rewards_train/chosen': '-2.3513', 'rewards_train/rejected': '-10.785', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.4343', 'logps_train/rejected': '-234.6', 'logps_train/chosen': '-66.674', 'loss/train': '0.098934', 'examples_per_second': '5.3762', 'grad_norm': '11.562', 'counters/examples': 27392, 'counters/updates': 1712}
skipping logging after 27408 examples to avoid logging too frequently
skipping logging after 27424 examples to avoid logging too frequently
skipping logging after 27440 examples to avoid logging too frequently
train stats after 27456 examples: {'rewards_train/chosen': '-2.3757', 'rewards_train/rejected': '-10.133', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.7595', 'logps_train/rejected': '-248.53', 'logps_train/chosen': '-69.667', 'loss/train': '0.13361', 'examples_per_second': '5.4625', 'grad_norm': '15.625', 'counters/examples': 27456, 'counters/updates': 1716}
skipping logging after 27472 examples to avoid logging too frequently
skipping logging after 27488 examples to avoid logging too frequently
skipping logging after 27504 examples to avoid logging too frequently
train stats after 27520 examples: {'rewards_train/chosen': '-2.4579', 'rewards_train/rejected': '-10.018', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.5603', 'logps_train/rejected': '-230.68', 'logps_train/chosen': '-70.262', 'loss/train': '0.035535', 'examples_per_second': '5.088', 'grad_norm': '8.5625', 'counters/examples': 27520, 'counters/updates': 1720}
skipping logging after 27536 examples to avoid logging too frequently
skipping logging after 27552 examples to avoid logging too frequently
skipping logging after 27568 examples to avoid logging too frequently
train stats after 27584 examples: {'rewards_train/chosen': '-2.1632', 'rewards_train/rejected': '-10.364', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.2031', 'logps_train/rejected': '-228.3', 'logps_train/chosen': '-54.467', 'loss/train': '0.12997', 'examples_per_second': '5.2371', 'grad_norm': '12.938', 'counters/examples': 27584, 'counters/updates': 1724}
skipping logging after 27600 examples to avoid logging too frequently
skipping logging after 27616 examples to avoid logging too frequently
skipping logging after 27632 examples to avoid logging too frequently
train stats after 27648 examples: {'rewards_train/chosen': '-1.7409', 'rewards_train/rejected': '-10.512', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.7712', 'logps_train/rejected': '-245.55', 'logps_train/chosen': '-54.963', 'loss/train': '0.025261', 'examples_per_second': '4.4282', 'grad_norm': '5.0625', 'counters/examples': 27648, 'counters/updates': 1728}
skipping logging after 27664 examples to avoid logging too frequently
skipping logging after 27680 examples to avoid logging too frequently
skipping logging after 27696 examples to avoid logging too frequently
train stats after 27712 examples: {'rewards_train/chosen': '-2.2601', 'rewards_train/rejected': '-10.618', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.3613', 'logps_train/rejected': '-232.26', 'logps_train/chosen': '-57.467', 'loss/train': '0.11867', 'examples_per_second': '5.64', 'grad_norm': '12.5', 'counters/examples': 27712, 'counters/updates': 1732}
skipping logging after 27728 examples to avoid logging too frequently
skipping logging after 27744 examples to avoid logging too frequently
skipping logging after 27760 examples to avoid logging too frequently
train stats after 27776 examples: {'rewards_train/chosen': '-1.9568', 'rewards_train/rejected': '-9.8545', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.897', 'logps_train/rejected': '-232.32', 'logps_train/chosen': '-55.822', 'loss/train': '0.048705', 'examples_per_second': '5.1535', 'grad_norm': '7.3438', 'counters/examples': 27776, 'counters/updates': 1736}
skipping logging after 27792 examples to avoid logging too frequently
skipping logging after 27808 examples to avoid logging too frequently
skipping logging after 27824 examples to avoid logging too frequently
train stats after 27840 examples: {'rewards_train/chosen': '-2.1954', 'rewards_train/rejected': '-9.558', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.3634', 'logps_train/rejected': '-220.49', 'logps_train/chosen': '-66.748', 'loss/train': '0.13216', 'examples_per_second': '5.42', 'grad_norm': '17.75', 'counters/examples': 27840, 'counters/updates': 1740}
skipping logging after 27856 examples to avoid logging too frequently
skipping logging after 27872 examples to avoid logging too frequently
skipping logging after 27888 examples to avoid logging too frequently
train stats after 27904 examples: {'rewards_train/chosen': '-2.0175', 'rewards_train/rejected': '-9.5161', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.4983', 'logps_train/rejected': '-248.15', 'logps_train/chosen': '-61.475', 'loss/train': '0.084091', 'examples_per_second': '4.5828', 'grad_norm': '10.938', 'counters/examples': 27904, 'counters/updates': 1744}
skipping logging after 27920 examples to avoid logging too frequently
skipping logging after 27936 examples to avoid logging too frequently
skipping logging after 27952 examples to avoid logging too frequently
train stats after 27968 examples: {'rewards_train/chosen': '-2.0412', 'rewards_train/rejected': '-10.16', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.1194', 'logps_train/rejected': '-262.34', 'logps_train/chosen': '-53.886', 'loss/train': '0.081266', 'examples_per_second': '4.7601', 'grad_norm': '10.125', 'counters/examples': 27968, 'counters/updates': 1748}
skipping logging after 27984 examples to avoid logging too frequently
skipping logging after 28000 examples to avoid logging too frequently
Running evaluation after 28000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:08,  2.20s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:03,  2.12s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:55,  1.90s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.89s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.55s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.65s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.49s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.49s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:22,  1.30s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.24s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.33s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.34s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.27s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.30s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.26s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:37<00:07,  1.30s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.48s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.41s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.61s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.42s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.42s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.44s/it]
eval after 28000: {'rewards_eval/chosen': '-8.935', 'rewards_eval/rejected': '-9.2898', 'rewards_eval/accuracies': '0.5293', 'rewards_eval/margins': '0.35466', 'logps_eval/rejected': '-240.56', 'logps_eval/chosen': '-234.26', 'loss/eval': '1.9257'}
skipping logging after 28016 examples to avoid logging too frequently
train stats after 28032 examples: {'rewards_train/chosen': '-2.0244', 'rewards_train/rejected': '-9.7698', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.7438', 'logps_train/rejected': '-245.13', 'logps_train/chosen': '-59.041', 'loss/train': '0.074544', 'examples_per_second': '5.1127', 'grad_norm': '6.25', 'counters/examples': 28032, 'counters/updates': 1752}
skipping logging after 28048 examples to avoid logging too frequently
skipping logging after 28064 examples to avoid logging too frequently
skipping logging after 28080 examples to avoid logging too frequently
train stats after 28096 examples: {'rewards_train/chosen': '-2.1728', 'rewards_train/rejected': '-10.121', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.9512', 'logps_train/rejected': '-244.15', 'logps_train/chosen': '-63.845', 'loss/train': '0.043105', 'examples_per_second': '4.6704', 'grad_norm': '7.375', 'counters/examples': 28096, 'counters/updates': 1756}
skipping logging after 28112 examples to avoid logging too frequently
skipping logging after 28128 examples to avoid logging too frequently
skipping logging after 28144 examples to avoid logging too frequently
train stats after 28160 examples: {'rewards_train/chosen': '-2.2988', 'rewards_train/rejected': '-9.9497', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.6493', 'logps_train/rejected': '-241.7', 'logps_train/chosen': '-61.046', 'loss/train': '0.062303', 'examples_per_second': '5.5416', 'grad_norm': '10.812', 'counters/examples': 28160, 'counters/updates': 1760}
skipping logging after 28176 examples to avoid logging too frequently
skipping logging after 28192 examples to avoid logging too frequently
skipping logging after 28208 examples to avoid logging too frequently
train stats after 28224 examples: {'rewards_train/chosen': '-2.8206', 'rewards_train/rejected': '-10.066', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.2473', 'logps_train/rejected': '-208.58', 'logps_train/chosen': '-59.296', 'loss/train': '0.096839', 'examples_per_second': '5.3483', 'grad_norm': '12.062', 'counters/examples': 28224, 'counters/updates': 1764}
skipping logging after 28240 examples to avoid logging too frequently
skipping logging after 28256 examples to avoid logging too frequently
skipping logging after 28272 examples to avoid logging too frequently
train stats after 28288 examples: {'rewards_train/chosen': '-2.4949', 'rewards_train/rejected': '-11.09', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.5958', 'logps_train/rejected': '-254.86', 'logps_train/chosen': '-67.444', 'loss/train': '0.088977', 'examples_per_second': '4.6849', 'grad_norm': '8.0625', 'counters/examples': 28288, 'counters/updates': 1768}
skipping logging after 28304 examples to avoid logging too frequently
skipping logging after 28320 examples to avoid logging too frequently
skipping logging after 28336 examples to avoid logging too frequently
train stats after 28352 examples: {'rewards_train/chosen': '-2.4284', 'rewards_train/rejected': '-11.873', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.4429', 'logps_train/rejected': '-277.67', 'logps_train/chosen': '-67.182', 'loss/train': '0.049849', 'examples_per_second': '4.6476', 'grad_norm': '4.25', 'counters/examples': 28352, 'counters/updates': 1772}
skipping logging after 28368 examples to avoid logging too frequently
skipping logging after 28384 examples to avoid logging too frequently
skipping logging after 28400 examples to avoid logging too frequently
train stats after 28416 examples: {'rewards_train/chosen': '-2.6806', 'rewards_train/rejected': '-11.305', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.6222', 'logps_train/rejected': '-241.59', 'logps_train/chosen': '-68.821', 'loss/train': '0.088273', 'examples_per_second': '6.4431', 'grad_norm': '15.875', 'counters/examples': 28416, 'counters/updates': 1776}
skipping logging after 28432 examples to avoid logging too frequently
skipping logging after 28448 examples to avoid logging too frequently
skipping logging after 28464 examples to avoid logging too frequently
train stats after 28480 examples: {'rewards_train/chosen': '-2.4149', 'rewards_train/rejected': '-9.8542', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.4397', 'logps_train/rejected': '-221.07', 'logps_train/chosen': '-64.701', 'loss/train': '0.1269', 'examples_per_second': '5.032', 'grad_norm': '18', 'counters/examples': 28480, 'counters/updates': 1780}
skipping logging after 28496 examples to avoid logging too frequently
skipping logging after 28512 examples to avoid logging too frequently
skipping logging after 28528 examples to avoid logging too frequently
train stats after 28544 examples: {'rewards_train/chosen': '-2.2961', 'rewards_train/rejected': '-11.089', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.7944', 'logps_train/rejected': '-286.11', 'logps_train/chosen': '-62.418', 'loss/train': '0.049973', 'examples_per_second': '4.7553', 'grad_norm': '9.875', 'counters/examples': 28544, 'counters/updates': 1784}
skipping logging after 28560 examples to avoid logging too frequently
skipping logging after 28576 examples to avoid logging too frequently
skipping logging after 28592 examples to avoid logging too frequently
train stats after 28608 examples: {'rewards_train/chosen': '-2.1019', 'rewards_train/rejected': '-10.677', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.5729', 'logps_train/rejected': '-254.57', 'logps_train/chosen': '-70.184', 'loss/train': '0.11623', 'examples_per_second': '4.8712', 'grad_norm': '14.938', 'counters/examples': 28608, 'counters/updates': 1788}
skipping logging after 28624 examples to avoid logging too frequently
skipping logging after 28640 examples to avoid logging too frequently
skipping logging after 28656 examples to avoid logging too frequently
train stats after 28672 examples: {'rewards_train/chosen': '-1.8338', 'rewards_train/rejected': '-8.4521', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.618', 'logps_train/rejected': '-243.8', 'logps_train/chosen': '-55.489', 'loss/train': '0.1085', 'examples_per_second': '4.6915', 'grad_norm': '9', 'counters/examples': 28672, 'counters/updates': 1792}
skipping logging after 28688 examples to avoid logging too frequently
skipping logging after 28704 examples to avoid logging too frequently
skipping logging after 28720 examples to avoid logging too frequently
train stats after 28736 examples: {'rewards_train/chosen': '-1.6094', 'rewards_train/rejected': '-8.0591', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.4485', 'logps_train/rejected': '-195.72', 'logps_train/chosen': '-58.382', 'loss/train': '0.0828', 'examples_per_second': '5.3361', 'grad_norm': '5.5312', 'counters/examples': 28736, 'counters/updates': 1796}
skipping logging after 28752 examples to avoid logging too frequently
skipping logging after 28768 examples to avoid logging too frequently
skipping logging after 28784 examples to avoid logging too frequently
train stats after 28800 examples: {'rewards_train/chosen': '-1.866', 'rewards_train/rejected': '-8.5593', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.6914', 'logps_train/rejected': '-225.38', 'logps_train/chosen': '-56.199', 'loss/train': '0.10057', 'examples_per_second': '5.3052', 'grad_norm': '6.5312', 'counters/examples': 28800, 'counters/updates': 1800}
skipping logging after 28816 examples to avoid logging too frequently
skipping logging after 28832 examples to avoid logging too frequently
skipping logging after 28848 examples to avoid logging too frequently
train stats after 28864 examples: {'rewards_train/chosen': '-1.9655', 'rewards_train/rejected': '-10.213', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.248', 'logps_train/rejected': '-272.82', 'logps_train/chosen': '-60.34', 'loss/train': '0.046595', 'examples_per_second': '4.3868', 'grad_norm': '7.1875', 'counters/examples': 28864, 'counters/updates': 1804}
skipping logging after 28880 examples to avoid logging too frequently
skipping logging after 28896 examples to avoid logging too frequently
skipping logging after 28912 examples to avoid logging too frequently
train stats after 28928 examples: {'rewards_train/chosen': '-2.0757', 'rewards_train/rejected': '-8.5915', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.5158', 'logps_train/rejected': '-216.32', 'logps_train/chosen': '-70.306', 'loss/train': '0.13185', 'examples_per_second': '5.6622', 'grad_norm': '11.5', 'counters/examples': 28928, 'counters/updates': 1808}
skipping logging after 28944 examples to avoid logging too frequently
skipping logging after 28960 examples to avoid logging too frequently
skipping logging after 28976 examples to avoid logging too frequently
train stats after 28992 examples: {'rewards_train/chosen': '-1.9666', 'rewards_train/rejected': '-10.383', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.4143', 'logps_train/rejected': '-262.88', 'logps_train/chosen': '-60.415', 'loss/train': '0.034015', 'examples_per_second': '5.2919', 'grad_norm': '8.875', 'counters/examples': 28992, 'counters/updates': 1812}
skipping logging after 29008 examples to avoid logging too frequently
skipping logging after 29024 examples to avoid logging too frequently
skipping logging after 29040 examples to avoid logging too frequently
train stats after 29056 examples: {'rewards_train/chosen': '-2.0428', 'rewards_train/rejected': '-9.8636', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.8225', 'logps_train/rejected': '-232.47', 'logps_train/chosen': '-53.893', 'loss/train': '0.066315', 'examples_per_second': '4.9291', 'grad_norm': '4.5938', 'counters/examples': 29056, 'counters/updates': 1816}
skipping logging after 29072 examples to avoid logging too frequently
skipping logging after 29088 examples to avoid logging too frequently
skipping logging after 29104 examples to avoid logging too frequently
train stats after 29120 examples: {'rewards_train/chosen': '-2.1169', 'rewards_train/rejected': '-9.5002', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.3824', 'logps_train/rejected': '-222.48', 'logps_train/chosen': '-61.634', 'loss/train': '0.074623', 'examples_per_second': '4.5515', 'grad_norm': '7.1562', 'counters/examples': 29120, 'counters/updates': 1820}
skipping logging after 29136 examples to avoid logging too frequently
skipping logging after 29152 examples to avoid logging too frequently
skipping logging after 29168 examples to avoid logging too frequently
train stats after 29184 examples: {'rewards_train/chosen': '-2.0132', 'rewards_train/rejected': '-11.034', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '9.0193', 'logps_train/rejected': '-274.74', 'logps_train/chosen': '-63.689', 'loss/train': '0.042127', 'examples_per_second': '4.5474', 'grad_norm': '6.5312', 'counters/examples': 29184, 'counters/updates': 1824}
skipping logging after 29200 examples to avoid logging too frequently
skipping logging after 29216 examples to avoid logging too frequently
skipping logging after 29232 examples to avoid logging too frequently
train stats after 29248 examples: {'rewards_train/chosen': '-2.1931', 'rewards_train/rejected': '-11.098', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.9058', 'logps_train/rejected': '-267.38', 'logps_train/chosen': '-69.914', 'loss/train': '0.12077', 'examples_per_second': '5.5581', 'grad_norm': '18.875', 'counters/examples': 29248, 'counters/updates': 1828}
skipping logging after 29264 examples to avoid logging too frequently
skipping logging after 29280 examples to avoid logging too frequently
skipping logging after 29296 examples to avoid logging too frequently
train stats after 29312 examples: {'rewards_train/chosen': '-2.0891', 'rewards_train/rejected': '-10.047', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.9563', 'logps_train/rejected': '-240.31', 'logps_train/chosen': '-60.146', 'loss/train': '0.088715', 'examples_per_second': '4.2465', 'grad_norm': '10.688', 'counters/examples': 29312, 'counters/updates': 1832}
skipping logging after 29328 examples to avoid logging too frequently
skipping logging after 29344 examples to avoid logging too frequently
skipping logging after 29360 examples to avoid logging too frequently
train stats after 29376 examples: {'rewards_train/chosen': '-2.1629', 'rewards_train/rejected': '-10.648', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.4832', 'logps_train/rejected': '-265.78', 'logps_train/chosen': '-62.26', 'loss/train': '0.066283', 'examples_per_second': '4.1554', 'grad_norm': '12.125', 'counters/examples': 29376, 'counters/updates': 1836}
skipping logging after 29392 examples to avoid logging too frequently
skipping logging after 29408 examples to avoid logging too frequently
skipping logging after 29424 examples to avoid logging too frequently
train stats after 29440 examples: {'rewards_train/chosen': '-2.3696', 'rewards_train/rejected': '-10.879', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.5109', 'logps_train/rejected': '-292.09', 'logps_train/chosen': '-77.087', 'loss/train': '0.040537', 'examples_per_second': '4.4689', 'grad_norm': '3.8281', 'counters/examples': 29440, 'counters/updates': 1840}
skipping logging after 29456 examples to avoid logging too frequently
skipping logging after 29472 examples to avoid logging too frequently
skipping logging after 29488 examples to avoid logging too frequently
train stats after 29504 examples: {'rewards_train/chosen': '-2.0962', 'rewards_train/rejected': '-8.6545', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.5568', 'logps_train/rejected': '-193.68', 'logps_train/chosen': '-65.941', 'loss/train': '0.1757', 'examples_per_second': '4.1393', 'grad_norm': '20.125', 'counters/examples': 29504, 'counters/updates': 1844}
skipping logging after 29520 examples to avoid logging too frequently
skipping logging after 29536 examples to avoid logging too frequently
skipping logging after 29552 examples to avoid logging too frequently
train stats after 29568 examples: {'rewards_train/chosen': '-2.016', 'rewards_train/rejected': '-8.2329', 'rewards_train/accuracies': '0.89062', 'rewards_train/margins': '6.2168', 'logps_train/rejected': '-203.13', 'logps_train/chosen': '-68.001', 'loss/train': '0.22998', 'examples_per_second': '5.2428', 'grad_norm': '18.375', 'counters/examples': 29568, 'counters/updates': 1848}
skipping logging after 29584 examples to avoid logging too frequently
skipping logging after 29600 examples to avoid logging too frequently
skipping logging after 29616 examples to avoid logging too frequently
train stats after 29632 examples: {'rewards_train/chosen': '-1.9879', 'rewards_train/rejected': '-7.5695', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '5.5807', 'logps_train/rejected': '-206.2', 'logps_train/chosen': '-57.62', 'loss/train': '0.13957', 'examples_per_second': '5.4877', 'grad_norm': '13.875', 'counters/examples': 29632, 'counters/updates': 1852}
skipping logging after 29648 examples to avoid logging too frequently
skipping logging after 29664 examples to avoid logging too frequently
skipping logging after 29680 examples to avoid logging too frequently
train stats after 29696 examples: {'rewards_train/chosen': '-1.496', 'rewards_train/rejected': '-8.5365', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.0383', 'logps_train/rejected': '-259.95', 'logps_train/chosen': '-58.769', 'loss/train': '0.04746', 'examples_per_second': '4.9372', 'grad_norm': '4.7188', 'counters/examples': 29696, 'counters/updates': 1856}
skipping logging after 29712 examples to avoid logging too frequently
skipping logging after 29728 examples to avoid logging too frequently
skipping logging after 29744 examples to avoid logging too frequently
train stats after 29760 examples: {'rewards_train/chosen': '-1.5772', 'rewards_train/rejected': '-8.8479', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.2678', 'logps_train/rejected': '-244.22', 'logps_train/chosen': '-57.783', 'loss/train': '0.053931', 'examples_per_second': '5.4727', 'grad_norm': '7.125', 'counters/examples': 29760, 'counters/updates': 1860}
skipping logging after 29776 examples to avoid logging too frequently
skipping logging after 29792 examples to avoid logging too frequently
skipping logging after 29808 examples to avoid logging too frequently
train stats after 29824 examples: {'rewards_train/chosen': '-1.9801', 'rewards_train/rejected': '-9.1382', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.1602', 'logps_train/rejected': '-263.57', 'logps_train/chosen': '-62.65', 'loss/train': '0.076911', 'examples_per_second': '4.6039', 'grad_norm': '12.938', 'counters/examples': 29824, 'counters/updates': 1864}
skipping logging after 29840 examples to avoid logging too frequently
skipping logging after 29856 examples to avoid logging too frequently
skipping logging after 29872 examples to avoid logging too frequently
train stats after 29888 examples: {'rewards_train/chosen': '-1.8978', 'rewards_train/rejected': '-8.2458', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.3486', 'logps_train/rejected': '-219.64', 'logps_train/chosen': '-74.811', 'loss/train': '0.054843', 'examples_per_second': '5.3938', 'grad_norm': '4.375', 'counters/examples': 29888, 'counters/updates': 1868}
skipping logging after 29904 examples to avoid logging too frequently
skipping logging after 29920 examples to avoid logging too frequently
skipping logging after 29936 examples to avoid logging too frequently
train stats after 29952 examples: {'rewards_train/chosen': '-1.9177', 'rewards_train/rejected': '-8.1792', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.2628', 'logps_train/rejected': '-210.8', 'logps_train/chosen': '-56.479', 'loss/train': '0.13439', 'examples_per_second': '5.381', 'grad_norm': '22.125', 'counters/examples': 29952, 'counters/updates': 1872}
skipping logging after 29968 examples to avoid logging too frequently
skipping logging after 29984 examples to avoid logging too frequently
skipping logging after 30000 examples to avoid logging too frequently
train stats after 30016 examples: {'rewards_train/chosen': '-1.4373', 'rewards_train/rejected': '-8.2783', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.8428', 'logps_train/rejected': '-223.73', 'logps_train/chosen': '-57.111', 'loss/train': '0.030014', 'examples_per_second': '4.9543', 'grad_norm': '5.0312', 'counters/examples': 30016, 'counters/updates': 1876}
skipping logging after 30032 examples to avoid logging too frequently
skipping logging after 30048 examples to avoid logging too frequently
skipping logging after 30064 examples to avoid logging too frequently
train stats after 30080 examples: {'rewards_train/chosen': '-2.201', 'rewards_train/rejected': '-8.2487', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.0461', 'logps_train/rejected': '-199.2', 'logps_train/chosen': '-60.216', 'loss/train': '0.14084', 'examples_per_second': '4.9531', 'grad_norm': '19', 'counters/examples': 30080, 'counters/updates': 1880}
skipping logging after 30096 examples to avoid logging too frequently
skipping logging after 30112 examples to avoid logging too frequently
skipping logging after 30128 examples to avoid logging too frequently
train stats after 30144 examples: {'rewards_train/chosen': '-1.5724', 'rewards_train/rejected': '-8.6528', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.0812', 'logps_train/rejected': '-266.93', 'logps_train/chosen': '-63.734', 'loss/train': '0.033866', 'examples_per_second': '4.5894', 'grad_norm': '3.875', 'counters/examples': 30144, 'counters/updates': 1884}
skipping logging after 30160 examples to avoid logging too frequently
skipping logging after 30176 examples to avoid logging too frequently
skipping logging after 30192 examples to avoid logging too frequently
train stats after 30208 examples: {'rewards_train/chosen': '-1.9021', 'rewards_train/rejected': '-7.8513', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '5.9515', 'logps_train/rejected': '-206.68', 'logps_train/chosen': '-61.442', 'loss/train': '0.083974', 'examples_per_second': '5.368', 'grad_norm': '11.5', 'counters/examples': 30208, 'counters/updates': 1888}
skipping logging after 30224 examples to avoid logging too frequently
skipping logging after 30240 examples to avoid logging too frequently
skipping logging after 30256 examples to avoid logging too frequently
train stats after 30272 examples: {'rewards_train/chosen': '-1.5449', 'rewards_train/rejected': '-7.7294', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.1856', 'logps_train/rejected': '-208.82', 'logps_train/chosen': '-59.614', 'loss/train': '0.047003', 'examples_per_second': '6.2102', 'grad_norm': '5.5625', 'counters/examples': 30272, 'counters/updates': 1892}
skipping logging after 30288 examples to avoid logging too frequently
skipping logging after 30304 examples to avoid logging too frequently
skipping logging after 30320 examples to avoid logging too frequently
train stats after 30336 examples: {'rewards_train/chosen': '-1.5707', 'rewards_train/rejected': '-8.3456', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.775', 'logps_train/rejected': '-190.2', 'logps_train/chosen': '-52.892', 'loss/train': '0.056698', 'examples_per_second': '5.5875', 'grad_norm': '5.5625', 'counters/examples': 30336, 'counters/updates': 1896}
skipping logging after 30352 examples to avoid logging too frequently
skipping logging after 30368 examples to avoid logging too frequently
skipping logging after 30384 examples to avoid logging too frequently
train stats after 30400 examples: {'rewards_train/chosen': '-2.0368', 'rewards_train/rejected': '-10.04', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.0016', 'logps_train/rejected': '-244.13', 'logps_train/chosen': '-63.15', 'loss/train': '0.037966', 'examples_per_second': '4.7094', 'grad_norm': '5.2812', 'counters/examples': 30400, 'counters/updates': 1900}
skipping logging after 30416 examples to avoid logging too frequently
skipping logging after 30432 examples to avoid logging too frequently
skipping logging after 30448 examples to avoid logging too frequently
train stats after 30464 examples: {'rewards_train/chosen': '-2.4431', 'rewards_train/rejected': '-9.0747', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.6309', 'logps_train/rejected': '-195.94', 'logps_train/chosen': '-69.519', 'loss/train': '0.11732', 'examples_per_second': '6.3538', 'grad_norm': '13.625', 'counters/examples': 30464, 'counters/updates': 1904}
skipping logging after 30480 examples to avoid logging too frequently
skipping logging after 30496 examples to avoid logging too frequently
skipping logging after 30512 examples to avoid logging too frequently
train stats after 30528 examples: {'rewards_train/chosen': '-2.3198', 'rewards_train/rejected': '-9.1699', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.8505', 'logps_train/rejected': '-224.46', 'logps_train/chosen': '-58.946', 'loss/train': '0.077156', 'examples_per_second': '5.2079', 'grad_norm': '11.188', 'counters/examples': 30528, 'counters/updates': 1908}
skipping logging after 30544 examples to avoid logging too frequently
skipping logging after 30560 examples to avoid logging too frequently
skipping logging after 30576 examples to avoid logging too frequently
train stats after 30592 examples: {'rewards_train/chosen': '-2.2956', 'rewards_train/rejected': '-10.478', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.1744', 'logps_train/rejected': '-229.69', 'logps_train/chosen': '-58.211', 'loss/train': '0.09837', 'examples_per_second': '5.1181', 'grad_norm': '11.125', 'counters/examples': 30592, 'counters/updates': 1912}
skipping logging after 30608 examples to avoid logging too frequently
skipping logging after 30624 examples to avoid logging too frequently
skipping logging after 30640 examples to avoid logging too frequently
train stats after 30656 examples: {'rewards_train/chosen': '-2.5757', 'rewards_train/rejected': '-9.895', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.3218', 'logps_train/rejected': '-224.86', 'logps_train/chosen': '-62.884', 'loss/train': '0.089475', 'examples_per_second': '4.4249', 'grad_norm': '11.375', 'counters/examples': 30656, 'counters/updates': 1916}
skipping logging after 30672 examples to avoid logging too frequently
skipping logging after 30688 examples to avoid logging too frequently
skipping logging after 30704 examples to avoid logging too frequently
train stats after 30720 examples: {'rewards_train/chosen': '-2.5635', 'rewards_train/rejected': '-10.562', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.9995', 'logps_train/rejected': '-251.4', 'logps_train/chosen': '-72.686', 'loss/train': '0.046066', 'examples_per_second': '5.6687', 'grad_norm': '8.0625', 'counters/examples': 30720, 'counters/updates': 1920}
skipping logging after 30736 examples to avoid logging too frequently
skipping logging after 30752 examples to avoid logging too frequently
skipping logging after 30768 examples to avoid logging too frequently
train stats after 30784 examples: {'rewards_train/chosen': '-2.3739', 'rewards_train/rejected': '-10.479', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.104', 'logps_train/rejected': '-246.87', 'logps_train/chosen': '-57.431', 'loss/train': '0.06951', 'examples_per_second': '5.0564', 'grad_norm': '11.75', 'counters/examples': 30784, 'counters/updates': 1924}
skipping logging after 30800 examples to avoid logging too frequently
skipping logging after 30816 examples to avoid logging too frequently
skipping logging after 30832 examples to avoid logging too frequently
train stats after 30848 examples: {'rewards_train/chosen': '-1.9314', 'rewards_train/rejected': '-9.2285', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.2986', 'logps_train/rejected': '-221.86', 'logps_train/chosen': '-61.209', 'loss/train': '0.040317', 'examples_per_second': '5.6778', 'grad_norm': '7.125', 'counters/examples': 30848, 'counters/updates': 1928}
skipping logging after 30864 examples to avoid logging too frequently
skipping logging after 30880 examples to avoid logging too frequently
skipping logging after 30896 examples to avoid logging too frequently
train stats after 30912 examples: {'rewards_train/chosen': '-2.0226', 'rewards_train/rejected': '-9.7561', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.7341', 'logps_train/rejected': '-221.89', 'logps_train/chosen': '-52.493', 'loss/train': '0.040871', 'examples_per_second': '5.8938', 'grad_norm': '8.5', 'counters/examples': 30912, 'counters/updates': 1932}
skipping logging after 30928 examples to avoid logging too frequently
skipping logging after 30944 examples to avoid logging too frequently
skipping logging after 30960 examples to avoid logging too frequently
train stats after 30976 examples: {'rewards_train/chosen': '-1.7968', 'rewards_train/rejected': '-9.0447', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.2452', 'logps_train/rejected': '-215.93', 'logps_train/chosen': '-57.73', 'loss/train': '0.069362', 'examples_per_second': '5.5462', 'grad_norm': '6.875', 'counters/examples': 30976, 'counters/updates': 1936}
skipping logging after 30992 examples to avoid logging too frequently
skipping logging after 31008 examples to avoid logging too frequently
skipping logging after 31024 examples to avoid logging too frequently
train stats after 31040 examples: {'rewards_train/chosen': '-1.7708', 'rewards_train/rejected': '-10.498', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.7288', 'logps_train/rejected': '-267.88', 'logps_train/chosen': '-66.303', 'loss/train': '0.072117', 'examples_per_second': '5.1952', 'grad_norm': '8.375', 'counters/examples': 31040, 'counters/updates': 1940}
skipping logging after 31056 examples to avoid logging too frequently
skipping logging after 31072 examples to avoid logging too frequently
skipping logging after 31088 examples to avoid logging too frequently
train stats after 31104 examples: {'rewards_train/chosen': '-2.214', 'rewards_train/rejected': '-9.095', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.876', 'logps_train/rejected': '-221.95', 'logps_train/chosen': '-56.134', 'loss/train': '0.054172', 'examples_per_second': '5.9239', 'grad_norm': '10.188', 'counters/examples': 31104, 'counters/updates': 1944}
skipping logging after 31120 examples to avoid logging too frequently
skipping logging after 31136 examples to avoid logging too frequently
skipping logging after 31152 examples to avoid logging too frequently
train stats after 31168 examples: {'rewards_train/chosen': '-2.0116', 'rewards_train/rejected': '-9.1661', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.1527', 'logps_train/rejected': '-231.12', 'logps_train/chosen': '-60.293', 'loss/train': '0.14583', 'examples_per_second': '4.9465', 'grad_norm': '10.875', 'counters/examples': 31168, 'counters/updates': 1948}
skipping logging after 31184 examples to avoid logging too frequently
skipping logging after 31200 examples to avoid logging too frequently
skipping logging after 31216 examples to avoid logging too frequently
train stats after 31232 examples: {'rewards_train/chosen': '-2.0905', 'rewards_train/rejected': '-8.3253', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.233', 'logps_train/rejected': '-204.14', 'logps_train/chosen': '-57.953', 'loss/train': '0.098146', 'examples_per_second': '5.0739', 'grad_norm': '9.5', 'counters/examples': 31232, 'counters/updates': 1952}
skipping logging after 31248 examples to avoid logging too frequently
skipping logging after 31264 examples to avoid logging too frequently
skipping logging after 31280 examples to avoid logging too frequently
train stats after 31296 examples: {'rewards_train/chosen': '-2.0444', 'rewards_train/rejected': '-8.9886', 'rewards_train/accuracies': '0.89062', 'rewards_train/margins': '6.9402', 'logps_train/rejected': '-216.55', 'logps_train/chosen': '-55.871', 'loss/train': '0.13757', 'examples_per_second': '6.1198', 'grad_norm': '10.375', 'counters/examples': 31296, 'counters/updates': 1956}
skipping logging after 31312 examples to avoid logging too frequently
skipping logging after 31328 examples to avoid logging too frequently
skipping logging after 31344 examples to avoid logging too frequently
train stats after 31360 examples: {'rewards_train/chosen': '-1.9423', 'rewards_train/rejected': '-9.7423', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.7988', 'logps_train/rejected': '-223.56', 'logps_train/chosen': '-54.805', 'loss/train': '0.12185', 'examples_per_second': '6.047', 'grad_norm': '7.375', 'counters/examples': 31360, 'counters/updates': 1960}
skipping logging after 31376 examples to avoid logging too frequently
skipping logging after 31392 examples to avoid logging too frequently
skipping logging after 31408 examples to avoid logging too frequently
train stats after 31424 examples: {'rewards_train/chosen': '-2.2023', 'rewards_train/rejected': '-9.8024', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.6029', 'logps_train/rejected': '-229.84', 'logps_train/chosen': '-63.565', 'loss/train': '0.090635', 'examples_per_second': '5.2413', 'grad_norm': '9', 'counters/examples': 31424, 'counters/updates': 1964}
skipping logging after 31440 examples to avoid logging too frequently
skipping logging after 31456 examples to avoid logging too frequently
skipping logging after 31472 examples to avoid logging too frequently
train stats after 31488 examples: {'rewards_train/chosen': '-1.9791', 'rewards_train/rejected': '-11.009', 'rewards_train/accuracies': '1', 'rewards_train/margins': '9.0295', 'logps_train/rejected': '-316.87', 'logps_train/chosen': '-56.813', 'loss/train': '0.036382', 'examples_per_second': '3.6577', 'grad_norm': '7.375', 'counters/examples': 31488, 'counters/updates': 1968}
skipping logging after 31504 examples to avoid logging too frequently
skipping logging after 31520 examples to avoid logging too frequently
skipping logging after 31536 examples to avoid logging too frequently
train stats after 31552 examples: {'rewards_train/chosen': '-1.8572', 'rewards_train/rejected': '-10.704', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.8427', 'logps_train/rejected': '-227.46', 'logps_train/chosen': '-51.913', 'loss/train': '0.033376', 'examples_per_second': '5.4465', 'grad_norm': '4.8438', 'counters/examples': 31552, 'counters/updates': 1972}
skipping logging after 31568 examples to avoid logging too frequently
skipping logging after 31584 examples to avoid logging too frequently
skipping logging after 31600 examples to avoid logging too frequently
train stats after 31616 examples: {'rewards_train/chosen': '-1.8943', 'rewards_train/rejected': '-10.642', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.7507', 'logps_train/rejected': '-234.32', 'logps_train/chosen': '-56.323', 'loss/train': '0.047531', 'examples_per_second': '4.8728', 'grad_norm': '8.6875', 'counters/examples': 31616, 'counters/updates': 1976}
skipping logging after 31632 examples to avoid logging too frequently
skipping logging after 31648 examples to avoid logging too frequently
skipping logging after 31664 examples to avoid logging too frequently
train stats after 31680 examples: {'rewards_train/chosen': '-2.1008', 'rewards_train/rejected': '-9.5365', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.4377', 'logps_train/rejected': '-239.19', 'logps_train/chosen': '-54.429', 'loss/train': '0.083527', 'examples_per_second': '5.544', 'grad_norm': '8.6875', 'counters/examples': 31680, 'counters/updates': 1980}
skipping logging after 31696 examples to avoid logging too frequently
skipping logging after 31712 examples to avoid logging too frequently
skipping logging after 31728 examples to avoid logging too frequently
train stats after 31744 examples: {'rewards_train/chosen': '-2.2919', 'rewards_train/rejected': '-11.182', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.8887', 'logps_train/rejected': '-265.28', 'logps_train/chosen': '-61.126', 'loss/train': '0.102', 'examples_per_second': '4.8066', 'grad_norm': '14', 'counters/examples': 31744, 'counters/updates': 1984}
skipping logging after 31760 examples to avoid logging too frequently
skipping logging after 31776 examples to avoid logging too frequently
skipping logging after 31792 examples to avoid logging too frequently
train stats after 31808 examples: {'rewards_train/chosen': '-2.4728', 'rewards_train/rejected': '-10.446', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.9729', 'logps_train/rejected': '-232.12', 'logps_train/chosen': '-67.449', 'loss/train': '0.10146', 'examples_per_second': '5.5851', 'grad_norm': '13.688', 'counters/examples': 31808, 'counters/updates': 1988}
skipping logging after 31824 examples to avoid logging too frequently
skipping logging after 31840 examples to avoid logging too frequently
skipping logging after 31856 examples to avoid logging too frequently
train stats after 31872 examples: {'rewards_train/chosen': '-2.4055', 'rewards_train/rejected': '-9.9471', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.5397', 'logps_train/rejected': '-226.86', 'logps_train/chosen': '-61.892', 'loss/train': '0.13004', 'examples_per_second': '4.7465', 'grad_norm': '11.062', 'counters/examples': 31872, 'counters/updates': 1992}
skipping logging after 31888 examples to avoid logging too frequently
skipping logging after 31904 examples to avoid logging too frequently
skipping logging after 31920 examples to avoid logging too frequently
train stats after 31936 examples: {'rewards_train/chosen': '-2.4406', 'rewards_train/rejected': '-10.561', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.1184', 'logps_train/rejected': '-234.66', 'logps_train/chosen': '-64.863', 'loss/train': '0.04015', 'examples_per_second': '5.2156', 'grad_norm': '9.375', 'counters/examples': 31936, 'counters/updates': 1996}
skipping logging after 31952 examples to avoid logging too frequently
skipping logging after 31968 examples to avoid logging too frequently
skipping logging after 31984 examples to avoid logging too frequently
train stats after 32000 examples: {'rewards_train/chosen': '-2.5992', 'rewards_train/rejected': '-9.5671', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '6.9679', 'logps_train/rejected': '-215.35', 'logps_train/chosen': '-66.671', 'loss/train': '0.10319', 'examples_per_second': '5.6079', 'grad_norm': '12.812', 'counters/examples': 32000, 'counters/updates': 2000}
Running evaluation after 32000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<01:00,  1.96s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:00,  2.03s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:53,  1.85s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:52,  1.86s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.52s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.50s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:22,  1.30s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.25s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:20,  1.33s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.34s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.27s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.30s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.26s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:36<00:07,  1.30s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:38<00:07,  1.48s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.42s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.62s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.42s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.42s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:45<00:00,  1.43s/it]
eval after 32000: {'rewards_eval/chosen': '-11.212', 'rewards_eval/rejected': '-11.637', 'rewards_eval/accuracies': '0.51562', 'rewards_eval/margins': '0.42506', 'logps_eval/rejected': '-264.04', 'logps_eval/chosen': '-257.04', 'loss/eval': '2.407'}
skipping logging after 32016 examples to avoid logging too frequently
skipping logging after 32032 examples to avoid logging too frequently
skipping logging after 32048 examples to avoid logging too frequently
train stats after 32064 examples: {'rewards_train/chosen': '-2.519', 'rewards_train/rejected': '-12.21', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.6896', 'logps_train/rejected': '-309.35', 'logps_train/chosen': '-72.165', 'loss/train': '0.055188', 'examples_per_second': '4.701', 'grad_norm': '10.188', 'counters/examples': 32064, 'counters/updates': 2004}
skipping logging after 32080 examples to avoid logging too frequently
skipping logging after 32096 examples to avoid logging too frequently
skipping logging after 32112 examples to avoid logging too frequently
train stats after 32128 examples: {'rewards_train/chosen': '-2.8059', 'rewards_train/rejected': '-10.605', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.802', 'logps_train/rejected': '-238.34', 'logps_train/chosen': '-71.135', 'loss/train': '0.060504', 'examples_per_second': '4.1699', 'grad_norm': '8.1875', 'counters/examples': 32128, 'counters/updates': 2008}
skipping logging after 32144 examples to avoid logging too frequently
skipping logging after 32160 examples to avoid logging too frequently
skipping logging after 32176 examples to avoid logging too frequently
train stats after 32192 examples: {'rewards_train/chosen': '-2.3768', 'rewards_train/rejected': '-10.863', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.4839', 'logps_train/rejected': '-240.99', 'logps_train/chosen': '-64.23', 'loss/train': '0.12147', 'examples_per_second': '4.9356', 'grad_norm': '13.812', 'counters/examples': 32192, 'counters/updates': 2012}
skipping logging after 32208 examples to avoid logging too frequently
skipping logging after 32224 examples to avoid logging too frequently
skipping logging after 32240 examples to avoid logging too frequently
train stats after 32256 examples: {'rewards_train/chosen': '-2.3612', 'rewards_train/rejected': '-10.694', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.3317', 'logps_train/rejected': '-281.34', 'logps_train/chosen': '-72.189', 'loss/train': '0.049907', 'examples_per_second': '4.7046', 'grad_norm': '9', 'counters/examples': 32256, 'counters/updates': 2016}
skipping logging after 32272 examples to avoid logging too frequently
skipping logging after 32288 examples to avoid logging too frequently
skipping logging after 32304 examples to avoid logging too frequently
train stats after 32320 examples: {'rewards_train/chosen': '-2.5328', 'rewards_train/rejected': '-10.094', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.5638', 'logps_train/rejected': '-224.14', 'logps_train/chosen': '-69.849', 'loss/train': '0.089029', 'examples_per_second': '5.3505', 'grad_norm': '17.875', 'counters/examples': 32320, 'counters/updates': 2020}
skipping logging after 32336 examples to avoid logging too frequently
skipping logging after 32352 examples to avoid logging too frequently
skipping logging after 32368 examples to avoid logging too frequently
train stats after 32384 examples: {'rewards_train/chosen': '-2.1188', 'rewards_train/rejected': '-10.146', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.0255', 'logps_train/rejected': '-231.5', 'logps_train/chosen': '-61.244', 'loss/train': '0.083791', 'examples_per_second': '4.7333', 'grad_norm': '11.312', 'counters/examples': 32384, 'counters/updates': 2024}
skipping logging after 32400 examples to avoid logging too frequently
skipping logging after 32416 examples to avoid logging too frequently
skipping logging after 32432 examples to avoid logging too frequently
train stats after 32448 examples: {'rewards_train/chosen': '-2.7209', 'rewards_train/rejected': '-11.939', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.2161', 'logps_train/rejected': '-264.7', 'logps_train/chosen': '-60.602', 'loss/train': '0.068539', 'examples_per_second': '5.034', 'grad_norm': '12.062', 'counters/examples': 32448, 'counters/updates': 2028}
skipping logging after 32464 examples to avoid logging too frequently
skipping logging after 32480 examples to avoid logging too frequently
skipping logging after 32496 examples to avoid logging too frequently
train stats after 32512 examples: {'rewards_train/chosen': '-2.2167', 'rewards_train/rejected': '-9.8655', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.6506', 'logps_train/rejected': '-208.69', 'logps_train/chosen': '-58.25', 'loss/train': '0.060664', 'examples_per_second': '5.7137', 'grad_norm': '7.1875', 'counters/examples': 32512, 'counters/updates': 2032}
skipping logging after 32528 examples to avoid logging too frequently
skipping logging after 32544 examples to avoid logging too frequently
skipping logging after 32560 examples to avoid logging too frequently
train stats after 32576 examples: {'rewards_train/chosen': '-1.8567', 'rewards_train/rejected': '-10.576', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.7174', 'logps_train/rejected': '-255.11', 'logps_train/chosen': '-56.138', 'loss/train': '0.027379', 'examples_per_second': '4.6805', 'grad_norm': '3.7031', 'counters/examples': 32576, 'counters/updates': 2036}
skipping logging after 32592 examples to avoid logging too frequently
skipping logging after 32608 examples to avoid logging too frequently
skipping logging after 32624 examples to avoid logging too frequently
train stats after 32640 examples: {'rewards_train/chosen': '-1.9817', 'rewards_train/rejected': '-10.184', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.2043', 'logps_train/rejected': '-243.52', 'logps_train/chosen': '-58.425', 'loss/train': '0.068548', 'examples_per_second': '5.742', 'grad_norm': '5.5625', 'counters/examples': 32640, 'counters/updates': 2040}
skipping logging after 32656 examples to avoid logging too frequently
skipping logging after 32672 examples to avoid logging too frequently
skipping logging after 32688 examples to avoid logging too frequently
train stats after 32704 examples: {'rewards_train/chosen': '-2.4581', 'rewards_train/rejected': '-9.7848', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.3275', 'logps_train/rejected': '-234.95', 'logps_train/chosen': '-76.598', 'loss/train': '0.22517', 'examples_per_second': '4.7773', 'grad_norm': '19.75', 'counters/examples': 32704, 'counters/updates': 2044}
skipping logging after 32720 examples to avoid logging too frequently
skipping logging after 32736 examples to avoid logging too frequently
skipping logging after 32752 examples to avoid logging too frequently
train stats after 32768 examples: {'rewards_train/chosen': '-2.1546', 'rewards_train/rejected': '-9.3613', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.2067', 'logps_train/rejected': '-215.09', 'logps_train/chosen': '-57.337', 'loss/train': '0.056413', 'examples_per_second': '5.4776', 'grad_norm': '6.6875', 'counters/examples': 32768, 'counters/updates': 2048}
skipping logging after 32784 examples to avoid logging too frequently
skipping logging after 32800 examples to avoid logging too frequently
skipping logging after 32816 examples to avoid logging too frequently
train stats after 32832 examples: {'rewards_train/chosen': '-1.8739', 'rewards_train/rejected': '-11.19', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.3154', 'logps_train/rejected': '-279.56', 'logps_train/chosen': '-57.939', 'loss/train': '0.069638', 'examples_per_second': '5.2222', 'grad_norm': '9.125', 'counters/examples': 32832, 'counters/updates': 2052}
skipping logging after 32848 examples to avoid logging too frequently
skipping logging after 32864 examples to avoid logging too frequently
skipping logging after 32880 examples to avoid logging too frequently
train stats after 32896 examples: {'rewards_train/chosen': '-2.2165', 'rewards_train/rejected': '-11.703', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.4885', 'logps_train/rejected': '-265.02', 'logps_train/chosen': '-60.324', 'loss/train': '0.079931', 'examples_per_second': '6.0146', 'grad_norm': '15', 'counters/examples': 32896, 'counters/updates': 2056}
skipping logging after 32912 examples to avoid logging too frequently
skipping logging after 32928 examples to avoid logging too frequently
skipping logging after 32944 examples to avoid logging too frequently
train stats after 32960 examples: {'rewards_train/chosen': '-2.158', 'rewards_train/rejected': '-10.138', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.9784', 'logps_train/rejected': '-267', 'logps_train/chosen': '-67.201', 'loss/train': '0.089072', 'examples_per_second': '4.3595', 'grad_norm': '11.625', 'counters/examples': 32960, 'counters/updates': 2060}
skipping logging after 32976 examples to avoid logging too frequently
skipping logging after 32992 examples to avoid logging too frequently
skipping logging after 33008 examples to avoid logging too frequently
train stats after 33024 examples: {'rewards_train/chosen': '-2.2901', 'rewards_train/rejected': '-10.544', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.2568', 'logps_train/rejected': '-238.92', 'logps_train/chosen': '-66.902', 'loss/train': '0.15149', 'examples_per_second': '4.979', 'grad_norm': '18.5', 'counters/examples': 33024, 'counters/updates': 2064}
skipping logging after 33040 examples to avoid logging too frequently
skipping logging after 33056 examples to avoid logging too frequently
skipping logging after 33072 examples to avoid logging too frequently
train stats after 33088 examples: {'rewards_train/chosen': '-2.5058', 'rewards_train/rejected': '-10.766', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.2656', 'logps_train/rejected': '-254.9', 'logps_train/chosen': '-70.998', 'loss/train': '0.037593', 'examples_per_second': '5.4883', 'grad_norm': '5.6875', 'counters/examples': 33088, 'counters/updates': 2068}
skipping logging after 33104 examples to avoid logging too frequently
skipping logging after 33120 examples to avoid logging too frequently
skipping logging after 33136 examples to avoid logging too frequently
train stats after 33152 examples: {'rewards_train/chosen': '-2.1543', 'rewards_train/rejected': '-9.8167', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.6602', 'logps_train/rejected': '-221', 'logps_train/chosen': '-66.126', 'loss/train': '0.11321', 'examples_per_second': '5.5955', 'grad_norm': '8.8125', 'counters/examples': 33152, 'counters/updates': 2072}
skipping logging after 33168 examples to avoid logging too frequently
skipping logging after 33184 examples to avoid logging too frequently
skipping logging after 33200 examples to avoid logging too frequently
train stats after 33216 examples: {'rewards_train/chosen': '-2.2654', 'rewards_train/rejected': '-9.9531', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.6881', 'logps_train/rejected': '-225.44', 'logps_train/chosen': '-62.546', 'loss/train': '0.059278', 'examples_per_second': '4.9549', 'grad_norm': '11.562', 'counters/examples': 33216, 'counters/updates': 2076}
skipping logging after 33232 examples to avoid logging too frequently
skipping logging after 33248 examples to avoid logging too frequently
skipping logging after 33264 examples to avoid logging too frequently
train stats after 33280 examples: {'rewards_train/chosen': '-2.2818', 'rewards_train/rejected': '-10.822', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.5394', 'logps_train/rejected': '-268.62', 'logps_train/chosen': '-57.594', 'loss/train': '0.061866', 'examples_per_second': '4.3659', 'grad_norm': '9.625', 'counters/examples': 33280, 'counters/updates': 2080}
skipping logging after 33296 examples to avoid logging too frequently
skipping logging after 33312 examples to avoid logging too frequently
skipping logging after 33328 examples to avoid logging too frequently
train stats after 33344 examples: {'rewards_train/chosen': '-2.0979', 'rewards_train/rejected': '-10.3', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.2002', 'logps_train/rejected': '-247.29', 'logps_train/chosen': '-60.967', 'loss/train': '0.039372', 'examples_per_second': '4.6785', 'grad_norm': '4.5625', 'counters/examples': 33344, 'counters/updates': 2084}
skipping logging after 33360 examples to avoid logging too frequently
skipping logging after 33376 examples to avoid logging too frequently
skipping logging after 33392 examples to avoid logging too frequently
train stats after 33408 examples: {'rewards_train/chosen': '-2.3905', 'rewards_train/rejected': '-9.7229', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.3341', 'logps_train/rejected': '-234.39', 'logps_train/chosen': '-66.331', 'loss/train': '0.042371', 'examples_per_second': '5.1826', 'grad_norm': '6.4375', 'counters/examples': 33408, 'counters/updates': 2088}
skipping logging after 33424 examples to avoid logging too frequently
skipping logging after 33440 examples to avoid logging too frequently
skipping logging after 33456 examples to avoid logging too frequently
train stats after 33472 examples: {'rewards_train/chosen': '-2.0325', 'rewards_train/rejected': '-10.142', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1094', 'logps_train/rejected': '-244.54', 'logps_train/chosen': '-65.078', 'loss/train': '0.081382', 'examples_per_second': '5.2511', 'grad_norm': '8.125', 'counters/examples': 33472, 'counters/updates': 2092}
skipping logging after 33488 examples to avoid logging too frequently
skipping logging after 33504 examples to avoid logging too frequently
skipping logging after 33520 examples to avoid logging too frequently
train stats after 33536 examples: {'rewards_train/chosen': '-2.724', 'rewards_train/rejected': '-10.355', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.6299', 'logps_train/rejected': '-245.62', 'logps_train/chosen': '-71.008', 'loss/train': '0.092887', 'examples_per_second': '5.9639', 'grad_norm': '13.625', 'counters/examples': 33536, 'counters/updates': 2096}
skipping logging after 33552 examples to avoid logging too frequently
skipping logging after 33568 examples to avoid logging too frequently
skipping logging after 33584 examples to avoid logging too frequently
train stats after 33600 examples: {'rewards_train/chosen': '-2.3059', 'rewards_train/rejected': '-8.5857', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.2822', 'logps_train/rejected': '-196.28', 'logps_train/chosen': '-61.168', 'loss/train': '0.076739', 'examples_per_second': '5.1006', 'grad_norm': '9.6875', 'counters/examples': 33600, 'counters/updates': 2100}
skipping logging after 33616 examples to avoid logging too frequently
skipping logging after 33632 examples to avoid logging too frequently
skipping logging after 33648 examples to avoid logging too frequently
train stats after 33664 examples: {'rewards_train/chosen': '-2.2157', 'rewards_train/rejected': '-9.96', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.7449', 'logps_train/rejected': '-246.75', 'logps_train/chosen': '-67.068', 'loss/train': '0.088886', 'examples_per_second': '4.4069', 'grad_norm': '10.875', 'counters/examples': 33664, 'counters/updates': 2104}
skipping logging after 33680 examples to avoid logging too frequently
skipping logging after 33696 examples to avoid logging too frequently
skipping logging after 33712 examples to avoid logging too frequently
train stats after 33728 examples: {'rewards_train/chosen': '-2.1115', 'rewards_train/rejected': '-10.596', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.4851', 'logps_train/rejected': '-247.9', 'logps_train/chosen': '-54.22', 'loss/train': '0.033581', 'examples_per_second': '6.0332', 'grad_norm': '6.0625', 'counters/examples': 33728, 'counters/updates': 2108}
skipping logging after 33744 examples to avoid logging too frequently
skipping logging after 33760 examples to avoid logging too frequently
skipping logging after 33776 examples to avoid logging too frequently
train stats after 33792 examples: {'rewards_train/chosen': '-2.3354', 'rewards_train/rejected': '-9.2324', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '6.897', 'logps_train/rejected': '-231.59', 'logps_train/chosen': '-62.576', 'loss/train': '0.050146', 'examples_per_second': '6.0251', 'grad_norm': '8.6875', 'counters/examples': 33792, 'counters/updates': 2112}
skipping logging after 33808 examples to avoid logging too frequently
skipping logging after 33824 examples to avoid logging too frequently
skipping logging after 33840 examples to avoid logging too frequently
train stats after 33856 examples: {'rewards_train/chosen': '-2.4827', 'rewards_train/rejected': '-10.505', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.0198', 'logps_train/rejected': '-253.31', 'logps_train/chosen': '-70.279', 'loss/train': '0.11295', 'examples_per_second': '4.6536', 'grad_norm': '10', 'counters/examples': 33856, 'counters/updates': 2116}
skipping logging after 33872 examples to avoid logging too frequently
skipping logging after 33888 examples to avoid logging too frequently
skipping logging after 33904 examples to avoid logging too frequently
train stats after 33920 examples: {'rewards_train/chosen': '-2.7737', 'rewards_train/rejected': '-10.919', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1445', 'logps_train/rejected': '-273.64', 'logps_train/chosen': '-78.049', 'loss/train': '0.080671', 'examples_per_second': '4.5009', 'grad_norm': '12.562', 'counters/examples': 33920, 'counters/updates': 2120}
skipping logging after 33936 examples to avoid logging too frequently
skipping logging after 33952 examples to avoid logging too frequently
skipping logging after 33968 examples to avoid logging too frequently
train stats after 33984 examples: {'rewards_train/chosen': '-3.1433', 'rewards_train/rejected': '-11.174', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.0312', 'logps_train/rejected': '-255.72', 'logps_train/chosen': '-81.461', 'loss/train': '0.13027', 'examples_per_second': '4.7917', 'grad_norm': '19.375', 'counters/examples': 33984, 'counters/updates': 2124}
skipping logging after 34000 examples to avoid logging too frequently
skipping logging after 34016 examples to avoid logging too frequently
skipping logging after 34032 examples to avoid logging too frequently
train stats after 34048 examples: {'rewards_train/chosen': '-2.3045', 'rewards_train/rejected': '-10.471', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1682', 'logps_train/rejected': '-250.09', 'logps_train/chosen': '-71.25', 'loss/train': '0.019923', 'examples_per_second': '5.5438', 'grad_norm': '2.9531', 'counters/examples': 34048, 'counters/updates': 2128}
skipping logging after 34064 examples to avoid logging too frequently
skipping logging after 34080 examples to avoid logging too frequently
skipping logging after 34096 examples to avoid logging too frequently
train stats after 34112 examples: {'rewards_train/chosen': '-2.5626', 'rewards_train/rejected': '-10.469', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.9114', 'logps_train/rejected': '-245.84', 'logps_train/chosen': '-66.115', 'loss/train': '0.10622', 'examples_per_second': '5.3946', 'grad_norm': '12', 'counters/examples': 34112, 'counters/updates': 2132}
skipping logging after 34128 examples to avoid logging too frequently
skipping logging after 34144 examples to avoid logging too frequently
skipping logging after 34160 examples to avoid logging too frequently
train stats after 34176 examples: {'rewards_train/chosen': '-2.4856', 'rewards_train/rejected': '-10.031', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.5435', 'logps_train/rejected': '-257.75', 'logps_train/chosen': '-76.959', 'loss/train': '0.060217', 'examples_per_second': '4.841', 'grad_norm': '12.375', 'counters/examples': 34176, 'counters/updates': 2136}
skipping logging after 34192 examples to avoid logging too frequently
skipping logging after 34208 examples to avoid logging too frequently
skipping logging after 34224 examples to avoid logging too frequently
train stats after 34240 examples: {'rewards_train/chosen': '-2.5626', 'rewards_train/rejected': '-9.9568', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.3954', 'logps_train/rejected': '-254.75', 'logps_train/chosen': '-61.371', 'loss/train': '0.093912', 'examples_per_second': '4.6589', 'grad_norm': '11.875', 'counters/examples': 34240, 'counters/updates': 2140}
skipping logging after 34256 examples to avoid logging too frequently
skipping logging after 34272 examples to avoid logging too frequently
skipping logging after 34288 examples to avoid logging too frequently
train stats after 34304 examples: {'rewards_train/chosen': '-2.5887', 'rewards_train/rejected': '-10.486', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.8979', 'logps_train/rejected': '-221.77', 'logps_train/chosen': '-58.535', 'loss/train': '0.081853', 'examples_per_second': '4.8107', 'grad_norm': '7.8438', 'counters/examples': 34304, 'counters/updates': 2144}
skipping logging after 34320 examples to avoid logging too frequently
skipping logging after 34336 examples to avoid logging too frequently
skipping logging after 34352 examples to avoid logging too frequently
train stats after 34368 examples: {'rewards_train/chosen': '-3.0007', 'rewards_train/rejected': '-11.896', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '8.895', 'logps_train/rejected': '-253.79', 'logps_train/chosen': '-80.717', 'loss/train': '0.059146', 'examples_per_second': '5.1287', 'grad_norm': '6.4688', 'counters/examples': 34368, 'counters/updates': 2148}
skipping logging after 34384 examples to avoid logging too frequently
skipping logging after 34400 examples to avoid logging too frequently
skipping logging after 34416 examples to avoid logging too frequently
train stats after 34432 examples: {'rewards_train/chosen': '-2.6414', 'rewards_train/rejected': '-11.236', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.5933', 'logps_train/rejected': '-236.13', 'logps_train/chosen': '-73.312', 'loss/train': '0.20174', 'examples_per_second': '5.7877', 'grad_norm': '27.625', 'counters/examples': 34432, 'counters/updates': 2152}
skipping logging after 34448 examples to avoid logging too frequently
skipping logging after 34464 examples to avoid logging too frequently
skipping logging after 34480 examples to avoid logging too frequently
train stats after 34496 examples: {'rewards_train/chosen': '-2.0385', 'rewards_train/rejected': '-10.094', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.0549', 'logps_train/rejected': '-257.07', 'logps_train/chosen': '-61.174', 'loss/train': '0.03806', 'examples_per_second': '5.0863', 'grad_norm': '7.1562', 'counters/examples': 34496, 'counters/updates': 2156}
skipping logging after 34512 examples to avoid logging too frequently
skipping logging after 34528 examples to avoid logging too frequently
skipping logging after 34544 examples to avoid logging too frequently
train stats after 34560 examples: {'rewards_train/chosen': '-2.8499', 'rewards_train/rejected': '-11.622', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.772', 'logps_train/rejected': '-268.83', 'logps_train/chosen': '-72.51', 'loss/train': '0.057701', 'examples_per_second': '6.1073', 'grad_norm': '10.688', 'counters/examples': 34560, 'counters/updates': 2160}
skipping logging after 34576 examples to avoid logging too frequently
skipping logging after 34592 examples to avoid logging too frequently
skipping logging after 34608 examples to avoid logging too frequently
train stats after 34624 examples: {'rewards_train/chosen': '-2.3508', 'rewards_train/rejected': '-10.535', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.1868', 'logps_train/rejected': '-261.98', 'logps_train/chosen': '-66.706', 'loss/train': '0.027582', 'examples_per_second': '6.6334', 'grad_norm': '3.4844', 'counters/examples': 34624, 'counters/updates': 2164}
skipping logging after 34640 examples to avoid logging too frequently
skipping logging after 34656 examples to avoid logging too frequently
skipping logging after 34672 examples to avoid logging too frequently
train stats after 34688 examples: {'rewards_train/chosen': '-2.5103', 'rewards_train/rejected': '-11.249', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.7388', 'logps_train/rejected': '-255.62', 'logps_train/chosen': '-60.104', 'loss/train': '0.089598', 'examples_per_second': '5.2243', 'grad_norm': '10.312', 'counters/examples': 34688, 'counters/updates': 2168}
skipping logging after 34704 examples to avoid logging too frequently
skipping logging after 34720 examples to avoid logging too frequently
skipping logging after 34736 examples to avoid logging too frequently
train stats after 34752 examples: {'rewards_train/chosen': '-2.1257', 'rewards_train/rejected': '-9.7288', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.6025', 'logps_train/rejected': '-221.02', 'logps_train/chosen': '-63.003', 'loss/train': '0.024431', 'examples_per_second': '3.7262', 'grad_norm': '3.5', 'counters/examples': 34752, 'counters/updates': 2172}
skipping logging after 34768 examples to avoid logging too frequently
skipping logging after 34784 examples to avoid logging too frequently
skipping logging after 34800 examples to avoid logging too frequently
train stats after 34816 examples: {'rewards_train/chosen': '-2.7616', 'rewards_train/rejected': '-10.448', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.6859', 'logps_train/rejected': '-277.37', 'logps_train/chosen': '-67.303', 'loss/train': '0.061617', 'examples_per_second': '5.035', 'grad_norm': '10.625', 'counters/examples': 34816, 'counters/updates': 2176}
skipping logging after 34832 examples to avoid logging too frequently
skipping logging after 34848 examples to avoid logging too frequently
skipping logging after 34864 examples to avoid logging too frequently
train stats after 34880 examples: {'rewards_train/chosen': '-2.7142', 'rewards_train/rejected': '-10.873', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.1575', 'logps_train/rejected': '-243.39', 'logps_train/chosen': '-67.312', 'loss/train': '0.093585', 'examples_per_second': '5.3361', 'grad_norm': '12.625', 'counters/examples': 34880, 'counters/updates': 2180}
skipping logging after 34896 examples to avoid logging too frequently
skipping logging after 34912 examples to avoid logging too frequently
skipping logging after 34928 examples to avoid logging too frequently
train stats after 34944 examples: {'rewards_train/chosen': '-2.3682', 'rewards_train/rejected': '-10.102', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.7316', 'logps_train/rejected': '-265.58', 'logps_train/chosen': '-61.442', 'loss/train': '0.046477', 'examples_per_second': '5.7391', 'grad_norm': '7.0938', 'counters/examples': 34944, 'counters/updates': 2184}
skipping logging after 34960 examples to avoid logging too frequently
skipping logging after 34976 examples to avoid logging too frequently
skipping logging after 34992 examples to avoid logging too frequently
train stats after 35008 examples: {'rewards_train/chosen': '-2.5594', 'rewards_train/rejected': '-10.086', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.5269', 'logps_train/rejected': '-262.95', 'logps_train/chosen': '-69.812', 'loss/train': '0.028669', 'examples_per_second': '5.0016', 'grad_norm': '4.6875', 'counters/examples': 35008, 'counters/updates': 2188}
skipping logging after 35024 examples to avoid logging too frequently
skipping logging after 35040 examples to avoid logging too frequently
skipping logging after 35056 examples to avoid logging too frequently
train stats after 35072 examples: {'rewards_train/chosen': '-2.5379', 'rewards_train/rejected': '-9.6704', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.1322', 'logps_train/rejected': '-223.71', 'logps_train/chosen': '-76.144', 'loss/train': '0.082504', 'examples_per_second': '4.3036', 'grad_norm': '6.5938', 'counters/examples': 35072, 'counters/updates': 2192}
skipping logging after 35088 examples to avoid logging too frequently
skipping logging after 35104 examples to avoid logging too frequently
skipping logging after 35120 examples to avoid logging too frequently
train stats after 35136 examples: {'rewards_train/chosen': '-2.2324', 'rewards_train/rejected': '-10.285', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.0524', 'logps_train/rejected': '-232.46', 'logps_train/chosen': '-64.158', 'loss/train': '0.042111', 'examples_per_second': '5.0815', 'grad_norm': '4.4062', 'counters/examples': 35136, 'counters/updates': 2196}
skipping logging after 35152 examples to avoid logging too frequently
skipping logging after 35168 examples to avoid logging too frequently
skipping logging after 35184 examples to avoid logging too frequently
train stats after 35200 examples: {'rewards_train/chosen': '-2.4343', 'rewards_train/rejected': '-10.273', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.8394', 'logps_train/rejected': '-236.7', 'logps_train/chosen': '-61.894', 'loss/train': '0.11126', 'examples_per_second': '4.4744', 'grad_norm': '13.938', 'counters/examples': 35200, 'counters/updates': 2200}
skipping logging after 35216 examples to avoid logging too frequently
skipping logging after 35232 examples to avoid logging too frequently
skipping logging after 35248 examples to avoid logging too frequently
train stats after 35264 examples: {'rewards_train/chosen': '-2.4933', 'rewards_train/rejected': '-10.491', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.9973', 'logps_train/rejected': '-211.45', 'logps_train/chosen': '-57.736', 'loss/train': '0.033152', 'examples_per_second': '5.8026', 'grad_norm': '3.9531', 'counters/examples': 35264, 'counters/updates': 2204}
skipping logging after 35280 examples to avoid logging too frequently
skipping logging after 35296 examples to avoid logging too frequently
skipping logging after 35312 examples to avoid logging too frequently
train stats after 35328 examples: {'rewards_train/chosen': '-2.7127', 'rewards_train/rejected': '-11.605', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.8901', 'logps_train/rejected': '-255.32', 'logps_train/chosen': '-68.104', 'loss/train': '0.061811', 'examples_per_second': '4.6183', 'grad_norm': '7.125', 'counters/examples': 35328, 'counters/updates': 2208}
skipping logging after 35344 examples to avoid logging too frequently
skipping logging after 35360 examples to avoid logging too frequently
skipping logging after 35376 examples to avoid logging too frequently
train stats after 35392 examples: {'rewards_train/chosen': '-3.158', 'rewards_train/rejected': '-12.077', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.9172', 'logps_train/rejected': '-267.44', 'logps_train/chosen': '-70.371', 'loss/train': '0.14098', 'examples_per_second': '5.0215', 'grad_norm': '18.75', 'counters/examples': 35392, 'counters/updates': 2212}
skipping logging after 35408 examples to avoid logging too frequently
skipping logging after 35424 examples to avoid logging too frequently
skipping logging after 35440 examples to avoid logging too frequently
train stats after 35456 examples: {'rewards_train/chosen': '-2.0441', 'rewards_train/rejected': '-10.655', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.6104', 'logps_train/rejected': '-266.16', 'logps_train/chosen': '-62.169', 'loss/train': '0.079078', 'examples_per_second': '5.4144', 'grad_norm': '14.312', 'counters/examples': 35456, 'counters/updates': 2216}
skipping logging after 35472 examples to avoid logging too frequently
skipping logging after 35488 examples to avoid logging too frequently
skipping logging after 35504 examples to avoid logging too frequently
train stats after 35520 examples: {'rewards_train/chosen': '-2.4329', 'rewards_train/rejected': '-8.7593', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '6.3232', 'logps_train/rejected': '-223.54', 'logps_train/chosen': '-70.119', 'loss/train': '0.092282', 'examples_per_second': '5.9665', 'grad_norm': '11.438', 'counters/examples': 35520, 'counters/updates': 2220}
skipping logging after 35536 examples to avoid logging too frequently
skipping logging after 35552 examples to avoid logging too frequently
skipping logging after 35568 examples to avoid logging too frequently
train stats after 35584 examples: {'rewards_train/chosen': '-1.8504', 'rewards_train/rejected': '-8.9778', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.127', 'logps_train/rejected': '-237.54', 'logps_train/chosen': '-52.361', 'loss/train': '0.087633', 'examples_per_second': '5.4305', 'grad_norm': '9.1875', 'counters/examples': 35584, 'counters/updates': 2224}
skipping logging after 35600 examples to avoid logging too frequently
skipping logging after 35616 examples to avoid logging too frequently
skipping logging after 35632 examples to avoid logging too frequently
train stats after 35648 examples: {'rewards_train/chosen': '-2.166', 'rewards_train/rejected': '-8.2471', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.0818', 'logps_train/rejected': '-191.46', 'logps_train/chosen': '-59.354', 'loss/train': '0.076043', 'examples_per_second': '4.9026', 'grad_norm': '10.438', 'counters/examples': 35648, 'counters/updates': 2228}
skipping logging after 35664 examples to avoid logging too frequently
skipping logging after 35680 examples to avoid logging too frequently
skipping logging after 35696 examples to avoid logging too frequently
train stats after 35712 examples: {'rewards_train/chosen': '-1.826', 'rewards_train/rejected': '-9.2854', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.4569', 'logps_train/rejected': '-225.66', 'logps_train/chosen': '-58.953', 'loss/train': '0.060828', 'examples_per_second': '4.5148', 'grad_norm': '5.625', 'counters/examples': 35712, 'counters/updates': 2232}
skipping logging after 35728 examples to avoid logging too frequently
skipping logging after 35744 examples to avoid logging too frequently
skipping logging after 35760 examples to avoid logging too frequently
train stats after 35776 examples: {'rewards_train/chosen': '-2.355', 'rewards_train/rejected': '-9.6221', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.2678', 'logps_train/rejected': '-231.29', 'logps_train/chosen': '-64.833', 'loss/train': '0.065784', 'examples_per_second': '5.9645', 'grad_norm': '10.688', 'counters/examples': 35776, 'counters/updates': 2236}
skipping logging after 35792 examples to avoid logging too frequently
skipping logging after 35808 examples to avoid logging too frequently
skipping logging after 35824 examples to avoid logging too frequently
train stats after 35840 examples: {'rewards_train/chosen': '-2.4035', 'rewards_train/rejected': '-9.6973', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.2941', 'logps_train/rejected': '-252.69', 'logps_train/chosen': '-67.785', 'loss/train': '0.071847', 'examples_per_second': '6.0451', 'grad_norm': '8.25', 'counters/examples': 35840, 'counters/updates': 2240}
skipping logging after 35856 examples to avoid logging too frequently
skipping logging after 35872 examples to avoid logging too frequently
skipping logging after 35888 examples to avoid logging too frequently
train stats after 35904 examples: {'rewards_train/chosen': '-2.1099', 'rewards_train/rejected': '-10.695', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.5863', 'logps_train/rejected': '-259.67', 'logps_train/chosen': '-69.415', 'loss/train': '0.03668', 'examples_per_second': '4.0627', 'grad_norm': '7.625', 'counters/examples': 35904, 'counters/updates': 2244}
skipping logging after 35920 examples to avoid logging too frequently
skipping logging after 35936 examples to avoid logging too frequently
skipping logging after 35952 examples to avoid logging too frequently
train stats after 35968 examples: {'rewards_train/chosen': '-2.3535', 'rewards_train/rejected': '-11.543', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.1907', 'logps_train/rejected': '-267.66', 'logps_train/chosen': '-70.426', 'loss/train': '0.062563', 'examples_per_second': '4.4262', 'grad_norm': '10.938', 'counters/examples': 35968, 'counters/updates': 2248}
skipping logging after 35984 examples to avoid logging too frequently
skipping logging after 36000 examples to avoid logging too frequently
Running evaluation after 36000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:02<01:13,  2.37s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:05,  2.19s/it]Computing eval metrics:   9%|▉         | 3/32 [00:06<00:56,  1.94s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:53,  1.91s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:42,  1.56s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:43,  1.66s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:37,  1.50s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.57s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:15<00:36,  1.57s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:18<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.50s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:22<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:23<00:22,  1.30s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.24s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.33s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:27<00:18,  1.34s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.24s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.27s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:33<00:10,  1.21s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.29s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:35<00:08,  1.26s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:37<00:07,  1.30s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:39<00:07,  1.48s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:40<00:05,  1.41s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:42<00:04,  1.61s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:43<00:02,  1.42s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:44<00:01,  1.41s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.40s/it]Computing eval metrics: 100%|██████████| 32/32 [00:46<00:00,  1.44s/it]
eval after 36000: {'rewards_eval/chosen': '-9.8657', 'rewards_eval/rejected': '-10.307', 'rewards_eval/accuracies': '0.5293', 'rewards_eval/margins': '0.44113', 'logps_eval/rejected': '-250.72', 'logps_eval/chosen': '-243.56', 'loss/eval': '2.0252'}
skipping logging after 36016 examples to avoid logging too frequently
train stats after 36032 examples: {'rewards_train/chosen': '-2.1198', 'rewards_train/rejected': '-10.458', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.3417', 'logps_train/rejected': '-248.28', 'logps_train/chosen': '-66.482', 'loss/train': '0.094709', 'examples_per_second': '4.56', 'grad_norm': '13.438', 'counters/examples': 36032, 'counters/updates': 2252}
skipping logging after 36048 examples to avoid logging too frequently
skipping logging after 36064 examples to avoid logging too frequently
skipping logging after 36080 examples to avoid logging too frequently
train stats after 36096 examples: {'rewards_train/chosen': '-2.3614', 'rewards_train/rejected': '-11.168', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.8069', 'logps_train/rejected': '-259.79', 'logps_train/chosen': '-68.016', 'loss/train': '0.018769', 'examples_per_second': '4.6897', 'grad_norm': '6.0625', 'counters/examples': 36096, 'counters/updates': 2256}
skipping logging after 36112 examples to avoid logging too frequently
skipping logging after 36128 examples to avoid logging too frequently
skipping logging after 36144 examples to avoid logging too frequently
train stats after 36160 examples: {'rewards_train/chosen': '-2.5174', 'rewards_train/rejected': '-11.498', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.9824', 'logps_train/rejected': '-272.46', 'logps_train/chosen': '-66.701', 'loss/train': '0.11349', 'examples_per_second': '5.0334', 'grad_norm': '11.938', 'counters/examples': 36160, 'counters/updates': 2260}
skipping logging after 36176 examples to avoid logging too frequently
skipping logging after 36192 examples to avoid logging too frequently
skipping logging after 36208 examples to avoid logging too frequently
train stats after 36224 examples: {'rewards_train/chosen': '-2.6094', 'rewards_train/rejected': '-10.869', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.2581', 'logps_train/rejected': '-247.87', 'logps_train/chosen': '-66.867', 'loss/train': '0.11494', 'examples_per_second': '5.9996', 'grad_norm': '17.25', 'counters/examples': 36224, 'counters/updates': 2264}
skipping logging after 36240 examples to avoid logging too frequently
skipping logging after 36256 examples to avoid logging too frequently
skipping logging after 36272 examples to avoid logging too frequently
train stats after 36288 examples: {'rewards_train/chosen': '-2.2464', 'rewards_train/rejected': '-9.6631', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.4158', 'logps_train/rejected': '-231.3', 'logps_train/chosen': '-59.773', 'loss/train': '0.080887', 'examples_per_second': '4.7514', 'grad_norm': '19.375', 'counters/examples': 36288, 'counters/updates': 2268}
skipping logging after 36304 examples to avoid logging too frequently
skipping logging after 36320 examples to avoid logging too frequently
skipping logging after 36336 examples to avoid logging too frequently
train stats after 36352 examples: {'rewards_train/chosen': '-3.116', 'rewards_train/rejected': '-11.539', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.4221', 'logps_train/rejected': '-246.95', 'logps_train/chosen': '-72.129', 'loss/train': '0.11075', 'examples_per_second': '5.311', 'grad_norm': '19', 'counters/examples': 36352, 'counters/updates': 2272}
skipping logging after 36368 examples to avoid logging too frequently
skipping logging after 36384 examples to avoid logging too frequently
skipping logging after 36400 examples to avoid logging too frequently
train stats after 36416 examples: {'rewards_train/chosen': '-2.7868', 'rewards_train/rejected': '-10.662', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.8755', 'logps_train/rejected': '-233.58', 'logps_train/chosen': '-66.696', 'loss/train': '0.11789', 'examples_per_second': '4.9261', 'grad_norm': '15.25', 'counters/examples': 36416, 'counters/updates': 2276}
skipping logging after 36432 examples to avoid logging too frequently
skipping logging after 36448 examples to avoid logging too frequently
skipping logging after 36464 examples to avoid logging too frequently
train stats after 36480 examples: {'rewards_train/chosen': '-2.5481', 'rewards_train/rejected': '-10.066', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.519', 'logps_train/rejected': '-233.95', 'logps_train/chosen': '-64.308', 'loss/train': '0.079596', 'examples_per_second': '4.9605', 'grad_norm': '9.5625', 'counters/examples': 36480, 'counters/updates': 2280}
skipping logging after 36496 examples to avoid logging too frequently
skipping logging after 36512 examples to avoid logging too frequently
skipping logging after 36528 examples to avoid logging too frequently
train stats after 36544 examples: {'rewards_train/chosen': '-2.483', 'rewards_train/rejected': '-11.51', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.0276', 'logps_train/rejected': '-277.82', 'logps_train/chosen': '-65.483', 'loss/train': '0.048776', 'examples_per_second': '5.0551', 'grad_norm': '5', 'counters/examples': 36544, 'counters/updates': 2284}
skipping logging after 36560 examples to avoid logging too frequently
skipping logging after 36576 examples to avoid logging too frequently
skipping logging after 36592 examples to avoid logging too frequently
train stats after 36608 examples: {'rewards_train/chosen': '-2.8838', 'rewards_train/rejected': '-10.346', 'rewards_train/accuracies': '1', 'rewards_train/margins': '7.4607', 'logps_train/rejected': '-235.41', 'logps_train/chosen': '-75.068', 'loss/train': '0.098904', 'examples_per_second': '5.0846', 'grad_norm': '14.375', 'counters/examples': 36608, 'counters/updates': 2288}
skipping logging after 36624 examples to avoid logging too frequently
skipping logging after 36640 examples to avoid logging too frequently
skipping logging after 36656 examples to avoid logging too frequently
train stats after 36672 examples: {'rewards_train/chosen': '-2.3137', 'rewards_train/rejected': '-11.814', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.5005', 'logps_train/rejected': '-291.22', 'logps_train/chosen': '-70.499', 'loss/train': '0.055571', 'examples_per_second': '4.892', 'grad_norm': '12.562', 'counters/examples': 36672, 'counters/updates': 2292}
skipping logging after 36688 examples to avoid logging too frequently
skipping logging after 36704 examples to avoid logging too frequently
skipping logging after 36720 examples to avoid logging too frequently
train stats after 36736 examples: {'rewards_train/chosen': '-2.26', 'rewards_train/rejected': '-10.58', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '8.3176', 'logps_train/rejected': '-239.11', 'logps_train/chosen': '-62.266', 'loss/train': '0.047077', 'examples_per_second': '4.4386', 'grad_norm': '4.0625', 'counters/examples': 36736, 'counters/updates': 2296}
skipping logging after 36752 examples to avoid logging too frequently
skipping logging after 36768 examples to avoid logging too frequently
skipping logging after 36784 examples to avoid logging too frequently
train stats after 36800 examples: {'rewards_train/chosen': '-2.6546', 'rewards_train/rejected': '-10.548', 'rewards_train/accuracies': '0.92188', 'rewards_train/margins': '7.8956', 'logps_train/rejected': '-263.73', 'logps_train/chosen': '-70.271', 'loss/train': '0.1245', 'examples_per_second': '4.7275', 'grad_norm': '13.375', 'counters/examples': 36800, 'counters/updates': 2300}
skipping logging after 36816 examples to avoid logging too frequently
skipping logging after 36832 examples to avoid logging too frequently
skipping logging after 36848 examples to avoid logging too frequently
train stats after 36864 examples: {'rewards_train/chosen': '-2.4101', 'rewards_train/rejected': '-8.9464', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.5378', 'logps_train/rejected': '-210.55', 'logps_train/chosen': '-55.042', 'loss/train': '0.056792', 'examples_per_second': '5.4217', 'grad_norm': '6.8438', 'counters/examples': 36864, 'counters/updates': 2304}
skipping logging after 36880 examples to avoid logging too frequently
skipping logging after 36896 examples to avoid logging too frequently
skipping logging after 36912 examples to avoid logging too frequently
train stats after 36928 examples: {'rewards_train/chosen': '-2.4186', 'rewards_train/rejected': '-9.7285', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.3092', 'logps_train/rejected': '-238.48', 'logps_train/chosen': '-67.66', 'loss/train': '0.11474', 'examples_per_second': '5.4349', 'grad_norm': '8.6875', 'counters/examples': 36928, 'counters/updates': 2308}
skipping logging after 36944 examples to avoid logging too frequently
skipping logging after 36960 examples to avoid logging too frequently
skipping logging after 36976 examples to avoid logging too frequently
train stats after 36992 examples: {'rewards_train/chosen': '-2.0101', 'rewards_train/rejected': '-10.278', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.265', 'logps_train/rejected': '-283.21', 'logps_train/chosen': '-71.572', 'loss/train': '0.06835', 'examples_per_second': '4.0064', 'grad_norm': '6.6875', 'counters/examples': 36992, 'counters/updates': 2312}
skipping logging after 37008 examples to avoid logging too frequently
skipping logging after 37024 examples to avoid logging too frequently
skipping logging after 37040 examples to avoid logging too frequently
train stats after 37056 examples: {'rewards_train/chosen': '-1.9072', 'rewards_train/rejected': '-9.3689', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.4613', 'logps_train/rejected': '-243', 'logps_train/chosen': '-68.189', 'loss/train': '0.04909', 'examples_per_second': '4.6801', 'grad_norm': '7.8125', 'counters/examples': 37056, 'counters/updates': 2316}
skipping logging after 37072 examples to avoid logging too frequently
skipping logging after 37088 examples to avoid logging too frequently
skipping logging after 37104 examples to avoid logging too frequently
train stats after 37120 examples: {'rewards_train/chosen': '-2.1383', 'rewards_train/rejected': '-9.068', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.9287', 'logps_train/rejected': '-202.9', 'logps_train/chosen': '-56.75', 'loss/train': '0.060849', 'examples_per_second': '4.8859', 'grad_norm': '6.5', 'counters/examples': 37120, 'counters/updates': 2320}
skipping logging after 37136 examples to avoid logging too frequently
skipping logging after 37152 examples to avoid logging too frequently
skipping logging after 37168 examples to avoid logging too frequently
train stats after 37184 examples: {'rewards_train/chosen': '-1.9829', 'rewards_train/rejected': '-9.5925', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.6094', 'logps_train/rejected': '-234.08', 'logps_train/chosen': '-58.438', 'loss/train': '0.080108', 'examples_per_second': '4.9725', 'grad_norm': '10.312', 'counters/examples': 37184, 'counters/updates': 2324}
skipping logging after 37200 examples to avoid logging too frequently
skipping logging after 37216 examples to avoid logging too frequently
skipping logging after 37232 examples to avoid logging too frequently
train stats after 37248 examples: {'rewards_train/chosen': '-2.0865', 'rewards_train/rejected': '-9.2664', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.1803', 'logps_train/rejected': '-240.04', 'logps_train/chosen': '-60.132', 'loss/train': '0.11938', 'examples_per_second': '4.8637', 'grad_norm': '10.312', 'counters/examples': 37248, 'counters/updates': 2328}
skipping logging after 37264 examples to avoid logging too frequently
skipping logging after 37280 examples to avoid logging too frequently
skipping logging after 37296 examples to avoid logging too frequently
train stats after 37312 examples: {'rewards_train/chosen': '-2.0208', 'rewards_train/rejected': '-9.1741', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.1514', 'logps_train/rejected': '-242.67', 'logps_train/chosen': '-57.897', 'loss/train': '0.085998', 'examples_per_second': '3.9433', 'grad_norm': '7.3125', 'counters/examples': 37312, 'counters/updates': 2332}
skipping logging after 37328 examples to avoid logging too frequently
skipping logging after 37344 examples to avoid logging too frequently
skipping logging after 37360 examples to avoid logging too frequently
train stats after 37376 examples: {'rewards_train/chosen': '-2.0224', 'rewards_train/rejected': '-10.479', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.4579', 'logps_train/rejected': '-253.42', 'logps_train/chosen': '-62.24', 'loss/train': '0.063089', 'examples_per_second': '5.0403', 'grad_norm': '5.4062', 'counters/examples': 37376, 'counters/updates': 2336}
skipping logging after 37392 examples to avoid logging too frequently
skipping logging after 37408 examples to avoid logging too frequently
skipping logging after 37424 examples to avoid logging too frequently
train stats after 37440 examples: {'rewards_train/chosen': '-2.381', 'rewards_train/rejected': '-10.244', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '7.8616', 'logps_train/rejected': '-228.95', 'logps_train/chosen': '-69.676', 'loss/train': '0.09668', 'examples_per_second': '5.139', 'grad_norm': '9.9375', 'counters/examples': 37440, 'counters/updates': 2340}
skipping logging after 37456 examples to avoid logging too frequently
skipping logging after 37472 examples to avoid logging too frequently
skipping logging after 37488 examples to avoid logging too frequently
train stats after 37504 examples: {'rewards_train/chosen': '-2.7394', 'rewards_train/rejected': '-10.855', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.1176', 'logps_train/rejected': '-239.28', 'logps_train/chosen': '-71.005', 'loss/train': '0.098276', 'examples_per_second': '5.0809', 'grad_norm': '9.8125', 'counters/examples': 37504, 'counters/updates': 2344}
skipping logging after 37520 examples to avoid logging too frequently
skipping logging after 37536 examples to avoid logging too frequently
skipping logging after 37552 examples to avoid logging too frequently
train stats after 37568 examples: {'rewards_train/chosen': '-2.6509', 'rewards_train/rejected': '-11.602', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.9526', 'logps_train/rejected': '-256.66', 'logps_train/chosen': '-65.313', 'loss/train': '0.072269', 'examples_per_second': '3.699', 'grad_norm': '6.5', 'counters/examples': 37568, 'counters/updates': 2348}
skipping logging after 37584 examples to avoid logging too frequently
skipping logging after 37600 examples to avoid logging too frequently
skipping logging after 37616 examples to avoid logging too frequently
train stats after 37632 examples: {'rewards_train/chosen': '-2.1702', 'rewards_train/rejected': '-12.625', 'rewards_train/accuracies': '1', 'rewards_train/margins': '10.452', 'logps_train/rejected': '-306.07', 'logps_train/chosen': '-69.394', 'loss/train': '0.048059', 'examples_per_second': '4.9526', 'grad_norm': '5.2812', 'counters/examples': 37632, 'counters/updates': 2352}
skipping logging after 37648 examples to avoid logging too frequently
skipping logging after 37664 examples to avoid logging too frequently
skipping logging after 37680 examples to avoid logging too frequently
train stats after 37696 examples: {'rewards_train/chosen': '-2.9319', 'rewards_train/rejected': '-11.217', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '8.2854', 'logps_train/rejected': '-254.48', 'logps_train/chosen': '-66.845', 'loss/train': '0.13606', 'examples_per_second': '4.3942', 'grad_norm': '10.75', 'counters/examples': 37696, 'counters/updates': 2356}
skipping logging after 37712 examples to avoid logging too frequently
skipping logging after 37728 examples to avoid logging too frequently
skipping logging after 37744 examples to avoid logging too frequently
train stats after 37760 examples: {'rewards_train/chosen': '-1.8194', 'rewards_train/rejected': '-11.961', 'rewards_train/accuracies': '1', 'rewards_train/margins': '10.142', 'logps_train/rejected': '-276.13', 'logps_train/chosen': '-61.79', 'loss/train': '0.027288', 'examples_per_second': '4.9521', 'grad_norm': '6.9375', 'counters/examples': 37760, 'counters/updates': 2360}
skipping logging after 37776 examples to avoid logging too frequently
skipping logging after 37792 examples to avoid logging too frequently
skipping logging after 37808 examples to avoid logging too frequently
train stats after 37824 examples: {'rewards_train/chosen': '-2.5177', 'rewards_train/rejected': '-9.6147', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.0981', 'logps_train/rejected': '-212.29', 'logps_train/chosen': '-64.569', 'loss/train': '0.054212', 'examples_per_second': '6.279', 'grad_norm': '15.625', 'counters/examples': 37824, 'counters/updates': 2364}
skipping logging after 37840 examples to avoid logging too frequently
skipping logging after 37856 examples to avoid logging too frequently
skipping logging after 37872 examples to avoid logging too frequently
train stats after 37888 examples: {'rewards_train/chosen': '-2.9173', 'rewards_train/rejected': '-11.03', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '8.114', 'logps_train/rejected': '-247.25', 'logps_train/chosen': '-72.809', 'loss/train': '0.13211', 'examples_per_second': '5.8577', 'grad_norm': '19.5', 'counters/examples': 37888, 'counters/updates': 2368}
skipping logging after 37904 examples to avoid logging too frequently
skipping logging after 37920 examples to avoid logging too frequently
skipping logging after 37936 examples to avoid logging too frequently
train stats after 37952 examples: {'rewards_train/chosen': '-2.7764', 'rewards_train/rejected': '-12.121', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '9.3405', 'logps_train/rejected': '-283.64', 'logps_train/chosen': '-72.805', 'loss/train': '0.095497', 'examples_per_second': '4.8322', 'grad_norm': '17.25', 'counters/examples': 37952, 'counters/updates': 2372}
skipping logging after 37968 examples to avoid logging too frequently
skipping logging after 37984 examples to avoid logging too frequently
skipping logging after 38000 examples to avoid logging too frequently
train stats after 38016 examples: {'rewards_train/chosen': '-2.3965', 'rewards_train/rejected': '-10.668', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.2715', 'logps_train/rejected': '-228.35', 'logps_train/chosen': '-60.41', 'loss/train': '0.042915', 'examples_per_second': '5.7677', 'grad_norm': '3.9688', 'counters/examples': 38016, 'counters/updates': 2376}
skipping logging after 38032 examples to avoid logging too frequently
skipping logging after 38048 examples to avoid logging too frequently
skipping logging after 38064 examples to avoid logging too frequently
train stats after 38080 examples: {'rewards_train/chosen': '-2.3112', 'rewards_train/rejected': '-11.194', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.8848', 'logps_train/rejected': '-277.25', 'logps_train/chosen': '-64.75', 'loss/train': '0.06774', 'examples_per_second': '4.9841', 'grad_norm': '15.375', 'counters/examples': 38080, 'counters/updates': 2380}
skipping logging after 38096 examples to avoid logging too frequently
skipping logging after 38112 examples to avoid logging too frequently
skipping logging after 38128 examples to avoid logging too frequently
train stats after 38144 examples: {'rewards_train/chosen': '-2.2883', 'rewards_train/rejected': '-9.8431', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.5564', 'logps_train/rejected': '-215.82', 'logps_train/chosen': '-61.61', 'loss/train': '0.084709', 'examples_per_second': '4.8601', 'grad_norm': '9.875', 'counters/examples': 38144, 'counters/updates': 2384}
skipping logging after 38160 examples to avoid logging too frequently
skipping logging after 38176 examples to avoid logging too frequently
skipping logging after 38192 examples to avoid logging too frequently
train stats after 38208 examples: {'rewards_train/chosen': '-2.3961', 'rewards_train/rejected': '-9.5787', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.1805', 'logps_train/rejected': '-214.59', 'logps_train/chosen': '-56.823', 'loss/train': '0.082675', 'examples_per_second': '5.8295', 'grad_norm': '9.75', 'counters/examples': 38208, 'counters/updates': 2388}
skipping logging after 38224 examples to avoid logging too frequently
skipping logging after 38240 examples to avoid logging too frequently
skipping logging after 38256 examples to avoid logging too frequently
train stats after 38272 examples: {'rewards_train/chosen': '-1.6601', 'rewards_train/rejected': '-12.457', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '10.795', 'logps_train/rejected': '-329.09', 'logps_train/chosen': '-56.39', 'loss/train': '0.014888', 'examples_per_second': '4.2741', 'grad_norm': '2.875', 'counters/examples': 38272, 'counters/updates': 2392}
skipping logging after 38288 examples to avoid logging too frequently
skipping logging after 38304 examples to avoid logging too frequently
skipping logging after 38320 examples to avoid logging too frequently
train stats after 38336 examples: {'rewards_train/chosen': '-2.4738', 'rewards_train/rejected': '-9.3722', 'rewards_train/accuracies': '0.89062', 'rewards_train/margins': '6.8937', 'logps_train/rejected': '-207.32', 'logps_train/chosen': '-59.189', 'loss/train': '0.16182', 'examples_per_second': '5.0333', 'grad_norm': '14.812', 'counters/examples': 38336, 'counters/updates': 2396}
skipping logging after 38352 examples to avoid logging too frequently
skipping logging after 38368 examples to avoid logging too frequently
skipping logging after 38384 examples to avoid logging too frequently
train stats after 38400 examples: {'rewards_train/chosen': '-1.846', 'rewards_train/rejected': '-10.172', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.3248', 'logps_train/rejected': '-266.84', 'logps_train/chosen': '-61.131', 'loss/train': '0.04483', 'examples_per_second': '5.1282', 'grad_norm': '4.0625', 'counters/examples': 38400, 'counters/updates': 2400}
skipping logging after 38416 examples to avoid logging too frequently
skipping logging after 38432 examples to avoid logging too frequently
skipping logging after 38448 examples to avoid logging too frequently
train stats after 38464 examples: {'rewards_train/chosen': '-1.8524', 'rewards_train/rejected': '-9.7237', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.8685', 'logps_train/rejected': '-274.41', 'logps_train/chosen': '-58.064', 'loss/train': '0.079196', 'examples_per_second': '4.3477', 'grad_norm': '8.125', 'counters/examples': 38464, 'counters/updates': 2404}
skipping logging after 38480 examples to avoid logging too frequently
skipping logging after 38496 examples to avoid logging too frequently
skipping logging after 38512 examples to avoid logging too frequently
train stats after 38528 examples: {'rewards_train/chosen': '-2.1341', 'rewards_train/rejected': '-9.8367', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.7049', 'logps_train/rejected': '-233.02', 'logps_train/chosen': '-60.016', 'loss/train': '0.062031', 'examples_per_second': '4.5847', 'grad_norm': '5.7188', 'counters/examples': 38528, 'counters/updates': 2408}
skipping logging after 38544 examples to avoid logging too frequently
skipping logging after 38560 examples to avoid logging too frequently
skipping logging after 38576 examples to avoid logging too frequently
train stats after 38592 examples: {'rewards_train/chosen': '-2.4937', 'rewards_train/rejected': '-10.875', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.3812', 'logps_train/rejected': '-248.36', 'logps_train/chosen': '-66.409', 'loss/train': '0.047472', 'examples_per_second': '4.2055', 'grad_norm': '11.312', 'counters/examples': 38592, 'counters/updates': 2412}
skipping logging after 38608 examples to avoid logging too frequently
skipping logging after 38624 examples to avoid logging too frequently
skipping logging after 38640 examples to avoid logging too frequently
train stats after 38656 examples: {'rewards_train/chosen': '-2.2098', 'rewards_train/rejected': '-10.153', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.9436', 'logps_train/rejected': '-218.45', 'logps_train/chosen': '-60.008', 'loss/train': '0.055279', 'examples_per_second': '5.8956', 'grad_norm': '5.7812', 'counters/examples': 38656, 'counters/updates': 2416}
skipping logging after 38672 examples to avoid logging too frequently
skipping logging after 38688 examples to avoid logging too frequently
skipping logging after 38704 examples to avoid logging too frequently
train stats after 38720 examples: {'rewards_train/chosen': '-2.2789', 'rewards_train/rejected': '-11.573', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '9.29', 'logps_train/rejected': '-252.04', 'logps_train/chosen': '-71.804', 'loss/train': '0.083641', 'examples_per_second': '6.1611', 'grad_norm': '13.312', 'counters/examples': 38720, 'counters/updates': 2420}
skipping logging after 38736 examples to avoid logging too frequently
skipping logging after 38752 examples to avoid logging too frequently
skipping logging after 38768 examples to avoid logging too frequently
train stats after 38784 examples: {'rewards_train/chosen': '-2.4341', 'rewards_train/rejected': '-11.007', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.5721', 'logps_train/rejected': '-260.67', 'logps_train/chosen': '-60.927', 'loss/train': '0.11199', 'examples_per_second': '5.1834', 'grad_norm': '16.375', 'counters/examples': 38784, 'counters/updates': 2424}
skipping logging after 38800 examples to avoid logging too frequently
skipping logging after 38816 examples to avoid logging too frequently
skipping logging after 38832 examples to avoid logging too frequently
train stats after 38848 examples: {'rewards_train/chosen': '-1.6333', 'rewards_train/rejected': '-10.268', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '8.6351', 'logps_train/rejected': '-237.52', 'logps_train/chosen': '-55.341', 'loss/train': '0.052039', 'examples_per_second': '5.2886', 'grad_norm': '4.7188', 'counters/examples': 38848, 'counters/updates': 2428}
skipping logging after 38864 examples to avoid logging too frequently
skipping logging after 38880 examples to avoid logging too frequently
skipping logging after 38896 examples to avoid logging too frequently
train stats after 38912 examples: {'rewards_train/chosen': '-2.3613', 'rewards_train/rejected': '-10.022', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.664', 'logps_train/rejected': '-242.14', 'logps_train/chosen': '-60.762', 'loss/train': '0.059976', 'examples_per_second': '4.9577', 'grad_norm': '8.125', 'counters/examples': 38912, 'counters/updates': 2432}
skipping logging after 38928 examples to avoid logging too frequently
skipping logging after 38944 examples to avoid logging too frequently
skipping logging after 38960 examples to avoid logging too frequently
train stats after 38976 examples: {'rewards_train/chosen': '-2.261', 'rewards_train/rejected': '-10.174', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.9126', 'logps_train/rejected': '-231.93', 'logps_train/chosen': '-60.762', 'loss/train': '0.023021', 'examples_per_second': '4.9557', 'grad_norm': '3.9688', 'counters/examples': 38976, 'counters/updates': 2436}
skipping logging after 38992 examples to avoid logging too frequently
skipping logging after 39008 examples to avoid logging too frequently
skipping logging after 39024 examples to avoid logging too frequently
train stats after 39040 examples: {'rewards_train/chosen': '-2.5741', 'rewards_train/rejected': '-10.714', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.1382', 'logps_train/rejected': '-235.19', 'logps_train/chosen': '-65.867', 'loss/train': '0.047131', 'examples_per_second': '5.9554', 'grad_norm': '7.0312', 'counters/examples': 39040, 'counters/updates': 2440}
skipping logging after 39056 examples to avoid logging too frequently
skipping logging after 39072 examples to avoid logging too frequently
skipping logging after 39088 examples to avoid logging too frequently
train stats after 39104 examples: {'rewards_train/chosen': '-2.1387', 'rewards_train/rejected': '-11.036', 'rewards_train/accuracies': '1', 'rewards_train/margins': '8.8997', 'logps_train/rejected': '-253.06', 'logps_train/chosen': '-61.736', 'loss/train': '0.036433', 'examples_per_second': '6.0032', 'grad_norm': '6.0312', 'counters/examples': 39104, 'counters/updates': 2444}
skipping logging after 39120 examples to avoid logging too frequently
skipping logging after 39136 examples to avoid logging too frequently
skipping logging after 39152 examples to avoid logging too frequently
train stats after 39168 examples: {'rewards_train/chosen': '-2.1942', 'rewards_train/rejected': '-10.392', 'rewards_train/accuracies': '0.95312', 'rewards_train/margins': '8.199', 'logps_train/rejected': '-233.89', 'logps_train/chosen': '-63.627', 'loss/train': '0.10414', 'examples_per_second': '4.7114', 'grad_norm': '15.875', 'counters/examples': 39168, 'counters/updates': 2448}
skipping logging after 39184 examples to avoid logging too frequently
skipping logging after 39200 examples to avoid logging too frequently
skipping logging after 39216 examples to avoid logging too frequently
train stats after 39232 examples: {'rewards_train/chosen': '-1.9777', 'rewards_train/rejected': '-9.9224', 'rewards_train/accuracies': '0.98438', 'rewards_train/margins': '7.9459', 'logps_train/rejected': '-254.18', 'logps_train/chosen': '-58.418', 'loss/train': '0.040464', 'examples_per_second': '4.3654', 'grad_norm': '6.5312', 'counters/examples': 39232, 'counters/updates': 2452}
skipping logging after 39248 examples to avoid logging too frequently
skipping logging after 39264 examples to avoid logging too frequently
skipping logging after 39280 examples to avoid logging too frequently
train stats after 39296 examples: {'rewards_train/chosen': '-1.7949', 'rewards_train/rejected': '-10.159', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.361', 'logps_train/rejected': '-244.6', 'logps_train/chosen': '-70.457', 'loss/train': '0.029716', 'examples_per_second': '5.4918', 'grad_norm': '4.0625', 'counters/examples': 39296, 'counters/updates': 2456}
skipping logging after 39312 examples to avoid logging too frequently
skipping logging after 39328 examples to avoid logging too frequently
skipping logging after 39344 examples to avoid logging too frequently
train stats after 39360 examples: {'rewards_train/chosen': '-1.9571', 'rewards_train/rejected': '-10.072', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.1143', 'logps_train/rejected': '-249.36', 'logps_train/chosen': '-58.881', 'loss/train': '0.1025', 'examples_per_second': '4.1857', 'grad_norm': '14.375', 'counters/examples': 39360, 'counters/updates': 2460}
skipping logging after 39376 examples to avoid logging too frequently
skipping logging after 39392 examples to avoid logging too frequently
skipping logging after 39408 examples to avoid logging too frequently
train stats after 39424 examples: {'rewards_train/chosen': '-1.998', 'rewards_train/rejected': '-9.6524', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.6572', 'logps_train/rejected': '-240.86', 'logps_train/chosen': '-70.95', 'loss/train': '0.11106', 'examples_per_second': '4.6539', 'grad_norm': '18.75', 'counters/examples': 39424, 'counters/updates': 2464}
skipping logging after 39440 examples to avoid logging too frequently
skipping logging after 39456 examples to avoid logging too frequently
skipping logging after 39472 examples to avoid logging too frequently
train stats after 39488 examples: {'rewards_train/chosen': '-2.1497', 'rewards_train/rejected': '-9.4619', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.3118', 'logps_train/rejected': '-223.9', 'logps_train/chosen': '-54.356', 'loss/train': '0.076899', 'examples_per_second': '5.566', 'grad_norm': '11.5', 'counters/examples': 39488, 'counters/updates': 2468}
skipping logging after 39504 examples to avoid logging too frequently
skipping logging after 39520 examples to avoid logging too frequently
skipping logging after 39536 examples to avoid logging too frequently
train stats after 39552 examples: {'rewards_train/chosen': '-2.267', 'rewards_train/rejected': '-10.861', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '8.5923', 'logps_train/rejected': '-257.52', 'logps_train/chosen': '-61.424', 'loss/train': '0.06147', 'examples_per_second': '4.8805', 'grad_norm': '11.812', 'counters/examples': 39552, 'counters/updates': 2472}
skipping logging after 39568 examples to avoid logging too frequently
skipping logging after 39584 examples to avoid logging too frequently
skipping logging after 39600 examples to avoid logging too frequently
train stats after 39616 examples: {'rewards_train/chosen': '-2.14', 'rewards_train/rejected': '-9.7297', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.5892', 'logps_train/rejected': '-238.94', 'logps_train/chosen': '-63.114', 'loss/train': '0.039321', 'examples_per_second': '4.6696', 'grad_norm': '6.5625', 'counters/examples': 39616, 'counters/updates': 2476}
skipping logging after 39632 examples to avoid logging too frequently
skipping logging after 39648 examples to avoid logging too frequently
skipping logging after 39664 examples to avoid logging too frequently
train stats after 39680 examples: {'rewards_train/chosen': '-2.3363', 'rewards_train/rejected': '-9.8287', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.4928', 'logps_train/rejected': '-228.79', 'logps_train/chosen': '-57.552', 'loss/train': '0.14373', 'examples_per_second': '4.4333', 'grad_norm': '13.875', 'counters/examples': 39680, 'counters/updates': 2480}
skipping logging after 39696 examples to avoid logging too frequently
skipping logging after 39712 examples to avoid logging too frequently
skipping logging after 39728 examples to avoid logging too frequently
train stats after 39744 examples: {'rewards_train/chosen': '-1.9395', 'rewards_train/rejected': '-9.7754', 'rewards_train/accuracies': '0.90625', 'rewards_train/margins': '7.8336', 'logps_train/rejected': '-255.34', 'logps_train/chosen': '-58.839', 'loss/train': '0.11359', 'examples_per_second': '5.2237', 'grad_norm': '8.6875', 'counters/examples': 39744, 'counters/updates': 2484}
skipping logging after 39760 examples to avoid logging too frequently
skipping logging after 39776 examples to avoid logging too frequently
skipping logging after 39792 examples to avoid logging too frequently
train stats after 39808 examples: {'rewards_train/chosen': '-1.9781', 'rewards_train/rejected': '-9.0776', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '7.0986', 'logps_train/rejected': '-219.67', 'logps_train/chosen': '-54.143', 'loss/train': '0.12016', 'examples_per_second': '5.1432', 'grad_norm': '10.375', 'counters/examples': 39808, 'counters/updates': 2488}
skipping logging after 39824 examples to avoid logging too frequently
skipping logging after 39840 examples to avoid logging too frequently
skipping logging after 39856 examples to avoid logging too frequently
train stats after 39872 examples: {'rewards_train/chosen': '-2.1448', 'rewards_train/rejected': '-9.9944', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '7.8516', 'logps_train/rejected': '-262.71', 'logps_train/chosen': '-66.207', 'loss/train': '0.066373', 'examples_per_second': '5.0446', 'grad_norm': '11.062', 'counters/examples': 39872, 'counters/updates': 2492}
skipping logging after 39888 examples to avoid logging too frequently
skipping logging after 39904 examples to avoid logging too frequently
skipping logging after 39920 examples to avoid logging too frequently
train stats after 39936 examples: {'rewards_train/chosen': '-2.2311', 'rewards_train/rejected': '-8.9321', 'rewards_train/accuracies': '0.96875', 'rewards_train/margins': '6.7026', 'logps_train/rejected': '-194.38', 'logps_train/chosen': '-61.456', 'loss/train': '0.096756', 'examples_per_second': '5.2931', 'grad_norm': '11.25', 'counters/examples': 39936, 'counters/updates': 2496}
skipping logging after 39952 examples to avoid logging too frequently
skipping logging after 39968 examples to avoid logging too frequently
skipping logging after 39984 examples to avoid logging too frequently
train stats after 40000 examples: {'rewards_train/chosen': '-2.4148', 'rewards_train/rejected': '-9.0229', 'rewards_train/accuracies': '0.9375', 'rewards_train/margins': '6.6088', 'logps_train/rejected': '-212.47', 'logps_train/chosen': '-58.343', 'loss/train': '0.2067', 'examples_per_second': '5.4823', 'grad_norm': '12.5', 'counters/examples': 40000, 'counters/updates': 2500}
Running evaluation after 40000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<01:00,  1.95s/it]Computing eval metrics:   6%|▋         | 2/32 [00:04<01:00,  2.02s/it]Computing eval metrics:   9%|▉         | 3/32 [00:05<00:53,  1.84s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:07<00:51,  1.86s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:41,  1.52s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:10<00:42,  1.64s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:11<00:36,  1.48s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:13<00:37,  1.56s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:14<00:35,  1.56s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:16<00:32,  1.49s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:17<00:32,  1.56s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:19<00:29,  1.50s/it]Computing eval metrics:  41%|████      | 13/32 [00:20<00:27,  1.45s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:21<00:25,  1.44s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:22<00:22,  1.30s/it]Computing eval metrics:  50%|█████     | 16/32 [00:24<00:19,  1.24s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:25<00:19,  1.33s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:26<00:18,  1.34s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:28<00:16,  1.29s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:29<00:14,  1.23s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:30<00:13,  1.27s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:31<00:11,  1.15s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:32<00:10,  1.22s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:34<00:10,  1.29s/it]