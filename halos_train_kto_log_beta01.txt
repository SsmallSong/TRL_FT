4
/home/wxt/.conda/envs/halos3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Making experiment directory /home/wxt/.cache/huggingface/hub/llama2_7b_kto_halos_beta01
no FSDP port specified; using open port for FSDP: 43093
seed: 1
exp_name: llama2_7b_kto_halos_beta01
datasets:
- hh
mode: train
debug: false
use_fsdp: true
fsdp_port: 43093
wandb:
  enabled: true
  entity: null
  project: archangel
cache_dir: /home/wxt/.cache/huggingface/hub
local_run_dir: /home/wxt/.cache/huggingface/hub/llama2_7b_kto_halos_beta01
do_first_eval: true
minimum_log_interval_secs: 1.0
intermediate_checkpoints: false
trainer: BasicTrainer
lr: 1.0e-05
n_epochs: 1
n_examples: null
optimizer: RMSprop
warmup_steps: 150
eval_every: 4000
n_samples: 128
samples_dir: samples/
n_eval_examples: 512
saved_policy: /home/wxt/.cache/huggingface/hub/llama2_7b_kto_halos_beta01/LATEST/policy.pt
top_p: 0.95
human_prefix: '

  <|user|>

  '
assistant_prefix: '

  <|assistant|>

  '
human_suffix: ''
assistant_suffix: ''
frac_unique_desirable: 1.0
frac_unique_undesirable: 1.0
model:
  name_or_path: daryl149/llama-2-7b-hf
  tokenizer_name_or_path: null
  load_from: /home/wxt/.cache/huggingface/hub/llama2_7b_sft_halos_2_3/LATEST/policy.pt
  block_name: LlamaDecoderLayer
  policy_dtype: bfloat16
  fsdp_policy_mp: null
  reference_dtype: bfloat16
  max_grad_norm: 10.0
  v_head_max_grad_norm: 0.1
  max_length: 1024
  max_prompt_length: 512
  activation_checkpointing: true
  batch_size: 16
  gradient_accumulation_steps: 4
  eval_batch_size: 16
  use_flash_attention: false
loss:
  name: kto
  beta: 0.1
  trainer: KTOTrainer
  dataloader: UnpairedPreferenceDataLoader
  use_reference_model: true
  desirable_weight: 1.0
  undesirable_weight: 1.0

================================================================================
Writing to design-agent-09:/home/wxt/.cache/huggingface/hub/llama2_7b_kto_halos_beta01
================================================================================
building policy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
building reference model
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]
loading pre-trained weights at step 159968 from /home/wxt/.cache/huggingface/hub/llama2_7b_sft_halos_2_3/LATEST/policy.pt with metrics {}
loaded pre-trained weights
Loading tokenizer daryl149/llama-2-7b-hf
0 special tokens added
Loading HH dataset (train split) from Huggingface...
Processing HH:   0%|          | 0/160800 [00:00<?, ?it/s]Processing HH:   1%|          | 1496/160800 [00:00<00:10, 14951.03it/s]Processing HH:   2%|▏         | 2992/160800 [00:00<00:10, 14874.73it/s]Processing HH:   3%|▎         | 4541/160800 [00:00<00:10, 15153.51it/s]Processing HH:   4%|▍         | 6122/160800 [00:00<00:10, 15408.47it/s]Processing HH:   5%|▍         | 7663/160800 [00:00<00:10, 15117.99it/s]Processing HH:   6%|▌         | 9186/160800 [00:00<00:10, 15155.11it/s]Processing HH:   7%|▋         | 10725/160800 [00:00<00:09, 15229.56it/s]Processing HH:   8%|▊         | 12249/160800 [00:00<00:09, 14909.30it/s]Processing HH:   9%|▊         | 13742/160800 [00:00<00:10, 14462.62it/s]Processing HH:   9%|▉         | 15192/160800 [00:01<00:13, 10507.31it/s]Processing HH:  10%|█         | 16704/160800 [00:01<00:12, 11596.30it/s]Processing HH:  11%|█▏        | 18221/160800 [00:01<00:11, 12495.46it/s]Processing HH:  12%|█▏        | 19728/160800 [00:01<00:10, 13176.55it/s]Processing HH:  13%|█▎        | 21192/160800 [00:01<00:10, 13577.99it/s]Processing HH:  14%|█▍        | 22753/160800 [00:01<00:09, 14145.05it/s]Processing HH:  15%|█▌        | 24298/160800 [00:01<00:09, 14519.26it/s]Processing HH:  16%|█▌        | 25787/160800 [00:01<00:09, 14583.33it/s]Processing HH:  17%|█▋        | 27345/160800 [00:01<00:08, 14872.04it/s]Processing HH:  18%|█▊        | 28851/160800 [00:02<00:08, 14893.21it/s]Processing HH:  19%|█▉        | 30354/160800 [00:02<00:08, 14810.79it/s]Processing HH:  20%|█▉        | 31862/160800 [00:02<00:08, 14886.84it/s]Processing HH:  21%|██        | 33403/160800 [00:02<00:08, 15040.89it/s]Processing HH:  22%|██▏       | 34912/160800 [00:02<00:11, 10650.80it/s]Processing HH:  23%|██▎       | 36411/160800 [00:02<00:10, 11653.70it/s]Processing HH:  24%|██▎       | 37898/160800 [00:02<00:09, 12451.75it/s]Processing HH:  24%|██▍       | 39376/160800 [00:02<00:09, 13059.01it/s]Processing HH:  25%|██▌       | 40862/160800 [00:02<00:08, 13547.34it/s]Processing HH:  26%|██▋       | 42325/160800 [00:03<00:08, 13849.33it/s]Processing HH:  27%|██▋       | 43764/160800 [00:03<00:08, 13904.30it/s]Processing HH:  28%|██▊       | 45192/160800 [00:03<00:08, 13934.52it/s]Processing HH:  29%|██▉       | 46631/160800 [00:03<00:08, 14066.38it/s]Processing HH:  30%|██▉       | 48057/160800 [00:03<00:08, 14062.75it/s]Processing HH:  31%|███       | 49477/160800 [00:03<00:07, 14004.13it/s]Processing HH:  32%|███▏      | 50887/160800 [00:03<00:07, 14014.13it/s]Processing HH:  33%|███▎      | 52295/160800 [00:03<00:07, 14010.23it/s]Processing HH:  33%|███▎      | 53750/160800 [00:03<00:07, 14165.45it/s]Processing HH:  34%|███▍      | 55199/160800 [00:04<00:07, 14261.47it/s]Processing HH:  35%|███▌      | 56628/160800 [00:04<00:07, 14209.87it/s]Processing HH:  36%|███▌      | 58051/160800 [00:04<00:10, 9820.86it/s] Processing HH:  37%|███▋      | 59434/160800 [00:04<00:09, 10731.69it/s]Processing HH:  38%|███▊      | 60772/160800 [00:04<00:08, 11378.16it/s]Processing HH:  39%|███▊      | 62175/160800 [00:04<00:08, 12064.24it/s]Processing HH:  40%|███▉      | 63572/160800 [00:04<00:07, 12579.22it/s]Processing HH:  40%|████      | 64975/160800 [00:04<00:07, 12981.77it/s]Processing HH:  41%|████▏     | 66403/160800 [00:04<00:07, 13350.19it/s]Processing HH:  42%|████▏     | 67806/160800 [00:05<00:06, 13545.35it/s]Processing HH:  43%|████▎     | 69207/160800 [00:05<00:06, 13680.79it/s]Processing HH:  44%|████▍     | 70600/160800 [00:05<00:06, 13751.38it/s]Processing HH:  45%|████▍     | 72041/160800 [00:05<00:06, 13945.91it/s]Processing HH:  46%|████▌     | 73447/160800 [00:05<00:06, 13973.12it/s]Processing HH:  47%|████▋     | 74852/160800 [00:05<00:06, 13906.54it/s]Processing HH:  47%|████▋     | 76248/160800 [00:05<00:06, 13859.63it/s]Processing HH:  48%|████▊     | 77661/160800 [00:05<00:05, 13939.16it/s]Processing HH:  49%|████▉     | 79066/160800 [00:05<00:05, 13970.85it/s]Processing HH:  50%|█████     | 80465/160800 [00:05<00:05, 13932.54it/s]Processing HH:  51%|█████     | 81910/160800 [00:06<00:05, 14084.17it/s]Processing HH:  52%|█████▏    | 83320/160800 [00:06<00:05, 14054.69it/s]Processing HH:  53%|█████▎    | 84753/160800 [00:06<00:05, 14135.46it/s]Processing HH:  54%|█████▎    | 86188/160800 [00:06<00:05, 14198.23it/s]Processing HH:  54%|█████▍    | 87609/160800 [00:06<00:10, 7311.96it/s] Processing HH:  55%|█████▌    | 88706/160800 [00:06<00:09, 7545.84it/s]Processing HH:  56%|█████▌    | 89725/160800 [00:07<00:09, 7766.23it/s]Processing HH:  56%|█████▋    | 90694/160800 [00:07<00:08, 7923.15it/s]Processing HH:  57%|█████▋    | 91625/160800 [00:07<00:08, 8003.32it/s]Processing HH:  58%|█████▊    | 92524/160800 [00:07<00:08, 8099.99it/s]Processing HH:  58%|█████▊    | 93405/160800 [00:07<00:08, 8056.69it/s]Processing HH:  59%|█████▊    | 94260/160800 [00:07<00:08, 8119.17it/s]Processing HH:  59%|█████▉    | 95108/160800 [00:07<00:08, 8189.09it/s]Processing HH:  60%|█████▉    | 95953/160800 [00:07<00:07, 8221.91it/s]Processing HH:  60%|██████    | 96817/160800 [00:07<00:07, 8337.05it/s]Processing HH:  61%|██████    | 97685/160800 [00:07<00:07, 8435.48it/s]Processing HH:  61%|██████▏   | 98539/160800 [00:08<00:07, 8397.87it/s]Processing HH:  62%|██████▏   | 99386/160800 [00:08<00:07, 8356.67it/s]Processing HH:  62%|██████▏   | 100227/160800 [00:08<00:07, 8334.29it/s]Processing HH:  63%|██████▎   | 101087/160800 [00:08<00:07, 8411.48it/s]Processing HH:  63%|██████▎   | 101931/160800 [00:08<00:07, 8322.07it/s]Processing HH:  64%|██████▍   | 102780/160800 [00:08<00:06, 8371.33it/s]Processing HH:  64%|██████▍   | 103644/160800 [00:08<00:06, 8450.72it/s]Processing HH:  65%|██████▍   | 104491/160800 [00:08<00:06, 8397.29it/s]Processing HH:  66%|██████▌   | 105332/160800 [00:08<00:06, 8399.69it/s]Processing HH:  66%|██████▌   | 106189/160800 [00:08<00:06, 8446.16it/s]Processing HH:  67%|██████▋   | 107035/160800 [00:09<00:06, 8407.05it/s]Processing HH:  67%|██████▋   | 107877/160800 [00:09<00:06, 8386.58it/s]Processing HH:  68%|██████▊   | 108892/160800 [00:09<00:05, 8909.46it/s]Processing HH:  69%|██████▊   | 110156/160800 [00:09<00:05, 10017.83it/s]Processing HH:  69%|██████▉   | 111342/160800 [00:09<00:04, 10565.98it/s]Processing HH:  70%|███████   | 112588/160800 [00:09<00:04, 11130.37it/s]Processing HH:  71%|███████   | 113810/160800 [00:09<00:04, 11453.13it/s]Processing HH:  72%|███████▏  | 115085/160800 [00:09<00:03, 11838.38it/s]Processing HH:  72%|███████▏  | 116333/160800 [00:09<00:03, 12029.58it/s]Processing HH:  73%|███████▎  | 117583/160800 [00:09<00:03, 12168.91it/s]Processing HH:  74%|███████▍  | 118812/160800 [00:10<00:03, 12204.17it/s]Processing HH:  75%|███████▍  | 120081/160800 [00:10<00:03, 12348.85it/s]Processing HH:  75%|███████▌  | 121350/160800 [00:10<00:03, 12448.99it/s]Processing HH:  76%|███████▋  | 122637/160800 [00:10<00:03, 12574.12it/s]Processing HH:  77%|███████▋  | 123895/160800 [00:10<00:04, 7971.38it/s] Processing HH:  78%|███████▊  | 125139/160800 [00:10<00:03, 8923.07it/s]Processing HH:  79%|███████▊  | 126366/160800 [00:10<00:03, 9702.77it/s]Processing HH:  79%|███████▉  | 127625/160800 [00:10<00:03, 10424.95it/s]Processing HH:  80%|████████  | 128903/160800 [00:11<00:02, 11043.18it/s]Processing HH:  81%|████████  | 130171/160800 [00:11<00:02, 11489.83it/s]Processing HH:  82%|████████▏ | 131423/160800 [00:11<00:02, 11777.24it/s]Processing HH:  82%|████████▏ | 132652/160800 [00:11<00:02, 11915.00it/s]Processing HH:  83%|████████▎ | 133880/160800 [00:11<00:02, 11968.57it/s]Processing HH:  84%|████████▍ | 135103/160800 [00:11<00:02, 12042.93it/s]Processing HH:  85%|████████▍ | 136359/160800 [00:11<00:02, 12193.55it/s]Processing HH:  86%|████████▌ | 137592/160800 [00:11<00:01, 12038.21it/s]Processing HH:  86%|████████▋ | 138806/160800 [00:11<00:01, 11859.70it/s]Processing HH:  87%|████████▋ | 139999/160800 [00:12<00:01, 11821.04it/s]Processing HH:  88%|████████▊ | 141223/160800 [00:12<00:01, 11942.93it/s]Processing HH:  89%|████████▊ | 142469/160800 [00:12<00:01, 12094.14it/s]Processing HH:  89%|████████▉ | 143724/160800 [00:12<00:01, 12228.83it/s]Processing HH:  90%|█████████ | 144966/160800 [00:12<00:01, 12284.01it/s]Processing HH:  91%|█████████ | 146196/160800 [00:12<00:01, 12128.39it/s]Processing HH:  92%|█████████▏| 147411/160800 [00:12<00:01, 12055.32it/s]Processing HH:  92%|█████████▏| 148659/160800 [00:12<00:00, 12177.20it/s]Processing HH:  93%|█████████▎| 149898/160800 [00:12<00:00, 12239.25it/s]Processing HH:  94%|█████████▍| 151142/160800 [00:12<00:00, 12297.31it/s]Processing HH:  95%|█████████▍| 152395/160800 [00:13<00:00, 12366.52it/s]Processing HH:  96%|█████████▌| 153633/160800 [00:13<00:00, 12308.40it/s]Processing HH:  96%|█████████▋| 154879/160800 [00:13<00:00, 12351.64it/s]Processing HH:  97%|█████████▋| 156130/160800 [00:13<00:00, 12398.11it/s]Processing HH:  98%|█████████▊| 157371/160800 [00:13<00:00, 12399.74it/s]Processing HH:  99%|█████████▊| 158612/160800 [00:13<00:00, 12112.67it/s]Processing HH:  99%|█████████▉| 159878/160800 [00:13<00:00, 12272.76it/s]Processing HH: 100%|██████████| 160800/160800 [00:13<00:00, 11739.56it/s]
Loading HH dataset (test split) from Huggingface...
Processing HH:   0%|          | 0/8552 [00:00<?, ?it/s]Processing HH:  17%|█▋        | 1465/8552 [00:00<00:00, 14642.26it/s]Processing HH:  34%|███▍      | 2930/8552 [00:00<00:00, 14612.89it/s]Processing HH:  51%|█████▏    | 4392/8552 [00:00<00:00, 14449.31it/s]Processing HH:  68%|██████▊   | 5838/8552 [00:00<00:00, 11811.79it/s]Processing HH:  83%|████████▎ | 7076/8552 [00:00<00:00, 11920.32it/s]Processing HH:  97%|█████████▋| 8306/8552 [00:00<00:00, 6227.38it/s] Processing HH: 100%|██████████| 8552/8552 [00:00<00:00, 8686.82it/s]
starting 4 processes for FSDP training
setting RLIMIT_NOFILE soft limit to 1048576 from 1024
4
0 initializing distributed
Creating trainer on process 0 with world size 4
Finished generating 512 examples on test split
Loaded 32 eval batches of size 16
Sharding models...
Attempting to enable activation checkpointing...
Applying activation checkpointing wrapper to policy...
FSDP activation checkpointing enabled!
Loaded model on rank 0
Using RMSprop optimizer with learning rate 1e-05
Running evaluation after 0 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]/home/wxt/.conda/envs/halos3/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/wxt/.conda/envs/halos3/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/wxt/.conda/envs/halos3/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/wxt/.conda/envs/halos3/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Computing eval metrics:   3%|▎         | 1/32 [00:01<00:51,  1.67s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:42,  1.41s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:35,  1.24s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:40,  1.46s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.65s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.46s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:33,  1.35s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:35,  1.49s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:33,  1.45s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.38s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:30,  1.45s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:27,  1.37s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:25,  1.35s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:23,  1.31s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.20s/it]Computing eval metrics:  50%|█████     | 16/32 [00:21<00:19,  1.25s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.23s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.22s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.12s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.13s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.13s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.16s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:12,  1.42s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:11,  1.48s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.34s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:34<00:08,  1.39s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:35<00:06,  1.29s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.29s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.18s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.17s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.14s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.11s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.29s/it]
eval after 0: {'rewards_eval/chosen': '0', 'rewards_eval/rejected': '0', 'rewards_eval/margins': '0', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.5'}
skipping logging after 16 examples to avoid logging too frequently
skipping logging after 32 examples to avoid logging too frequently
skipping logging after 48 examples to avoid logging too frequently
train stats after 64 examples: {'rewards_train/chosen': '0', 'rewards_train/rejected': '0', 'rewards_train/margins': '0', 'rewards_train/KL_estimate': '0', 'loss/train': '0.5', 'examples_per_second': '5.3972', 'grad_norm': '9.5', 'counters/examples': 64, 'counters/updates': 4}
skipping logging after 80 examples to avoid logging too frequently
skipping logging after 96 examples to avoid logging too frequently
skipping logging after 112 examples to avoid logging too frequently
train stats after 128 examples: {'rewards_train/chosen': '0.0052908', 'rewards_train/rejected': '-0.00019455', 'rewards_train/margins': '0.0023384', 'rewards_train/KL_estimate': '0.025879', 'loss/train': '0.49915', 'examples_per_second': '4.4023', 'grad_norm': '9', 'counters/examples': 128, 'counters/updates': 8}
skipping logging after 144 examples to avoid logging too frequently
skipping logging after 160 examples to avoid logging too frequently
skipping logging after 176 examples to avoid logging too frequently
train stats after 192 examples: {'rewards_train/chosen': '0.0068415', 'rewards_train/rejected': '-0.0052416', 'rewards_train/margins': '0.01506', 'rewards_train/KL_estimate': '0.010742', 'loss/train': '0.49841', 'examples_per_second': '4.9015', 'grad_norm': '9.8125', 'counters/examples': 192, 'counters/updates': 12}
skipping logging after 208 examples to avoid logging too frequently
skipping logging after 224 examples to avoid logging too frequently
skipping logging after 240 examples to avoid logging too frequently
train stats after 256 examples: {'rewards_train/chosen': '0.0040229', 'rewards_train/rejected': '-0.016574', 'rewards_train/margins': '0.020844', 'rewards_train/KL_estimate': '0.026367', 'loss/train': '0.49689', 'examples_per_second': '4.8029', 'grad_norm': '9.9375', 'counters/examples': 256, 'counters/updates': 16}
skipping logging after 272 examples to avoid logging too frequently
skipping logging after 288 examples to avoid logging too frequently
skipping logging after 304 examples to avoid logging too frequently
train stats after 320 examples: {'rewards_train/chosen': '0.012188', 'rewards_train/rejected': '-0.0071032', 'rewards_train/margins': '0.032959', 'rewards_train/KL_estimate': '0.021484', 'loss/train': '0.49768', 'examples_per_second': '4.5577', 'grad_norm': '9.75', 'counters/examples': 320, 'counters/updates': 20}
skipping logging after 336 examples to avoid logging too frequently
skipping logging after 352 examples to avoid logging too frequently
skipping logging after 368 examples to avoid logging too frequently
train stats after 384 examples: {'rewards_train/chosen': '0.014698', 'rewards_train/rejected': '-0.026383', 'rewards_train/margins': '0.06163', 'rewards_train/KL_estimate': '0.0039062', 'loss/train': '0.4953', 'examples_per_second': '5.961', 'grad_norm': '8.4375', 'counters/examples': 384, 'counters/updates': 24}
skipping logging after 400 examples to avoid logging too frequently
skipping logging after 416 examples to avoid logging too frequently
skipping logging after 432 examples to avoid logging too frequently
train stats after 448 examples: {'rewards_train/chosen': '0.015848', 'rewards_train/rejected': '-0.0089102', 'rewards_train/margins': '0.02832', 'rewards_train/KL_estimate': '0.0024414', 'loss/train': '0.49707', 'examples_per_second': '4.4845', 'grad_norm': '9.1875', 'counters/examples': 448, 'counters/updates': 28}
skipping logging after 464 examples to avoid logging too frequently
skipping logging after 480 examples to avoid logging too frequently
skipping logging after 496 examples to avoid logging too frequently
train stats after 512 examples: {'rewards_train/chosen': '0.012286', 'rewards_train/rejected': '-0.049286', 'rewards_train/margins': '0.059753', 'rewards_train/KL_estimate': '0.0058594', 'loss/train': '0.49176', 'examples_per_second': '4.2464', 'grad_norm': '9.0625', 'counters/examples': 512, 'counters/updates': 32}
skipping logging after 528 examples to avoid logging too frequently
skipping logging after 544 examples to avoid logging too frequently
skipping logging after 560 examples to avoid logging too frequently
train stats after 576 examples: {'rewards_train/chosen': '0.019995', 'rewards_train/rejected': '-0.065605', 'rewards_train/margins': '0.08728', 'rewards_train/KL_estimate': '0', 'loss/train': '0.48975', 'examples_per_second': '5.2142', 'grad_norm': '8.1875', 'counters/examples': 576, 'counters/updates': 36}
skipping logging after 592 examples to avoid logging too frequently
skipping logging after 608 examples to avoid logging too frequently
skipping logging after 624 examples to avoid logging too frequently
train stats after 640 examples: {'rewards_train/chosen': '0.030313', 'rewards_train/rejected': '-0.090068', 'rewards_train/margins': '0.11658', 'rewards_train/KL_estimate': '0.0078125', 'loss/train': '0.48376', 'examples_per_second': '4.5936', 'grad_norm': '10.25', 'counters/examples': 640, 'counters/updates': 40}
skipping logging after 656 examples to avoid logging too frequently
skipping logging after 672 examples to avoid logging too frequently
skipping logging after 688 examples to avoid logging too frequently
train stats after 704 examples: {'rewards_train/chosen': '0.019978', 'rewards_train/rejected': '-0.10137', 'rewards_train/margins': '0.12134', 'rewards_train/KL_estimate': '0', 'loss/train': '0.48792', 'examples_per_second': '4.565', 'grad_norm': '8.6875', 'counters/examples': 704, 'counters/updates': 44}
skipping logging after 720 examples to avoid logging too frequently
skipping logging after 736 examples to avoid logging too frequently
skipping logging after 752 examples to avoid logging too frequently
train stats after 768 examples: {'rewards_train/chosen': '0.028965', 'rewards_train/rejected': '-0.0874', 'rewards_train/margins': '0.11719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.48621', 'examples_per_second': '4.4821', 'grad_norm': '7.8438', 'counters/examples': 768, 'counters/updates': 48}
skipping logging after 784 examples to avoid logging too frequently
skipping logging after 800 examples to avoid logging too frequently
skipping logging after 816 examples to avoid logging too frequently
train stats after 832 examples: {'rewards_train/chosen': '0.055824', 'rewards_train/rejected': '-0.13458', 'rewards_train/margins': '0.19165', 'rewards_train/KL_estimate': '0', 'loss/train': '0.47504', 'examples_per_second': '4.8467', 'grad_norm': '10.188', 'counters/examples': 832, 'counters/updates': 52}
skipping logging after 848 examples to avoid logging too frequently
skipping logging after 864 examples to avoid logging too frequently
skipping logging after 880 examples to avoid logging too frequently
train stats after 896 examples: {'rewards_train/chosen': '0.056437', 'rewards_train/rejected': '-0.13827', 'rewards_train/margins': '0.19214', 'rewards_train/KL_estimate': '0', 'loss/train': '0.47589', 'examples_per_second': '4.777', 'grad_norm': '8.75', 'counters/examples': 896, 'counters/updates': 56}
skipping logging after 912 examples to avoid logging too frequently
skipping logging after 928 examples to avoid logging too frequently
skipping logging after 944 examples to avoid logging too frequently
train stats after 960 examples: {'rewards_train/chosen': '0.053535', 'rewards_train/rejected': '-0.13059', 'rewards_train/margins': '0.1886', 'rewards_train/KL_estimate': '0', 'loss/train': '0.47723', 'examples_per_second': '4.9257', 'grad_norm': '7.6562', 'counters/examples': 960, 'counters/updates': 60}
skipping logging after 976 examples to avoid logging too frequently
skipping logging after 992 examples to avoid logging too frequently
skipping logging after 1008 examples to avoid logging too frequently
train stats after 1024 examples: {'rewards_train/chosen': '0.077203', 'rewards_train/rejected': '-0.14272', 'rewards_train/margins': '0.22217', 'rewards_train/KL_estimate': '0.0048828', 'loss/train': '0.47308', 'examples_per_second': '4.5569', 'grad_norm': '8.5625', 'counters/examples': 1024, 'counters/updates': 64}
skipping logging after 1040 examples to avoid logging too frequently
skipping logging after 1056 examples to avoid logging too frequently
skipping logging after 1072 examples to avoid logging too frequently
train stats after 1088 examples: {'rewards_train/chosen': '0.07699', 'rewards_train/rejected': '-0.13227', 'rewards_train/margins': '0.21118', 'rewards_train/KL_estimate': '0', 'loss/train': '0.47449', 'examples_per_second': '4.9612', 'grad_norm': '7.1562', 'counters/examples': 1088, 'counters/updates': 68}
skipping logging after 1104 examples to avoid logging too frequently
skipping logging after 1120 examples to avoid logging too frequently
skipping logging after 1136 examples to avoid logging too frequently
train stats after 1152 examples: {'rewards_train/chosen': '0.088027', 'rewards_train/rejected': '-0.25251', 'rewards_train/margins': '0.34424', 'rewards_train/KL_estimate': '0', 'loss/train': '0.45569', 'examples_per_second': '4.21', 'grad_norm': '9.625', 'counters/examples': 1152, 'counters/updates': 72}
skipping logging after 1168 examples to avoid logging too frequently
skipping logging after 1184 examples to avoid logging too frequently
skipping logging after 1200 examples to avoid logging too frequently
train stats after 1216 examples: {'rewards_train/chosen': '0.070111', 'rewards_train/rejected': '-0.19498', 'rewards_train/margins': '0.26318', 'rewards_train/KL_estimate': '0', 'loss/train': '0.46539', 'examples_per_second': '5.8428', 'grad_norm': '7.7812', 'counters/examples': 1216, 'counters/updates': 76}
skipping logging after 1232 examples to avoid logging too frequently
skipping logging after 1248 examples to avoid logging too frequently
skipping logging after 1264 examples to avoid logging too frequently
train stats after 1280 examples: {'rewards_train/chosen': '0.10138', 'rewards_train/rejected': '-0.27813', 'rewards_train/margins': '0.36084', 'rewards_train/KL_estimate': '0', 'loss/train': '0.45288', 'examples_per_second': '4.796', 'grad_norm': '9.625', 'counters/examples': 1280, 'counters/updates': 80}
skipping logging after 1296 examples to avoid logging too frequently
skipping logging after 1312 examples to avoid logging too frequently
skipping logging after 1328 examples to avoid logging too frequently
train stats after 1344 examples: {'rewards_train/chosen': '0.13251', 'rewards_train/rejected': '-0.33518', 'rewards_train/margins': '0.48535', 'rewards_train/KL_estimate': '0', 'loss/train': '0.44482', 'examples_per_second': '5.2791', 'grad_norm': '8.5', 'counters/examples': 1344, 'counters/updates': 84}
skipping logging after 1360 examples to avoid logging too frequently
skipping logging after 1376 examples to avoid logging too frequently
skipping logging after 1392 examples to avoid logging too frequently
train stats after 1408 examples: {'rewards_train/chosen': '0.11324', 'rewards_train/rejected': '-0.34377', 'rewards_train/margins': '0.42432', 'rewards_train/KL_estimate': '0', 'loss/train': '0.453', 'examples_per_second': '3.8749', 'grad_norm': '7.9062', 'counters/examples': 1408, 'counters/updates': 88}
skipping logging after 1424 examples to avoid logging too frequently
skipping logging after 1440 examples to avoid logging too frequently
skipping logging after 1456 examples to avoid logging too frequently
train stats after 1472 examples: {'rewards_train/chosen': '0.12662', 'rewards_train/rejected': '-0.38838', 'rewards_train/margins': '0.50781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.44312', 'examples_per_second': '4.9273', 'grad_norm': '7.5312', 'counters/examples': 1472, 'counters/updates': 92}
skipping logging after 1488 examples to avoid logging too frequently
skipping logging after 1504 examples to avoid logging too frequently
skipping logging after 1520 examples to avoid logging too frequently
train stats after 1536 examples: {'rewards_train/chosen': '0.13376', 'rewards_train/rejected': '-0.56985', 'rewards_train/margins': '0.66797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.42548', 'examples_per_second': '4.8408', 'grad_norm': '8.4375', 'counters/examples': 1536, 'counters/updates': 96}
skipping logging after 1552 examples to avoid logging too frequently
skipping logging after 1568 examples to avoid logging too frequently
skipping logging after 1584 examples to avoid logging too frequently
train stats after 1600 examples: {'rewards_train/chosen': '0.13644', 'rewards_train/rejected': '-0.46655', 'rewards_train/margins': '0.58838', 'rewards_train/KL_estimate': '0', 'loss/train': '0.42981', 'examples_per_second': '5.5264', 'grad_norm': '7.8125', 'counters/examples': 1600, 'counters/updates': 100}
skipping logging after 1616 examples to avoid logging too frequently
skipping logging after 1632 examples to avoid logging too frequently
skipping logging after 1648 examples to avoid logging too frequently
train stats after 1664 examples: {'rewards_train/chosen': '0.23169', 'rewards_train/rejected': '-0.67254', 'rewards_train/margins': '0.91211', 'rewards_train/KL_estimate': '0', 'loss/train': '0.39294', 'examples_per_second': '5.9695', 'grad_norm': '9.5625', 'counters/examples': 1664, 'counters/updates': 104}
skipping logging after 1680 examples to avoid logging too frequently
skipping logging after 1696 examples to avoid logging too frequently
skipping logging after 1712 examples to avoid logging too frequently
train stats after 1728 examples: {'rewards_train/chosen': '0.20784', 'rewards_train/rejected': '-0.51528', 'rewards_train/margins': '0.72656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.42065', 'examples_per_second': '5.9037', 'grad_norm': '7.4375', 'counters/examples': 1728, 'counters/updates': 108}
skipping logging after 1744 examples to avoid logging too frequently
skipping logging after 1760 examples to avoid logging too frequently
skipping logging after 1776 examples to avoid logging too frequently
train stats after 1792 examples: {'rewards_train/chosen': '0.18347', 'rewards_train/rejected': '-0.70362', 'rewards_train/margins': '0.87109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.40802', 'examples_per_second': '4.5944', 'grad_norm': '7.0625', 'counters/examples': 1792, 'counters/updates': 112}
skipping logging after 1808 examples to avoid logging too frequently
skipping logging after 1824 examples to avoid logging too frequently
skipping logging after 1840 examples to avoid logging too frequently
train stats after 1856 examples: {'rewards_train/chosen': '0.25237', 'rewards_train/rejected': '-0.79198', 'rewards_train/margins': '1.0537', 'rewards_train/KL_estimate': '0', 'loss/train': '0.38177', 'examples_per_second': '5.2214', 'grad_norm': '8', 'counters/examples': 1856, 'counters/updates': 116}
skipping logging after 1872 examples to avoid logging too frequently
skipping logging after 1888 examples to avoid logging too frequently
skipping logging after 1904 examples to avoid logging too frequently
train stats after 1920 examples: {'rewards_train/chosen': '0.20308', 'rewards_train/rejected': '-0.76045', 'rewards_train/margins': '0.96387', 'rewards_train/KL_estimate': '0', 'loss/train': '0.38617', 'examples_per_second': '5.604', 'grad_norm': '8.0625', 'counters/examples': 1920, 'counters/updates': 120}
skipping logging after 1936 examples to avoid logging too frequently
skipping logging after 1952 examples to avoid logging too frequently
skipping logging after 1968 examples to avoid logging too frequently
train stats after 1984 examples: {'rewards_train/chosen': '0.19922', 'rewards_train/rejected': '-0.86203', 'rewards_train/margins': '1.0635', 'rewards_train/KL_estimate': '0', 'loss/train': '0.38226', 'examples_per_second': '5.0459', 'grad_norm': '7.6875', 'counters/examples': 1984, 'counters/updates': 124}
skipping logging after 2000 examples to avoid logging too frequently
skipping logging after 2016 examples to avoid logging too frequently
skipping logging after 2032 examples to avoid logging too frequently
train stats after 2048 examples: {'rewards_train/chosen': '0.25715', 'rewards_train/rejected': '-0.93526', 'rewards_train/margins': '1.2109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.37134', 'examples_per_second': '4.7156', 'grad_norm': '7.8125', 'counters/examples': 2048, 'counters/updates': 128}
skipping logging after 2064 examples to avoid logging too frequently
skipping logging after 2080 examples to avoid logging too frequently
skipping logging after 2096 examples to avoid logging too frequently
train stats after 2112 examples: {'rewards_train/chosen': '0.24572', 'rewards_train/rejected': '-0.86157', 'rewards_train/margins': '0.98047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.37744', 'examples_per_second': '5.2971', 'grad_norm': '7.3125', 'counters/examples': 2112, 'counters/updates': 132}
skipping logging after 2128 examples to avoid logging too frequently
skipping logging after 2144 examples to avoid logging too frequently
skipping logging after 2160 examples to avoid logging too frequently
train stats after 2176 examples: {'rewards_train/chosen': '0.2041', 'rewards_train/rejected': '-1.0034', 'rewards_train/margins': '1.2207', 'rewards_train/KL_estimate': '0', 'loss/train': '0.37921', 'examples_per_second': '6.0069', 'grad_norm': '6.6562', 'counters/examples': 2176, 'counters/updates': 136}
skipping logging after 2192 examples to avoid logging too frequently
skipping logging after 2208 examples to avoid logging too frequently
skipping logging after 2224 examples to avoid logging too frequently
train stats after 2240 examples: {'rewards_train/chosen': '0.33287', 'rewards_train/rejected': '-1.1741', 'rewards_train/margins': '1.5254', 'rewards_train/KL_estimate': '0', 'loss/train': '0.35583', 'examples_per_second': '3.8678', 'grad_norm': '6.7188', 'counters/examples': 2240, 'counters/updates': 140}
skipping logging after 2256 examples to avoid logging too frequently
skipping logging after 2272 examples to avoid logging too frequently
skipping logging after 2288 examples to avoid logging too frequently
train stats after 2304 examples: {'rewards_train/chosen': '0.28656', 'rewards_train/rejected': '-0.96332', 'rewards_train/margins': '1.2383', 'rewards_train/KL_estimate': '0', 'loss/train': '0.37189', 'examples_per_second': '5.0659', 'grad_norm': '6.375', 'counters/examples': 2304, 'counters/updates': 144}
skipping logging after 2320 examples to avoid logging too frequently
skipping logging after 2336 examples to avoid logging too frequently
skipping logging after 2352 examples to avoid logging too frequently
train stats after 2368 examples: {'rewards_train/chosen': '0.3318', 'rewards_train/rejected': '-1.4478', 'rewards_train/margins': '1.7051', 'rewards_train/KL_estimate': '0', 'loss/train': '0.33868', 'examples_per_second': '4.9632', 'grad_norm': '6.0625', 'counters/examples': 2368, 'counters/updates': 148}
skipping logging after 2384 examples to avoid logging too frequently
skipping logging after 2400 examples to avoid logging too frequently
skipping logging after 2416 examples to avoid logging too frequently
train stats after 2432 examples: {'rewards_train/chosen': '0.24045', 'rewards_train/rejected': '-1.3193', 'rewards_train/margins': '1.4082', 'rewards_train/KL_estimate': '0', 'loss/train': '0.36694', 'examples_per_second': '5.4075', 'grad_norm': '6', 'counters/examples': 2432, 'counters/updates': 152}
skipping logging after 2448 examples to avoid logging too frequently
skipping logging after 2464 examples to avoid logging too frequently
skipping logging after 2480 examples to avoid logging too frequently
train stats after 2496 examples: {'rewards_train/chosen': '0.33763', 'rewards_train/rejected': '-1.6078', 'rewards_train/margins': '1.8154', 'rewards_train/KL_estimate': '0', 'loss/train': '0.34686', 'examples_per_second': '5.0815', 'grad_norm': '5.875', 'counters/examples': 2496, 'counters/updates': 156}
skipping logging after 2512 examples to avoid logging too frequently
skipping logging after 2528 examples to avoid logging too frequently
skipping logging after 2544 examples to avoid logging too frequently
train stats after 2560 examples: {'rewards_train/chosen': '0.28832', 'rewards_train/rejected': '-1.169', 'rewards_train/margins': '1.4668', 'rewards_train/KL_estimate': '0', 'loss/train': '0.33362', 'examples_per_second': '5.4378', 'grad_norm': '6.875', 'counters/examples': 2560, 'counters/updates': 160}
skipping logging after 2576 examples to avoid logging too frequently
skipping logging after 2592 examples to avoid logging too frequently
skipping logging after 2608 examples to avoid logging too frequently
train stats after 2624 examples: {'rewards_train/chosen': '0.32575', 'rewards_train/rejected': '-1.2401', 'rewards_train/margins': '1.5488', 'rewards_train/KL_estimate': '0', 'loss/train': '0.3526', 'examples_per_second': '5.2805', 'grad_norm': '6.1562', 'counters/examples': 2624, 'counters/updates': 164}
skipping logging after 2640 examples to avoid logging too frequently
skipping logging after 2656 examples to avoid logging too frequently
skipping logging after 2672 examples to avoid logging too frequently
train stats after 2688 examples: {'rewards_train/chosen': '0.22396', 'rewards_train/rejected': '-1.3784', 'rewards_train/margins': '1.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.35095', 'examples_per_second': '4.9775', 'grad_norm': '6', 'counters/examples': 2688, 'counters/updates': 168}
skipping logging after 2704 examples to avoid logging too frequently
skipping logging after 2720 examples to avoid logging too frequently
skipping logging after 2736 examples to avoid logging too frequently
train stats after 2752 examples: {'rewards_train/chosen': '0.33806', 'rewards_train/rejected': '-2.291', 'rewards_train/margins': '2.5898', 'rewards_train/KL_estimate': '0', 'loss/train': '0.34058', 'examples_per_second': '5.6208', 'grad_norm': '5', 'counters/examples': 2752, 'counters/updates': 172}
skipping logging after 2768 examples to avoid logging too frequently
skipping logging after 2784 examples to avoid logging too frequently
skipping logging after 2800 examples to avoid logging too frequently
train stats after 2816 examples: {'rewards_train/chosen': '0.34041', 'rewards_train/rejected': '-1.4909', 'rewards_train/margins': '1.7285', 'rewards_train/KL_estimate': '0', 'loss/train': '0.33801', 'examples_per_second': '4.4248', 'grad_norm': '5.6562', 'counters/examples': 2816, 'counters/updates': 176}
skipping logging after 2832 examples to avoid logging too frequently
skipping logging after 2848 examples to avoid logging too frequently
skipping logging after 2864 examples to avoid logging too frequently
train stats after 2880 examples: {'rewards_train/chosen': '0.48981', 'rewards_train/rejected': '-1.3712', 'rewards_train/margins': '1.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.34229', 'examples_per_second': '4.5322', 'grad_norm': '6.1562', 'counters/examples': 2880, 'counters/updates': 180}
skipping logging after 2896 examples to avoid logging too frequently
skipping logging after 2912 examples to avoid logging too frequently
skipping logging after 2928 examples to avoid logging too frequently
train stats after 2944 examples: {'rewards_train/chosen': '0.38704', 'rewards_train/rejected': '-1.2102', 'rewards_train/margins': '1.6973', 'rewards_train/KL_estimate': '0', 'loss/train': '0.35138', 'examples_per_second': '5.1365', 'grad_norm': '5.75', 'counters/examples': 2944, 'counters/updates': 184}
skipping logging after 2960 examples to avoid logging too frequently
skipping logging after 2976 examples to avoid logging too frequently
skipping logging after 2992 examples to avoid logging too frequently
train stats after 3008 examples: {'rewards_train/chosen': '0.31176', 'rewards_train/rejected': '-1.6697', 'rewards_train/margins': '1.9199', 'rewards_train/KL_estimate': '0.033203', 'loss/train': '0.32886', 'examples_per_second': '4.4743', 'grad_norm': '5.2812', 'counters/examples': 3008, 'counters/updates': 188}
skipping logging after 3024 examples to avoid logging too frequently
skipping logging after 3040 examples to avoid logging too frequently
skipping logging after 3056 examples to avoid logging too frequently
train stats after 3072 examples: {'rewards_train/chosen': '0.44406', 'rewards_train/rejected': '-1.6126', 'rewards_train/margins': '1.9648', 'rewards_train/KL_estimate': '0', 'loss/train': '0.33173', 'examples_per_second': '5.8742', 'grad_norm': '5.1875', 'counters/examples': 3072, 'counters/updates': 192}
skipping logging after 3088 examples to avoid logging too frequently
skipping logging after 3104 examples to avoid logging too frequently
skipping logging after 3120 examples to avoid logging too frequently
train stats after 3136 examples: {'rewards_train/chosen': '0.36541', 'rewards_train/rejected': '-1.3521', 'rewards_train/margins': '1.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.34528', 'examples_per_second': '4.7147', 'grad_norm': '5.3438', 'counters/examples': 3136, 'counters/updates': 196}
skipping logging after 3152 examples to avoid logging too frequently
skipping logging after 3168 examples to avoid logging too frequently
skipping logging after 3184 examples to avoid logging too frequently
train stats after 3200 examples: {'rewards_train/chosen': '0.40918', 'rewards_train/rejected': '-2.0087', 'rewards_train/margins': '2.4414', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2937', 'examples_per_second': '5.1395', 'grad_norm': '5.3438', 'counters/examples': 3200, 'counters/updates': 200}
skipping logging after 3216 examples to avoid logging too frequently
skipping logging after 3232 examples to avoid logging too frequently
skipping logging after 3248 examples to avoid logging too frequently
train stats after 3264 examples: {'rewards_train/chosen': '0.46218', 'rewards_train/rejected': '-2.0484', 'rewards_train/margins': '2.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24884', 'examples_per_second': '6.4122', 'grad_norm': '5.9688', 'counters/examples': 3264, 'counters/updates': 204}
skipping logging after 3280 examples to avoid logging too frequently
skipping logging after 3296 examples to avoid logging too frequently
skipping logging after 3312 examples to avoid logging too frequently
train stats after 3328 examples: {'rewards_train/chosen': '0.35973', 'rewards_train/rejected': '-2.5791', 'rewards_train/margins': '2.8105', 'rewards_train/KL_estimate': '0', 'loss/train': '0.32574', 'examples_per_second': '5.2842', 'grad_norm': '5.125', 'counters/examples': 3328, 'counters/updates': 208}
skipping logging after 3344 examples to avoid logging too frequently
skipping logging after 3360 examples to avoid logging too frequently
skipping logging after 3376 examples to avoid logging too frequently
train stats after 3392 examples: {'rewards_train/chosen': '0.37255', 'rewards_train/rejected': '-1.6633', 'rewards_train/margins': '1.9941', 'rewards_train/KL_estimate': '0', 'loss/train': '0.32538', 'examples_per_second': '5.1059', 'grad_norm': '5.1562', 'counters/examples': 3392, 'counters/updates': 212}
skipping logging after 3408 examples to avoid logging too frequently
skipping logging after 3424 examples to avoid logging too frequently
skipping logging after 3440 examples to avoid logging too frequently
train stats after 3456 examples: {'rewards_train/chosen': '0.65201', 'rewards_train/rejected': '-2.266', 'rewards_train/margins': '2.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27393', 'examples_per_second': '5.0821', 'grad_norm': '4.9375', 'counters/examples': 3456, 'counters/updates': 216}
skipping logging after 3472 examples to avoid logging too frequently
skipping logging after 3488 examples to avoid logging too frequently
skipping logging after 3504 examples to avoid logging too frequently
train stats after 3520 examples: {'rewards_train/chosen': '0.39708', 'rewards_train/rejected': '-2.411', 'rewards_train/margins': '2.8223', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27765', 'examples_per_second': '5.7868', 'grad_norm': '5.1562', 'counters/examples': 3520, 'counters/updates': 220}
skipping logging after 3536 examples to avoid logging too frequently
skipping logging after 3552 examples to avoid logging too frequently
skipping logging after 3568 examples to avoid logging too frequently
train stats after 3584 examples: {'rewards_train/chosen': '0.33795', 'rewards_train/rejected': '-2.8416', 'rewards_train/margins': '3.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29272', 'examples_per_second': '4.9958', 'grad_norm': '4.8438', 'counters/examples': 3584, 'counters/updates': 224}
skipping logging after 3600 examples to avoid logging too frequently
skipping logging after 3616 examples to avoid logging too frequently
skipping logging after 3632 examples to avoid logging too frequently
train stats after 3648 examples: {'rewards_train/chosen': '0.45717', 'rewards_train/rejected': '-2.5821', 'rewards_train/margins': '2.9727', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30231', 'examples_per_second': '5.1573', 'grad_norm': '4.875', 'counters/examples': 3648, 'counters/updates': 228}
skipping logging after 3664 examples to avoid logging too frequently
skipping logging after 3680 examples to avoid logging too frequently
skipping logging after 3696 examples to avoid logging too frequently
train stats after 3712 examples: {'rewards_train/chosen': '0.34145', 'rewards_train/rejected': '-2.2442', 'rewards_train/margins': '2.5938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.32062', 'examples_per_second': '6.1661', 'grad_norm': '4.3438', 'counters/examples': 3712, 'counters/updates': 232}
skipping logging after 3728 examples to avoid logging too frequently
skipping logging after 3744 examples to avoid logging too frequently
skipping logging after 3760 examples to avoid logging too frequently
train stats after 3776 examples: {'rewards_train/chosen': '0.42812', 'rewards_train/rejected': '-2.6851', 'rewards_train/margins': '2.9199', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27063', 'examples_per_second': '5.0646', 'grad_norm': '5.8125', 'counters/examples': 3776, 'counters/updates': 236}
skipping logging after 3792 examples to avoid logging too frequently
skipping logging after 3808 examples to avoid logging too frequently
skipping logging after 3824 examples to avoid logging too frequently
train stats after 3840 examples: {'rewards_train/chosen': '0.38679', 'rewards_train/rejected': '-2.6895', 'rewards_train/margins': '3.0879', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27466', 'examples_per_second': '4.571', 'grad_norm': '5.0938', 'counters/examples': 3840, 'counters/updates': 240}
skipping logging after 3856 examples to avoid logging too frequently
skipping logging after 3872 examples to avoid logging too frequently
skipping logging after 3888 examples to avoid logging too frequently
train stats after 3904 examples: {'rewards_train/chosen': '0.23624', 'rewards_train/rejected': '-2.2153', 'rewards_train/margins': '2.4844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30304', 'examples_per_second': '5.6033', 'grad_norm': '5.4062', 'counters/examples': 3904, 'counters/updates': 244}
skipping logging after 3920 examples to avoid logging too frequently
skipping logging after 3936 examples to avoid logging too frequently
skipping logging after 3952 examples to avoid logging too frequently
train stats after 3968 examples: {'rewards_train/chosen': '0.42082', 'rewards_train/rejected': '-3.5214', 'rewards_train/margins': '4.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27679', 'examples_per_second': '5.5876', 'grad_norm': '4.625', 'counters/examples': 3968, 'counters/updates': 248}
skipping logging after 3984 examples to avoid logging too frequently
skipping logging after 4000 examples to avoid logging too frequently
Running evaluation after 4000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:46,  1.50s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:40,  1.36s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:35,  1.22s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:40,  1.46s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.67s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.48s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:34,  1.37s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:30,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:12,  1.44s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.31s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.20s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.18s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.31s/it]
eval after 4000: {'rewards_eval/chosen': '-2.7587', 'rewards_eval/rejected': '-2.9098', 'rewards_eval/margins': '0.099121', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.47638'}
skipping logging after 4016 examples to avoid logging too frequently
train stats after 4032 examples: {'rewards_train/chosen': '0.43277', 'rewards_train/rejected': '-2.2743', 'rewards_train/margins': '2.7148', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2829', 'examples_per_second': '4.9911', 'grad_norm': '4.7812', 'counters/examples': 4032, 'counters/updates': 252}
skipping logging after 4048 examples to avoid logging too frequently
skipping logging after 4064 examples to avoid logging too frequently
skipping logging after 4080 examples to avoid logging too frequently
train stats after 4096 examples: {'rewards_train/chosen': '0.59075', 'rewards_train/rejected': '-2.352', 'rewards_train/margins': '2.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24805', 'examples_per_second': '4.9366', 'grad_norm': '5.3125', 'counters/examples': 4096, 'counters/updates': 256}
skipping logging after 4112 examples to avoid logging too frequently
skipping logging after 4128 examples to avoid logging too frequently
skipping logging after 4144 examples to avoid logging too frequently
train stats after 4160 examples: {'rewards_train/chosen': '0.48178', 'rewards_train/rejected': '-3.1071', 'rewards_train/margins': '3.5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25574', 'examples_per_second': '4.8578', 'grad_norm': '5.0625', 'counters/examples': 4160, 'counters/updates': 260}
skipping logging after 4176 examples to avoid logging too frequently
skipping logging after 4192 examples to avoid logging too frequently
skipping logging after 4208 examples to avoid logging too frequently
train stats after 4224 examples: {'rewards_train/chosen': '0.37041', 'rewards_train/rejected': '-3.4837', 'rewards_train/margins': '3.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2641', 'examples_per_second': '4.5842', 'grad_norm': '4.625', 'counters/examples': 4224, 'counters/updates': 264}
skipping logging after 4240 examples to avoid logging too frequently
skipping logging after 4256 examples to avoid logging too frequently
skipping logging after 4272 examples to avoid logging too frequently
train stats after 4288 examples: {'rewards_train/chosen': '0.43724', 'rewards_train/rejected': '-2.5243', 'rewards_train/margins': '2.9141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29132', 'examples_per_second': '5.5883', 'grad_norm': '4.9688', 'counters/examples': 4288, 'counters/updates': 268}
skipping logging after 4304 examples to avoid logging too frequently
skipping logging after 4320 examples to avoid logging too frequently
skipping logging after 4336 examples to avoid logging too frequently
train stats after 4352 examples: {'rewards_train/chosen': '0.37863', 'rewards_train/rejected': '-3.8953', 'rewards_train/margins': '4.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26489', 'examples_per_second': '5.0837', 'grad_norm': '5.375', 'counters/examples': 4352, 'counters/updates': 272}
skipping logging after 4368 examples to avoid logging too frequently
skipping logging after 4384 examples to avoid logging too frequently
skipping logging after 4400 examples to avoid logging too frequently
train stats after 4416 examples: {'rewards_train/chosen': '0.47092', 'rewards_train/rejected': '-3.2278', 'rewards_train/margins': '3.5508', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26733', 'examples_per_second': '4.9685', 'grad_norm': '4.5312', 'counters/examples': 4416, 'counters/updates': 276}
skipping logging after 4432 examples to avoid logging too frequently
skipping logging after 4448 examples to avoid logging too frequently
skipping logging after 4464 examples to avoid logging too frequently
train stats after 4480 examples: {'rewards_train/chosen': '0.38254', 'rewards_train/rejected': '-4.1864', 'rewards_train/margins': '4.5391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2442', 'examples_per_second': '4.5259', 'grad_norm': '4.4688', 'counters/examples': 4480, 'counters/updates': 280}
skipping logging after 4496 examples to avoid logging too frequently
skipping logging after 4512 examples to avoid logging too frequently
skipping logging after 4528 examples to avoid logging too frequently
train stats after 4544 examples: {'rewards_train/chosen': '0.43406', 'rewards_train/rejected': '-3.0058', 'rewards_train/margins': '3.4492', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25348', 'examples_per_second': '5.9763', 'grad_norm': '4.8125', 'counters/examples': 4544, 'counters/updates': 284}
skipping logging after 4560 examples to avoid logging too frequently
skipping logging after 4576 examples to avoid logging too frequently
skipping logging after 4592 examples to avoid logging too frequently
train stats after 4608 examples: {'rewards_train/chosen': '0.42418', 'rewards_train/rejected': '-2.8731', 'rewards_train/margins': '3.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29791', 'examples_per_second': '5.2894', 'grad_norm': '4.9375', 'counters/examples': 4608, 'counters/updates': 288}
skipping logging after 4624 examples to avoid logging too frequently
skipping logging after 4640 examples to avoid logging too frequently
skipping logging after 4656 examples to avoid logging too frequently
train stats after 4672 examples: {'rewards_train/chosen': '0.43191', 'rewards_train/rejected': '-3.5859', 'rewards_train/margins': '3.832', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27991', 'examples_per_second': '4.7025', 'grad_norm': '5.5625', 'counters/examples': 4672, 'counters/updates': 292}
skipping logging after 4688 examples to avoid logging too frequently
skipping logging after 4704 examples to avoid logging too frequently
skipping logging after 4720 examples to avoid logging too frequently
train stats after 4736 examples: {'rewards_train/chosen': '0.27013', 'rewards_train/rejected': '-3.7627', 'rewards_train/margins': '4.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25366', 'examples_per_second': '4.7431', 'grad_norm': '4.1875', 'counters/examples': 4736, 'counters/updates': 296}
skipping logging after 4752 examples to avoid logging too frequently
skipping logging after 4768 examples to avoid logging too frequently
skipping logging after 4784 examples to avoid logging too frequently
train stats after 4800 examples: {'rewards_train/chosen': '0.23736', 'rewards_train/rejected': '-4.3699', 'rewards_train/margins': '5.1055', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2738', 'examples_per_second': '5.6281', 'grad_norm': '4.4062', 'counters/examples': 4800, 'counters/updates': 300}
skipping logging after 4816 examples to avoid logging too frequently
skipping logging after 4832 examples to avoid logging too frequently
skipping logging after 4848 examples to avoid logging too frequently
train stats after 4864 examples: {'rewards_train/chosen': '0.58461', 'rewards_train/rejected': '-3.2708', 'rewards_train/margins': '3.6934', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27557', 'examples_per_second': '5.9983', 'grad_norm': '4.6562', 'counters/examples': 4864, 'counters/updates': 304}
skipping logging after 4880 examples to avoid logging too frequently
skipping logging after 4896 examples to avoid logging too frequently
skipping logging after 4912 examples to avoid logging too frequently
train stats after 4928 examples: {'rewards_train/chosen': '0.5068', 'rewards_train/rejected': '-5.4627', 'rewards_train/margins': '5.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25958', 'examples_per_second': '5.4401', 'grad_norm': '5.0312', 'counters/examples': 4928, 'counters/updates': 308}
skipping logging after 4944 examples to avoid logging too frequently
skipping logging after 4960 examples to avoid logging too frequently
skipping logging after 4976 examples to avoid logging too frequently
train stats after 4992 examples: {'rewards_train/chosen': '0.39892', 'rewards_train/rejected': '-3.0534', 'rewards_train/margins': '3.5723', 'rewards_train/KL_estimate': '0', 'loss/train': '0.33643', 'examples_per_second': '5.1773', 'grad_norm': '5.5312', 'counters/examples': 4992, 'counters/updates': 312}
skipping logging after 5008 examples to avoid logging too frequently
skipping logging after 5024 examples to avoid logging too frequently
skipping logging after 5040 examples to avoid logging too frequently
train stats after 5056 examples: {'rewards_train/chosen': '0.38698', 'rewards_train/rejected': '-3.4996', 'rewards_train/margins': '3.9824', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25244', 'examples_per_second': '5.0355', 'grad_norm': '3.9375', 'counters/examples': 5056, 'counters/updates': 316}
skipping logging after 5072 examples to avoid logging too frequently
skipping logging after 5088 examples to avoid logging too frequently
skipping logging after 5104 examples to avoid logging too frequently
train stats after 5120 examples: {'rewards_train/chosen': '0.56337', 'rewards_train/rejected': '-3.0563', 'rewards_train/margins': '3.6445', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27942', 'examples_per_second': '5.6383', 'grad_norm': '4.875', 'counters/examples': 5120, 'counters/updates': 320}
skipping logging after 5136 examples to avoid logging too frequently
skipping logging after 5152 examples to avoid logging too frequently
skipping logging after 5168 examples to avoid logging too frequently
train stats after 5184 examples: {'rewards_train/chosen': '0.4025', 'rewards_train/rejected': '-4.1201', 'rewards_train/margins': '4.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21674', 'examples_per_second': '5.7035', 'grad_norm': '5', 'counters/examples': 5184, 'counters/updates': 324}
skipping logging after 5200 examples to avoid logging too frequently
skipping logging after 5216 examples to avoid logging too frequently
skipping logging after 5232 examples to avoid logging too frequently
train stats after 5248 examples: {'rewards_train/chosen': '0.52001', 'rewards_train/rejected': '-3.3317', 'rewards_train/margins': '3.7422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27606', 'examples_per_second': '5.0425', 'grad_norm': '4.7188', 'counters/examples': 5248, 'counters/updates': 328}
skipping logging after 5264 examples to avoid logging too frequently
skipping logging after 5280 examples to avoid logging too frequently
skipping logging after 5296 examples to avoid logging too frequently
train stats after 5312 examples: {'rewards_train/chosen': '0.52804', 'rewards_train/rejected': '-3.3916', 'rewards_train/margins': '4.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2998', 'examples_per_second': '6.3879', 'grad_norm': '4.6562', 'counters/examples': 5312, 'counters/updates': 332}
skipping logging after 5328 examples to avoid logging too frequently
skipping logging after 5344 examples to avoid logging too frequently
skipping logging after 5360 examples to avoid logging too frequently
train stats after 5376 examples: {'rewards_train/chosen': '0.14006', 'rewards_train/rejected': '-2.7677', 'rewards_train/margins': '3.1191', 'rewards_train/KL_estimate': '0', 'loss/train': '0.34668', 'examples_per_second': '4.6939', 'grad_norm': '5.75', 'counters/examples': 5376, 'counters/updates': 336}
skipping logging after 5392 examples to avoid logging too frequently
skipping logging after 5408 examples to avoid logging too frequently
skipping logging after 5424 examples to avoid logging too frequently
train stats after 5440 examples: {'rewards_train/chosen': '0.46384', 'rewards_train/rejected': '-3.8043', 'rewards_train/margins': '4.2773', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25586', 'examples_per_second': '5.1995', 'grad_norm': '4.2188', 'counters/examples': 5440, 'counters/updates': 340}
skipping logging after 5456 examples to avoid logging too frequently
skipping logging after 5472 examples to avoid logging too frequently
skipping logging after 5488 examples to avoid logging too frequently
train stats after 5504 examples: {'rewards_train/chosen': '0.37236', 'rewards_train/rejected': '-4.6107', 'rewards_train/margins': '4.8906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23761', 'examples_per_second': '5.6378', 'grad_norm': '3.7969', 'counters/examples': 5504, 'counters/updates': 344}
skipping logging after 5520 examples to avoid logging too frequently
skipping logging after 5536 examples to avoid logging too frequently
skipping logging after 5552 examples to avoid logging too frequently
train stats after 5568 examples: {'rewards_train/chosen': '0.35368', 'rewards_train/rejected': '-3.6168', 'rewards_train/margins': '4.2148', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25281', 'examples_per_second': '6.5899', 'grad_norm': '5.0312', 'counters/examples': 5568, 'counters/updates': 348}
skipping logging after 5584 examples to avoid logging too frequently
skipping logging after 5600 examples to avoid logging too frequently
skipping logging after 5616 examples to avoid logging too frequently
train stats after 5632 examples: {'rewards_train/chosen': '0.50872', 'rewards_train/rejected': '-3.6306', 'rewards_train/margins': '4.1406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28986', 'examples_per_second': '4.8754', 'grad_norm': '4.9688', 'counters/examples': 5632, 'counters/updates': 352}
skipping logging after 5648 examples to avoid logging too frequently
skipping logging after 5664 examples to avoid logging too frequently
skipping logging after 5680 examples to avoid logging too frequently
train stats after 5696 examples: {'rewards_train/chosen': '0.13323', 'rewards_train/rejected': '-3.1972', 'rewards_train/margins': '3.6328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28326', 'examples_per_second': '5.36', 'grad_norm': '5.25', 'counters/examples': 5696, 'counters/updates': 356}
skipping logging after 5712 examples to avoid logging too frequently
skipping logging after 5728 examples to avoid logging too frequently
skipping logging after 5744 examples to avoid logging too frequently
train stats after 5760 examples: {'rewards_train/chosen': '0.51801', 'rewards_train/rejected': '-3.639', 'rewards_train/margins': '3.9297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.271', 'examples_per_second': '4.3706', 'grad_norm': '4.7812', 'counters/examples': 5760, 'counters/updates': 360}
skipping logging after 5776 examples to avoid logging too frequently
skipping logging after 5792 examples to avoid logging too frequently
skipping logging after 5808 examples to avoid logging too frequently
train stats after 5824 examples: {'rewards_train/chosen': '0.36096', 'rewards_train/rejected': '-4.6877', 'rewards_train/margins': '4.8164', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30469', 'examples_per_second': '4.8336', 'grad_norm': '5', 'counters/examples': 5824, 'counters/updates': 364}
skipping logging after 5840 examples to avoid logging too frequently
skipping logging after 5856 examples to avoid logging too frequently
skipping logging after 5872 examples to avoid logging too frequently
train stats after 5888 examples: {'rewards_train/chosen': '0.41262', 'rewards_train/rejected': '-4.3385', 'rewards_train/margins': '4.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25647', 'examples_per_second': '4.7774', 'grad_norm': '4.8125', 'counters/examples': 5888, 'counters/updates': 368}
skipping logging after 5904 examples to avoid logging too frequently
skipping logging after 5920 examples to avoid logging too frequently
skipping logging after 5936 examples to avoid logging too frequently
train stats after 5952 examples: {'rewards_train/chosen': '0.55077', 'rewards_train/rejected': '-3.5442', 'rewards_train/margins': '4.3086', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23907', 'examples_per_second': '5.6395', 'grad_norm': '5.0625', 'counters/examples': 5952, 'counters/updates': 372}
skipping logging after 5968 examples to avoid logging too frequently
skipping logging after 5984 examples to avoid logging too frequently
skipping logging after 6000 examples to avoid logging too frequently
train stats after 6016 examples: {'rewards_train/chosen': '0.5718', 'rewards_train/rejected': '-3.8297', 'rewards_train/margins': '4.1016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26111', 'examples_per_second': '4.6913', 'grad_norm': '4.125', 'counters/examples': 6016, 'counters/updates': 376}
skipping logging after 6032 examples to avoid logging too frequently
skipping logging after 6048 examples to avoid logging too frequently
skipping logging after 6064 examples to avoid logging too frequently
train stats after 6080 examples: {'rewards_train/chosen': '0.37401', 'rewards_train/rejected': '-4.678', 'rewards_train/margins': '4.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24622', 'examples_per_second': '4.3195', 'grad_norm': '4.9688', 'counters/examples': 6080, 'counters/updates': 380}
skipping logging after 6096 examples to avoid logging too frequently
skipping logging after 6112 examples to avoid logging too frequently
skipping logging after 6128 examples to avoid logging too frequently
train stats after 6144 examples: {'rewards_train/chosen': '0.45104', 'rewards_train/rejected': '-2.2568', 'rewards_train/margins': '2.6133', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29767', 'examples_per_second': '4.4963', 'grad_norm': '4.9688', 'counters/examples': 6144, 'counters/updates': 384}
skipping logging after 6160 examples to avoid logging too frequently
skipping logging after 6176 examples to avoid logging too frequently
skipping logging after 6192 examples to avoid logging too frequently
train stats after 6208 examples: {'rewards_train/chosen': '0.27076', 'rewards_train/rejected': '-4.0952', 'rewards_train/margins': '4.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29047', 'examples_per_second': '5.0555', 'grad_norm': '4.7812', 'counters/examples': 6208, 'counters/updates': 388}
skipping logging after 6224 examples to avoid logging too frequently
skipping logging after 6240 examples to avoid logging too frequently
skipping logging after 6256 examples to avoid logging too frequently
train stats after 6272 examples: {'rewards_train/chosen': '0.58155', 'rewards_train/rejected': '-4.2773', 'rewards_train/margins': '4.6914', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2439', 'examples_per_second': '4.884', 'grad_norm': '5.625', 'counters/examples': 6272, 'counters/updates': 392}
skipping logging after 6288 examples to avoid logging too frequently
skipping logging after 6304 examples to avoid logging too frequently
skipping logging after 6320 examples to avoid logging too frequently
train stats after 6336 examples: {'rewards_train/chosen': '0.446', 'rewards_train/rejected': '-4.4712', 'rewards_train/margins': '4.6758', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2287', 'examples_per_second': '5.0805', 'grad_norm': '4.4375', 'counters/examples': 6336, 'counters/updates': 396}
skipping logging after 6352 examples to avoid logging too frequently
skipping logging after 6368 examples to avoid logging too frequently
skipping logging after 6384 examples to avoid logging too frequently
train stats after 6400 examples: {'rewards_train/chosen': '0.36893', 'rewards_train/rejected': '-4.4702', 'rewards_train/margins': '4.7617', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27209', 'examples_per_second': '4.2926', 'grad_norm': '4.6562', 'counters/examples': 6400, 'counters/updates': 400}
skipping logging after 6416 examples to avoid logging too frequently
skipping logging after 6432 examples to avoid logging too frequently
skipping logging after 6448 examples to avoid logging too frequently
train stats after 6464 examples: {'rewards_train/chosen': '0.69711', 'rewards_train/rejected': '-4.6882', 'rewards_train/margins': '5.375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21075', 'examples_per_second': '4.0423', 'grad_norm': '4.625', 'counters/examples': 6464, 'counters/updates': 404}
skipping logging after 6480 examples to avoid logging too frequently
skipping logging after 6496 examples to avoid logging too frequently
skipping logging after 6512 examples to avoid logging too frequently
train stats after 6528 examples: {'rewards_train/chosen': '0.25914', 'rewards_train/rejected': '-4.6234', 'rewards_train/margins': '4.9023', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27667', 'examples_per_second': '4.4831', 'grad_norm': '4.7188', 'counters/examples': 6528, 'counters/updates': 408}
skipping logging after 6544 examples to avoid logging too frequently
skipping logging after 6560 examples to avoid logging too frequently
skipping logging after 6576 examples to avoid logging too frequently
train stats after 6592 examples: {'rewards_train/chosen': '0.52423', 'rewards_train/rejected': '-4.4197', 'rewards_train/margins': '4.7734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27515', 'examples_per_second': '5.0095', 'grad_norm': '4.5312', 'counters/examples': 6592, 'counters/updates': 412}
skipping logging after 6608 examples to avoid logging too frequently
skipping logging after 6624 examples to avoid logging too frequently
skipping logging after 6640 examples to avoid logging too frequently
train stats after 6656 examples: {'rewards_train/chosen': '-0.17021', 'rewards_train/rejected': '-4.3938', 'rewards_train/margins': '4.2344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24799', 'examples_per_second': '5.6046', 'grad_norm': '3.9531', 'counters/examples': 6656, 'counters/updates': 416}
skipping logging after 6672 examples to avoid logging too frequently
skipping logging after 6688 examples to avoid logging too frequently
skipping logging after 6704 examples to avoid logging too frequently
train stats after 6720 examples: {'rewards_train/chosen': '0.4944', 'rewards_train/rejected': '-3.8938', 'rewards_train/margins': '4.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2384', 'examples_per_second': '4.8761', 'grad_norm': '4.6875', 'counters/examples': 6720, 'counters/updates': 420}
skipping logging after 6736 examples to avoid logging too frequently
skipping logging after 6752 examples to avoid logging too frequently
skipping logging after 6768 examples to avoid logging too frequently
train stats after 6784 examples: {'rewards_train/chosen': '0.53337', 'rewards_train/rejected': '-4.5749', 'rewards_train/margins': '5.043', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24335', 'examples_per_second': '5.2696', 'grad_norm': '5.7188', 'counters/examples': 6784, 'counters/updates': 424}
skipping logging after 6800 examples to avoid logging too frequently
skipping logging after 6816 examples to avoid logging too frequently
skipping logging after 6832 examples to avoid logging too frequently
train stats after 6848 examples: {'rewards_train/chosen': '0.53923', 'rewards_train/rejected': '-4.4664', 'rewards_train/margins': '5.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.258', 'examples_per_second': '4.6017', 'grad_norm': '5.4375', 'counters/examples': 6848, 'counters/updates': 428}
skipping logging after 6864 examples to avoid logging too frequently
skipping logging after 6880 examples to avoid logging too frequently
skipping logging after 6896 examples to avoid logging too frequently
train stats after 6912 examples: {'rewards_train/chosen': '0.52596', 'rewards_train/rejected': '-4.2068', 'rewards_train/margins': '4.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2558', 'examples_per_second': '4.9256', 'grad_norm': '4', 'counters/examples': 6912, 'counters/updates': 432}
skipping logging after 6928 examples to avoid logging too frequently
skipping logging after 6944 examples to avoid logging too frequently
skipping logging after 6960 examples to avoid logging too frequently
train stats after 6976 examples: {'rewards_train/chosen': '0.42076', 'rewards_train/rejected': '-3.3482', 'rewards_train/margins': '3.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28046', 'examples_per_second': '5.6577', 'grad_norm': '4.875', 'counters/examples': 6976, 'counters/updates': 436}
skipping logging after 6992 examples to avoid logging too frequently
skipping logging after 7008 examples to avoid logging too frequently
skipping logging after 7024 examples to avoid logging too frequently
train stats after 7040 examples: {'rewards_train/chosen': '0.52893', 'rewards_train/rejected': '-3.8946', 'rewards_train/margins': '4.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26208', 'examples_per_second': '5.7709', 'grad_norm': '4.25', 'counters/examples': 7040, 'counters/updates': 440}
skipping logging after 7056 examples to avoid logging too frequently
skipping logging after 7072 examples to avoid logging too frequently
skipping logging after 7088 examples to avoid logging too frequently
train stats after 7104 examples: {'rewards_train/chosen': '0.36768', 'rewards_train/rejected': '-4.0515', 'rewards_train/margins': '4.3203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26477', 'examples_per_second': '4.7702', 'grad_norm': '4.9688', 'counters/examples': 7104, 'counters/updates': 444}
skipping logging after 7120 examples to avoid logging too frequently
skipping logging after 7136 examples to avoid logging too frequently
skipping logging after 7152 examples to avoid logging too frequently
train stats after 7168 examples: {'rewards_train/chosen': '0.7894', 'rewards_train/rejected': '-5.2549', 'rewards_train/margins': '5.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2215', 'examples_per_second': '5.1539', 'grad_norm': '4.8125', 'counters/examples': 7168, 'counters/updates': 448}
skipping logging after 7184 examples to avoid logging too frequently
skipping logging after 7200 examples to avoid logging too frequently
skipping logging after 7216 examples to avoid logging too frequently
train stats after 7232 examples: {'rewards_train/chosen': '0.30152', 'rewards_train/rejected': '-3.9418', 'rewards_train/margins': '4.2539', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26758', 'examples_per_second': '4.8719', 'grad_norm': '5.1562', 'counters/examples': 7232, 'counters/updates': 452}
skipping logging after 7248 examples to avoid logging too frequently
skipping logging after 7264 examples to avoid logging too frequently
skipping logging after 7280 examples to avoid logging too frequently
train stats after 7296 examples: {'rewards_train/chosen': '0.3304', 'rewards_train/rejected': '-4.3555', 'rewards_train/margins': '4.6484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24963', 'examples_per_second': '4.8988', 'grad_norm': '4.8125', 'counters/examples': 7296, 'counters/updates': 456}
skipping logging after 7312 examples to avoid logging too frequently
skipping logging after 7328 examples to avoid logging too frequently
skipping logging after 7344 examples to avoid logging too frequently
train stats after 7360 examples: {'rewards_train/chosen': '0.70349', 'rewards_train/rejected': '-5.5349', 'rewards_train/margins': '5.8203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19629', 'examples_per_second': '5.2663', 'grad_norm': '4.75', 'counters/examples': 7360, 'counters/updates': 460}
skipping logging after 7376 examples to avoid logging too frequently
skipping logging after 7392 examples to avoid logging too frequently
skipping logging after 7408 examples to avoid logging too frequently
train stats after 7424 examples: {'rewards_train/chosen': '0.35446', 'rewards_train/rejected': '-3.5871', 'rewards_train/margins': '3.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2757', 'examples_per_second': '5.1757', 'grad_norm': '5.4062', 'counters/examples': 7424, 'counters/updates': 464}
skipping logging after 7440 examples to avoid logging too frequently
skipping logging after 7456 examples to avoid logging too frequently
skipping logging after 7472 examples to avoid logging too frequently
train stats after 7488 examples: {'rewards_train/chosen': '0.42725', 'rewards_train/rejected': '-4.4714', 'rewards_train/margins': '5.2305', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23657', 'examples_per_second': '5.0521', 'grad_norm': '5.1875', 'counters/examples': 7488, 'counters/updates': 468}
skipping logging after 7504 examples to avoid logging too frequently
skipping logging after 7520 examples to avoid logging too frequently
skipping logging after 7536 examples to avoid logging too frequently
train stats after 7552 examples: {'rewards_train/chosen': '0.38151', 'rewards_train/rejected': '-3.8705', 'rewards_train/margins': '4.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28247', 'examples_per_second': '5.9812', 'grad_norm': '5.4688', 'counters/examples': 7552, 'counters/updates': 472}
skipping logging after 7568 examples to avoid logging too frequently
skipping logging after 7584 examples to avoid logging too frequently
skipping logging after 7600 examples to avoid logging too frequently
train stats after 7616 examples: {'rewards_train/chosen': '0.45872', 'rewards_train/rejected': '-4.4139', 'rewards_train/margins': '5.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24213', 'examples_per_second': '5.2387', 'grad_norm': '4.4062', 'counters/examples': 7616, 'counters/updates': 476}
skipping logging after 7632 examples to avoid logging too frequently
skipping logging after 7648 examples to avoid logging too frequently
skipping logging after 7664 examples to avoid logging too frequently
train stats after 7680 examples: {'rewards_train/chosen': '0.22', 'rewards_train/rejected': '-3.7078', 'rewards_train/margins': '3.9766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27545', 'examples_per_second': '5.9872', 'grad_norm': '5.25', 'counters/examples': 7680, 'counters/updates': 480}
skipping logging after 7696 examples to avoid logging too frequently
skipping logging after 7712 examples to avoid logging too frequently
skipping logging after 7728 examples to avoid logging too frequently
train stats after 7744 examples: {'rewards_train/chosen': '0.34278', 'rewards_train/rejected': '-3.4013', 'rewards_train/margins': '3.4805', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26746', 'examples_per_second': '5.4564', 'grad_norm': '4.375', 'counters/examples': 7744, 'counters/updates': 484}
skipping logging after 7760 examples to avoid logging too frequently
skipping logging after 7776 examples to avoid logging too frequently
skipping logging after 7792 examples to avoid logging too frequently
train stats after 7808 examples: {'rewards_train/chosen': '0.35244', 'rewards_train/rejected': '-4.3847', 'rewards_train/margins': '4.6875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24323', 'examples_per_second': '5.4025', 'grad_norm': '4.625', 'counters/examples': 7808, 'counters/updates': 488}
skipping logging after 7824 examples to avoid logging too frequently
skipping logging after 7840 examples to avoid logging too frequently
skipping logging after 7856 examples to avoid logging too frequently
train stats after 7872 examples: {'rewards_train/chosen': '0.054908', 'rewards_train/rejected': '-5.297', 'rewards_train/margins': '5.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21405', 'examples_per_second': '5.4192', 'grad_norm': '3.8125', 'counters/examples': 7872, 'counters/updates': 492}
skipping logging after 7888 examples to avoid logging too frequently
skipping logging after 7904 examples to avoid logging too frequently
skipping logging after 7920 examples to avoid logging too frequently
train stats after 7936 examples: {'rewards_train/chosen': '0.040395', 'rewards_train/rejected': '-5.0412', 'rewards_train/margins': '5.0156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27753', 'examples_per_second': '4.8677', 'grad_norm': '5.5625', 'counters/examples': 7936, 'counters/updates': 496}
skipping logging after 7952 examples to avoid logging too frequently
skipping logging after 7968 examples to avoid logging too frequently
skipping logging after 7984 examples to avoid logging too frequently
train stats after 8000 examples: {'rewards_train/chosen': '0.38552', 'rewards_train/rejected': '-4.3762', 'rewards_train/margins': '4.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22693', 'examples_per_second': '6.719', 'grad_norm': '5.1875', 'counters/examples': 8000, 'counters/updates': 500}
Running evaluation after 8000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.26s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.26s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.17s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:40,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.66s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.48s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:34,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.51s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.41s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.28s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.51s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.18s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.31s/it]
eval after 8000: {'rewards_eval/chosen': '-4.4429', 'rewards_eval/rejected': '-4.7687', 'rewards_eval/margins': '0.23633', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46796'}
skipping logging after 8016 examples to avoid logging too frequently
skipping logging after 8032 examples to avoid logging too frequently
skipping logging after 8048 examples to avoid logging too frequently
train stats after 8064 examples: {'rewards_train/chosen': '0.60988', 'rewards_train/rejected': '-4.4145', 'rewards_train/margins': '5.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26501', 'examples_per_second': '4.7038', 'grad_norm': '4.9688', 'counters/examples': 8064, 'counters/updates': 504}
skipping logging after 8080 examples to avoid logging too frequently
skipping logging after 8096 examples to avoid logging too frequently
skipping logging after 8112 examples to avoid logging too frequently
train stats after 8128 examples: {'rewards_train/chosen': '0.33337', 'rewards_train/rejected': '-4.2436', 'rewards_train/margins': '4.4414', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28351', 'examples_per_second': '5.484', 'grad_norm': '4.6875', 'counters/examples': 8128, 'counters/updates': 508}
skipping logging after 8144 examples to avoid logging too frequently
skipping logging after 8160 examples to avoid logging too frequently
skipping logging after 8176 examples to avoid logging too frequently
train stats after 8192 examples: {'rewards_train/chosen': '0.23104', 'rewards_train/rejected': '-3.8369', 'rewards_train/margins': '4.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27087', 'examples_per_second': '5.8192', 'grad_norm': '4.8125', 'counters/examples': 8192, 'counters/updates': 512}
skipping logging after 8208 examples to avoid logging too frequently
skipping logging after 8224 examples to avoid logging too frequently
skipping logging after 8240 examples to avoid logging too frequently
train stats after 8256 examples: {'rewards_train/chosen': '0.39386', 'rewards_train/rejected': '-3.8234', 'rewards_train/margins': '4.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24255', 'examples_per_second': '5.415', 'grad_norm': '4.5312', 'counters/examples': 8256, 'counters/updates': 516}
skipping logging after 8272 examples to avoid logging too frequently
skipping logging after 8288 examples to avoid logging too frequently
skipping logging after 8304 examples to avoid logging too frequently
train stats after 8320 examples: {'rewards_train/chosen': '0.25994', 'rewards_train/rejected': '-3.9508', 'rewards_train/margins': '4.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25977', 'examples_per_second': '5.6314', 'grad_norm': '5', 'counters/examples': 8320, 'counters/updates': 520}
skipping logging after 8336 examples to avoid logging too frequently
skipping logging after 8352 examples to avoid logging too frequently
skipping logging after 8368 examples to avoid logging too frequently
train stats after 8384 examples: {'rewards_train/chosen': '0.42793', 'rewards_train/rejected': '-3.9453', 'rewards_train/margins': '4.5977', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24609', 'examples_per_second': '5.1856', 'grad_norm': '6.3438', 'counters/examples': 8384, 'counters/updates': 524}
skipping logging after 8400 examples to avoid logging too frequently
skipping logging after 8416 examples to avoid logging too frequently
skipping logging after 8432 examples to avoid logging too frequently
train stats after 8448 examples: {'rewards_train/chosen': '0.32932', 'rewards_train/rejected': '-4.0994', 'rewards_train/margins': '4.543', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2572', 'examples_per_second': '5.7783', 'grad_norm': '4.6875', 'counters/examples': 8448, 'counters/updates': 528}
skipping logging after 8464 examples to avoid logging too frequently
skipping logging after 8480 examples to avoid logging too frequently
skipping logging after 8496 examples to avoid logging too frequently
train stats after 8512 examples: {'rewards_train/chosen': '0.50453', 'rewards_train/rejected': '-5.5842', 'rewards_train/margins': '6.1719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25311', 'examples_per_second': '4.8161', 'grad_norm': '4.8438', 'counters/examples': 8512, 'counters/updates': 532}
skipping logging after 8528 examples to avoid logging too frequently
skipping logging after 8544 examples to avoid logging too frequently
skipping logging after 8560 examples to avoid logging too frequently
train stats after 8576 examples: {'rewards_train/chosen': '0.59307', 'rewards_train/rejected': '-3.5745', 'rewards_train/margins': '4.293', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25647', 'examples_per_second': '4.8708', 'grad_norm': '5.2188', 'counters/examples': 8576, 'counters/updates': 536}
skipping logging after 8592 examples to avoid logging too frequently
skipping logging after 8608 examples to avoid logging too frequently
skipping logging after 8624 examples to avoid logging too frequently
train stats after 8640 examples: {'rewards_train/chosen': '0.66907', 'rewards_train/rejected': '-4.3085', 'rewards_train/margins': '4.9883', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22144', 'examples_per_second': '3.8928', 'grad_norm': '5.375', 'counters/examples': 8640, 'counters/updates': 540}
skipping logging after 8656 examples to avoid logging too frequently
skipping logging after 8672 examples to avoid logging too frequently
skipping logging after 8688 examples to avoid logging too frequently
train stats after 8704 examples: {'rewards_train/chosen': '0.32586', 'rewards_train/rejected': '-3.8114', 'rewards_train/margins': '4.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2702', 'examples_per_second': '4.867', 'grad_norm': '6', 'counters/examples': 8704, 'counters/updates': 544}
skipping logging after 8720 examples to avoid logging too frequently
skipping logging after 8736 examples to avoid logging too frequently
skipping logging after 8752 examples to avoid logging too frequently
train stats after 8768 examples: {'rewards_train/chosen': '0.42101', 'rewards_train/rejected': '-4.4612', 'rewards_train/margins': '4.6562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26031', 'examples_per_second': '5.9056', 'grad_norm': '4.625', 'counters/examples': 8768, 'counters/updates': 548}
skipping logging after 8784 examples to avoid logging too frequently
skipping logging after 8800 examples to avoid logging too frequently
skipping logging after 8816 examples to avoid logging too frequently
train stats after 8832 examples: {'rewards_train/chosen': '0.15456', 'rewards_train/rejected': '-3.4032', 'rewards_train/margins': '3.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25854', 'examples_per_second': '5.7657', 'grad_norm': '4.8438', 'counters/examples': 8832, 'counters/updates': 552}
skipping logging after 8848 examples to avoid logging too frequently
skipping logging after 8864 examples to avoid logging too frequently
skipping logging after 8880 examples to avoid logging too frequently
train stats after 8896 examples: {'rewards_train/chosen': '0.58609', 'rewards_train/rejected': '-4.6047', 'rewards_train/margins': '5.1172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23016', 'examples_per_second': '4.3432', 'grad_norm': '4.75', 'counters/examples': 8896, 'counters/updates': 556}
skipping logging after 8912 examples to avoid logging too frequently
skipping logging after 8928 examples to avoid logging too frequently
skipping logging after 8944 examples to avoid logging too frequently
train stats after 8960 examples: {'rewards_train/chosen': '0.45432', 'rewards_train/rejected': '-4.8382', 'rewards_train/margins': '5.2109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24213', 'examples_per_second': '5.0709', 'grad_norm': '4.4375', 'counters/examples': 8960, 'counters/updates': 560}
skipping logging after 8976 examples to avoid logging too frequently
skipping logging after 8992 examples to avoid logging too frequently
skipping logging after 9008 examples to avoid logging too frequently
train stats after 9024 examples: {'rewards_train/chosen': '0.16955', 'rewards_train/rejected': '-6.4764', 'rewards_train/margins': '6.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28802', 'examples_per_second': '6.2138', 'grad_norm': '5.5', 'counters/examples': 9024, 'counters/updates': 564}
skipping logging after 9040 examples to avoid logging too frequently
skipping logging after 9056 examples to avoid logging too frequently
skipping logging after 9072 examples to avoid logging too frequently
train stats after 9088 examples: {'rewards_train/chosen': '0.38429', 'rewards_train/rejected': '-4.855', 'rewards_train/margins': '5.1875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24475', 'examples_per_second': '5.7062', 'grad_norm': '4.8438', 'counters/examples': 9088, 'counters/updates': 568}
skipping logging after 9104 examples to avoid logging too frequently
skipping logging after 9120 examples to avoid logging too frequently
skipping logging after 9136 examples to avoid logging too frequently
train stats after 9152 examples: {'rewards_train/chosen': '0.33981', 'rewards_train/rejected': '-4.3098', 'rewards_train/margins': '4.6562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20947', 'examples_per_second': '5.1817', 'grad_norm': '4.9062', 'counters/examples': 9152, 'counters/updates': 572}
skipping logging after 9168 examples to avoid logging too frequently
skipping logging after 9184 examples to avoid logging too frequently
skipping logging after 9200 examples to avoid logging too frequently
train stats after 9216 examples: {'rewards_train/chosen': '0.59344', 'rewards_train/rejected': '-3.7957', 'rewards_train/margins': '4.7227', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2157', 'examples_per_second': '5.1421', 'grad_norm': '4.9375', 'counters/examples': 9216, 'counters/updates': 576}
skipping logging after 9232 examples to avoid logging too frequently
skipping logging after 9248 examples to avoid logging too frequently
skipping logging after 9264 examples to avoid logging too frequently
train stats after 9280 examples: {'rewards_train/chosen': '0.40716', 'rewards_train/rejected': '-5.1087', 'rewards_train/margins': '5.6328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28888', 'examples_per_second': '5.3697', 'grad_norm': '5.375', 'counters/examples': 9280, 'counters/updates': 580}
skipping logging after 9296 examples to avoid logging too frequently
skipping logging after 9312 examples to avoid logging too frequently
skipping logging after 9328 examples to avoid logging too frequently
train stats after 9344 examples: {'rewards_train/chosen': '-0.2723', 'rewards_train/rejected': '-4.2171', 'rewards_train/margins': '3.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26093', 'examples_per_second': '4.4114', 'grad_norm': '4.8438', 'counters/examples': 9344, 'counters/updates': 584}
skipping logging after 9360 examples to avoid logging too frequently
skipping logging after 9376 examples to avoid logging too frequently
skipping logging after 9392 examples to avoid logging too frequently
train stats after 9408 examples: {'rewards_train/chosen': '0.60084', 'rewards_train/rejected': '-4.4984', 'rewards_train/margins': '4.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25458', 'examples_per_second': '4.3179', 'grad_norm': '4.9375', 'counters/examples': 9408, 'counters/updates': 588}
skipping logging after 9424 examples to avoid logging too frequently
skipping logging after 9440 examples to avoid logging too frequently
skipping logging after 9456 examples to avoid logging too frequently
train stats after 9472 examples: {'rewards_train/chosen': '0.21851', 'rewards_train/rejected': '-4.2841', 'rewards_train/margins': '4.4648', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24762', 'examples_per_second': '5.5779', 'grad_norm': '4.9062', 'counters/examples': 9472, 'counters/updates': 592}
skipping logging after 9488 examples to avoid logging too frequently
skipping logging after 9504 examples to avoid logging too frequently
skipping logging after 9520 examples to avoid logging too frequently
train stats after 9536 examples: {'rewards_train/chosen': '0.47885', 'rewards_train/rejected': '-5.1697', 'rewards_train/margins': '5.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23083', 'examples_per_second': '4.948', 'grad_norm': '4.4375', 'counters/examples': 9536, 'counters/updates': 596}
skipping logging after 9552 examples to avoid logging too frequently
skipping logging after 9568 examples to avoid logging too frequently
skipping logging after 9584 examples to avoid logging too frequently
train stats after 9600 examples: {'rewards_train/chosen': '0.85053', 'rewards_train/rejected': '-4.1799', 'rewards_train/margins': '5.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21643', 'examples_per_second': '5.0511', 'grad_norm': '5.2188', 'counters/examples': 9600, 'counters/updates': 600}
skipping logging after 9616 examples to avoid logging too frequently
skipping logging after 9632 examples to avoid logging too frequently
skipping logging after 9648 examples to avoid logging too frequently
train stats after 9664 examples: {'rewards_train/chosen': '0.048815', 'rewards_train/rejected': '-4.1478', 'rewards_train/margins': '3.7539', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28784', 'examples_per_second': '5.6042', 'grad_norm': '5.4688', 'counters/examples': 9664, 'counters/updates': 604}
skipping logging after 9680 examples to avoid logging too frequently
skipping logging after 9696 examples to avoid logging too frequently
skipping logging after 9712 examples to avoid logging too frequently
train stats after 9728 examples: {'rewards_train/chosen': '0.74352', 'rewards_train/rejected': '-4.6098', 'rewards_train/margins': '5.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.203', 'examples_per_second': '4.5911', 'grad_norm': '4.25', 'counters/examples': 9728, 'counters/updates': 608}
skipping logging after 9744 examples to avoid logging too frequently
skipping logging after 9760 examples to avoid logging too frequently
skipping logging after 9776 examples to avoid logging too frequently
train stats after 9792 examples: {'rewards_train/chosen': '0.29449', 'rewards_train/rejected': '-4.2266', 'rewards_train/margins': '4.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2384', 'examples_per_second': '5.6603', 'grad_norm': '4.25', 'counters/examples': 9792, 'counters/updates': 612}
skipping logging after 9808 examples to avoid logging too frequently
skipping logging after 9824 examples to avoid logging too frequently
skipping logging after 9840 examples to avoid logging too frequently
train stats after 9856 examples: {'rewards_train/chosen': '0.39702', 'rewards_train/rejected': '-6.5668', 'rewards_train/margins': '6.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21075', 'examples_per_second': '4.5984', 'grad_norm': '4.1562', 'counters/examples': 9856, 'counters/updates': 616}
skipping logging after 9872 examples to avoid logging too frequently
skipping logging after 9888 examples to avoid logging too frequently
skipping logging after 9904 examples to avoid logging too frequently
train stats after 9920 examples: {'rewards_train/chosen': '0.46599', 'rewards_train/rejected': '-4.5632', 'rewards_train/margins': '5.0508', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24304', 'examples_per_second': '5.1557', 'grad_norm': '5.0625', 'counters/examples': 9920, 'counters/updates': 620}
skipping logging after 9936 examples to avoid logging too frequently
skipping logging after 9952 examples to avoid logging too frequently
skipping logging after 9968 examples to avoid logging too frequently
train stats after 9984 examples: {'rewards_train/chosen': '0.62752', 'rewards_train/rejected': '-4.2344', 'rewards_train/margins': '4.6641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22522', 'examples_per_second': '4.3335', 'grad_norm': '5.125', 'counters/examples': 9984, 'counters/updates': 624}
skipping logging after 10000 examples to avoid logging too frequently
skipping logging after 10016 examples to avoid logging too frequently
skipping logging after 10032 examples to avoid logging too frequently
train stats after 10048 examples: {'rewards_train/chosen': '0.27988', 'rewards_train/rejected': '-4.4281', 'rewards_train/margins': '4.6641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23218', 'examples_per_second': '5.9554', 'grad_norm': '5.875', 'counters/examples': 10048, 'counters/updates': 628}
skipping logging after 10064 examples to avoid logging too frequently
skipping logging after 10080 examples to avoid logging too frequently
skipping logging after 10096 examples to avoid logging too frequently
train stats after 10112 examples: {'rewards_train/chosen': '0.44909', 'rewards_train/rejected': '-3.9894', 'rewards_train/margins': '4.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21191', 'examples_per_second': '5.75', 'grad_norm': '4.875', 'counters/examples': 10112, 'counters/updates': 632}
skipping logging after 10128 examples to avoid logging too frequently
skipping logging after 10144 examples to avoid logging too frequently
skipping logging after 10160 examples to avoid logging too frequently
train stats after 10176 examples: {'rewards_train/chosen': '0.076709', 'rewards_train/rejected': '-5.7263', 'rewards_train/margins': '5.8906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26361', 'examples_per_second': '5.1835', 'grad_norm': '5.7812', 'counters/examples': 10176, 'counters/updates': 636}
skipping logging after 10192 examples to avoid logging too frequently
skipping logging after 10208 examples to avoid logging too frequently
skipping logging after 10224 examples to avoid logging too frequently
train stats after 10240 examples: {'rewards_train/chosen': '0.62111', 'rewards_train/rejected': '-3.8117', 'rewards_train/margins': '4.375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23322', 'examples_per_second': '4.9288', 'grad_norm': '5.1562', 'counters/examples': 10240, 'counters/updates': 640}
skipping logging after 10256 examples to avoid logging too frequently
skipping logging after 10272 examples to avoid logging too frequently
skipping logging after 10288 examples to avoid logging too frequently
train stats after 10304 examples: {'rewards_train/chosen': '0.60093', 'rewards_train/rejected': '-5.9125', 'rewards_train/margins': '6.1992', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23572', 'examples_per_second': '4.3685', 'grad_norm': '4.9688', 'counters/examples': 10304, 'counters/updates': 644}
skipping logging after 10320 examples to avoid logging too frequently
skipping logging after 10336 examples to avoid logging too frequently
skipping logging after 10352 examples to avoid logging too frequently
train stats after 10368 examples: {'rewards_train/chosen': '0.3287', 'rewards_train/rejected': '-5.4098', 'rewards_train/margins': '5.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21655', 'examples_per_second': '5.6287', 'grad_norm': '4.125', 'counters/examples': 10368, 'counters/updates': 648}
skipping logging after 10384 examples to avoid logging too frequently
skipping logging after 10400 examples to avoid logging too frequently
skipping logging after 10416 examples to avoid logging too frequently
train stats after 10432 examples: {'rewards_train/chosen': '0.40825', 'rewards_train/rejected': '-3.292', 'rewards_train/margins': '3.6836', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28009', 'examples_per_second': '6.5237', 'grad_norm': '4.9688', 'counters/examples': 10432, 'counters/updates': 652}
skipping logging after 10448 examples to avoid logging too frequently
skipping logging after 10464 examples to avoid logging too frequently
skipping logging after 10480 examples to avoid logging too frequently
train stats after 10496 examples: {'rewards_train/chosen': '0.55829', 'rewards_train/rejected': '-5.3718', 'rewards_train/margins': '5.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24432', 'examples_per_second': '5.5446', 'grad_norm': '4.125', 'counters/examples': 10496, 'counters/updates': 656}
skipping logging after 10512 examples to avoid logging too frequently
skipping logging after 10528 examples to avoid logging too frequently
skipping logging after 10544 examples to avoid logging too frequently
train stats after 10560 examples: {'rewards_train/chosen': '0.19121', 'rewards_train/rejected': '-4.801', 'rewards_train/margins': '4.8828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19147', 'examples_per_second': '5.8381', 'grad_norm': '4.4375', 'counters/examples': 10560, 'counters/updates': 660}
skipping logging after 10576 examples to avoid logging too frequently
skipping logging after 10592 examples to avoid logging too frequently
skipping logging after 10608 examples to avoid logging too frequently
train stats after 10624 examples: {'rewards_train/chosen': '0.79771', 'rewards_train/rejected': '-5.4789', 'rewards_train/margins': '6.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.15198', 'examples_per_second': '3.922', 'grad_norm': '3.6406', 'counters/examples': 10624, 'counters/updates': 664}
skipping logging after 10640 examples to avoid logging too frequently
skipping logging after 10656 examples to avoid logging too frequently
skipping logging after 10672 examples to avoid logging too frequently
train stats after 10688 examples: {'rewards_train/chosen': '0.38086', 'rewards_train/rejected': '-5.5049', 'rewards_train/margins': '6.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26141', 'examples_per_second': '5.3392', 'grad_norm': '5.5', 'counters/examples': 10688, 'counters/updates': 668}
skipping logging after 10704 examples to avoid logging too frequently
skipping logging after 10720 examples to avoid logging too frequently
skipping logging after 10736 examples to avoid logging too frequently
train stats after 10752 examples: {'rewards_train/chosen': '0.32913', 'rewards_train/rejected': '-5.0213', 'rewards_train/margins': '5.3867', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28021', 'examples_per_second': '4.9223', 'grad_norm': '4.9062', 'counters/examples': 10752, 'counters/updates': 672}
skipping logging after 10768 examples to avoid logging too frequently
skipping logging after 10784 examples to avoid logging too frequently
skipping logging after 10800 examples to avoid logging too frequently
train stats after 10816 examples: {'rewards_train/chosen': '0.14583', 'rewards_train/rejected': '-5.001', 'rewards_train/margins': '5.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24396', 'examples_per_second': '5.2871', 'grad_norm': '5.1875', 'counters/examples': 10816, 'counters/updates': 676}
skipping logging after 10832 examples to avoid logging too frequently
skipping logging after 10848 examples to avoid logging too frequently
skipping logging after 10864 examples to avoid logging too frequently
train stats after 10880 examples: {'rewards_train/chosen': '0.29016', 'rewards_train/rejected': '-5.0399', 'rewards_train/margins': '5.4414', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2533', 'examples_per_second': '5.1905', 'grad_norm': '5', 'counters/examples': 10880, 'counters/updates': 680}
skipping logging after 10896 examples to avoid logging too frequently
skipping logging after 10912 examples to avoid logging too frequently
skipping logging after 10928 examples to avoid logging too frequently
train stats after 10944 examples: {'rewards_train/chosen': '0.11534', 'rewards_train/rejected': '-4.5544', 'rewards_train/margins': '4.6211', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25665', 'examples_per_second': '5.941', 'grad_norm': '5.375', 'counters/examples': 10944, 'counters/updates': 684}
skipping logging after 10960 examples to avoid logging too frequently
skipping logging after 10976 examples to avoid logging too frequently
skipping logging after 10992 examples to avoid logging too frequently
train stats after 11008 examples: {'rewards_train/chosen': '0.26389', 'rewards_train/rejected': '-5.2567', 'rewards_train/margins': '5.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29919', 'examples_per_second': '5.6474', 'grad_norm': '5.3125', 'counters/examples': 11008, 'counters/updates': 688}
skipping logging after 11024 examples to avoid logging too frequently
skipping logging after 11040 examples to avoid logging too frequently
skipping logging after 11056 examples to avoid logging too frequently
train stats after 11072 examples: {'rewards_train/chosen': '0.30748', 'rewards_train/rejected': '-4.5725', 'rewards_train/margins': '4.8906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24744', 'examples_per_second': '4.8054', 'grad_norm': '4.75', 'counters/examples': 11072, 'counters/updates': 692}
skipping logging after 11088 examples to avoid logging too frequently
skipping logging after 11104 examples to avoid logging too frequently
skipping logging after 11120 examples to avoid logging too frequently
train stats after 11136 examples: {'rewards_train/chosen': '0.4369', 'rewards_train/rejected': '-6.0874', 'rewards_train/margins': '6.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20593', 'examples_per_second': '4.8268', 'grad_norm': '4.9375', 'counters/examples': 11136, 'counters/updates': 696}
skipping logging after 11152 examples to avoid logging too frequently
skipping logging after 11168 examples to avoid logging too frequently
skipping logging after 11184 examples to avoid logging too frequently
train stats after 11200 examples: {'rewards_train/chosen': '0.42489', 'rewards_train/rejected': '-4.1914', 'rewards_train/margins': '4.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23273', 'examples_per_second': '5.1425', 'grad_norm': '4.8125', 'counters/examples': 11200, 'counters/updates': 700}
skipping logging after 11216 examples to avoid logging too frequently
skipping logging after 11232 examples to avoid logging too frequently
skipping logging after 11248 examples to avoid logging too frequently
train stats after 11264 examples: {'rewards_train/chosen': '0.61631', 'rewards_train/rejected': '-5.3926', 'rewards_train/margins': '5.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22858', 'examples_per_second': '5.3076', 'grad_norm': '4.6875', 'counters/examples': 11264, 'counters/updates': 704}
skipping logging after 11280 examples to avoid logging too frequently
skipping logging after 11296 examples to avoid logging too frequently
skipping logging after 11312 examples to avoid logging too frequently
train stats after 11328 examples: {'rewards_train/chosen': '0.15047', 'rewards_train/rejected': '-5.3265', 'rewards_train/margins': '5.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28143', 'examples_per_second': '4.0764', 'grad_norm': '6.2188', 'counters/examples': 11328, 'counters/updates': 708}
skipping logging after 11344 examples to avoid logging too frequently
skipping logging after 11360 examples to avoid logging too frequently
skipping logging after 11376 examples to avoid logging too frequently
train stats after 11392 examples: {'rewards_train/chosen': '0.49579', 'rewards_train/rejected': '-5.0543', 'rewards_train/margins': '5.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23883', 'examples_per_second': '5.8613', 'grad_norm': '5.3438', 'counters/examples': 11392, 'counters/updates': 712}
skipping logging after 11408 examples to avoid logging too frequently
skipping logging after 11424 examples to avoid logging too frequently
skipping logging after 11440 examples to avoid logging too frequently
train stats after 11456 examples: {'rewards_train/chosen': '0.35983', 'rewards_train/rejected': '-4.3824', 'rewards_train/margins': '4.8867', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26135', 'examples_per_second': '4.6734', 'grad_norm': '4.6875', 'counters/examples': 11456, 'counters/updates': 716}
skipping logging after 11472 examples to avoid logging too frequently
skipping logging after 11488 examples to avoid logging too frequently
skipping logging after 11504 examples to avoid logging too frequently
train stats after 11520 examples: {'rewards_train/chosen': '0.3695', 'rewards_train/rejected': '-5.0575', 'rewards_train/margins': '5.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27667', 'examples_per_second': '5.9701', 'grad_norm': '5.1562', 'counters/examples': 11520, 'counters/updates': 720}
skipping logging after 11536 examples to avoid logging too frequently
skipping logging after 11552 examples to avoid logging too frequently
skipping logging after 11568 examples to avoid logging too frequently
train stats after 11584 examples: {'rewards_train/chosen': '0.77017', 'rewards_train/rejected': '-2.4096', 'rewards_train/margins': '3.2148', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25793', 'examples_per_second': '5.035', 'grad_norm': '5.5625', 'counters/examples': 11584, 'counters/updates': 724}
skipping logging after 11600 examples to avoid logging too frequently
skipping logging after 11616 examples to avoid logging too frequently
skipping logging after 11632 examples to avoid logging too frequently
train stats after 11648 examples: {'rewards_train/chosen': '0.46146', 'rewards_train/rejected': '-6.4622', 'rewards_train/margins': '6.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21796', 'examples_per_second': '4.1768', 'grad_norm': '4.9375', 'counters/examples': 11648, 'counters/updates': 728}
skipping logging after 11664 examples to avoid logging too frequently
skipping logging after 11680 examples to avoid logging too frequently
skipping logging after 11696 examples to avoid logging too frequently
train stats after 11712 examples: {'rewards_train/chosen': '0.2787', 'rewards_train/rejected': '-5.0222', 'rewards_train/margins': '5.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24207', 'examples_per_second': '5.763', 'grad_norm': '4.7812', 'counters/examples': 11712, 'counters/updates': 732}
skipping logging after 11728 examples to avoid logging too frequently
skipping logging after 11744 examples to avoid logging too frequently
skipping logging after 11760 examples to avoid logging too frequently
train stats after 11776 examples: {'rewards_train/chosen': '0.45572', 'rewards_train/rejected': '-5.3221', 'rewards_train/margins': '5.8672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22858', 'examples_per_second': '4.4706', 'grad_norm': '4.6562', 'counters/examples': 11776, 'counters/updates': 736}
skipping logging after 11792 examples to avoid logging too frequently
skipping logging after 11808 examples to avoid logging too frequently
skipping logging after 11824 examples to avoid logging too frequently
train stats after 11840 examples: {'rewards_train/chosen': '0.55976', 'rewards_train/rejected': '-4.8262', 'rewards_train/margins': '5.8125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23218', 'examples_per_second': '5.3933', 'grad_norm': '4.625', 'counters/examples': 11840, 'counters/updates': 740}
skipping logging after 11856 examples to avoid logging too frequently
skipping logging after 11872 examples to avoid logging too frequently
skipping logging after 11888 examples to avoid logging too frequently
train stats after 11904 examples: {'rewards_train/chosen': '0.21763', 'rewards_train/rejected': '-5.3558', 'rewards_train/margins': '5.6016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26935', 'examples_per_second': '5.4537', 'grad_norm': '4.875', 'counters/examples': 11904, 'counters/updates': 744}
skipping logging after 11920 examples to avoid logging too frequently
skipping logging after 11936 examples to avoid logging too frequently
skipping logging after 11952 examples to avoid logging too frequently
train stats after 11968 examples: {'rewards_train/chosen': '0.58116', 'rewards_train/rejected': '-5.3799', 'rewards_train/margins': '5.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19189', 'examples_per_second': '4.5946', 'grad_norm': '4.1562', 'counters/examples': 11968, 'counters/updates': 748}
skipping logging after 11984 examples to avoid logging too frequently
skipping logging after 12000 examples to avoid logging too frequently
Running evaluation after 12000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:47,  1.55s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:41,  1.38s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:35,  1.24s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.47s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.68s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.49s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:34,  1.37s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:30,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.31s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.18s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.31s/it]
eval after 12000: {'rewards_eval/chosen': '-4.902', 'rewards_eval/rejected': '-5.277', 'rewards_eval/margins': '0.2666', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46152'}
skipping logging after 12016 examples to avoid logging too frequently
train stats after 12032 examples: {'rewards_train/chosen': '0.38309', 'rewards_train/rejected': '-5.7784', 'rewards_train/margins': '6.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23853', 'examples_per_second': '5.7298', 'grad_norm': '5.5', 'counters/examples': 12032, 'counters/updates': 752}
skipping logging after 12048 examples to avoid logging too frequently
skipping logging after 12064 examples to avoid logging too frequently
skipping logging after 12080 examples to avoid logging too frequently
train stats after 12096 examples: {'rewards_train/chosen': '0.47178', 'rewards_train/rejected': '-4.5888', 'rewards_train/margins': '5.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26624', 'examples_per_second': '6.0176', 'grad_norm': '5', 'counters/examples': 12096, 'counters/updates': 756}
skipping logging after 12112 examples to avoid logging too frequently
skipping logging after 12128 examples to avoid logging too frequently
skipping logging after 12144 examples to avoid logging too frequently
train stats after 12160 examples: {'rewards_train/chosen': '0.17641', 'rewards_train/rejected': '-3.9747', 'rewards_train/margins': '4.0352', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2746', 'examples_per_second': '5.6451', 'grad_norm': '5.5312', 'counters/examples': 12160, 'counters/updates': 760}
skipping logging after 12176 examples to avoid logging too frequently
skipping logging after 12192 examples to avoid logging too frequently
skipping logging after 12208 examples to avoid logging too frequently
train stats after 12224 examples: {'rewards_train/chosen': '0.30448', 'rewards_train/rejected': '-5.0352', 'rewards_train/margins': '5.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24396', 'examples_per_second': '4.1863', 'grad_norm': '5.375', 'counters/examples': 12224, 'counters/updates': 764}
skipping logging after 12240 examples to avoid logging too frequently
skipping logging after 12256 examples to avoid logging too frequently
skipping logging after 12272 examples to avoid logging too frequently
train stats after 12288 examples: {'rewards_train/chosen': '0.37193', 'rewards_train/rejected': '-4.8353', 'rewards_train/margins': '5.1719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23199', 'examples_per_second': '5.0696', 'grad_norm': '4.25', 'counters/examples': 12288, 'counters/updates': 768}
skipping logging after 12304 examples to avoid logging too frequently
skipping logging after 12320 examples to avoid logging too frequently
skipping logging after 12336 examples to avoid logging too frequently
train stats after 12352 examples: {'rewards_train/chosen': '0.52441', 'rewards_train/rejected': '-4.623', 'rewards_train/margins': '5.4727', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21942', 'examples_per_second': '5.2682', 'grad_norm': '5', 'counters/examples': 12352, 'counters/updates': 772}
skipping logging after 12368 examples to avoid logging too frequently
skipping logging after 12384 examples to avoid logging too frequently
skipping logging after 12400 examples to avoid logging too frequently
train stats after 12416 examples: {'rewards_train/chosen': '0.43636', 'rewards_train/rejected': '-6.4764', 'rewards_train/margins': '6.8828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1734', 'examples_per_second': '4.6312', 'grad_norm': '4.0625', 'counters/examples': 12416, 'counters/updates': 776}
skipping logging after 12432 examples to avoid logging too frequently
skipping logging after 12448 examples to avoid logging too frequently
skipping logging after 12464 examples to avoid logging too frequently
train stats after 12480 examples: {'rewards_train/chosen': '0.27631', 'rewards_train/rejected': '-5.7477', 'rewards_train/margins': '5.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23438', 'examples_per_second': '5.1563', 'grad_norm': '5.0938', 'counters/examples': 12480, 'counters/updates': 780}
skipping logging after 12496 examples to avoid logging too frequently
skipping logging after 12512 examples to avoid logging too frequently
skipping logging after 12528 examples to avoid logging too frequently
train stats after 12544 examples: {'rewards_train/chosen': '0.21513', 'rewards_train/rejected': '-5.4113', 'rewards_train/margins': '5.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26251', 'examples_per_second': '4.913', 'grad_norm': '4.9688', 'counters/examples': 12544, 'counters/updates': 784}
skipping logging after 12560 examples to avoid logging too frequently
skipping logging after 12576 examples to avoid logging too frequently
skipping logging after 12592 examples to avoid logging too frequently
train stats after 12608 examples: {'rewards_train/chosen': '0.73104', 'rewards_train/rejected': '-3.965', 'rewards_train/margins': '4.6602', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20514', 'examples_per_second': '4.936', 'grad_norm': '4.7812', 'counters/examples': 12608, 'counters/updates': 788}
skipping logging after 12624 examples to avoid logging too frequently
skipping logging after 12640 examples to avoid logging too frequently
skipping logging after 12656 examples to avoid logging too frequently
train stats after 12672 examples: {'rewards_train/chosen': '0.15146', 'rewards_train/rejected': '-5.3901', 'rewards_train/margins': '4.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.33533', 'examples_per_second': '5.1153', 'grad_norm': '6.0938', 'counters/examples': 12672, 'counters/updates': 792}
skipping logging after 12688 examples to avoid logging too frequently
skipping logging after 12704 examples to avoid logging too frequently
skipping logging after 12720 examples to avoid logging too frequently
train stats after 12736 examples: {'rewards_train/chosen': '0.6613', 'rewards_train/rejected': '-4.0112', 'rewards_train/margins': '4.6562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20624', 'examples_per_second': '6.1809', 'grad_norm': '4', 'counters/examples': 12736, 'counters/updates': 796}
skipping logging after 12752 examples to avoid logging too frequently
skipping logging after 12768 examples to avoid logging too frequently
skipping logging after 12784 examples to avoid logging too frequently
train stats after 12800 examples: {'rewards_train/chosen': '0.49956', 'rewards_train/rejected': '-4.0251', 'rewards_train/margins': '4.5664', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24396', 'examples_per_second': '5.3245', 'grad_norm': '5.3125', 'counters/examples': 12800, 'counters/updates': 800}
skipping logging after 12816 examples to avoid logging too frequently
skipping logging after 12832 examples to avoid logging too frequently
skipping logging after 12848 examples to avoid logging too frequently
train stats after 12864 examples: {'rewards_train/chosen': '0.30293', 'rewards_train/rejected': '-4.5021', 'rewards_train/margins': '4.9961', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28778', 'examples_per_second': '5.2386', 'grad_norm': '5.5938', 'counters/examples': 12864, 'counters/updates': 804}
skipping logging after 12880 examples to avoid logging too frequently
skipping logging after 12896 examples to avoid logging too frequently
skipping logging after 12912 examples to avoid logging too frequently
train stats after 12928 examples: {'rewards_train/chosen': '0.39709', 'rewards_train/rejected': '-3.8558', 'rewards_train/margins': '4.4805', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24268', 'examples_per_second': '5.7159', 'grad_norm': '4.9375', 'counters/examples': 12928, 'counters/updates': 808}
skipping logging after 12944 examples to avoid logging too frequently
skipping logging after 12960 examples to avoid logging too frequently
skipping logging after 12976 examples to avoid logging too frequently
train stats after 12992 examples: {'rewards_train/chosen': '0.4063', 'rewards_train/rejected': '-4.574', 'rewards_train/margins': '4.8242', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23364', 'examples_per_second': '4.9004', 'grad_norm': '4.2812', 'counters/examples': 12992, 'counters/updates': 812}
skipping logging after 13008 examples to avoid logging too frequently
skipping logging after 13024 examples to avoid logging too frequently
skipping logging after 13040 examples to avoid logging too frequently
train stats after 13056 examples: {'rewards_train/chosen': '0.39883', 'rewards_train/rejected': '-4.3128', 'rewards_train/margins': '4.707', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24182', 'examples_per_second': '4.6541', 'grad_norm': '4.5312', 'counters/examples': 13056, 'counters/updates': 816}
skipping logging after 13072 examples to avoid logging too frequently
skipping logging after 13088 examples to avoid logging too frequently
skipping logging after 13104 examples to avoid logging too frequently
train stats after 13120 examples: {'rewards_train/chosen': '0.28024', 'rewards_train/rejected': '-6.3104', 'rewards_train/margins': '6.8867', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25623', 'examples_per_second': '5.3887', 'grad_norm': '4.8438', 'counters/examples': 13120, 'counters/updates': 820}
skipping logging after 13136 examples to avoid logging too frequently
skipping logging after 13152 examples to avoid logging too frequently
skipping logging after 13168 examples to avoid logging too frequently
train stats after 13184 examples: {'rewards_train/chosen': '0.59836', 'rewards_train/rejected': '-4.8407', 'rewards_train/margins': '5.4531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20245', 'examples_per_second': '5.728', 'grad_norm': '5.1562', 'counters/examples': 13184, 'counters/updates': 824}
skipping logging after 13200 examples to avoid logging too frequently
skipping logging after 13216 examples to avoid logging too frequently
skipping logging after 13232 examples to avoid logging too frequently
train stats after 13248 examples: {'rewards_train/chosen': '0.46533', 'rewards_train/rejected': '-4.9957', 'rewards_train/margins': '5.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21613', 'examples_per_second': '4.7479', 'grad_norm': '4.4375', 'counters/examples': 13248, 'counters/updates': 828}
skipping logging after 13264 examples to avoid logging too frequently
skipping logging after 13280 examples to avoid logging too frequently
skipping logging after 13296 examples to avoid logging too frequently
train stats after 13312 examples: {'rewards_train/chosen': '0.57169', 'rewards_train/rejected': '-4.9573', 'rewards_train/margins': '5.6445', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23358', 'examples_per_second': '3.8416', 'grad_norm': '5.0938', 'counters/examples': 13312, 'counters/updates': 832}
skipping logging after 13328 examples to avoid logging too frequently
skipping logging after 13344 examples to avoid logging too frequently
skipping logging after 13360 examples to avoid logging too frequently
train stats after 13376 examples: {'rewards_train/chosen': '0.41908', 'rewards_train/rejected': '-7.1948', 'rewards_train/margins': '7.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22437', 'examples_per_second': '5.9098', 'grad_norm': '5.125', 'counters/examples': 13376, 'counters/updates': 836}
skipping logging after 13392 examples to avoid logging too frequently
skipping logging after 13408 examples to avoid logging too frequently
skipping logging after 13424 examples to avoid logging too frequently
train stats after 13440 examples: {'rewards_train/chosen': '0.314', 'rewards_train/rejected': '-4.2504', 'rewards_train/margins': '4.4961', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23993', 'examples_per_second': '5.7995', 'grad_norm': '4.9062', 'counters/examples': 13440, 'counters/updates': 840}
skipping logging after 13456 examples to avoid logging too frequently
skipping logging after 13472 examples to avoid logging too frequently
skipping logging after 13488 examples to avoid logging too frequently
train stats after 13504 examples: {'rewards_train/chosen': '0.10952', 'rewards_train/rejected': '-4.7635', 'rewards_train/margins': '4.9102', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26447', 'examples_per_second': '4.1686', 'grad_norm': '5.4688', 'counters/examples': 13504, 'counters/updates': 844}
skipping logging after 13520 examples to avoid logging too frequently
skipping logging after 13536 examples to avoid logging too frequently
skipping logging after 13552 examples to avoid logging too frequently
train stats after 13568 examples: {'rewards_train/chosen': '0.37758', 'rewards_train/rejected': '-4.3384', 'rewards_train/margins': '4.4844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24432', 'examples_per_second': '6.055', 'grad_norm': '4.7188', 'counters/examples': 13568, 'counters/updates': 848}
skipping logging after 13584 examples to avoid logging too frequently
skipping logging after 13600 examples to avoid logging too frequently
skipping logging after 13616 examples to avoid logging too frequently
train stats after 13632 examples: {'rewards_train/chosen': '0.57015', 'rewards_train/rejected': '-4.8491', 'rewards_train/margins': '5.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23492', 'examples_per_second': '6.1472', 'grad_norm': '4.6875', 'counters/examples': 13632, 'counters/updates': 852}
skipping logging after 13648 examples to avoid logging too frequently
skipping logging after 13664 examples to avoid logging too frequently
skipping logging after 13680 examples to avoid logging too frequently
train stats after 13696 examples: {'rewards_train/chosen': '0.51279', 'rewards_train/rejected': '-4.9344', 'rewards_train/margins': '5.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21558', 'examples_per_second': '5.7138', 'grad_norm': '4.4062', 'counters/examples': 13696, 'counters/updates': 856}
skipping logging after 13712 examples to avoid logging too frequently
skipping logging after 13728 examples to avoid logging too frequently
skipping logging after 13744 examples to avoid logging too frequently
train stats after 13760 examples: {'rewards_train/chosen': '0.52163', 'rewards_train/rejected': '-4.229', 'rewards_train/margins': '4.6094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26129', 'examples_per_second': '4.7194', 'grad_norm': '5.0625', 'counters/examples': 13760, 'counters/updates': 860}
skipping logging after 13776 examples to avoid logging too frequently
skipping logging after 13792 examples to avoid logging too frequently
skipping logging after 13808 examples to avoid logging too frequently
train stats after 13824 examples: {'rewards_train/chosen': '0.7442', 'rewards_train/rejected': '-5.0431', 'rewards_train/margins': '5.5684', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19983', 'examples_per_second': '4.9298', 'grad_norm': '5.0625', 'counters/examples': 13824, 'counters/updates': 864}
skipping logging after 13840 examples to avoid logging too frequently
skipping logging after 13856 examples to avoid logging too frequently
skipping logging after 13872 examples to avoid logging too frequently
train stats after 13888 examples: {'rewards_train/chosen': '0.41108', 'rewards_train/rejected': '-5.1038', 'rewards_train/margins': '5.4531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28131', 'examples_per_second': '5.3581', 'grad_norm': '4.4062', 'counters/examples': 13888, 'counters/updates': 868}
skipping logging after 13904 examples to avoid logging too frequently
skipping logging after 13920 examples to avoid logging too frequently
skipping logging after 13936 examples to avoid logging too frequently
train stats after 13952 examples: {'rewards_train/chosen': '0.31907', 'rewards_train/rejected': '-5.0343', 'rewards_train/margins': '5.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21912', 'examples_per_second': '4.954', 'grad_norm': '4.4062', 'counters/examples': 13952, 'counters/updates': 872}
skipping logging after 13968 examples to avoid logging too frequently
skipping logging after 13984 examples to avoid logging too frequently
skipping logging after 14000 examples to avoid logging too frequently
train stats after 14016 examples: {'rewards_train/chosen': '0.26734', 'rewards_train/rejected': '-5.8425', 'rewards_train/margins': '6.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23145', 'examples_per_second': '4.2576', 'grad_norm': '4.625', 'counters/examples': 14016, 'counters/updates': 876}
skipping logging after 14032 examples to avoid logging too frequently
skipping logging after 14048 examples to avoid logging too frequently
skipping logging after 14064 examples to avoid logging too frequently
train stats after 14080 examples: {'rewards_train/chosen': '0.23098', 'rewards_train/rejected': '-5.3263', 'rewards_train/margins': '5.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2793', 'examples_per_second': '5.653', 'grad_norm': '5.9375', 'counters/examples': 14080, 'counters/updates': 880}
skipping logging after 14096 examples to avoid logging too frequently
skipping logging after 14112 examples to avoid logging too frequently
skipping logging after 14128 examples to avoid logging too frequently
train stats after 14144 examples: {'rewards_train/chosen': '0.307', 'rewards_train/rejected': '-3.5659', 'rewards_train/margins': '3.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26605', 'examples_per_second': '5.6571', 'grad_norm': '4.5625', 'counters/examples': 14144, 'counters/updates': 884}
skipping logging after 14160 examples to avoid logging too frequently
skipping logging after 14176 examples to avoid logging too frequently
skipping logging after 14192 examples to avoid logging too frequently
train stats after 14208 examples: {'rewards_train/chosen': '0.53945', 'rewards_train/rejected': '-4.4233', 'rewards_train/margins': '4.6094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24188', 'examples_per_second': '5.2715', 'grad_norm': '5.25', 'counters/examples': 14208, 'counters/updates': 888}
skipping logging after 14224 examples to avoid logging too frequently
skipping logging after 14240 examples to avoid logging too frequently
skipping logging after 14256 examples to avoid logging too frequently
train stats after 14272 examples: {'rewards_train/chosen': '0.64261', 'rewards_train/rejected': '-4.571', 'rewards_train/margins': '5.2695', 'rewards_train/KL_estimate': '0', 'loss/train': '0.16125', 'examples_per_second': '6.0444', 'grad_norm': '4.375', 'counters/examples': 14272, 'counters/updates': 892}
skipping logging after 14288 examples to avoid logging too frequently
skipping logging after 14304 examples to avoid logging too frequently
skipping logging after 14320 examples to avoid logging too frequently
train stats after 14336 examples: {'rewards_train/chosen': '0.44652', 'rewards_train/rejected': '-6.1128', 'rewards_train/margins': '6.5781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19519', 'examples_per_second': '5.0579', 'grad_norm': '5.4688', 'counters/examples': 14336, 'counters/updates': 896}
skipping logging after 14352 examples to avoid logging too frequently
skipping logging after 14368 examples to avoid logging too frequently
skipping logging after 14384 examples to avoid logging too frequently
train stats after 14400 examples: {'rewards_train/chosen': '0.19523', 'rewards_train/rejected': '-4.2593', 'rewards_train/margins': '4.457', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24731', 'examples_per_second': '5.7975', 'grad_norm': '5.8125', 'counters/examples': 14400, 'counters/updates': 900}
skipping logging after 14416 examples to avoid logging too frequently
skipping logging after 14432 examples to avoid logging too frequently
skipping logging after 14448 examples to avoid logging too frequently
train stats after 14464 examples: {'rewards_train/chosen': '0.71753', 'rewards_train/rejected': '-4.601', 'rewards_train/margins': '5.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20026', 'examples_per_second': '4.5943', 'grad_norm': '4.9062', 'counters/examples': 14464, 'counters/updates': 904}
skipping logging after 14480 examples to avoid logging too frequently
skipping logging after 14496 examples to avoid logging too frequently
skipping logging after 14512 examples to avoid logging too frequently
train stats after 14528 examples: {'rewards_train/chosen': '0.58086', 'rewards_train/rejected': '-5.2174', 'rewards_train/margins': '5.793', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21082', 'examples_per_second': '5.4648', 'grad_norm': '4.8438', 'counters/examples': 14528, 'counters/updates': 908}
skipping logging after 14544 examples to avoid logging too frequently
skipping logging after 14560 examples to avoid logging too frequently
skipping logging after 14576 examples to avoid logging too frequently
train stats after 14592 examples: {'rewards_train/chosen': '0.32022', 'rewards_train/rejected': '-6.4217', 'rewards_train/margins': '6.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21838', 'examples_per_second': '5.1784', 'grad_norm': '5.1562', 'counters/examples': 14592, 'counters/updates': 912}
skipping logging after 14608 examples to avoid logging too frequently
skipping logging after 14624 examples to avoid logging too frequently
skipping logging after 14640 examples to avoid logging too frequently
train stats after 14656 examples: {'rewards_train/chosen': '0.21614', 'rewards_train/rejected': '-5.0543', 'rewards_train/margins': '5.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27856', 'examples_per_second': '5.0061', 'grad_norm': '5.4062', 'counters/examples': 14656, 'counters/updates': 916}
skipping logging after 14672 examples to avoid logging too frequently
skipping logging after 14688 examples to avoid logging too frequently
skipping logging after 14704 examples to avoid logging too frequently
train stats after 14720 examples: {'rewards_train/chosen': '0.46535', 'rewards_train/rejected': '-3.8042', 'rewards_train/margins': '4.2617', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2417', 'examples_per_second': '5.3816', 'grad_norm': '5.25', 'counters/examples': 14720, 'counters/updates': 920}
skipping logging after 14736 examples to avoid logging too frequently
skipping logging after 14752 examples to avoid logging too frequently
skipping logging after 14768 examples to avoid logging too frequently
train stats after 14784 examples: {'rewards_train/chosen': '0.4406', 'rewards_train/rejected': '-4.3697', 'rewards_train/margins': '4.7578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24463', 'examples_per_second': '5.0245', 'grad_norm': '5.7812', 'counters/examples': 14784, 'counters/updates': 924}
skipping logging after 14800 examples to avoid logging too frequently
skipping logging after 14816 examples to avoid logging too frequently
skipping logging after 14832 examples to avoid logging too frequently
train stats after 14848 examples: {'rewards_train/chosen': '0.37605', 'rewards_train/rejected': '-5.0582', 'rewards_train/margins': '5.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24579', 'examples_per_second': '4.8412', 'grad_norm': '4.6875', 'counters/examples': 14848, 'counters/updates': 928}
skipping logging after 14864 examples to avoid logging too frequently
skipping logging after 14880 examples to avoid logging too frequently
skipping logging after 14896 examples to avoid logging too frequently
train stats after 14912 examples: {'rewards_train/chosen': '0.50436', 'rewards_train/rejected': '-6.243', 'rewards_train/margins': '6.5469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24408', 'examples_per_second': '6.6442', 'grad_norm': '5.3125', 'counters/examples': 14912, 'counters/updates': 932}
skipping logging after 14928 examples to avoid logging too frequently
skipping logging after 14944 examples to avoid logging too frequently
skipping logging after 14960 examples to avoid logging too frequently
train stats after 14976 examples: {'rewards_train/chosen': '0.50298', 'rewards_train/rejected': '-5.2392', 'rewards_train/margins': '5.7812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22217', 'examples_per_second': '5.1172', 'grad_norm': '5.5625', 'counters/examples': 14976, 'counters/updates': 936}
skipping logging after 14992 examples to avoid logging too frequently
skipping logging after 15008 examples to avoid logging too frequently
skipping logging after 15024 examples to avoid logging too frequently
train stats after 15040 examples: {'rewards_train/chosen': '0.34015', 'rewards_train/rejected': '-4.7887', 'rewards_train/margins': '5.2852', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26575', 'examples_per_second': '6.3385', 'grad_norm': '4.5312', 'counters/examples': 15040, 'counters/updates': 940}
skipping logging after 15056 examples to avoid logging too frequently
skipping logging after 15072 examples to avoid logging too frequently
skipping logging after 15088 examples to avoid logging too frequently
train stats after 15104 examples: {'rewards_train/chosen': '0.21969', 'rewards_train/rejected': '-4.7725', 'rewards_train/margins': '5.1289', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24884', 'examples_per_second': '5.3941', 'grad_norm': '4.875', 'counters/examples': 15104, 'counters/updates': 944}
skipping logging after 15120 examples to avoid logging too frequently
skipping logging after 15136 examples to avoid logging too frequently
skipping logging after 15152 examples to avoid logging too frequently
train stats after 15168 examples: {'rewards_train/chosen': '0.78338', 'rewards_train/rejected': '-4.6481', 'rewards_train/margins': '5.4609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2356', 'examples_per_second': '5.0837', 'grad_norm': '5.6562', 'counters/examples': 15168, 'counters/updates': 948}
skipping logging after 15184 examples to avoid logging too frequently
skipping logging after 15200 examples to avoid logging too frequently
skipping logging after 15216 examples to avoid logging too frequently
train stats after 15232 examples: {'rewards_train/chosen': '0.35169', 'rewards_train/rejected': '-4.1113', 'rewards_train/margins': '4.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24255', 'examples_per_second': '6.196', 'grad_norm': '5.625', 'counters/examples': 15232, 'counters/updates': 952}
skipping logging after 15248 examples to avoid logging too frequently
skipping logging after 15264 examples to avoid logging too frequently
skipping logging after 15280 examples to avoid logging too frequently
train stats after 15296 examples: {'rewards_train/chosen': '0.41377', 'rewards_train/rejected': '-5.4224', 'rewards_train/margins': '5.9375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23566', 'examples_per_second': '5.5938', 'grad_norm': '5.0938', 'counters/examples': 15296, 'counters/updates': 956}
skipping logging after 15312 examples to avoid logging too frequently
skipping logging after 15328 examples to avoid logging too frequently
skipping logging after 15344 examples to avoid logging too frequently
train stats after 15360 examples: {'rewards_train/chosen': '0.25448', 'rewards_train/rejected': '-4.5023', 'rewards_train/margins': '4.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26697', 'examples_per_second': '5.4084', 'grad_norm': '5.625', 'counters/examples': 15360, 'counters/updates': 960}
skipping logging after 15376 examples to avoid logging too frequently
skipping logging after 15392 examples to avoid logging too frequently
skipping logging after 15408 examples to avoid logging too frequently
train stats after 15424 examples: {'rewards_train/chosen': '0.72372', 'rewards_train/rejected': '-4.7558', 'rewards_train/margins': '5.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21606', 'examples_per_second': '4.4916', 'grad_norm': '5.25', 'counters/examples': 15424, 'counters/updates': 964}
skipping logging after 15440 examples to avoid logging too frequently
skipping logging after 15456 examples to avoid logging too frequently
skipping logging after 15472 examples to avoid logging too frequently
train stats after 15488 examples: {'rewards_train/chosen': '0.48888', 'rewards_train/rejected': '-5.2176', 'rewards_train/margins': '5.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26733', 'examples_per_second': '5.1842', 'grad_norm': '5.125', 'counters/examples': 15488, 'counters/updates': 968}
skipping logging after 15504 examples to avoid logging too frequently
skipping logging after 15520 examples to avoid logging too frequently
skipping logging after 15536 examples to avoid logging too frequently
train stats after 15552 examples: {'rewards_train/chosen': '0.52586', 'rewards_train/rejected': '-4.2225', 'rewards_train/margins': '4.7305', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23712', 'examples_per_second': '5.1925', 'grad_norm': '4.4688', 'counters/examples': 15552, 'counters/updates': 972}
skipping logging after 15568 examples to avoid logging too frequently
skipping logging after 15584 examples to avoid logging too frequently
skipping logging after 15600 examples to avoid logging too frequently
train stats after 15616 examples: {'rewards_train/chosen': '0.30685', 'rewards_train/rejected': '-4.3783', 'rewards_train/margins': '4.7148', 'rewards_train/KL_estimate': '0', 'loss/train': '0.31775', 'examples_per_second': '5.2825', 'grad_norm': '5.5', 'counters/examples': 15616, 'counters/updates': 976}
skipping logging after 15632 examples to avoid logging too frequently
skipping logging after 15648 examples to avoid logging too frequently
skipping logging after 15664 examples to avoid logging too frequently
train stats after 15680 examples: {'rewards_train/chosen': '0.22396', 'rewards_train/rejected': '-4.7151', 'rewards_train/margins': '4.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2215', 'examples_per_second': '4.8507', 'grad_norm': '4.5312', 'counters/examples': 15680, 'counters/updates': 980}
skipping logging after 15696 examples to avoid logging too frequently
skipping logging after 15712 examples to avoid logging too frequently
skipping logging after 15728 examples to avoid logging too frequently
train stats after 15744 examples: {'rewards_train/chosen': '0.34098', 'rewards_train/rejected': '-5.3759', 'rewards_train/margins': '5.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25751', 'examples_per_second': '4.5574', 'grad_norm': '5.375', 'counters/examples': 15744, 'counters/updates': 984}
skipping logging after 15760 examples to avoid logging too frequently
skipping logging after 15776 examples to avoid logging too frequently
skipping logging after 15792 examples to avoid logging too frequently
train stats after 15808 examples: {'rewards_train/chosen': '0.49962', 'rewards_train/rejected': '-5.9415', 'rewards_train/margins': '6.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23346', 'examples_per_second': '5.5036', 'grad_norm': '4.625', 'counters/examples': 15808, 'counters/updates': 988}
skipping logging after 15824 examples to avoid logging too frequently
skipping logging after 15840 examples to avoid logging too frequently
skipping logging after 15856 examples to avoid logging too frequently
train stats after 15872 examples: {'rewards_train/chosen': '0.41387', 'rewards_train/rejected': '-6.0552', 'rewards_train/margins': '6.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28577', 'examples_per_second': '5.1331', 'grad_norm': '5.5312', 'counters/examples': 15872, 'counters/updates': 992}
skipping logging after 15888 examples to avoid logging too frequently
skipping logging after 15904 examples to avoid logging too frequently
skipping logging after 15920 examples to avoid logging too frequently
train stats after 15936 examples: {'rewards_train/chosen': '0.48092', 'rewards_train/rejected': '-4.8614', 'rewards_train/margins': '5.1875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2373', 'examples_per_second': '4.7021', 'grad_norm': '4.5938', 'counters/examples': 15936, 'counters/updates': 996}
skipping logging after 15952 examples to avoid logging too frequently
skipping logging after 15968 examples to avoid logging too frequently
skipping logging after 15984 examples to avoid logging too frequently
train stats after 16000 examples: {'rewards_train/chosen': '0.6018', 'rewards_train/rejected': '-4.6934', 'rewards_train/margins': '5.5664', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22675', 'examples_per_second': '5.674', 'grad_norm': '4.7188', 'counters/examples': 16000, 'counters/updates': 1000}
Running evaluation after 16000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:39,  1.26s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.26s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.17s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:40,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.66s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.48s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:34,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.41s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.39s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.28s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.20s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.31s/it]
eval after 16000: {'rewards_eval/chosen': '-4.8634', 'rewards_eval/rejected': '-5.1207', 'rewards_eval/margins': '0.13818', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46278'}
skipping logging after 16016 examples to avoid logging too frequently
skipping logging after 16032 examples to avoid logging too frequently
skipping logging after 16048 examples to avoid logging too frequently
train stats after 16064 examples: {'rewards_train/chosen': '0.49254', 'rewards_train/rejected': '-5.5819', 'rewards_train/margins': '6.3203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22424', 'examples_per_second': '4.3165', 'grad_norm': '5.0312', 'counters/examples': 16064, 'counters/updates': 1004}
skipping logging after 16080 examples to avoid logging too frequently
skipping logging after 16096 examples to avoid logging too frequently
skipping logging after 16112 examples to avoid logging too frequently
train stats after 16128 examples: {'rewards_train/chosen': '0.60355', 'rewards_train/rejected': '-6.2415', 'rewards_train/margins': '6.8984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2121', 'examples_per_second': '5.2744', 'grad_norm': '5.5938', 'counters/examples': 16128, 'counters/updates': 1008}
skipping logging after 16144 examples to avoid logging too frequently
skipping logging after 16160 examples to avoid logging too frequently
skipping logging after 16176 examples to avoid logging too frequently
train stats after 16192 examples: {'rewards_train/chosen': '0.50547', 'rewards_train/rejected': '-4.2873', 'rewards_train/margins': '4.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24878', 'examples_per_second': '4.534', 'grad_norm': '5.4062', 'counters/examples': 16192, 'counters/updates': 1012}
skipping logging after 16208 examples to avoid logging too frequently
skipping logging after 16224 examples to avoid logging too frequently
skipping logging after 16240 examples to avoid logging too frequently
train stats after 16256 examples: {'rewards_train/chosen': '0.48831', 'rewards_train/rejected': '-4.7971', 'rewards_train/margins': '5.3203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21863', 'examples_per_second': '4.4688', 'grad_norm': '4.625', 'counters/examples': 16256, 'counters/updates': 1016}
skipping logging after 16272 examples to avoid logging too frequently
skipping logging after 16288 examples to avoid logging too frequently
skipping logging after 16304 examples to avoid logging too frequently
train stats after 16320 examples: {'rewards_train/chosen': '0.68676', 'rewards_train/rejected': '-4.8786', 'rewards_train/margins': '5.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20514', 'examples_per_second': '5.1063', 'grad_norm': '4.9688', 'counters/examples': 16320, 'counters/updates': 1020}
skipping logging after 16336 examples to avoid logging too frequently
skipping logging after 16352 examples to avoid logging too frequently
skipping logging after 16368 examples to avoid logging too frequently
train stats after 16384 examples: {'rewards_train/chosen': '0.34779', 'rewards_train/rejected': '-4.4695', 'rewards_train/margins': '4.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25684', 'examples_per_second': '4.963', 'grad_norm': '5.0312', 'counters/examples': 16384, 'counters/updates': 1024}
skipping logging after 16400 examples to avoid logging too frequently
skipping logging after 16416 examples to avoid logging too frequently
skipping logging after 16432 examples to avoid logging too frequently
train stats after 16448 examples: {'rewards_train/chosen': '0.28376', 'rewards_train/rejected': '-4.6102', 'rewards_train/margins': '4.8984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25891', 'examples_per_second': '5.5884', 'grad_norm': '5.0938', 'counters/examples': 16448, 'counters/updates': 1028}
skipping logging after 16464 examples to avoid logging too frequently
skipping logging after 16480 examples to avoid logging too frequently
skipping logging after 16496 examples to avoid logging too frequently
train stats after 16512 examples: {'rewards_train/chosen': '0.27845', 'rewards_train/rejected': '-4.335', 'rewards_train/margins': '4.6094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24023', 'examples_per_second': '6.1313', 'grad_norm': '4.5938', 'counters/examples': 16512, 'counters/updates': 1032}
skipping logging after 16528 examples to avoid logging too frequently
skipping logging after 16544 examples to avoid logging too frequently
skipping logging after 16560 examples to avoid logging too frequently
train stats after 16576 examples: {'rewards_train/chosen': '0.26746', 'rewards_train/rejected': '-5.7896', 'rewards_train/margins': '6.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25385', 'examples_per_second': '4.5529', 'grad_norm': '5', 'counters/examples': 16576, 'counters/updates': 1036}
skipping logging after 16592 examples to avoid logging too frequently
skipping logging after 16608 examples to avoid logging too frequently
skipping logging after 16624 examples to avoid logging too frequently
train stats after 16640 examples: {'rewards_train/chosen': '0.13926', 'rewards_train/rejected': '-4.8151', 'rewards_train/margins': '4.8477', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2514', 'examples_per_second': '6.2158', 'grad_norm': '4.625', 'counters/examples': 16640, 'counters/updates': 1040}
skipping logging after 16656 examples to avoid logging too frequently
skipping logging after 16672 examples to avoid logging too frequently
skipping logging after 16688 examples to avoid logging too frequently
train stats after 16704 examples: {'rewards_train/chosen': '0.49223', 'rewards_train/rejected': '-3.7329', 'rewards_train/margins': '3.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24738', 'examples_per_second': '6.075', 'grad_norm': '5.6875', 'counters/examples': 16704, 'counters/updates': 1044}
skipping logging after 16720 examples to avoid logging too frequently
skipping logging after 16736 examples to avoid logging too frequently
skipping logging after 16752 examples to avoid logging too frequently
train stats after 16768 examples: {'rewards_train/chosen': '0.37274', 'rewards_train/rejected': '-4.597', 'rewards_train/margins': '4.8203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22705', 'examples_per_second': '5.0755', 'grad_norm': '4.8125', 'counters/examples': 16768, 'counters/updates': 1048}
skipping logging after 16784 examples to avoid logging too frequently
skipping logging after 16800 examples to avoid logging too frequently
skipping logging after 16816 examples to avoid logging too frequently
train stats after 16832 examples: {'rewards_train/chosen': '0.2761', 'rewards_train/rejected': '-4.6077', 'rewards_train/margins': '4.8125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23804', 'examples_per_second': '5.1169', 'grad_norm': '5.7188', 'counters/examples': 16832, 'counters/updates': 1052}
skipping logging after 16848 examples to avoid logging too frequently
skipping logging after 16864 examples to avoid logging too frequently
skipping logging after 16880 examples to avoid logging too frequently
train stats after 16896 examples: {'rewards_train/chosen': '0.32112', 'rewards_train/rejected': '-4.4438', 'rewards_train/margins': '4.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.31476', 'examples_per_second': '4.1647', 'grad_norm': '5.3438', 'counters/examples': 16896, 'counters/updates': 1056}
skipping logging after 16912 examples to avoid logging too frequently
skipping logging after 16928 examples to avoid logging too frequently
skipping logging after 16944 examples to avoid logging too frequently
train stats after 16960 examples: {'rewards_train/chosen': '0.21275', 'rewards_train/rejected': '-4.2538', 'rewards_train/margins': '4.3711', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27008', 'examples_per_second': '5.6509', 'grad_norm': '5.6875', 'counters/examples': 16960, 'counters/updates': 1060}
skipping logging after 16976 examples to avoid logging too frequently
skipping logging after 16992 examples to avoid logging too frequently
skipping logging after 17008 examples to avoid logging too frequently
train stats after 17024 examples: {'rewards_train/chosen': '0.52679', 'rewards_train/rejected': '-4.577', 'rewards_train/margins': '4.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2301', 'examples_per_second': '5.1829', 'grad_norm': '5.1875', 'counters/examples': 17024, 'counters/updates': 1064}
skipping logging after 17040 examples to avoid logging too frequently
skipping logging after 17056 examples to avoid logging too frequently
skipping logging after 17072 examples to avoid logging too frequently
train stats after 17088 examples: {'rewards_train/chosen': '0.47519', 'rewards_train/rejected': '-5.7318', 'rewards_train/margins': '6.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22443', 'examples_per_second': '4.8084', 'grad_norm': '4.625', 'counters/examples': 17088, 'counters/updates': 1068}
skipping logging after 17104 examples to avoid logging too frequently
skipping logging after 17120 examples to avoid logging too frequently
skipping logging after 17136 examples to avoid logging too frequently
train stats after 17152 examples: {'rewards_train/chosen': '0.39854', 'rewards_train/rejected': '-5.4983', 'rewards_train/margins': '5.8984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27576', 'examples_per_second': '5.0238', 'grad_norm': '5.125', 'counters/examples': 17152, 'counters/updates': 1072}
skipping logging after 17168 examples to avoid logging too frequently
skipping logging after 17184 examples to avoid logging too frequently
skipping logging after 17200 examples to avoid logging too frequently
train stats after 17216 examples: {'rewards_train/chosen': '0.54304', 'rewards_train/rejected': '-5.483', 'rewards_train/margins': '6.0312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21503', 'examples_per_second': '5.8854', 'grad_norm': '4.6875', 'counters/examples': 17216, 'counters/updates': 1076}
skipping logging after 17232 examples to avoid logging too frequently
skipping logging after 17248 examples to avoid logging too frequently
skipping logging after 17264 examples to avoid logging too frequently
train stats after 17280 examples: {'rewards_train/chosen': '0.40288', 'rewards_train/rejected': '-5.3593', 'rewards_train/margins': '5.7891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28009', 'examples_per_second': '4.9886', 'grad_norm': '5.4375', 'counters/examples': 17280, 'counters/updates': 1080}
skipping logging after 17296 examples to avoid logging too frequently
skipping logging after 17312 examples to avoid logging too frequently
skipping logging after 17328 examples to avoid logging too frequently
train stats after 17344 examples: {'rewards_train/chosen': '0.49726', 'rewards_train/rejected': '-3.8292', 'rewards_train/margins': '4.4844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25769', 'examples_per_second': '5.4163', 'grad_norm': '4.6562', 'counters/examples': 17344, 'counters/updates': 1084}
skipping logging after 17360 examples to avoid logging too frequently
skipping logging after 17376 examples to avoid logging too frequently
skipping logging after 17392 examples to avoid logging too frequently
train stats after 17408 examples: {'rewards_train/chosen': '0.27792', 'rewards_train/rejected': '-5.2695', 'rewards_train/margins': '5.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28766', 'examples_per_second': '4.8859', 'grad_norm': '6.1875', 'counters/examples': 17408, 'counters/updates': 1088}
skipping logging after 17424 examples to avoid logging too frequently
skipping logging after 17440 examples to avoid logging too frequently
skipping logging after 17456 examples to avoid logging too frequently
train stats after 17472 examples: {'rewards_train/chosen': '0.61896', 'rewards_train/rejected': '-4.5033', 'rewards_train/margins': '5.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24463', 'examples_per_second': '4.4704', 'grad_norm': '4.8125', 'counters/examples': 17472, 'counters/updates': 1092}
skipping logging after 17488 examples to avoid logging too frequently
skipping logging after 17504 examples to avoid logging too frequently
skipping logging after 17520 examples to avoid logging too frequently
train stats after 17536 examples: {'rewards_train/chosen': '0.38698', 'rewards_train/rejected': '-4.4358', 'rewards_train/margins': '4.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22418', 'examples_per_second': '6.2864', 'grad_norm': '4.25', 'counters/examples': 17536, 'counters/updates': 1096}
skipping logging after 17552 examples to avoid logging too frequently
skipping logging after 17568 examples to avoid logging too frequently
skipping logging after 17584 examples to avoid logging too frequently
train stats after 17600 examples: {'rewards_train/chosen': '0.3892', 'rewards_train/rejected': '-4.4148', 'rewards_train/margins': '4.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25665', 'examples_per_second': '4.4333', 'grad_norm': '5.125', 'counters/examples': 17600, 'counters/updates': 1100}
skipping logging after 17616 examples to avoid logging too frequently
skipping logging after 17632 examples to avoid logging too frequently
skipping logging after 17648 examples to avoid logging too frequently
train stats after 17664 examples: {'rewards_train/chosen': '0.66667', 'rewards_train/rejected': '-4.4384', 'rewards_train/margins': '5.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22186', 'examples_per_second': '6.1417', 'grad_norm': '4.5', 'counters/examples': 17664, 'counters/updates': 1104}
skipping logging after 17680 examples to avoid logging too frequently
skipping logging after 17696 examples to avoid logging too frequently
skipping logging after 17712 examples to avoid logging too frequently
train stats after 17728 examples: {'rewards_train/chosen': '0.46887', 'rewards_train/rejected': '-4.6812', 'rewards_train/margins': '4.8945', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26581', 'examples_per_second': '6.44', 'grad_norm': '5.2812', 'counters/examples': 17728, 'counters/updates': 1108}
skipping logging after 17744 examples to avoid logging too frequently
skipping logging after 17760 examples to avoid logging too frequently
skipping logging after 17776 examples to avoid logging too frequently
train stats after 17792 examples: {'rewards_train/chosen': '0.46694', 'rewards_train/rejected': '-4.9447', 'rewards_train/margins': '5.3203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21814', 'examples_per_second': '5.7898', 'grad_norm': '4.0625', 'counters/examples': 17792, 'counters/updates': 1112}
skipping logging after 17808 examples to avoid logging too frequently
skipping logging after 17824 examples to avoid logging too frequently
skipping logging after 17840 examples to avoid logging too frequently
train stats after 17856 examples: {'rewards_train/chosen': '0.32258', 'rewards_train/rejected': '-6.0229', 'rewards_train/margins': '6.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21515', 'examples_per_second': '5.5732', 'grad_norm': '4.125', 'counters/examples': 17856, 'counters/updates': 1116}
skipping logging after 17872 examples to avoid logging too frequently
skipping logging after 17888 examples to avoid logging too frequently
skipping logging after 17904 examples to avoid logging too frequently
train stats after 17920 examples: {'rewards_train/chosen': '0.58722', 'rewards_train/rejected': '-4.2838', 'rewards_train/margins': '4.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20795', 'examples_per_second': '4.9676', 'grad_norm': '5.6875', 'counters/examples': 17920, 'counters/updates': 1120}
skipping logging after 17936 examples to avoid logging too frequently
skipping logging after 17952 examples to avoid logging too frequently
skipping logging after 17968 examples to avoid logging too frequently
train stats after 17984 examples: {'rewards_train/chosen': '0.58548', 'rewards_train/rejected': '-5.5918', 'rewards_train/margins': '6.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22388', 'examples_per_second': '5.1879', 'grad_norm': '4.4688', 'counters/examples': 17984, 'counters/updates': 1124}
skipping logging after 18000 examples to avoid logging too frequently
skipping logging after 18016 examples to avoid logging too frequently
skipping logging after 18032 examples to avoid logging too frequently
train stats after 18048 examples: {'rewards_train/chosen': '0.54984', 'rewards_train/rejected': '-6.2722', 'rewards_train/margins': '6.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24384', 'examples_per_second': '4.7501', 'grad_norm': '5.1562', 'counters/examples': 18048, 'counters/updates': 1128}
skipping logging after 18064 examples to avoid logging too frequently
skipping logging after 18080 examples to avoid logging too frequently
skipping logging after 18096 examples to avoid logging too frequently
train stats after 18112 examples: {'rewards_train/chosen': '0.5829', 'rewards_train/rejected': '-4.5341', 'rewards_train/margins': '5.1992', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23157', 'examples_per_second': '5.5667', 'grad_norm': '4.8438', 'counters/examples': 18112, 'counters/updates': 1132}
skipping logging after 18128 examples to avoid logging too frequently
skipping logging after 18144 examples to avoid logging too frequently
skipping logging after 18160 examples to avoid logging too frequently
train stats after 18176 examples: {'rewards_train/chosen': '0.44004', 'rewards_train/rejected': '-5.1677', 'rewards_train/margins': '5.8984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25909', 'examples_per_second': '5.5448', 'grad_norm': '5.75', 'counters/examples': 18176, 'counters/updates': 1136}
skipping logging after 18192 examples to avoid logging too frequently
skipping logging after 18208 examples to avoid logging too frequently
skipping logging after 18224 examples to avoid logging too frequently
train stats after 18240 examples: {'rewards_train/chosen': '0.5955', 'rewards_train/rejected': '-4.4391', 'rewards_train/margins': '5.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23755', 'examples_per_second': '4.0702', 'grad_norm': '4.75', 'counters/examples': 18240, 'counters/updates': 1140}
skipping logging after 18256 examples to avoid logging too frequently
skipping logging after 18272 examples to avoid logging too frequently
skipping logging after 18288 examples to avoid logging too frequently
train stats after 18304 examples: {'rewards_train/chosen': '0.34757', 'rewards_train/rejected': '-3.8546', 'rewards_train/margins': '4.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27002', 'examples_per_second': '5.0227', 'grad_norm': '5', 'counters/examples': 18304, 'counters/updates': 1144}
skipping logging after 18320 examples to avoid logging too frequently
skipping logging after 18336 examples to avoid logging too frequently
skipping logging after 18352 examples to avoid logging too frequently
train stats after 18368 examples: {'rewards_train/chosen': '0.61251', 'rewards_train/rejected': '-4.9147', 'rewards_train/margins': '5.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19604', 'examples_per_second': '4.8796', 'grad_norm': '4.5625', 'counters/examples': 18368, 'counters/updates': 1148}
skipping logging after 18384 examples to avoid logging too frequently
skipping logging after 18400 examples to avoid logging too frequently
skipping logging after 18416 examples to avoid logging too frequently
train stats after 18432 examples: {'rewards_train/chosen': '0.16706', 'rewards_train/rejected': '-5.1238', 'rewards_train/margins': '5.1875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21979', 'examples_per_second': '6.2354', 'grad_norm': '4.4062', 'counters/examples': 18432, 'counters/updates': 1152}
skipping logging after 18448 examples to avoid logging too frequently
skipping logging after 18464 examples to avoid logging too frequently
skipping logging after 18480 examples to avoid logging too frequently
train stats after 18496 examples: {'rewards_train/chosen': '0.19508', 'rewards_train/rejected': '-5.7927', 'rewards_train/margins': '6.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20013', 'examples_per_second': '5.904', 'grad_norm': '4.2188', 'counters/examples': 18496, 'counters/updates': 1156}
skipping logging after 18512 examples to avoid logging too frequently
skipping logging after 18528 examples to avoid logging too frequently
skipping logging after 18544 examples to avoid logging too frequently
train stats after 18560 examples: {'rewards_train/chosen': '0.47411', 'rewards_train/rejected': '-5.7635', 'rewards_train/margins': '6.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19263', 'examples_per_second': '4.7324', 'grad_norm': '4.25', 'counters/examples': 18560, 'counters/updates': 1160}
skipping logging after 18576 examples to avoid logging too frequently
skipping logging after 18592 examples to avoid logging too frequently
skipping logging after 18608 examples to avoid logging too frequently
train stats after 18624 examples: {'rewards_train/chosen': '0.49704', 'rewards_train/rejected': '-4.817', 'rewards_train/margins': '5.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22394', 'examples_per_second': '5.7774', 'grad_norm': '4.3125', 'counters/examples': 18624, 'counters/updates': 1164}
skipping logging after 18640 examples to avoid logging too frequently
skipping logging after 18656 examples to avoid logging too frequently
skipping logging after 18672 examples to avoid logging too frequently
train stats after 18688 examples: {'rewards_train/chosen': '0.5267', 'rewards_train/rejected': '-5.4324', 'rewards_train/margins': '5.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18744', 'examples_per_second': '4.8111', 'grad_norm': '4.0312', 'counters/examples': 18688, 'counters/updates': 1168}
skipping logging after 18704 examples to avoid logging too frequently
skipping logging after 18720 examples to avoid logging too frequently
skipping logging after 18736 examples to avoid logging too frequently
train stats after 18752 examples: {'rewards_train/chosen': '0.48499', 'rewards_train/rejected': '-7.0234', 'rewards_train/margins': '7.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21216', 'examples_per_second': '4.9864', 'grad_norm': '4.7812', 'counters/examples': 18752, 'counters/updates': 1172}
skipping logging after 18768 examples to avoid logging too frequently
skipping logging after 18784 examples to avoid logging too frequently
skipping logging after 18800 examples to avoid logging too frequently
train stats after 18816 examples: {'rewards_train/chosen': '0.28253', 'rewards_train/rejected': '-5.774', 'rewards_train/margins': '5.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26099', 'examples_per_second': '5.5778', 'grad_norm': '5.3125', 'counters/examples': 18816, 'counters/updates': 1176}
skipping logging after 18832 examples to avoid logging too frequently
skipping logging after 18848 examples to avoid logging too frequently
skipping logging after 18864 examples to avoid logging too frequently
train stats after 18880 examples: {'rewards_train/chosen': '0.41734', 'rewards_train/rejected': '-4.8616', 'rewards_train/margins': '5.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26428', 'examples_per_second': '4.8199', 'grad_norm': '5.25', 'counters/examples': 18880, 'counters/updates': 1180}
skipping logging after 18896 examples to avoid logging too frequently
skipping logging after 18912 examples to avoid logging too frequently
skipping logging after 18928 examples to avoid logging too frequently
train stats after 18944 examples: {'rewards_train/chosen': '0.43427', 'rewards_train/rejected': '-5.8292', 'rewards_train/margins': '6.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24689', 'examples_per_second': '5.2438', 'grad_norm': '5.1875', 'counters/examples': 18944, 'counters/updates': 1184}
skipping logging after 18960 examples to avoid logging too frequently
skipping logging after 18976 examples to avoid logging too frequently
skipping logging after 18992 examples to avoid logging too frequently
train stats after 19008 examples: {'rewards_train/chosen': '0.67687', 'rewards_train/rejected': '-4.762', 'rewards_train/margins': '5.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23657', 'examples_per_second': '4.7753', 'grad_norm': '5.375', 'counters/examples': 19008, 'counters/updates': 1188}
skipping logging after 19024 examples to avoid logging too frequently
skipping logging after 19040 examples to avoid logging too frequently
skipping logging after 19056 examples to avoid logging too frequently
train stats after 19072 examples: {'rewards_train/chosen': '0.69227', 'rewards_train/rejected': '-5.4367', 'rewards_train/margins': '6.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24646', 'examples_per_second': '4.6081', 'grad_norm': '4.5938', 'counters/examples': 19072, 'counters/updates': 1192}
skipping logging after 19088 examples to avoid logging too frequently
skipping logging after 19104 examples to avoid logging too frequently
skipping logging after 19120 examples to avoid logging too frequently
train stats after 19136 examples: {'rewards_train/chosen': '0.46824', 'rewards_train/rejected': '-5.4473', 'rewards_train/margins': '6.1914', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21893', 'examples_per_second': '5.11', 'grad_norm': '5.2188', 'counters/examples': 19136, 'counters/updates': 1196}
skipping logging after 19152 examples to avoid logging too frequently
skipping logging after 19168 examples to avoid logging too frequently
skipping logging after 19184 examples to avoid logging too frequently
train stats after 19200 examples: {'rewards_train/chosen': '0.48575', 'rewards_train/rejected': '-4.664', 'rewards_train/margins': '5.2773', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22192', 'examples_per_second': '5.3853', 'grad_norm': '5.3125', 'counters/examples': 19200, 'counters/updates': 1200}
skipping logging after 19216 examples to avoid logging too frequently
skipping logging after 19232 examples to avoid logging too frequently
skipping logging after 19248 examples to avoid logging too frequently
train stats after 19264 examples: {'rewards_train/chosen': '0.30964', 'rewards_train/rejected': '-4.358', 'rewards_train/margins': '4.6094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24335', 'examples_per_second': '6.8968', 'grad_norm': '5.0625', 'counters/examples': 19264, 'counters/updates': 1204}
skipping logging after 19280 examples to avoid logging too frequently
skipping logging after 19296 examples to avoid logging too frequently
skipping logging after 19312 examples to avoid logging too frequently
train stats after 19328 examples: {'rewards_train/chosen': '0.43573', 'rewards_train/rejected': '-5.1292', 'rewards_train/margins': '5.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28381', 'examples_per_second': '4.4508', 'grad_norm': '5.5938', 'counters/examples': 19328, 'counters/updates': 1208}
skipping logging after 19344 examples to avoid logging too frequently
skipping logging after 19360 examples to avoid logging too frequently
skipping logging after 19376 examples to avoid logging too frequently
train stats after 19392 examples: {'rewards_train/chosen': '0.62578', 'rewards_train/rejected': '-4.6786', 'rewards_train/margins': '5.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19458', 'examples_per_second': '5.6051', 'grad_norm': '5.25', 'counters/examples': 19392, 'counters/updates': 1212}
skipping logging after 19408 examples to avoid logging too frequently
skipping logging after 19424 examples to avoid logging too frequently
skipping logging after 19440 examples to avoid logging too frequently
train stats after 19456 examples: {'rewards_train/chosen': '0.55395', 'rewards_train/rejected': '-4.0052', 'rewards_train/margins': '4.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21722', 'examples_per_second': '5.337', 'grad_norm': '4.4688', 'counters/examples': 19456, 'counters/updates': 1216}
skipping logging after 19472 examples to avoid logging too frequently
skipping logging after 19488 examples to avoid logging too frequently
skipping logging after 19504 examples to avoid logging too frequently
train stats after 19520 examples: {'rewards_train/chosen': '0.82287', 'rewards_train/rejected': '-6.2417', 'rewards_train/margins': '6.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20691', 'examples_per_second': '5.6256', 'grad_norm': '5.0312', 'counters/examples': 19520, 'counters/updates': 1220}
skipping logging after 19536 examples to avoid logging too frequently
skipping logging after 19552 examples to avoid logging too frequently
skipping logging after 19568 examples to avoid logging too frequently
train stats after 19584 examples: {'rewards_train/chosen': '0.17576', 'rewards_train/rejected': '-5.9868', 'rewards_train/margins': '6.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24402', 'examples_per_second': '6.3004', 'grad_norm': '5.0938', 'counters/examples': 19584, 'counters/updates': 1224}
skipping logging after 19600 examples to avoid logging too frequently
skipping logging after 19616 examples to avoid logging too frequently
skipping logging after 19632 examples to avoid logging too frequently
train stats after 19648 examples: {'rewards_train/chosen': '0.64268', 'rewards_train/rejected': '-4.9986', 'rewards_train/margins': '5.6484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22955', 'examples_per_second': '5.6395', 'grad_norm': '4.5', 'counters/examples': 19648, 'counters/updates': 1228}
skipping logging after 19664 examples to avoid logging too frequently
skipping logging after 19680 examples to avoid logging too frequently
skipping logging after 19696 examples to avoid logging too frequently
train stats after 19712 examples: {'rewards_train/chosen': '0.24198', 'rewards_train/rejected': '-6.0237', 'rewards_train/margins': '5.7734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23279', 'examples_per_second': '5.1776', 'grad_norm': '4.0312', 'counters/examples': 19712, 'counters/updates': 1232}
skipping logging after 19728 examples to avoid logging too frequently
skipping logging after 19744 examples to avoid logging too frequently
skipping logging after 19760 examples to avoid logging too frequently
train stats after 19776 examples: {'rewards_train/chosen': '0.38298', 'rewards_train/rejected': '-4.8397', 'rewards_train/margins': '5.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27063', 'examples_per_second': '4.6786', 'grad_norm': '5.5', 'counters/examples': 19776, 'counters/updates': 1236}
skipping logging after 19792 examples to avoid logging too frequently
skipping logging after 19808 examples to avoid logging too frequently
skipping logging after 19824 examples to avoid logging too frequently
train stats after 19840 examples: {'rewards_train/chosen': '0.42873', 'rewards_train/rejected': '-4.5684', 'rewards_train/margins': '4.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22357', 'examples_per_second': '5.3379', 'grad_norm': '4.25', 'counters/examples': 19840, 'counters/updates': 1240}
skipping logging after 19856 examples to avoid logging too frequently
skipping logging after 19872 examples to avoid logging too frequently
skipping logging after 19888 examples to avoid logging too frequently
train stats after 19904 examples: {'rewards_train/chosen': '0.3072', 'rewards_train/rejected': '-5.6986', 'rewards_train/margins': '5.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23285', 'examples_per_second': '5.2477', 'grad_norm': '5.4062', 'counters/examples': 19904, 'counters/updates': 1244}
skipping logging after 19920 examples to avoid logging too frequently
skipping logging after 19936 examples to avoid logging too frequently
skipping logging after 19952 examples to avoid logging too frequently
train stats after 19968 examples: {'rewards_train/chosen': '0.31361', 'rewards_train/rejected': '-4.9538', 'rewards_train/margins': '5.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27704', 'examples_per_second': '5.0358', 'grad_norm': '5.3125', 'counters/examples': 19968, 'counters/updates': 1248}
skipping logging after 19984 examples to avoid logging too frequently
skipping logging after 20000 examples to avoid logging too frequently
Running evaluation after 20000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:49,  1.61s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:42,  1.40s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:36,  1.25s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.48s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.69s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.50s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:10<00:34,  1.38s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.53s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.49s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:31,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:31,  1.49s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.41s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.39s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:20<00:24,  1.35s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:21<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.28s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.26s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.25s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:28<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:12,  1.51s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.42s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:38<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.20s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:40<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:41<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]
eval after 20000: {'rewards_eval/chosen': '-4.8037', 'rewards_eval/rejected': '-5.1363', 'rewards_eval/margins': '0.22412', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46204'}
skipping logging after 20016 examples to avoid logging too frequently
train stats after 20032 examples: {'rewards_train/chosen': '0.51761', 'rewards_train/rejected': '-4.4848', 'rewards_train/margins': '5.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23615', 'examples_per_second': '5.7683', 'grad_norm': '4.7812', 'counters/examples': 20032, 'counters/updates': 1252}
skipping logging after 20048 examples to avoid logging too frequently
skipping logging after 20064 examples to avoid logging too frequently
skipping logging after 20080 examples to avoid logging too frequently
train stats after 20096 examples: {'rewards_train/chosen': '0.12392', 'rewards_train/rejected': '-4.4497', 'rewards_train/margins': '4.6328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27344', 'examples_per_second': '6.1822', 'grad_norm': '6.2188', 'counters/examples': 20096, 'counters/updates': 1256}
skipping logging after 20112 examples to avoid logging too frequently
skipping logging after 20128 examples to avoid logging too frequently
skipping logging after 20144 examples to avoid logging too frequently
train stats after 20160 examples: {'rewards_train/chosen': '0.53021', 'rewards_train/rejected': '-3.8814', 'rewards_train/margins': '4.3281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21747', 'examples_per_second': '5.0373', 'grad_norm': '5', 'counters/examples': 20160, 'counters/updates': 1260}
skipping logging after 20176 examples to avoid logging too frequently
skipping logging after 20192 examples to avoid logging too frequently
skipping logging after 20208 examples to avoid logging too frequently
train stats after 20224 examples: {'rewards_train/chosen': '0.51541', 'rewards_train/rejected': '-3.7767', 'rewards_train/margins': '4.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23096', 'examples_per_second': '5.7706', 'grad_norm': '5.3125', 'counters/examples': 20224, 'counters/updates': 1264}
skipping logging after 20240 examples to avoid logging too frequently
skipping logging after 20256 examples to avoid logging too frequently
skipping logging after 20272 examples to avoid logging too frequently
train stats after 20288 examples: {'rewards_train/chosen': '0.14542', 'rewards_train/rejected': '-5.9357', 'rewards_train/margins': '6.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2533', 'examples_per_second': '6.1505', 'grad_norm': '5.875', 'counters/examples': 20288, 'counters/updates': 1268}
skipping logging after 20304 examples to avoid logging too frequently
skipping logging after 20320 examples to avoid logging too frequently
skipping logging after 20336 examples to avoid logging too frequently
train stats after 20352 examples: {'rewards_train/chosen': '0.18635', 'rewards_train/rejected': '-4.3884', 'rewards_train/margins': '4.707', 'rewards_train/KL_estimate': '0', 'loss/train': '0.31519', 'examples_per_second': '5.7979', 'grad_norm': '5.4688', 'counters/examples': 20352, 'counters/updates': 1272}
skipping logging after 20368 examples to avoid logging too frequently
skipping logging after 20384 examples to avoid logging too frequently
skipping logging after 20400 examples to avoid logging too frequently
train stats after 20416 examples: {'rewards_train/chosen': '0.53404', 'rewards_train/rejected': '-5.4524', 'rewards_train/margins': '5.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2124', 'examples_per_second': '5.1971', 'grad_norm': '4.2188', 'counters/examples': 20416, 'counters/updates': 1276}
skipping logging after 20432 examples to avoid logging too frequently
skipping logging after 20448 examples to avoid logging too frequently
skipping logging after 20464 examples to avoid logging too frequently
train stats after 20480 examples: {'rewards_train/chosen': '0.13158', 'rewards_train/rejected': '-4.7613', 'rewards_train/margins': '4.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25781', 'examples_per_second': '5.2478', 'grad_norm': '5.0625', 'counters/examples': 20480, 'counters/updates': 1280}
skipping logging after 20496 examples to avoid logging too frequently
skipping logging after 20512 examples to avoid logging too frequently
skipping logging after 20528 examples to avoid logging too frequently
train stats after 20544 examples: {'rewards_train/chosen': '0.46057', 'rewards_train/rejected': '-5.6884', 'rewards_train/margins': '6.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25171', 'examples_per_second': '4.756', 'grad_norm': '4.75', 'counters/examples': 20544, 'counters/updates': 1284}
skipping logging after 20560 examples to avoid logging too frequently
skipping logging after 20576 examples to avoid logging too frequently
skipping logging after 20592 examples to avoid logging too frequently
train stats after 20608 examples: {'rewards_train/chosen': '0.72281', 'rewards_train/rejected': '-5.2239', 'rewards_train/margins': '5.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22382', 'examples_per_second': '4.5804', 'grad_norm': '4.5', 'counters/examples': 20608, 'counters/updates': 1288}
skipping logging after 20624 examples to avoid logging too frequently
skipping logging after 20640 examples to avoid logging too frequently
skipping logging after 20656 examples to avoid logging too frequently
train stats after 20672 examples: {'rewards_train/chosen': '0.46109', 'rewards_train/rejected': '-4.3207', 'rewards_train/margins': '4.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28992', 'examples_per_second': '5.9823', 'grad_norm': '5.1875', 'counters/examples': 20672, 'counters/updates': 1292}
skipping logging after 20688 examples to avoid logging too frequently
skipping logging after 20704 examples to avoid logging too frequently
skipping logging after 20720 examples to avoid logging too frequently
train stats after 20736 examples: {'rewards_train/chosen': '0.40263', 'rewards_train/rejected': '-4.5255', 'rewards_train/margins': '4.9453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25562', 'examples_per_second': '4.9234', 'grad_norm': '4.5312', 'counters/examples': 20736, 'counters/updates': 1296}
skipping logging after 20752 examples to avoid logging too frequently
skipping logging after 20768 examples to avoid logging too frequently
skipping logging after 20784 examples to avoid logging too frequently
train stats after 20800 examples: {'rewards_train/chosen': '0.45966', 'rewards_train/rejected': '-7.3317', 'rewards_train/margins': '7.9297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25305', 'examples_per_second': '5.2056', 'grad_norm': '5.6875', 'counters/examples': 20800, 'counters/updates': 1300}
skipping logging after 20816 examples to avoid logging too frequently
skipping logging after 20832 examples to avoid logging too frequently
skipping logging after 20848 examples to avoid logging too frequently
train stats after 20864 examples: {'rewards_train/chosen': '0.31455', 'rewards_train/rejected': '-4.7486', 'rewards_train/margins': '5.0312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23071', 'examples_per_second': '6.0383', 'grad_norm': '4.375', 'counters/examples': 20864, 'counters/updates': 1304}
skipping logging after 20880 examples to avoid logging too frequently
skipping logging after 20896 examples to avoid logging too frequently
skipping logging after 20912 examples to avoid logging too frequently
train stats after 20928 examples: {'rewards_train/chosen': '0.64307', 'rewards_train/rejected': '-4.3403', 'rewards_train/margins': '5.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20648', 'examples_per_second': '5.7463', 'grad_norm': '4.2812', 'counters/examples': 20928, 'counters/updates': 1308}
skipping logging after 20944 examples to avoid logging too frequently
skipping logging after 20960 examples to avoid logging too frequently
skipping logging after 20976 examples to avoid logging too frequently
train stats after 20992 examples: {'rewards_train/chosen': '0.63353', 'rewards_train/rejected': '-5.1487', 'rewards_train/margins': '5.6914', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22418', 'examples_per_second': '4.4137', 'grad_norm': '4.5625', 'counters/examples': 20992, 'counters/updates': 1312}
skipping logging after 21008 examples to avoid logging too frequently
skipping logging after 21024 examples to avoid logging too frequently
skipping logging after 21040 examples to avoid logging too frequently
train stats after 21056 examples: {'rewards_train/chosen': '0.4979', 'rewards_train/rejected': '-5.3525', 'rewards_train/margins': '6.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25659', 'examples_per_second': '4.8445', 'grad_norm': '5', 'counters/examples': 21056, 'counters/updates': 1316}
skipping logging after 21072 examples to avoid logging too frequently
skipping logging after 21088 examples to avoid logging too frequently
skipping logging after 21104 examples to avoid logging too frequently
train stats after 21120 examples: {'rewards_train/chosen': '0.51397', 'rewards_train/rejected': '-4.3407', 'rewards_train/margins': '4.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27869', 'examples_per_second': '4.0742', 'grad_norm': '5.1562', 'counters/examples': 21120, 'counters/updates': 1320}
skipping logging after 21136 examples to avoid logging too frequently
skipping logging after 21152 examples to avoid logging too frequently
skipping logging after 21168 examples to avoid logging too frequently
train stats after 21184 examples: {'rewards_train/chosen': '0.63278', 'rewards_train/rejected': '-4.4247', 'rewards_train/margins': '4.9961', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2124', 'examples_per_second': '5.035', 'grad_norm': '4.8125', 'counters/examples': 21184, 'counters/updates': 1324}
skipping logging after 21200 examples to avoid logging too frequently
skipping logging after 21216 examples to avoid logging too frequently
skipping logging after 21232 examples to avoid logging too frequently
train stats after 21248 examples: {'rewards_train/chosen': '0.359', 'rewards_train/rejected': '-3.9246', 'rewards_train/margins': '4.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30408', 'examples_per_second': '6.2389', 'grad_norm': '6.4688', 'counters/examples': 21248, 'counters/updates': 1328}
skipping logging after 21264 examples to avoid logging too frequently
skipping logging after 21280 examples to avoid logging too frequently
skipping logging after 21296 examples to avoid logging too frequently
train stats after 21312 examples: {'rewards_train/chosen': '0.45272', 'rewards_train/rejected': '-4.3389', 'rewards_train/margins': '5.4609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26538', 'examples_per_second': '6.1925', 'grad_norm': '5.4375', 'counters/examples': 21312, 'counters/updates': 1332}
skipping logging after 21328 examples to avoid logging too frequently
skipping logging after 21344 examples to avoid logging too frequently
skipping logging after 21360 examples to avoid logging too frequently
train stats after 21376 examples: {'rewards_train/chosen': '0.56445', 'rewards_train/rejected': '-4.6091', 'rewards_train/margins': '5.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22516', 'examples_per_second': '5.0581', 'grad_norm': '4.8438', 'counters/examples': 21376, 'counters/updates': 1336}
skipping logging after 21392 examples to avoid logging too frequently
skipping logging after 21408 examples to avoid logging too frequently
skipping logging after 21424 examples to avoid logging too frequently
train stats after 21440 examples: {'rewards_train/chosen': '0.34077', 'rewards_train/rejected': '-5.6746', 'rewards_train/margins': '5.3711', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26062', 'examples_per_second': '4.6381', 'grad_norm': '4.5625', 'counters/examples': 21440, 'counters/updates': 1340}
skipping logging after 21456 examples to avoid logging too frequently
skipping logging after 21472 examples to avoid logging too frequently
skipping logging after 21488 examples to avoid logging too frequently
train stats after 21504 examples: {'rewards_train/chosen': '0.62002', 'rewards_train/rejected': '-4.8071', 'rewards_train/margins': '5.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26007', 'examples_per_second': '5.1309', 'grad_norm': '4.4062', 'counters/examples': 21504, 'counters/updates': 1344}
skipping logging after 21520 examples to avoid logging too frequently
skipping logging after 21536 examples to avoid logging too frequently
skipping logging after 21552 examples to avoid logging too frequently
train stats after 21568 examples: {'rewards_train/chosen': '0.55781', 'rewards_train/rejected': '-4.811', 'rewards_train/margins': '5.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21832', 'examples_per_second': '5.1992', 'grad_norm': '4.4062', 'counters/examples': 21568, 'counters/updates': 1348}
skipping logging after 21584 examples to avoid logging too frequently
skipping logging after 21600 examples to avoid logging too frequently
skipping logging after 21616 examples to avoid logging too frequently
train stats after 21632 examples: {'rewards_train/chosen': '0.4187', 'rewards_train/rejected': '-5.2206', 'rewards_train/margins': '5.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25458', 'examples_per_second': '5.6424', 'grad_norm': '4.7812', 'counters/examples': 21632, 'counters/updates': 1352}
skipping logging after 21648 examples to avoid logging too frequently
skipping logging after 21664 examples to avoid logging too frequently
skipping logging after 21680 examples to avoid logging too frequently
train stats after 21696 examples: {'rewards_train/chosen': '0.45366', 'rewards_train/rejected': '-4.5546', 'rewards_train/margins': '4.9883', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2525', 'examples_per_second': '5.1165', 'grad_norm': '4.4688', 'counters/examples': 21696, 'counters/updates': 1356}
skipping logging after 21712 examples to avoid logging too frequently
skipping logging after 21728 examples to avoid logging too frequently
skipping logging after 21744 examples to avoid logging too frequently
train stats after 21760 examples: {'rewards_train/chosen': '0.82532', 'rewards_train/rejected': '-5.3715', 'rewards_train/margins': '5.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1795', 'examples_per_second': '4.002', 'grad_norm': '5.1875', 'counters/examples': 21760, 'counters/updates': 1360}
skipping logging after 21776 examples to avoid logging too frequently
skipping logging after 21792 examples to avoid logging too frequently
skipping logging after 21808 examples to avoid logging too frequently
train stats after 21824 examples: {'rewards_train/chosen': '0.73722', 'rewards_train/rejected': '-5.6969', 'rewards_train/margins': '6.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21967', 'examples_per_second': '5.859', 'grad_norm': '4.8438', 'counters/examples': 21824, 'counters/updates': 1364}
skipping logging after 21840 examples to avoid logging too frequently
skipping logging after 21856 examples to avoid logging too frequently
skipping logging after 21872 examples to avoid logging too frequently
train stats after 21888 examples: {'rewards_train/chosen': '0.45756', 'rewards_train/rejected': '-6.1857', 'rewards_train/margins': '6.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25549', 'examples_per_second': '6.1461', 'grad_norm': '6.2188', 'counters/examples': 21888, 'counters/updates': 1368}
skipping logging after 21904 examples to avoid logging too frequently
skipping logging after 21920 examples to avoid logging too frequently
skipping logging after 21936 examples to avoid logging too frequently
train stats after 21952 examples: {'rewards_train/chosen': '0.12018', 'rewards_train/rejected': '-4.6485', 'rewards_train/margins': '4.7656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26807', 'examples_per_second': '5.1821', 'grad_norm': '5.25', 'counters/examples': 21952, 'counters/updates': 1372}
skipping logging after 21968 examples to avoid logging too frequently
skipping logging after 21984 examples to avoid logging too frequently
skipping logging after 22000 examples to avoid logging too frequently
train stats after 22016 examples: {'rewards_train/chosen': '0.61581', 'rewards_train/rejected': '-3.5151', 'rewards_train/margins': '4.2695', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25745', 'examples_per_second': '5.3422', 'grad_norm': '4.9688', 'counters/examples': 22016, 'counters/updates': 1376}
skipping logging after 22032 examples to avoid logging too frequently
skipping logging after 22048 examples to avoid logging too frequently
skipping logging after 22064 examples to avoid logging too frequently
train stats after 22080 examples: {'rewards_train/chosen': '0.27959', 'rewards_train/rejected': '-4.5772', 'rewards_train/margins': '5.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27423', 'examples_per_second': '5.3763', 'grad_norm': '5.375', 'counters/examples': 22080, 'counters/updates': 1380}
skipping logging after 22096 examples to avoid logging too frequently
skipping logging after 22112 examples to avoid logging too frequently
skipping logging after 22128 examples to avoid logging too frequently
train stats after 22144 examples: {'rewards_train/chosen': '0.46356', 'rewards_train/rejected': '-3.8902', 'rewards_train/margins': '4.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26862', 'examples_per_second': '5.3938', 'grad_norm': '4.6562', 'counters/examples': 22144, 'counters/updates': 1384}
skipping logging after 22160 examples to avoid logging too frequently
skipping logging after 22176 examples to avoid logging too frequently
skipping logging after 22192 examples to avoid logging too frequently
train stats after 22208 examples: {'rewards_train/chosen': '0.052395', 'rewards_train/rejected': '-4.807', 'rewards_train/margins': '4.8828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22357', 'examples_per_second': '5.7422', 'grad_norm': '4.7812', 'counters/examples': 22208, 'counters/updates': 1388}
skipping logging after 22224 examples to avoid logging too frequently
skipping logging after 22240 examples to avoid logging too frequently
skipping logging after 22256 examples to avoid logging too frequently
train stats after 22272 examples: {'rewards_train/chosen': '0.77499', 'rewards_train/rejected': '-5.2198', 'rewards_train/margins': '5.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20721', 'examples_per_second': '4.6003', 'grad_norm': '4.8438', 'counters/examples': 22272, 'counters/updates': 1392}
skipping logging after 22288 examples to avoid logging too frequently
skipping logging after 22304 examples to avoid logging too frequently
skipping logging after 22320 examples to avoid logging too frequently
train stats after 22336 examples: {'rewards_train/chosen': '0.17386', 'rewards_train/rejected': '-6.9403', 'rewards_train/margins': '7.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28229', 'examples_per_second': '5.1583', 'grad_norm': '5.1562', 'counters/examples': 22336, 'counters/updates': 1396}
skipping logging after 22352 examples to avoid logging too frequently
skipping logging after 22368 examples to avoid logging too frequently
skipping logging after 22384 examples to avoid logging too frequently
train stats after 22400 examples: {'rewards_train/chosen': '0.29831', 'rewards_train/rejected': '-4.826', 'rewards_train/margins': '4.9414', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25836', 'examples_per_second': '5.7773', 'grad_norm': '6.0312', 'counters/examples': 22400, 'counters/updates': 1400}
skipping logging after 22416 examples to avoid logging too frequently
skipping logging after 22432 examples to avoid logging too frequently
skipping logging after 22448 examples to avoid logging too frequently
train stats after 22464 examples: {'rewards_train/chosen': '0.31715', 'rewards_train/rejected': '-4.0203', 'rewards_train/margins': '4.2969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24524', 'examples_per_second': '5.3054', 'grad_norm': '4.9062', 'counters/examples': 22464, 'counters/updates': 1404}
skipping logging after 22480 examples to avoid logging too frequently
skipping logging after 22496 examples to avoid logging too frequently
skipping logging after 22512 examples to avoid logging too frequently
train stats after 22528 examples: {'rewards_train/chosen': '0.44366', 'rewards_train/rejected': '-5.1517', 'rewards_train/margins': '5.6328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19202', 'examples_per_second': '4.9516', 'grad_norm': '3.9688', 'counters/examples': 22528, 'counters/updates': 1408}
skipping logging after 22544 examples to avoid logging too frequently
skipping logging after 22560 examples to avoid logging too frequently
skipping logging after 22576 examples to avoid logging too frequently
train stats after 22592 examples: {'rewards_train/chosen': '0.30578', 'rewards_train/rejected': '-5.1648', 'rewards_train/margins': '5.6211', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25391', 'examples_per_second': '5.3453', 'grad_norm': '4.7188', 'counters/examples': 22592, 'counters/updates': 1412}
skipping logging after 22608 examples to avoid logging too frequently
skipping logging after 22624 examples to avoid logging too frequently
skipping logging after 22640 examples to avoid logging too frequently
train stats after 22656 examples: {'rewards_train/chosen': '0.40527', 'rewards_train/rejected': '-5.3695', 'rewards_train/margins': '5.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22931', 'examples_per_second': '7.1565', 'grad_norm': '5.625', 'counters/examples': 22656, 'counters/updates': 1416}
skipping logging after 22672 examples to avoid logging too frequently
skipping logging after 22688 examples to avoid logging too frequently
skipping logging after 22704 examples to avoid logging too frequently
train stats after 22720 examples: {'rewards_train/chosen': '0.22825', 'rewards_train/rejected': '-4.1158', 'rewards_train/margins': '4.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24994', 'examples_per_second': '5.3685', 'grad_norm': '5.3438', 'counters/examples': 22720, 'counters/updates': 1420}
skipping logging after 22736 examples to avoid logging too frequently
skipping logging after 22752 examples to avoid logging too frequently
skipping logging after 22768 examples to avoid logging too frequently
train stats after 22784 examples: {'rewards_train/chosen': '0.31902', 'rewards_train/rejected': '-5.3925', 'rewards_train/margins': '5.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27881', 'examples_per_second': '4.964', 'grad_norm': '6.3125', 'counters/examples': 22784, 'counters/updates': 1424}
skipping logging after 22800 examples to avoid logging too frequently
skipping logging after 22816 examples to avoid logging too frequently
skipping logging after 22832 examples to avoid logging too frequently
train stats after 22848 examples: {'rewards_train/chosen': '0.37964', 'rewards_train/rejected': '-4.0728', 'rewards_train/margins': '4.6328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25299', 'examples_per_second': '4.7779', 'grad_norm': '5', 'counters/examples': 22848, 'counters/updates': 1428}
skipping logging after 22864 examples to avoid logging too frequently
skipping logging after 22880 examples to avoid logging too frequently
skipping logging after 22896 examples to avoid logging too frequently
train stats after 22912 examples: {'rewards_train/chosen': '0.38104', 'rewards_train/rejected': '-4.1415', 'rewards_train/margins': '4.5352', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24005', 'examples_per_second': '4.4671', 'grad_norm': '5.0938', 'counters/examples': 22912, 'counters/updates': 1432}
skipping logging after 22928 examples to avoid logging too frequently
skipping logging after 22944 examples to avoid logging too frequently
skipping logging after 22960 examples to avoid logging too frequently
train stats after 22976 examples: {'rewards_train/chosen': '0.24868', 'rewards_train/rejected': '-4.543', 'rewards_train/margins': '4.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25696', 'examples_per_second': '4.8448', 'grad_norm': '4.25', 'counters/examples': 22976, 'counters/updates': 1436}
skipping logging after 22992 examples to avoid logging too frequently
skipping logging after 23008 examples to avoid logging too frequently
skipping logging after 23024 examples to avoid logging too frequently
train stats after 23040 examples: {'rewards_train/chosen': '0.55628', 'rewards_train/rejected': '-5.187', 'rewards_train/margins': '5.8203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20459', 'examples_per_second': '5.6565', 'grad_norm': '5.0625', 'counters/examples': 23040, 'counters/updates': 1440}
skipping logging after 23056 examples to avoid logging too frequently
skipping logging after 23072 examples to avoid logging too frequently
skipping logging after 23088 examples to avoid logging too frequently
train stats after 23104 examples: {'rewards_train/chosen': '0.51368', 'rewards_train/rejected': '-4.7949', 'rewards_train/margins': '5.4102', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21918', 'examples_per_second': '4.3614', 'grad_norm': '5.125', 'counters/examples': 23104, 'counters/updates': 1444}
skipping logging after 23120 examples to avoid logging too frequently
skipping logging after 23136 examples to avoid logging too frequently
skipping logging after 23152 examples to avoid logging too frequently
train stats after 23168 examples: {'rewards_train/chosen': '0.66397', 'rewards_train/rejected': '-5.45', 'rewards_train/margins': '6.3281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20862', 'examples_per_second': '4.515', 'grad_norm': '5.1875', 'counters/examples': 23168, 'counters/updates': 1448}
skipping logging after 23184 examples to avoid logging too frequently
skipping logging after 23200 examples to avoid logging too frequently
skipping logging after 23216 examples to avoid logging too frequently
train stats after 23232 examples: {'rewards_train/chosen': '0.51801', 'rewards_train/rejected': '-5.2956', 'rewards_train/margins': '5.9453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26752', 'examples_per_second': '5.6873', 'grad_norm': '5.375', 'counters/examples': 23232, 'counters/updates': 1452}
skipping logging after 23248 examples to avoid logging too frequently
skipping logging after 23264 examples to avoid logging too frequently
skipping logging after 23280 examples to avoid logging too frequently
train stats after 23296 examples: {'rewards_train/chosen': '0.67297', 'rewards_train/rejected': '-4.8389', 'rewards_train/margins': '5.332', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21429', 'examples_per_second': '4.6919', 'grad_norm': '4.375', 'counters/examples': 23296, 'counters/updates': 1456}
skipping logging after 23312 examples to avoid logging too frequently
skipping logging after 23328 examples to avoid logging too frequently
skipping logging after 23344 examples to avoid logging too frequently
train stats after 23360 examples: {'rewards_train/chosen': '0.56297', 'rewards_train/rejected': '-5.3093', 'rewards_train/margins': '5.7422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18646', 'examples_per_second': '4.6925', 'grad_norm': '4.9688', 'counters/examples': 23360, 'counters/updates': 1460}
skipping logging after 23376 examples to avoid logging too frequently
skipping logging after 23392 examples to avoid logging too frequently
skipping logging after 23408 examples to avoid logging too frequently
train stats after 23424 examples: {'rewards_train/chosen': '0.65194', 'rewards_train/rejected': '-4.8103', 'rewards_train/margins': '5.3828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21643', 'examples_per_second': '4.7209', 'grad_norm': '5.1875', 'counters/examples': 23424, 'counters/updates': 1464}
skipping logging after 23440 examples to avoid logging too frequently
skipping logging after 23456 examples to avoid logging too frequently
skipping logging after 23472 examples to avoid logging too frequently
train stats after 23488 examples: {'rewards_train/chosen': '0.67179', 'rewards_train/rejected': '-5.7869', 'rewards_train/margins': '6.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1861', 'examples_per_second': '4.5461', 'grad_norm': '4.625', 'counters/examples': 23488, 'counters/updates': 1468}
skipping logging after 23504 examples to avoid logging too frequently
skipping logging after 23520 examples to avoid logging too frequently
skipping logging after 23536 examples to avoid logging too frequently
train stats after 23552 examples: {'rewards_train/chosen': '0.082184', 'rewards_train/rejected': '-5.9068', 'rewards_train/margins': '6.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20325', 'examples_per_second': '4.9393', 'grad_norm': '5', 'counters/examples': 23552, 'counters/updates': 1472}
skipping logging after 23568 examples to avoid logging too frequently
skipping logging after 23584 examples to avoid logging too frequently
skipping logging after 23600 examples to avoid logging too frequently
train stats after 23616 examples: {'rewards_train/chosen': '0.45789', 'rewards_train/rejected': '-4.9295', 'rewards_train/margins': '5.4414', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21063', 'examples_per_second': '5.6634', 'grad_norm': '5.6875', 'counters/examples': 23616, 'counters/updates': 1476}
skipping logging after 23632 examples to avoid logging too frequently
skipping logging after 23648 examples to avoid logging too frequently
skipping logging after 23664 examples to avoid logging too frequently
train stats after 23680 examples: {'rewards_train/chosen': '0.43661', 'rewards_train/rejected': '-4.925', 'rewards_train/margins': '5.3398', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24164', 'examples_per_second': '4.2276', 'grad_norm': '4.9062', 'counters/examples': 23680, 'counters/updates': 1480}
skipping logging after 23696 examples to avoid logging too frequently
skipping logging after 23712 examples to avoid logging too frequently
skipping logging after 23728 examples to avoid logging too frequently
train stats after 23744 examples: {'rewards_train/chosen': '0.14906', 'rewards_train/rejected': '-5.6065', 'rewards_train/margins': '5.5938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24658', 'examples_per_second': '5.4853', 'grad_norm': '5.3125', 'counters/examples': 23744, 'counters/updates': 1484}
skipping logging after 23760 examples to avoid logging too frequently
skipping logging after 23776 examples to avoid logging too frequently
skipping logging after 23792 examples to avoid logging too frequently
train stats after 23808 examples: {'rewards_train/chosen': '0.37171', 'rewards_train/rejected': '-4.6559', 'rewards_train/margins': '5.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23254', 'examples_per_second': '5.617', 'grad_norm': '4.8125', 'counters/examples': 23808, 'counters/updates': 1488}
skipping logging after 23824 examples to avoid logging too frequently
skipping logging after 23840 examples to avoid logging too frequently
skipping logging after 23856 examples to avoid logging too frequently
train stats after 23872 examples: {'rewards_train/chosen': '0.28488', 'rewards_train/rejected': '-6.6123', 'rewards_train/margins': '6.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20337', 'examples_per_second': '5.7428', 'grad_norm': '4.7812', 'counters/examples': 23872, 'counters/updates': 1492}
skipping logging after 23888 examples to avoid logging too frequently
skipping logging after 23904 examples to avoid logging too frequently
skipping logging after 23920 examples to avoid logging too frequently
train stats after 23936 examples: {'rewards_train/chosen': '0.1901', 'rewards_train/rejected': '-3.8684', 'rewards_train/margins': '4.1523', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28406', 'examples_per_second': '6.1613', 'grad_norm': '5.4062', 'counters/examples': 23936, 'counters/updates': 1496}
skipping logging after 23952 examples to avoid logging too frequently
skipping logging after 23968 examples to avoid logging too frequently
skipping logging after 23984 examples to avoid logging too frequently
train stats after 24000 examples: {'rewards_train/chosen': '0.4067', 'rewards_train/rejected': '-6.3274', 'rewards_train/margins': '6.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24695', 'examples_per_second': '5.6993', 'grad_norm': '5.5', 'counters/examples': 24000, 'counters/updates': 1500}
Running evaluation after 24000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:39,  1.27s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.26s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.17s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:40,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.66s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.48s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:34,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.41s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.39s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.28s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.20s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.31s/it]
eval after 24000: {'rewards_eval/chosen': '-4.7799', 'rewards_eval/rejected': '-5.0823', 'rewards_eval/margins': '0.20996', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46581'}
skipping logging after 24016 examples to avoid logging too frequently
skipping logging after 24032 examples to avoid logging too frequently
skipping logging after 24048 examples to avoid logging too frequently
train stats after 24064 examples: {'rewards_train/chosen': '0.31525', 'rewards_train/rejected': '-5.2652', 'rewards_train/margins': '5.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26648', 'examples_per_second': '5.0439', 'grad_norm': '4.4062', 'counters/examples': 24064, 'counters/updates': 1504}
skipping logging after 24080 examples to avoid logging too frequently
skipping logging after 24096 examples to avoid logging too frequently
skipping logging after 24112 examples to avoid logging too frequently
train stats after 24128 examples: {'rewards_train/chosen': '0.57331', 'rewards_train/rejected': '-4.0468', 'rewards_train/margins': '4.5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2561', 'examples_per_second': '5.1237', 'grad_norm': '5.25', 'counters/examples': 24128, 'counters/updates': 1508}
skipping logging after 24144 examples to avoid logging too frequently
skipping logging after 24160 examples to avoid logging too frequently
skipping logging after 24176 examples to avoid logging too frequently
train stats after 24192 examples: {'rewards_train/chosen': '0.55696', 'rewards_train/rejected': '-4.69', 'rewards_train/margins': '5.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19928', 'examples_per_second': '5.4513', 'grad_norm': '4.1562', 'counters/examples': 24192, 'counters/updates': 1512}
skipping logging after 24208 examples to avoid logging too frequently
skipping logging after 24224 examples to avoid logging too frequently
skipping logging after 24240 examples to avoid logging too frequently
train stats after 24256 examples: {'rewards_train/chosen': '0.61509', 'rewards_train/rejected': '-5.1684', 'rewards_train/margins': '5.7891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25696', 'examples_per_second': '4.7847', 'grad_norm': '4.9688', 'counters/examples': 24256, 'counters/updates': 1516}
skipping logging after 24272 examples to avoid logging too frequently
skipping logging after 24288 examples to avoid logging too frequently
skipping logging after 24304 examples to avoid logging too frequently
train stats after 24320 examples: {'rewards_train/chosen': '0.049488', 'rewards_train/rejected': '-6.3673', 'rewards_train/margins': '6.2344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29785', 'examples_per_second': '5.6876', 'grad_norm': '6.5', 'counters/examples': 24320, 'counters/updates': 1520}
skipping logging after 24336 examples to avoid logging too frequently
skipping logging after 24352 examples to avoid logging too frequently
skipping logging after 24368 examples to avoid logging too frequently
train stats after 24384 examples: {'rewards_train/chosen': '0.57519', 'rewards_train/rejected': '-5.1392', 'rewards_train/margins': '5.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23535', 'examples_per_second': '4.1888', 'grad_norm': '4.0625', 'counters/examples': 24384, 'counters/updates': 1524}
skipping logging after 24400 examples to avoid logging too frequently
skipping logging after 24416 examples to avoid logging too frequently
skipping logging after 24432 examples to avoid logging too frequently
train stats after 24448 examples: {'rewards_train/chosen': '0.6943', 'rewards_train/rejected': '-4.5304', 'rewards_train/margins': '5.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21527', 'examples_per_second': '5.6157', 'grad_norm': '4.4062', 'counters/examples': 24448, 'counters/updates': 1528}
skipping logging after 24464 examples to avoid logging too frequently
skipping logging after 24480 examples to avoid logging too frequently
skipping logging after 24496 examples to avoid logging too frequently
train stats after 24512 examples: {'rewards_train/chosen': '0.54978', 'rewards_train/rejected': '-4.4794', 'rewards_train/margins': '4.9375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19952', 'examples_per_second': '6.3535', 'grad_norm': '3.9844', 'counters/examples': 24512, 'counters/updates': 1532}
skipping logging after 24528 examples to avoid logging too frequently
skipping logging after 24544 examples to avoid logging too frequently
skipping logging after 24560 examples to avoid logging too frequently
train stats after 24576 examples: {'rewards_train/chosen': '0.51074', 'rewards_train/rejected': '-4.6495', 'rewards_train/margins': '5.1367', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24066', 'examples_per_second': '5.4805', 'grad_norm': '4.375', 'counters/examples': 24576, 'counters/updates': 1536}
skipping logging after 24592 examples to avoid logging too frequently
skipping logging after 24608 examples to avoid logging too frequently
skipping logging after 24624 examples to avoid logging too frequently
train stats after 24640 examples: {'rewards_train/chosen': '0.39642', 'rewards_train/rejected': '-6.4821', 'rewards_train/margins': '7.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21588', 'examples_per_second': '4.362', 'grad_norm': '5.375', 'counters/examples': 24640, 'counters/updates': 1540}
skipping logging after 24656 examples to avoid logging too frequently
skipping logging after 24672 examples to avoid logging too frequently
skipping logging after 24688 examples to avoid logging too frequently
train stats after 24704 examples: {'rewards_train/chosen': '0.44555', 'rewards_train/rejected': '-6.1914', 'rewards_train/margins': '6.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25159', 'examples_per_second': '4.4049', 'grad_norm': '4.375', 'counters/examples': 24704, 'counters/updates': 1544}
skipping logging after 24720 examples to avoid logging too frequently
skipping logging after 24736 examples to avoid logging too frequently
skipping logging after 24752 examples to avoid logging too frequently
train stats after 24768 examples: {'rewards_train/chosen': '0.42896', 'rewards_train/rejected': '-4.7006', 'rewards_train/margins': '5.0156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21722', 'examples_per_second': '5.5108', 'grad_norm': '4.9688', 'counters/examples': 24768, 'counters/updates': 1548}
skipping logging after 24784 examples to avoid logging too frequently
skipping logging after 24800 examples to avoid logging too frequently
skipping logging after 24816 examples to avoid logging too frequently
train stats after 24832 examples: {'rewards_train/chosen': '0.56236', 'rewards_train/rejected': '-4.6974', 'rewards_train/margins': '5.2539', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21454', 'examples_per_second': '6.111', 'grad_norm': '5.3438', 'counters/examples': 24832, 'counters/updates': 1552}
skipping logging after 24848 examples to avoid logging too frequently
skipping logging after 24864 examples to avoid logging too frequently
skipping logging after 24880 examples to avoid logging too frequently
train stats after 24896 examples: {'rewards_train/chosen': '0.50211', 'rewards_train/rejected': '-4.9605', 'rewards_train/margins': '5.4219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21759', 'examples_per_second': '4.5966', 'grad_norm': '4.9062', 'counters/examples': 24896, 'counters/updates': 1556}
skipping logging after 24912 examples to avoid logging too frequently
skipping logging after 24928 examples to avoid logging too frequently
skipping logging after 24944 examples to avoid logging too frequently
train stats after 24960 examples: {'rewards_train/chosen': '0.34517', 'rewards_train/rejected': '-4.682', 'rewards_train/margins': '4.9375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22638', 'examples_per_second': '5.5386', 'grad_norm': '5.2188', 'counters/examples': 24960, 'counters/updates': 1560}
skipping logging after 24976 examples to avoid logging too frequently
skipping logging after 24992 examples to avoid logging too frequently
skipping logging after 25008 examples to avoid logging too frequently
train stats after 25024 examples: {'rewards_train/chosen': '0.032468', 'rewards_train/rejected': '-6.0708', 'rewards_train/margins': '5.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23254', 'examples_per_second': '5.3733', 'grad_norm': '5.7188', 'counters/examples': 25024, 'counters/updates': 1564}
skipping logging after 25040 examples to avoid logging too frequently
skipping logging after 25056 examples to avoid logging too frequently
skipping logging after 25072 examples to avoid logging too frequently
train stats after 25088 examples: {'rewards_train/chosen': '0.56265', 'rewards_train/rejected': '-5.0856', 'rewards_train/margins': '5.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19971', 'examples_per_second': '4.6024', 'grad_norm': '4.8125', 'counters/examples': 25088, 'counters/updates': 1568}
skipping logging after 25104 examples to avoid logging too frequently
skipping logging after 25120 examples to avoid logging too frequently
skipping logging after 25136 examples to avoid logging too frequently
train stats after 25152 examples: {'rewards_train/chosen': '0.84477', 'rewards_train/rejected': '-5.7283', 'rewards_train/margins': '6.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18359', 'examples_per_second': '5.0474', 'grad_norm': '4.75', 'counters/examples': 25152, 'counters/updates': 1572}
skipping logging after 25168 examples to avoid logging too frequently
skipping logging after 25184 examples to avoid logging too frequently
skipping logging after 25200 examples to avoid logging too frequently
train stats after 25216 examples: {'rewards_train/chosen': '0.62229', 'rewards_train/rejected': '-5.0807', 'rewards_train/margins': '5.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22711', 'examples_per_second': '4.6693', 'grad_norm': '4.9062', 'counters/examples': 25216, 'counters/updates': 1576}
skipping logging after 25232 examples to avoid logging too frequently
skipping logging after 25248 examples to avoid logging too frequently
skipping logging after 25264 examples to avoid logging too frequently
train stats after 25280 examples: {'rewards_train/chosen': '0.53777', 'rewards_train/rejected': '-5.5137', 'rewards_train/margins': '6.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23871', 'examples_per_second': '4.9231', 'grad_norm': '4.4062', 'counters/examples': 25280, 'counters/updates': 1580}
skipping logging after 25296 examples to avoid logging too frequently
skipping logging after 25312 examples to avoid logging too frequently
skipping logging after 25328 examples to avoid logging too frequently
train stats after 25344 examples: {'rewards_train/chosen': '0.32858', 'rewards_train/rejected': '-4.7409', 'rewards_train/margins': '5.0312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2522', 'examples_per_second': '4.9373', 'grad_norm': '5.0625', 'counters/examples': 25344, 'counters/updates': 1584}
skipping logging after 25360 examples to avoid logging too frequently
skipping logging after 25376 examples to avoid logging too frequently
skipping logging after 25392 examples to avoid logging too frequently
train stats after 25408 examples: {'rewards_train/chosen': '0.51286', 'rewards_train/rejected': '-5.0902', 'rewards_train/margins': '5.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25012', 'examples_per_second': '4.3147', 'grad_norm': '4.2812', 'counters/examples': 25408, 'counters/updates': 1588}
skipping logging after 25424 examples to avoid logging too frequently
skipping logging after 25440 examples to avoid logging too frequently
skipping logging after 25456 examples to avoid logging too frequently
train stats after 25472 examples: {'rewards_train/chosen': '0.57933', 'rewards_train/rejected': '-6.2818', 'rewards_train/margins': '6.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23798', 'examples_per_second': '5.4206', 'grad_norm': '4.9688', 'counters/examples': 25472, 'counters/updates': 1592}
skipping logging after 25488 examples to avoid logging too frequently
skipping logging after 25504 examples to avoid logging too frequently
skipping logging after 25520 examples to avoid logging too frequently
train stats after 25536 examples: {'rewards_train/chosen': '0.22424', 'rewards_train/rejected': '-4.6032', 'rewards_train/margins': '4.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25079', 'examples_per_second': '5.8358', 'grad_norm': '5.1562', 'counters/examples': 25536, 'counters/updates': 1596}
skipping logging after 25552 examples to avoid logging too frequently
skipping logging after 25568 examples to avoid logging too frequently
skipping logging after 25584 examples to avoid logging too frequently
train stats after 25600 examples: {'rewards_train/chosen': '0.087598', 'rewards_train/rejected': '-5.8103', 'rewards_train/margins': '5.7891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26044', 'examples_per_second': '5.3934', 'grad_norm': '4.7188', 'counters/examples': 25600, 'counters/updates': 1600}
skipping logging after 25616 examples to avoid logging too frequently
skipping logging after 25632 examples to avoid logging too frequently
skipping logging after 25648 examples to avoid logging too frequently
train stats after 25664 examples: {'rewards_train/chosen': '0.39089', 'rewards_train/rejected': '-5.1322', 'rewards_train/margins': '5.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22852', 'examples_per_second': '5.9403', 'grad_norm': '4.75', 'counters/examples': 25664, 'counters/updates': 1604}
skipping logging after 25680 examples to avoid logging too frequently
skipping logging after 25696 examples to avoid logging too frequently
skipping logging after 25712 examples to avoid logging too frequently
train stats after 25728 examples: {'rewards_train/chosen': '0.63406', 'rewards_train/rejected': '-5.2356', 'rewards_train/margins': '5.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20874', 'examples_per_second': '4.8265', 'grad_norm': '5.7812', 'counters/examples': 25728, 'counters/updates': 1608}
skipping logging after 25744 examples to avoid logging too frequently
skipping logging after 25760 examples to avoid logging too frequently
skipping logging after 25776 examples to avoid logging too frequently
train stats after 25792 examples: {'rewards_train/chosen': '0.7001', 'rewards_train/rejected': '-3.5826', 'rewards_train/margins': '4.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22424', 'examples_per_second': '5.6185', 'grad_norm': '5.0312', 'counters/examples': 25792, 'counters/updates': 1612}
skipping logging after 25808 examples to avoid logging too frequently
skipping logging after 25824 examples to avoid logging too frequently
skipping logging after 25840 examples to avoid logging too frequently
train stats after 25856 examples: {'rewards_train/chosen': '0.2187', 'rewards_train/rejected': '-5.2427', 'rewards_train/margins': '5.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27417', 'examples_per_second': '5.3001', 'grad_norm': '5.2188', 'counters/examples': 25856, 'counters/updates': 1616}
skipping logging after 25872 examples to avoid logging too frequently
skipping logging after 25888 examples to avoid logging too frequently
skipping logging after 25904 examples to avoid logging too frequently
train stats after 25920 examples: {'rewards_train/chosen': '0.59168', 'rewards_train/rejected': '-6.4227', 'rewards_train/margins': '7.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1958', 'examples_per_second': '4.31', 'grad_norm': '4.7812', 'counters/examples': 25920, 'counters/updates': 1620}
skipping logging after 25936 examples to avoid logging too frequently
skipping logging after 25952 examples to avoid logging too frequently
skipping logging after 25968 examples to avoid logging too frequently
train stats after 25984 examples: {'rewards_train/chosen': '0.16162', 'rewards_train/rejected': '-5.6267', 'rewards_train/margins': '5.9297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27661', 'examples_per_second': '4.326', 'grad_norm': '6.125', 'counters/examples': 25984, 'counters/updates': 1624}
skipping logging after 26000 examples to avoid logging too frequently
skipping logging after 26016 examples to avoid logging too frequently
skipping logging after 26032 examples to avoid logging too frequently
train stats after 26048 examples: {'rewards_train/chosen': '0.36545', 'rewards_train/rejected': '-4.9552', 'rewards_train/margins': '5.2422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23938', 'examples_per_second': '5.0902', 'grad_norm': '4.8438', 'counters/examples': 26048, 'counters/updates': 1628}
skipping logging after 26064 examples to avoid logging too frequently
skipping logging after 26080 examples to avoid logging too frequently
skipping logging after 26096 examples to avoid logging too frequently
train stats after 26112 examples: {'rewards_train/chosen': '0.58522', 'rewards_train/rejected': '-4.0109', 'rewards_train/margins': '4.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21802', 'examples_per_second': '4.8735', 'grad_norm': '4.4375', 'counters/examples': 26112, 'counters/updates': 1632}
skipping logging after 26128 examples to avoid logging too frequently
skipping logging after 26144 examples to avoid logging too frequently
skipping logging after 26160 examples to avoid logging too frequently
train stats after 26176 examples: {'rewards_train/chosen': '0.73541', 'rewards_train/rejected': '-5.4852', 'rewards_train/margins': '6.6641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17511', 'examples_per_second': '4.5133', 'grad_norm': '4.2812', 'counters/examples': 26176, 'counters/updates': 1636}
skipping logging after 26192 examples to avoid logging too frequently
skipping logging after 26208 examples to avoid logging too frequently
skipping logging after 26224 examples to avoid logging too frequently
train stats after 26240 examples: {'rewards_train/chosen': '0.12042', 'rewards_train/rejected': '-4.433', 'rewards_train/margins': '4.4219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28632', 'examples_per_second': '5.0654', 'grad_norm': '5.2188', 'counters/examples': 26240, 'counters/updates': 1640}
skipping logging after 26256 examples to avoid logging too frequently
skipping logging after 26272 examples to avoid logging too frequently
skipping logging after 26288 examples to avoid logging too frequently
train stats after 26304 examples: {'rewards_train/chosen': '-0.036291', 'rewards_train/rejected': '-5.4095', 'rewards_train/margins': '5.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.32324', 'examples_per_second': '4.8721', 'grad_norm': '6.9062', 'counters/examples': 26304, 'counters/updates': 1644}
skipping logging after 26320 examples to avoid logging too frequently
skipping logging after 26336 examples to avoid logging too frequently
skipping logging after 26352 examples to avoid logging too frequently
train stats after 26368 examples: {'rewards_train/chosen': '0.4404', 'rewards_train/rejected': '-4.7812', 'rewards_train/margins': '5.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24731', 'examples_per_second': '4.3933', 'grad_norm': '5.4375', 'counters/examples': 26368, 'counters/updates': 1648}
skipping logging after 26384 examples to avoid logging too frequently
skipping logging after 26400 examples to avoid logging too frequently
skipping logging after 26416 examples to avoid logging too frequently
train stats after 26432 examples: {'rewards_train/chosen': '0.49039', 'rewards_train/rejected': '-5.4228', 'rewards_train/margins': '5.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24463', 'examples_per_second': '4.811', 'grad_norm': '4.7188', 'counters/examples': 26432, 'counters/updates': 1652}
skipping logging after 26448 examples to avoid logging too frequently
skipping logging after 26464 examples to avoid logging too frequently
skipping logging after 26480 examples to avoid logging too frequently
train stats after 26496 examples: {'rewards_train/chosen': '0.46902', 'rewards_train/rejected': '-4.8403', 'rewards_train/margins': '5.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1958', 'examples_per_second': '4.7285', 'grad_norm': '5.2188', 'counters/examples': 26496, 'counters/updates': 1656}
skipping logging after 26512 examples to avoid logging too frequently
skipping logging after 26528 examples to avoid logging too frequently
skipping logging after 26544 examples to avoid logging too frequently
train stats after 26560 examples: {'rewards_train/chosen': '0.21338', 'rewards_train/rejected': '-4.54', 'rewards_train/margins': '4.6875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30322', 'examples_per_second': '6.135', 'grad_norm': '5.7188', 'counters/examples': 26560, 'counters/updates': 1660}
skipping logging after 26576 examples to avoid logging too frequently
skipping logging after 26592 examples to avoid logging too frequently
skipping logging after 26608 examples to avoid logging too frequently
train stats after 26624 examples: {'rewards_train/chosen': '0.56025', 'rewards_train/rejected': '-5.7915', 'rewards_train/margins': '6.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.242', 'examples_per_second': '4.7715', 'grad_norm': '5.4688', 'counters/examples': 26624, 'counters/updates': 1664}
skipping logging after 26640 examples to avoid logging too frequently
skipping logging after 26656 examples to avoid logging too frequently
skipping logging after 26672 examples to avoid logging too frequently
train stats after 26688 examples: {'rewards_train/chosen': '0.60914', 'rewards_train/rejected': '-4.4113', 'rewards_train/margins': '5.082', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22461', 'examples_per_second': '4.4435', 'grad_norm': '4.7812', 'counters/examples': 26688, 'counters/updates': 1668}
skipping logging after 26704 examples to avoid logging too frequently
skipping logging after 26720 examples to avoid logging too frequently
skipping logging after 26736 examples to avoid logging too frequently
train stats after 26752 examples: {'rewards_train/chosen': '0.44061', 'rewards_train/rejected': '-5.3961', 'rewards_train/margins': '5.6328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23627', 'examples_per_second': '5.0599', 'grad_norm': '5.4688', 'counters/examples': 26752, 'counters/updates': 1672}
skipping logging after 26768 examples to avoid logging too frequently
skipping logging after 26784 examples to avoid logging too frequently
skipping logging after 26800 examples to avoid logging too frequently
train stats after 26816 examples: {'rewards_train/chosen': '0.50686', 'rewards_train/rejected': '-4.5939', 'rewards_train/margins': '5.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.255', 'examples_per_second': '6.0869', 'grad_norm': '5', 'counters/examples': 26816, 'counters/updates': 1676}
skipping logging after 26832 examples to avoid logging too frequently
skipping logging after 26848 examples to avoid logging too frequently
skipping logging after 26864 examples to avoid logging too frequently
train stats after 26880 examples: {'rewards_train/chosen': '0.60054', 'rewards_train/rejected': '-5.7354', 'rewards_train/margins': '5.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24158', 'examples_per_second': '5.4862', 'grad_norm': '5.1562', 'counters/examples': 26880, 'counters/updates': 1680}
skipping logging after 26896 examples to avoid logging too frequently
skipping logging after 26912 examples to avoid logging too frequently
skipping logging after 26928 examples to avoid logging too frequently
train stats after 26944 examples: {'rewards_train/chosen': '0.35506', 'rewards_train/rejected': '-6.2325', 'rewards_train/margins': '6.6641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23444', 'examples_per_second': '5.0561', 'grad_norm': '4.4688', 'counters/examples': 26944, 'counters/updates': 1684}
skipping logging after 26960 examples to avoid logging too frequently
skipping logging after 26976 examples to avoid logging too frequently
skipping logging after 26992 examples to avoid logging too frequently
train stats after 27008 examples: {'rewards_train/chosen': '0.086043', 'rewards_train/rejected': '-5.9106', 'rewards_train/margins': '5.8945', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28662', 'examples_per_second': '6.155', 'grad_norm': '4.9688', 'counters/examples': 27008, 'counters/updates': 1688}
skipping logging after 27024 examples to avoid logging too frequently
skipping logging after 27040 examples to avoid logging too frequently
skipping logging after 27056 examples to avoid logging too frequently
train stats after 27072 examples: {'rewards_train/chosen': '0.18216', 'rewards_train/rejected': '-4.1571', 'rewards_train/margins': '4.4805', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27612', 'examples_per_second': '5.6077', 'grad_norm': '6.2812', 'counters/examples': 27072, 'counters/updates': 1692}
skipping logging after 27088 examples to avoid logging too frequently
skipping logging after 27104 examples to avoid logging too frequently
skipping logging after 27120 examples to avoid logging too frequently
train stats after 27136 examples: {'rewards_train/chosen': '0.4633', 'rewards_train/rejected': '-4.3372', 'rewards_train/margins': '4.9805', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26123', 'examples_per_second': '6.9259', 'grad_norm': '5.1875', 'counters/examples': 27136, 'counters/updates': 1696}
skipping logging after 27152 examples to avoid logging too frequently
skipping logging after 27168 examples to avoid logging too frequently
skipping logging after 27184 examples to avoid logging too frequently
train stats after 27200 examples: {'rewards_train/chosen': '0.46149', 'rewards_train/rejected': '-5.0508', 'rewards_train/margins': '5.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23352', 'examples_per_second': '4.613', 'grad_norm': '5', 'counters/examples': 27200, 'counters/updates': 1700}
skipping logging after 27216 examples to avoid logging too frequently
skipping logging after 27232 examples to avoid logging too frequently
skipping logging after 27248 examples to avoid logging too frequently
train stats after 27264 examples: {'rewards_train/chosen': '0.21451', 'rewards_train/rejected': '-5.195', 'rewards_train/margins': '5.4258', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24841', 'examples_per_second': '4.4596', 'grad_norm': '4.8125', 'counters/examples': 27264, 'counters/updates': 1704}
skipping logging after 27280 examples to avoid logging too frequently
skipping logging after 27296 examples to avoid logging too frequently
skipping logging after 27312 examples to avoid logging too frequently
train stats after 27328 examples: {'rewards_train/chosen': '0.48087', 'rewards_train/rejected': '-5.2261', 'rewards_train/margins': '5.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26642', 'examples_per_second': '4.6308', 'grad_norm': '5.8125', 'counters/examples': 27328, 'counters/updates': 1708}
skipping logging after 27344 examples to avoid logging too frequently
skipping logging after 27360 examples to avoid logging too frequently
skipping logging after 27376 examples to avoid logging too frequently
train stats after 27392 examples: {'rewards_train/chosen': '0.22183', 'rewards_train/rejected': '-5.6969', 'rewards_train/margins': '5.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28558', 'examples_per_second': '4.4157', 'grad_norm': '4.7188', 'counters/examples': 27392, 'counters/updates': 1712}
skipping logging after 27408 examples to avoid logging too frequently
skipping logging after 27424 examples to avoid logging too frequently
skipping logging after 27440 examples to avoid logging too frequently
train stats after 27456 examples: {'rewards_train/chosen': '0.46484', 'rewards_train/rejected': '-4.9953', 'rewards_train/margins': '5.5742', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23602', 'examples_per_second': '5.5152', 'grad_norm': '5.1875', 'counters/examples': 27456, 'counters/updates': 1716}
skipping logging after 27472 examples to avoid logging too frequently
skipping logging after 27488 examples to avoid logging too frequently
skipping logging after 27504 examples to avoid logging too frequently
train stats after 27520 examples: {'rewards_train/chosen': '0.3682', 'rewards_train/rejected': '-4.7388', 'rewards_train/margins': '4.9766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25476', 'examples_per_second': '4.1889', 'grad_norm': '5.2188', 'counters/examples': 27520, 'counters/updates': 1720}
skipping logging after 27536 examples to avoid logging too frequently
skipping logging after 27552 examples to avoid logging too frequently
skipping logging after 27568 examples to avoid logging too frequently
train stats after 27584 examples: {'rewards_train/chosen': '0.42879', 'rewards_train/rejected': '-5.7591', 'rewards_train/margins': '5.6641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21588', 'examples_per_second': '5.4537', 'grad_norm': '4.5312', 'counters/examples': 27584, 'counters/updates': 1724}
skipping logging after 27600 examples to avoid logging too frequently
skipping logging after 27616 examples to avoid logging too frequently
skipping logging after 27632 examples to avoid logging too frequently
train stats after 27648 examples: {'rewards_train/chosen': '0.39281', 'rewards_train/rejected': '-5.8569', 'rewards_train/margins': '5.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2309', 'examples_per_second': '5.6609', 'grad_norm': '4.4375', 'counters/examples': 27648, 'counters/updates': 1728}
skipping logging after 27664 examples to avoid logging too frequently
skipping logging after 27680 examples to avoid logging too frequently
skipping logging after 27696 examples to avoid logging too frequently
train stats after 27712 examples: {'rewards_train/chosen': '0.60449', 'rewards_train/rejected': '-5.8976', 'rewards_train/margins': '6.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19269', 'examples_per_second': '4.3855', 'grad_norm': '4.6875', 'counters/examples': 27712, 'counters/updates': 1732}
skipping logging after 27728 examples to avoid logging too frequently
skipping logging after 27744 examples to avoid logging too frequently
skipping logging after 27760 examples to avoid logging too frequently
train stats after 27776 examples: {'rewards_train/chosen': '0.32364', 'rewards_train/rejected': '-6.0362', 'rewards_train/margins': '6.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23431', 'examples_per_second': '4.9688', 'grad_norm': '5.0312', 'counters/examples': 27776, 'counters/updates': 1736}
skipping logging after 27792 examples to avoid logging too frequently
skipping logging after 27808 examples to avoid logging too frequently
skipping logging after 27824 examples to avoid logging too frequently
train stats after 27840 examples: {'rewards_train/chosen': '0.70979', 'rewards_train/rejected': '-5.8076', 'rewards_train/margins': '6.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19403', 'examples_per_second': '4.7751', 'grad_norm': '5.1875', 'counters/examples': 27840, 'counters/updates': 1740}
skipping logging after 27856 examples to avoid logging too frequently
skipping logging after 27872 examples to avoid logging too frequently
skipping logging after 27888 examples to avoid logging too frequently
train stats after 27904 examples: {'rewards_train/chosen': '0.20753', 'rewards_train/rejected': '-3.8713', 'rewards_train/margins': '4.0352', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29535', 'examples_per_second': '4.7551', 'grad_norm': '5.3125', 'counters/examples': 27904, 'counters/updates': 1744}
skipping logging after 27920 examples to avoid logging too frequently
skipping logging after 27936 examples to avoid logging too frequently
skipping logging after 27952 examples to avoid logging too frequently
train stats after 27968 examples: {'rewards_train/chosen': '0.44658', 'rewards_train/rejected': '-5.432', 'rewards_train/margins': '6.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24127', 'examples_per_second': '5.4426', 'grad_norm': '4.8125', 'counters/examples': 27968, 'counters/updates': 1748}
skipping logging after 27984 examples to avoid logging too frequently
skipping logging after 28000 examples to avoid logging too frequently
Running evaluation after 28000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:47,  1.55s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:41,  1.37s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:35,  1.23s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.47s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.68s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.49s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:34,  1.37s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.40s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:30,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:11,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.31s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.18s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.31s/it]
eval after 28000: {'rewards_eval/chosen': '-4.9988', 'rewards_eval/rejected': '-5.3229', 'rewards_eval/margins': '0.2334', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46407'}
skipping logging after 28016 examples to avoid logging too frequently
train stats after 28032 examples: {'rewards_train/chosen': '0.20459', 'rewards_train/rejected': '-5.1492', 'rewards_train/margins': '5.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24896', 'examples_per_second': '4.8136', 'grad_norm': '4.2812', 'counters/examples': 28032, 'counters/updates': 1752}
skipping logging after 28048 examples to avoid logging too frequently
skipping logging after 28064 examples to avoid logging too frequently
skipping logging after 28080 examples to avoid logging too frequently
train stats after 28096 examples: {'rewards_train/chosen': '0.30349', 'rewards_train/rejected': '-5.2125', 'rewards_train/margins': '5.4102', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23181', 'examples_per_second': '5.1418', 'grad_norm': '4.625', 'counters/examples': 28096, 'counters/updates': 1756}
skipping logging after 28112 examples to avoid logging too frequently
skipping logging after 28128 examples to avoid logging too frequently
skipping logging after 28144 examples to avoid logging too frequently
train stats after 28160 examples: {'rewards_train/chosen': '0.49034', 'rewards_train/rejected': '-5.6653', 'rewards_train/margins': '5.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20245', 'examples_per_second': '4.2173', 'grad_norm': '4.6875', 'counters/examples': 28160, 'counters/updates': 1760}
skipping logging after 28176 examples to avoid logging too frequently
skipping logging after 28192 examples to avoid logging too frequently
skipping logging after 28208 examples to avoid logging too frequently
train stats after 28224 examples: {'rewards_train/chosen': '0.40356', 'rewards_train/rejected': '-3.6921', 'rewards_train/margins': '4.168', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26013', 'examples_per_second': '6.5444', 'grad_norm': '4.6562', 'counters/examples': 28224, 'counters/updates': 1764}
skipping logging after 28240 examples to avoid logging too frequently
skipping logging after 28256 examples to avoid logging too frequently
skipping logging after 28272 examples to avoid logging too frequently
train stats after 28288 examples: {'rewards_train/chosen': '0.2468', 'rewards_train/rejected': '-5.7351', 'rewards_train/margins': '5.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22797', 'examples_per_second': '4.0264', 'grad_norm': '5.1562', 'counters/examples': 28288, 'counters/updates': 1768}
skipping logging after 28304 examples to avoid logging too frequently
skipping logging after 28320 examples to avoid logging too frequently
skipping logging after 28336 examples to avoid logging too frequently
train stats after 28352 examples: {'rewards_train/chosen': '0.26494', 'rewards_train/rejected': '-5.1013', 'rewards_train/margins': '5.3281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22845', 'examples_per_second': '6.2976', 'grad_norm': '5.0625', 'counters/examples': 28352, 'counters/updates': 1772}
skipping logging after 28368 examples to avoid logging too frequently
skipping logging after 28384 examples to avoid logging too frequently
skipping logging after 28400 examples to avoid logging too frequently
train stats after 28416 examples: {'rewards_train/chosen': '0.39', 'rewards_train/rejected': '-5.5746', 'rewards_train/margins': '6.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22137', 'examples_per_second': '5.5019', 'grad_norm': '4.5312', 'counters/examples': 28416, 'counters/updates': 1776}
skipping logging after 28432 examples to avoid logging too frequently
skipping logging after 28448 examples to avoid logging too frequently
skipping logging after 28464 examples to avoid logging too frequently
train stats after 28480 examples: {'rewards_train/chosen': '0.56629', 'rewards_train/rejected': '-5.5501', 'rewards_train/margins': '6.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18701', 'examples_per_second': '4.2218', 'grad_norm': '4.375', 'counters/examples': 28480, 'counters/updates': 1780}
skipping logging after 28496 examples to avoid logging too frequently
skipping logging after 28512 examples to avoid logging too frequently
skipping logging after 28528 examples to avoid logging too frequently
train stats after 28544 examples: {'rewards_train/chosen': '0.3099', 'rewards_train/rejected': '-5.9295', 'rewards_train/margins': '6.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21741', 'examples_per_second': '5.7106', 'grad_norm': '4.9062', 'counters/examples': 28544, 'counters/updates': 1784}
skipping logging after 28560 examples to avoid logging too frequently
skipping logging after 28576 examples to avoid logging too frequently
skipping logging after 28592 examples to avoid logging too frequently
train stats after 28608 examples: {'rewards_train/chosen': '0.13499', 'rewards_train/rejected': '-5.6681', 'rewards_train/margins': '5.4883', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22723', 'examples_per_second': '5.5483', 'grad_norm': '5', 'counters/examples': 28608, 'counters/updates': 1788}
skipping logging after 28624 examples to avoid logging too frequently
skipping logging after 28640 examples to avoid logging too frequently
skipping logging after 28656 examples to avoid logging too frequently
train stats after 28672 examples: {'rewards_train/chosen': '0.15449', 'rewards_train/rejected': '-5.5178', 'rewards_train/margins': '5.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23737', 'examples_per_second': '5.3397', 'grad_norm': '5.0625', 'counters/examples': 28672, 'counters/updates': 1792}
skipping logging after 28688 examples to avoid logging too frequently
skipping logging after 28704 examples to avoid logging too frequently
skipping logging after 28720 examples to avoid logging too frequently
train stats after 28736 examples: {'rewards_train/chosen': '0.28653', 'rewards_train/rejected': '-5.1498', 'rewards_train/margins': '5.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24774', 'examples_per_second': '5.2184', 'grad_norm': '5.0625', 'counters/examples': 28736, 'counters/updates': 1796}
skipping logging after 28752 examples to avoid logging too frequently
skipping logging after 28768 examples to avoid logging too frequently
skipping logging after 28784 examples to avoid logging too frequently
train stats after 28800 examples: {'rewards_train/chosen': '0.42816', 'rewards_train/rejected': '-5.0877', 'rewards_train/margins': '5.5781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25964', 'examples_per_second': '5.4117', 'grad_norm': '4.7188', 'counters/examples': 28800, 'counters/updates': 1800}
skipping logging after 28816 examples to avoid logging too frequently
skipping logging after 28832 examples to avoid logging too frequently
skipping logging after 28848 examples to avoid logging too frequently
train stats after 28864 examples: {'rewards_train/chosen': '0.27572', 'rewards_train/rejected': '-5.8117', 'rewards_train/margins': '6.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25104', 'examples_per_second': '4.6564', 'grad_norm': '5.375', 'counters/examples': 28864, 'counters/updates': 1804}
skipping logging after 28880 examples to avoid logging too frequently
skipping logging after 28896 examples to avoid logging too frequently
skipping logging after 28912 examples to avoid logging too frequently
train stats after 28928 examples: {'rewards_train/chosen': '0.41915', 'rewards_train/rejected': '-4.421', 'rewards_train/margins': '4.707', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26935', 'examples_per_second': '5.8513', 'grad_norm': '5.0625', 'counters/examples': 28928, 'counters/updates': 1808}
skipping logging after 28944 examples to avoid logging too frequently
skipping logging after 28960 examples to avoid logging too frequently
skipping logging after 28976 examples to avoid logging too frequently
train stats after 28992 examples: {'rewards_train/chosen': '0.3976', 'rewards_train/rejected': '-5.8247', 'rewards_train/margins': '5.9453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21173', 'examples_per_second': '4.9662', 'grad_norm': '4.375', 'counters/examples': 28992, 'counters/updates': 1812}
skipping logging after 29008 examples to avoid logging too frequently
skipping logging after 29024 examples to avoid logging too frequently
skipping logging after 29040 examples to avoid logging too frequently
train stats after 29056 examples: {'rewards_train/chosen': '0.39331', 'rewards_train/rejected': '-5.8067', 'rewards_train/margins': '6.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21716', 'examples_per_second': '4.1538', 'grad_norm': '4.375', 'counters/examples': 29056, 'counters/updates': 1816}
skipping logging after 29072 examples to avoid logging too frequently
skipping logging after 29088 examples to avoid logging too frequently
skipping logging after 29104 examples to avoid logging too frequently
train stats after 29120 examples: {'rewards_train/chosen': '0.28218', 'rewards_train/rejected': '-5.1345', 'rewards_train/margins': '5.3633', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25653', 'examples_per_second': '5.0061', 'grad_norm': '4.8125', 'counters/examples': 29120, 'counters/updates': 1820}
skipping logging after 29136 examples to avoid logging too frequently
skipping logging after 29152 examples to avoid logging too frequently
skipping logging after 29168 examples to avoid logging too frequently
train stats after 29184 examples: {'rewards_train/chosen': '0.26718', 'rewards_train/rejected': '-5.3704', 'rewards_train/margins': '5.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20801', 'examples_per_second': '6.2268', 'grad_norm': '4.8438', 'counters/examples': 29184, 'counters/updates': 1824}
skipping logging after 29200 examples to avoid logging too frequently
skipping logging after 29216 examples to avoid logging too frequently
skipping logging after 29232 examples to avoid logging too frequently
train stats after 29248 examples: {'rewards_train/chosen': '0.61713', 'rewards_train/rejected': '-6.0505', 'rewards_train/margins': '6.7266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22656', 'examples_per_second': '5.2276', 'grad_norm': '5.4062', 'counters/examples': 29248, 'counters/updates': 1828}
skipping logging after 29264 examples to avoid logging too frequently
skipping logging after 29280 examples to avoid logging too frequently
skipping logging after 29296 examples to avoid logging too frequently
train stats after 29312 examples: {'rewards_train/chosen': '0.59425', 'rewards_train/rejected': '-6.0293', 'rewards_train/margins': '6.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18982', 'examples_per_second': '5.1121', 'grad_norm': '4.6562', 'counters/examples': 29312, 'counters/updates': 1832}
skipping logging after 29328 examples to avoid logging too frequently
skipping logging after 29344 examples to avoid logging too frequently
skipping logging after 29360 examples to avoid logging too frequently
train stats after 29376 examples: {'rewards_train/chosen': '0.53055', 'rewards_train/rejected': '-5.4288', 'rewards_train/margins': '5.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25916', 'examples_per_second': '4.9879', 'grad_norm': '4.6562', 'counters/examples': 29376, 'counters/updates': 1836}
skipping logging after 29392 examples to avoid logging too frequently
skipping logging after 29408 examples to avoid logging too frequently
skipping logging after 29424 examples to avoid logging too frequently
train stats after 29440 examples: {'rewards_train/chosen': '0.51765', 'rewards_train/rejected': '-4.0827', 'rewards_train/margins': '4.6328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26031', 'examples_per_second': '4.9206', 'grad_norm': '5.4688', 'counters/examples': 29440, 'counters/updates': 1840}
skipping logging after 29456 examples to avoid logging too frequently
skipping logging after 29472 examples to avoid logging too frequently
skipping logging after 29488 examples to avoid logging too frequently
train stats after 29504 examples: {'rewards_train/chosen': '0.47957', 'rewards_train/rejected': '-6.0669', 'rewards_train/margins': '6.4609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19403', 'examples_per_second': '4.2698', 'grad_norm': '4.1875', 'counters/examples': 29504, 'counters/updates': 1844}
skipping logging after 29520 examples to avoid logging too frequently
skipping logging after 29536 examples to avoid logging too frequently
skipping logging after 29552 examples to avoid logging too frequently
train stats after 29568 examples: {'rewards_train/chosen': '0.59777', 'rewards_train/rejected': '-7.1766', 'rewards_train/margins': '7.7578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19037', 'examples_per_second': '5.0346', 'grad_norm': '4.9062', 'counters/examples': 29568, 'counters/updates': 1848}
skipping logging after 29584 examples to avoid logging too frequently
skipping logging after 29600 examples to avoid logging too frequently
skipping logging after 29616 examples to avoid logging too frequently
train stats after 29632 examples: {'rewards_train/chosen': '0.52997', 'rewards_train/rejected': '-4.7364', 'rewards_train/margins': '5.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22266', 'examples_per_second': '5.2301', 'grad_norm': '5.125', 'counters/examples': 29632, 'counters/updates': 1852}
skipping logging after 29648 examples to avoid logging too frequently
skipping logging after 29664 examples to avoid logging too frequently
skipping logging after 29680 examples to avoid logging too frequently
train stats after 29696 examples: {'rewards_train/chosen': '0.29653', 'rewards_train/rejected': '-4.9929', 'rewards_train/margins': '5.375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23358', 'examples_per_second': '4.1794', 'grad_norm': '6.3125', 'counters/examples': 29696, 'counters/updates': 1856}
skipping logging after 29712 examples to avoid logging too frequently
skipping logging after 29728 examples to avoid logging too frequently
skipping logging after 29744 examples to avoid logging too frequently
train stats after 29760 examples: {'rewards_train/chosen': '0.15003', 'rewards_train/rejected': '-4.3345', 'rewards_train/margins': '4.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23944', 'examples_per_second': '4.0862', 'grad_norm': '5.2812', 'counters/examples': 29760, 'counters/updates': 1860}
skipping logging after 29776 examples to avoid logging too frequently
skipping logging after 29792 examples to avoid logging too frequently
skipping logging after 29808 examples to avoid logging too frequently
train stats after 29824 examples: {'rewards_train/chosen': '0.21719', 'rewards_train/rejected': '-5.3634', 'rewards_train/margins': '5.7891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26025', 'examples_per_second': '5.1783', 'grad_norm': '4.6562', 'counters/examples': 29824, 'counters/updates': 1864}
skipping logging after 29840 examples to avoid logging too frequently
skipping logging after 29856 examples to avoid logging too frequently
skipping logging after 29872 examples to avoid logging too frequently
train stats after 29888 examples: {'rewards_train/chosen': '0.51389', 'rewards_train/rejected': '-5.4887', 'rewards_train/margins': '6.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25787', 'examples_per_second': '4.8207', 'grad_norm': '4.8438', 'counters/examples': 29888, 'counters/updates': 1868}
skipping logging after 29904 examples to avoid logging too frequently
skipping logging after 29920 examples to avoid logging too frequently
skipping logging after 29936 examples to avoid logging too frequently
train stats after 29952 examples: {'rewards_train/chosen': '0.63181', 'rewards_train/rejected': '-5.7002', 'rewards_train/margins': '5.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20007', 'examples_per_second': '4.8123', 'grad_norm': '4.3125', 'counters/examples': 29952, 'counters/updates': 1872}
skipping logging after 29968 examples to avoid logging too frequently
skipping logging after 29984 examples to avoid logging too frequently
skipping logging after 30000 examples to avoid logging too frequently
train stats after 30016 examples: {'rewards_train/chosen': '0.13307', 'rewards_train/rejected': '-5.9033', 'rewards_train/margins': '6.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23651', 'examples_per_second': '4.2938', 'grad_norm': '4.4688', 'counters/examples': 30016, 'counters/updates': 1876}
skipping logging after 30032 examples to avoid logging too frequently
skipping logging after 30048 examples to avoid logging too frequently
skipping logging after 30064 examples to avoid logging too frequently
train stats after 30080 examples: {'rewards_train/chosen': '0.42108', 'rewards_train/rejected': '-5.4124', 'rewards_train/margins': '5.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21222', 'examples_per_second': '5.1282', 'grad_norm': '4.2812', 'counters/examples': 30080, 'counters/updates': 1880}
skipping logging after 30096 examples to avoid logging too frequently
skipping logging after 30112 examples to avoid logging too frequently
skipping logging after 30128 examples to avoid logging too frequently
train stats after 30144 examples: {'rewards_train/chosen': '0.24976', 'rewards_train/rejected': '-5.7921', 'rewards_train/margins': '6', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25946', 'examples_per_second': '5.8965', 'grad_norm': '5.125', 'counters/examples': 30144, 'counters/updates': 1884}
skipping logging after 30160 examples to avoid logging too frequently
skipping logging after 30176 examples to avoid logging too frequently
skipping logging after 30192 examples to avoid logging too frequently
train stats after 30208 examples: {'rewards_train/chosen': '0.3672', 'rewards_train/rejected': '-3.8598', 'rewards_train/margins': '4.332', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24554', 'examples_per_second': '5.3434', 'grad_norm': '5.0625', 'counters/examples': 30208, 'counters/updates': 1888}
skipping logging after 30224 examples to avoid logging too frequently
skipping logging after 30240 examples to avoid logging too frequently
skipping logging after 30256 examples to avoid logging too frequently
train stats after 30272 examples: {'rewards_train/chosen': '0.14576', 'rewards_train/rejected': '-4.7796', 'rewards_train/margins': '4.9375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22424', 'examples_per_second': '6.0915', 'grad_norm': '5.25', 'counters/examples': 30272, 'counters/updates': 1892}
skipping logging after 30288 examples to avoid logging too frequently
skipping logging after 30304 examples to avoid logging too frequently
skipping logging after 30320 examples to avoid logging too frequently
train stats after 30336 examples: {'rewards_train/chosen': '0.16089', 'rewards_train/rejected': '-5.6948', 'rewards_train/margins': '5.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25665', 'examples_per_second': '4.5532', 'grad_norm': '5.3125', 'counters/examples': 30336, 'counters/updates': 1896}
skipping logging after 30352 examples to avoid logging too frequently
skipping logging after 30368 examples to avoid logging too frequently
skipping logging after 30384 examples to avoid logging too frequently
train stats after 30400 examples: {'rewards_train/chosen': '0.035637', 'rewards_train/rejected': '-5.6526', 'rewards_train/margins': '5.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2644', 'examples_per_second': '5.2456', 'grad_norm': '4.6562', 'counters/examples': 30400, 'counters/updates': 1900}
skipping logging after 30416 examples to avoid logging too frequently
skipping logging after 30432 examples to avoid logging too frequently
skipping logging after 30448 examples to avoid logging too frequently
train stats after 30464 examples: {'rewards_train/chosen': '0.52039', 'rewards_train/rejected': '-4.669', 'rewards_train/margins': '5.0859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27325', 'examples_per_second': '5.246', 'grad_norm': '5.1562', 'counters/examples': 30464, 'counters/updates': 1904}
skipping logging after 30480 examples to avoid logging too frequently
skipping logging after 30496 examples to avoid logging too frequently
skipping logging after 30512 examples to avoid logging too frequently
train stats after 30528 examples: {'rewards_train/chosen': '0.46963', 'rewards_train/rejected': '-4.4895', 'rewards_train/margins': '4.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21832', 'examples_per_second': '4.7744', 'grad_norm': '4.4688', 'counters/examples': 30528, 'counters/updates': 1908}
skipping logging after 30544 examples to avoid logging too frequently
skipping logging after 30560 examples to avoid logging too frequently
skipping logging after 30576 examples to avoid logging too frequently
train stats after 30592 examples: {'rewards_train/chosen': '0.54998', 'rewards_train/rejected': '-5.5201', 'rewards_train/margins': '6.0312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24249', 'examples_per_second': '6.0085', 'grad_norm': '5.875', 'counters/examples': 30592, 'counters/updates': 1912}
skipping logging after 30608 examples to avoid logging too frequently
skipping logging after 30624 examples to avoid logging too frequently
skipping logging after 30640 examples to avoid logging too frequently
train stats after 30656 examples: {'rewards_train/chosen': '0.36127', 'rewards_train/rejected': '-5.0074', 'rewards_train/margins': '5.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26208', 'examples_per_second': '4.9038', 'grad_norm': '4.8125', 'counters/examples': 30656, 'counters/updates': 1916}
skipping logging after 30672 examples to avoid logging too frequently
skipping logging after 30688 examples to avoid logging too frequently
skipping logging after 30704 examples to avoid logging too frequently
train stats after 30720 examples: {'rewards_train/chosen': '0.43356', 'rewards_train/rejected': '-5.3825', 'rewards_train/margins': '5.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22137', 'examples_per_second': '5.6774', 'grad_norm': '4.7812', 'counters/examples': 30720, 'counters/updates': 1920}
skipping logging after 30736 examples to avoid logging too frequently
skipping logging after 30752 examples to avoid logging too frequently
skipping logging after 30768 examples to avoid logging too frequently
train stats after 30784 examples: {'rewards_train/chosen': '0.41873', 'rewards_train/rejected': '-5.3252', 'rewards_train/margins': '5.918', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23633', 'examples_per_second': '5.9683', 'grad_norm': '4.9062', 'counters/examples': 30784, 'counters/updates': 1924}
skipping logging after 30800 examples to avoid logging too frequently
skipping logging after 30816 examples to avoid logging too frequently
skipping logging after 30832 examples to avoid logging too frequently
train stats after 30848 examples: {'rewards_train/chosen': '0.11486', 'rewards_train/rejected': '-4.7956', 'rewards_train/margins': '4.9258', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26025', 'examples_per_second': '5.3552', 'grad_norm': '4.9062', 'counters/examples': 30848, 'counters/updates': 1928}
skipping logging after 30864 examples to avoid logging too frequently
skipping logging after 30880 examples to avoid logging too frequently
skipping logging after 30896 examples to avoid logging too frequently
train stats after 30912 examples: {'rewards_train/chosen': '0.63642', 'rewards_train/rejected': '-4.7878', 'rewards_train/margins': '5.3672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24268', 'examples_per_second': '5.7146', 'grad_norm': '5.1875', 'counters/examples': 30912, 'counters/updates': 1932}
skipping logging after 30928 examples to avoid logging too frequently
skipping logging after 30944 examples to avoid logging too frequently
skipping logging after 30960 examples to avoid logging too frequently
train stats after 30976 examples: {'rewards_train/chosen': '0.50331', 'rewards_train/rejected': '-6.9392', 'rewards_train/margins': '7.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17896', 'examples_per_second': '4.4729', 'grad_norm': '4.3125', 'counters/examples': 30976, 'counters/updates': 1936}
skipping logging after 30992 examples to avoid logging too frequently
skipping logging after 31008 examples to avoid logging too frequently
skipping logging after 31024 examples to avoid logging too frequently
train stats after 31040 examples: {'rewards_train/chosen': '0.29634', 'rewards_train/rejected': '-4.7998', 'rewards_train/margins': '5.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.271', 'examples_per_second': '6.6319', 'grad_norm': '5.875', 'counters/examples': 31040, 'counters/updates': 1940}
skipping logging after 31056 examples to avoid logging too frequently
skipping logging after 31072 examples to avoid logging too frequently
skipping logging after 31088 examples to avoid logging too frequently
train stats after 31104 examples: {'rewards_train/chosen': '0.39385', 'rewards_train/rejected': '-5.4062', 'rewards_train/margins': '5.7148', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21893', 'examples_per_second': '4.8739', 'grad_norm': '4.4062', 'counters/examples': 31104, 'counters/updates': 1944}
skipping logging after 31120 examples to avoid logging too frequently
skipping logging after 31136 examples to avoid logging too frequently
skipping logging after 31152 examples to avoid logging too frequently
train stats after 31168 examples: {'rewards_train/chosen': '0.56909', 'rewards_train/rejected': '-4.7752', 'rewards_train/margins': '5.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22864', 'examples_per_second': '4.4647', 'grad_norm': '5.1875', 'counters/examples': 31168, 'counters/updates': 1948}
skipping logging after 31184 examples to avoid logging too frequently
skipping logging after 31200 examples to avoid logging too frequently
skipping logging after 31216 examples to avoid logging too frequently
train stats after 31232 examples: {'rewards_train/chosen': '0.40298', 'rewards_train/rejected': '-6.7312', 'rewards_train/margins': '6.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20245', 'examples_per_second': '4.9559', 'grad_norm': '4.5', 'counters/examples': 31232, 'counters/updates': 1952}
skipping logging after 31248 examples to avoid logging too frequently
skipping logging after 31264 examples to avoid logging too frequently
skipping logging after 31280 examples to avoid logging too frequently
train stats after 31296 examples: {'rewards_train/chosen': '0.57847', 'rewards_train/rejected': '-4.9864', 'rewards_train/margins': '5.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23541', 'examples_per_second': '5.2155', 'grad_norm': '4.2812', 'counters/examples': 31296, 'counters/updates': 1956}
skipping logging after 31312 examples to avoid logging too frequently
skipping logging after 31328 examples to avoid logging too frequently
skipping logging after 31344 examples to avoid logging too frequently
train stats after 31360 examples: {'rewards_train/chosen': '0.5385', 'rewards_train/rejected': '-4.6607', 'rewards_train/margins': '5.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21191', 'examples_per_second': '5.5908', 'grad_norm': '5.0312', 'counters/examples': 31360, 'counters/updates': 1960}
skipping logging after 31376 examples to avoid logging too frequently
skipping logging after 31392 examples to avoid logging too frequently
skipping logging after 31408 examples to avoid logging too frequently
train stats after 31424 examples: {'rewards_train/chosen': '0.43439', 'rewards_train/rejected': '-6.4446', 'rewards_train/margins': '6.7734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21234', 'examples_per_second': '5.9107', 'grad_norm': '4.4062', 'counters/examples': 31424, 'counters/updates': 1964}
skipping logging after 31440 examples to avoid logging too frequently
skipping logging after 31456 examples to avoid logging too frequently
skipping logging after 31472 examples to avoid logging too frequently
train stats after 31488 examples: {'rewards_train/chosen': '0.33613', 'rewards_train/rejected': '-4.559', 'rewards_train/margins': '4.8477', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24884', 'examples_per_second': '6.1625', 'grad_norm': '4.8438', 'counters/examples': 31488, 'counters/updates': 1968}
skipping logging after 31504 examples to avoid logging too frequently
skipping logging after 31520 examples to avoid logging too frequently
skipping logging after 31536 examples to avoid logging too frequently
train stats after 31552 examples: {'rewards_train/chosen': '0.24296', 'rewards_train/rejected': '-5.1244', 'rewards_train/margins': '5.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.3009', 'examples_per_second': '6.1492', 'grad_norm': '5.1875', 'counters/examples': 31552, 'counters/updates': 1972}
skipping logging after 31568 examples to avoid logging too frequently
skipping logging after 31584 examples to avoid logging too frequently
skipping logging after 31600 examples to avoid logging too frequently
train stats after 31616 examples: {'rewards_train/chosen': '0.56054', 'rewards_train/rejected': '-4.7407', 'rewards_train/margins': '5.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25964', 'examples_per_second': '4.7254', 'grad_norm': '6.2188', 'counters/examples': 31616, 'counters/updates': 1976}
skipping logging after 31632 examples to avoid logging too frequently
skipping logging after 31648 examples to avoid logging too frequently
skipping logging after 31664 examples to avoid logging too frequently
train stats after 31680 examples: {'rewards_train/chosen': '0.50643', 'rewards_train/rejected': '-3.9456', 'rewards_train/margins': '4.5391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24432', 'examples_per_second': '5.4002', 'grad_norm': '5.0625', 'counters/examples': 31680, 'counters/updates': 1980}
skipping logging after 31696 examples to avoid logging too frequently
skipping logging after 31712 examples to avoid logging too frequently
skipping logging after 31728 examples to avoid logging too frequently
train stats after 31744 examples: {'rewards_train/chosen': '0.4736', 'rewards_train/rejected': '-4.7342', 'rewards_train/margins': '5.1016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23999', 'examples_per_second': '4.097', 'grad_norm': '4.9375', 'counters/examples': 31744, 'counters/updates': 1984}
skipping logging after 31760 examples to avoid logging too frequently
skipping logging after 31776 examples to avoid logging too frequently
skipping logging after 31792 examples to avoid logging too frequently
train stats after 31808 examples: {'rewards_train/chosen': '0.20217', 'rewards_train/rejected': '-5.1274', 'rewards_train/margins': '5.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26892', 'examples_per_second': '5.1519', 'grad_norm': '5.25', 'counters/examples': 31808, 'counters/updates': 1988}
skipping logging after 31824 examples to avoid logging too frequently
skipping logging after 31840 examples to avoid logging too frequently
skipping logging after 31856 examples to avoid logging too frequently
train stats after 31872 examples: {'rewards_train/chosen': '0.52332', 'rewards_train/rejected': '-4.0304', 'rewards_train/margins': '4.6211', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24982', 'examples_per_second': '5.0367', 'grad_norm': '5.0312', 'counters/examples': 31872, 'counters/updates': 1992}
skipping logging after 31888 examples to avoid logging too frequently
skipping logging after 31904 examples to avoid logging too frequently
skipping logging after 31920 examples to avoid logging too frequently
train stats after 31936 examples: {'rewards_train/chosen': '0.44575', 'rewards_train/rejected': '-6.3438', 'rewards_train/margins': '6.7812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19', 'examples_per_second': '6.3716', 'grad_norm': '3.8438', 'counters/examples': 31936, 'counters/updates': 1996}
skipping logging after 31952 examples to avoid logging too frequently
skipping logging after 31968 examples to avoid logging too frequently
skipping logging after 31984 examples to avoid logging too frequently
train stats after 32000 examples: {'rewards_train/chosen': '0.55164', 'rewards_train/rejected': '-5.8823', 'rewards_train/margins': '6.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22589', 'examples_per_second': '5.9659', 'grad_norm': '4.75', 'counters/examples': 32000, 'counters/updates': 2000}
Running evaluation after 32000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.26s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.17s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:40,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.66s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.47s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:34,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.41s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.28s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.42s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.20s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.31s/it]
eval after 32000: {'rewards_eval/chosen': '-4.983', 'rewards_eval/rejected': '-5.2562', 'rewards_eval/margins': '0.17139', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.4642'}
skipping logging after 32016 examples to avoid logging too frequently
skipping logging after 32032 examples to avoid logging too frequently
skipping logging after 32048 examples to avoid logging too frequently
train stats after 32064 examples: {'rewards_train/chosen': '0.52535', 'rewards_train/rejected': '-5.7096', 'rewards_train/margins': '6.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20557', 'examples_per_second': '5.9639', 'grad_norm': '3.9844', 'counters/examples': 32064, 'counters/updates': 2004}
skipping logging after 32080 examples to avoid logging too frequently
skipping logging after 32096 examples to avoid logging too frequently
skipping logging after 32112 examples to avoid logging too frequently
train stats after 32128 examples: {'rewards_train/chosen': '0.58255', 'rewards_train/rejected': '-5.418', 'rewards_train/margins': '5.8203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22205', 'examples_per_second': '5.155', 'grad_norm': '4.7812', 'counters/examples': 32128, 'counters/updates': 2008}
skipping logging after 32144 examples to avoid logging too frequently
skipping logging after 32160 examples to avoid logging too frequently
skipping logging after 32176 examples to avoid logging too frequently
train stats after 32192 examples: {'rewards_train/chosen': '0.22332', 'rewards_train/rejected': '-6.4617', 'rewards_train/margins': '6.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27563', 'examples_per_second': '5.0546', 'grad_norm': '4.9375', 'counters/examples': 32192, 'counters/updates': 2012}
skipping logging after 32208 examples to avoid logging too frequently
skipping logging after 32224 examples to avoid logging too frequently
skipping logging after 32240 examples to avoid logging too frequently
train stats after 32256 examples: {'rewards_train/chosen': '0.50877', 'rewards_train/rejected': '-5.2961', 'rewards_train/margins': '5.8125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22137', 'examples_per_second': '5.186', 'grad_norm': '4.2188', 'counters/examples': 32256, 'counters/updates': 2016}
skipping logging after 32272 examples to avoid logging too frequently
skipping logging after 32288 examples to avoid logging too frequently
skipping logging after 32304 examples to avoid logging too frequently
train stats after 32320 examples: {'rewards_train/chosen': '0.2466', 'rewards_train/rejected': '-6.4235', 'rewards_train/margins': '6.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24146', 'examples_per_second': '5.2327', 'grad_norm': '4.8438', 'counters/examples': 32320, 'counters/updates': 2020}
skipping logging after 32336 examples to avoid logging too frequently
skipping logging after 32352 examples to avoid logging too frequently
skipping logging after 32368 examples to avoid logging too frequently
train stats after 32384 examples: {'rewards_train/chosen': '0.13959', 'rewards_train/rejected': '-3.8035', 'rewards_train/margins': '3.8984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27106', 'examples_per_second': '5.6426', 'grad_norm': '5.0312', 'counters/examples': 32384, 'counters/updates': 2024}
skipping logging after 32400 examples to avoid logging too frequently
skipping logging after 32416 examples to avoid logging too frequently
skipping logging after 32432 examples to avoid logging too frequently
train stats after 32448 examples: {'rewards_train/chosen': '0.3227', 'rewards_train/rejected': '-5.5297', 'rewards_train/margins': '5.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23016', 'examples_per_second': '4.9594', 'grad_norm': '4.6875', 'counters/examples': 32448, 'counters/updates': 2028}
skipping logging after 32464 examples to avoid logging too frequently
skipping logging after 32480 examples to avoid logging too frequently
skipping logging after 32496 examples to avoid logging too frequently
train stats after 32512 examples: {'rewards_train/chosen': '0.68513', 'rewards_train/rejected': '-5.0148', 'rewards_train/margins': '5.6484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22333', 'examples_per_second': '4.1808', 'grad_norm': '4.5938', 'counters/examples': 32512, 'counters/updates': 2032}
skipping logging after 32528 examples to avoid logging too frequently
skipping logging after 32544 examples to avoid logging too frequently
skipping logging after 32560 examples to avoid logging too frequently
train stats after 32576 examples: {'rewards_train/chosen': '0.2147', 'rewards_train/rejected': '-5.5633', 'rewards_train/margins': '5.9883', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23383', 'examples_per_second': '5.36', 'grad_norm': '4.625', 'counters/examples': 32576, 'counters/updates': 2036}
skipping logging after 32592 examples to avoid logging too frequently
skipping logging after 32608 examples to avoid logging too frequently
skipping logging after 32624 examples to avoid logging too frequently
train stats after 32640 examples: {'rewards_train/chosen': '0.51248', 'rewards_train/rejected': '-5.1472', 'rewards_train/margins': '5.7031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23615', 'examples_per_second': '5.456', 'grad_norm': '5.0938', 'counters/examples': 32640, 'counters/updates': 2040}
skipping logging after 32656 examples to avoid logging too frequently
skipping logging after 32672 examples to avoid logging too frequently
skipping logging after 32688 examples to avoid logging too frequently
train stats after 32704 examples: {'rewards_train/chosen': '0.27306', 'rewards_train/rejected': '-4.9682', 'rewards_train/margins': '4.8828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26184', 'examples_per_second': '5.5485', 'grad_norm': '5.4375', 'counters/examples': 32704, 'counters/updates': 2044}
skipping logging after 32720 examples to avoid logging too frequently
skipping logging after 32736 examples to avoid logging too frequently
skipping logging after 32752 examples to avoid logging too frequently
train stats after 32768 examples: {'rewards_train/chosen': '0.87258', 'rewards_train/rejected': '-5.9502', 'rewards_train/margins': '6.8125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.16644', 'examples_per_second': '5.3583', 'grad_norm': '4.2812', 'counters/examples': 32768, 'counters/updates': 2048}
skipping logging after 32784 examples to avoid logging too frequently
skipping logging after 32800 examples to avoid logging too frequently
skipping logging after 32816 examples to avoid logging too frequently
train stats after 32832 examples: {'rewards_train/chosen': '0.46599', 'rewards_train/rejected': '-5.4406', 'rewards_train/margins': '5.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24713', 'examples_per_second': '5.6446', 'grad_norm': '5.5312', 'counters/examples': 32832, 'counters/updates': 2052}
skipping logging after 32848 examples to avoid logging too frequently
skipping logging after 32864 examples to avoid logging too frequently
skipping logging after 32880 examples to avoid logging too frequently
train stats after 32896 examples: {'rewards_train/chosen': '0.64597', 'rewards_train/rejected': '-5.9733', 'rewards_train/margins': '6.5781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23212', 'examples_per_second': '4.6362', 'grad_norm': '5', 'counters/examples': 32896, 'counters/updates': 2056}
skipping logging after 32912 examples to avoid logging too frequently
skipping logging after 32928 examples to avoid logging too frequently
skipping logging after 32944 examples to avoid logging too frequently
train stats after 32960 examples: {'rewards_train/chosen': '0.3982', 'rewards_train/rejected': '-5.492', 'rewards_train/margins': '5.6211', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2771', 'examples_per_second': '4.4917', 'grad_norm': '5.0312', 'counters/examples': 32960, 'counters/updates': 2060}
skipping logging after 32976 examples to avoid logging too frequently
skipping logging after 32992 examples to avoid logging too frequently
skipping logging after 33008 examples to avoid logging too frequently
train stats after 33024 examples: {'rewards_train/chosen': '0.45126', 'rewards_train/rejected': '-4.0167', 'rewards_train/margins': '4.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24164', 'examples_per_second': '4.4382', 'grad_norm': '5.5', 'counters/examples': 33024, 'counters/updates': 2064}
skipping logging after 33040 examples to avoid logging too frequently
skipping logging after 33056 examples to avoid logging too frequently
skipping logging after 33072 examples to avoid logging too frequently
train stats after 33088 examples: {'rewards_train/chosen': '0.095891', 'rewards_train/rejected': '-5.0801', 'rewards_train/margins': '5.2461', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22607', 'examples_per_second': '6.2464', 'grad_norm': '4.9062', 'counters/examples': 33088, 'counters/updates': 2068}
skipping logging after 33104 examples to avoid logging too frequently
skipping logging after 33120 examples to avoid logging too frequently
skipping logging after 33136 examples to avoid logging too frequently
train stats after 33152 examples: {'rewards_train/chosen': '0.45841', 'rewards_train/rejected': '-6.3683', 'rewards_train/margins': '6.8672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21808', 'examples_per_second': '4.7953', 'grad_norm': '4.0312', 'counters/examples': 33152, 'counters/updates': 2072}
skipping logging after 33168 examples to avoid logging too frequently
skipping logging after 33184 examples to avoid logging too frequently
skipping logging after 33200 examples to avoid logging too frequently
train stats after 33216 examples: {'rewards_train/chosen': '0.38933', 'rewards_train/rejected': '-4.9579', 'rewards_train/margins': '5.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19702', 'examples_per_second': '5.0511', 'grad_norm': '4.5625', 'counters/examples': 33216, 'counters/updates': 2076}
skipping logging after 33232 examples to avoid logging too frequently
skipping logging after 33248 examples to avoid logging too frequently
skipping logging after 33264 examples to avoid logging too frequently
train stats after 33280 examples: {'rewards_train/chosen': '0.35707', 'rewards_train/rejected': '-5.0631', 'rewards_train/margins': '5.3477', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27502', 'examples_per_second': '5.4671', 'grad_norm': '5.125', 'counters/examples': 33280, 'counters/updates': 2080}
skipping logging after 33296 examples to avoid logging too frequently
skipping logging after 33312 examples to avoid logging too frequently
skipping logging after 33328 examples to avoid logging too frequently
train stats after 33344 examples: {'rewards_train/chosen': '0.457', 'rewards_train/rejected': '-6.0489', 'rewards_train/margins': '6.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18243', 'examples_per_second': '4.7695', 'grad_norm': '3.9844', 'counters/examples': 33344, 'counters/updates': 2084}
skipping logging after 33360 examples to avoid logging too frequently
skipping logging after 33376 examples to avoid logging too frequently
skipping logging after 33392 examples to avoid logging too frequently
train stats after 33408 examples: {'rewards_train/chosen': '0.5976', 'rewards_train/rejected': '-5.0037', 'rewards_train/margins': '5.6016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20386', 'examples_per_second': '5.5563', 'grad_norm': '5', 'counters/examples': 33408, 'counters/updates': 2088}
skipping logging after 33424 examples to avoid logging too frequently
skipping logging after 33440 examples to avoid logging too frequently
skipping logging after 33456 examples to avoid logging too frequently
train stats after 33472 examples: {'rewards_train/chosen': '0.17708', 'rewards_train/rejected': '-5.3469', 'rewards_train/margins': '5.1406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22119', 'examples_per_second': '5.0359', 'grad_norm': '5.2188', 'counters/examples': 33472, 'counters/updates': 2092}
skipping logging after 33488 examples to avoid logging too frequently
skipping logging after 33504 examples to avoid logging too frequently
skipping logging after 33520 examples to avoid logging too frequently
train stats after 33536 examples: {'rewards_train/chosen': '0.42532', 'rewards_train/rejected': '-7.4342', 'rewards_train/margins': '7.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23798', 'examples_per_second': '3.7436', 'grad_norm': '4.8438', 'counters/examples': 33536, 'counters/updates': 2096}
skipping logging after 33552 examples to avoid logging too frequently
skipping logging after 33568 examples to avoid logging too frequently
skipping logging after 33584 examples to avoid logging too frequently
train stats after 33600 examples: {'rewards_train/chosen': '0.28151', 'rewards_train/rejected': '-4.9297', 'rewards_train/margins': '5.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2428', 'examples_per_second': '6.1508', 'grad_norm': '5.2812', 'counters/examples': 33600, 'counters/updates': 2100}
skipping logging after 33616 examples to avoid logging too frequently
skipping logging after 33632 examples to avoid logging too frequently
skipping logging after 33648 examples to avoid logging too frequently
train stats after 33664 examples: {'rewards_train/chosen': '0.54925', 'rewards_train/rejected': '-5.3911', 'rewards_train/margins': '5.7812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21576', 'examples_per_second': '5.3427', 'grad_norm': '3.9062', 'counters/examples': 33664, 'counters/updates': 2104}
skipping logging after 33680 examples to avoid logging too frequently
skipping logging after 33696 examples to avoid logging too frequently
skipping logging after 33712 examples to avoid logging too frequently
train stats after 33728 examples: {'rewards_train/chosen': '0.6083', 'rewards_train/rejected': '-5.6736', 'rewards_train/margins': '6.7812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23901', 'examples_per_second': '5.0821', 'grad_norm': '6.125', 'counters/examples': 33728, 'counters/updates': 2108}
skipping logging after 33744 examples to avoid logging too frequently
skipping logging after 33760 examples to avoid logging too frequently
skipping logging after 33776 examples to avoid logging too frequently
train stats after 33792 examples: {'rewards_train/chosen': '0.18748', 'rewards_train/rejected': '-4.8156', 'rewards_train/margins': '4.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28265', 'examples_per_second': '5.6444', 'grad_norm': '5.4688', 'counters/examples': 33792, 'counters/updates': 2112}
skipping logging after 33808 examples to avoid logging too frequently
skipping logging after 33824 examples to avoid logging too frequently
skipping logging after 33840 examples to avoid logging too frequently
train stats after 33856 examples: {'rewards_train/chosen': '0.24671', 'rewards_train/rejected': '-4.2426', 'rewards_train/margins': '4.3242', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26862', 'examples_per_second': '5.4273', 'grad_norm': '4.4375', 'counters/examples': 33856, 'counters/updates': 2116}
skipping logging after 33872 examples to avoid logging too frequently
skipping logging after 33888 examples to avoid logging too frequently
skipping logging after 33904 examples to avoid logging too frequently
train stats after 33920 examples: {'rewards_train/chosen': '0.46933', 'rewards_train/rejected': '-5.2562', 'rewards_train/margins': '5.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20752', 'examples_per_second': '4.6535', 'grad_norm': '4.4375', 'counters/examples': 33920, 'counters/updates': 2120}
skipping logging after 33936 examples to avoid logging too frequently
skipping logging after 33952 examples to avoid logging too frequently
skipping logging after 33968 examples to avoid logging too frequently
train stats after 33984 examples: {'rewards_train/chosen': '0.55059', 'rewards_train/rejected': '-5.0428', 'rewards_train/margins': '5.5117', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22833', 'examples_per_second': '5.865', 'grad_norm': '5.4375', 'counters/examples': 33984, 'counters/updates': 2124}
skipping logging after 34000 examples to avoid logging too frequently
skipping logging after 34016 examples to avoid logging too frequently
skipping logging after 34032 examples to avoid logging too frequently
train stats after 34048 examples: {'rewards_train/chosen': '0.40925', 'rewards_train/rejected': '-5.2672', 'rewards_train/margins': '5.6094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24438', 'examples_per_second': '4.8611', 'grad_norm': '6.3438', 'counters/examples': 34048, 'counters/updates': 2128}
skipping logging after 34064 examples to avoid logging too frequently
skipping logging after 34080 examples to avoid logging too frequently
skipping logging after 34096 examples to avoid logging too frequently
train stats after 34112 examples: {'rewards_train/chosen': '0.53269', 'rewards_train/rejected': '-4.384', 'rewards_train/margins': '4.8203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20447', 'examples_per_second': '4.7126', 'grad_norm': '4.75', 'counters/examples': 34112, 'counters/updates': 2132}
skipping logging after 34128 examples to avoid logging too frequently
skipping logging after 34144 examples to avoid logging too frequently
skipping logging after 34160 examples to avoid logging too frequently
train stats after 34176 examples: {'rewards_train/chosen': '0.66351', 'rewards_train/rejected': '-5.9976', 'rewards_train/margins': '6.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20715', 'examples_per_second': '4.6927', 'grad_norm': '4.5', 'counters/examples': 34176, 'counters/updates': 2136}
skipping logging after 34192 examples to avoid logging too frequently
skipping logging after 34208 examples to avoid logging too frequently
skipping logging after 34224 examples to avoid logging too frequently
train stats after 34240 examples: {'rewards_train/chosen': '0.45533', 'rewards_train/rejected': '-5.6181', 'rewards_train/margins': '6.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20209', 'examples_per_second': '5.8783', 'grad_norm': '5.2188', 'counters/examples': 34240, 'counters/updates': 2140}
skipping logging after 34256 examples to avoid logging too frequently
skipping logging after 34272 examples to avoid logging too frequently
skipping logging after 34288 examples to avoid logging too frequently
train stats after 34304 examples: {'rewards_train/chosen': '0.52795', 'rewards_train/rejected': '-5.4489', 'rewards_train/margins': '6.0742', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21814', 'examples_per_second': '6.0617', 'grad_norm': '5.1562', 'counters/examples': 34304, 'counters/updates': 2144}
skipping logging after 34320 examples to avoid logging too frequently
skipping logging after 34336 examples to avoid logging too frequently
skipping logging after 34352 examples to avoid logging too frequently
train stats after 34368 examples: {'rewards_train/chosen': '0.38559', 'rewards_train/rejected': '-6.2581', 'rewards_train/margins': '6.5781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2077', 'examples_per_second': '5.8543', 'grad_norm': '4.875', 'counters/examples': 34368, 'counters/updates': 2148}
skipping logging after 34384 examples to avoid logging too frequently
skipping logging after 34400 examples to avoid logging too frequently
skipping logging after 34416 examples to avoid logging too frequently
train stats after 34432 examples: {'rewards_train/chosen': '0.39239', 'rewards_train/rejected': '-5.5482', 'rewards_train/margins': '6.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26599', 'examples_per_second': '4.3395', 'grad_norm': '5.7188', 'counters/examples': 34432, 'counters/updates': 2152}
skipping logging after 34448 examples to avoid logging too frequently
skipping logging after 34464 examples to avoid logging too frequently
skipping logging after 34480 examples to avoid logging too frequently
train stats after 34496 examples: {'rewards_train/chosen': '0.57033', 'rewards_train/rejected': '-5.5296', 'rewards_train/margins': '5.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1828', 'examples_per_second': '5.6983', 'grad_norm': '5.0625', 'counters/examples': 34496, 'counters/updates': 2156}
skipping logging after 34512 examples to avoid logging too frequently
skipping logging after 34528 examples to avoid logging too frequently
skipping logging after 34544 examples to avoid logging too frequently
train stats after 34560 examples: {'rewards_train/chosen': '0.24808', 'rewards_train/rejected': '-5.5689', 'rewards_train/margins': '5.8164', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23547', 'examples_per_second': '6.584', 'grad_norm': '5.2188', 'counters/examples': 34560, 'counters/updates': 2160}
skipping logging after 34576 examples to avoid logging too frequently
skipping logging after 34592 examples to avoid logging too frequently
skipping logging after 34608 examples to avoid logging too frequently
train stats after 34624 examples: {'rewards_train/chosen': '0.39037', 'rewards_train/rejected': '-4.7737', 'rewards_train/margins': '5.1875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27185', 'examples_per_second': '4.9709', 'grad_norm': '4.7188', 'counters/examples': 34624, 'counters/updates': 2164}
skipping logging after 34640 examples to avoid logging too frequently
skipping logging after 34656 examples to avoid logging too frequently
skipping logging after 34672 examples to avoid logging too frequently
train stats after 34688 examples: {'rewards_train/chosen': '0.41282', 'rewards_train/rejected': '-5.7212', 'rewards_train/margins': '6.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24915', 'examples_per_second': '4.883', 'grad_norm': '5.6875', 'counters/examples': 34688, 'counters/updates': 2168}
skipping logging after 34704 examples to avoid logging too frequently
skipping logging after 34720 examples to avoid logging too frequently
skipping logging after 34736 examples to avoid logging too frequently
train stats after 34752 examples: {'rewards_train/chosen': '0.40795', 'rewards_train/rejected': '-4.7862', 'rewards_train/margins': '5.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2663', 'examples_per_second': '5.9998', 'grad_norm': '5.25', 'counters/examples': 34752, 'counters/updates': 2172}
skipping logging after 34768 examples to avoid logging too frequently
skipping logging after 34784 examples to avoid logging too frequently
skipping logging after 34800 examples to avoid logging too frequently
train stats after 34816 examples: {'rewards_train/chosen': '0.60001', 'rewards_train/rejected': '-4.6502', 'rewards_train/margins': '5.4336', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20844', 'examples_per_second': '4.5957', 'grad_norm': '4.5625', 'counters/examples': 34816, 'counters/updates': 2176}
skipping logging after 34832 examples to avoid logging too frequently
skipping logging after 34848 examples to avoid logging too frequently
skipping logging after 34864 examples to avoid logging too frequently
train stats after 34880 examples: {'rewards_train/chosen': '0.47377', 'rewards_train/rejected': '-4.6158', 'rewards_train/margins': '4.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23773', 'examples_per_second': '5.1356', 'grad_norm': '5.125', 'counters/examples': 34880, 'counters/updates': 2180}
skipping logging after 34896 examples to avoid logging too frequently
skipping logging after 34912 examples to avoid logging too frequently
skipping logging after 34928 examples to avoid logging too frequently
train stats after 34944 examples: {'rewards_train/chosen': '0.5835', 'rewards_train/rejected': '-4.3423', 'rewards_train/margins': '5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2088', 'examples_per_second': '5.1919', 'grad_norm': '4.4375', 'counters/examples': 34944, 'counters/updates': 2184}
skipping logging after 34960 examples to avoid logging too frequently
skipping logging after 34976 examples to avoid logging too frequently
skipping logging after 34992 examples to avoid logging too frequently
train stats after 35008 examples: {'rewards_train/chosen': '0.65727', 'rewards_train/rejected': '-5.7414', 'rewards_train/margins': '6.375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21649', 'examples_per_second': '4.3516', 'grad_norm': '5', 'counters/examples': 35008, 'counters/updates': 2188}
skipping logging after 35024 examples to avoid logging too frequently
skipping logging after 35040 examples to avoid logging too frequently
skipping logging after 35056 examples to avoid logging too frequently
train stats after 35072 examples: {'rewards_train/chosen': '0.28063', 'rewards_train/rejected': '-5.4852', 'rewards_train/margins': '5.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20355', 'examples_per_second': '5.6424', 'grad_norm': '4.4062', 'counters/examples': 35072, 'counters/updates': 2192}
skipping logging after 35088 examples to avoid logging too frequently
skipping logging after 35104 examples to avoid logging too frequently
skipping logging after 35120 examples to avoid logging too frequently
train stats after 35136 examples: {'rewards_train/chosen': '0.51517', 'rewards_train/rejected': '-3.9932', 'rewards_train/margins': '4.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26544', 'examples_per_second': '4.5965', 'grad_norm': '5.2188', 'counters/examples': 35136, 'counters/updates': 2196}
skipping logging after 35152 examples to avoid logging too frequently
skipping logging after 35168 examples to avoid logging too frequently
skipping logging after 35184 examples to avoid logging too frequently
train stats after 35200 examples: {'rewards_train/chosen': '0.53578', 'rewards_train/rejected': '-4.6479', 'rewards_train/margins': '5.3281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22729', 'examples_per_second': '4.4703', 'grad_norm': '5.1562', 'counters/examples': 35200, 'counters/updates': 2200}
skipping logging after 35216 examples to avoid logging too frequently
skipping logging after 35232 examples to avoid logging too frequently
skipping logging after 35248 examples to avoid logging too frequently
train stats after 35264 examples: {'rewards_train/chosen': '0.24852', 'rewards_train/rejected': '-5.0812', 'rewards_train/margins': '5.4805', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23645', 'examples_per_second': '4.7177', 'grad_norm': '5.0312', 'counters/examples': 35264, 'counters/updates': 2204}
skipping logging after 35280 examples to avoid logging too frequently
skipping logging after 35296 examples to avoid logging too frequently
skipping logging after 35312 examples to avoid logging too frequently
train stats after 35328 examples: {'rewards_train/chosen': '0.71801', 'rewards_train/rejected': '-5.5697', 'rewards_train/margins': '6.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24951', 'examples_per_second': '5.7323', 'grad_norm': '4.5938', 'counters/examples': 35328, 'counters/updates': 2208}
skipping logging after 35344 examples to avoid logging too frequently
skipping logging after 35360 examples to avoid logging too frequently
skipping logging after 35376 examples to avoid logging too frequently
train stats after 35392 examples: {'rewards_train/chosen': '0.31894', 'rewards_train/rejected': '-4.8477', 'rewards_train/margins': '5.1406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24005', 'examples_per_second': '5.7218', 'grad_norm': '4.5625', 'counters/examples': 35392, 'counters/updates': 2212}
skipping logging after 35408 examples to avoid logging too frequently
skipping logging after 35424 examples to avoid logging too frequently
skipping logging after 35440 examples to avoid logging too frequently
train stats after 35456 examples: {'rewards_train/chosen': '0.11286', 'rewards_train/rejected': '-5.9282', 'rewards_train/margins': '6', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2384', 'examples_per_second': '4.4932', 'grad_norm': '4.375', 'counters/examples': 35456, 'counters/updates': 2216}
skipping logging after 35472 examples to avoid logging too frequently
skipping logging after 35488 examples to avoid logging too frequently
skipping logging after 35504 examples to avoid logging too frequently
train stats after 35520 examples: {'rewards_train/chosen': '0.71105', 'rewards_train/rejected': '-5.511', 'rewards_train/margins': '6.2266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20105', 'examples_per_second': '5.2573', 'grad_norm': '4', 'counters/examples': 35520, 'counters/updates': 2220}
skipping logging after 35536 examples to avoid logging too frequently
skipping logging after 35552 examples to avoid logging too frequently
skipping logging after 35568 examples to avoid logging too frequently
train stats after 35584 examples: {'rewards_train/chosen': '0.54352', 'rewards_train/rejected': '-5.9061', 'rewards_train/margins': '6.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22473', 'examples_per_second': '5.4599', 'grad_norm': '5.0625', 'counters/examples': 35584, 'counters/updates': 2224}
skipping logging after 35600 examples to avoid logging too frequently
skipping logging after 35616 examples to avoid logging too frequently
skipping logging after 35632 examples to avoid logging too frequently
train stats after 35648 examples: {'rewards_train/chosen': '0.71722', 'rewards_train/rejected': '-4.9799', 'rewards_train/margins': '5.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2207', 'examples_per_second': '4.4656', 'grad_norm': '4.5', 'counters/examples': 35648, 'counters/updates': 2228}
skipping logging after 35664 examples to avoid logging too frequently
skipping logging after 35680 examples to avoid logging too frequently
skipping logging after 35696 examples to avoid logging too frequently
train stats after 35712 examples: {'rewards_train/chosen': '0.51268', 'rewards_train/rejected': '-5.7285', 'rewards_train/margins': '6.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21942', 'examples_per_second': '4.5607', 'grad_norm': '6.0625', 'counters/examples': 35712, 'counters/updates': 2232}
skipping logging after 35728 examples to avoid logging too frequently
skipping logging after 35744 examples to avoid logging too frequently
skipping logging after 35760 examples to avoid logging too frequently
train stats after 35776 examples: {'rewards_train/chosen': '0.40023', 'rewards_train/rejected': '-5.7338', 'rewards_train/margins': '6.6094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24005', 'examples_per_second': '4.8867', 'grad_norm': '5', 'counters/examples': 35776, 'counters/updates': 2236}
skipping logging after 35792 examples to avoid logging too frequently
skipping logging after 35808 examples to avoid logging too frequently
skipping logging after 35824 examples to avoid logging too frequently
train stats after 35840 examples: {'rewards_train/chosen': '0.20385', 'rewards_train/rejected': '-4.8578', 'rewards_train/margins': '5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19916', 'examples_per_second': '5.055', 'grad_norm': '4', 'counters/examples': 35840, 'counters/updates': 2240}
skipping logging after 35856 examples to avoid logging too frequently
skipping logging after 35872 examples to avoid logging too frequently
skipping logging after 35888 examples to avoid logging too frequently
train stats after 35904 examples: {'rewards_train/chosen': '0.48318', 'rewards_train/rejected': '-5.8581', 'rewards_train/margins': '6.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18427', 'examples_per_second': '4.8326', 'grad_norm': '5.1875', 'counters/examples': 35904, 'counters/updates': 2244}
skipping logging after 35920 examples to avoid logging too frequently
skipping logging after 35936 examples to avoid logging too frequently
skipping logging after 35952 examples to avoid logging too frequently
train stats after 35968 examples: {'rewards_train/chosen': '0.31656', 'rewards_train/rejected': '-4.8086', 'rewards_train/margins': '5.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23206', 'examples_per_second': '4.7978', 'grad_norm': '4.625', 'counters/examples': 35968, 'counters/updates': 2248}
skipping logging after 35984 examples to avoid logging too frequently
skipping logging after 36000 examples to avoid logging too frequently
Running evaluation after 36000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:49,  1.60s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:41,  1.40s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:35,  1.24s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.47s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.68s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.49s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:10<00:34,  1.37s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.49s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.41s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.28s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.44s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:41<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]
eval after 36000: {'rewards_eval/chosen': '-5.1164', 'rewards_eval/rejected': '-5.4749', 'rewards_eval/margins': '0.25146', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46397'}
skipping logging after 36016 examples to avoid logging too frequently
train stats after 36032 examples: {'rewards_train/chosen': '0.48262', 'rewards_train/rejected': '-4.8342', 'rewards_train/margins': '5.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27295', 'examples_per_second': '6.1769', 'grad_norm': '5.2812', 'counters/examples': 36032, 'counters/updates': 2252}
skipping logging after 36048 examples to avoid logging too frequently
skipping logging after 36064 examples to avoid logging too frequently
skipping logging after 36080 examples to avoid logging too frequently
train stats after 36096 examples: {'rewards_train/chosen': '0.45574', 'rewards_train/rejected': '-6.3752', 'rewards_train/margins': '6.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21289', 'examples_per_second': '4.6654', 'grad_norm': '4.0625', 'counters/examples': 36096, 'counters/updates': 2256}
skipping logging after 36112 examples to avoid logging too frequently
skipping logging after 36128 examples to avoid logging too frequently
skipping logging after 36144 examples to avoid logging too frequently
train stats after 36160 examples: {'rewards_train/chosen': '0.39698', 'rewards_train/rejected': '-4.8076', 'rewards_train/margins': '5.0312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1994', 'examples_per_second': '5.1994', 'grad_norm': '4.3438', 'counters/examples': 36160, 'counters/updates': 2260}
skipping logging after 36176 examples to avoid logging too frequently
skipping logging after 36192 examples to avoid logging too frequently
skipping logging after 36208 examples to avoid logging too frequently
train stats after 36224 examples: {'rewards_train/chosen': '0.40077', 'rewards_train/rejected': '-6.6539', 'rewards_train/margins': '7.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25177', 'examples_per_second': '5.6041', 'grad_norm': '4.9062', 'counters/examples': 36224, 'counters/updates': 2264}
skipping logging after 36240 examples to avoid logging too frequently
skipping logging after 36256 examples to avoid logging too frequently
skipping logging after 36272 examples to avoid logging too frequently
train stats after 36288 examples: {'rewards_train/chosen': '0.57239', 'rewards_train/rejected': '-5.1408', 'rewards_train/margins': '5.5352', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24384', 'examples_per_second': '4.5584', 'grad_norm': '5.1562', 'counters/examples': 36288, 'counters/updates': 2268}
skipping logging after 36304 examples to avoid logging too frequently
skipping logging after 36320 examples to avoid logging too frequently
skipping logging after 36336 examples to avoid logging too frequently
train stats after 36352 examples: {'rewards_train/chosen': '0.72407', 'rewards_train/rejected': '-5.413', 'rewards_train/margins': '6.1953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20435', 'examples_per_second': '5.2092', 'grad_norm': '4.5938', 'counters/examples': 36352, 'counters/updates': 2272}
skipping logging after 36368 examples to avoid logging too frequently
skipping logging after 36384 examples to avoid logging too frequently
skipping logging after 36400 examples to avoid logging too frequently
train stats after 36416 examples: {'rewards_train/chosen': '0.4527', 'rewards_train/rejected': '-5.3655', 'rewards_train/margins': '5.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.31232', 'examples_per_second': '5.6124', 'grad_norm': '6.1875', 'counters/examples': 36416, 'counters/updates': 2276}
skipping logging after 36432 examples to avoid logging too frequently
skipping logging after 36448 examples to avoid logging too frequently
skipping logging after 36464 examples to avoid logging too frequently
train stats after 36480 examples: {'rewards_train/chosen': '0.55056', 'rewards_train/rejected': '-5.0365', 'rewards_train/margins': '5.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21039', 'examples_per_second': '5.4128', 'grad_norm': '4.6562', 'counters/examples': 36480, 'counters/updates': 2280}
skipping logging after 36496 examples to avoid logging too frequently
skipping logging after 36512 examples to avoid logging too frequently
skipping logging after 36528 examples to avoid logging too frequently
train stats after 36544 examples: {'rewards_train/chosen': '0.56554', 'rewards_train/rejected': '-4.6289', 'rewards_train/margins': '5.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21332', 'examples_per_second': '6.1218', 'grad_norm': '4.25', 'counters/examples': 36544, 'counters/updates': 2284}
skipping logging after 36560 examples to avoid logging too frequently
skipping logging after 36576 examples to avoid logging too frequently
skipping logging after 36592 examples to avoid logging too frequently
train stats after 36608 examples: {'rewards_train/chosen': '0.37459', 'rewards_train/rejected': '-5.5593', 'rewards_train/margins': '5.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25677', 'examples_per_second': '6.6973', 'grad_norm': '5', 'counters/examples': 36608, 'counters/updates': 2288}
skipping logging after 36624 examples to avoid logging too frequently
skipping logging after 36640 examples to avoid logging too frequently
skipping logging after 36656 examples to avoid logging too frequently
train stats after 36672 examples: {'rewards_train/chosen': '0.47653', 'rewards_train/rejected': '-5.9981', 'rewards_train/margins': '6.3594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22314', 'examples_per_second': '4.3216', 'grad_norm': '4.9688', 'counters/examples': 36672, 'counters/updates': 2292}
skipping logging after 36688 examples to avoid logging too frequently
skipping logging after 36704 examples to avoid logging too frequently
skipping logging after 36720 examples to avoid logging too frequently
train stats after 36736 examples: {'rewards_train/chosen': '0.67176', 'rewards_train/rejected': '-6.0465', 'rewards_train/margins': '6.8906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20276', 'examples_per_second': '4.8966', 'grad_norm': '5.5', 'counters/examples': 36736, 'counters/updates': 2296}
skipping logging after 36752 examples to avoid logging too frequently
skipping logging after 36768 examples to avoid logging too frequently
skipping logging after 36784 examples to avoid logging too frequently
train stats after 36800 examples: {'rewards_train/chosen': '0.56556', 'rewards_train/rejected': '-4.0923', 'rewards_train/margins': '4.6484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24744', 'examples_per_second': '6.0818', 'grad_norm': '5', 'counters/examples': 36800, 'counters/updates': 2300}
skipping logging after 36816 examples to avoid logging too frequently
skipping logging after 36832 examples to avoid logging too frequently
skipping logging after 36848 examples to avoid logging too frequently
train stats after 36864 examples: {'rewards_train/chosen': '0.51453', 'rewards_train/rejected': '-6.3276', 'rewards_train/margins': '6.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22876', 'examples_per_second': '4.4178', 'grad_norm': '5.0938', 'counters/examples': 36864, 'counters/updates': 2304}
skipping logging after 36880 examples to avoid logging too frequently
skipping logging after 36896 examples to avoid logging too frequently
skipping logging after 36912 examples to avoid logging too frequently
train stats after 36928 examples: {'rewards_train/chosen': '0.38574', 'rewards_train/rejected': '-5.9589', 'rewards_train/margins': '6.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22522', 'examples_per_second': '7.217', 'grad_norm': '5.5', 'counters/examples': 36928, 'counters/updates': 2308}
skipping logging after 36944 examples to avoid logging too frequently
skipping logging after 36960 examples to avoid logging too frequently
skipping logging after 36976 examples to avoid logging too frequently
train stats after 36992 examples: {'rewards_train/chosen': '0.63348', 'rewards_train/rejected': '-5.3169', 'rewards_train/margins': '5.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18073', 'examples_per_second': '5.4453', 'grad_norm': '4.0312', 'counters/examples': 36992, 'counters/updates': 2312}
skipping logging after 37008 examples to avoid logging too frequently
skipping logging after 37024 examples to avoid logging too frequently
skipping logging after 37040 examples to avoid logging too frequently
train stats after 37056 examples: {'rewards_train/chosen': '0.36772', 'rewards_train/rejected': '-5.7929', 'rewards_train/margins': '6.0156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21661', 'examples_per_second': '5.0064', 'grad_norm': '5.125', 'counters/examples': 37056, 'counters/updates': 2316}
skipping logging after 37072 examples to avoid logging too frequently
skipping logging after 37088 examples to avoid logging too frequently
skipping logging after 37104 examples to avoid logging too frequently
train stats after 37120 examples: {'rewards_train/chosen': '0.57504', 'rewards_train/rejected': '-5.6152', 'rewards_train/margins': '6.1953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23114', 'examples_per_second': '5.7275', 'grad_norm': '4.9688', 'counters/examples': 37120, 'counters/updates': 2320}
skipping logging after 37136 examples to avoid logging too frequently
skipping logging after 37152 examples to avoid logging too frequently
skipping logging after 37168 examples to avoid logging too frequently
train stats after 37184 examples: {'rewards_train/chosen': '0.58201', 'rewards_train/rejected': '-4.6385', 'rewards_train/margins': '5.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22955', 'examples_per_second': '5.7819', 'grad_norm': '4.7188', 'counters/examples': 37184, 'counters/updates': 2324}
skipping logging after 37200 examples to avoid logging too frequently
skipping logging after 37216 examples to avoid logging too frequently
skipping logging after 37232 examples to avoid logging too frequently
train stats after 37248 examples: {'rewards_train/chosen': '0.44579', 'rewards_train/rejected': '-4.6327', 'rewards_train/margins': '5.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27344', 'examples_per_second': '6.4184', 'grad_norm': '5.9688', 'counters/examples': 37248, 'counters/updates': 2328}
skipping logging after 37264 examples to avoid logging too frequently
skipping logging after 37280 examples to avoid logging too frequently
skipping logging after 37296 examples to avoid logging too frequently
train stats after 37312 examples: {'rewards_train/chosen': '0.75966', 'rewards_train/rejected': '-4.9357', 'rewards_train/margins': '5.7812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22156', 'examples_per_second': '4.956', 'grad_norm': '5.375', 'counters/examples': 37312, 'counters/updates': 2332}
skipping logging after 37328 examples to avoid logging too frequently
skipping logging after 37344 examples to avoid logging too frequently
skipping logging after 37360 examples to avoid logging too frequently
train stats after 37376 examples: {'rewards_train/chosen': '0.63955', 'rewards_train/rejected': '-4.9111', 'rewards_train/margins': '5.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21082', 'examples_per_second': '5.6007', 'grad_norm': '4.7188', 'counters/examples': 37376, 'counters/updates': 2336}
skipping logging after 37392 examples to avoid logging too frequently
skipping logging after 37408 examples to avoid logging too frequently
skipping logging after 37424 examples to avoid logging too frequently
train stats after 37440 examples: {'rewards_train/chosen': '-0.050319', 'rewards_train/rejected': '-4.4455', 'rewards_train/margins': '4.4141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30194', 'examples_per_second': '4.4853', 'grad_norm': '5.375', 'counters/examples': 37440, 'counters/updates': 2340}
skipping logging after 37456 examples to avoid logging too frequently
skipping logging after 37472 examples to avoid logging too frequently
skipping logging after 37488 examples to avoid logging too frequently
train stats after 37504 examples: {'rewards_train/chosen': '0.54361', 'rewards_train/rejected': '-5.0971', 'rewards_train/margins': '5.9727', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28363', 'examples_per_second': '4.5146', 'grad_norm': '4.8125', 'counters/examples': 37504, 'counters/updates': 2344}
skipping logging after 37520 examples to avoid logging too frequently
skipping logging after 37536 examples to avoid logging too frequently
skipping logging after 37552 examples to avoid logging too frequently
train stats after 37568 examples: {'rewards_train/chosen': '0.57354', 'rewards_train/rejected': '-4.1713', 'rewards_train/margins': '4.8203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19635', 'examples_per_second': '5.9046', 'grad_norm': '4.7812', 'counters/examples': 37568, 'counters/updates': 2348}
skipping logging after 37584 examples to avoid logging too frequently
skipping logging after 37600 examples to avoid logging too frequently
skipping logging after 37616 examples to avoid logging too frequently
train stats after 37632 examples: {'rewards_train/chosen': '0.39192', 'rewards_train/rejected': '-6.2087', 'rewards_train/margins': '6.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2229', 'examples_per_second': '4.9068', 'grad_norm': '5.4375', 'counters/examples': 37632, 'counters/updates': 2352}
skipping logging after 37648 examples to avoid logging too frequently
skipping logging after 37664 examples to avoid logging too frequently
skipping logging after 37680 examples to avoid logging too frequently
train stats after 37696 examples: {'rewards_train/chosen': '0.55482', 'rewards_train/rejected': '-4.9876', 'rewards_train/margins': '5.5781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21808', 'examples_per_second': '5.7659', 'grad_norm': '5.2188', 'counters/examples': 37696, 'counters/updates': 2356}
skipping logging after 37712 examples to avoid logging too frequently
skipping logging after 37728 examples to avoid logging too frequently
skipping logging after 37744 examples to avoid logging too frequently
train stats after 37760 examples: {'rewards_train/chosen': '0.46219', 'rewards_train/rejected': '-5.2602', 'rewards_train/margins': '5.668', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28821', 'examples_per_second': '5.1519', 'grad_norm': '5.4062', 'counters/examples': 37760, 'counters/updates': 2360}
skipping logging after 37776 examples to avoid logging too frequently
skipping logging after 37792 examples to avoid logging too frequently
skipping logging after 37808 examples to avoid logging too frequently
train stats after 37824 examples: {'rewards_train/chosen': '0.46913', 'rewards_train/rejected': '-4.5534', 'rewards_train/margins': '4.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2489', 'examples_per_second': '5.9188', 'grad_norm': '5.25', 'counters/examples': 37824, 'counters/updates': 2364}
skipping logging after 37840 examples to avoid logging too frequently
skipping logging after 37856 examples to avoid logging too frequently
skipping logging after 37872 examples to avoid logging too frequently
train stats after 37888 examples: {'rewards_train/chosen': '0.43062', 'rewards_train/rejected': '-4.8397', 'rewards_train/margins': '5.4805', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26135', 'examples_per_second': '4.3366', 'grad_norm': '4.75', 'counters/examples': 37888, 'counters/updates': 2368}
skipping logging after 37904 examples to avoid logging too frequently
skipping logging after 37920 examples to avoid logging too frequently
skipping logging after 37936 examples to avoid logging too frequently
train stats after 37952 examples: {'rewards_train/chosen': '0.44693', 'rewards_train/rejected': '-5.2754', 'rewards_train/margins': '5.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26135', 'examples_per_second': '3.8453', 'grad_norm': '5.5312', 'counters/examples': 37952, 'counters/updates': 2372}
skipping logging after 37968 examples to avoid logging too frequently
skipping logging after 37984 examples to avoid logging too frequently
skipping logging after 38000 examples to avoid logging too frequently
train stats after 38016 examples: {'rewards_train/chosen': '0.75354', 'rewards_train/rejected': '-4.9814', 'rewards_train/margins': '5.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20667', 'examples_per_second': '5.5707', 'grad_norm': '5.1875', 'counters/examples': 38016, 'counters/updates': 2376}
skipping logging after 38032 examples to avoid logging too frequently
skipping logging after 38048 examples to avoid logging too frequently
skipping logging after 38064 examples to avoid logging too frequently
train stats after 38080 examples: {'rewards_train/chosen': '0.61212', 'rewards_train/rejected': '-6.8816', 'rewards_train/margins': '7.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18738', 'examples_per_second': '5.1817', 'grad_norm': '4.2812', 'counters/examples': 38080, 'counters/updates': 2380}
skipping logging after 38096 examples to avoid logging too frequently
skipping logging after 38112 examples to avoid logging too frequently
skipping logging after 38128 examples to avoid logging too frequently
train stats after 38144 examples: {'rewards_train/chosen': '0.052917', 'rewards_train/rejected': '-6.9367', 'rewards_train/margins': '6.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26239', 'examples_per_second': '5.1394', 'grad_norm': '5.125', 'counters/examples': 38144, 'counters/updates': 2384}
skipping logging after 38160 examples to avoid logging too frequently
skipping logging after 38176 examples to avoid logging too frequently
skipping logging after 38192 examples to avoid logging too frequently
train stats after 38208 examples: {'rewards_train/chosen': '0.49894', 'rewards_train/rejected': '-5.8495', 'rewards_train/margins': '6.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22272', 'examples_per_second': '4.0562', 'grad_norm': '5.5625', 'counters/examples': 38208, 'counters/updates': 2388}
skipping logging after 38224 examples to avoid logging too frequently
skipping logging after 38240 examples to avoid logging too frequently
skipping logging after 38256 examples to avoid logging too frequently
train stats after 38272 examples: {'rewards_train/chosen': '0.64267', 'rewards_train/rejected': '-3.9782', 'rewards_train/margins': '4.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24353', 'examples_per_second': '4.6582', 'grad_norm': '5.4688', 'counters/examples': 38272, 'counters/updates': 2392}
skipping logging after 38288 examples to avoid logging too frequently
skipping logging after 38304 examples to avoid logging too frequently
skipping logging after 38320 examples to avoid logging too frequently
train stats after 38336 examples: {'rewards_train/chosen': '0.44148', 'rewards_train/rejected': '-5.5542', 'rewards_train/margins': '5.9141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23975', 'examples_per_second': '5.2397', 'grad_norm': '5.7188', 'counters/examples': 38336, 'counters/updates': 2396}
skipping logging after 38352 examples to avoid logging too frequently
skipping logging after 38368 examples to avoid logging too frequently
skipping logging after 38384 examples to avoid logging too frequently
train stats after 38400 examples: {'rewards_train/chosen': '0.74541', 'rewards_train/rejected': '-5.0975', 'rewards_train/margins': '5.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24219', 'examples_per_second': '5.212', 'grad_norm': '4.7812', 'counters/examples': 38400, 'counters/updates': 2400}
skipping logging after 38416 examples to avoid logging too frequently
skipping logging after 38432 examples to avoid logging too frequently
skipping logging after 38448 examples to avoid logging too frequently
train stats after 38464 examples: {'rewards_train/chosen': '0.49468', 'rewards_train/rejected': '-6.0285', 'rewards_train/margins': '6.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23328', 'examples_per_second': '4.9436', 'grad_norm': '4.9062', 'counters/examples': 38464, 'counters/updates': 2404}
skipping logging after 38480 examples to avoid logging too frequently
skipping logging after 38496 examples to avoid logging too frequently
skipping logging after 38512 examples to avoid logging too frequently
train stats after 38528 examples: {'rewards_train/chosen': '0.19477', 'rewards_train/rejected': '-4.218', 'rewards_train/margins': '4.3398', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22595', 'examples_per_second': '6.1435', 'grad_norm': '4.25', 'counters/examples': 38528, 'counters/updates': 2408}
skipping logging after 38544 examples to avoid logging too frequently
skipping logging after 38560 examples to avoid logging too frequently
skipping logging after 38576 examples to avoid logging too frequently
train stats after 38592 examples: {'rewards_train/chosen': '0.38238', 'rewards_train/rejected': '-6.3647', 'rewards_train/margins': '6.6016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21234', 'examples_per_second': '5.0641', 'grad_norm': '5.25', 'counters/examples': 38592, 'counters/updates': 2412}
skipping logging after 38608 examples to avoid logging too frequently
skipping logging after 38624 examples to avoid logging too frequently
skipping logging after 38640 examples to avoid logging too frequently
train stats after 38656 examples: {'rewards_train/chosen': '0.63806', 'rewards_train/rejected': '-4.4536', 'rewards_train/margins': '5.0039', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21338', 'examples_per_second': '5.8595', 'grad_norm': '4.9375', 'counters/examples': 38656, 'counters/updates': 2416}
skipping logging after 38672 examples to avoid logging too frequently
skipping logging after 38688 examples to avoid logging too frequently
skipping logging after 38704 examples to avoid logging too frequently
train stats after 38720 examples: {'rewards_train/chosen': '0.32263', 'rewards_train/rejected': '-4.6943', 'rewards_train/margins': '4.9023', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23566', 'examples_per_second': '4.7058', 'grad_norm': '5.25', 'counters/examples': 38720, 'counters/updates': 2420}
skipping logging after 38736 examples to avoid logging too frequently
skipping logging after 38752 examples to avoid logging too frequently
skipping logging after 38768 examples to avoid logging too frequently
train stats after 38784 examples: {'rewards_train/chosen': '0.4638', 'rewards_train/rejected': '-5.2325', 'rewards_train/margins': '5.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24365', 'examples_per_second': '5.3144', 'grad_norm': '4.9062', 'counters/examples': 38784, 'counters/updates': 2424}
skipping logging after 38800 examples to avoid logging too frequently
skipping logging after 38816 examples to avoid logging too frequently
skipping logging after 38832 examples to avoid logging too frequently
train stats after 38848 examples: {'rewards_train/chosen': '0.65312', 'rewards_train/rejected': '-4.4316', 'rewards_train/margins': '5.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23602', 'examples_per_second': '4.9279', 'grad_norm': '6.5312', 'counters/examples': 38848, 'counters/updates': 2428}
skipping logging after 38864 examples to avoid logging too frequently
skipping logging after 38880 examples to avoid logging too frequently
skipping logging after 38896 examples to avoid logging too frequently
train stats after 38912 examples: {'rewards_train/chosen': '0.61721', 'rewards_train/rejected': '-5.9768', 'rewards_train/margins': '6.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.16919', 'examples_per_second': '5.2204', 'grad_norm': '4.9062', 'counters/examples': 38912, 'counters/updates': 2432}
skipping logging after 38928 examples to avoid logging too frequently
skipping logging after 38944 examples to avoid logging too frequently
skipping logging after 38960 examples to avoid logging too frequently
train stats after 38976 examples: {'rewards_train/chosen': '0.432', 'rewards_train/rejected': '-5.5572', 'rewards_train/margins': '5.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23108', 'examples_per_second': '4.9344', 'grad_norm': '5.875', 'counters/examples': 38976, 'counters/updates': 2436}
skipping logging after 38992 examples to avoid logging too frequently
skipping logging after 39008 examples to avoid logging too frequently
skipping logging after 39024 examples to avoid logging too frequently
train stats after 39040 examples: {'rewards_train/chosen': '0.26597', 'rewards_train/rejected': '-6.3608', 'rewards_train/margins': '6.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20856', 'examples_per_second': '5.2291', 'grad_norm': '4.5', 'counters/examples': 39040, 'counters/updates': 2440}
skipping logging after 39056 examples to avoid logging too frequently
skipping logging after 39072 examples to avoid logging too frequently
skipping logging after 39088 examples to avoid logging too frequently
train stats after 39104 examples: {'rewards_train/chosen': '0.30213', 'rewards_train/rejected': '-4.8175', 'rewards_train/margins': '5.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22644', 'examples_per_second': '5.5654', 'grad_norm': '6.0625', 'counters/examples': 39104, 'counters/updates': 2444}
skipping logging after 39120 examples to avoid logging too frequently
skipping logging after 39136 examples to avoid logging too frequently
skipping logging after 39152 examples to avoid logging too frequently
train stats after 39168 examples: {'rewards_train/chosen': '0.32019', 'rewards_train/rejected': '-5.9632', 'rewards_train/margins': '6.1172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22278', 'examples_per_second': '5.1606', 'grad_norm': '4.7812', 'counters/examples': 39168, 'counters/updates': 2448}
skipping logging after 39184 examples to avoid logging too frequently
skipping logging after 39200 examples to avoid logging too frequently
skipping logging after 39216 examples to avoid logging too frequently
train stats after 39232 examples: {'rewards_train/chosen': '0.31351', 'rewards_train/rejected': '-6.2708', 'rewards_train/margins': '6.7734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25006', 'examples_per_second': '5.1016', 'grad_norm': '5.2812', 'counters/examples': 39232, 'counters/updates': 2452}
skipping logging after 39248 examples to avoid logging too frequently
skipping logging after 39264 examples to avoid logging too frequently
skipping logging after 39280 examples to avoid logging too frequently
train stats after 39296 examples: {'rewards_train/chosen': '0.61123', 'rewards_train/rejected': '-5.3326', 'rewards_train/margins': '5.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22668', 'examples_per_second': '4.2099', 'grad_norm': '5.2188', 'counters/examples': 39296, 'counters/updates': 2456}
skipping logging after 39312 examples to avoid logging too frequently
skipping logging after 39328 examples to avoid logging too frequently
skipping logging after 39344 examples to avoid logging too frequently
train stats after 39360 examples: {'rewards_train/chosen': '0.70652', 'rewards_train/rejected': '-4.1932', 'rewards_train/margins': '5.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21472', 'examples_per_second': '5.6823', 'grad_norm': '4.7188', 'counters/examples': 39360, 'counters/updates': 2460}
skipping logging after 39376 examples to avoid logging too frequently
skipping logging after 39392 examples to avoid logging too frequently
skipping logging after 39408 examples to avoid logging too frequently
train stats after 39424 examples: {'rewards_train/chosen': '0.16039', 'rewards_train/rejected': '-5.6255', 'rewards_train/margins': '5.5391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23499', 'examples_per_second': '4.4138', 'grad_norm': '5', 'counters/examples': 39424, 'counters/updates': 2464}
skipping logging after 39440 examples to avoid logging too frequently
skipping logging after 39456 examples to avoid logging too frequently
skipping logging after 39472 examples to avoid logging too frequently
train stats after 39488 examples: {'rewards_train/chosen': '0.46611', 'rewards_train/rejected': '-5.9952', 'rewards_train/margins': '6.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26392', 'examples_per_second': '4.3615', 'grad_norm': '5.6562', 'counters/examples': 39488, 'counters/updates': 2468}
skipping logging after 39504 examples to avoid logging too frequently
skipping logging after 39520 examples to avoid logging too frequently
skipping logging after 39536 examples to avoid logging too frequently
train stats after 39552 examples: {'rewards_train/chosen': '0.59395', 'rewards_train/rejected': '-4.8988', 'rewards_train/margins': '5.6289', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2243', 'examples_per_second': '4.7694', 'grad_norm': '5.0938', 'counters/examples': 39552, 'counters/updates': 2472}
skipping logging after 39568 examples to avoid logging too frequently
skipping logging after 39584 examples to avoid logging too frequently
skipping logging after 39600 examples to avoid logging too frequently
train stats after 39616 examples: {'rewards_train/chosen': '0.84884', 'rewards_train/rejected': '-5.4305', 'rewards_train/margins': '6.2266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18347', 'examples_per_second': '5.0934', 'grad_norm': '4.3125', 'counters/examples': 39616, 'counters/updates': 2476}
skipping logging after 39632 examples to avoid logging too frequently
skipping logging after 39648 examples to avoid logging too frequently
skipping logging after 39664 examples to avoid logging too frequently
train stats after 39680 examples: {'rewards_train/chosen': '0.54758', 'rewards_train/rejected': '-5.0977', 'rewards_train/margins': '5.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22375', 'examples_per_second': '4.344', 'grad_norm': '5.9062', 'counters/examples': 39680, 'counters/updates': 2480}
skipping logging after 39696 examples to avoid logging too frequently
skipping logging after 39712 examples to avoid logging too frequently
skipping logging after 39728 examples to avoid logging too frequently
train stats after 39744 examples: {'rewards_train/chosen': '0.3845', 'rewards_train/rejected': '-5.6188', 'rewards_train/margins': '6.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23364', 'examples_per_second': '5.2187', 'grad_norm': '4.9375', 'counters/examples': 39744, 'counters/updates': 2484}
skipping logging after 39760 examples to avoid logging too frequently
skipping logging after 39776 examples to avoid logging too frequently
skipping logging after 39792 examples to avoid logging too frequently
train stats after 39808 examples: {'rewards_train/chosen': '0.24307', 'rewards_train/rejected': '-5.5447', 'rewards_train/margins': '5.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26782', 'examples_per_second': '5.5761', 'grad_norm': '4.9688', 'counters/examples': 39808, 'counters/updates': 2488}
skipping logging after 39824 examples to avoid logging too frequently
skipping logging after 39840 examples to avoid logging too frequently
skipping logging after 39856 examples to avoid logging too frequently
train stats after 39872 examples: {'rewards_train/chosen': '0.23426', 'rewards_train/rejected': '-4.4091', 'rewards_train/margins': '4.6641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24176', 'examples_per_second': '5.4745', 'grad_norm': '4.8125', 'counters/examples': 39872, 'counters/updates': 2492}
skipping logging after 39888 examples to avoid logging too frequently
skipping logging after 39904 examples to avoid logging too frequently
skipping logging after 39920 examples to avoid logging too frequently
train stats after 39936 examples: {'rewards_train/chosen': '0.53485', 'rewards_train/rejected': '-6.0721', 'rewards_train/margins': '6.6484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20056', 'examples_per_second': '5.2811', 'grad_norm': '4.3438', 'counters/examples': 39936, 'counters/updates': 2496}
skipping logging after 39952 examples to avoid logging too frequently
skipping logging after 39968 examples to avoid logging too frequently
skipping logging after 39984 examples to avoid logging too frequently
train stats after 40000 examples: {'rewards_train/chosen': '0.59239', 'rewards_train/rejected': '-5.6418', 'rewards_train/margins': '6.2109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17175', 'examples_per_second': '4.2846', 'grad_norm': '4.6875', 'counters/examples': 40000, 'counters/updates': 2500}
Running evaluation after 40000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.25s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.17s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:39,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.65s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.47s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:33,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.51s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:33,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.40s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:30,  1.47s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:21<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:12,  1.44s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:11,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.31s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.30s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.18s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]
eval after 40000: {'rewards_eval/chosen': '-5.3206', 'rewards_eval/rejected': '-5.7097', 'rewards_eval/margins': '0.27783', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.4642'}
skipping logging after 40016 examples to avoid logging too frequently
skipping logging after 40032 examples to avoid logging too frequently
skipping logging after 40048 examples to avoid logging too frequently
train stats after 40064 examples: {'rewards_train/chosen': '0.43156', 'rewards_train/rejected': '-4.8551', 'rewards_train/margins': '4.9375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24713', 'examples_per_second': '5.7381', 'grad_norm': '4.625', 'counters/examples': 40064, 'counters/updates': 2504}
skipping logging after 40080 examples to avoid logging too frequently
skipping logging after 40096 examples to avoid logging too frequently
skipping logging after 40112 examples to avoid logging too frequently
train stats after 40128 examples: {'rewards_train/chosen': '0.54898', 'rewards_train/rejected': '-5.8456', 'rewards_train/margins': '6.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19739', 'examples_per_second': '4.7241', 'grad_norm': '4.375', 'counters/examples': 40128, 'counters/updates': 2508}
skipping logging after 40144 examples to avoid logging too frequently
skipping logging after 40160 examples to avoid logging too frequently
skipping logging after 40176 examples to avoid logging too frequently
train stats after 40192 examples: {'rewards_train/chosen': '0.31808', 'rewards_train/rejected': '-5.9347', 'rewards_train/margins': '6.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22888', 'examples_per_second': '5.2881', 'grad_norm': '4.875', 'counters/examples': 40192, 'counters/updates': 2512}
skipping logging after 40208 examples to avoid logging too frequently
skipping logging after 40224 examples to avoid logging too frequently
skipping logging after 40240 examples to avoid logging too frequently
train stats after 40256 examples: {'rewards_train/chosen': '0.33797', 'rewards_train/rejected': '-5.2', 'rewards_train/margins': '5.668', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26471', 'examples_per_second': '4.7949', 'grad_norm': '5.6875', 'counters/examples': 40256, 'counters/updates': 2516}
skipping logging after 40272 examples to avoid logging too frequently
skipping logging after 40288 examples to avoid logging too frequently
skipping logging after 40304 examples to avoid logging too frequently
train stats after 40320 examples: {'rewards_train/chosen': '0.41056', 'rewards_train/rejected': '-6.1072', 'rewards_train/margins': '6.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24554', 'examples_per_second': '5.0922', 'grad_norm': '5.4688', 'counters/examples': 40320, 'counters/updates': 2520}
skipping logging after 40336 examples to avoid logging too frequently
skipping logging after 40352 examples to avoid logging too frequently
skipping logging after 40368 examples to avoid logging too frequently
train stats after 40384 examples: {'rewards_train/chosen': '0.75611', 'rewards_train/rejected': '-5.2342', 'rewards_train/margins': '6.1719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18762', 'examples_per_second': '5.4069', 'grad_norm': '5.0312', 'counters/examples': 40384, 'counters/updates': 2524}
skipping logging after 40400 examples to avoid logging too frequently
skipping logging after 40416 examples to avoid logging too frequently
skipping logging after 40432 examples to avoid logging too frequently
train stats after 40448 examples: {'rewards_train/chosen': '0.63177', 'rewards_train/rejected': '-4.5372', 'rewards_train/margins': '5.207', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17908', 'examples_per_second': '6.6472', 'grad_norm': '4.5', 'counters/examples': 40448, 'counters/updates': 2528}
skipping logging after 40464 examples to avoid logging too frequently
skipping logging after 40480 examples to avoid logging too frequently
skipping logging after 40496 examples to avoid logging too frequently
train stats after 40512 examples: {'rewards_train/chosen': '0.65433', 'rewards_train/rejected': '-6.5275', 'rewards_train/margins': '7.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17773', 'examples_per_second': '4.8425', 'grad_norm': '4.6875', 'counters/examples': 40512, 'counters/updates': 2532}
skipping logging after 40528 examples to avoid logging too frequently
skipping logging after 40544 examples to avoid logging too frequently
skipping logging after 40560 examples to avoid logging too frequently
train stats after 40576 examples: {'rewards_train/chosen': '-0.2237', 'rewards_train/rejected': '-4.9807', 'rewards_train/margins': '4.8711', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2395', 'examples_per_second': '6.2969', 'grad_norm': '5', 'counters/examples': 40576, 'counters/updates': 2536}
skipping logging after 40592 examples to avoid logging too frequently
skipping logging after 40608 examples to avoid logging too frequently
skipping logging after 40624 examples to avoid logging too frequently
train stats after 40640 examples: {'rewards_train/chosen': '0.40302', 'rewards_train/rejected': '-6.2358', 'rewards_train/margins': '6.9375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21698', 'examples_per_second': '4.9207', 'grad_norm': '4.625', 'counters/examples': 40640, 'counters/updates': 2540}
skipping logging after 40656 examples to avoid logging too frequently
skipping logging after 40672 examples to avoid logging too frequently
skipping logging after 40688 examples to avoid logging too frequently
train stats after 40704 examples: {'rewards_train/chosen': '0.46922', 'rewards_train/rejected': '-5.2442', 'rewards_train/margins': '5.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27783', 'examples_per_second': '4.4964', 'grad_norm': '6.7188', 'counters/examples': 40704, 'counters/updates': 2544}
skipping logging after 40720 examples to avoid logging too frequently
skipping logging after 40736 examples to avoid logging too frequently
skipping logging after 40752 examples to avoid logging too frequently
train stats after 40768 examples: {'rewards_train/chosen': '0.32747', 'rewards_train/rejected': '-4.8368', 'rewards_train/margins': '5.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26697', 'examples_per_second': '6.2793', 'grad_norm': '5.1562', 'counters/examples': 40768, 'counters/updates': 2548}
skipping logging after 40784 examples to avoid logging too frequently
skipping logging after 40800 examples to avoid logging too frequently
skipping logging after 40816 examples to avoid logging too frequently
train stats after 40832 examples: {'rewards_train/chosen': '0.6791', 'rewards_train/rejected': '-5.7544', 'rewards_train/margins': '6.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17548', 'examples_per_second': '5.0964', 'grad_norm': '4.2812', 'counters/examples': 40832, 'counters/updates': 2552}
skipping logging after 40848 examples to avoid logging too frequently
skipping logging after 40864 examples to avoid logging too frequently
skipping logging after 40880 examples to avoid logging too frequently
train stats after 40896 examples: {'rewards_train/chosen': '0.39328', 'rewards_train/rejected': '-5.2971', 'rewards_train/margins': '5.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25623', 'examples_per_second': '4.7852', 'grad_norm': '5.3438', 'counters/examples': 40896, 'counters/updates': 2556}
skipping logging after 40912 examples to avoid logging too frequently
skipping logging after 40928 examples to avoid logging too frequently
skipping logging after 40944 examples to avoid logging too frequently
train stats after 40960 examples: {'rewards_train/chosen': '0.073207', 'rewards_train/rejected': '-4.1818', 'rewards_train/margins': '4.0195', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28015', 'examples_per_second': '5.3347', 'grad_norm': '5.125', 'counters/examples': 40960, 'counters/updates': 2560}
skipping logging after 40976 examples to avoid logging too frequently
skipping logging after 40992 examples to avoid logging too frequently
skipping logging after 41008 examples to avoid logging too frequently
train stats after 41024 examples: {'rewards_train/chosen': '0.26398', 'rewards_train/rejected': '-6.5049', 'rewards_train/margins': '6.8984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21362', 'examples_per_second': '5.6952', 'grad_norm': '4.5938', 'counters/examples': 41024, 'counters/updates': 2564}
skipping logging after 41040 examples to avoid logging too frequently
skipping logging after 41056 examples to avoid logging too frequently
skipping logging after 41072 examples to avoid logging too frequently
train stats after 41088 examples: {'rewards_train/chosen': '0.37014', 'rewards_train/rejected': '-5.5846', 'rewards_train/margins': '6.1719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21155', 'examples_per_second': '4.7317', 'grad_norm': '5.125', 'counters/examples': 41088, 'counters/updates': 2568}
skipping logging after 41104 examples to avoid logging too frequently
skipping logging after 41120 examples to avoid logging too frequently
skipping logging after 41136 examples to avoid logging too frequently
train stats after 41152 examples: {'rewards_train/chosen': '0.6457', 'rewards_train/rejected': '-5.5717', 'rewards_train/margins': '6.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1983', 'examples_per_second': '4.6436', 'grad_norm': '4.8125', 'counters/examples': 41152, 'counters/updates': 2572}
skipping logging after 41168 examples to avoid logging too frequently
skipping logging after 41184 examples to avoid logging too frequently
skipping logging after 41200 examples to avoid logging too frequently
train stats after 41216 examples: {'rewards_train/chosen': '0.43152', 'rewards_train/rejected': '-5.4574', 'rewards_train/margins': '5.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2019', 'examples_per_second': '4.7427', 'grad_norm': '4.25', 'counters/examples': 41216, 'counters/updates': 2576}
skipping logging after 41232 examples to avoid logging too frequently
skipping logging after 41248 examples to avoid logging too frequently
skipping logging after 41264 examples to avoid logging too frequently
train stats after 41280 examples: {'rewards_train/chosen': '0.25685', 'rewards_train/rejected': '-4.9949', 'rewards_train/margins': '5.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25256', 'examples_per_second': '5.3887', 'grad_norm': '5.75', 'counters/examples': 41280, 'counters/updates': 2580}
skipping logging after 41296 examples to avoid logging too frequently
skipping logging after 41312 examples to avoid logging too frequently
skipping logging after 41328 examples to avoid logging too frequently
train stats after 41344 examples: {'rewards_train/chosen': '0.53881', 'rewards_train/rejected': '-6.2702', 'rewards_train/margins': '6.4961', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23114', 'examples_per_second': '5.8601', 'grad_norm': '4.7812', 'counters/examples': 41344, 'counters/updates': 2584}
skipping logging after 41360 examples to avoid logging too frequently
skipping logging after 41376 examples to avoid logging too frequently
skipping logging after 41392 examples to avoid logging too frequently
train stats after 41408 examples: {'rewards_train/chosen': '0.33902', 'rewards_train/rejected': '-4.6822', 'rewards_train/margins': '5.0859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25659', 'examples_per_second': '5.7565', 'grad_norm': '4.4375', 'counters/examples': 41408, 'counters/updates': 2588}
skipping logging after 41424 examples to avoid logging too frequently
skipping logging after 41440 examples to avoid logging too frequently
skipping logging after 41456 examples to avoid logging too frequently
train stats after 41472 examples: {'rewards_train/chosen': '0.294', 'rewards_train/rejected': '-4.7964', 'rewards_train/margins': '5.1133', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25061', 'examples_per_second': '4.1711', 'grad_norm': '4.9688', 'counters/examples': 41472, 'counters/updates': 2592}
skipping logging after 41488 examples to avoid logging too frequently
skipping logging after 41504 examples to avoid logging too frequently
skipping logging after 41520 examples to avoid logging too frequently
train stats after 41536 examples: {'rewards_train/chosen': '0.17236', 'rewards_train/rejected': '-5.1265', 'rewards_train/margins': '5.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22235', 'examples_per_second': '5.1711', 'grad_norm': '4.875', 'counters/examples': 41536, 'counters/updates': 2596}
skipping logging after 41552 examples to avoid logging too frequently
skipping logging after 41568 examples to avoid logging too frequently
skipping logging after 41584 examples to avoid logging too frequently
train stats after 41600 examples: {'rewards_train/chosen': '0.39511', 'rewards_train/rejected': '-6.3088', 'rewards_train/margins': '6.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21509', 'examples_per_second': '5.7101', 'grad_norm': '4.4375', 'counters/examples': 41600, 'counters/updates': 2600}
skipping logging after 41616 examples to avoid logging too frequently
skipping logging after 41632 examples to avoid logging too frequently
skipping logging after 41648 examples to avoid logging too frequently
train stats after 41664 examples: {'rewards_train/chosen': '0.34709', 'rewards_train/rejected': '-5.8632', 'rewards_train/margins': '6.3594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23694', 'examples_per_second': '4.2072', 'grad_norm': '5.0312', 'counters/examples': 41664, 'counters/updates': 2604}
skipping logging after 41680 examples to avoid logging too frequently
skipping logging after 41696 examples to avoid logging too frequently
skipping logging after 41712 examples to avoid logging too frequently
train stats after 41728 examples: {'rewards_train/chosen': '0.16868', 'rewards_train/rejected': '-5.3206', 'rewards_train/margins': '5.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21399', 'examples_per_second': '5.2658', 'grad_norm': '4.4688', 'counters/examples': 41728, 'counters/updates': 2608}
skipping logging after 41744 examples to avoid logging too frequently
skipping logging after 41760 examples to avoid logging too frequently
skipping logging after 41776 examples to avoid logging too frequently
train stats after 41792 examples: {'rewards_train/chosen': '0.3417', 'rewards_train/rejected': '-5.399', 'rewards_train/margins': '5.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23517', 'examples_per_second': '6.3809', 'grad_norm': '5.0625', 'counters/examples': 41792, 'counters/updates': 2612}
skipping logging after 41808 examples to avoid logging too frequently
skipping logging after 41824 examples to avoid logging too frequently
skipping logging after 41840 examples to avoid logging too frequently
train stats after 41856 examples: {'rewards_train/chosen': '0.083763', 'rewards_train/rejected': '-6.3142', 'rewards_train/margins': '6.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24915', 'examples_per_second': '6.5869', 'grad_norm': '5', 'counters/examples': 41856, 'counters/updates': 2616}
skipping logging after 41872 examples to avoid logging too frequently
skipping logging after 41888 examples to avoid logging too frequently
skipping logging after 41904 examples to avoid logging too frequently
train stats after 41920 examples: {'rewards_train/chosen': '0.63403', 'rewards_train/rejected': '-4.5917', 'rewards_train/margins': '5.1719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19904', 'examples_per_second': '5.268', 'grad_norm': '4.625', 'counters/examples': 41920, 'counters/updates': 2620}
skipping logging after 41936 examples to avoid logging too frequently
skipping logging after 41952 examples to avoid logging too frequently
skipping logging after 41968 examples to avoid logging too frequently
train stats after 41984 examples: {'rewards_train/chosen': '0.44775', 'rewards_train/rejected': '-5.0521', 'rewards_train/margins': '5.3672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24683', 'examples_per_second': '4.496', 'grad_norm': '5.9062', 'counters/examples': 41984, 'counters/updates': 2624}
skipping logging after 42000 examples to avoid logging too frequently
skipping logging after 42016 examples to avoid logging too frequently
skipping logging after 42032 examples to avoid logging too frequently
train stats after 42048 examples: {'rewards_train/chosen': '0.37077', 'rewards_train/rejected': '-5.0466', 'rewards_train/margins': '5.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23877', 'examples_per_second': '6.2552', 'grad_norm': '5.1875', 'counters/examples': 42048, 'counters/updates': 2628}
skipping logging after 42064 examples to avoid logging too frequently
skipping logging after 42080 examples to avoid logging too frequently
skipping logging after 42096 examples to avoid logging too frequently
train stats after 42112 examples: {'rewards_train/chosen': '0.59091', 'rewards_train/rejected': '-5.2706', 'rewards_train/margins': '5.4844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25848', 'examples_per_second': '4.8044', 'grad_norm': '5.9375', 'counters/examples': 42112, 'counters/updates': 2632}
skipping logging after 42128 examples to avoid logging too frequently
skipping logging after 42144 examples to avoid logging too frequently
skipping logging after 42160 examples to avoid logging too frequently
train stats after 42176 examples: {'rewards_train/chosen': '0.29404', 'rewards_train/rejected': '-4.9988', 'rewards_train/margins': '5.2461', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23633', 'examples_per_second': '5.2421', 'grad_norm': '4.4062', 'counters/examples': 42176, 'counters/updates': 2636}
skipping logging after 42192 examples to avoid logging too frequently
skipping logging after 42208 examples to avoid logging too frequently
skipping logging after 42224 examples to avoid logging too frequently
train stats after 42240 examples: {'rewards_train/chosen': '0.13904', 'rewards_train/rejected': '-5.5915', 'rewards_train/margins': '5.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22986', 'examples_per_second': '6.0012', 'grad_norm': '5.125', 'counters/examples': 42240, 'counters/updates': 2640}
skipping logging after 42256 examples to avoid logging too frequently
skipping logging after 42272 examples to avoid logging too frequently
skipping logging after 42288 examples to avoid logging too frequently
train stats after 42304 examples: {'rewards_train/chosen': '0.55533', 'rewards_train/rejected': '-5.3066', 'rewards_train/margins': '5.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25232', 'examples_per_second': '4.4057', 'grad_norm': '5.5', 'counters/examples': 42304, 'counters/updates': 2644}
skipping logging after 42320 examples to avoid logging too frequently
skipping logging after 42336 examples to avoid logging too frequently
skipping logging after 42352 examples to avoid logging too frequently
train stats after 42368 examples: {'rewards_train/chosen': '0.47632', 'rewards_train/rejected': '-6.4407', 'rewards_train/margins': '6.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24512', 'examples_per_second': '4.3462', 'grad_norm': '4.6875', 'counters/examples': 42368, 'counters/updates': 2648}
skipping logging after 42384 examples to avoid logging too frequently
skipping logging after 42400 examples to avoid logging too frequently
skipping logging after 42416 examples to avoid logging too frequently
train stats after 42432 examples: {'rewards_train/chosen': '0.5103', 'rewards_train/rejected': '-5.2524', 'rewards_train/margins': '5.9375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23907', 'examples_per_second': '4.49', 'grad_norm': '4.75', 'counters/examples': 42432, 'counters/updates': 2652}
skipping logging after 42448 examples to avoid logging too frequently
skipping logging after 42464 examples to avoid logging too frequently
skipping logging after 42480 examples to avoid logging too frequently
train stats after 42496 examples: {'rewards_train/chosen': '0.43894', 'rewards_train/rejected': '-6.2543', 'rewards_train/margins': '6.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24677', 'examples_per_second': '4.9913', 'grad_norm': '4.6875', 'counters/examples': 42496, 'counters/updates': 2656}
skipping logging after 42512 examples to avoid logging too frequently
skipping logging after 42528 examples to avoid logging too frequently
skipping logging after 42544 examples to avoid logging too frequently
train stats after 42560 examples: {'rewards_train/chosen': '0.55988', 'rewards_train/rejected': '-5.5625', 'rewards_train/margins': '6.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20862', 'examples_per_second': '4.7379', 'grad_norm': '4.5312', 'counters/examples': 42560, 'counters/updates': 2660}
skipping logging after 42576 examples to avoid logging too frequently
skipping logging after 42592 examples to avoid logging too frequently
skipping logging after 42608 examples to avoid logging too frequently
train stats after 42624 examples: {'rewards_train/chosen': '0.49443', 'rewards_train/rejected': '-5.5992', 'rewards_train/margins': '6.2422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23999', 'examples_per_second': '4.8128', 'grad_norm': '5.1562', 'counters/examples': 42624, 'counters/updates': 2664}
skipping logging after 42640 examples to avoid logging too frequently
skipping logging after 42656 examples to avoid logging too frequently
skipping logging after 42672 examples to avoid logging too frequently
train stats after 42688 examples: {'rewards_train/chosen': '0.45063', 'rewards_train/rejected': '-6.6001', 'rewards_train/margins': '7.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21906', 'examples_per_second': '6.3543', 'grad_norm': '4.3125', 'counters/examples': 42688, 'counters/updates': 2668}
skipping logging after 42704 examples to avoid logging too frequently
skipping logging after 42720 examples to avoid logging too frequently
skipping logging after 42736 examples to avoid logging too frequently
train stats after 42752 examples: {'rewards_train/chosen': '0.53446', 'rewards_train/rejected': '-3.9256', 'rewards_train/margins': '4.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27246', 'examples_per_second': '5.5074', 'grad_norm': '5.0312', 'counters/examples': 42752, 'counters/updates': 2672}
skipping logging after 42768 examples to avoid logging too frequently
skipping logging after 42784 examples to avoid logging too frequently
skipping logging after 42800 examples to avoid logging too frequently
train stats after 42816 examples: {'rewards_train/chosen': '0.61187', 'rewards_train/rejected': '-5.4548', 'rewards_train/margins': '6.0156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20172', 'examples_per_second': '4.7901', 'grad_norm': '4.5312', 'counters/examples': 42816, 'counters/updates': 2676}
skipping logging after 42832 examples to avoid logging too frequently
skipping logging after 42848 examples to avoid logging too frequently
skipping logging after 42864 examples to avoid logging too frequently
train stats after 42880 examples: {'rewards_train/chosen': '0.33433', 'rewards_train/rejected': '-6.3167', 'rewards_train/margins': '6.5938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26727', 'examples_per_second': '4.3099', 'grad_norm': '5.5938', 'counters/examples': 42880, 'counters/updates': 2680}
skipping logging after 42896 examples to avoid logging too frequently
skipping logging after 42912 examples to avoid logging too frequently
skipping logging after 42928 examples to avoid logging too frequently
train stats after 42944 examples: {'rewards_train/chosen': '0.5483', 'rewards_train/rejected': '-4.639', 'rewards_train/margins': '5.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23352', 'examples_per_second': '4.5788', 'grad_norm': '5.25', 'counters/examples': 42944, 'counters/updates': 2684}
skipping logging after 42960 examples to avoid logging too frequently
skipping logging after 42976 examples to avoid logging too frequently
skipping logging after 42992 examples to avoid logging too frequently
train stats after 43008 examples: {'rewards_train/chosen': '0.52236', 'rewards_train/rejected': '-4.5448', 'rewards_train/margins': '5.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18054', 'examples_per_second': '5.3883', 'grad_norm': '4.6562', 'counters/examples': 43008, 'counters/updates': 2688}
skipping logging after 43024 examples to avoid logging too frequently
skipping logging after 43040 examples to avoid logging too frequently
skipping logging after 43056 examples to avoid logging too frequently
train stats after 43072 examples: {'rewards_train/chosen': '0.28046', 'rewards_train/rejected': '-6.307', 'rewards_train/margins': '6.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22504', 'examples_per_second': '4.889', 'grad_norm': '6.4062', 'counters/examples': 43072, 'counters/updates': 2692}
skipping logging after 43088 examples to avoid logging too frequently
skipping logging after 43104 examples to avoid logging too frequently
skipping logging after 43120 examples to avoid logging too frequently
train stats after 43136 examples: {'rewards_train/chosen': '0.35783', 'rewards_train/rejected': '-5.9618', 'rewards_train/margins': '6.1875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24091', 'examples_per_second': '4.3853', 'grad_norm': '4.7812', 'counters/examples': 43136, 'counters/updates': 2696}
skipping logging after 43152 examples to avoid logging too frequently
skipping logging after 43168 examples to avoid logging too frequently
skipping logging after 43184 examples to avoid logging too frequently
train stats after 43200 examples: {'rewards_train/chosen': '0.44156', 'rewards_train/rejected': '-5.2237', 'rewards_train/margins': '5.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20831', 'examples_per_second': '5.5499', 'grad_norm': '4.5625', 'counters/examples': 43200, 'counters/updates': 2700}
skipping logging after 43216 examples to avoid logging too frequently
skipping logging after 43232 examples to avoid logging too frequently
skipping logging after 43248 examples to avoid logging too frequently
train stats after 43264 examples: {'rewards_train/chosen': '0.27376', 'rewards_train/rejected': '-4.8041', 'rewards_train/margins': '4.7734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25568', 'examples_per_second': '6.001', 'grad_norm': '4.5312', 'counters/examples': 43264, 'counters/updates': 2704}
skipping logging after 43280 examples to avoid logging too frequently
skipping logging after 43296 examples to avoid logging too frequently
skipping logging after 43312 examples to avoid logging too frequently
train stats after 43328 examples: {'rewards_train/chosen': '0.58188', 'rewards_train/rejected': '-5.328', 'rewards_train/margins': '5.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23016', 'examples_per_second': '5.3764', 'grad_norm': '4.9062', 'counters/examples': 43328, 'counters/updates': 2708}
skipping logging after 43344 examples to avoid logging too frequently
skipping logging after 43360 examples to avoid logging too frequently
skipping logging after 43376 examples to avoid logging too frequently
train stats after 43392 examples: {'rewards_train/chosen': '0.4347', 'rewards_train/rejected': '-4.9862', 'rewards_train/margins': '5.4883', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23553', 'examples_per_second': '5.74', 'grad_norm': '5.4062', 'counters/examples': 43392, 'counters/updates': 2712}
skipping logging after 43408 examples to avoid logging too frequently
skipping logging after 43424 examples to avoid logging too frequently
skipping logging after 43440 examples to avoid logging too frequently
train stats after 43456 examples: {'rewards_train/chosen': '0.52698', 'rewards_train/rejected': '-5.0311', 'rewards_train/margins': '5.4102', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23804', 'examples_per_second': '5.872', 'grad_norm': '5.2812', 'counters/examples': 43456, 'counters/updates': 2716}
skipping logging after 43472 examples to avoid logging too frequently
skipping logging after 43488 examples to avoid logging too frequently
skipping logging after 43504 examples to avoid logging too frequently
train stats after 43520 examples: {'rewards_train/chosen': '0.73282', 'rewards_train/rejected': '-5.4561', 'rewards_train/margins': '6.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17175', 'examples_per_second': '4.2358', 'grad_norm': '4.4375', 'counters/examples': 43520, 'counters/updates': 2720}
skipping logging after 43536 examples to avoid logging too frequently
skipping logging after 43552 examples to avoid logging too frequently
skipping logging after 43568 examples to avoid logging too frequently
train stats after 43584 examples: {'rewards_train/chosen': '0.49069', 'rewards_train/rejected': '-5.0156', 'rewards_train/margins': '5.6016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23456', 'examples_per_second': '4.8938', 'grad_norm': '4.9375', 'counters/examples': 43584, 'counters/updates': 2724}
skipping logging after 43600 examples to avoid logging too frequently
skipping logging after 43616 examples to avoid logging too frequently
skipping logging after 43632 examples to avoid logging too frequently
train stats after 43648 examples: {'rewards_train/chosen': '0.45428', 'rewards_train/rejected': '-5.886', 'rewards_train/margins': '6.3594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24799', 'examples_per_second': '4.8324', 'grad_norm': '4.9688', 'counters/examples': 43648, 'counters/updates': 2728}
skipping logging after 43664 examples to avoid logging too frequently
skipping logging after 43680 examples to avoid logging too frequently
skipping logging after 43696 examples to avoid logging too frequently
train stats after 43712 examples: {'rewards_train/chosen': '0.48062', 'rewards_train/rejected': '-5.2013', 'rewards_train/margins': '5.7578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22455', 'examples_per_second': '5.3589', 'grad_norm': '4.5625', 'counters/examples': 43712, 'counters/updates': 2732}
skipping logging after 43728 examples to avoid logging too frequently
skipping logging after 43744 examples to avoid logging too frequently
skipping logging after 43760 examples to avoid logging too frequently
train stats after 43776 examples: {'rewards_train/chosen': '0.46503', 'rewards_train/rejected': '-5.5544', 'rewards_train/margins': '5.8555', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23096', 'examples_per_second': '4.6045', 'grad_norm': '4.9688', 'counters/examples': 43776, 'counters/updates': 2736}
skipping logging after 43792 examples to avoid logging too frequently
skipping logging after 43808 examples to avoid logging too frequently
skipping logging after 43824 examples to avoid logging too frequently
train stats after 43840 examples: {'rewards_train/chosen': '0.28073', 'rewards_train/rejected': '-7.3766', 'rewards_train/margins': '7.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27643', 'examples_per_second': '4.4435', 'grad_norm': '5.5625', 'counters/examples': 43840, 'counters/updates': 2740}
skipping logging after 43856 examples to avoid logging too frequently
skipping logging after 43872 examples to avoid logging too frequently
skipping logging after 43888 examples to avoid logging too frequently
train stats after 43904 examples: {'rewards_train/chosen': '0.5477', 'rewards_train/rejected': '-4.293', 'rewards_train/margins': '4.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22742', 'examples_per_second': '5.4827', 'grad_norm': '5.1875', 'counters/examples': 43904, 'counters/updates': 2744}
skipping logging after 43920 examples to avoid logging too frequently
skipping logging after 43936 examples to avoid logging too frequently
skipping logging after 43952 examples to avoid logging too frequently
train stats after 43968 examples: {'rewards_train/chosen': '0.32199', 'rewards_train/rejected': '-6.0391', 'rewards_train/margins': '6.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2547', 'examples_per_second': '4.956', 'grad_norm': '5.3438', 'counters/examples': 43968, 'counters/updates': 2748}
skipping logging after 43984 examples to avoid logging too frequently
skipping logging after 44000 examples to avoid logging too frequently
Running evaluation after 44000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:50,  1.64s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:42,  1.41s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:36,  1.25s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.48s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.69s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.50s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:10<00:34,  1.38s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.53s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.49s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:31,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.41s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.39s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:20<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:21<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.28s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:28<00:12,  1.16s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:12,  1.51s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.42s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:38<00:05,  1.32s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.20s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:40<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:41<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]
eval after 44000: {'rewards_eval/chosen': '-4.9462', 'rewards_eval/rejected': '-5.2794', 'rewards_eval/margins': '0.23096', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46468'}
skipping logging after 44016 examples to avoid logging too frequently
train stats after 44032 examples: {'rewards_train/chosen': '0.37396', 'rewards_train/rejected': '-6.4187', 'rewards_train/margins': '6.8125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17432', 'examples_per_second': '5.3718', 'grad_norm': '5.2188', 'counters/examples': 44032, 'counters/updates': 2752}
skipping logging after 44048 examples to avoid logging too frequently
skipping logging after 44064 examples to avoid logging too frequently
skipping logging after 44080 examples to avoid logging too frequently
train stats after 44096 examples: {'rewards_train/chosen': '0.46765', 'rewards_train/rejected': '-5.0708', 'rewards_train/margins': '5.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2417', 'examples_per_second': '5.4416', 'grad_norm': '5.6875', 'counters/examples': 44096, 'counters/updates': 2756}
skipping logging after 44112 examples to avoid logging too frequently
skipping logging after 44128 examples to avoid logging too frequently
skipping logging after 44144 examples to avoid logging too frequently
train stats after 44160 examples: {'rewards_train/chosen': '0.48501', 'rewards_train/rejected': '-5.8317', 'rewards_train/margins': '6.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22748', 'examples_per_second': '5.0732', 'grad_norm': '4.3438', 'counters/examples': 44160, 'counters/updates': 2760}
skipping logging after 44176 examples to avoid logging too frequently
skipping logging after 44192 examples to avoid logging too frequently
skipping logging after 44208 examples to avoid logging too frequently
train stats after 44224 examples: {'rewards_train/chosen': '0.67115', 'rewards_train/rejected': '-5.5639', 'rewards_train/margins': '6.2266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19855', 'examples_per_second': '5.9186', 'grad_norm': '4.875', 'counters/examples': 44224, 'counters/updates': 2764}
skipping logging after 44240 examples to avoid logging too frequently
skipping logging after 44256 examples to avoid logging too frequently
skipping logging after 44272 examples to avoid logging too frequently
train stats after 44288 examples: {'rewards_train/chosen': '0.36409', 'rewards_train/rejected': '-5.9752', 'rewards_train/margins': '6.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24811', 'examples_per_second': '5.0872', 'grad_norm': '4.9688', 'counters/examples': 44288, 'counters/updates': 2768}
skipping logging after 44304 examples to avoid logging too frequently
skipping logging after 44320 examples to avoid logging too frequently
skipping logging after 44336 examples to avoid logging too frequently
train stats after 44352 examples: {'rewards_train/chosen': '0.68272', 'rewards_train/rejected': '-5.0906', 'rewards_train/margins': '5.9297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24194', 'examples_per_second': '4.533', 'grad_norm': '4.5938', 'counters/examples': 44352, 'counters/updates': 2772}
skipping logging after 44368 examples to avoid logging too frequently
skipping logging after 44384 examples to avoid logging too frequently
skipping logging after 44400 examples to avoid logging too frequently
train stats after 44416 examples: {'rewards_train/chosen': '0.17188', 'rewards_train/rejected': '-4.4689', 'rewards_train/margins': '4.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30115', 'examples_per_second': '5.7586', 'grad_norm': '5.1562', 'counters/examples': 44416, 'counters/updates': 2776}
skipping logging after 44432 examples to avoid logging too frequently
skipping logging after 44448 examples to avoid logging too frequently
skipping logging after 44464 examples to avoid logging too frequently
train stats after 44480 examples: {'rewards_train/chosen': '0.59353', 'rewards_train/rejected': '-6.4855', 'rewards_train/margins': '6.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19922', 'examples_per_second': '4.665', 'grad_norm': '4.1875', 'counters/examples': 44480, 'counters/updates': 2780}
skipping logging after 44496 examples to avoid logging too frequently
skipping logging after 44512 examples to avoid logging too frequently
skipping logging after 44528 examples to avoid logging too frequently
train stats after 44544 examples: {'rewards_train/chosen': '0.34977', 'rewards_train/rejected': '-4.6564', 'rewards_train/margins': '5.0234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25439', 'examples_per_second': '5.0533', 'grad_norm': '5.2812', 'counters/examples': 44544, 'counters/updates': 2784}
skipping logging after 44560 examples to avoid logging too frequently
skipping logging after 44576 examples to avoid logging too frequently
skipping logging after 44592 examples to avoid logging too frequently
train stats after 44608 examples: {'rewards_train/chosen': '0.28024', 'rewards_train/rejected': '-5.005', 'rewards_train/margins': '5.3477', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23926', 'examples_per_second': '5.2795', 'grad_norm': '4.6875', 'counters/examples': 44608, 'counters/updates': 2788}
skipping logging after 44624 examples to avoid logging too frequently
skipping logging after 44640 examples to avoid logging too frequently
skipping logging after 44656 examples to avoid logging too frequently
train stats after 44672 examples: {'rewards_train/chosen': '0.48206', 'rewards_train/rejected': '-5.6642', 'rewards_train/margins': '6.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20752', 'examples_per_second': '5.1434', 'grad_norm': '4.4375', 'counters/examples': 44672, 'counters/updates': 2792}
skipping logging after 44688 examples to avoid logging too frequently
skipping logging after 44704 examples to avoid logging too frequently
skipping logging after 44720 examples to avoid logging too frequently
train stats after 44736 examples: {'rewards_train/chosen': '0.46221', 'rewards_train/rejected': '-5.1642', 'rewards_train/margins': '5.6133', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21948', 'examples_per_second': '5.674', 'grad_norm': '5.7812', 'counters/examples': 44736, 'counters/updates': 2796}
skipping logging after 44752 examples to avoid logging too frequently
skipping logging after 44768 examples to avoid logging too frequently
skipping logging after 44784 examples to avoid logging too frequently
train stats after 44800 examples: {'rewards_train/chosen': '0.32131', 'rewards_train/rejected': '-4.6393', 'rewards_train/margins': '4.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26215', 'examples_per_second': '5.2048', 'grad_norm': '4.875', 'counters/examples': 44800, 'counters/updates': 2800}
skipping logging after 44816 examples to avoid logging too frequently
skipping logging after 44832 examples to avoid logging too frequently
skipping logging after 44848 examples to avoid logging too frequently
train stats after 44864 examples: {'rewards_train/chosen': '0.49463', 'rewards_train/rejected': '-6.6872', 'rewards_train/margins': '7.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23199', 'examples_per_second': '5.1404', 'grad_norm': '5.4062', 'counters/examples': 44864, 'counters/updates': 2804}
skipping logging after 44880 examples to avoid logging too frequently
skipping logging after 44896 examples to avoid logging too frequently
skipping logging after 44912 examples to avoid logging too frequently
train stats after 44928 examples: {'rewards_train/chosen': '0.60986', 'rewards_train/rejected': '-4.9297', 'rewards_train/margins': '5.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21094', 'examples_per_second': '5.4394', 'grad_norm': '5.25', 'counters/examples': 44928, 'counters/updates': 2808}
skipping logging after 44944 examples to avoid logging too frequently
skipping logging after 44960 examples to avoid logging too frequently
skipping logging after 44976 examples to avoid logging too frequently
train stats after 44992 examples: {'rewards_train/chosen': '0.34543', 'rewards_train/rejected': '-5.4054', 'rewards_train/margins': '5.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24219', 'examples_per_second': '4.6677', 'grad_norm': '4.6875', 'counters/examples': 44992, 'counters/updates': 2812}
skipping logging after 45008 examples to avoid logging too frequently
skipping logging after 45024 examples to avoid logging too frequently
skipping logging after 45040 examples to avoid logging too frequently
train stats after 45056 examples: {'rewards_train/chosen': '0.40884', 'rewards_train/rejected': '-5.9905', 'rewards_train/margins': '6.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23871', 'examples_per_second': '4.9468', 'grad_norm': '5.5625', 'counters/examples': 45056, 'counters/updates': 2816}
skipping logging after 45072 examples to avoid logging too frequently
skipping logging after 45088 examples to avoid logging too frequently
skipping logging after 45104 examples to avoid logging too frequently
train stats after 45120 examples: {'rewards_train/chosen': '0.77423', 'rewards_train/rejected': '-5.7917', 'rewards_train/margins': '6.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21252', 'examples_per_second': '5.8412', 'grad_norm': '5.2812', 'counters/examples': 45120, 'counters/updates': 2820}
skipping logging after 45136 examples to avoid logging too frequently
skipping logging after 45152 examples to avoid logging too frequently
skipping logging after 45168 examples to avoid logging too frequently
train stats after 45184 examples: {'rewards_train/chosen': '0.21194', 'rewards_train/rejected': '-5.1724', 'rewards_train/margins': '5.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26288', 'examples_per_second': '5.9034', 'grad_norm': '5.0312', 'counters/examples': 45184, 'counters/updates': 2824}
skipping logging after 45200 examples to avoid logging too frequently
skipping logging after 45216 examples to avoid logging too frequently
skipping logging after 45232 examples to avoid logging too frequently
train stats after 45248 examples: {'rewards_train/chosen': '0.10036', 'rewards_train/rejected': '-5.4509', 'rewards_train/margins': '5.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25726', 'examples_per_second': '6.1499', 'grad_norm': '5.0938', 'counters/examples': 45248, 'counters/updates': 2828}
skipping logging after 45264 examples to avoid logging too frequently
skipping logging after 45280 examples to avoid logging too frequently
skipping logging after 45296 examples to avoid logging too frequently
train stats after 45312 examples: {'rewards_train/chosen': '0.68042', 'rewards_train/rejected': '-4.8082', 'rewards_train/margins': '5.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22168', 'examples_per_second': '5.306', 'grad_norm': '4.3125', 'counters/examples': 45312, 'counters/updates': 2832}
skipping logging after 45328 examples to avoid logging too frequently
skipping logging after 45344 examples to avoid logging too frequently
skipping logging after 45360 examples to avoid logging too frequently
train stats after 45376 examples: {'rewards_train/chosen': '0.38526', 'rewards_train/rejected': '-5.4215', 'rewards_train/margins': '5.7812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21613', 'examples_per_second': '5.514', 'grad_norm': '4.1875', 'counters/examples': 45376, 'counters/updates': 2836}
skipping logging after 45392 examples to avoid logging too frequently
skipping logging after 45408 examples to avoid logging too frequently
skipping logging after 45424 examples to avoid logging too frequently
train stats after 45440 examples: {'rewards_train/chosen': '0.30843', 'rewards_train/rejected': '-5.1842', 'rewards_train/margins': '5.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21472', 'examples_per_second': '5.0506', 'grad_norm': '3.9062', 'counters/examples': 45440, 'counters/updates': 2840}
skipping logging after 45456 examples to avoid logging too frequently
skipping logging after 45472 examples to avoid logging too frequently
skipping logging after 45488 examples to avoid logging too frequently
train stats after 45504 examples: {'rewards_train/chosen': '0.589', 'rewards_train/rejected': '-4.8296', 'rewards_train/margins': '5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2547', 'examples_per_second': '4.6764', 'grad_norm': '6.2812', 'counters/examples': 45504, 'counters/updates': 2844}
skipping logging after 45520 examples to avoid logging too frequently
skipping logging after 45536 examples to avoid logging too frequently
skipping logging after 45552 examples to avoid logging too frequently
train stats after 45568 examples: {'rewards_train/chosen': '0.66291', 'rewards_train/rejected': '-6.6521', 'rewards_train/margins': '7.375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17719', 'examples_per_second': '4.7864', 'grad_norm': '4.6875', 'counters/examples': 45568, 'counters/updates': 2848}
skipping logging after 45584 examples to avoid logging too frequently
skipping logging after 45600 examples to avoid logging too frequently
skipping logging after 45616 examples to avoid logging too frequently
train stats after 45632 examples: {'rewards_train/chosen': '0.020275', 'rewards_train/rejected': '-6.8632', 'rewards_train/margins': '6.9141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22614', 'examples_per_second': '4.2568', 'grad_norm': '4.5312', 'counters/examples': 45632, 'counters/updates': 2852}
skipping logging after 45648 examples to avoid logging too frequently
skipping logging after 45664 examples to avoid logging too frequently
skipping logging after 45680 examples to avoid logging too frequently
train stats after 45696 examples: {'rewards_train/chosen': '0.5021', 'rewards_train/rejected': '-4.6295', 'rewards_train/margins': '4.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23108', 'examples_per_second': '6.1714', 'grad_norm': '4.4375', 'counters/examples': 45696, 'counters/updates': 2856}
skipping logging after 45712 examples to avoid logging too frequently
skipping logging after 45728 examples to avoid logging too frequently
skipping logging after 45744 examples to avoid logging too frequently
train stats after 45760 examples: {'rewards_train/chosen': '0.44271', 'rewards_train/rejected': '-4.9732', 'rewards_train/margins': '5.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21069', 'examples_per_second': '5.3892', 'grad_norm': '5.6875', 'counters/examples': 45760, 'counters/updates': 2860}
skipping logging after 45776 examples to avoid logging too frequently
skipping logging after 45792 examples to avoid logging too frequently
skipping logging after 45808 examples to avoid logging too frequently
train stats after 45824 examples: {'rewards_train/chosen': '0.26669', 'rewards_train/rejected': '-5.249', 'rewards_train/margins': '5.3086', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21045', 'examples_per_second': '4.8603', 'grad_norm': '5', 'counters/examples': 45824, 'counters/updates': 2864}
skipping logging after 45840 examples to avoid logging too frequently
skipping logging after 45856 examples to avoid logging too frequently
skipping logging after 45872 examples to avoid logging too frequently
train stats after 45888 examples: {'rewards_train/chosen': '0.3609', 'rewards_train/rejected': '-5.6481', 'rewards_train/margins': '6.1172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2168', 'examples_per_second': '5.9179', 'grad_norm': '4.375', 'counters/examples': 45888, 'counters/updates': 2868}
skipping logging after 45904 examples to avoid logging too frequently
skipping logging after 45920 examples to avoid logging too frequently
skipping logging after 45936 examples to avoid logging too frequently
train stats after 45952 examples: {'rewards_train/chosen': '0.55156', 'rewards_train/rejected': '-5.6591', 'rewards_train/margins': '6.1172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19464', 'examples_per_second': '5.0213', 'grad_norm': '5.5938', 'counters/examples': 45952, 'counters/updates': 2872}
skipping logging after 45968 examples to avoid logging too frequently
skipping logging after 45984 examples to avoid logging too frequently
skipping logging after 46000 examples to avoid logging too frequently
train stats after 46016 examples: {'rewards_train/chosen': '0.18464', 'rewards_train/rejected': '-6.0244', 'rewards_train/margins': '5.5781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26404', 'examples_per_second': '5.0386', 'grad_norm': '4.9688', 'counters/examples': 46016, 'counters/updates': 2876}
skipping logging after 46032 examples to avoid logging too frequently
skipping logging after 46048 examples to avoid logging too frequently
skipping logging after 46064 examples to avoid logging too frequently
train stats after 46080 examples: {'rewards_train/chosen': '0.38865', 'rewards_train/rejected': '-5.0828', 'rewards_train/margins': '5.2969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23297', 'examples_per_second': '5.3656', 'grad_norm': '5.3438', 'counters/examples': 46080, 'counters/updates': 2880}
skipping logging after 46096 examples to avoid logging too frequently
skipping logging after 46112 examples to avoid logging too frequently
skipping logging after 46128 examples to avoid logging too frequently
train stats after 46144 examples: {'rewards_train/chosen': '0.36187', 'rewards_train/rejected': '-5.6496', 'rewards_train/margins': '5.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22205', 'examples_per_second': '5.147', 'grad_norm': '5.2188', 'counters/examples': 46144, 'counters/updates': 2884}
skipping logging after 46160 examples to avoid logging too frequently
skipping logging after 46176 examples to avoid logging too frequently
skipping logging after 46192 examples to avoid logging too frequently
train stats after 46208 examples: {'rewards_train/chosen': '0.1915', 'rewards_train/rejected': '-5.0032', 'rewards_train/margins': '5.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21881', 'examples_per_second': '5.6535', 'grad_norm': '4.625', 'counters/examples': 46208, 'counters/updates': 2888}
skipping logging after 46224 examples to avoid logging too frequently
skipping logging after 46240 examples to avoid logging too frequently
skipping logging after 46256 examples to avoid logging too frequently
train stats after 46272 examples: {'rewards_train/chosen': '0.47466', 'rewards_train/rejected': '-6.0878', 'rewards_train/margins': '6.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21588', 'examples_per_second': '4.2593', 'grad_norm': '4.9688', 'counters/examples': 46272, 'counters/updates': 2892}
skipping logging after 46288 examples to avoid logging too frequently
skipping logging after 46304 examples to avoid logging too frequently
skipping logging after 46320 examples to avoid logging too frequently
train stats after 46336 examples: {'rewards_train/chosen': '0.44128', 'rewards_train/rejected': '-4.2449', 'rewards_train/margins': '4.8828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20782', 'examples_per_second': '6.6446', 'grad_norm': '4.8125', 'counters/examples': 46336, 'counters/updates': 2896}
skipping logging after 46352 examples to avoid logging too frequently
skipping logging after 46368 examples to avoid logging too frequently
skipping logging after 46384 examples to avoid logging too frequently
train stats after 46400 examples: {'rewards_train/chosen': '0.28566', 'rewards_train/rejected': '-4.962', 'rewards_train/margins': '5.2266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27759', 'examples_per_second': '5.2645', 'grad_norm': '4.8125', 'counters/examples': 46400, 'counters/updates': 2900}
skipping logging after 46416 examples to avoid logging too frequently
skipping logging after 46432 examples to avoid logging too frequently
skipping logging after 46448 examples to avoid logging too frequently
train stats after 46464 examples: {'rewards_train/chosen': '0.22271', 'rewards_train/rejected': '-4.7535', 'rewards_train/margins': '4.6016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27722', 'examples_per_second': '4.6947', 'grad_norm': '4.9375', 'counters/examples': 46464, 'counters/updates': 2904}
skipping logging after 46480 examples to avoid logging too frequently
skipping logging after 46496 examples to avoid logging too frequently
skipping logging after 46512 examples to avoid logging too frequently
train stats after 46528 examples: {'rewards_train/chosen': '0.3556', 'rewards_train/rejected': '-4.6576', 'rewards_train/margins': '5.0312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24994', 'examples_per_second': '5.5674', 'grad_norm': '5.375', 'counters/examples': 46528, 'counters/updates': 2908}
skipping logging after 46544 examples to avoid logging too frequently
skipping logging after 46560 examples to avoid logging too frequently
skipping logging after 46576 examples to avoid logging too frequently
train stats after 46592 examples: {'rewards_train/chosen': '0.32853', 'rewards_train/rejected': '-4.5361', 'rewards_train/margins': '4.9766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25952', 'examples_per_second': '4.5792', 'grad_norm': '5.6562', 'counters/examples': 46592, 'counters/updates': 2912}
skipping logging after 46608 examples to avoid logging too frequently
skipping logging after 46624 examples to avoid logging too frequently
skipping logging after 46640 examples to avoid logging too frequently
train stats after 46656 examples: {'rewards_train/chosen': '0.35625', 'rewards_train/rejected': '-6.4446', 'rewards_train/margins': '6.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23254', 'examples_per_second': '4.969', 'grad_norm': '5', 'counters/examples': 46656, 'counters/updates': 2916}
skipping logging after 46672 examples to avoid logging too frequently
skipping logging after 46688 examples to avoid logging too frequently
skipping logging after 46704 examples to avoid logging too frequently
train stats after 46720 examples: {'rewards_train/chosen': '0.40665', 'rewards_train/rejected': '-5.0465', 'rewards_train/margins': '5.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23291', 'examples_per_second': '4.5447', 'grad_norm': '5.1562', 'counters/examples': 46720, 'counters/updates': 2920}
skipping logging after 46736 examples to avoid logging too frequently
skipping logging after 46752 examples to avoid logging too frequently
skipping logging after 46768 examples to avoid logging too frequently
train stats after 46784 examples: {'rewards_train/chosen': '0.40719', 'rewards_train/rejected': '-3.6812', 'rewards_train/margins': '4.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.31091', 'examples_per_second': '5.5556', 'grad_norm': '5.7188', 'counters/examples': 46784, 'counters/updates': 2924}
skipping logging after 46800 examples to avoid logging too frequently
skipping logging after 46816 examples to avoid logging too frequently
skipping logging after 46832 examples to avoid logging too frequently
train stats after 46848 examples: {'rewards_train/chosen': '-0.051636', 'rewards_train/rejected': '-5.8352', 'rewards_train/margins': '5.8203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.33118', 'examples_per_second': '5.8619', 'grad_norm': '6.0625', 'counters/examples': 46848, 'counters/updates': 2928}
skipping logging after 46864 examples to avoid logging too frequently
skipping logging after 46880 examples to avoid logging too frequently
skipping logging after 46896 examples to avoid logging too frequently
train stats after 46912 examples: {'rewards_train/chosen': '0.69107', 'rewards_train/rejected': '-5.5158', 'rewards_train/margins': '6.2266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23358', 'examples_per_second': '5.3308', 'grad_norm': '4.4688', 'counters/examples': 46912, 'counters/updates': 2932}
skipping logging after 46928 examples to avoid logging too frequently
skipping logging after 46944 examples to avoid logging too frequently
skipping logging after 46960 examples to avoid logging too frequently
train stats after 46976 examples: {'rewards_train/chosen': '0.63105', 'rewards_train/rejected': '-4.8076', 'rewards_train/margins': '5.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18915', 'examples_per_second': '4.5316', 'grad_norm': '4.9062', 'counters/examples': 46976, 'counters/updates': 2936}
skipping logging after 46992 examples to avoid logging too frequently
skipping logging after 47008 examples to avoid logging too frequently
skipping logging after 47024 examples to avoid logging too frequently
train stats after 47040 examples: {'rewards_train/chosen': '0.34836', 'rewards_train/rejected': '-5.3743', 'rewards_train/margins': '5.8203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20325', 'examples_per_second': '5.1218', 'grad_norm': '5.0625', 'counters/examples': 47040, 'counters/updates': 2940}
skipping logging after 47056 examples to avoid logging too frequently
skipping logging after 47072 examples to avoid logging too frequently
skipping logging after 47088 examples to avoid logging too frequently
train stats after 47104 examples: {'rewards_train/chosen': '0.50016', 'rewards_train/rejected': '-3.9137', 'rewards_train/margins': '4.4414', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2326', 'examples_per_second': '5.0799', 'grad_norm': '5.5625', 'counters/examples': 47104, 'counters/updates': 2944}
skipping logging after 47120 examples to avoid logging too frequently
skipping logging after 47136 examples to avoid logging too frequently
skipping logging after 47152 examples to avoid logging too frequently
train stats after 47168 examples: {'rewards_train/chosen': '0.12262', 'rewards_train/rejected': '-5.0973', 'rewards_train/margins': '5.1719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2782', 'examples_per_second': '5.5417', 'grad_norm': '5.8125', 'counters/examples': 47168, 'counters/updates': 2948}
skipping logging after 47184 examples to avoid logging too frequently
skipping logging after 47200 examples to avoid logging too frequently
skipping logging after 47216 examples to avoid logging too frequently
train stats after 47232 examples: {'rewards_train/chosen': '0.44172', 'rewards_train/rejected': '-4.5344', 'rewards_train/margins': '4.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23224', 'examples_per_second': '4.9948', 'grad_norm': '4.8438', 'counters/examples': 47232, 'counters/updates': 2952}
skipping logging after 47248 examples to avoid logging too frequently
skipping logging after 47264 examples to avoid logging too frequently
skipping logging after 47280 examples to avoid logging too frequently
train stats after 47296 examples: {'rewards_train/chosen': '0.50778', 'rewards_train/rejected': '-4.6898', 'rewards_train/margins': '5.2344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21198', 'examples_per_second': '6.1212', 'grad_norm': '4.7812', 'counters/examples': 47296, 'counters/updates': 2956}
skipping logging after 47312 examples to avoid logging too frequently
skipping logging after 47328 examples to avoid logging too frequently
skipping logging after 47344 examples to avoid logging too frequently
train stats after 47360 examples: {'rewards_train/chosen': '0.22781', 'rewards_train/rejected': '-5.8461', 'rewards_train/margins': '6.0547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29211', 'examples_per_second': '4.5332', 'grad_norm': '5.375', 'counters/examples': 47360, 'counters/updates': 2960}
skipping logging after 47376 examples to avoid logging too frequently
skipping logging after 47392 examples to avoid logging too frequently
skipping logging after 47408 examples to avoid logging too frequently
train stats after 47424 examples: {'rewards_train/chosen': '0.58775', 'rewards_train/rejected': '-5.1619', 'rewards_train/margins': '5.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20233', 'examples_per_second': '5.1908', 'grad_norm': '5.4062', 'counters/examples': 47424, 'counters/updates': 2964}
skipping logging after 47440 examples to avoid logging too frequently
skipping logging after 47456 examples to avoid logging too frequently
skipping logging after 47472 examples to avoid logging too frequently
train stats after 47488 examples: {'rewards_train/chosen': '0.24496', 'rewards_train/rejected': '-5.6402', 'rewards_train/margins': '5.7812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23291', 'examples_per_second': '5.375', 'grad_norm': '4.4062', 'counters/examples': 47488, 'counters/updates': 2968}
skipping logging after 47504 examples to avoid logging too frequently
skipping logging after 47520 examples to avoid logging too frequently
skipping logging after 47536 examples to avoid logging too frequently
train stats after 47552 examples: {'rewards_train/chosen': '0.34258', 'rewards_train/rejected': '-5.7969', 'rewards_train/margins': '6.3203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20819', 'examples_per_second': '5.8194', 'grad_norm': '5.1875', 'counters/examples': 47552, 'counters/updates': 2972}
skipping logging after 47568 examples to avoid logging too frequently
skipping logging after 47584 examples to avoid logging too frequently
skipping logging after 47600 examples to avoid logging too frequently
train stats after 47616 examples: {'rewards_train/chosen': '0.48327', 'rewards_train/rejected': '-4.5437', 'rewards_train/margins': '5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2157', 'examples_per_second': '4.9699', 'grad_norm': '5.1562', 'counters/examples': 47616, 'counters/updates': 2976}
skipping logging after 47632 examples to avoid logging too frequently
skipping logging after 47648 examples to avoid logging too frequently
skipping logging after 47664 examples to avoid logging too frequently
train stats after 47680 examples: {'rewards_train/chosen': '-0.16273', 'rewards_train/rejected': '-4.8191', 'rewards_train/margins': '4.4961', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29626', 'examples_per_second': '5.9341', 'grad_norm': '6', 'counters/examples': 47680, 'counters/updates': 2980}
skipping logging after 47696 examples to avoid logging too frequently
skipping logging after 47712 examples to avoid logging too frequently
skipping logging after 47728 examples to avoid logging too frequently
train stats after 47744 examples: {'rewards_train/chosen': '0.42501', 'rewards_train/rejected': '-4.926', 'rewards_train/margins': '5.3164', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25916', 'examples_per_second': '5.5074', 'grad_norm': '6.5', 'counters/examples': 47744, 'counters/updates': 2984}
skipping logging after 47760 examples to avoid logging too frequently
skipping logging after 47776 examples to avoid logging too frequently
skipping logging after 47792 examples to avoid logging too frequently
train stats after 47808 examples: {'rewards_train/chosen': '0.55622', 'rewards_train/rejected': '-5.0168', 'rewards_train/margins': '5.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24774', 'examples_per_second': '5.0075', 'grad_norm': '5.4375', 'counters/examples': 47808, 'counters/updates': 2988}
skipping logging after 47824 examples to avoid logging too frequently
skipping logging after 47840 examples to avoid logging too frequently
skipping logging after 47856 examples to avoid logging too frequently
train stats after 47872 examples: {'rewards_train/chosen': '0.28758', 'rewards_train/rejected': '-5.7661', 'rewards_train/margins': '5.8477', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22943', 'examples_per_second': '5.9928', 'grad_norm': '4.3438', 'counters/examples': 47872, 'counters/updates': 2992}
skipping logging after 47888 examples to avoid logging too frequently
skipping logging after 47904 examples to avoid logging too frequently
skipping logging after 47920 examples to avoid logging too frequently
train stats after 47936 examples: {'rewards_train/chosen': '0.65457', 'rewards_train/rejected': '-5.5241', 'rewards_train/margins': '6.0117', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2453', 'examples_per_second': '4.1993', 'grad_norm': '5.4688', 'counters/examples': 47936, 'counters/updates': 2996}
skipping logging after 47952 examples to avoid logging too frequently
skipping logging after 47968 examples to avoid logging too frequently
skipping logging after 47984 examples to avoid logging too frequently
train stats after 48000 examples: {'rewards_train/chosen': '0.4235', 'rewards_train/rejected': '-4.6095', 'rewards_train/margins': '4.9961', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2453', 'examples_per_second': '5.9231', 'grad_norm': '5.375', 'counters/examples': 48000, 'counters/updates': 3000}
Running evaluation after 48000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.25s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.17s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:39,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.65s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.47s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:33,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.51s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:33,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.40s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:30,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:21<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:13,  1.44s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.31s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.18s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.12s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]
eval after 48000: {'rewards_eval/chosen': '-5.3606', 'rewards_eval/rejected': '-5.7701', 'rewards_eval/margins': '0.29346', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.4646'}
skipping logging after 48016 examples to avoid logging too frequently
skipping logging after 48032 examples to avoid logging too frequently
skipping logging after 48048 examples to avoid logging too frequently
train stats after 48064 examples: {'rewards_train/chosen': '0.57271', 'rewards_train/rejected': '-5.0312', 'rewards_train/margins': '5.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17554', 'examples_per_second': '4.5927', 'grad_norm': '5.0625', 'counters/examples': 48064, 'counters/updates': 3004}
skipping logging after 48080 examples to avoid logging too frequently
skipping logging after 48096 examples to avoid logging too frequently
skipping logging after 48112 examples to avoid logging too frequently
train stats after 48128 examples: {'rewards_train/chosen': '0.68312', 'rewards_train/rejected': '-5.6443', 'rewards_train/margins': '6.4141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17157', 'examples_per_second': '5.1892', 'grad_norm': '5', 'counters/examples': 48128, 'counters/updates': 3008}
skipping logging after 48144 examples to avoid logging too frequently
skipping logging after 48160 examples to avoid logging too frequently
skipping logging after 48176 examples to avoid logging too frequently
train stats after 48192 examples: {'rewards_train/chosen': '0.33776', 'rewards_train/rejected': '-5.7354', 'rewards_train/margins': '6.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2373', 'examples_per_second': '4.2182', 'grad_norm': '5.1875', 'counters/examples': 48192, 'counters/updates': 3012}
skipping logging after 48208 examples to avoid logging too frequently
skipping logging after 48224 examples to avoid logging too frequently
skipping logging after 48240 examples to avoid logging too frequently
train stats after 48256 examples: {'rewards_train/chosen': '0.55957', 'rewards_train/rejected': '-5.9064', 'rewards_train/margins': '6.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1908', 'examples_per_second': '5.3178', 'grad_norm': '4.5312', 'counters/examples': 48256, 'counters/updates': 3016}
skipping logging after 48272 examples to avoid logging too frequently
skipping logging after 48288 examples to avoid logging too frequently
skipping logging after 48304 examples to avoid logging too frequently
train stats after 48320 examples: {'rewards_train/chosen': '0.55626', 'rewards_train/rejected': '-5.5409', 'rewards_train/margins': '6.2969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22028', 'examples_per_second': '5.0043', 'grad_norm': '4.875', 'counters/examples': 48320, 'counters/updates': 3020}
skipping logging after 48336 examples to avoid logging too frequently
skipping logging after 48352 examples to avoid logging too frequently
skipping logging after 48368 examples to avoid logging too frequently
train stats after 48384 examples: {'rewards_train/chosen': '0.77899', 'rewards_train/rejected': '-5.3061', 'rewards_train/margins': '6.0859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19788', 'examples_per_second': '4.6858', 'grad_norm': '4.7188', 'counters/examples': 48384, 'counters/updates': 3024}
skipping logging after 48400 examples to avoid logging too frequently
skipping logging after 48416 examples to avoid logging too frequently
skipping logging after 48432 examples to avoid logging too frequently
train stats after 48448 examples: {'rewards_train/chosen': '0.34191', 'rewards_train/rejected': '-5.9733', 'rewards_train/margins': '6.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24683', 'examples_per_second': '5.5566', 'grad_norm': '5.3125', 'counters/examples': 48448, 'counters/updates': 3028}
skipping logging after 48464 examples to avoid logging too frequently
skipping logging after 48480 examples to avoid logging too frequently
skipping logging after 48496 examples to avoid logging too frequently
train stats after 48512 examples: {'rewards_train/chosen': '-0.15485', 'rewards_train/rejected': '-5.1585', 'rewards_train/margins': '4.8633', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28076', 'examples_per_second': '6.152', 'grad_norm': '4.5625', 'counters/examples': 48512, 'counters/updates': 3032}
skipping logging after 48528 examples to avoid logging too frequently
skipping logging after 48544 examples to avoid logging too frequently
skipping logging after 48560 examples to avoid logging too frequently
train stats after 48576 examples: {'rewards_train/chosen': '0.67707', 'rewards_train/rejected': '-4.8845', 'rewards_train/margins': '5.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20837', 'examples_per_second': '5.2522', 'grad_norm': '4.75', 'counters/examples': 48576, 'counters/updates': 3036}
skipping logging after 48592 examples to avoid logging too frequently
skipping logging after 48608 examples to avoid logging too frequently
skipping logging after 48624 examples to avoid logging too frequently
train stats after 48640 examples: {'rewards_train/chosen': '0.6764', 'rewards_train/rejected': '-5.5157', 'rewards_train/margins': '6.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19855', 'examples_per_second': '5.4115', 'grad_norm': '4.125', 'counters/examples': 48640, 'counters/updates': 3040}
skipping logging after 48656 examples to avoid logging too frequently
skipping logging after 48672 examples to avoid logging too frequently
skipping logging after 48688 examples to avoid logging too frequently
train stats after 48704 examples: {'rewards_train/chosen': '0.53669', 'rewards_train/rejected': '-5.5221', 'rewards_train/margins': '6.2109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22778', 'examples_per_second': '5.5421', 'grad_norm': '4.6562', 'counters/examples': 48704, 'counters/updates': 3044}
skipping logging after 48720 examples to avoid logging too frequently
skipping logging after 48736 examples to avoid logging too frequently
skipping logging after 48752 examples to avoid logging too frequently
train stats after 48768 examples: {'rewards_train/chosen': '0.42235', 'rewards_train/rejected': '-5.8142', 'rewards_train/margins': '6.375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22363', 'examples_per_second': '4.5036', 'grad_norm': '5.4062', 'counters/examples': 48768, 'counters/updates': 3048}
skipping logging after 48784 examples to avoid logging too frequently
skipping logging after 48800 examples to avoid logging too frequently
skipping logging after 48816 examples to avoid logging too frequently
train stats after 48832 examples: {'rewards_train/chosen': '0.38164', 'rewards_train/rejected': '-4.1338', 'rewards_train/margins': '4.5664', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2334', 'examples_per_second': '5.3141', 'grad_norm': '4.8438', 'counters/examples': 48832, 'counters/updates': 3052}
skipping logging after 48848 examples to avoid logging too frequently
skipping logging after 48864 examples to avoid logging too frequently
skipping logging after 48880 examples to avoid logging too frequently
train stats after 48896 examples: {'rewards_train/chosen': '0.68904', 'rewards_train/rejected': '-5.8776', 'rewards_train/margins': '6.7031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20953', 'examples_per_second': '4.6867', 'grad_norm': '5', 'counters/examples': 48896, 'counters/updates': 3056}
skipping logging after 48912 examples to avoid logging too frequently
skipping logging after 48928 examples to avoid logging too frequently
skipping logging after 48944 examples to avoid logging too frequently
train stats after 48960 examples: {'rewards_train/chosen': '0.51236', 'rewards_train/rejected': '-4.8388', 'rewards_train/margins': '5.3828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22992', 'examples_per_second': '5.6435', 'grad_norm': '5.0312', 'counters/examples': 48960, 'counters/updates': 3060}
skipping logging after 48976 examples to avoid logging too frequently
skipping logging after 48992 examples to avoid logging too frequently
skipping logging after 49008 examples to avoid logging too frequently
train stats after 49024 examples: {'rewards_train/chosen': '0.30613', 'rewards_train/rejected': '-6.4833', 'rewards_train/margins': '6.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23914', 'examples_per_second': '4.5742', 'grad_norm': '5.4375', 'counters/examples': 49024, 'counters/updates': 3064}
skipping logging after 49040 examples to avoid logging too frequently
skipping logging after 49056 examples to avoid logging too frequently
skipping logging after 49072 examples to avoid logging too frequently
train stats after 49088 examples: {'rewards_train/chosen': '0.34965', 'rewards_train/rejected': '-4.665', 'rewards_train/margins': '4.8945', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23053', 'examples_per_second': '6.3074', 'grad_norm': '4.5625', 'counters/examples': 49088, 'counters/updates': 3068}
skipping logging after 49104 examples to avoid logging too frequently
skipping logging after 49120 examples to avoid logging too frequently
skipping logging after 49136 examples to avoid logging too frequently
train stats after 49152 examples: {'rewards_train/chosen': '0.32093', 'rewards_train/rejected': '-5.4724', 'rewards_train/margins': '5.8828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21826', 'examples_per_second': '5.7336', 'grad_norm': '5.0625', 'counters/examples': 49152, 'counters/updates': 3072}
skipping logging after 49168 examples to avoid logging too frequently
skipping logging after 49184 examples to avoid logging too frequently
skipping logging after 49200 examples to avoid logging too frequently
train stats after 49216 examples: {'rewards_train/chosen': '0.50609', 'rewards_train/rejected': '-5.2553', 'rewards_train/margins': '5.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26617', 'examples_per_second': '4.9077', 'grad_norm': '5.5625', 'counters/examples': 49216, 'counters/updates': 3076}
skipping logging after 49232 examples to avoid logging too frequently
skipping logging after 49248 examples to avoid logging too frequently
skipping logging after 49264 examples to avoid logging too frequently
train stats after 49280 examples: {'rewards_train/chosen': '0.30387', 'rewards_train/rejected': '-4.8517', 'rewards_train/margins': '5.1406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24579', 'examples_per_second': '5.5394', 'grad_norm': '4.9062', 'counters/examples': 49280, 'counters/updates': 3080}
skipping logging after 49296 examples to avoid logging too frequently
skipping logging after 49312 examples to avoid logging too frequently
skipping logging after 49328 examples to avoid logging too frequently
train stats after 49344 examples: {'rewards_train/chosen': '0.40323', 'rewards_train/rejected': '-5.0268', 'rewards_train/margins': '5.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23236', 'examples_per_second': '5.5975', 'grad_norm': '4.125', 'counters/examples': 49344, 'counters/updates': 3084}
skipping logging after 49360 examples to avoid logging too frequently
skipping logging after 49376 examples to avoid logging too frequently
skipping logging after 49392 examples to avoid logging too frequently
train stats after 49408 examples: {'rewards_train/chosen': '0.44132', 'rewards_train/rejected': '-6.3263', 'rewards_train/margins': '6.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25439', 'examples_per_second': '4.3989', 'grad_norm': '4.6562', 'counters/examples': 49408, 'counters/updates': 3088}
skipping logging after 49424 examples to avoid logging too frequently
skipping logging after 49440 examples to avoid logging too frequently
skipping logging after 49456 examples to avoid logging too frequently
train stats after 49472 examples: {'rewards_train/chosen': '-0.10997', 'rewards_train/rejected': '-5.4893', 'rewards_train/margins': '5.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19476', 'examples_per_second': '5.0445', 'grad_norm': '4.5938', 'counters/examples': 49472, 'counters/updates': 3092}
skipping logging after 49488 examples to avoid logging too frequently
skipping logging after 49504 examples to avoid logging too frequently
skipping logging after 49520 examples to avoid logging too frequently
train stats after 49536 examples: {'rewards_train/chosen': '0.61296', 'rewards_train/rejected': '-4.5573', 'rewards_train/margins': '5.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21387', 'examples_per_second': '4.4942', 'grad_norm': '5', 'counters/examples': 49536, 'counters/updates': 3096}
skipping logging after 49552 examples to avoid logging too frequently
skipping logging after 49568 examples to avoid logging too frequently
skipping logging after 49584 examples to avoid logging too frequently
train stats after 49600 examples: {'rewards_train/chosen': '0.093962', 'rewards_train/rejected': '-6.4163', 'rewards_train/margins': '6.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24658', 'examples_per_second': '4.5386', 'grad_norm': '4.9688', 'counters/examples': 49600, 'counters/updates': 3100}
skipping logging after 49616 examples to avoid logging too frequently
skipping logging after 49632 examples to avoid logging too frequently
skipping logging after 49648 examples to avoid logging too frequently
train stats after 49664 examples: {'rewards_train/chosen': '0.31874', 'rewards_train/rejected': '-5.6789', 'rewards_train/margins': '5.8672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25763', 'examples_per_second': '4.783', 'grad_norm': '5.25', 'counters/examples': 49664, 'counters/updates': 3104}
skipping logging after 49680 examples to avoid logging too frequently
skipping logging after 49696 examples to avoid logging too frequently
skipping logging after 49712 examples to avoid logging too frequently
train stats after 49728 examples: {'rewards_train/chosen': '0.51485', 'rewards_train/rejected': '-6.2914', 'rewards_train/margins': '6.8672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24261', 'examples_per_second': '4.656', 'grad_norm': '4.625', 'counters/examples': 49728, 'counters/updates': 3108}
skipping logging after 49744 examples to avoid logging too frequently
skipping logging after 49760 examples to avoid logging too frequently
skipping logging after 49776 examples to avoid logging too frequently
train stats after 49792 examples: {'rewards_train/chosen': '0.56986', 'rewards_train/rejected': '-6.3389', 'rewards_train/margins': '6.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18317', 'examples_per_second': '4.3665', 'grad_norm': '4.5938', 'counters/examples': 49792, 'counters/updates': 3112}
skipping logging after 49808 examples to avoid logging too frequently
skipping logging after 49824 examples to avoid logging too frequently
skipping logging after 49840 examples to avoid logging too frequently
train stats after 49856 examples: {'rewards_train/chosen': '0.48632', 'rewards_train/rejected': '-5.8387', 'rewards_train/margins': '6.0156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24481', 'examples_per_second': '4.9097', 'grad_norm': '5.375', 'counters/examples': 49856, 'counters/updates': 3116}
skipping logging after 49872 examples to avoid logging too frequently
skipping logging after 49888 examples to avoid logging too frequently
skipping logging after 49904 examples to avoid logging too frequently
train stats after 49920 examples: {'rewards_train/chosen': '0.3867', 'rewards_train/rejected': '-6.4094', 'rewards_train/margins': '6.7422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21564', 'examples_per_second': '5.5364', 'grad_norm': '4.1562', 'counters/examples': 49920, 'counters/updates': 3120}
skipping logging after 49936 examples to avoid logging too frequently
skipping logging after 49952 examples to avoid logging too frequently
skipping logging after 49968 examples to avoid logging too frequently
train stats after 49984 examples: {'rewards_train/chosen': '0.72776', 'rewards_train/rejected': '-4.6266', 'rewards_train/margins': '5.1992', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18085', 'examples_per_second': '5.5885', 'grad_norm': '4.9688', 'counters/examples': 49984, 'counters/updates': 3124}
skipping logging after 50000 examples to avoid logging too frequently
skipping logging after 50016 examples to avoid logging too frequently
skipping logging after 50032 examples to avoid logging too frequently
train stats after 50048 examples: {'rewards_train/chosen': '0.43981', 'rewards_train/rejected': '-4.3049', 'rewards_train/margins': '4.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23877', 'examples_per_second': '5.4798', 'grad_norm': '5.2812', 'counters/examples': 50048, 'counters/updates': 3128}
skipping logging after 50064 examples to avoid logging too frequently
skipping logging after 50080 examples to avoid logging too frequently
skipping logging after 50096 examples to avoid logging too frequently
train stats after 50112 examples: {'rewards_train/chosen': '0.54378', 'rewards_train/rejected': '-5.6027', 'rewards_train/margins': '6.1016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.216', 'examples_per_second': '5.8299', 'grad_norm': '4.5625', 'counters/examples': 50112, 'counters/updates': 3132}
skipping logging after 50128 examples to avoid logging too frequently
skipping logging after 50144 examples to avoid logging too frequently
skipping logging after 50160 examples to avoid logging too frequently
train stats after 50176 examples: {'rewards_train/chosen': '0.60482', 'rewards_train/rejected': '-4.5686', 'rewards_train/margins': '5.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19391', 'examples_per_second': '4.7963', 'grad_norm': '4.5938', 'counters/examples': 50176, 'counters/updates': 3136}
skipping logging after 50192 examples to avoid logging too frequently
skipping logging after 50208 examples to avoid logging too frequently
skipping logging after 50224 examples to avoid logging too frequently
train stats after 50240 examples: {'rewards_train/chosen': '0.37054', 'rewards_train/rejected': '-5.1881', 'rewards_train/margins': '5.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23956', 'examples_per_second': '5.3005', 'grad_norm': '5.2812', 'counters/examples': 50240, 'counters/updates': 3140}
skipping logging after 50256 examples to avoid logging too frequently
skipping logging after 50272 examples to avoid logging too frequently
skipping logging after 50288 examples to avoid logging too frequently
train stats after 50304 examples: {'rewards_train/chosen': '0.51693', 'rewards_train/rejected': '-6.4389', 'rewards_train/margins': '6.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18292', 'examples_per_second': '5.2806', 'grad_norm': '4.3125', 'counters/examples': 50304, 'counters/updates': 3144}
skipping logging after 50320 examples to avoid logging too frequently
skipping logging after 50336 examples to avoid logging too frequently
skipping logging after 50352 examples to avoid logging too frequently
train stats after 50368 examples: {'rewards_train/chosen': '0.59582', 'rewards_train/rejected': '-6.6586', 'rewards_train/margins': '7.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21094', 'examples_per_second': '5.0123', 'grad_norm': '5.0312', 'counters/examples': 50368, 'counters/updates': 3148}
skipping logging after 50384 examples to avoid logging too frequently
skipping logging after 50400 examples to avoid logging too frequently
skipping logging after 50416 examples to avoid logging too frequently
train stats after 50432 examples: {'rewards_train/chosen': '0.47836', 'rewards_train/rejected': '-4.6061', 'rewards_train/margins': '4.9961', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19409', 'examples_per_second': '4.9409', 'grad_norm': '5.3438', 'counters/examples': 50432, 'counters/updates': 3152}
skipping logging after 50448 examples to avoid logging too frequently
skipping logging after 50464 examples to avoid logging too frequently
skipping logging after 50480 examples to avoid logging too frequently
train stats after 50496 examples: {'rewards_train/chosen': '0.23777', 'rewards_train/rejected': '-6.4515', 'rewards_train/margins': '6.6094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27673', 'examples_per_second': '5.0785', 'grad_norm': '6', 'counters/examples': 50496, 'counters/updates': 3156}
skipping logging after 50512 examples to avoid logging too frequently
skipping logging after 50528 examples to avoid logging too frequently
skipping logging after 50544 examples to avoid logging too frequently
train stats after 50560 examples: {'rewards_train/chosen': '0.57079', 'rewards_train/rejected': '-4.6646', 'rewards_train/margins': '5.207', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25146', 'examples_per_second': '5.3488', 'grad_norm': '4.9688', 'counters/examples': 50560, 'counters/updates': 3160}
skipping logging after 50576 examples to avoid logging too frequently
skipping logging after 50592 examples to avoid logging too frequently
skipping logging after 50608 examples to avoid logging too frequently
train stats after 50624 examples: {'rewards_train/chosen': '0.36927', 'rewards_train/rejected': '-3.8926', 'rewards_train/margins': '4.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26068', 'examples_per_second': '6.0606', 'grad_norm': '4.9375', 'counters/examples': 50624, 'counters/updates': 3164}
skipping logging after 50640 examples to avoid logging too frequently
skipping logging after 50656 examples to avoid logging too frequently
skipping logging after 50672 examples to avoid logging too frequently
train stats after 50688 examples: {'rewards_train/chosen': '0.23012', 'rewards_train/rejected': '-6.2321', 'rewards_train/margins': '6.7031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23175', 'examples_per_second': '4.7819', 'grad_norm': '5.4375', 'counters/examples': 50688, 'counters/updates': 3168}
skipping logging after 50704 examples to avoid logging too frequently
skipping logging after 50720 examples to avoid logging too frequently
skipping logging after 50736 examples to avoid logging too frequently
train stats after 50752 examples: {'rewards_train/chosen': '0.63446', 'rewards_train/rejected': '-5.3615', 'rewards_train/margins': '5.9375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23242', 'examples_per_second': '4.6583', 'grad_norm': '5.4688', 'counters/examples': 50752, 'counters/updates': 3172}
skipping logging after 50768 examples to avoid logging too frequently
skipping logging after 50784 examples to avoid logging too frequently
skipping logging after 50800 examples to avoid logging too frequently
train stats after 50816 examples: {'rewards_train/chosen': '0.40563', 'rewards_train/rejected': '-5.0332', 'rewards_train/margins': '5.5391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19379', 'examples_per_second': '4.83', 'grad_norm': '4.4375', 'counters/examples': 50816, 'counters/updates': 3176}
skipping logging after 50832 examples to avoid logging too frequently
skipping logging after 50848 examples to avoid logging too frequently
skipping logging after 50864 examples to avoid logging too frequently
train stats after 50880 examples: {'rewards_train/chosen': '0.48535', 'rewards_train/rejected': '-5.9961', 'rewards_train/margins': '6.3672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20673', 'examples_per_second': '4.7079', 'grad_norm': '5', 'counters/examples': 50880, 'counters/updates': 3180}
skipping logging after 50896 examples to avoid logging too frequently
skipping logging after 50912 examples to avoid logging too frequently
skipping logging after 50928 examples to avoid logging too frequently
train stats after 50944 examples: {'rewards_train/chosen': '0.59911', 'rewards_train/rejected': '-5.7351', 'rewards_train/margins': '6.3672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20557', 'examples_per_second': '4.8767', 'grad_norm': '4.9062', 'counters/examples': 50944, 'counters/updates': 3184}
skipping logging after 50960 examples to avoid logging too frequently
skipping logging after 50976 examples to avoid logging too frequently
skipping logging after 50992 examples to avoid logging too frequently
train stats after 51008 examples: {'rewards_train/chosen': '0.25404', 'rewards_train/rejected': '-5.4694', 'rewards_train/margins': '5.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23914', 'examples_per_second': '4.5973', 'grad_norm': '5.0938', 'counters/examples': 51008, 'counters/updates': 3188}
skipping logging after 51024 examples to avoid logging too frequently
skipping logging after 51040 examples to avoid logging too frequently
skipping logging after 51056 examples to avoid logging too frequently
train stats after 51072 examples: {'rewards_train/chosen': '0.38714', 'rewards_train/rejected': '-5.7743', 'rewards_train/margins': '6.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24908', 'examples_per_second': '6.5091', 'grad_norm': '4.7812', 'counters/examples': 51072, 'counters/updates': 3192}
skipping logging after 51088 examples to avoid logging too frequently
skipping logging after 51104 examples to avoid logging too frequently
skipping logging after 51120 examples to avoid logging too frequently
train stats after 51136 examples: {'rewards_train/chosen': '0.32644', 'rewards_train/rejected': '-5.3705', 'rewards_train/margins': '5.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24597', 'examples_per_second': '4.5903', 'grad_norm': '4.7812', 'counters/examples': 51136, 'counters/updates': 3196}
skipping logging after 51152 examples to avoid logging too frequently
skipping logging after 51168 examples to avoid logging too frequently
skipping logging after 51184 examples to avoid logging too frequently
train stats after 51200 examples: {'rewards_train/chosen': '0.84012', 'rewards_train/rejected': '-5.7766', 'rewards_train/margins': '6.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.15845', 'examples_per_second': '4.9019', 'grad_norm': '3.3594', 'counters/examples': 51200, 'counters/updates': 3200}
skipping logging after 51216 examples to avoid logging too frequently
skipping logging after 51232 examples to avoid logging too frequently
skipping logging after 51248 examples to avoid logging too frequently
train stats after 51264 examples: {'rewards_train/chosen': '0.16194', 'rewards_train/rejected': '-4.7164', 'rewards_train/margins': '4.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24719', 'examples_per_second': '4.8786', 'grad_norm': '5.1875', 'counters/examples': 51264, 'counters/updates': 3204}
skipping logging after 51280 examples to avoid logging too frequently
skipping logging after 51296 examples to avoid logging too frequently
skipping logging after 51312 examples to avoid logging too frequently
train stats after 51328 examples: {'rewards_train/chosen': '0.42902', 'rewards_train/rejected': '-4.6335', 'rewards_train/margins': '5.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23553', 'examples_per_second': '6.023', 'grad_norm': '4.9688', 'counters/examples': 51328, 'counters/updates': 3208}
skipping logging after 51344 examples to avoid logging too frequently
skipping logging after 51360 examples to avoid logging too frequently
skipping logging after 51376 examples to avoid logging too frequently
train stats after 51392 examples: {'rewards_train/chosen': '0.44539', 'rewards_train/rejected': '-6.2276', 'rewards_train/margins': '6.9375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26227', 'examples_per_second': '4.856', 'grad_norm': '5.5', 'counters/examples': 51392, 'counters/updates': 3212}
skipping logging after 51408 examples to avoid logging too frequently
skipping logging after 51424 examples to avoid logging too frequently
skipping logging after 51440 examples to avoid logging too frequently
train stats after 51456 examples: {'rewards_train/chosen': '0.35785', 'rewards_train/rejected': '-5.9029', 'rewards_train/margins': '6.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23004', 'examples_per_second': '4.494', 'grad_norm': '4.1875', 'counters/examples': 51456, 'counters/updates': 3216}
skipping logging after 51472 examples to avoid logging too frequently
skipping logging after 51488 examples to avoid logging too frequently
skipping logging after 51504 examples to avoid logging too frequently
train stats after 51520 examples: {'rewards_train/chosen': '0.43591', 'rewards_train/rejected': '-5.99', 'rewards_train/margins': '6.375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21765', 'examples_per_second': '4.198', 'grad_norm': '5.2812', 'counters/examples': 51520, 'counters/updates': 3220}
skipping logging after 51536 examples to avoid logging too frequently
skipping logging after 51552 examples to avoid logging too frequently
skipping logging after 51568 examples to avoid logging too frequently
train stats after 51584 examples: {'rewards_train/chosen': '0.38488', 'rewards_train/rejected': '-6.4885', 'rewards_train/margins': '6.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24762', 'examples_per_second': '4.5888', 'grad_norm': '4.7812', 'counters/examples': 51584, 'counters/updates': 3224}
skipping logging after 51600 examples to avoid logging too frequently
skipping logging after 51616 examples to avoid logging too frequently
skipping logging after 51632 examples to avoid logging too frequently
train stats after 51648 examples: {'rewards_train/chosen': '0.34844', 'rewards_train/rejected': '-4.6748', 'rewards_train/margins': '4.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28253', 'examples_per_second': '4.4561', 'grad_norm': '5.625', 'counters/examples': 51648, 'counters/updates': 3228}
skipping logging after 51664 examples to avoid logging too frequently
skipping logging after 51680 examples to avoid logging too frequently
skipping logging after 51696 examples to avoid logging too frequently
train stats after 51712 examples: {'rewards_train/chosen': '0.33258', 'rewards_train/rejected': '-3.7672', 'rewards_train/margins': '3.9297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26196', 'examples_per_second': '6.0959', 'grad_norm': '5.0312', 'counters/examples': 51712, 'counters/updates': 3232}
skipping logging after 51728 examples to avoid logging too frequently
skipping logging after 51744 examples to avoid logging too frequently
skipping logging after 51760 examples to avoid logging too frequently
train stats after 51776 examples: {'rewards_train/chosen': '0.18716', 'rewards_train/rejected': '-6.151', 'rewards_train/margins': '6.4844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28076', 'examples_per_second': '5.0078', 'grad_norm': '6.25', 'counters/examples': 51776, 'counters/updates': 3236}
skipping logging after 51792 examples to avoid logging too frequently
skipping logging after 51808 examples to avoid logging too frequently
skipping logging after 51824 examples to avoid logging too frequently
train stats after 51840 examples: {'rewards_train/chosen': '0.53693', 'rewards_train/rejected': '-4.9691', 'rewards_train/margins': '5.3789', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23151', 'examples_per_second': '4.4985', 'grad_norm': '4.75', 'counters/examples': 51840, 'counters/updates': 3240}
skipping logging after 51856 examples to avoid logging too frequently
skipping logging after 51872 examples to avoid logging too frequently
skipping logging after 51888 examples to avoid logging too frequently
train stats after 51904 examples: {'rewards_train/chosen': '0.38828', 'rewards_train/rejected': '-5.7979', 'rewards_train/margins': '6.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19641', 'examples_per_second': '6.242', 'grad_norm': '5.625', 'counters/examples': 51904, 'counters/updates': 3244}
skipping logging after 51920 examples to avoid logging too frequently
skipping logging after 51936 examples to avoid logging too frequently
skipping logging after 51952 examples to avoid logging too frequently
train stats after 51968 examples: {'rewards_train/chosen': '0.42364', 'rewards_train/rejected': '-5.2998', 'rewards_train/margins': '5.6016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24554', 'examples_per_second': '4.5151', 'grad_norm': '5.0938', 'counters/examples': 51968, 'counters/updates': 3248}
skipping logging after 51984 examples to avoid logging too frequently
skipping logging after 52000 examples to avoid logging too frequently
Running evaluation after 52000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:48,  1.57s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:41,  1.38s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:35,  1.24s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.47s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.68s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.49s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:10<00:34,  1.37s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.40s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:30,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.22s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:12,  1.44s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.31s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.18s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.31s/it]
eval after 52000: {'rewards_eval/chosen': '-4.9613', 'rewards_eval/rejected': '-5.3384', 'rewards_eval/margins': '0.26465', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46415'}
skipping logging after 52016 examples to avoid logging too frequently
train stats after 52032 examples: {'rewards_train/chosen': '0.36418', 'rewards_train/rejected': '-5.1884', 'rewards_train/margins': '5.3945', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25372', 'examples_per_second': '5.6284', 'grad_norm': '5.0625', 'counters/examples': 52032, 'counters/updates': 3252}
skipping logging after 52048 examples to avoid logging too frequently
skipping logging after 52064 examples to avoid logging too frequently
skipping logging after 52080 examples to avoid logging too frequently
train stats after 52096 examples: {'rewards_train/chosen': '0.20498', 'rewards_train/rejected': '-5.3135', 'rewards_train/margins': '5.1172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26038', 'examples_per_second': '4.7474', 'grad_norm': '4.5938', 'counters/examples': 52096, 'counters/updates': 3256}
skipping logging after 52112 examples to avoid logging too frequently
skipping logging after 52128 examples to avoid logging too frequently
skipping logging after 52144 examples to avoid logging too frequently
train stats after 52160 examples: {'rewards_train/chosen': '0.097429', 'rewards_train/rejected': '-5.2621', 'rewards_train/margins': '5.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28241', 'examples_per_second': '4.7922', 'grad_norm': '4.9688', 'counters/examples': 52160, 'counters/updates': 3260}
skipping logging after 52176 examples to avoid logging too frequently
skipping logging after 52192 examples to avoid logging too frequently
skipping logging after 52208 examples to avoid logging too frequently
train stats after 52224 examples: {'rewards_train/chosen': '0.46716', 'rewards_train/rejected': '-5.4578', 'rewards_train/margins': '5.9141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20337', 'examples_per_second': '4.8281', 'grad_norm': '4.5', 'counters/examples': 52224, 'counters/updates': 3264}
skipping logging after 52240 examples to avoid logging too frequently
skipping logging after 52256 examples to avoid logging too frequently
skipping logging after 52272 examples to avoid logging too frequently
train stats after 52288 examples: {'rewards_train/chosen': '0.71865', 'rewards_train/rejected': '-5.4088', 'rewards_train/margins': '6.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22693', 'examples_per_second': '4.8993', 'grad_norm': '5.0312', 'counters/examples': 52288, 'counters/updates': 3268}
skipping logging after 52304 examples to avoid logging too frequently
skipping logging after 52320 examples to avoid logging too frequently
skipping logging after 52336 examples to avoid logging too frequently
train stats after 52352 examples: {'rewards_train/chosen': '0.58131', 'rewards_train/rejected': '-5.8481', 'rewards_train/margins': '6.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22546', 'examples_per_second': '4.7207', 'grad_norm': '4.8125', 'counters/examples': 52352, 'counters/updates': 3272}
skipping logging after 52368 examples to avoid logging too frequently
skipping logging after 52384 examples to avoid logging too frequently
skipping logging after 52400 examples to avoid logging too frequently
train stats after 52416 examples: {'rewards_train/chosen': '0.45274', 'rewards_train/rejected': '-4.7238', 'rewards_train/margins': '5.1172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2536', 'examples_per_second': '4.1894', 'grad_norm': '5.375', 'counters/examples': 52416, 'counters/updates': 3276}
skipping logging after 52432 examples to avoid logging too frequently
skipping logging after 52448 examples to avoid logging too frequently
skipping logging after 52464 examples to avoid logging too frequently
train stats after 52480 examples: {'rewards_train/chosen': '0.42493', 'rewards_train/rejected': '-5.5988', 'rewards_train/margins': '5.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24463', 'examples_per_second': '5.1322', 'grad_norm': '4.1875', 'counters/examples': 52480, 'counters/updates': 3280}
skipping logging after 52496 examples to avoid logging too frequently
skipping logging after 52512 examples to avoid logging too frequently
skipping logging after 52528 examples to avoid logging too frequently
train stats after 52544 examples: {'rewards_train/chosen': '0.11495', 'rewards_train/rejected': '-5.1408', 'rewards_train/margins': '5.125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23822', 'examples_per_second': '4.9068', 'grad_norm': '5.0938', 'counters/examples': 52544, 'counters/updates': 3284}
skipping logging after 52560 examples to avoid logging too frequently
skipping logging after 52576 examples to avoid logging too frequently
skipping logging after 52592 examples to avoid logging too frequently
train stats after 52608 examples: {'rewards_train/chosen': '0.52295', 'rewards_train/rejected': '-6.7231', 'rewards_train/margins': '6.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17279', 'examples_per_second': '5.7641', 'grad_norm': '3.875', 'counters/examples': 52608, 'counters/updates': 3288}
skipping logging after 52624 examples to avoid logging too frequently
skipping logging after 52640 examples to avoid logging too frequently
skipping logging after 52656 examples to avoid logging too frequently
train stats after 52672 examples: {'rewards_train/chosen': '0.27859', 'rewards_train/rejected': '-5.254', 'rewards_train/margins': '5.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23279', 'examples_per_second': '5.8238', 'grad_norm': '5.25', 'counters/examples': 52672, 'counters/updates': 3292}
skipping logging after 52688 examples to avoid logging too frequently
skipping logging after 52704 examples to avoid logging too frequently
skipping logging after 52720 examples to avoid logging too frequently
train stats after 52736 examples: {'rewards_train/chosen': '0.63391', 'rewards_train/rejected': '-5.1341', 'rewards_train/margins': '5.8125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23792', 'examples_per_second': '4.9614', 'grad_norm': '4.5', 'counters/examples': 52736, 'counters/updates': 3296}
skipping logging after 52752 examples to avoid logging too frequently
skipping logging after 52768 examples to avoid logging too frequently
skipping logging after 52784 examples to avoid logging too frequently
train stats after 52800 examples: {'rewards_train/chosen': '0.39193', 'rewards_train/rejected': '-4.8278', 'rewards_train/margins': '5.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23944', 'examples_per_second': '5.4056', 'grad_norm': '4.8125', 'counters/examples': 52800, 'counters/updates': 3300}
skipping logging after 52816 examples to avoid logging too frequently
skipping logging after 52832 examples to avoid logging too frequently
skipping logging after 52848 examples to avoid logging too frequently
train stats after 52864 examples: {'rewards_train/chosen': '0.59755', 'rewards_train/rejected': '-5.2097', 'rewards_train/margins': '5.9141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26532', 'examples_per_second': '5.2327', 'grad_norm': '4.875', 'counters/examples': 52864, 'counters/updates': 3304}
skipping logging after 52880 examples to avoid logging too frequently
skipping logging after 52896 examples to avoid logging too frequently
skipping logging after 52912 examples to avoid logging too frequently
train stats after 52928 examples: {'rewards_train/chosen': '0.45671', 'rewards_train/rejected': '-5.1701', 'rewards_train/margins': '5.7031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28204', 'examples_per_second': '6.1538', 'grad_norm': '5.1562', 'counters/examples': 52928, 'counters/updates': 3308}
skipping logging after 52944 examples to avoid logging too frequently
skipping logging after 52960 examples to avoid logging too frequently
skipping logging after 52976 examples to avoid logging too frequently
train stats after 52992 examples: {'rewards_train/chosen': '0.56446', 'rewards_train/rejected': '-5.1506', 'rewards_train/margins': '5.9453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24768', 'examples_per_second': '6.2815', 'grad_norm': '5.5312', 'counters/examples': 52992, 'counters/updates': 3312}
skipping logging after 53008 examples to avoid logging too frequently
skipping logging after 53024 examples to avoid logging too frequently
skipping logging after 53040 examples to avoid logging too frequently
train stats after 53056 examples: {'rewards_train/chosen': '0.62277', 'rewards_train/rejected': '-4.5194', 'rewards_train/margins': '5.2344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20844', 'examples_per_second': '6.1291', 'grad_norm': '5.875', 'counters/examples': 53056, 'counters/updates': 3316}
skipping logging after 53072 examples to avoid logging too frequently
skipping logging after 53088 examples to avoid logging too frequently
skipping logging after 53104 examples to avoid logging too frequently
train stats after 53120 examples: {'rewards_train/chosen': '0.56154', 'rewards_train/rejected': '-5.5387', 'rewards_train/margins': '6.2969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21344', 'examples_per_second': '5.3359', 'grad_norm': '4.1875', 'counters/examples': 53120, 'counters/updates': 3320}
skipping logging after 53136 examples to avoid logging too frequently
skipping logging after 53152 examples to avoid logging too frequently
skipping logging after 53168 examples to avoid logging too frequently
train stats after 53184 examples: {'rewards_train/chosen': '0.65022', 'rewards_train/rejected': '-4.9499', 'rewards_train/margins': '5.7266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20587', 'examples_per_second': '4.751', 'grad_norm': '4.625', 'counters/examples': 53184, 'counters/updates': 3324}
skipping logging after 53200 examples to avoid logging too frequently
skipping logging after 53216 examples to avoid logging too frequently
skipping logging after 53232 examples to avoid logging too frequently
train stats after 53248 examples: {'rewards_train/chosen': '0.68963', 'rewards_train/rejected': '-5.3717', 'rewards_train/margins': '5.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20203', 'examples_per_second': '4.8324', 'grad_norm': '5.25', 'counters/examples': 53248, 'counters/updates': 3328}
skipping logging after 53264 examples to avoid logging too frequently
skipping logging after 53280 examples to avoid logging too frequently
skipping logging after 53296 examples to avoid logging too frequently
train stats after 53312 examples: {'rewards_train/chosen': '0.53451', 'rewards_train/rejected': '-7.0091', 'rewards_train/margins': '7.4531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24481', 'examples_per_second': '4.1983', 'grad_norm': '5.6562', 'counters/examples': 53312, 'counters/updates': 3332}
skipping logging after 53328 examples to avoid logging too frequently
skipping logging after 53344 examples to avoid logging too frequently
skipping logging after 53360 examples to avoid logging too frequently
train stats after 53376 examples: {'rewards_train/chosen': '0.48645', 'rewards_train/rejected': '-5.655', 'rewards_train/margins': '6.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24292', 'examples_per_second': '5.6488', 'grad_norm': '5.3125', 'counters/examples': 53376, 'counters/updates': 3336}
skipping logging after 53392 examples to avoid logging too frequently
skipping logging after 53408 examples to avoid logging too frequently
skipping logging after 53424 examples to avoid logging too frequently
train stats after 53440 examples: {'rewards_train/chosen': '0.51234', 'rewards_train/rejected': '-4.8369', 'rewards_train/margins': '5.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21887', 'examples_per_second': '5.4496', 'grad_norm': '4.5', 'counters/examples': 53440, 'counters/updates': 3340}
skipping logging after 53456 examples to avoid logging too frequently
skipping logging after 53472 examples to avoid logging too frequently
skipping logging after 53488 examples to avoid logging too frequently
train stats after 53504 examples: {'rewards_train/chosen': '0.38759', 'rewards_train/rejected': '-5.637', 'rewards_train/margins': '6.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23694', 'examples_per_second': '4.492', 'grad_norm': '5.7812', 'counters/examples': 53504, 'counters/updates': 3344}
skipping logging after 53520 examples to avoid logging too frequently
skipping logging after 53536 examples to avoid logging too frequently
skipping logging after 53552 examples to avoid logging too frequently
train stats after 53568 examples: {'rewards_train/chosen': '0.60752', 'rewards_train/rejected': '-5.0509', 'rewards_train/margins': '5.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19952', 'examples_per_second': '5.6657', 'grad_norm': '4.3438', 'counters/examples': 53568, 'counters/updates': 3348}
skipping logging after 53584 examples to avoid logging too frequently
skipping logging after 53600 examples to avoid logging too frequently
skipping logging after 53616 examples to avoid logging too frequently
train stats after 53632 examples: {'rewards_train/chosen': '0.34931', 'rewards_train/rejected': '-6.3385', 'rewards_train/margins': '6.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22992', 'examples_per_second': '5.0068', 'grad_norm': '4.6875', 'counters/examples': 53632, 'counters/updates': 3352}
skipping logging after 53648 examples to avoid logging too frequently
skipping logging after 53664 examples to avoid logging too frequently
skipping logging after 53680 examples to avoid logging too frequently
train stats after 53696 examples: {'rewards_train/chosen': '0.424', 'rewards_train/rejected': '-5.267', 'rewards_train/margins': '5.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21667', 'examples_per_second': '5.4392', 'grad_norm': '5.5625', 'counters/examples': 53696, 'counters/updates': 3356}
skipping logging after 53712 examples to avoid logging too frequently
skipping logging after 53728 examples to avoid logging too frequently
skipping logging after 53744 examples to avoid logging too frequently
train stats after 53760 examples: {'rewards_train/chosen': '0.41483', 'rewards_train/rejected': '-7.2225', 'rewards_train/margins': '7.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2431', 'examples_per_second': '4.1664', 'grad_norm': '4.875', 'counters/examples': 53760, 'counters/updates': 3360}
skipping logging after 53776 examples to avoid logging too frequently
skipping logging after 53792 examples to avoid logging too frequently
skipping logging after 53808 examples to avoid logging too frequently
train stats after 53824 examples: {'rewards_train/chosen': '0.34147', 'rewards_train/rejected': '-6.7318', 'rewards_train/margins': '6.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22638', 'examples_per_second': '6.1141', 'grad_norm': '4.9062', 'counters/examples': 53824, 'counters/updates': 3364}
skipping logging after 53840 examples to avoid logging too frequently
skipping logging after 53856 examples to avoid logging too frequently
skipping logging after 53872 examples to avoid logging too frequently
train stats after 53888 examples: {'rewards_train/chosen': '0.30896', 'rewards_train/rejected': '-5.5675', 'rewards_train/margins': '5.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28162', 'examples_per_second': '4.5343', 'grad_norm': '5.125', 'counters/examples': 53888, 'counters/updates': 3368}
skipping logging after 53904 examples to avoid logging too frequently
skipping logging after 53920 examples to avoid logging too frequently
skipping logging after 53936 examples to avoid logging too frequently
train stats after 53952 examples: {'rewards_train/chosen': '0.56382', 'rewards_train/rejected': '-5.44', 'rewards_train/margins': '6.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20508', 'examples_per_second': '5.2854', 'grad_norm': '4.2812', 'counters/examples': 53952, 'counters/updates': 3372}
skipping logging after 53968 examples to avoid logging too frequently
skipping logging after 53984 examples to avoid logging too frequently
skipping logging after 54000 examples to avoid logging too frequently
train stats after 54016 examples: {'rewards_train/chosen': '0.38523', 'rewards_train/rejected': '-6.3589', 'rewards_train/margins': '6.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24274', 'examples_per_second': '5.002', 'grad_norm': '4.5625', 'counters/examples': 54016, 'counters/updates': 3376}
skipping logging after 54032 examples to avoid logging too frequently
skipping logging after 54048 examples to avoid logging too frequently
skipping logging after 54064 examples to avoid logging too frequently
train stats after 54080 examples: {'rewards_train/chosen': '0.43371', 'rewards_train/rejected': '-5.2295', 'rewards_train/margins': '5.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22681', 'examples_per_second': '5.606', 'grad_norm': '5.3125', 'counters/examples': 54080, 'counters/updates': 3380}
skipping logging after 54096 examples to avoid logging too frequently
skipping logging after 54112 examples to avoid logging too frequently
skipping logging after 54128 examples to avoid logging too frequently
train stats after 54144 examples: {'rewards_train/chosen': '0.53476', 'rewards_train/rejected': '-6.6513', 'rewards_train/margins': '7.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21643', 'examples_per_second': '4.7081', 'grad_norm': '4.5938', 'counters/examples': 54144, 'counters/updates': 3384}
skipping logging after 54160 examples to avoid logging too frequently
skipping logging after 54176 examples to avoid logging too frequently
skipping logging after 54192 examples to avoid logging too frequently
train stats after 54208 examples: {'rewards_train/chosen': '0.61498', 'rewards_train/rejected': '-5.884', 'rewards_train/margins': '6.8672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18823', 'examples_per_second': '5.8706', 'grad_norm': '4.2188', 'counters/examples': 54208, 'counters/updates': 3388}
skipping logging after 54224 examples to avoid logging too frequently
skipping logging after 54240 examples to avoid logging too frequently
skipping logging after 54256 examples to avoid logging too frequently
train stats after 54272 examples: {'rewards_train/chosen': '0.48613', 'rewards_train/rejected': '-4.0744', 'rewards_train/margins': '4.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25', 'examples_per_second': '6.1294', 'grad_norm': '4.9688', 'counters/examples': 54272, 'counters/updates': 3392}
skipping logging after 54288 examples to avoid logging too frequently
skipping logging after 54304 examples to avoid logging too frequently
skipping logging after 54320 examples to avoid logging too frequently
train stats after 54336 examples: {'rewards_train/chosen': '0.31521', 'rewards_train/rejected': '-7.1947', 'rewards_train/margins': '7.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28174', 'examples_per_second': '5.5059', 'grad_norm': '5.7812', 'counters/examples': 54336, 'counters/updates': 3396}
skipping logging after 54352 examples to avoid logging too frequently
skipping logging after 54368 examples to avoid logging too frequently
skipping logging after 54384 examples to avoid logging too frequently
train stats after 54400 examples: {'rewards_train/chosen': '0.44855', 'rewards_train/rejected': '-5.7866', 'rewards_train/margins': '5.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26343', 'examples_per_second': '5.1249', 'grad_norm': '4.9688', 'counters/examples': 54400, 'counters/updates': 3400}
skipping logging after 54416 examples to avoid logging too frequently
skipping logging after 54432 examples to avoid logging too frequently
skipping logging after 54448 examples to avoid logging too frequently
train stats after 54464 examples: {'rewards_train/chosen': '0.065874', 'rewards_train/rejected': '-4.1775', 'rewards_train/margins': '4.125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21698', 'examples_per_second': '5.9115', 'grad_norm': '4.2812', 'counters/examples': 54464, 'counters/updates': 3404}
skipping logging after 54480 examples to avoid logging too frequently
skipping logging after 54496 examples to avoid logging too frequently
skipping logging after 54512 examples to avoid logging too frequently
train stats after 54528 examples: {'rewards_train/chosen': '0.27013', 'rewards_train/rejected': '-4.591', 'rewards_train/margins': '4.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25085', 'examples_per_second': '4.9713', 'grad_norm': '4.9688', 'counters/examples': 54528, 'counters/updates': 3408}
skipping logging after 54544 examples to avoid logging too frequently
skipping logging after 54560 examples to avoid logging too frequently
skipping logging after 54576 examples to avoid logging too frequently
train stats after 54592 examples: {'rewards_train/chosen': '0.21428', 'rewards_train/rejected': '-6.0725', 'rewards_train/margins': '6.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26355', 'examples_per_second': '4.3447', 'grad_norm': '4.7812', 'counters/examples': 54592, 'counters/updates': 3412}
skipping logging after 54608 examples to avoid logging too frequently
skipping logging after 54624 examples to avoid logging too frequently
skipping logging after 54640 examples to avoid logging too frequently
train stats after 54656 examples: {'rewards_train/chosen': '0.27746', 'rewards_train/rejected': '-5.1209', 'rewards_train/margins': '5.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2218', 'examples_per_second': '4.436', 'grad_norm': '5.4375', 'counters/examples': 54656, 'counters/updates': 3416}
skipping logging after 54672 examples to avoid logging too frequently
skipping logging after 54688 examples to avoid logging too frequently
skipping logging after 54704 examples to avoid logging too frequently
train stats after 54720 examples: {'rewards_train/chosen': '0.48347', 'rewards_train/rejected': '-5.8278', 'rewards_train/margins': '6.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24622', 'examples_per_second': '5.3754', 'grad_norm': '5.625', 'counters/examples': 54720, 'counters/updates': 3420}
skipping logging after 54736 examples to avoid logging too frequently
skipping logging after 54752 examples to avoid logging too frequently
skipping logging after 54768 examples to avoid logging too frequently
train stats after 54784 examples: {'rewards_train/chosen': '0.33407', 'rewards_train/rejected': '-4.8876', 'rewards_train/margins': '5.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23926', 'examples_per_second': '5.1069', 'grad_norm': '5.2188', 'counters/examples': 54784, 'counters/updates': 3424}
skipping logging after 54800 examples to avoid logging too frequently
skipping logging after 54816 examples to avoid logging too frequently
skipping logging after 54832 examples to avoid logging too frequently
train stats after 54848 examples: {'rewards_train/chosen': '0.46236', 'rewards_train/rejected': '-5.2364', 'rewards_train/margins': '5.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25409', 'examples_per_second': '4.434', 'grad_norm': '4.5938', 'counters/examples': 54848, 'counters/updates': 3428}
skipping logging after 54864 examples to avoid logging too frequently
skipping logging after 54880 examples to avoid logging too frequently
skipping logging after 54896 examples to avoid logging too frequently
train stats after 54912 examples: {'rewards_train/chosen': '0.84456', 'rewards_train/rejected': '-4.3394', 'rewards_train/margins': '5.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20624', 'examples_per_second': '4.5861', 'grad_norm': '4.9375', 'counters/examples': 54912, 'counters/updates': 3432}
skipping logging after 54928 examples to avoid logging too frequently
skipping logging after 54944 examples to avoid logging too frequently
skipping logging after 54960 examples to avoid logging too frequently
train stats after 54976 examples: {'rewards_train/chosen': '0.34914', 'rewards_train/rejected': '-4.7955', 'rewards_train/margins': '5.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25055', 'examples_per_second': '5.4179', 'grad_norm': '5.9062', 'counters/examples': 54976, 'counters/updates': 3436}
skipping logging after 54992 examples to avoid logging too frequently
skipping logging after 55008 examples to avoid logging too frequently
skipping logging after 55024 examples to avoid logging too frequently
train stats after 55040 examples: {'rewards_train/chosen': '0.085794', 'rewards_train/rejected': '-5.0563', 'rewards_train/margins': '5.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23389', 'examples_per_second': '5.7364', 'grad_norm': '4', 'counters/examples': 55040, 'counters/updates': 3440}
skipping logging after 55056 examples to avoid logging too frequently
skipping logging after 55072 examples to avoid logging too frequently
skipping logging after 55088 examples to avoid logging too frequently
train stats after 55104 examples: {'rewards_train/chosen': '0.49149', 'rewards_train/rejected': '-6.2496', 'rewards_train/margins': '6.6094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19928', 'examples_per_second': '5.2743', 'grad_norm': '4.625', 'counters/examples': 55104, 'counters/updates': 3444}
skipping logging after 55120 examples to avoid logging too frequently
skipping logging after 55136 examples to avoid logging too frequently
skipping logging after 55152 examples to avoid logging too frequently
train stats after 55168 examples: {'rewards_train/chosen': '0.49181', 'rewards_train/rejected': '-6.2821', 'rewards_train/margins': '6.6641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24084', 'examples_per_second': '5.6566', 'grad_norm': '5.9062', 'counters/examples': 55168, 'counters/updates': 3448}
skipping logging after 55184 examples to avoid logging too frequently
skipping logging after 55200 examples to avoid logging too frequently
skipping logging after 55216 examples to avoid logging too frequently
train stats after 55232 examples: {'rewards_train/chosen': '0.52564', 'rewards_train/rejected': '-4.6397', 'rewards_train/margins': '5.1758', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24725', 'examples_per_second': '5.1575', 'grad_norm': '4.7812', 'counters/examples': 55232, 'counters/updates': 3452}
skipping logging after 55248 examples to avoid logging too frequently
skipping logging after 55264 examples to avoid logging too frequently
skipping logging after 55280 examples to avoid logging too frequently
train stats after 55296 examples: {'rewards_train/chosen': '0.31027', 'rewards_train/rejected': '-5.0769', 'rewards_train/margins': '5.3672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25446', 'examples_per_second': '5.3155', 'grad_norm': '4.6875', 'counters/examples': 55296, 'counters/updates': 3456}
skipping logging after 55312 examples to avoid logging too frequently
skipping logging after 55328 examples to avoid logging too frequently
skipping logging after 55344 examples to avoid logging too frequently
train stats after 55360 examples: {'rewards_train/chosen': '0.38913', 'rewards_train/rejected': '-5.7525', 'rewards_train/margins': '6.168', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2489', 'examples_per_second': '4.3419', 'grad_norm': '4.4688', 'counters/examples': 55360, 'counters/updates': 3460}
skipping logging after 55376 examples to avoid logging too frequently
skipping logging after 55392 examples to avoid logging too frequently
skipping logging after 55408 examples to avoid logging too frequently
train stats after 55424 examples: {'rewards_train/chosen': '0.67062', 'rewards_train/rejected': '-4.7631', 'rewards_train/margins': '5.3828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22559', 'examples_per_second': '4.9169', 'grad_norm': '3.6875', 'counters/examples': 55424, 'counters/updates': 3464}
skipping logging after 55440 examples to avoid logging too frequently
skipping logging after 55456 examples to avoid logging too frequently
skipping logging after 55472 examples to avoid logging too frequently
train stats after 55488 examples: {'rewards_train/chosen': '0.59969', 'rewards_train/rejected': '-5.7232', 'rewards_train/margins': '6.3281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18579', 'examples_per_second': '5.6785', 'grad_norm': '4.25', 'counters/examples': 55488, 'counters/updates': 3468}
skipping logging after 55504 examples to avoid logging too frequently
skipping logging after 55520 examples to avoid logging too frequently
skipping logging after 55536 examples to avoid logging too frequently
train stats after 55552 examples: {'rewards_train/chosen': '0.80216', 'rewards_train/rejected': '-5.6491', 'rewards_train/margins': '6.168', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19299', 'examples_per_second': '4.7037', 'grad_norm': '4.6562', 'counters/examples': 55552, 'counters/updates': 3472}
skipping logging after 55568 examples to avoid logging too frequently
skipping logging after 55584 examples to avoid logging too frequently
skipping logging after 55600 examples to avoid logging too frequently
train stats after 55616 examples: {'rewards_train/chosen': '0.30798', 'rewards_train/rejected': '-5.4152', 'rewards_train/margins': '5.7031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23694', 'examples_per_second': '5.2912', 'grad_norm': '5.1562', 'counters/examples': 55616, 'counters/updates': 3476}
skipping logging after 55632 examples to avoid logging too frequently
skipping logging after 55648 examples to avoid logging too frequently
skipping logging after 55664 examples to avoid logging too frequently
train stats after 55680 examples: {'rewards_train/chosen': '0.35524', 'rewards_train/rejected': '-6.4681', 'rewards_train/margins': '6.7422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24072', 'examples_per_second': '5.3374', 'grad_norm': '4.5312', 'counters/examples': 55680, 'counters/updates': 3480}
skipping logging after 55696 examples to avoid logging too frequently
skipping logging after 55712 examples to avoid logging too frequently
skipping logging after 55728 examples to avoid logging too frequently
train stats after 55744 examples: {'rewards_train/chosen': '0.46673', 'rewards_train/rejected': '-5.5184', 'rewards_train/margins': '6.125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20898', 'examples_per_second': '5.317', 'grad_norm': '4.5625', 'counters/examples': 55744, 'counters/updates': 3484}
skipping logging after 55760 examples to avoid logging too frequently
skipping logging after 55776 examples to avoid logging too frequently
skipping logging after 55792 examples to avoid logging too frequently
train stats after 55808 examples: {'rewards_train/chosen': '-0.27712', 'rewards_train/rejected': '-6.2273', 'rewards_train/margins': '5.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2132', 'examples_per_second': '5.6716', 'grad_norm': '4.8438', 'counters/examples': 55808, 'counters/updates': 3488}
skipping logging after 55824 examples to avoid logging too frequently
skipping logging after 55840 examples to avoid logging too frequently
skipping logging after 55856 examples to avoid logging too frequently
train stats after 55872 examples: {'rewards_train/chosen': '0.49118', 'rewards_train/rejected': '-6.4788', 'rewards_train/margins': '7.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20874', 'examples_per_second': '5.4595', 'grad_norm': '5.8125', 'counters/examples': 55872, 'counters/updates': 3492}
skipping logging after 55888 examples to avoid logging too frequently
skipping logging after 55904 examples to avoid logging too frequently
skipping logging after 55920 examples to avoid logging too frequently
train stats after 55936 examples: {'rewards_train/chosen': '0.43116', 'rewards_train/rejected': '-4.6492', 'rewards_train/margins': '5.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2793', 'examples_per_second': '4.8238', 'grad_norm': '6.1562', 'counters/examples': 55936, 'counters/updates': 3496}
skipping logging after 55952 examples to avoid logging too frequently
skipping logging after 55968 examples to avoid logging too frequently
skipping logging after 55984 examples to avoid logging too frequently
train stats after 56000 examples: {'rewards_train/chosen': '0.42507', 'rewards_train/rejected': '-5.2658', 'rewards_train/margins': '5.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2149', 'examples_per_second': '5.7914', 'grad_norm': '5', 'counters/examples': 56000, 'counters/updates': 3500}
Running evaluation after 56000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.26s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.26s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.17s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:40,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.65s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.47s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:33,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.51s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.41s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.28s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.31s/it]
eval after 56000: {'rewards_eval/chosen': '-4.9757', 'rewards_eval/rejected': '-5.4113', 'rewards_eval/margins': '0.32959', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46328'}
skipping logging after 56016 examples to avoid logging too frequently
skipping logging after 56032 examples to avoid logging too frequently
skipping logging after 56048 examples to avoid logging too frequently
train stats after 56064 examples: {'rewards_train/chosen': '0.29195', 'rewards_train/rejected': '-5.9191', 'rewards_train/margins': '6.4531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25775', 'examples_per_second': '3.9955', 'grad_norm': '4.6875', 'counters/examples': 56064, 'counters/updates': 3504}
skipping logging after 56080 examples to avoid logging too frequently
skipping logging after 56096 examples to avoid logging too frequently
skipping logging after 56112 examples to avoid logging too frequently
train stats after 56128 examples: {'rewards_train/chosen': '0.42866', 'rewards_train/rejected': '-5.3027', 'rewards_train/margins': '5.8086', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23865', 'examples_per_second': '5.1992', 'grad_norm': '4.875', 'counters/examples': 56128, 'counters/updates': 3508}
skipping logging after 56144 examples to avoid logging too frequently
skipping logging after 56160 examples to avoid logging too frequently
skipping logging after 56176 examples to avoid logging too frequently
train stats after 56192 examples: {'rewards_train/chosen': '0.50472', 'rewards_train/rejected': '-5.8055', 'rewards_train/margins': '6.4844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23474', 'examples_per_second': '4.5052', 'grad_norm': '5.0625', 'counters/examples': 56192, 'counters/updates': 3512}
skipping logging after 56208 examples to avoid logging too frequently
skipping logging after 56224 examples to avoid logging too frequently
skipping logging after 56240 examples to avoid logging too frequently
train stats after 56256 examples: {'rewards_train/chosen': '0.60791', 'rewards_train/rejected': '-6.0861', 'rewards_train/margins': '6.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23792', 'examples_per_second': '5.6035', 'grad_norm': '5.5', 'counters/examples': 56256, 'counters/updates': 3516}
skipping logging after 56272 examples to avoid logging too frequently
skipping logging after 56288 examples to avoid logging too frequently
skipping logging after 56304 examples to avoid logging too frequently
train stats after 56320 examples: {'rewards_train/chosen': '0.0018751', 'rewards_train/rejected': '-6.8103', 'rewards_train/margins': '6.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29053', 'examples_per_second': '5.3881', 'grad_norm': '4.6875', 'counters/examples': 56320, 'counters/updates': 3520}
skipping logging after 56336 examples to avoid logging too frequently
skipping logging after 56352 examples to avoid logging too frequently
skipping logging after 56368 examples to avoid logging too frequently
train stats after 56384 examples: {'rewards_train/chosen': '0.54294', 'rewards_train/rejected': '-5.7404', 'rewards_train/margins': '6.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21661', 'examples_per_second': '5.3004', 'grad_norm': '4.5', 'counters/examples': 56384, 'counters/updates': 3524}
skipping logging after 56400 examples to avoid logging too frequently
skipping logging after 56416 examples to avoid logging too frequently
skipping logging after 56432 examples to avoid logging too frequently
train stats after 56448 examples: {'rewards_train/chosen': '0.46074', 'rewards_train/rejected': '-4.7355', 'rewards_train/margins': '5.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22394', 'examples_per_second': '5.5834', 'grad_norm': '5.3125', 'counters/examples': 56448, 'counters/updates': 3528}
skipping logging after 56464 examples to avoid logging too frequently
skipping logging after 56480 examples to avoid logging too frequently
skipping logging after 56496 examples to avoid logging too frequently
train stats after 56512 examples: {'rewards_train/chosen': '0.58776', 'rewards_train/rejected': '-6.7637', 'rewards_train/margins': '7.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24109', 'examples_per_second': '5.0919', 'grad_norm': '4.5938', 'counters/examples': 56512, 'counters/updates': 3532}
skipping logging after 56528 examples to avoid logging too frequently
skipping logging after 56544 examples to avoid logging too frequently
skipping logging after 56560 examples to avoid logging too frequently
train stats after 56576 examples: {'rewards_train/chosen': '0.25006', 'rewards_train/rejected': '-7.2472', 'rewards_train/margins': '7.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24097', 'examples_per_second': '4.3272', 'grad_norm': '5.3438', 'counters/examples': 56576, 'counters/updates': 3536}
skipping logging after 56592 examples to avoid logging too frequently
skipping logging after 56608 examples to avoid logging too frequently
skipping logging after 56624 examples to avoid logging too frequently
train stats after 56640 examples: {'rewards_train/chosen': '0.095454', 'rewards_train/rejected': '-5.16', 'rewards_train/margins': '5.3203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28546', 'examples_per_second': '5.2201', 'grad_norm': '5.4375', 'counters/examples': 56640, 'counters/updates': 3540}
skipping logging after 56656 examples to avoid logging too frequently
skipping logging after 56672 examples to avoid logging too frequently
skipping logging after 56688 examples to avoid logging too frequently
train stats after 56704 examples: {'rewards_train/chosen': '0.38135', 'rewards_train/rejected': '-5.5392', 'rewards_train/margins': '5.8828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20062', 'examples_per_second': '5.0892', 'grad_norm': '4.25', 'counters/examples': 56704, 'counters/updates': 3544}
skipping logging after 56720 examples to avoid logging too frequently
skipping logging after 56736 examples to avoid logging too frequently
skipping logging after 56752 examples to avoid logging too frequently
train stats after 56768 examples: {'rewards_train/chosen': '0.41589', 'rewards_train/rejected': '-5.9018', 'rewards_train/margins': '6.3672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22858', 'examples_per_second': '5.8095', 'grad_norm': '5.5', 'counters/examples': 56768, 'counters/updates': 3548}
skipping logging after 56784 examples to avoid logging too frequently
skipping logging after 56800 examples to avoid logging too frequently
skipping logging after 56816 examples to avoid logging too frequently
train stats after 56832 examples: {'rewards_train/chosen': '0.50645', 'rewards_train/rejected': '-5.3598', 'rewards_train/margins': '6.0156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23145', 'examples_per_second': '4.8379', 'grad_norm': '5.625', 'counters/examples': 56832, 'counters/updates': 3552}
skipping logging after 56848 examples to avoid logging too frequently
skipping logging after 56864 examples to avoid logging too frequently
skipping logging after 56880 examples to avoid logging too frequently
train stats after 56896 examples: {'rewards_train/chosen': '0.41352', 'rewards_train/rejected': '-5.5343', 'rewards_train/margins': '5.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23126', 'examples_per_second': '5.8961', 'grad_norm': '4.8125', 'counters/examples': 56896, 'counters/updates': 3556}
skipping logging after 56912 examples to avoid logging too frequently
skipping logging after 56928 examples to avoid logging too frequently
skipping logging after 56944 examples to avoid logging too frequently
train stats after 56960 examples: {'rewards_train/chosen': '0.29757', 'rewards_train/rejected': '-6.8754', 'rewards_train/margins': '6.8906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22687', 'examples_per_second': '4.8958', 'grad_norm': '4.4375', 'counters/examples': 56960, 'counters/updates': 3560}
skipping logging after 56976 examples to avoid logging too frequently
skipping logging after 56992 examples to avoid logging too frequently
skipping logging after 57008 examples to avoid logging too frequently
train stats after 57024 examples: {'rewards_train/chosen': '0.59075', 'rewards_train/rejected': '-5.3294', 'rewards_train/margins': '5.7031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25433', 'examples_per_second': '5.0625', 'grad_norm': '5.1875', 'counters/examples': 57024, 'counters/updates': 3564}
skipping logging after 57040 examples to avoid logging too frequently
skipping logging after 57056 examples to avoid logging too frequently
skipping logging after 57072 examples to avoid logging too frequently
train stats after 57088 examples: {'rewards_train/chosen': '0.45006', 'rewards_train/rejected': '-5.3611', 'rewards_train/margins': '5.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27203', 'examples_per_second': '6.4423', 'grad_norm': '4.625', 'counters/examples': 57088, 'counters/updates': 3568}
skipping logging after 57104 examples to avoid logging too frequently
skipping logging after 57120 examples to avoid logging too frequently
skipping logging after 57136 examples to avoid logging too frequently
train stats after 57152 examples: {'rewards_train/chosen': '0.5341', 'rewards_train/rejected': '-5.4036', 'rewards_train/margins': '5.9414', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21411', 'examples_per_second': '5.2831', 'grad_norm': '4.0312', 'counters/examples': 57152, 'counters/updates': 3572}
skipping logging after 57168 examples to avoid logging too frequently
skipping logging after 57184 examples to avoid logging too frequently
skipping logging after 57200 examples to avoid logging too frequently
train stats after 57216 examples: {'rewards_train/chosen': '0.37165', 'rewards_train/rejected': '-5.5484', 'rewards_train/margins': '6.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23694', 'examples_per_second': '5.5706', 'grad_norm': '4.8438', 'counters/examples': 57216, 'counters/updates': 3576}
skipping logging after 57232 examples to avoid logging too frequently
skipping logging after 57248 examples to avoid logging too frequently
skipping logging after 57264 examples to avoid logging too frequently
train stats after 57280 examples: {'rewards_train/chosen': '0.40081', 'rewards_train/rejected': '-4.5145', 'rewards_train/margins': '4.9141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24237', 'examples_per_second': '5.7906', 'grad_norm': '4.75', 'counters/examples': 57280, 'counters/updates': 3580}
skipping logging after 57296 examples to avoid logging too frequently
skipping logging after 57312 examples to avoid logging too frequently
skipping logging after 57328 examples to avoid logging too frequently
train stats after 57344 examples: {'rewards_train/chosen': '0.40526', 'rewards_train/rejected': '-4.8265', 'rewards_train/margins': '4.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26172', 'examples_per_second': '6.1881', 'grad_norm': '5.6562', 'counters/examples': 57344, 'counters/updates': 3584}
skipping logging after 57360 examples to avoid logging too frequently
skipping logging after 57376 examples to avoid logging too frequently
skipping logging after 57392 examples to avoid logging too frequently
train stats after 57408 examples: {'rewards_train/chosen': '0.5183', 'rewards_train/rejected': '-4.4695', 'rewards_train/margins': '5.0977', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25696', 'examples_per_second': '6.0817', 'grad_norm': '5.4688', 'counters/examples': 57408, 'counters/updates': 3588}
skipping logging after 57424 examples to avoid logging too frequently
skipping logging after 57440 examples to avoid logging too frequently
skipping logging after 57456 examples to avoid logging too frequently
train stats after 57472 examples: {'rewards_train/chosen': '0.43648', 'rewards_train/rejected': '-4.4402', 'rewards_train/margins': '4.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21625', 'examples_per_second': '4.9837', 'grad_norm': '4.8125', 'counters/examples': 57472, 'counters/updates': 3592}
skipping logging after 57488 examples to avoid logging too frequently
skipping logging after 57504 examples to avoid logging too frequently
skipping logging after 57520 examples to avoid logging too frequently
train stats after 57536 examples: {'rewards_train/chosen': '0.46029', 'rewards_train/rejected': '-6.2926', 'rewards_train/margins': '7.0234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22717', 'examples_per_second': '4.1694', 'grad_norm': '4.625', 'counters/examples': 57536, 'counters/updates': 3596}
skipping logging after 57552 examples to avoid logging too frequently
skipping logging after 57568 examples to avoid logging too frequently
skipping logging after 57584 examples to avoid logging too frequently
train stats after 57600 examples: {'rewards_train/chosen': '0.39122', 'rewards_train/rejected': '-5.1266', 'rewards_train/margins': '5.4727', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27179', 'examples_per_second': '6.2108', 'grad_norm': '5.5', 'counters/examples': 57600, 'counters/updates': 3600}
skipping logging after 57616 examples to avoid logging too frequently
skipping logging after 57632 examples to avoid logging too frequently
skipping logging after 57648 examples to avoid logging too frequently
train stats after 57664 examples: {'rewards_train/chosen': '0.63114', 'rewards_train/rejected': '-6.0105', 'rewards_train/margins': '6.6016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2179', 'examples_per_second': '4.5507', 'grad_norm': '5.0938', 'counters/examples': 57664, 'counters/updates': 3604}
skipping logging after 57680 examples to avoid logging too frequently
skipping logging after 57696 examples to avoid logging too frequently
skipping logging after 57712 examples to avoid logging too frequently
train stats after 57728 examples: {'rewards_train/chosen': '0.4982', 'rewards_train/rejected': '-4.7301', 'rewards_train/margins': '4.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25543', 'examples_per_second': '5.7768', 'grad_norm': '4.4375', 'counters/examples': 57728, 'counters/updates': 3608}
skipping logging after 57744 examples to avoid logging too frequently
skipping logging after 57760 examples to avoid logging too frequently
skipping logging after 57776 examples to avoid logging too frequently
train stats after 57792 examples: {'rewards_train/chosen': '0.65405', 'rewards_train/rejected': '-4.5417', 'rewards_train/margins': '5.1719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19098', 'examples_per_second': '5.8654', 'grad_norm': '4.5312', 'counters/examples': 57792, 'counters/updates': 3612}
skipping logging after 57808 examples to avoid logging too frequently
skipping logging after 57824 examples to avoid logging too frequently
skipping logging after 57840 examples to avoid logging too frequently
train stats after 57856 examples: {'rewards_train/chosen': '0.36857', 'rewards_train/rejected': '-5.59', 'rewards_train/margins': '6.1875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23169', 'examples_per_second': '4.3609', 'grad_norm': '4.75', 'counters/examples': 57856, 'counters/updates': 3616}
skipping logging after 57872 examples to avoid logging too frequently
skipping logging after 57888 examples to avoid logging too frequently
skipping logging after 57904 examples to avoid logging too frequently
train stats after 57920 examples: {'rewards_train/chosen': '0.6515', 'rewards_train/rejected': '-5.8344', 'rewards_train/margins': '6.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18921', 'examples_per_second': '4.7194', 'grad_norm': '4.2812', 'counters/examples': 57920, 'counters/updates': 3620}
skipping logging after 57936 examples to avoid logging too frequently
skipping logging after 57952 examples to avoid logging too frequently
skipping logging after 57968 examples to avoid logging too frequently
train stats after 57984 examples: {'rewards_train/chosen': '0.53792', 'rewards_train/rejected': '-3.8074', 'rewards_train/margins': '4.0586', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23877', 'examples_per_second': '5.699', 'grad_norm': '4.7812', 'counters/examples': 57984, 'counters/updates': 3624}
skipping logging after 58000 examples to avoid logging too frequently
skipping logging after 58016 examples to avoid logging too frequently
skipping logging after 58032 examples to avoid logging too frequently
train stats after 58048 examples: {'rewards_train/chosen': '0.48685', 'rewards_train/rejected': '-5.8416', 'rewards_train/margins': '6.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22394', 'examples_per_second': '6.3927', 'grad_norm': '5.3125', 'counters/examples': 58048, 'counters/updates': 3628}
skipping logging after 58064 examples to avoid logging too frequently
skipping logging after 58080 examples to avoid logging too frequently
skipping logging after 58096 examples to avoid logging too frequently
train stats after 58112 examples: {'rewards_train/chosen': '0.48848', 'rewards_train/rejected': '-5.4824', 'rewards_train/margins': '6.0312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2088', 'examples_per_second': '5.8085', 'grad_norm': '5.4688', 'counters/examples': 58112, 'counters/updates': 3632}
skipping logging after 58128 examples to avoid logging too frequently
skipping logging after 58144 examples to avoid logging too frequently
skipping logging after 58160 examples to avoid logging too frequently
train stats after 58176 examples: {'rewards_train/chosen': '0.30536', 'rewards_train/rejected': '-5.4107', 'rewards_train/margins': '5.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25653', 'examples_per_second': '6.0429', 'grad_norm': '4.6875', 'counters/examples': 58176, 'counters/updates': 3636}
skipping logging after 58192 examples to avoid logging too frequently
skipping logging after 58208 examples to avoid logging too frequently
skipping logging after 58224 examples to avoid logging too frequently
train stats after 58240 examples: {'rewards_train/chosen': '0.40771', 'rewards_train/rejected': '-5.1995', 'rewards_train/margins': '5.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23273', 'examples_per_second': '5.4832', 'grad_norm': '4.875', 'counters/examples': 58240, 'counters/updates': 3640}
skipping logging after 58256 examples to avoid logging too frequently
skipping logging after 58272 examples to avoid logging too frequently
skipping logging after 58288 examples to avoid logging too frequently
train stats after 58304 examples: {'rewards_train/chosen': '0.60022', 'rewards_train/rejected': '-5.4878', 'rewards_train/margins': '5.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20813', 'examples_per_second': '5.1957', 'grad_norm': '5.625', 'counters/examples': 58304, 'counters/updates': 3644}
skipping logging after 58320 examples to avoid logging too frequently
skipping logging after 58336 examples to avoid logging too frequently
skipping logging after 58352 examples to avoid logging too frequently
train stats after 58368 examples: {'rewards_train/chosen': '0.50267', 'rewards_train/rejected': '-6.0123', 'rewards_train/margins': '6.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20209', 'examples_per_second': '5.9438', 'grad_norm': '4.5312', 'counters/examples': 58368, 'counters/updates': 3648}
skipping logging after 58384 examples to avoid logging too frequently
skipping logging after 58400 examples to avoid logging too frequently
skipping logging after 58416 examples to avoid logging too frequently
train stats after 58432 examples: {'rewards_train/chosen': '0.28631', 'rewards_train/rejected': '-5.4589', 'rewards_train/margins': '5.8125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24451', 'examples_per_second': '4.236', 'grad_norm': '5.625', 'counters/examples': 58432, 'counters/updates': 3652}
skipping logging after 58448 examples to avoid logging too frequently
skipping logging after 58464 examples to avoid logging too frequently
skipping logging after 58480 examples to avoid logging too frequently
train stats after 58496 examples: {'rewards_train/chosen': '0.61008', 'rewards_train/rejected': '-5.1845', 'rewards_train/margins': '5.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18646', 'examples_per_second': '5.322', 'grad_norm': '5.0312', 'counters/examples': 58496, 'counters/updates': 3656}
skipping logging after 58512 examples to avoid logging too frequently
skipping logging after 58528 examples to avoid logging too frequently
skipping logging after 58544 examples to avoid logging too frequently
train stats after 58560 examples: {'rewards_train/chosen': '0.16382', 'rewards_train/rejected': '-7.1434', 'rewards_train/margins': '7.4609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26361', 'examples_per_second': '5.5046', 'grad_norm': '5', 'counters/examples': 58560, 'counters/updates': 3660}
skipping logging after 58576 examples to avoid logging too frequently
skipping logging after 58592 examples to avoid logging too frequently
skipping logging after 58608 examples to avoid logging too frequently
train stats after 58624 examples: {'rewards_train/chosen': '0.17286', 'rewards_train/rejected': '-5.9074', 'rewards_train/margins': '5.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26715', 'examples_per_second': '4.5997', 'grad_norm': '4.9688', 'counters/examples': 58624, 'counters/updates': 3664}
skipping logging after 58640 examples to avoid logging too frequently
skipping logging after 58656 examples to avoid logging too frequently
skipping logging after 58672 examples to avoid logging too frequently
train stats after 58688 examples: {'rewards_train/chosen': '0.56748', 'rewards_train/rejected': '-4.922', 'rewards_train/margins': '5.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23828', 'examples_per_second': '5.9336', 'grad_norm': '6.625', 'counters/examples': 58688, 'counters/updates': 3668}
skipping logging after 58704 examples to avoid logging too frequently
skipping logging after 58720 examples to avoid logging too frequently
skipping logging after 58736 examples to avoid logging too frequently
train stats after 58752 examples: {'rewards_train/chosen': '0.64068', 'rewards_train/rejected': '-5.9044', 'rewards_train/margins': '6.8828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.229', 'examples_per_second': '4.892', 'grad_norm': '4.4688', 'counters/examples': 58752, 'counters/updates': 3672}
skipping logging after 58768 examples to avoid logging too frequently
skipping logging after 58784 examples to avoid logging too frequently
skipping logging after 58800 examples to avoid logging too frequently
train stats after 58816 examples: {'rewards_train/chosen': '0.44568', 'rewards_train/rejected': '-5.2345', 'rewards_train/margins': '5.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26923', 'examples_per_second': '6.3017', 'grad_norm': '6.0312', 'counters/examples': 58816, 'counters/updates': 3676}
skipping logging after 58832 examples to avoid logging too frequently
skipping logging after 58848 examples to avoid logging too frequently
skipping logging after 58864 examples to avoid logging too frequently
train stats after 58880 examples: {'rewards_train/chosen': '0.1568', 'rewards_train/rejected': '-4.0282', 'rewards_train/margins': '4.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2431', 'examples_per_second': '4.8946', 'grad_norm': '5.375', 'counters/examples': 58880, 'counters/updates': 3680}
skipping logging after 58896 examples to avoid logging too frequently
skipping logging after 58912 examples to avoid logging too frequently
skipping logging after 58928 examples to avoid logging too frequently
train stats after 58944 examples: {'rewards_train/chosen': '0.15637', 'rewards_train/rejected': '-5.1859', 'rewards_train/margins': '5.1406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26605', 'examples_per_second': '6.7738', 'grad_norm': '4.625', 'counters/examples': 58944, 'counters/updates': 3684}
skipping logging after 58960 examples to avoid logging too frequently
skipping logging after 58976 examples to avoid logging too frequently
skipping logging after 58992 examples to avoid logging too frequently
train stats after 59008 examples: {'rewards_train/chosen': '0.39095', 'rewards_train/rejected': '-6.2827', 'rewards_train/margins': '6.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27545', 'examples_per_second': '4.3777', 'grad_norm': '6.0312', 'counters/examples': 59008, 'counters/updates': 3688}
skipping logging after 59024 examples to avoid logging too frequently
skipping logging after 59040 examples to avoid logging too frequently
skipping logging after 59056 examples to avoid logging too frequently
train stats after 59072 examples: {'rewards_train/chosen': '0.58039', 'rewards_train/rejected': '-5.5611', 'rewards_train/margins': '5.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23206', 'examples_per_second': '4.7203', 'grad_norm': '4.0938', 'counters/examples': 59072, 'counters/updates': 3692}
skipping logging after 59088 examples to avoid logging too frequently
skipping logging after 59104 examples to avoid logging too frequently
skipping logging after 59120 examples to avoid logging too frequently
train stats after 59136 examples: {'rewards_train/chosen': '0.46481', 'rewards_train/rejected': '-4.9937', 'rewards_train/margins': '5.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24127', 'examples_per_second': '6.0293', 'grad_norm': '4.875', 'counters/examples': 59136, 'counters/updates': 3696}
skipping logging after 59152 examples to avoid logging too frequently
skipping logging after 59168 examples to avoid logging too frequently
skipping logging after 59184 examples to avoid logging too frequently
train stats after 59200 examples: {'rewards_train/chosen': '0.48187', 'rewards_train/rejected': '-5.1119', 'rewards_train/margins': '5.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23846', 'examples_per_second': '4.9713', 'grad_norm': '4.5312', 'counters/examples': 59200, 'counters/updates': 3700}
skipping logging after 59216 examples to avoid logging too frequently
skipping logging after 59232 examples to avoid logging too frequently
skipping logging after 59248 examples to avoid logging too frequently
train stats after 59264 examples: {'rewards_train/chosen': '0.31262', 'rewards_train/rejected': '-5.0991', 'rewards_train/margins': '5.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20856', 'examples_per_second': '4.2986', 'grad_norm': '4.0938', 'counters/examples': 59264, 'counters/updates': 3704}
skipping logging after 59280 examples to avoid logging too frequently
skipping logging after 59296 examples to avoid logging too frequently
skipping logging after 59312 examples to avoid logging too frequently
train stats after 59328 examples: {'rewards_train/chosen': '0.46477', 'rewards_train/rejected': '-6.0893', 'rewards_train/margins': '6.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2691', 'examples_per_second': '6.5429', 'grad_norm': '5.125', 'counters/examples': 59328, 'counters/updates': 3708}
skipping logging after 59344 examples to avoid logging too frequently
skipping logging after 59360 examples to avoid logging too frequently
skipping logging after 59376 examples to avoid logging too frequently
train stats after 59392 examples: {'rewards_train/chosen': '0.64697', 'rewards_train/rejected': '-4.5652', 'rewards_train/margins': '5.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21692', 'examples_per_second': '5.4816', 'grad_norm': '5.1875', 'counters/examples': 59392, 'counters/updates': 3712}
skipping logging after 59408 examples to avoid logging too frequently
skipping logging after 59424 examples to avoid logging too frequently
skipping logging after 59440 examples to avoid logging too frequently
train stats after 59456 examples: {'rewards_train/chosen': '0.10849', 'rewards_train/rejected': '-4.3386', 'rewards_train/margins': '4.5898', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26025', 'examples_per_second': '5.7039', 'grad_norm': '4.7812', 'counters/examples': 59456, 'counters/updates': 3716}
skipping logging after 59472 examples to avoid logging too frequently
skipping logging after 59488 examples to avoid logging too frequently
skipping logging after 59504 examples to avoid logging too frequently
train stats after 59520 examples: {'rewards_train/chosen': '0.42399', 'rewards_train/rejected': '-6.4112', 'rewards_train/margins': '6.9375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26965', 'examples_per_second': '5.338', 'grad_norm': '5.7812', 'counters/examples': 59520, 'counters/updates': 3720}
skipping logging after 59536 examples to avoid logging too frequently
skipping logging after 59552 examples to avoid logging too frequently
skipping logging after 59568 examples to avoid logging too frequently
train stats after 59584 examples: {'rewards_train/chosen': '0.56205', 'rewards_train/rejected': '-5.1332', 'rewards_train/margins': '5.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23975', 'examples_per_second': '5.1443', 'grad_norm': '5.875', 'counters/examples': 59584, 'counters/updates': 3724}
skipping logging after 59600 examples to avoid logging too frequently
skipping logging after 59616 examples to avoid logging too frequently
skipping logging after 59632 examples to avoid logging too frequently
train stats after 59648 examples: {'rewards_train/chosen': '0.5445', 'rewards_train/rejected': '-6.1375', 'rewards_train/margins': '6.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21594', 'examples_per_second': '5.3796', 'grad_norm': '4.5', 'counters/examples': 59648, 'counters/updates': 3728}
skipping logging after 59664 examples to avoid logging too frequently
skipping logging after 59680 examples to avoid logging too frequently
skipping logging after 59696 examples to avoid logging too frequently
train stats after 59712 examples: {'rewards_train/chosen': '0.27194', 'rewards_train/rejected': '-6.1555', 'rewards_train/margins': '6.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27991', 'examples_per_second': '4.9244', 'grad_norm': '5.2188', 'counters/examples': 59712, 'counters/updates': 3732}
skipping logging after 59728 examples to avoid logging too frequently
skipping logging after 59744 examples to avoid logging too frequently
skipping logging after 59760 examples to avoid logging too frequently
train stats after 59776 examples: {'rewards_train/chosen': '0.27822', 'rewards_train/rejected': '-4.4763', 'rewards_train/margins': '4.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22711', 'examples_per_second': '5.6078', 'grad_norm': '4.4688', 'counters/examples': 59776, 'counters/updates': 3736}
skipping logging after 59792 examples to avoid logging too frequently
skipping logging after 59808 examples to avoid logging too frequently
skipping logging after 59824 examples to avoid logging too frequently
train stats after 59840 examples: {'rewards_train/chosen': '0.39853', 'rewards_train/rejected': '-6.8487', 'rewards_train/margins': '7.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23676', 'examples_per_second': '4.2695', 'grad_norm': '5.25', 'counters/examples': 59840, 'counters/updates': 3740}
skipping logging after 59856 examples to avoid logging too frequently
skipping logging after 59872 examples to avoid logging too frequently
skipping logging after 59888 examples to avoid logging too frequently
train stats after 59904 examples: {'rewards_train/chosen': '0.19299', 'rewards_train/rejected': '-6.2323', 'rewards_train/margins': '6.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26526', 'examples_per_second': '4.9147', 'grad_norm': '4.7812', 'counters/examples': 59904, 'counters/updates': 3744}
skipping logging after 59920 examples to avoid logging too frequently
skipping logging after 59936 examples to avoid logging too frequently
skipping logging after 59952 examples to avoid logging too frequently
train stats after 59968 examples: {'rewards_train/chosen': '0.50544', 'rewards_train/rejected': '-6.612', 'rewards_train/margins': '7.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19366', 'examples_per_second': '5.0715', 'grad_norm': '4.4062', 'counters/examples': 59968, 'counters/updates': 3748}
skipping logging after 59984 examples to avoid logging too frequently
skipping logging after 60000 examples to avoid logging too frequently
Running evaluation after 60000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:53,  1.73s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:43,  1.45s/it]Computing eval metrics:   9%|▉         | 3/32 [00:04<00:36,  1.27s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.49s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.69s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:09<00:38,  1.50s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:10<00:34,  1.38s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:12<00:36,  1.53s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.49s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:31,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.41s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:20<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:21<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:28<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.31s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:40<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:41<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.12s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]
eval after 60000: {'rewards_eval/chosen': '-5.3217', 'rewards_eval/rejected': '-5.7112', 'rewards_eval/margins': '0.29248', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46532'}
skipping logging after 60016 examples to avoid logging too frequently
train stats after 60032 examples: {'rewards_train/chosen': '0.24311', 'rewards_train/rejected': '-5.5642', 'rewards_train/margins': '5.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26849', 'examples_per_second': '6.1403', 'grad_norm': '5.2188', 'counters/examples': 60032, 'counters/updates': 3752}
skipping logging after 60048 examples to avoid logging too frequently
skipping logging after 60064 examples to avoid logging too frequently
skipping logging after 60080 examples to avoid logging too frequently
train stats after 60096 examples: {'rewards_train/chosen': '0.42838', 'rewards_train/rejected': '-5.3942', 'rewards_train/margins': '5.7734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20239', 'examples_per_second': '5.4825', 'grad_norm': '4.1562', 'counters/examples': 60096, 'counters/updates': 3756}
skipping logging after 60112 examples to avoid logging too frequently
skipping logging after 60128 examples to avoid logging too frequently
skipping logging after 60144 examples to avoid logging too frequently
train stats after 60160 examples: {'rewards_train/chosen': '0.49509', 'rewards_train/rejected': '-5.61', 'rewards_train/margins': '6.0312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24725', 'examples_per_second': '4.3911', 'grad_norm': '4.9375', 'counters/examples': 60160, 'counters/updates': 3760}
skipping logging after 60176 examples to avoid logging too frequently
skipping logging after 60192 examples to avoid logging too frequently
skipping logging after 60208 examples to avoid logging too frequently
train stats after 60224 examples: {'rewards_train/chosen': '0.51728', 'rewards_train/rejected': '-6.4221', 'rewards_train/margins': '7.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18555', 'examples_per_second': '4.0928', 'grad_norm': '4.3125', 'counters/examples': 60224, 'counters/updates': 3764}
skipping logging after 60240 examples to avoid logging too frequently
skipping logging after 60256 examples to avoid logging too frequently
skipping logging after 60272 examples to avoid logging too frequently
train stats after 60288 examples: {'rewards_train/chosen': '0.66964', 'rewards_train/rejected': '-5.9446', 'rewards_train/margins': '6.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2121', 'examples_per_second': '5.1953', 'grad_norm': '4.5938', 'counters/examples': 60288, 'counters/updates': 3768}
skipping logging after 60304 examples to avoid logging too frequently
skipping logging after 60320 examples to avoid logging too frequently
skipping logging after 60336 examples to avoid logging too frequently
train stats after 60352 examples: {'rewards_train/chosen': '0.34989', 'rewards_train/rejected': '-6.0481', 'rewards_train/margins': '6.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25824', 'examples_per_second': '5.9981', 'grad_norm': '5.2188', 'counters/examples': 60352, 'counters/updates': 3772}
skipping logging after 60368 examples to avoid logging too frequently
skipping logging after 60384 examples to avoid logging too frequently
skipping logging after 60400 examples to avoid logging too frequently
train stats after 60416 examples: {'rewards_train/chosen': '0.50836', 'rewards_train/rejected': '-4.5907', 'rewards_train/margins': '5.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21228', 'examples_per_second': '6.5701', 'grad_norm': '4.9375', 'counters/examples': 60416, 'counters/updates': 3776}
skipping logging after 60432 examples to avoid logging too frequently
skipping logging after 60448 examples to avoid logging too frequently
skipping logging after 60464 examples to avoid logging too frequently
train stats after 60480 examples: {'rewards_train/chosen': '0.80098', 'rewards_train/rejected': '-5.9831', 'rewards_train/margins': '6.7422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1792', 'examples_per_second': '4.7987', 'grad_norm': '4.1562', 'counters/examples': 60480, 'counters/updates': 3780}
skipping logging after 60496 examples to avoid logging too frequently
skipping logging after 60512 examples to avoid logging too frequently
skipping logging after 60528 examples to avoid logging too frequently
train stats after 60544 examples: {'rewards_train/chosen': '0.3008', 'rewards_train/rejected': '-6.6095', 'rewards_train/margins': '7.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21515', 'examples_per_second': '5.5696', 'grad_norm': '4.5312', 'counters/examples': 60544, 'counters/updates': 3784}
skipping logging after 60560 examples to avoid logging too frequently
skipping logging after 60576 examples to avoid logging too frequently
skipping logging after 60592 examples to avoid logging too frequently
train stats after 60608 examples: {'rewards_train/chosen': '0.56786', 'rewards_train/rejected': '-5.2944', 'rewards_train/margins': '5.9297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21289', 'examples_per_second': '5.0976', 'grad_norm': '5.25', 'counters/examples': 60608, 'counters/updates': 3788}
skipping logging after 60624 examples to avoid logging too frequently
skipping logging after 60640 examples to avoid logging too frequently
skipping logging after 60656 examples to avoid logging too frequently
train stats after 60672 examples: {'rewards_train/chosen': '0.31156', 'rewards_train/rejected': '-4.9787', 'rewards_train/margins': '4.832', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27527', 'examples_per_second': '4.941', 'grad_norm': '5.75', 'counters/examples': 60672, 'counters/updates': 3792}
skipping logging after 60688 examples to avoid logging too frequently
skipping logging after 60704 examples to avoid logging too frequently
skipping logging after 60720 examples to avoid logging too frequently
train stats after 60736 examples: {'rewards_train/chosen': '0.47669', 'rewards_train/rejected': '-4.957', 'rewards_train/margins': '5.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22479', 'examples_per_second': '5.4612', 'grad_norm': '5.0938', 'counters/examples': 60736, 'counters/updates': 3796}
skipping logging after 60752 examples to avoid logging too frequently
skipping logging after 60768 examples to avoid logging too frequently
skipping logging after 60784 examples to avoid logging too frequently
train stats after 60800 examples: {'rewards_train/chosen': '0.36156', 'rewards_train/rejected': '-5.1201', 'rewards_train/margins': '5.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23956', 'examples_per_second': '4.9272', 'grad_norm': '5.125', 'counters/examples': 60800, 'counters/updates': 3800}
skipping logging after 60816 examples to avoid logging too frequently
skipping logging after 60832 examples to avoid logging too frequently
skipping logging after 60848 examples to avoid logging too frequently
train stats after 60864 examples: {'rewards_train/chosen': '0.43954', 'rewards_train/rejected': '-6.3315', 'rewards_train/margins': '6.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22559', 'examples_per_second': '5.0481', 'grad_norm': '5.5625', 'counters/examples': 60864, 'counters/updates': 3804}
skipping logging after 60880 examples to avoid logging too frequently
skipping logging after 60896 examples to avoid logging too frequently
skipping logging after 60912 examples to avoid logging too frequently
train stats after 60928 examples: {'rewards_train/chosen': '0.49315', 'rewards_train/rejected': '-4.7588', 'rewards_train/margins': '4.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26697', 'examples_per_second': '5.2329', 'grad_norm': '5.5312', 'counters/examples': 60928, 'counters/updates': 3808}
skipping logging after 60944 examples to avoid logging too frequently
skipping logging after 60960 examples to avoid logging too frequently
skipping logging after 60976 examples to avoid logging too frequently
train stats after 60992 examples: {'rewards_train/chosen': '0.58725', 'rewards_train/rejected': '-5.4641', 'rewards_train/margins': '5.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23633', 'examples_per_second': '5.4234', 'grad_norm': '4.6875', 'counters/examples': 60992, 'counters/updates': 3812}
skipping logging after 61008 examples to avoid logging too frequently
skipping logging after 61024 examples to avoid logging too frequently
skipping logging after 61040 examples to avoid logging too frequently
train stats after 61056 examples: {'rewards_train/chosen': '0.53977', 'rewards_train/rejected': '-4.0202', 'rewards_train/margins': '4.5469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24506', 'examples_per_second': '5.7571', 'grad_norm': '4.5625', 'counters/examples': 61056, 'counters/updates': 3816}
skipping logging after 61072 examples to avoid logging too frequently
skipping logging after 61088 examples to avoid logging too frequently
skipping logging after 61104 examples to avoid logging too frequently
train stats after 61120 examples: {'rewards_train/chosen': '0.28566', 'rewards_train/rejected': '-4.4684', 'rewards_train/margins': '4.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28979', 'examples_per_second': '5.3978', 'grad_norm': '5.75', 'counters/examples': 61120, 'counters/updates': 3820}
skipping logging after 61136 examples to avoid logging too frequently
skipping logging after 61152 examples to avoid logging too frequently
skipping logging after 61168 examples to avoid logging too frequently
train stats after 61184 examples: {'rewards_train/chosen': '0.46864', 'rewards_train/rejected': '-4.9602', 'rewards_train/margins': '5.4609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24524', 'examples_per_second': '4.9147', 'grad_norm': '5.5312', 'counters/examples': 61184, 'counters/updates': 3824}
skipping logging after 61200 examples to avoid logging too frequently
skipping logging after 61216 examples to avoid logging too frequently
skipping logging after 61232 examples to avoid logging too frequently
train stats after 61248 examples: {'rewards_train/chosen': '0.59798', 'rewards_train/rejected': '-4.5408', 'rewards_train/margins': '5.3672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20355', 'examples_per_second': '4.6329', 'grad_norm': '5.375', 'counters/examples': 61248, 'counters/updates': 3828}
skipping logging after 61264 examples to avoid logging too frequently
skipping logging after 61280 examples to avoid logging too frequently
skipping logging after 61296 examples to avoid logging too frequently
train stats after 61312 examples: {'rewards_train/chosen': '0.25071', 'rewards_train/rejected': '-5.1487', 'rewards_train/margins': '5.8125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25116', 'examples_per_second': '4.1619', 'grad_norm': '4.875', 'counters/examples': 61312, 'counters/updates': 3832}
skipping logging after 61328 examples to avoid logging too frequently
skipping logging after 61344 examples to avoid logging too frequently
skipping logging after 61360 examples to avoid logging too frequently
train stats after 61376 examples: {'rewards_train/chosen': '0.31992', 'rewards_train/rejected': '-6.578', 'rewards_train/margins': '6.7891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29956', 'examples_per_second': '6.4264', 'grad_norm': '5.8125', 'counters/examples': 61376, 'counters/updates': 3836}
skipping logging after 61392 examples to avoid logging too frequently
skipping logging after 61408 examples to avoid logging too frequently
skipping logging after 61424 examples to avoid logging too frequently
train stats after 61440 examples: {'rewards_train/chosen': '0.41021', 'rewards_train/rejected': '-5.4113', 'rewards_train/margins': '5.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21356', 'examples_per_second': '5.9586', 'grad_norm': '4.9375', 'counters/examples': 61440, 'counters/updates': 3840}
skipping logging after 61456 examples to avoid logging too frequently
skipping logging after 61472 examples to avoid logging too frequently
skipping logging after 61488 examples to avoid logging too frequently
train stats after 61504 examples: {'rewards_train/chosen': '0.36101', 'rewards_train/rejected': '-6.1252', 'rewards_train/margins': '6.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23035', 'examples_per_second': '4.3875', 'grad_norm': '4.2812', 'counters/examples': 61504, 'counters/updates': 3844}
skipping logging after 61520 examples to avoid logging too frequently
skipping logging after 61536 examples to avoid logging too frequently
skipping logging after 61552 examples to avoid logging too frequently
train stats after 61568 examples: {'rewards_train/chosen': '0.49953', 'rewards_train/rejected': '-4.6189', 'rewards_train/margins': '4.8867', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28217', 'examples_per_second': '5.1816', 'grad_norm': '5.4375', 'counters/examples': 61568, 'counters/updates': 3848}
skipping logging after 61584 examples to avoid logging too frequently
skipping logging after 61600 examples to avoid logging too frequently
skipping logging after 61616 examples to avoid logging too frequently
train stats after 61632 examples: {'rewards_train/chosen': '0.23398', 'rewards_train/rejected': '-4.4282', 'rewards_train/margins': '4.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25275', 'examples_per_second': '6.3465', 'grad_norm': '5.2188', 'counters/examples': 61632, 'counters/updates': 3852}
skipping logging after 61648 examples to avoid logging too frequently
skipping logging after 61664 examples to avoid logging too frequently
skipping logging after 61680 examples to avoid logging too frequently
train stats after 61696 examples: {'rewards_train/chosen': '0.64948', 'rewards_train/rejected': '-6.8552', 'rewards_train/margins': '7.3203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23438', 'examples_per_second': '6.3794', 'grad_norm': '5.375', 'counters/examples': 61696, 'counters/updates': 3856}
skipping logging after 61712 examples to avoid logging too frequently
skipping logging after 61728 examples to avoid logging too frequently
skipping logging after 61744 examples to avoid logging too frequently
train stats after 61760 examples: {'rewards_train/chosen': '0.48306', 'rewards_train/rejected': '-6.7721', 'rewards_train/margins': '7.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22363', 'examples_per_second': '5.7091', 'grad_norm': '4.75', 'counters/examples': 61760, 'counters/updates': 3860}
skipping logging after 61776 examples to avoid logging too frequently
skipping logging after 61792 examples to avoid logging too frequently
skipping logging after 61808 examples to avoid logging too frequently
train stats after 61824 examples: {'rewards_train/chosen': '0.38322', 'rewards_train/rejected': '-5.2547', 'rewards_train/margins': '5.7578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23999', 'examples_per_second': '5.5733', 'grad_norm': '5.25', 'counters/examples': 61824, 'counters/updates': 3864}
skipping logging after 61840 examples to avoid logging too frequently
skipping logging after 61856 examples to avoid logging too frequently
skipping logging after 61872 examples to avoid logging too frequently
train stats after 61888 examples: {'rewards_train/chosen': '0.45684', 'rewards_train/rejected': '-5.7964', 'rewards_train/margins': '5.7148', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21783', 'examples_per_second': '4.8492', 'grad_norm': '4.1875', 'counters/examples': 61888, 'counters/updates': 3868}
skipping logging after 61904 examples to avoid logging too frequently
skipping logging after 61920 examples to avoid logging too frequently
skipping logging after 61936 examples to avoid logging too frequently
train stats after 61952 examples: {'rewards_train/chosen': '0.45614', 'rewards_train/rejected': '-5.9483', 'rewards_train/margins': '6.3594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23853', 'examples_per_second': '5.2134', 'grad_norm': '4.625', 'counters/examples': 61952, 'counters/updates': 3872}
skipping logging after 61968 examples to avoid logging too frequently
skipping logging after 61984 examples to avoid logging too frequently
skipping logging after 62000 examples to avoid logging too frequently
train stats after 62016 examples: {'rewards_train/chosen': '0.37792', 'rewards_train/rejected': '-5.0808', 'rewards_train/margins': '5.7422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27063', 'examples_per_second': '5.5525', 'grad_norm': '6.75', 'counters/examples': 62016, 'counters/updates': 3876}
skipping logging after 62032 examples to avoid logging too frequently
skipping logging after 62048 examples to avoid logging too frequently
skipping logging after 62064 examples to avoid logging too frequently
train stats after 62080 examples: {'rewards_train/chosen': '0.60744', 'rewards_train/rejected': '-5.9986', 'rewards_train/margins': '6.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20984', 'examples_per_second': '5.0483', 'grad_norm': '4.6562', 'counters/examples': 62080, 'counters/updates': 3880}
skipping logging after 62096 examples to avoid logging too frequently
skipping logging after 62112 examples to avoid logging too frequently
skipping logging after 62128 examples to avoid logging too frequently
train stats after 62144 examples: {'rewards_train/chosen': '0.27202', 'rewards_train/rejected': '-5.1994', 'rewards_train/margins': '5.5938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22113', 'examples_per_second': '5.6113', 'grad_norm': '6.4688', 'counters/examples': 62144, 'counters/updates': 3884}
skipping logging after 62160 examples to avoid logging too frequently
skipping logging after 62176 examples to avoid logging too frequently
skipping logging after 62192 examples to avoid logging too frequently
train stats after 62208 examples: {'rewards_train/chosen': '0.28597', 'rewards_train/rejected': '-5.7743', 'rewards_train/margins': '6.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21942', 'examples_per_second': '5.6287', 'grad_norm': '4.5', 'counters/examples': 62208, 'counters/updates': 3888}
skipping logging after 62224 examples to avoid logging too frequently
skipping logging after 62240 examples to avoid logging too frequently
skipping logging after 62256 examples to avoid logging too frequently
train stats after 62272 examples: {'rewards_train/chosen': '0.30373', 'rewards_train/rejected': '-4.6515', 'rewards_train/margins': '4.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24872', 'examples_per_second': '5.8929', 'grad_norm': '6.375', 'counters/examples': 62272, 'counters/updates': 3892}
skipping logging after 62288 examples to avoid logging too frequently
skipping logging after 62304 examples to avoid logging too frequently
skipping logging after 62320 examples to avoid logging too frequently
train stats after 62336 examples: {'rewards_train/chosen': '0.4602', 'rewards_train/rejected': '-5.0204', 'rewards_train/margins': '5.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22699', 'examples_per_second': '5.6902', 'grad_norm': '4.8438', 'counters/examples': 62336, 'counters/updates': 3896}
skipping logging after 62352 examples to avoid logging too frequently
skipping logging after 62368 examples to avoid logging too frequently
skipping logging after 62384 examples to avoid logging too frequently
train stats after 62400 examples: {'rewards_train/chosen': '0.5517', 'rewards_train/rejected': '-6.2668', 'rewards_train/margins': '6.5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20959', 'examples_per_second': '5.8112', 'grad_norm': '6.3438', 'counters/examples': 62400, 'counters/updates': 3900}
skipping logging after 62416 examples to avoid logging too frequently
skipping logging after 62432 examples to avoid logging too frequently
skipping logging after 62448 examples to avoid logging too frequently
train stats after 62464 examples: {'rewards_train/chosen': '0.30338', 'rewards_train/rejected': '-5.5079', 'rewards_train/margins': '5.8828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20807', 'examples_per_second': '6.2077', 'grad_norm': '4.9062', 'counters/examples': 62464, 'counters/updates': 3904}
skipping logging after 62480 examples to avoid logging too frequently
skipping logging after 62496 examples to avoid logging too frequently
skipping logging after 62512 examples to avoid logging too frequently
train stats after 62528 examples: {'rewards_train/chosen': '0.12885', 'rewards_train/rejected': '-7.6801', 'rewards_train/margins': '8.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25183', 'examples_per_second': '4.9185', 'grad_norm': '5.125', 'counters/examples': 62528, 'counters/updates': 3908}
skipping logging after 62544 examples to avoid logging too frequently
skipping logging after 62560 examples to avoid logging too frequently
skipping logging after 62576 examples to avoid logging too frequently
train stats after 62592 examples: {'rewards_train/chosen': '0.64752', 'rewards_train/rejected': '-5.6665', 'rewards_train/margins': '6.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21326', 'examples_per_second': '4.8685', 'grad_norm': '4.5625', 'counters/examples': 62592, 'counters/updates': 3912}
skipping logging after 62608 examples to avoid logging too frequently
skipping logging after 62624 examples to avoid logging too frequently
skipping logging after 62640 examples to avoid logging too frequently
train stats after 62656 examples: {'rewards_train/chosen': '0.56735', 'rewards_train/rejected': '-5.3043', 'rewards_train/margins': '5.7656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25488', 'examples_per_second': '4.1193', 'grad_norm': '5', 'counters/examples': 62656, 'counters/updates': 3916}
skipping logging after 62672 examples to avoid logging too frequently
skipping logging after 62688 examples to avoid logging too frequently
skipping logging after 62704 examples to avoid logging too frequently
train stats after 62720 examples: {'rewards_train/chosen': '0.28018', 'rewards_train/rejected': '-5.2432', 'rewards_train/margins': '5.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28229', 'examples_per_second': '4.7169', 'grad_norm': '5.4375', 'counters/examples': 62720, 'counters/updates': 3920}
skipping logging after 62736 examples to avoid logging too frequently
skipping logging after 62752 examples to avoid logging too frequently
skipping logging after 62768 examples to avoid logging too frequently
train stats after 62784 examples: {'rewards_train/chosen': '0.75794', 'rewards_train/rejected': '-4.9069', 'rewards_train/margins': '5.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20319', 'examples_per_second': '4.8966', 'grad_norm': '5.375', 'counters/examples': 62784, 'counters/updates': 3924}
skipping logging after 62800 examples to avoid logging too frequently
skipping logging after 62816 examples to avoid logging too frequently
skipping logging after 62832 examples to avoid logging too frequently
train stats after 62848 examples: {'rewards_train/chosen': '0.47161', 'rewards_train/rejected': '-4.3364', 'rewards_train/margins': '4.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2298', 'examples_per_second': '4.6922', 'grad_norm': '5.0312', 'counters/examples': 62848, 'counters/updates': 3928}
skipping logging after 62864 examples to avoid logging too frequently
skipping logging after 62880 examples to avoid logging too frequently
skipping logging after 62896 examples to avoid logging too frequently
train stats after 62912 examples: {'rewards_train/chosen': '0.4469', 'rewards_train/rejected': '-5.022', 'rewards_train/margins': '5.3594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25415', 'examples_per_second': '4.4291', 'grad_norm': '5.5', 'counters/examples': 62912, 'counters/updates': 3932}
skipping logging after 62928 examples to avoid logging too frequently
skipping logging after 62944 examples to avoid logging too frequently
skipping logging after 62960 examples to avoid logging too frequently
train stats after 62976 examples: {'rewards_train/chosen': '0.52183', 'rewards_train/rejected': '-5.4518', 'rewards_train/margins': '6.125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25305', 'examples_per_second': '4.4178', 'grad_norm': '5.625', 'counters/examples': 62976, 'counters/updates': 3936}
skipping logging after 62992 examples to avoid logging too frequently
skipping logging after 63008 examples to avoid logging too frequently
skipping logging after 63024 examples to avoid logging too frequently
train stats after 63040 examples: {'rewards_train/chosen': '0.32903', 'rewards_train/rejected': '-4.9531', 'rewards_train/margins': '5.3281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25739', 'examples_per_second': '5.1661', 'grad_norm': '4.625', 'counters/examples': 63040, 'counters/updates': 3940}
skipping logging after 63056 examples to avoid logging too frequently
skipping logging after 63072 examples to avoid logging too frequently
skipping logging after 63088 examples to avoid logging too frequently
train stats after 63104 examples: {'rewards_train/chosen': '0.88174', 'rewards_train/rejected': '-6.0235', 'rewards_train/margins': '6.8125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19208', 'examples_per_second': '4.3325', 'grad_norm': '24.75', 'counters/examples': 63104, 'counters/updates': 3944}
skipping logging after 63120 examples to avoid logging too frequently
skipping logging after 63136 examples to avoid logging too frequently
skipping logging after 63152 examples to avoid logging too frequently
train stats after 63168 examples: {'rewards_train/chosen': '0.58493', 'rewards_train/rejected': '-5.6602', 'rewards_train/margins': '6.7891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20709', 'examples_per_second': '4.9915', 'grad_norm': '3.7656', 'counters/examples': 63168, 'counters/updates': 3948}
skipping logging after 63184 examples to avoid logging too frequently
skipping logging after 63200 examples to avoid logging too frequently
skipping logging after 63216 examples to avoid logging too frequently
train stats after 63232 examples: {'rewards_train/chosen': '0.50001', 'rewards_train/rejected': '-5.6445', 'rewards_train/margins': '5.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23254', 'examples_per_second': '6.2105', 'grad_norm': '5.8125', 'counters/examples': 63232, 'counters/updates': 3952}
skipping logging after 63248 examples to avoid logging too frequently
skipping logging after 63264 examples to avoid logging too frequently
skipping logging after 63280 examples to avoid logging too frequently
train stats after 63296 examples: {'rewards_train/chosen': '0.34311', 'rewards_train/rejected': '-4.9062', 'rewards_train/margins': '5.1367', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21393', 'examples_per_second': '5.7082', 'grad_norm': '5.1875', 'counters/examples': 63296, 'counters/updates': 3956}
skipping logging after 63312 examples to avoid logging too frequently
skipping logging after 63328 examples to avoid logging too frequently
skipping logging after 63344 examples to avoid logging too frequently
train stats after 63360 examples: {'rewards_train/chosen': '0.065094', 'rewards_train/rejected': '-5.2195', 'rewards_train/margins': '4.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23297', 'examples_per_second': '5.5172', 'grad_norm': '4.875', 'counters/examples': 63360, 'counters/updates': 3960}
skipping logging after 63376 examples to avoid logging too frequently
skipping logging after 63392 examples to avoid logging too frequently
skipping logging after 63408 examples to avoid logging too frequently
train stats after 63424 examples: {'rewards_train/chosen': '0.56569', 'rewards_train/rejected': '-4.9786', 'rewards_train/margins': '5.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20227', 'examples_per_second': '5.5612', 'grad_norm': '5.0938', 'counters/examples': 63424, 'counters/updates': 3964}
skipping logging after 63440 examples to avoid logging too frequently
skipping logging after 63456 examples to avoid logging too frequently
skipping logging after 63472 examples to avoid logging too frequently
train stats after 63488 examples: {'rewards_train/chosen': '0.64718', 'rewards_train/rejected': '-5.3803', 'rewards_train/margins': '6.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21136', 'examples_per_second': '5.4433', 'grad_norm': '5.1562', 'counters/examples': 63488, 'counters/updates': 3968}
skipping logging after 63504 examples to avoid logging too frequently
skipping logging after 63520 examples to avoid logging too frequently
skipping logging after 63536 examples to avoid logging too frequently
train stats after 63552 examples: {'rewards_train/chosen': '0.46583', 'rewards_train/rejected': '-5.0765', 'rewards_train/margins': '5.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21423', 'examples_per_second': '6.0802', 'grad_norm': '4.8125', 'counters/examples': 63552, 'counters/updates': 3972}
skipping logging after 63568 examples to avoid logging too frequently
skipping logging after 63584 examples to avoid logging too frequently
skipping logging after 63600 examples to avoid logging too frequently
train stats after 63616 examples: {'rewards_train/chosen': '0.25211', 'rewards_train/rejected': '-5.6468', 'rewards_train/margins': '5.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26843', 'examples_per_second': '5.2206', 'grad_norm': '6.0938', 'counters/examples': 63616, 'counters/updates': 3976}
skipping logging after 63632 examples to avoid logging too frequently
skipping logging after 63648 examples to avoid logging too frequently
skipping logging after 63664 examples to avoid logging too frequently
train stats after 63680 examples: {'rewards_train/chosen': '0.37664', 'rewards_train/rejected': '-5.8256', 'rewards_train/margins': '6.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23383', 'examples_per_second': '4.5992', 'grad_norm': '5.8438', 'counters/examples': 63680, 'counters/updates': 3980}
skipping logging after 63696 examples to avoid logging too frequently
skipping logging after 63712 examples to avoid logging too frequently
skipping logging after 63728 examples to avoid logging too frequently
train stats after 63744 examples: {'rewards_train/chosen': '0.55023', 'rewards_train/rejected': '-4.7337', 'rewards_train/margins': '5.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22565', 'examples_per_second': '4.8299', 'grad_norm': '4.6562', 'counters/examples': 63744, 'counters/updates': 3984}
skipping logging after 63760 examples to avoid logging too frequently
skipping logging after 63776 examples to avoid logging too frequently
skipping logging after 63792 examples to avoid logging too frequently
train stats after 63808 examples: {'rewards_train/chosen': '0.72097', 'rewards_train/rejected': '-4.8708', 'rewards_train/margins': '5.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.216', 'examples_per_second': '4.8062', 'grad_norm': '4.5625', 'counters/examples': 63808, 'counters/updates': 3988}
skipping logging after 63824 examples to avoid logging too frequently
skipping logging after 63840 examples to avoid logging too frequently
skipping logging after 63856 examples to avoid logging too frequently
train stats after 63872 examples: {'rewards_train/chosen': '0.32889', 'rewards_train/rejected': '-6.0952', 'rewards_train/margins': '6.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2439', 'examples_per_second': '5.7986', 'grad_norm': '5.0312', 'counters/examples': 63872, 'counters/updates': 3992}
skipping logging after 63888 examples to avoid logging too frequently
skipping logging after 63904 examples to avoid logging too frequently
skipping logging after 63920 examples to avoid logging too frequently
train stats after 63936 examples: {'rewards_train/chosen': '0.25731', 'rewards_train/rejected': '-6.4579', 'rewards_train/margins': '6.7266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21674', 'examples_per_second': '5.0302', 'grad_norm': '4.4062', 'counters/examples': 63936, 'counters/updates': 3996}
skipping logging after 63952 examples to avoid logging too frequently
skipping logging after 63968 examples to avoid logging too frequently
skipping logging after 63984 examples to avoid logging too frequently
train stats after 64000 examples: {'rewards_train/chosen': '0.62784', 'rewards_train/rejected': '-6.4435', 'rewards_train/margins': '7.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21808', 'examples_per_second': '5.6506', 'grad_norm': '4.2812', 'counters/examples': 64000, 'counters/updates': 4000}
Running evaluation after 64000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.25s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.17s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:39,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.65s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.47s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:33,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.51s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:33,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.40s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:30,  1.47s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:21<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:12,  1.44s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]
eval after 64000: {'rewards_eval/chosen': '-5.4769', 'rewards_eval/rejected': '-5.8714', 'rewards_eval/margins': '0.25635', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46398'}
skipping logging after 64016 examples to avoid logging too frequently
skipping logging after 64032 examples to avoid logging too frequently
skipping logging after 64048 examples to avoid logging too frequently
train stats after 64064 examples: {'rewards_train/chosen': '0.03861', 'rewards_train/rejected': '-6.1553', 'rewards_train/margins': '6.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22217', 'examples_per_second': '5.8435', 'grad_norm': '4.4375', 'counters/examples': 64064, 'counters/updates': 4004}
skipping logging after 64080 examples to avoid logging too frequently
skipping logging after 64096 examples to avoid logging too frequently
skipping logging after 64112 examples to avoid logging too frequently
train stats after 64128 examples: {'rewards_train/chosen': '0.21445', 'rewards_train/rejected': '-6.2522', 'rewards_train/margins': '6.7109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2124', 'examples_per_second': '5.6289', 'grad_norm': '5.4688', 'counters/examples': 64128, 'counters/updates': 4008}
skipping logging after 64144 examples to avoid logging too frequently
skipping logging after 64160 examples to avoid logging too frequently
skipping logging after 64176 examples to avoid logging too frequently
train stats after 64192 examples: {'rewards_train/chosen': '0.1634', 'rewards_train/rejected': '-7.3982', 'rewards_train/margins': '7.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24579', 'examples_per_second': '5.2807', 'grad_norm': '4.5938', 'counters/examples': 64192, 'counters/updates': 4012}
skipping logging after 64208 examples to avoid logging too frequently
skipping logging after 64224 examples to avoid logging too frequently
skipping logging after 64240 examples to avoid logging too frequently
train stats after 64256 examples: {'rewards_train/chosen': '0.31663', 'rewards_train/rejected': '-3.5541', 'rewards_train/margins': '4.0195', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27271', 'examples_per_second': '5.2156', 'grad_norm': '8.1875', 'counters/examples': 64256, 'counters/updates': 4016}
skipping logging after 64272 examples to avoid logging too frequently
skipping logging after 64288 examples to avoid logging too frequently
skipping logging after 64304 examples to avoid logging too frequently
train stats after 64320 examples: {'rewards_train/chosen': '0.53836', 'rewards_train/rejected': '-5.8426', 'rewards_train/margins': '6.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23871', 'examples_per_second': '4.8239', 'grad_norm': '4.875', 'counters/examples': 64320, 'counters/updates': 4020}
skipping logging after 64336 examples to avoid logging too frequently
skipping logging after 64352 examples to avoid logging too frequently
skipping logging after 64368 examples to avoid logging too frequently
train stats after 64384 examples: {'rewards_train/chosen': '0.085353', 'rewards_train/rejected': '-5.2157', 'rewards_train/margins': '5.2422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26178', 'examples_per_second': '5.1696', 'grad_norm': '5.2812', 'counters/examples': 64384, 'counters/updates': 4024}
skipping logging after 64400 examples to avoid logging too frequently
skipping logging after 64416 examples to avoid logging too frequently
skipping logging after 64432 examples to avoid logging too frequently
train stats after 64448 examples: {'rewards_train/chosen': '-0.45972', 'rewards_train/rejected': '-5.2427', 'rewards_train/margins': '4.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28625', 'examples_per_second': '4.3246', 'grad_norm': '5.7188', 'counters/examples': 64448, 'counters/updates': 4028}
skipping logging after 64464 examples to avoid logging too frequently
skipping logging after 64480 examples to avoid logging too frequently
skipping logging after 64496 examples to avoid logging too frequently
train stats after 64512 examples: {'rewards_train/chosen': '0.7842', 'rewards_train/rejected': '-4.695', 'rewards_train/margins': '5.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19421', 'examples_per_second': '4.6827', 'grad_norm': '4.5625', 'counters/examples': 64512, 'counters/updates': 4032}
skipping logging after 64528 examples to avoid logging too frequently
skipping logging after 64544 examples to avoid logging too frequently
skipping logging after 64560 examples to avoid logging too frequently
train stats after 64576 examples: {'rewards_train/chosen': '0.5301', 'rewards_train/rejected': '-6.4705', 'rewards_train/margins': '7.0859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20544', 'examples_per_second': '5.4594', 'grad_norm': '4.9375', 'counters/examples': 64576, 'counters/updates': 4036}
skipping logging after 64592 examples to avoid logging too frequently
skipping logging after 64608 examples to avoid logging too frequently
skipping logging after 64624 examples to avoid logging too frequently
train stats after 64640 examples: {'rewards_train/chosen': '0.47303', 'rewards_train/rejected': '-4.5388', 'rewards_train/margins': '5.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21844', 'examples_per_second': '5.4485', 'grad_norm': '4.8125', 'counters/examples': 64640, 'counters/updates': 4040}
skipping logging after 64656 examples to avoid logging too frequently
skipping logging after 64672 examples to avoid logging too frequently
skipping logging after 64688 examples to avoid logging too frequently
train stats after 64704 examples: {'rewards_train/chosen': '0.82616', 'rewards_train/rejected': '-5.8599', 'rewards_train/margins': '6.7266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20447', 'examples_per_second': '4.4379', 'grad_norm': '5.8125', 'counters/examples': 64704, 'counters/updates': 4044}
skipping logging after 64720 examples to avoid logging too frequently
skipping logging after 64736 examples to avoid logging too frequently
skipping logging after 64752 examples to avoid logging too frequently
train stats after 64768 examples: {'rewards_train/chosen': '0.44721', 'rewards_train/rejected': '-5.7743', 'rewards_train/margins': '6.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22632', 'examples_per_second': '5.3048', 'grad_norm': '5.2812', 'counters/examples': 64768, 'counters/updates': 4048}
skipping logging after 64784 examples to avoid logging too frequently
skipping logging after 64800 examples to avoid logging too frequently
skipping logging after 64816 examples to avoid logging too frequently
train stats after 64832 examples: {'rewards_train/chosen': '0.32506', 'rewards_train/rejected': '-5.5452', 'rewards_train/margins': '5.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25201', 'examples_per_second': '5.2523', 'grad_norm': '4.9062', 'counters/examples': 64832, 'counters/updates': 4052}
skipping logging after 64848 examples to avoid logging too frequently
skipping logging after 64864 examples to avoid logging too frequently
skipping logging after 64880 examples to avoid logging too frequently
train stats after 64896 examples: {'rewards_train/chosen': '0.25328', 'rewards_train/rejected': '-5.9331', 'rewards_train/margins': '6.1016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24341', 'examples_per_second': '5.7356', 'grad_norm': '4.4375', 'counters/examples': 64896, 'counters/updates': 4056}
skipping logging after 64912 examples to avoid logging too frequently
skipping logging after 64928 examples to avoid logging too frequently
skipping logging after 64944 examples to avoid logging too frequently
train stats after 64960 examples: {'rewards_train/chosen': '0.51468', 'rewards_train/rejected': '-4.3543', 'rewards_train/margins': '4.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20428', 'examples_per_second': '5.8657', 'grad_norm': '4.125', 'counters/examples': 64960, 'counters/updates': 4060}
skipping logging after 64976 examples to avoid logging too frequently
skipping logging after 64992 examples to avoid logging too frequently
skipping logging after 65008 examples to avoid logging too frequently
train stats after 65024 examples: {'rewards_train/chosen': '0.47096', 'rewards_train/rejected': '-7.4713', 'rewards_train/margins': '7.8828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2226', 'examples_per_second': '6.5565', 'grad_norm': '4.4062', 'counters/examples': 65024, 'counters/updates': 4064}
skipping logging after 65040 examples to avoid logging too frequently
skipping logging after 65056 examples to avoid logging too frequently
skipping logging after 65072 examples to avoid logging too frequently
train stats after 65088 examples: {'rewards_train/chosen': '-0.16592', 'rewards_train/rejected': '-5.046', 'rewards_train/margins': '5.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.32141', 'examples_per_second': '5.5597', 'grad_norm': '4.5938', 'counters/examples': 65088, 'counters/updates': 4068}
skipping logging after 65104 examples to avoid logging too frequently
skipping logging after 65120 examples to avoid logging too frequently
skipping logging after 65136 examples to avoid logging too frequently
train stats after 65152 examples: {'rewards_train/chosen': '0.56785', 'rewards_train/rejected': '-5.2968', 'rewards_train/margins': '5.8984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23865', 'examples_per_second': '4.4676', 'grad_norm': '4.3438', 'counters/examples': 65152, 'counters/updates': 4072}
skipping logging after 65168 examples to avoid logging too frequently
skipping logging after 65184 examples to avoid logging too frequently
skipping logging after 65200 examples to avoid logging too frequently
train stats after 65216 examples: {'rewards_train/chosen': '0.19589', 'rewards_train/rejected': '-5.1659', 'rewards_train/margins': '5.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26581', 'examples_per_second': '4.2446', 'grad_norm': '4.75', 'counters/examples': 65216, 'counters/updates': 4076}
skipping logging after 65232 examples to avoid logging too frequently
skipping logging after 65248 examples to avoid logging too frequently
skipping logging after 65264 examples to avoid logging too frequently
train stats after 65280 examples: {'rewards_train/chosen': '0.32025', 'rewards_train/rejected': '-5.6837', 'rewards_train/margins': '5.9414', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22778', 'examples_per_second': '4.8708', 'grad_norm': '5', 'counters/examples': 65280, 'counters/updates': 4080}
skipping logging after 65296 examples to avoid logging too frequently
skipping logging after 65312 examples to avoid logging too frequently
skipping logging after 65328 examples to avoid logging too frequently
train stats after 65344 examples: {'rewards_train/chosen': '0.56739', 'rewards_train/rejected': '-5.267', 'rewards_train/margins': '6.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24451', 'examples_per_second': '4.9', 'grad_norm': '4.5938', 'counters/examples': 65344, 'counters/updates': 4084}
skipping logging after 65360 examples to avoid logging too frequently
skipping logging after 65376 examples to avoid logging too frequently
skipping logging after 65392 examples to avoid logging too frequently
train stats after 65408 examples: {'rewards_train/chosen': '0.63947', 'rewards_train/rejected': '-5.7283', 'rewards_train/margins': '6.7422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22418', 'examples_per_second': '4.6682', 'grad_norm': '5.3125', 'counters/examples': 65408, 'counters/updates': 4088}
skipping logging after 65424 examples to avoid logging too frequently
skipping logging after 65440 examples to avoid logging too frequently
skipping logging after 65456 examples to avoid logging too frequently
train stats after 65472 examples: {'rewards_train/chosen': '0.29699', 'rewards_train/rejected': '-5.5788', 'rewards_train/margins': '6.3203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25336', 'examples_per_second': '5.6416', 'grad_norm': '5.3438', 'counters/examples': 65472, 'counters/updates': 4092}
skipping logging after 65488 examples to avoid logging too frequently
skipping logging after 65504 examples to avoid logging too frequently
skipping logging after 65520 examples to avoid logging too frequently
train stats after 65536 examples: {'rewards_train/chosen': '0.48252', 'rewards_train/rejected': '-6.0551', 'rewards_train/margins': '6.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23676', 'examples_per_second': '4.0517', 'grad_norm': '4.7188', 'counters/examples': 65536, 'counters/updates': 4096}
skipping logging after 65552 examples to avoid logging too frequently
skipping logging after 65568 examples to avoid logging too frequently
skipping logging after 65584 examples to avoid logging too frequently
train stats after 65600 examples: {'rewards_train/chosen': '0.62803', 'rewards_train/rejected': '-5.8181', 'rewards_train/margins': '6.4141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22449', 'examples_per_second': '5.2265', 'grad_norm': '4.4688', 'counters/examples': 65600, 'counters/updates': 4100}
skipping logging after 65616 examples to avoid logging too frequently
skipping logging after 65632 examples to avoid logging too frequently
skipping logging after 65648 examples to avoid logging too frequently
train stats after 65664 examples: {'rewards_train/chosen': '0.51198', 'rewards_train/rejected': '-4.5557', 'rewards_train/margins': '5.0352', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25037', 'examples_per_second': '4.9272', 'grad_norm': '5.1562', 'counters/examples': 65664, 'counters/updates': 4104}
skipping logging after 65680 examples to avoid logging too frequently
skipping logging after 65696 examples to avoid logging too frequently
skipping logging after 65712 examples to avoid logging too frequently
train stats after 65728 examples: {'rewards_train/chosen': '0.11262', 'rewards_train/rejected': '-6.9083', 'rewards_train/margins': '7.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18994', 'examples_per_second': '6.1511', 'grad_norm': '5.125', 'counters/examples': 65728, 'counters/updates': 4108}
skipping logging after 65744 examples to avoid logging too frequently
skipping logging after 65760 examples to avoid logging too frequently
skipping logging after 65776 examples to avoid logging too frequently
train stats after 65792 examples: {'rewards_train/chosen': '0.53512', 'rewards_train/rejected': '-5.9197', 'rewards_train/margins': '6.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21918', 'examples_per_second': '5.3942', 'grad_norm': '4.875', 'counters/examples': 65792, 'counters/updates': 4112}
skipping logging after 65808 examples to avoid logging too frequently
skipping logging after 65824 examples to avoid logging too frequently
skipping logging after 65840 examples to avoid logging too frequently
train stats after 65856 examples: {'rewards_train/chosen': '0.33691', 'rewards_train/rejected': '-6.0371', 'rewards_train/margins': '6.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26923', 'examples_per_second': '4.0712', 'grad_norm': '4.5938', 'counters/examples': 65856, 'counters/updates': 4116}
skipping logging after 65872 examples to avoid logging too frequently
skipping logging after 65888 examples to avoid logging too frequently
skipping logging after 65904 examples to avoid logging too frequently
train stats after 65920 examples: {'rewards_train/chosen': '0.31406', 'rewards_train/rejected': '-7.1721', 'rewards_train/margins': '7.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21777', 'examples_per_second': '4.1447', 'grad_norm': '5.4688', 'counters/examples': 65920, 'counters/updates': 4120}
skipping logging after 65936 examples to avoid logging too frequently
skipping logging after 65952 examples to avoid logging too frequently
skipping logging after 65968 examples to avoid logging too frequently
train stats after 65984 examples: {'rewards_train/chosen': '0.49126', 'rewards_train/rejected': '-4.8178', 'rewards_train/margins': '5.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23163', 'examples_per_second': '4.2709', 'grad_norm': '4.4688', 'counters/examples': 65984, 'counters/updates': 4124}
skipping logging after 66000 examples to avoid logging too frequently
skipping logging after 66016 examples to avoid logging too frequently
skipping logging after 66032 examples to avoid logging too frequently
train stats after 66048 examples: {'rewards_train/chosen': '0.26096', 'rewards_train/rejected': '-5.3085', 'rewards_train/margins': '5.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24048', 'examples_per_second': '5.336', 'grad_norm': '4.9062', 'counters/examples': 66048, 'counters/updates': 4128}
skipping logging after 66064 examples to avoid logging too frequently
skipping logging after 66080 examples to avoid logging too frequently
skipping logging after 66096 examples to avoid logging too frequently
train stats after 66112 examples: {'rewards_train/chosen': '0.57858', 'rewards_train/rejected': '-5.4663', 'rewards_train/margins': '5.9961', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28119', 'examples_per_second': '5.2178', 'grad_norm': '5.625', 'counters/examples': 66112, 'counters/updates': 4132}
skipping logging after 66128 examples to avoid logging too frequently
skipping logging after 66144 examples to avoid logging too frequently
skipping logging after 66160 examples to avoid logging too frequently
train stats after 66176 examples: {'rewards_train/chosen': '0.058852', 'rewards_train/rejected': '-4.5062', 'rewards_train/margins': '4.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2934', 'examples_per_second': '4.0359', 'grad_norm': '4.7812', 'counters/examples': 66176, 'counters/updates': 4136}
skipping logging after 66192 examples to avoid logging too frequently
skipping logging after 66208 examples to avoid logging too frequently
skipping logging after 66224 examples to avoid logging too frequently
train stats after 66240 examples: {'rewards_train/chosen': '0.32605', 'rewards_train/rejected': '-4.8135', 'rewards_train/margins': '5.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26392', 'examples_per_second': '5.648', 'grad_norm': '5.4062', 'counters/examples': 66240, 'counters/updates': 4140}
skipping logging after 66256 examples to avoid logging too frequently
skipping logging after 66272 examples to avoid logging too frequently
skipping logging after 66288 examples to avoid logging too frequently
train stats after 66304 examples: {'rewards_train/chosen': '0.62628', 'rewards_train/rejected': '-5.4337', 'rewards_train/margins': '5.9453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2229', 'examples_per_second': '5.2536', 'grad_norm': '5.1562', 'counters/examples': 66304, 'counters/updates': 4144}
skipping logging after 66320 examples to avoid logging too frequently
skipping logging after 66336 examples to avoid logging too frequently
skipping logging after 66352 examples to avoid logging too frequently
train stats after 66368 examples: {'rewards_train/chosen': '0.32342', 'rewards_train/rejected': '-5.4747', 'rewards_train/margins': '5.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22961', 'examples_per_second': '5.0606', 'grad_norm': '4.1875', 'counters/examples': 66368, 'counters/updates': 4148}
skipping logging after 66384 examples to avoid logging too frequently
skipping logging after 66400 examples to avoid logging too frequently
skipping logging after 66416 examples to avoid logging too frequently
train stats after 66432 examples: {'rewards_train/chosen': '0.5312', 'rewards_train/rejected': '-5.2295', 'rewards_train/margins': '5.7422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21289', 'examples_per_second': '4.4725', 'grad_norm': '4.9375', 'counters/examples': 66432, 'counters/updates': 4152}
skipping logging after 66448 examples to avoid logging too frequently
skipping logging after 66464 examples to avoid logging too frequently
skipping logging after 66480 examples to avoid logging too frequently
train stats after 66496 examples: {'rewards_train/chosen': '0.73591', 'rewards_train/rejected': '-5.8539', 'rewards_train/margins': '6.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19385', 'examples_per_second': '6.1592', 'grad_norm': '4.9375', 'counters/examples': 66496, 'counters/updates': 4156}
skipping logging after 66512 examples to avoid logging too frequently
skipping logging after 66528 examples to avoid logging too frequently
skipping logging after 66544 examples to avoid logging too frequently
train stats after 66560 examples: {'rewards_train/chosen': '0.57599', 'rewards_train/rejected': '-6.213', 'rewards_train/margins': '6.7578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22357', 'examples_per_second': '4.0131', 'grad_norm': '5.8438', 'counters/examples': 66560, 'counters/updates': 4160}
skipping logging after 66576 examples to avoid logging too frequently
skipping logging after 66592 examples to avoid logging too frequently
skipping logging after 66608 examples to avoid logging too frequently
train stats after 66624 examples: {'rewards_train/chosen': '0.57223', 'rewards_train/rejected': '-5.2192', 'rewards_train/margins': '5.8945', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21472', 'examples_per_second': '5.5726', 'grad_norm': '5.4062', 'counters/examples': 66624, 'counters/updates': 4164}
skipping logging after 66640 examples to avoid logging too frequently
skipping logging after 66656 examples to avoid logging too frequently
skipping logging after 66672 examples to avoid logging too frequently
train stats after 66688 examples: {'rewards_train/chosen': '0.46848', 'rewards_train/rejected': '-5.8374', 'rewards_train/margins': '6.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19843', 'examples_per_second': '4.8982', 'grad_norm': '4.875', 'counters/examples': 66688, 'counters/updates': 4168}
skipping logging after 66704 examples to avoid logging too frequently
skipping logging after 66720 examples to avoid logging too frequently
skipping logging after 66736 examples to avoid logging too frequently
train stats after 66752 examples: {'rewards_train/chosen': '0.43532', 'rewards_train/rejected': '-5.2701', 'rewards_train/margins': '5.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20001', 'examples_per_second': '4.9029', 'grad_norm': '5.0938', 'counters/examples': 66752, 'counters/updates': 4172}
skipping logging after 66768 examples to avoid logging too frequently
skipping logging after 66784 examples to avoid logging too frequently
skipping logging after 66800 examples to avoid logging too frequently
train stats after 66816 examples: {'rewards_train/chosen': '0.45961', 'rewards_train/rejected': '-5.2238', 'rewards_train/margins': '5.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24414', 'examples_per_second': '5.2043', 'grad_norm': '4.9375', 'counters/examples': 66816, 'counters/updates': 4176}
skipping logging after 66832 examples to avoid logging too frequently
skipping logging after 66848 examples to avoid logging too frequently
skipping logging after 66864 examples to avoid logging too frequently
train stats after 66880 examples: {'rewards_train/chosen': '-0.021605', 'rewards_train/rejected': '-4.8196', 'rewards_train/margins': '4.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29224', 'examples_per_second': '5.1274', 'grad_norm': '5.7188', 'counters/examples': 66880, 'counters/updates': 4180}
skipping logging after 66896 examples to avoid logging too frequently
skipping logging after 66912 examples to avoid logging too frequently
skipping logging after 66928 examples to avoid logging too frequently
train stats after 66944 examples: {'rewards_train/chosen': '0.4617', 'rewards_train/rejected': '-5.2885', 'rewards_train/margins': '5.7031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22302', 'examples_per_second': '5.327', 'grad_norm': '4.8125', 'counters/examples': 66944, 'counters/updates': 4184}
skipping logging after 66960 examples to avoid logging too frequently
skipping logging after 66976 examples to avoid logging too frequently
skipping logging after 66992 examples to avoid logging too frequently
train stats after 67008 examples: {'rewards_train/chosen': '0.18492', 'rewards_train/rejected': '-6.7307', 'rewards_train/margins': '6.9453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19537', 'examples_per_second': '5.2926', 'grad_norm': '4.625', 'counters/examples': 67008, 'counters/updates': 4188}
skipping logging after 67024 examples to avoid logging too frequently
skipping logging after 67040 examples to avoid logging too frequently
skipping logging after 67056 examples to avoid logging too frequently
train stats after 67072 examples: {'rewards_train/chosen': '0.6183', 'rewards_train/rejected': '-5.107', 'rewards_train/margins': '5.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17175', 'examples_per_second': '5.6112', 'grad_norm': '4.5625', 'counters/examples': 67072, 'counters/updates': 4192}
skipping logging after 67088 examples to avoid logging too frequently
skipping logging after 67104 examples to avoid logging too frequently
skipping logging after 67120 examples to avoid logging too frequently
train stats after 67136 examples: {'rewards_train/chosen': '0.21453', 'rewards_train/rejected': '-6.6213', 'rewards_train/margins': '6.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21552', 'examples_per_second': '4.8396', 'grad_norm': '5.5', 'counters/examples': 67136, 'counters/updates': 4196}
skipping logging after 67152 examples to avoid logging too frequently
skipping logging after 67168 examples to avoid logging too frequently
skipping logging after 67184 examples to avoid logging too frequently
train stats after 67200 examples: {'rewards_train/chosen': '-0.11328', 'rewards_train/rejected': '-6.2371', 'rewards_train/margins': '5.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24341', 'examples_per_second': '6.278', 'grad_norm': '4.625', 'counters/examples': 67200, 'counters/updates': 4200}
skipping logging after 67216 examples to avoid logging too frequently
skipping logging after 67232 examples to avoid logging too frequently
skipping logging after 67248 examples to avoid logging too frequently
train stats after 67264 examples: {'rewards_train/chosen': '0.15417', 'rewards_train/rejected': '-4.8743', 'rewards_train/margins': '5.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26801', 'examples_per_second': '5.537', 'grad_norm': '5.6875', 'counters/examples': 67264, 'counters/updates': 4204}
skipping logging after 67280 examples to avoid logging too frequently
skipping logging after 67296 examples to avoid logging too frequently
skipping logging after 67312 examples to avoid logging too frequently
train stats after 67328 examples: {'rewards_train/chosen': '0.6759', 'rewards_train/rejected': '-5.5874', 'rewards_train/margins': '6.4531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23206', 'examples_per_second': '5.452', 'grad_norm': '4.2812', 'counters/examples': 67328, 'counters/updates': 4208}
skipping logging after 67344 examples to avoid logging too frequently
skipping logging after 67360 examples to avoid logging too frequently
skipping logging after 67376 examples to avoid logging too frequently
train stats after 67392 examples: {'rewards_train/chosen': '0.17736', 'rewards_train/rejected': '-5.7931', 'rewards_train/margins': '5.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28308', 'examples_per_second': '4.6833', 'grad_norm': '5.6875', 'counters/examples': 67392, 'counters/updates': 4212}
skipping logging after 67408 examples to avoid logging too frequently
skipping logging after 67424 examples to avoid logging too frequently
skipping logging after 67440 examples to avoid logging too frequently
train stats after 67456 examples: {'rewards_train/chosen': '0.48423', 'rewards_train/rejected': '-4.5837', 'rewards_train/margins': '5.1719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2674', 'examples_per_second': '5.4041', 'grad_norm': '4.7188', 'counters/examples': 67456, 'counters/updates': 4216}
skipping logging after 67472 examples to avoid logging too frequently
skipping logging after 67488 examples to avoid logging too frequently
skipping logging after 67504 examples to avoid logging too frequently
train stats after 67520 examples: {'rewards_train/chosen': '0.662', 'rewards_train/rejected': '-5.0162', 'rewards_train/margins': '5.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21552', 'examples_per_second': '4.7319', 'grad_norm': '5.1875', 'counters/examples': 67520, 'counters/updates': 4220}
skipping logging after 67536 examples to avoid logging too frequently
skipping logging after 67552 examples to avoid logging too frequently
skipping logging after 67568 examples to avoid logging too frequently
train stats after 67584 examples: {'rewards_train/chosen': '0.57864', 'rewards_train/rejected': '-4.6472', 'rewards_train/margins': '5.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24005', 'examples_per_second': '5.4577', 'grad_norm': '4.375', 'counters/examples': 67584, 'counters/updates': 4224}
skipping logging after 67600 examples to avoid logging too frequently
skipping logging after 67616 examples to avoid logging too frequently
skipping logging after 67632 examples to avoid logging too frequently
train stats after 67648 examples: {'rewards_train/chosen': '0.45768', 'rewards_train/rejected': '-4.5532', 'rewards_train/margins': '5.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23694', 'examples_per_second': '4.2794', 'grad_norm': '5.0938', 'counters/examples': 67648, 'counters/updates': 4228}
skipping logging after 67664 examples to avoid logging too frequently
skipping logging after 67680 examples to avoid logging too frequently
skipping logging after 67696 examples to avoid logging too frequently
train stats after 67712 examples: {'rewards_train/chosen': '0.41521', 'rewards_train/rejected': '-5.0668', 'rewards_train/margins': '5.3945', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23633', 'examples_per_second': '6.6646', 'grad_norm': '4.5625', 'counters/examples': 67712, 'counters/updates': 4232}
skipping logging after 67728 examples to avoid logging too frequently
skipping logging after 67744 examples to avoid logging too frequently
skipping logging after 67760 examples to avoid logging too frequently
train stats after 67776 examples: {'rewards_train/chosen': '0.48221', 'rewards_train/rejected': '-5.1424', 'rewards_train/margins': '5.4219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24048', 'examples_per_second': '5.3284', 'grad_norm': '4.4375', 'counters/examples': 67776, 'counters/updates': 4236}
skipping logging after 67792 examples to avoid logging too frequently
skipping logging after 67808 examples to avoid logging too frequently
skipping logging after 67824 examples to avoid logging too frequently
train stats after 67840 examples: {'rewards_train/chosen': '0.25665', 'rewards_train/rejected': '-5.7992', 'rewards_train/margins': '5.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27264', 'examples_per_second': '5.2953', 'grad_norm': '4.9062', 'counters/examples': 67840, 'counters/updates': 4240}
skipping logging after 67856 examples to avoid logging too frequently
skipping logging after 67872 examples to avoid logging too frequently
skipping logging after 67888 examples to avoid logging too frequently
train stats after 67904 examples: {'rewards_train/chosen': '0.18671', 'rewards_train/rejected': '-5.8715', 'rewards_train/margins': '6.0547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24536', 'examples_per_second': '6.0952', 'grad_norm': '4.3438', 'counters/examples': 67904, 'counters/updates': 4244}
skipping logging after 67920 examples to avoid logging too frequently
skipping logging after 67936 examples to avoid logging too frequently
skipping logging after 67952 examples to avoid logging too frequently
train stats after 67968 examples: {'rewards_train/chosen': '0.32278', 'rewards_train/rejected': '-5.4262', 'rewards_train/margins': '5.7422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24323', 'examples_per_second': '5.9445', 'grad_norm': '5', 'counters/examples': 67968, 'counters/updates': 4248}
skipping logging after 67984 examples to avoid logging too frequently
skipping logging after 68000 examples to avoid logging too frequently
Running evaluation after 68000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:47,  1.54s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:41,  1.37s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:35,  1.23s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.47s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.68s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.49s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:34,  1.37s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.49s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.22s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.31s/it]
eval after 68000: {'rewards_eval/chosen': '-5.1961', 'rewards_eval/rejected': '-5.6185', 'rewards_eval/margins': '0.31299', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46448'}
skipping logging after 68016 examples to avoid logging too frequently
train stats after 68032 examples: {'rewards_train/chosen': '0.48918', 'rewards_train/rejected': '-6.0647', 'rewards_train/margins': '6.6641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23969', 'examples_per_second': '5.1475', 'grad_norm': '5.4375', 'counters/examples': 68032, 'counters/updates': 4252}
skipping logging after 68048 examples to avoid logging too frequently
skipping logging after 68064 examples to avoid logging too frequently
skipping logging after 68080 examples to avoid logging too frequently
train stats after 68096 examples: {'rewards_train/chosen': '0.27946', 'rewards_train/rejected': '-4.7439', 'rewards_train/margins': '5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.31183', 'examples_per_second': '4.3681', 'grad_norm': '5.5312', 'counters/examples': 68096, 'counters/updates': 4256}
skipping logging after 68112 examples to avoid logging too frequently
skipping logging after 68128 examples to avoid logging too frequently
skipping logging after 68144 examples to avoid logging too frequently
train stats after 68160 examples: {'rewards_train/chosen': '0.4368', 'rewards_train/rejected': '-5.9469', 'rewards_train/margins': '6.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22217', 'examples_per_second': '4.7607', 'grad_norm': '4.7812', 'counters/examples': 68160, 'counters/updates': 4260}
skipping logging after 68176 examples to avoid logging too frequently
skipping logging after 68192 examples to avoid logging too frequently
skipping logging after 68208 examples to avoid logging too frequently
train stats after 68224 examples: {'rewards_train/chosen': '0.67976', 'rewards_train/rejected': '-5.5198', 'rewards_train/margins': '6.0977', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23914', 'examples_per_second': '4.524', 'grad_norm': '4.8125', 'counters/examples': 68224, 'counters/updates': 4264}
skipping logging after 68240 examples to avoid logging too frequently
skipping logging after 68256 examples to avoid logging too frequently
skipping logging after 68272 examples to avoid logging too frequently
train stats after 68288 examples: {'rewards_train/chosen': '0.41022', 'rewards_train/rejected': '-6.1043', 'rewards_train/margins': '6.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20782', 'examples_per_second': '5.3859', 'grad_norm': '4.5', 'counters/examples': 68288, 'counters/updates': 4268}
skipping logging after 68304 examples to avoid logging too frequently
skipping logging after 68320 examples to avoid logging too frequently
skipping logging after 68336 examples to avoid logging too frequently
train stats after 68352 examples: {'rewards_train/chosen': '0.513', 'rewards_train/rejected': '-4.3603', 'rewards_train/margins': '4.9453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26324', 'examples_per_second': '5.6549', 'grad_norm': '4.2812', 'counters/examples': 68352, 'counters/updates': 4272}
skipping logging after 68368 examples to avoid logging too frequently
skipping logging after 68384 examples to avoid logging too frequently
skipping logging after 68400 examples to avoid logging too frequently
train stats after 68416 examples: {'rewards_train/chosen': '0.13883', 'rewards_train/rejected': '-5.4087', 'rewards_train/margins': '5.6602', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24475', 'examples_per_second': '5.4516', 'grad_norm': '4.5312', 'counters/examples': 68416, 'counters/updates': 4276}
skipping logging after 68432 examples to avoid logging too frequently
skipping logging after 68448 examples to avoid logging too frequently
skipping logging after 68464 examples to avoid logging too frequently
train stats after 68480 examples: {'rewards_train/chosen': '0.18666', 'rewards_train/rejected': '-6.4871', 'rewards_train/margins': '7.375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26624', 'examples_per_second': '4.8202', 'grad_norm': '4.7812', 'counters/examples': 68480, 'counters/updates': 4280}
skipping logging after 68496 examples to avoid logging too frequently
skipping logging after 68512 examples to avoid logging too frequently
skipping logging after 68528 examples to avoid logging too frequently
train stats after 68544 examples: {'rewards_train/chosen': '0.32854', 'rewards_train/rejected': '-5.5741', 'rewards_train/margins': '5.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24817', 'examples_per_second': '4.8875', 'grad_norm': '5.7188', 'counters/examples': 68544, 'counters/updates': 4284}
skipping logging after 68560 examples to avoid logging too frequently
skipping logging after 68576 examples to avoid logging too frequently
skipping logging after 68592 examples to avoid logging too frequently
train stats after 68608 examples: {'rewards_train/chosen': '0.43927', 'rewards_train/rejected': '-6.2314', 'rewards_train/margins': '9.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27039', 'examples_per_second': '5.2855', 'grad_norm': '5.5625', 'counters/examples': 68608, 'counters/updates': 4288}
skipping logging after 68624 examples to avoid logging too frequently
skipping logging after 68640 examples to avoid logging too frequently
skipping logging after 68656 examples to avoid logging too frequently
train stats after 68672 examples: {'rewards_train/chosen': '0.42672', 'rewards_train/rejected': '-5.2812', 'rewards_train/margins': '5.4805', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24811', 'examples_per_second': '5.875', 'grad_norm': '4.5', 'counters/examples': 68672, 'counters/updates': 4292}
skipping logging after 68688 examples to avoid logging too frequently
skipping logging after 68704 examples to avoid logging too frequently
skipping logging after 68720 examples to avoid logging too frequently
train stats after 68736 examples: {'rewards_train/chosen': '0.39714', 'rewards_train/rejected': '-5.5772', 'rewards_train/margins': '6.1836', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26038', 'examples_per_second': '4.3368', 'grad_norm': '5.5938', 'counters/examples': 68736, 'counters/updates': 4296}
skipping logging after 68752 examples to avoid logging too frequently
skipping logging after 68768 examples to avoid logging too frequently
skipping logging after 68784 examples to avoid logging too frequently
train stats after 68800 examples: {'rewards_train/chosen': '0.61432', 'rewards_train/rejected': '-7.0091', 'rewards_train/margins': '7.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20184', 'examples_per_second': '4.5569', 'grad_norm': '4.375', 'counters/examples': 68800, 'counters/updates': 4300}
skipping logging after 68816 examples to avoid logging too frequently
skipping logging after 68832 examples to avoid logging too frequently
skipping logging after 68848 examples to avoid logging too frequently
train stats after 68864 examples: {'rewards_train/chosen': '0.098995', 'rewards_train/rejected': '-6.9665', 'rewards_train/margins': '6.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22302', 'examples_per_second': '6.1305', 'grad_norm': '3.8594', 'counters/examples': 68864, 'counters/updates': 4304}
skipping logging after 68880 examples to avoid logging too frequently
skipping logging after 68896 examples to avoid logging too frequently
skipping logging after 68912 examples to avoid logging too frequently
train stats after 68928 examples: {'rewards_train/chosen': '0.3759', 'rewards_train/rejected': '-5.3762', 'rewards_train/margins': '5.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1983', 'examples_per_second': '4.9324', 'grad_norm': '4.3438', 'counters/examples': 68928, 'counters/updates': 4308}
skipping logging after 68944 examples to avoid logging too frequently
skipping logging after 68960 examples to avoid logging too frequently
skipping logging after 68976 examples to avoid logging too frequently
train stats after 68992 examples: {'rewards_train/chosen': '0.60386', 'rewards_train/rejected': '-6.5167', 'rewards_train/margins': '6.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21851', 'examples_per_second': '5.0491', 'grad_norm': '4.25', 'counters/examples': 68992, 'counters/updates': 4312}
skipping logging after 69008 examples to avoid logging too frequently
skipping logging after 69024 examples to avoid logging too frequently
skipping logging after 69040 examples to avoid logging too frequently
train stats after 69056 examples: {'rewards_train/chosen': '0.67194', 'rewards_train/rejected': '-5.3617', 'rewards_train/margins': '6.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20911', 'examples_per_second': '6.1144', 'grad_norm': '4.8438', 'counters/examples': 69056, 'counters/updates': 4316}
skipping logging after 69072 examples to avoid logging too frequently
skipping logging after 69088 examples to avoid logging too frequently
skipping logging after 69104 examples to avoid logging too frequently
train stats after 69120 examples: {'rewards_train/chosen': '0.43144', 'rewards_train/rejected': '-5.6511', 'rewards_train/margins': '6.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21747', 'examples_per_second': '6.0056', 'grad_norm': '4.8125', 'counters/examples': 69120, 'counters/updates': 4320}
skipping logging after 69136 examples to avoid logging too frequently
skipping logging after 69152 examples to avoid logging too frequently
skipping logging after 69168 examples to avoid logging too frequently
train stats after 69184 examples: {'rewards_train/chosen': '0.49529', 'rewards_train/rejected': '-6.1392', 'rewards_train/margins': '6.7266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23474', 'examples_per_second': '4.8561', 'grad_norm': '6.0938', 'counters/examples': 69184, 'counters/updates': 4324}
skipping logging after 69200 examples to avoid logging too frequently
skipping logging after 69216 examples to avoid logging too frequently
skipping logging after 69232 examples to avoid logging too frequently
train stats after 69248 examples: {'rewards_train/chosen': '0.42993', 'rewards_train/rejected': '-5.8886', 'rewards_train/margins': '6.5781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20325', 'examples_per_second': '5.3351', 'grad_norm': '4.3438', 'counters/examples': 69248, 'counters/updates': 4328}
skipping logging after 69264 examples to avoid logging too frequently
skipping logging after 69280 examples to avoid logging too frequently
skipping logging after 69296 examples to avoid logging too frequently
train stats after 69312 examples: {'rewards_train/chosen': '0.29765', 'rewards_train/rejected': '-4.5222', 'rewards_train/margins': '4.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25189', 'examples_per_second': '5.7716', 'grad_norm': '5.4688', 'counters/examples': 69312, 'counters/updates': 4332}
skipping logging after 69328 examples to avoid logging too frequently
skipping logging after 69344 examples to avoid logging too frequently
skipping logging after 69360 examples to avoid logging too frequently
train stats after 69376 examples: {'rewards_train/chosen': '0.34548', 'rewards_train/rejected': '-7.2693', 'rewards_train/margins': '7.8125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22571', 'examples_per_second': '5.2418', 'grad_norm': '4.875', 'counters/examples': 69376, 'counters/updates': 4336}
skipping logging after 69392 examples to avoid logging too frequently
skipping logging after 69408 examples to avoid logging too frequently
skipping logging after 69424 examples to avoid logging too frequently
train stats after 69440 examples: {'rewards_train/chosen': '0.5103', 'rewards_train/rejected': '-5.9295', 'rewards_train/margins': '6.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25085', 'examples_per_second': '4.4024', 'grad_norm': '4.875', 'counters/examples': 69440, 'counters/updates': 4340}
skipping logging after 69456 examples to avoid logging too frequently
skipping logging after 69472 examples to avoid logging too frequently
skipping logging after 69488 examples to avoid logging too frequently
train stats after 69504 examples: {'rewards_train/chosen': '0.66605', 'rewards_train/rejected': '-4.4693', 'rewards_train/margins': '4.9766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23041', 'examples_per_second': '5.8543', 'grad_norm': '4.7188', 'counters/examples': 69504, 'counters/updates': 4344}
skipping logging after 69520 examples to avoid logging too frequently
skipping logging after 69536 examples to avoid logging too frequently
skipping logging after 69552 examples to avoid logging too frequently
train stats after 69568 examples: {'rewards_train/chosen': '0.60321', 'rewards_train/rejected': '-4.9128', 'rewards_train/margins': '5.4609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21545', 'examples_per_second': '6.9604', 'grad_norm': '4.3438', 'counters/examples': 69568, 'counters/updates': 4348}
skipping logging after 69584 examples to avoid logging too frequently
skipping logging after 69600 examples to avoid logging too frequently
skipping logging after 69616 examples to avoid logging too frequently
train stats after 69632 examples: {'rewards_train/chosen': '0.42559', 'rewards_train/rejected': '-5.5284', 'rewards_train/margins': '5.9766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25256', 'examples_per_second': '4.7706', 'grad_norm': '5.9062', 'counters/examples': 69632, 'counters/updates': 4352}
skipping logging after 69648 examples to avoid logging too frequently
skipping logging after 69664 examples to avoid logging too frequently
skipping logging after 69680 examples to avoid logging too frequently
train stats after 69696 examples: {'rewards_train/chosen': '0.58465', 'rewards_train/rejected': '-5.5451', 'rewards_train/margins': '6.168', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19507', 'examples_per_second': '5.2432', 'grad_norm': '6.3125', 'counters/examples': 69696, 'counters/updates': 4356}
skipping logging after 69712 examples to avoid logging too frequently
skipping logging after 69728 examples to avoid logging too frequently
skipping logging after 69744 examples to avoid logging too frequently
train stats after 69760 examples: {'rewards_train/chosen': '0.1897', 'rewards_train/rejected': '-5.4763', 'rewards_train/margins': '5.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30243', 'examples_per_second': '4.6055', 'grad_norm': '6.0312', 'counters/examples': 69760, 'counters/updates': 4360}
skipping logging after 69776 examples to avoid logging too frequently
skipping logging after 69792 examples to avoid logging too frequently
skipping logging after 69808 examples to avoid logging too frequently
train stats after 69824 examples: {'rewards_train/chosen': '0.083259', 'rewards_train/rejected': '-5.7768', 'rewards_train/margins': '5.9297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28204', 'examples_per_second': '5.3409', 'grad_norm': '5.4062', 'counters/examples': 69824, 'counters/updates': 4364}
skipping logging after 69840 examples to avoid logging too frequently
skipping logging after 69856 examples to avoid logging too frequently
skipping logging after 69872 examples to avoid logging too frequently
train stats after 69888 examples: {'rewards_train/chosen': '0.069141', 'rewards_train/rejected': '-5.4531', 'rewards_train/margins': '5.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24762', 'examples_per_second': '4.4008', 'grad_norm': '4.8125', 'counters/examples': 69888, 'counters/updates': 4368}
skipping logging after 69904 examples to avoid logging too frequently
skipping logging after 69920 examples to avoid logging too frequently
skipping logging after 69936 examples to avoid logging too frequently
train stats after 69952 examples: {'rewards_train/chosen': '0.66574', 'rewards_train/rejected': '-4.3859', 'rewards_train/margins': '5.1133', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22595', 'examples_per_second': '5.5912', 'grad_norm': '4.875', 'counters/examples': 69952, 'counters/updates': 4372}
skipping logging after 69968 examples to avoid logging too frequently
skipping logging after 69984 examples to avoid logging too frequently
skipping logging after 70000 examples to avoid logging too frequently
train stats after 70016 examples: {'rewards_train/chosen': '0.40892', 'rewards_train/rejected': '-5.4904', 'rewards_train/margins': '5.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23291', 'examples_per_second': '6.5495', 'grad_norm': '5.625', 'counters/examples': 70016, 'counters/updates': 4376}
skipping logging after 70032 examples to avoid logging too frequently
skipping logging after 70048 examples to avoid logging too frequently
skipping logging after 70064 examples to avoid logging too frequently
train stats after 70080 examples: {'rewards_train/chosen': '0.49688', 'rewards_train/rejected': '-5.8052', 'rewards_train/margins': '6.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18439', 'examples_per_second': '4.3116', 'grad_norm': '4.25', 'counters/examples': 70080, 'counters/updates': 4380}
skipping logging after 70096 examples to avoid logging too frequently
skipping logging after 70112 examples to avoid logging too frequently
skipping logging after 70128 examples to avoid logging too frequently
train stats after 70144 examples: {'rewards_train/chosen': '0.5333', 'rewards_train/rejected': '-4.6252', 'rewards_train/margins': '5.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26978', 'examples_per_second': '5.823', 'grad_norm': '5.5', 'counters/examples': 70144, 'counters/updates': 4384}
skipping logging after 70160 examples to avoid logging too frequently
skipping logging after 70176 examples to avoid logging too frequently
skipping logging after 70192 examples to avoid logging too frequently
train stats after 70208 examples: {'rewards_train/chosen': '0.17828', 'rewards_train/rejected': '-6.1369', 'rewards_train/margins': '6.6562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25281', 'examples_per_second': '5.0244', 'grad_norm': '5.2812', 'counters/examples': 70208, 'counters/updates': 4388}
skipping logging after 70224 examples to avoid logging too frequently
skipping logging after 70240 examples to avoid logging too frequently
skipping logging after 70256 examples to avoid logging too frequently
train stats after 70272 examples: {'rewards_train/chosen': '0.22755', 'rewards_train/rejected': '-5.5762', 'rewards_train/margins': '5.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26068', 'examples_per_second': '5.8964', 'grad_norm': '5.5312', 'counters/examples': 70272, 'counters/updates': 4392}
skipping logging after 70288 examples to avoid logging too frequently
skipping logging after 70304 examples to avoid logging too frequently
skipping logging after 70320 examples to avoid logging too frequently
train stats after 70336 examples: {'rewards_train/chosen': '0.53867', 'rewards_train/rejected': '-6.8845', 'rewards_train/margins': '7.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21558', 'examples_per_second': '4.3287', 'grad_norm': '4.625', 'counters/examples': 70336, 'counters/updates': 4396}
skipping logging after 70352 examples to avoid logging too frequently
skipping logging after 70368 examples to avoid logging too frequently
skipping logging after 70384 examples to avoid logging too frequently
train stats after 70400 examples: {'rewards_train/chosen': '0.077106', 'rewards_train/rejected': '-5.1773', 'rewards_train/margins': '5.418', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23779', 'examples_per_second': '5.2606', 'grad_norm': '4.8125', 'counters/examples': 70400, 'counters/updates': 4400}
skipping logging after 70416 examples to avoid logging too frequently
skipping logging after 70432 examples to avoid logging too frequently
skipping logging after 70448 examples to avoid logging too frequently
train stats after 70464 examples: {'rewards_train/chosen': '-0.084884', 'rewards_train/rejected': '-5.8524', 'rewards_train/margins': '5.3789', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28137', 'examples_per_second': '5.5939', 'grad_norm': '5.0312', 'counters/examples': 70464, 'counters/updates': 4404}
skipping logging after 70480 examples to avoid logging too frequently
skipping logging after 70496 examples to avoid logging too frequently
skipping logging after 70512 examples to avoid logging too frequently
train stats after 70528 examples: {'rewards_train/chosen': '0.45068', 'rewards_train/rejected': '-5.6777', 'rewards_train/margins': '6.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18793', 'examples_per_second': '5.5499', 'grad_norm': '3.7188', 'counters/examples': 70528, 'counters/updates': 4408}
skipping logging after 70544 examples to avoid logging too frequently
skipping logging after 70560 examples to avoid logging too frequently
skipping logging after 70576 examples to avoid logging too frequently
train stats after 70592 examples: {'rewards_train/chosen': '0.43398', 'rewards_train/rejected': '-6.1008', 'rewards_train/margins': '6.6016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19934', 'examples_per_second': '4.6986', 'grad_norm': '4', 'counters/examples': 70592, 'counters/updates': 4412}
skipping logging after 70608 examples to avoid logging too frequently
skipping logging after 70624 examples to avoid logging too frequently
skipping logging after 70640 examples to avoid logging too frequently
train stats after 70656 examples: {'rewards_train/chosen': '0.39953', 'rewards_train/rejected': '-7.4885', 'rewards_train/margins': '7.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19135', 'examples_per_second': '5.0114', 'grad_norm': '4.8125', 'counters/examples': 70656, 'counters/updates': 4416}
skipping logging after 70672 examples to avoid logging too frequently
skipping logging after 70688 examples to avoid logging too frequently
skipping logging after 70704 examples to avoid logging too frequently
train stats after 70720 examples: {'rewards_train/chosen': '0.23726', 'rewards_train/rejected': '-6.5145', 'rewards_train/margins': '6.7578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23657', 'examples_per_second': '4.7155', 'grad_norm': '6.125', 'counters/examples': 70720, 'counters/updates': 4420}
skipping logging after 70736 examples to avoid logging too frequently
skipping logging after 70752 examples to avoid logging too frequently
skipping logging after 70768 examples to avoid logging too frequently
train stats after 70784 examples: {'rewards_train/chosen': '0.39795', 'rewards_train/rejected': '-5.4954', 'rewards_train/margins': '6', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27283', 'examples_per_second': '5.1947', 'grad_norm': '5.5938', 'counters/examples': 70784, 'counters/updates': 4424}
skipping logging after 70800 examples to avoid logging too frequently
skipping logging after 70816 examples to avoid logging too frequently
skipping logging after 70832 examples to avoid logging too frequently
train stats after 70848 examples: {'rewards_train/chosen': '0.51535', 'rewards_train/rejected': '-4.8458', 'rewards_train/margins': '5.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23694', 'examples_per_second': '5.4904', 'grad_norm': '5.0938', 'counters/examples': 70848, 'counters/updates': 4428}
skipping logging after 70864 examples to avoid logging too frequently
skipping logging after 70880 examples to avoid logging too frequently
skipping logging after 70896 examples to avoid logging too frequently
train stats after 70912 examples: {'rewards_train/chosen': '0.46396', 'rewards_train/rejected': '-5.0851', 'rewards_train/margins': '5.6328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20941', 'examples_per_second': '5.4559', 'grad_norm': '3.6875', 'counters/examples': 70912, 'counters/updates': 4432}
skipping logging after 70928 examples to avoid logging too frequently
skipping logging after 70944 examples to avoid logging too frequently
skipping logging after 70960 examples to avoid logging too frequently
train stats after 70976 examples: {'rewards_train/chosen': '0.42458', 'rewards_train/rejected': '-5.807', 'rewards_train/margins': '6.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24048', 'examples_per_second': '4.4747', 'grad_norm': '4.625', 'counters/examples': 70976, 'counters/updates': 4436}
skipping logging after 70992 examples to avoid logging too frequently
skipping logging after 71008 examples to avoid logging too frequently
skipping logging after 71024 examples to avoid logging too frequently
train stats after 71040 examples: {'rewards_train/chosen': '0.6421', 'rewards_train/rejected': '-7.1909', 'rewards_train/margins': '7.8906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2099', 'examples_per_second': '5.1433', 'grad_norm': '4.5312', 'counters/examples': 71040, 'counters/updates': 4440}
skipping logging after 71056 examples to avoid logging too frequently
skipping logging after 71072 examples to avoid logging too frequently
skipping logging after 71088 examples to avoid logging too frequently
train stats after 71104 examples: {'rewards_train/chosen': '0.43479', 'rewards_train/rejected': '-4.4693', 'rewards_train/margins': '4.8672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24146', 'examples_per_second': '5.0594', 'grad_norm': '4.2812', 'counters/examples': 71104, 'counters/updates': 4444}
skipping logging after 71120 examples to avoid logging too frequently
skipping logging after 71136 examples to avoid logging too frequently
skipping logging after 71152 examples to avoid logging too frequently
train stats after 71168 examples: {'rewards_train/chosen': '0.086166', 'rewards_train/rejected': '-5.2456', 'rewards_train/margins': '5.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28192', 'examples_per_second': '6.4071', 'grad_norm': '5.1875', 'counters/examples': 71168, 'counters/updates': 4448}
skipping logging after 71184 examples to avoid logging too frequently
skipping logging after 71200 examples to avoid logging too frequently
skipping logging after 71216 examples to avoid logging too frequently
train stats after 71232 examples: {'rewards_train/chosen': '-0.31542', 'rewards_train/rejected': '-5.4707', 'rewards_train/margins': '5.0547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28119', 'examples_per_second': '5.6515', 'grad_norm': '4.9375', 'counters/examples': 71232, 'counters/updates': 4452}
skipping logging after 71248 examples to avoid logging too frequently
skipping logging after 71264 examples to avoid logging too frequently
skipping logging after 71280 examples to avoid logging too frequently
train stats after 71296 examples: {'rewards_train/chosen': '0.36977', 'rewards_train/rejected': '-5.2104', 'rewards_train/margins': '5.5273', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21063', 'examples_per_second': '4.1338', 'grad_norm': '4.5938', 'counters/examples': 71296, 'counters/updates': 4456}
skipping logging after 71312 examples to avoid logging too frequently
skipping logging after 71328 examples to avoid logging too frequently
skipping logging after 71344 examples to avoid logging too frequently
train stats after 71360 examples: {'rewards_train/chosen': '0.3238', 'rewards_train/rejected': '-5.5432', 'rewards_train/margins': '5.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24762', 'examples_per_second': '5.5075', 'grad_norm': '5.625', 'counters/examples': 71360, 'counters/updates': 4460}
skipping logging after 71376 examples to avoid logging too frequently
skipping logging after 71392 examples to avoid logging too frequently
skipping logging after 71408 examples to avoid logging too frequently
train stats after 71424 examples: {'rewards_train/chosen': '0.58835', 'rewards_train/rejected': '-5.405', 'rewards_train/margins': '5.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22144', 'examples_per_second': '5.4806', 'grad_norm': '4.7812', 'counters/examples': 71424, 'counters/updates': 4464}
skipping logging after 71440 examples to avoid logging too frequently
skipping logging after 71456 examples to avoid logging too frequently
skipping logging after 71472 examples to avoid logging too frequently
train stats after 71488 examples: {'rewards_train/chosen': '0.76326', 'rewards_train/rejected': '-5.8163', 'rewards_train/margins': '6.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21069', 'examples_per_second': '4.6242', 'grad_norm': '5.375', 'counters/examples': 71488, 'counters/updates': 4468}
skipping logging after 71504 examples to avoid logging too frequently
skipping logging after 71520 examples to avoid logging too frequently
skipping logging after 71536 examples to avoid logging too frequently
train stats after 71552 examples: {'rewards_train/chosen': '0.70481', 'rewards_train/rejected': '-5.6944', 'rewards_train/margins': '6.4609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18842', 'examples_per_second': '4.9791', 'grad_norm': '4.875', 'counters/examples': 71552, 'counters/updates': 4472}
skipping logging after 71568 examples to avoid logging too frequently
skipping logging after 71584 examples to avoid logging too frequently
skipping logging after 71600 examples to avoid logging too frequently
train stats after 71616 examples: {'rewards_train/chosen': '0.69166', 'rewards_train/rejected': '-5.9103', 'rewards_train/margins': '6.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19696', 'examples_per_second': '4.5407', 'grad_norm': '4.3438', 'counters/examples': 71616, 'counters/updates': 4476}
skipping logging after 71632 examples to avoid logging too frequently
skipping logging after 71648 examples to avoid logging too frequently
skipping logging after 71664 examples to avoid logging too frequently
train stats after 71680 examples: {'rewards_train/chosen': '0.3565', 'rewards_train/rejected': '-4.8674', 'rewards_train/margins': '5.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22034', 'examples_per_second': '5.4518', 'grad_norm': '4.5625', 'counters/examples': 71680, 'counters/updates': 4480}
skipping logging after 71696 examples to avoid logging too frequently
skipping logging after 71712 examples to avoid logging too frequently
skipping logging after 71728 examples to avoid logging too frequently
train stats after 71744 examples: {'rewards_train/chosen': '0.47464', 'rewards_train/rejected': '-5.9377', 'rewards_train/margins': '6.4609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26166', 'examples_per_second': '4.0854', 'grad_norm': '5.5625', 'counters/examples': 71744, 'counters/updates': 4484}
skipping logging after 71760 examples to avoid logging too frequently
skipping logging after 71776 examples to avoid logging too frequently
skipping logging after 71792 examples to avoid logging too frequently
train stats after 71808 examples: {'rewards_train/chosen': '0.35909', 'rewards_train/rejected': '-4.678', 'rewards_train/margins': '4.6094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23352', 'examples_per_second': '5.6186', 'grad_norm': '5.125', 'counters/examples': 71808, 'counters/updates': 4488}
skipping logging after 71824 examples to avoid logging too frequently
skipping logging after 71840 examples to avoid logging too frequently
skipping logging after 71856 examples to avoid logging too frequently
train stats after 71872 examples: {'rewards_train/chosen': '0.1809', 'rewards_train/rejected': '-5.8458', 'rewards_train/margins': '5.9297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25885', 'examples_per_second': '4.7535', 'grad_norm': '6.2812', 'counters/examples': 71872, 'counters/updates': 4492}
skipping logging after 71888 examples to avoid logging too frequently
skipping logging after 71904 examples to avoid logging too frequently
skipping logging after 71920 examples to avoid logging too frequently
train stats after 71936 examples: {'rewards_train/chosen': '0.65142', 'rewards_train/rejected': '-4.7165', 'rewards_train/margins': '5.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18463', 'examples_per_second': '4.6583', 'grad_norm': '4.5938', 'counters/examples': 71936, 'counters/updates': 4496}
skipping logging after 71952 examples to avoid logging too frequently
skipping logging after 71968 examples to avoid logging too frequently
skipping logging after 71984 examples to avoid logging too frequently
train stats after 72000 examples: {'rewards_train/chosen': '0.5122', 'rewards_train/rejected': '-5.2755', 'rewards_train/margins': '5.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20044', 'examples_per_second': '4.7963', 'grad_norm': '4.7188', 'counters/examples': 72000, 'counters/updates': 4500}
Running evaluation after 72000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.25s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.16s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:39,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.65s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.47s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:33,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.40s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:21<00:20,  1.28s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.20s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.31s/it]
eval after 72000: {'rewards_eval/chosen': '-5.4278', 'rewards_eval/rejected': '-5.7975', 'rewards_eval/margins': '0.26465', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46489'}
skipping logging after 72016 examples to avoid logging too frequently
skipping logging after 72032 examples to avoid logging too frequently
skipping logging after 72048 examples to avoid logging too frequently
train stats after 72064 examples: {'rewards_train/chosen': '0.28707', 'rewards_train/rejected': '-5.6037', 'rewards_train/margins': '5.668', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23206', 'examples_per_second': '5.3111', 'grad_norm': '4.6875', 'counters/examples': 72064, 'counters/updates': 4504}
skipping logging after 72080 examples to avoid logging too frequently
skipping logging after 72096 examples to avoid logging too frequently
skipping logging after 72112 examples to avoid logging too frequently
train stats after 72128 examples: {'rewards_train/chosen': '0.2303', 'rewards_train/rejected': '-7.0605', 'rewards_train/margins': '7.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20813', 'examples_per_second': '4.4126', 'grad_norm': '4.8125', 'counters/examples': 72128, 'counters/updates': 4508}
skipping logging after 72144 examples to avoid logging too frequently
skipping logging after 72160 examples to avoid logging too frequently
skipping logging after 72176 examples to avoid logging too frequently
train stats after 72192 examples: {'rewards_train/chosen': '0.21538', 'rewards_train/rejected': '-4.6363', 'rewards_train/margins': '4.8789', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2782', 'examples_per_second': '5.7197', 'grad_norm': '5.5625', 'counters/examples': 72192, 'counters/updates': 4512}
skipping logging after 72208 examples to avoid logging too frequently
skipping logging after 72224 examples to avoid logging too frequently
skipping logging after 72240 examples to avoid logging too frequently
train stats after 72256 examples: {'rewards_train/chosen': '0.8672', 'rewards_train/rejected': '-5.7849', 'rewards_train/margins': '6.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.15698', 'examples_per_second': '6.1395', 'grad_norm': '3.7031', 'counters/examples': 72256, 'counters/updates': 4516}
skipping logging after 72272 examples to avoid logging too frequently
skipping logging after 72288 examples to avoid logging too frequently
skipping logging after 72304 examples to avoid logging too frequently
train stats after 72320 examples: {'rewards_train/chosen': '0.52877', 'rewards_train/rejected': '-4.5308', 'rewards_train/margins': '5.0156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1972', 'examples_per_second': '5.416', 'grad_norm': '4.5625', 'counters/examples': 72320, 'counters/updates': 4520}
skipping logging after 72336 examples to avoid logging too frequently
skipping logging after 72352 examples to avoid logging too frequently
skipping logging after 72368 examples to avoid logging too frequently
train stats after 72384 examples: {'rewards_train/chosen': '0.43837', 'rewards_train/rejected': '-5.9952', 'rewards_train/margins': '6.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23291', 'examples_per_second': '5.0618', 'grad_norm': '4.4062', 'counters/examples': 72384, 'counters/updates': 4524}
skipping logging after 72400 examples to avoid logging too frequently
skipping logging after 72416 examples to avoid logging too frequently
skipping logging after 72432 examples to avoid logging too frequently
train stats after 72448 examples: {'rewards_train/chosen': '0.63014', 'rewards_train/rejected': '-5.2683', 'rewards_train/margins': '5.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22742', 'examples_per_second': '5.7441', 'grad_norm': '4.4375', 'counters/examples': 72448, 'counters/updates': 4528}
skipping logging after 72464 examples to avoid logging too frequently
skipping logging after 72480 examples to avoid logging too frequently
skipping logging after 72496 examples to avoid logging too frequently
train stats after 72512 examples: {'rewards_train/chosen': '0.63101', 'rewards_train/rejected': '-7.8131', 'rewards_train/margins': '8.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22821', 'examples_per_second': '5.2141', 'grad_norm': '4.7812', 'counters/examples': 72512, 'counters/updates': 4532}
skipping logging after 72528 examples to avoid logging too frequently
skipping logging after 72544 examples to avoid logging too frequently
skipping logging after 72560 examples to avoid logging too frequently
train stats after 72576 examples: {'rewards_train/chosen': '0.68025', 'rewards_train/rejected': '-5.0552', 'rewards_train/margins': '5.8672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24323', 'examples_per_second': '5.3713', 'grad_norm': '4.6562', 'counters/examples': 72576, 'counters/updates': 4536}
skipping logging after 72592 examples to avoid logging too frequently
skipping logging after 72608 examples to avoid logging too frequently
skipping logging after 72624 examples to avoid logging too frequently
train stats after 72640 examples: {'rewards_train/chosen': '0.26073', 'rewards_train/rejected': '-5.8731', 'rewards_train/margins': '6.4141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.16138', 'examples_per_second': '5.3278', 'grad_norm': '4.5', 'counters/examples': 72640, 'counters/updates': 4540}
skipping logging after 72656 examples to avoid logging too frequently
skipping logging after 72672 examples to avoid logging too frequently
skipping logging after 72688 examples to avoid logging too frequently
train stats after 72704 examples: {'rewards_train/chosen': '0.10946', 'rewards_train/rejected': '-4.7841', 'rewards_train/margins': '4.7266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2597', 'examples_per_second': '4.8265', 'grad_norm': '6.2188', 'counters/examples': 72704, 'counters/updates': 4544}
skipping logging after 72720 examples to avoid logging too frequently
skipping logging after 72736 examples to avoid logging too frequently
skipping logging after 72752 examples to avoid logging too frequently
train stats after 72768 examples: {'rewards_train/chosen': '0.48673', 'rewards_train/rejected': '-6.4646', 'rewards_train/margins': '6.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22443', 'examples_per_second': '5.1114', 'grad_norm': '5.5625', 'counters/examples': 72768, 'counters/updates': 4548}
skipping logging after 72784 examples to avoid logging too frequently
skipping logging after 72800 examples to avoid logging too frequently
skipping logging after 72816 examples to avoid logging too frequently
train stats after 72832 examples: {'rewards_train/chosen': '0.38645', 'rewards_train/rejected': '-4.9513', 'rewards_train/margins': '5.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27728', 'examples_per_second': '4.8416', 'grad_norm': '5.625', 'counters/examples': 72832, 'counters/updates': 4552}
skipping logging after 72848 examples to avoid logging too frequently
skipping logging after 72864 examples to avoid logging too frequently
skipping logging after 72880 examples to avoid logging too frequently
train stats after 72896 examples: {'rewards_train/chosen': '0.48687', 'rewards_train/rejected': '-5.617', 'rewards_train/margins': '6.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20935', 'examples_per_second': '5.8065', 'grad_norm': '4.4375', 'counters/examples': 72896, 'counters/updates': 4556}
skipping logging after 72912 examples to avoid logging too frequently
skipping logging after 72928 examples to avoid logging too frequently
skipping logging after 72944 examples to avoid logging too frequently
train stats after 72960 examples: {'rewards_train/chosen': '0.33477', 'rewards_train/rejected': '-7.0419', 'rewards_train/margins': '7.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24518', 'examples_per_second': '4.6261', 'grad_norm': '5.1875', 'counters/examples': 72960, 'counters/updates': 4560}
skipping logging after 72976 examples to avoid logging too frequently
skipping logging after 72992 examples to avoid logging too frequently
skipping logging after 73008 examples to avoid logging too frequently
train stats after 73024 examples: {'rewards_train/chosen': '0.48246', 'rewards_train/rejected': '-5.2474', 'rewards_train/margins': '5.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27563', 'examples_per_second': '5.6669', 'grad_norm': '5.0938', 'counters/examples': 73024, 'counters/updates': 4564}
skipping logging after 73040 examples to avoid logging too frequently
skipping logging after 73056 examples to avoid logging too frequently
skipping logging after 73072 examples to avoid logging too frequently
train stats after 73088 examples: {'rewards_train/chosen': '0.60153', 'rewards_train/rejected': '-5.2034', 'rewards_train/margins': '5.7109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21771', 'examples_per_second': '5.0625', 'grad_norm': '4.875', 'counters/examples': 73088, 'counters/updates': 4568}
skipping logging after 73104 examples to avoid logging too frequently
skipping logging after 73120 examples to avoid logging too frequently
skipping logging after 73136 examples to avoid logging too frequently
train stats after 73152 examples: {'rewards_train/chosen': '0.38507', 'rewards_train/rejected': '-5.3891', 'rewards_train/margins': '5.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27197', 'examples_per_second': '5.4894', 'grad_norm': '5.125', 'counters/examples': 73152, 'counters/updates': 4572}
skipping logging after 73168 examples to avoid logging too frequently
skipping logging after 73184 examples to avoid logging too frequently
skipping logging after 73200 examples to avoid logging too frequently
train stats after 73216 examples: {'rewards_train/chosen': '0.4348', 'rewards_train/rejected': '-4.1715', 'rewards_train/margins': '4.5508', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22839', 'examples_per_second': '5.5169', 'grad_norm': '5.125', 'counters/examples': 73216, 'counters/updates': 4576}
skipping logging after 73232 examples to avoid logging too frequently
skipping logging after 73248 examples to avoid logging too frequently
skipping logging after 73264 examples to avoid logging too frequently
train stats after 73280 examples: {'rewards_train/chosen': '0.30549', 'rewards_train/rejected': '-7.1924', 'rewards_train/margins': '7.7266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23602', 'examples_per_second': '5.6929', 'grad_norm': '4.9688', 'counters/examples': 73280, 'counters/updates': 4580}
skipping logging after 73296 examples to avoid logging too frequently
skipping logging after 73312 examples to avoid logging too frequently
skipping logging after 73328 examples to avoid logging too frequently
train stats after 73344 examples: {'rewards_train/chosen': '0.30265', 'rewards_train/rejected': '-4.3618', 'rewards_train/margins': '4.707', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27124', 'examples_per_second': '5.5619', 'grad_norm': '4.5312', 'counters/examples': 73344, 'counters/updates': 4584}
skipping logging after 73360 examples to avoid logging too frequently
skipping logging after 73376 examples to avoid logging too frequently
skipping logging after 73392 examples to avoid logging too frequently
train stats after 73408 examples: {'rewards_train/chosen': '0.28151', 'rewards_train/rejected': '-5.2435', 'rewards_train/margins': '5.3867', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24713', 'examples_per_second': '4.9166', 'grad_norm': '5.4062', 'counters/examples': 73408, 'counters/updates': 4588}
skipping logging after 73424 examples to avoid logging too frequently
skipping logging after 73440 examples to avoid logging too frequently
skipping logging after 73456 examples to avoid logging too frequently
train stats after 73472 examples: {'rewards_train/chosen': '0.21288', 'rewards_train/rejected': '-5.0805', 'rewards_train/margins': '5.3828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27838', 'examples_per_second': '5.8589', 'grad_norm': '4.375', 'counters/examples': 73472, 'counters/updates': 4592}
skipping logging after 73488 examples to avoid logging too frequently
skipping logging after 73504 examples to avoid logging too frequently
skipping logging after 73520 examples to avoid logging too frequently
train stats after 73536 examples: {'rewards_train/chosen': '0.42057', 'rewards_train/rejected': '-6.9482', 'rewards_train/margins': '7.125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21594', 'examples_per_second': '5.9684', 'grad_norm': '4.1562', 'counters/examples': 73536, 'counters/updates': 4596}
skipping logging after 73552 examples to avoid logging too frequently
skipping logging after 73568 examples to avoid logging too frequently
skipping logging after 73584 examples to avoid logging too frequently
train stats after 73600 examples: {'rewards_train/chosen': '0.34124', 'rewards_train/rejected': '-6.2792', 'rewards_train/margins': '7.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23608', 'examples_per_second': '5.1235', 'grad_norm': '4.5312', 'counters/examples': 73600, 'counters/updates': 4600}
skipping logging after 73616 examples to avoid logging too frequently
skipping logging after 73632 examples to avoid logging too frequently
skipping logging after 73648 examples to avoid logging too frequently
train stats after 73664 examples: {'rewards_train/chosen': '0.73579', 'rewards_train/rejected': '-4.6384', 'rewards_train/margins': '6.0859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21722', 'examples_per_second': '4.4255', 'grad_norm': '6.0312', 'counters/examples': 73664, 'counters/updates': 4604}
skipping logging after 73680 examples to avoid logging too frequently
skipping logging after 73696 examples to avoid logging too frequently
skipping logging after 73712 examples to avoid logging too frequently
train stats after 73728 examples: {'rewards_train/chosen': '0.23317', 'rewards_train/rejected': '-5.228', 'rewards_train/margins': '5.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23865', 'examples_per_second': '6.5116', 'grad_norm': '4.875', 'counters/examples': 73728, 'counters/updates': 4608}
skipping logging after 73744 examples to avoid logging too frequently
skipping logging after 73760 examples to avoid logging too frequently
skipping logging after 73776 examples to avoid logging too frequently
train stats after 73792 examples: {'rewards_train/chosen': '0.19312', 'rewards_train/rejected': '-5.4964', 'rewards_train/margins': '5.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25177', 'examples_per_second': '4.4737', 'grad_norm': '4.9688', 'counters/examples': 73792, 'counters/updates': 4612}
skipping logging after 73808 examples to avoid logging too frequently
skipping logging after 73824 examples to avoid logging too frequently
skipping logging after 73840 examples to avoid logging too frequently
train stats after 73856 examples: {'rewards_train/chosen': '0.49272', 'rewards_train/rejected': '-5.3278', 'rewards_train/margins': '5.7891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2616', 'examples_per_second': '4.1784', 'grad_norm': '6', 'counters/examples': 73856, 'counters/updates': 4616}
skipping logging after 73872 examples to avoid logging too frequently
skipping logging after 73888 examples to avoid logging too frequently
skipping logging after 73904 examples to avoid logging too frequently
train stats after 73920 examples: {'rewards_train/chosen': '0.23548', 'rewards_train/rejected': '-4.6553', 'rewards_train/margins': '4.4805', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27991', 'examples_per_second': '5.1236', 'grad_norm': '4.6562', 'counters/examples': 73920, 'counters/updates': 4620}
skipping logging after 73936 examples to avoid logging too frequently
skipping logging after 73952 examples to avoid logging too frequently
skipping logging after 73968 examples to avoid logging too frequently
train stats after 73984 examples: {'rewards_train/chosen': '0.56061', 'rewards_train/rejected': '-5.3472', 'rewards_train/margins': '5.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25806', 'examples_per_second': '4.7452', 'grad_norm': '4.6875', 'counters/examples': 73984, 'counters/updates': 4624}
skipping logging after 74000 examples to avoid logging too frequently
skipping logging after 74016 examples to avoid logging too frequently
skipping logging after 74032 examples to avoid logging too frequently
train stats after 74048 examples: {'rewards_train/chosen': '0.63536', 'rewards_train/rejected': '-6.5423', 'rewards_train/margins': '6.7422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21393', 'examples_per_second': '4.4198', 'grad_norm': '5.3438', 'counters/examples': 74048, 'counters/updates': 4628}
skipping logging after 74064 examples to avoid logging too frequently
skipping logging after 74080 examples to avoid logging too frequently
skipping logging after 74096 examples to avoid logging too frequently
train stats after 74112 examples: {'rewards_train/chosen': '0.41724', 'rewards_train/rejected': '-4.2359', 'rewards_train/margins': '4.6328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27148', 'examples_per_second': '4.859', 'grad_norm': '5.875', 'counters/examples': 74112, 'counters/updates': 4632}
skipping logging after 74128 examples to avoid logging too frequently
skipping logging after 74144 examples to avoid logging too frequently
skipping logging after 74160 examples to avoid logging too frequently
train stats after 74176 examples: {'rewards_train/chosen': '0.50303', 'rewards_train/rejected': '-5.7499', 'rewards_train/margins': '6.3203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22418', 'examples_per_second': '5.1175', 'grad_norm': '4.5312', 'counters/examples': 74176, 'counters/updates': 4636}
skipping logging after 74192 examples to avoid logging too frequently
skipping logging after 74208 examples to avoid logging too frequently
skipping logging after 74224 examples to avoid logging too frequently
train stats after 74240 examples: {'rewards_train/chosen': '0.48725', 'rewards_train/rejected': '-5.9028', 'rewards_train/margins': '6.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2276', 'examples_per_second': '4.7899', 'grad_norm': '4', 'counters/examples': 74240, 'counters/updates': 4640}
skipping logging after 74256 examples to avoid logging too frequently
skipping logging after 74272 examples to avoid logging too frequently
skipping logging after 74288 examples to avoid logging too frequently
train stats after 74304 examples: {'rewards_train/chosen': '0.80534', 'rewards_train/rejected': '-4.1665', 'rewards_train/margins': '5.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20471', 'examples_per_second': '6.3616', 'grad_norm': '5.2812', 'counters/examples': 74304, 'counters/updates': 4644}
skipping logging after 74320 examples to avoid logging too frequently
skipping logging after 74336 examples to avoid logging too frequently
skipping logging after 74352 examples to avoid logging too frequently
train stats after 74368 examples: {'rewards_train/chosen': '0.4756', 'rewards_train/rejected': '-5.4605', 'rewards_train/margins': '6.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22559', 'examples_per_second': '5.0194', 'grad_norm': '4.6562', 'counters/examples': 74368, 'counters/updates': 4648}
skipping logging after 74384 examples to avoid logging too frequently
skipping logging after 74400 examples to avoid logging too frequently
skipping logging after 74416 examples to avoid logging too frequently
train stats after 74432 examples: {'rewards_train/chosen': '0.038173', 'rewards_train/rejected': '-4.4686', 'rewards_train/margins': '4.5117', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28381', 'examples_per_second': '5.3197', 'grad_norm': '5.4375', 'counters/examples': 74432, 'counters/updates': 4652}
skipping logging after 74448 examples to avoid logging too frequently
skipping logging after 74464 examples to avoid logging too frequently
skipping logging after 74480 examples to avoid logging too frequently
train stats after 74496 examples: {'rewards_train/chosen': '0.56794', 'rewards_train/rejected': '-4.6208', 'rewards_train/margins': '5.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24457', 'examples_per_second': '5.6171', 'grad_norm': '5.125', 'counters/examples': 74496, 'counters/updates': 4656}
skipping logging after 74512 examples to avoid logging too frequently
skipping logging after 74528 examples to avoid logging too frequently
skipping logging after 74544 examples to avoid logging too frequently
train stats after 74560 examples: {'rewards_train/chosen': '0.25977', 'rewards_train/rejected': '-5.7059', 'rewards_train/margins': '6.2539', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25043', 'examples_per_second': '5.225', 'grad_norm': '5.5', 'counters/examples': 74560, 'counters/updates': 4660}
skipping logging after 74576 examples to avoid logging too frequently
skipping logging after 74592 examples to avoid logging too frequently
skipping logging after 74608 examples to avoid logging too frequently
train stats after 74624 examples: {'rewards_train/chosen': '0.60266', 'rewards_train/rejected': '-5.7114', 'rewards_train/margins': '6.2109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.16473', 'examples_per_second': '4.8536', 'grad_norm': '4.0938', 'counters/examples': 74624, 'counters/updates': 4664}
skipping logging after 74640 examples to avoid logging too frequently
skipping logging after 74656 examples to avoid logging too frequently
skipping logging after 74672 examples to avoid logging too frequently
train stats after 74688 examples: {'rewards_train/chosen': '0.28026', 'rewards_train/rejected': '-5.8249', 'rewards_train/margins': '6.125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20508', 'examples_per_second': '6.6493', 'grad_norm': '6.0938', 'counters/examples': 74688, 'counters/updates': 4668}
skipping logging after 74704 examples to avoid logging too frequently
skipping logging after 74720 examples to avoid logging too frequently
skipping logging after 74736 examples to avoid logging too frequently
train stats after 74752 examples: {'rewards_train/chosen': '0.13274', 'rewards_train/rejected': '-5.156', 'rewards_train/margins': '5.2109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27631', 'examples_per_second': '5.5937', 'grad_norm': '5.1875', 'counters/examples': 74752, 'counters/updates': 4672}
skipping logging after 74768 examples to avoid logging too frequently
skipping logging after 74784 examples to avoid logging too frequently
skipping logging after 74800 examples to avoid logging too frequently
train stats after 74816 examples: {'rewards_train/chosen': '0.76659', 'rewards_train/rejected': '-5.697', 'rewards_train/margins': '6.3281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21552', 'examples_per_second': '5.1981', 'grad_norm': '4.9062', 'counters/examples': 74816, 'counters/updates': 4676}
skipping logging after 74832 examples to avoid logging too frequently
skipping logging after 74848 examples to avoid logging too frequently
skipping logging after 74864 examples to avoid logging too frequently
train stats after 74880 examples: {'rewards_train/chosen': '0.31269', 'rewards_train/rejected': '-4.9954', 'rewards_train/margins': '5.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24329', 'examples_per_second': '5.1927', 'grad_norm': '5.1562', 'counters/examples': 74880, 'counters/updates': 4680}
skipping logging after 74896 examples to avoid logging too frequently
skipping logging after 74912 examples to avoid logging too frequently
skipping logging after 74928 examples to avoid logging too frequently
train stats after 74944 examples: {'rewards_train/chosen': '0.64811', 'rewards_train/rejected': '-5.5675', 'rewards_train/margins': '6.2109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21313', 'examples_per_second': '5.2581', 'grad_norm': '5.6875', 'counters/examples': 74944, 'counters/updates': 4684}
skipping logging after 74960 examples to avoid logging too frequently
skipping logging after 74976 examples to avoid logging too frequently
skipping logging after 74992 examples to avoid logging too frequently
train stats after 75008 examples: {'rewards_train/chosen': '0.44312', 'rewards_train/rejected': '-5.6175', 'rewards_train/margins': '6', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25104', 'examples_per_second': '5.5119', 'grad_norm': '4.9375', 'counters/examples': 75008, 'counters/updates': 4688}
skipping logging after 75024 examples to avoid logging too frequently
skipping logging after 75040 examples to avoid logging too frequently
skipping logging after 75056 examples to avoid logging too frequently
train stats after 75072 examples: {'rewards_train/chosen': '0.63444', 'rewards_train/rejected': '-5.3311', 'rewards_train/margins': '5.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19568', 'examples_per_second': '5.0599', 'grad_norm': '4.4062', 'counters/examples': 75072, 'counters/updates': 4692}
skipping logging after 75088 examples to avoid logging too frequently
skipping logging after 75104 examples to avoid logging too frequently
skipping logging after 75120 examples to avoid logging too frequently
train stats after 75136 examples: {'rewards_train/chosen': '0.42714', 'rewards_train/rejected': '-6.0128', 'rewards_train/margins': '6.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21844', 'examples_per_second': '4.8742', 'grad_norm': '4.8125', 'counters/examples': 75136, 'counters/updates': 4696}
skipping logging after 75152 examples to avoid logging too frequently
skipping logging after 75168 examples to avoid logging too frequently
skipping logging after 75184 examples to avoid logging too frequently
train stats after 75200 examples: {'rewards_train/chosen': '0.20547', 'rewards_train/rejected': '-5.9935', 'rewards_train/margins': '6.1953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23456', 'examples_per_second': '4.3801', 'grad_norm': '4.3125', 'counters/examples': 75200, 'counters/updates': 4700}
skipping logging after 75216 examples to avoid logging too frequently
skipping logging after 75232 examples to avoid logging too frequently
skipping logging after 75248 examples to avoid logging too frequently
train stats after 75264 examples: {'rewards_train/chosen': '0.27771', 'rewards_train/rejected': '-5.5821', 'rewards_train/margins': '6.0234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21747', 'examples_per_second': '5.8488', 'grad_norm': '4.4375', 'counters/examples': 75264, 'counters/updates': 4704}
skipping logging after 75280 examples to avoid logging too frequently
skipping logging after 75296 examples to avoid logging too frequently
skipping logging after 75312 examples to avoid logging too frequently
train stats after 75328 examples: {'rewards_train/chosen': '0.1422', 'rewards_train/rejected': '-7.9036', 'rewards_train/margins': '8.1172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22736', 'examples_per_second': '4.2964', 'grad_norm': '5.2812', 'counters/examples': 75328, 'counters/updates': 4708}
skipping logging after 75344 examples to avoid logging too frequently
skipping logging after 75360 examples to avoid logging too frequently
skipping logging after 75376 examples to avoid logging too frequently
train stats after 75392 examples: {'rewards_train/chosen': '0.4421', 'rewards_train/rejected': '-4.9662', 'rewards_train/margins': '5.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26788', 'examples_per_second': '5.54', 'grad_norm': '4.6875', 'counters/examples': 75392, 'counters/updates': 4712}
skipping logging after 75408 examples to avoid logging too frequently
skipping logging after 75424 examples to avoid logging too frequently
skipping logging after 75440 examples to avoid logging too frequently
train stats after 75456 examples: {'rewards_train/chosen': '0.32169', 'rewards_train/rejected': '-4.9018', 'rewards_train/margins': '5.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22101', 'examples_per_second': '5.7721', 'grad_norm': '4.7812', 'counters/examples': 75456, 'counters/updates': 4716}
skipping logging after 75472 examples to avoid logging too frequently
skipping logging after 75488 examples to avoid logging too frequently
skipping logging after 75504 examples to avoid logging too frequently
train stats after 75520 examples: {'rewards_train/chosen': '0.52257', 'rewards_train/rejected': '-6.2367', 'rewards_train/margins': '6.1719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25476', 'examples_per_second': '5.7138', 'grad_norm': '5.2188', 'counters/examples': 75520, 'counters/updates': 4720}
skipping logging after 75536 examples to avoid logging too frequently
skipping logging after 75552 examples to avoid logging too frequently
skipping logging after 75568 examples to avoid logging too frequently
train stats after 75584 examples: {'rewards_train/chosen': '0.59849', 'rewards_train/rejected': '-5.0355', 'rewards_train/margins': '5.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19464', 'examples_per_second': '5.8281', 'grad_norm': '4.4062', 'counters/examples': 75584, 'counters/updates': 4724}
skipping logging after 75600 examples to avoid logging too frequently
skipping logging after 75616 examples to avoid logging too frequently
skipping logging after 75632 examples to avoid logging too frequently
train stats after 75648 examples: {'rewards_train/chosen': '0.27869', 'rewards_train/rejected': '-5.0946', 'rewards_train/margins': '5.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26776', 'examples_per_second': '4.9157', 'grad_norm': '5.6562', 'counters/examples': 75648, 'counters/updates': 4728}
skipping logging after 75664 examples to avoid logging too frequently
skipping logging after 75680 examples to avoid logging too frequently
skipping logging after 75696 examples to avoid logging too frequently
train stats after 75712 examples: {'rewards_train/chosen': '0.40567', 'rewards_train/rejected': '-6.222', 'rewards_train/margins': '6.6641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22076', 'examples_per_second': '5.9275', 'grad_norm': '4.375', 'counters/examples': 75712, 'counters/updates': 4732}
skipping logging after 75728 examples to avoid logging too frequently
skipping logging after 75744 examples to avoid logging too frequently
skipping logging after 75760 examples to avoid logging too frequently
train stats after 75776 examples: {'rewards_train/chosen': '-0.086024', 'rewards_train/rejected': '-5.3959', 'rewards_train/margins': '5.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2702', 'examples_per_second': '5.688', 'grad_norm': '5.4062', 'counters/examples': 75776, 'counters/updates': 4736}
skipping logging after 75792 examples to avoid logging too frequently
skipping logging after 75808 examples to avoid logging too frequently
skipping logging after 75824 examples to avoid logging too frequently
train stats after 75840 examples: {'rewards_train/chosen': '0.2864', 'rewards_train/rejected': '-5.8362', 'rewards_train/margins': '6.0156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25848', 'examples_per_second': '5.7325', 'grad_norm': '5.0312', 'counters/examples': 75840, 'counters/updates': 4740}
skipping logging after 75856 examples to avoid logging too frequently
skipping logging after 75872 examples to avoid logging too frequently
skipping logging after 75888 examples to avoid logging too frequently
train stats after 75904 examples: {'rewards_train/chosen': '0.51292', 'rewards_train/rejected': '-4.9374', 'rewards_train/margins': '5.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24719', 'examples_per_second': '4.6417', 'grad_norm': '5.4688', 'counters/examples': 75904, 'counters/updates': 4744}
skipping logging after 75920 examples to avoid logging too frequently
skipping logging after 75936 examples to avoid logging too frequently
skipping logging after 75952 examples to avoid logging too frequently
train stats after 75968 examples: {'rewards_train/chosen': '0.14232', 'rewards_train/rejected': '-5.2344', 'rewards_train/margins': '5.5352', 'rewards_train/KL_estimate': '0', 'loss/train': '0.3205', 'examples_per_second': '4.9312', 'grad_norm': '5.8438', 'counters/examples': 75968, 'counters/updates': 4748}
skipping logging after 75984 examples to avoid logging too frequently
skipping logging after 76000 examples to avoid logging too frequently
Running evaluation after 76000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:52,  1.68s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:42,  1.43s/it]Computing eval metrics:   9%|▉         | 3/32 [00:04<00:36,  1.26s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.49s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.69s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:09<00:38,  1.50s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:10<00:34,  1.38s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.53s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.49s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:31,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.41s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:20<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:21<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.28s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:28<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.31s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.20s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:40<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:41<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]
eval after 76000: {'rewards_eval/chosen': '-5.2002', 'rewards_eval/rejected': '-5.6361', 'rewards_eval/margins': '0.31738', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46153'}
skipping logging after 76016 examples to avoid logging too frequently
train stats after 76032 examples: {'rewards_train/chosen': '0.31674', 'rewards_train/rejected': '-6.1033', 'rewards_train/margins': '6.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25537', 'examples_per_second': '5.8222', 'grad_norm': '4.4688', 'counters/examples': 76032, 'counters/updates': 4752}
skipping logging after 76048 examples to avoid logging too frequently
skipping logging after 76064 examples to avoid logging too frequently
skipping logging after 76080 examples to avoid logging too frequently
train stats after 76096 examples: {'rewards_train/chosen': '0.17597', 'rewards_train/rejected': '-5.5189', 'rewards_train/margins': '5.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24866', 'examples_per_second': '4.9096', 'grad_norm': '5.0625', 'counters/examples': 76096, 'counters/updates': 4756}
skipping logging after 76112 examples to avoid logging too frequently
skipping logging after 76128 examples to avoid logging too frequently
skipping logging after 76144 examples to avoid logging too frequently
train stats after 76160 examples: {'rewards_train/chosen': '0.31748', 'rewards_train/rejected': '-5.0967', 'rewards_train/margins': '5.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23541', 'examples_per_second': '5.4648', 'grad_norm': '4.2812', 'counters/examples': 76160, 'counters/updates': 4760}
skipping logging after 76176 examples to avoid logging too frequently
skipping logging after 76192 examples to avoid logging too frequently
skipping logging after 76208 examples to avoid logging too frequently
train stats after 76224 examples: {'rewards_train/chosen': '0.40636', 'rewards_train/rejected': '-5.8683', 'rewards_train/margins': '6.2109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21838', 'examples_per_second': '5.203', 'grad_norm': '4.6875', 'counters/examples': 76224, 'counters/updates': 4764}
skipping logging after 76240 examples to avoid logging too frequently
skipping logging after 76256 examples to avoid logging too frequently
skipping logging after 76272 examples to avoid logging too frequently
train stats after 76288 examples: {'rewards_train/chosen': '0.49911', 'rewards_train/rejected': '-6.3068', 'rewards_train/margins': '6.9453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24371', 'examples_per_second': '5.597', 'grad_norm': '4.5', 'counters/examples': 76288, 'counters/updates': 4768}
skipping logging after 76304 examples to avoid logging too frequently
skipping logging after 76320 examples to avoid logging too frequently
skipping logging after 76336 examples to avoid logging too frequently
train stats after 76352 examples: {'rewards_train/chosen': '0.26527', 'rewards_train/rejected': '-5.3192', 'rewards_train/margins': '6.1055', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28735', 'examples_per_second': '4.7499', 'grad_norm': '5.6562', 'counters/examples': 76352, 'counters/updates': 4772}
skipping logging after 76368 examples to avoid logging too frequently
skipping logging after 76384 examples to avoid logging too frequently
skipping logging after 76400 examples to avoid logging too frequently
train stats after 76416 examples: {'rewards_train/chosen': '-0.093093', 'rewards_train/rejected': '-5.6808', 'rewards_train/margins': '5.8125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.255', 'examples_per_second': '5.7162', 'grad_norm': '4.6875', 'counters/examples': 76416, 'counters/updates': 4776}
skipping logging after 76432 examples to avoid logging too frequently
skipping logging after 76448 examples to avoid logging too frequently
skipping logging after 76464 examples to avoid logging too frequently
train stats after 76480 examples: {'rewards_train/chosen': '0.3791', 'rewards_train/rejected': '-6.1761', 'rewards_train/margins': '6.6484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25952', 'examples_per_second': '5.0974', 'grad_norm': '7.2188', 'counters/examples': 76480, 'counters/updates': 4780}
skipping logging after 76496 examples to avoid logging too frequently
skipping logging after 76512 examples to avoid logging too frequently
skipping logging after 76528 examples to avoid logging too frequently
train stats after 76544 examples: {'rewards_train/chosen': '0.54399', 'rewards_train/rejected': '-5.7192', 'rewards_train/margins': '6.2422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23303', 'examples_per_second': '4.3812', 'grad_norm': '4.2812', 'counters/examples': 76544, 'counters/updates': 4784}
skipping logging after 76560 examples to avoid logging too frequently
skipping logging after 76576 examples to avoid logging too frequently
skipping logging after 76592 examples to avoid logging too frequently
train stats after 76608 examples: {'rewards_train/chosen': '0.40889', 'rewards_train/rejected': '-5.8799', 'rewards_train/margins': '6.2422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22711', 'examples_per_second': '5.4499', 'grad_norm': '4.9062', 'counters/examples': 76608, 'counters/updates': 4788}
skipping logging after 76624 examples to avoid logging too frequently
skipping logging after 76640 examples to avoid logging too frequently
skipping logging after 76656 examples to avoid logging too frequently
train stats after 76672 examples: {'rewards_train/chosen': '0.23093', 'rewards_train/rejected': '-5.8566', 'rewards_train/margins': '6.125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25232', 'examples_per_second': '5.9785', 'grad_norm': '4.9688', 'counters/examples': 76672, 'counters/updates': 4792}
skipping logging after 76688 examples to avoid logging too frequently
skipping logging after 76704 examples to avoid logging too frequently
skipping logging after 76720 examples to avoid logging too frequently
train stats after 76736 examples: {'rewards_train/chosen': '0.34494', 'rewards_train/rejected': '-4.8118', 'rewards_train/margins': '5.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24884', 'examples_per_second': '5.1903', 'grad_norm': '5', 'counters/examples': 76736, 'counters/updates': 4796}
skipping logging after 76752 examples to avoid logging too frequently
skipping logging after 76768 examples to avoid logging too frequently
skipping logging after 76784 examples to avoid logging too frequently
train stats after 76800 examples: {'rewards_train/chosen': '0.65535', 'rewards_train/rejected': '-6.1511', 'rewards_train/margins': '6.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23663', 'examples_per_second': '6.4889', 'grad_norm': '5.5', 'counters/examples': 76800, 'counters/updates': 4800}
skipping logging after 76816 examples to avoid logging too frequently
skipping logging after 76832 examples to avoid logging too frequently
skipping logging after 76848 examples to avoid logging too frequently
train stats after 76864 examples: {'rewards_train/chosen': '0.41941', 'rewards_train/rejected': '-5.4359', 'rewards_train/margins': '5.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20142', 'examples_per_second': '4.9739', 'grad_norm': '4.875', 'counters/examples': 76864, 'counters/updates': 4804}
skipping logging after 76880 examples to avoid logging too frequently
skipping logging after 76896 examples to avoid logging too frequently
skipping logging after 76912 examples to avoid logging too frequently
train stats after 76928 examples: {'rewards_train/chosen': '0.37547', 'rewards_train/rejected': '-4.8477', 'rewards_train/margins': '5.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24609', 'examples_per_second': '5.7386', 'grad_norm': '5.125', 'counters/examples': 76928, 'counters/updates': 4808}
skipping logging after 76944 examples to avoid logging too frequently
skipping logging after 76960 examples to avoid logging too frequently
skipping logging after 76976 examples to avoid logging too frequently
train stats after 76992 examples: {'rewards_train/chosen': '0.52662', 'rewards_train/rejected': '-5.744', 'rewards_train/margins': '6.1875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2171', 'examples_per_second': '4.7167', 'grad_norm': '5.0938', 'counters/examples': 76992, 'counters/updates': 4812}
skipping logging after 77008 examples to avoid logging too frequently
skipping logging after 77024 examples to avoid logging too frequently
skipping logging after 77040 examples to avoid logging too frequently
train stats after 77056 examples: {'rewards_train/chosen': '0.70359', 'rewards_train/rejected': '-7.3509', 'rewards_train/margins': '8', 'rewards_train/KL_estimate': '0', 'loss/train': '0.15546', 'examples_per_second': '4.7561', 'grad_norm': '4.5625', 'counters/examples': 77056, 'counters/updates': 4816}
skipping logging after 77072 examples to avoid logging too frequently
skipping logging after 77088 examples to avoid logging too frequently
skipping logging after 77104 examples to avoid logging too frequently
train stats after 77120 examples: {'rewards_train/chosen': '0.14062', 'rewards_train/rejected': '-4.9591', 'rewards_train/margins': '5.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25671', 'examples_per_second': '5.0786', 'grad_norm': '5.1875', 'counters/examples': 77120, 'counters/updates': 4820}
skipping logging after 77136 examples to avoid logging too frequently
skipping logging after 77152 examples to avoid logging too frequently
skipping logging after 77168 examples to avoid logging too frequently
train stats after 77184 examples: {'rewards_train/chosen': '0.37076', 'rewards_train/rejected': '-4.6671', 'rewards_train/margins': '5.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24652', 'examples_per_second': '6.1585', 'grad_norm': '5.1875', 'counters/examples': 77184, 'counters/updates': 4824}
skipping logging after 77200 examples to avoid logging too frequently
skipping logging after 77216 examples to avoid logging too frequently
skipping logging after 77232 examples to avoid logging too frequently
train stats after 77248 examples: {'rewards_train/chosen': '0.22117', 'rewards_train/rejected': '-5.5305', 'rewards_train/margins': '6.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21259', 'examples_per_second': '5.4982', 'grad_norm': '5.8438', 'counters/examples': 77248, 'counters/updates': 4828}
skipping logging after 77264 examples to avoid logging too frequently
skipping logging after 77280 examples to avoid logging too frequently
skipping logging after 77296 examples to avoid logging too frequently
train stats after 77312 examples: {'rewards_train/chosen': '0.29521', 'rewards_train/rejected': '-5.2825', 'rewards_train/margins': '5.5938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18848', 'examples_per_second': '5.2465', 'grad_norm': '4', 'counters/examples': 77312, 'counters/updates': 4832}
skipping logging after 77328 examples to avoid logging too frequently
skipping logging after 77344 examples to avoid logging too frequently
skipping logging after 77360 examples to avoid logging too frequently
train stats after 77376 examples: {'rewards_train/chosen': '0.04284', 'rewards_train/rejected': '-4.8291', 'rewards_train/margins': '4.7773', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2782', 'examples_per_second': '4.6468', 'grad_norm': '4.6875', 'counters/examples': 77376, 'counters/updates': 4836}
skipping logging after 77392 examples to avoid logging too frequently
skipping logging after 77408 examples to avoid logging too frequently
skipping logging after 77424 examples to avoid logging too frequently
train stats after 77440 examples: {'rewards_train/chosen': '0.51517', 'rewards_train/rejected': '-6.4877', 'rewards_train/margins': '7.1953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26575', 'examples_per_second': '4.4574', 'grad_norm': '4.6562', 'counters/examples': 77440, 'counters/updates': 4840}
skipping logging after 77456 examples to avoid logging too frequently
skipping logging after 77472 examples to avoid logging too frequently
skipping logging after 77488 examples to avoid logging too frequently
train stats after 77504 examples: {'rewards_train/chosen': '0.43114', 'rewards_train/rejected': '-5.4595', 'rewards_train/margins': '6.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27344', 'examples_per_second': '5.3357', 'grad_norm': '4.2812', 'counters/examples': 77504, 'counters/updates': 4844}
skipping logging after 77520 examples to avoid logging too frequently
skipping logging after 77536 examples to avoid logging too frequently
skipping logging after 77552 examples to avoid logging too frequently
train stats after 77568 examples: {'rewards_train/chosen': '0.24876', 'rewards_train/rejected': '-5.3128', 'rewards_train/margins': '5.5938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28503', 'examples_per_second': '5.7902', 'grad_norm': '4.9062', 'counters/examples': 77568, 'counters/updates': 4848}
skipping logging after 77584 examples to avoid logging too frequently
skipping logging after 77600 examples to avoid logging too frequently
skipping logging after 77616 examples to avoid logging too frequently
train stats after 77632 examples: {'rewards_train/chosen': '0.50158', 'rewards_train/rejected': '-6.5809', 'rewards_train/margins': '6.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22772', 'examples_per_second': '4.8848', 'grad_norm': '5.2812', 'counters/examples': 77632, 'counters/updates': 4852}
skipping logging after 77648 examples to avoid logging too frequently
skipping logging after 77664 examples to avoid logging too frequently
skipping logging after 77680 examples to avoid logging too frequently
train stats after 77696 examples: {'rewards_train/chosen': '0.49388', 'rewards_train/rejected': '-5.9243', 'rewards_train/margins': '6.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24438', 'examples_per_second': '5.1238', 'grad_norm': '4.75', 'counters/examples': 77696, 'counters/updates': 4856}
skipping logging after 77712 examples to avoid logging too frequently
skipping logging after 77728 examples to avoid logging too frequently
skipping logging after 77744 examples to avoid logging too frequently
train stats after 77760 examples: {'rewards_train/chosen': '0.55932', 'rewards_train/rejected': '-6.2354', 'rewards_train/margins': '6.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22845', 'examples_per_second': '5.3796', 'grad_norm': '4.5938', 'counters/examples': 77760, 'counters/updates': 4860}
skipping logging after 77776 examples to avoid logging too frequently
skipping logging after 77792 examples to avoid logging too frequently
skipping logging after 77808 examples to avoid logging too frequently
train stats after 77824 examples: {'rewards_train/chosen': '0.45804', 'rewards_train/rejected': '-6.9347', 'rewards_train/margins': '7.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21106', 'examples_per_second': '4.4483', 'grad_norm': '4.75', 'counters/examples': 77824, 'counters/updates': 4864}
skipping logging after 77840 examples to avoid logging too frequently
skipping logging after 77856 examples to avoid logging too frequently
skipping logging after 77872 examples to avoid logging too frequently
train stats after 77888 examples: {'rewards_train/chosen': '0.48', 'rewards_train/rejected': '-6.5078', 'rewards_train/margins': '7.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23846', 'examples_per_second': '4.1639', 'grad_norm': '4.875', 'counters/examples': 77888, 'counters/updates': 4868}
skipping logging after 77904 examples to avoid logging too frequently
skipping logging after 77920 examples to avoid logging too frequently
skipping logging after 77936 examples to avoid logging too frequently
train stats after 77952 examples: {'rewards_train/chosen': '0.79412', 'rewards_train/rejected': '-6.498', 'rewards_train/margins': '7.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21698', 'examples_per_second': '5.011', 'grad_norm': '4.5312', 'counters/examples': 77952, 'counters/updates': 4872}
skipping logging after 77968 examples to avoid logging too frequently
skipping logging after 77984 examples to avoid logging too frequently
skipping logging after 78000 examples to avoid logging too frequently
train stats after 78016 examples: {'rewards_train/chosen': '0.4471', 'rewards_train/rejected': '-5.8177', 'rewards_train/margins': '6.3828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27472', 'examples_per_second': '4.7245', 'grad_norm': '4.875', 'counters/examples': 78016, 'counters/updates': 4876}
skipping logging after 78032 examples to avoid logging too frequently
skipping logging after 78048 examples to avoid logging too frequently
skipping logging after 78064 examples to avoid logging too frequently
train stats after 78080 examples: {'rewards_train/chosen': '0.48297', 'rewards_train/rejected': '-5.4904', 'rewards_train/margins': '5.8984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2019', 'examples_per_second': '5.3047', 'grad_norm': '4.6875', 'counters/examples': 78080, 'counters/updates': 4880}
skipping logging after 78096 examples to avoid logging too frequently
skipping logging after 78112 examples to avoid logging too frequently
skipping logging after 78128 examples to avoid logging too frequently
train stats after 78144 examples: {'rewards_train/chosen': '0.31259', 'rewards_train/rejected': '-4.8988', 'rewards_train/margins': '5.3008', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24396', 'examples_per_second': '5.7076', 'grad_norm': '5.0312', 'counters/examples': 78144, 'counters/updates': 4884}
skipping logging after 78160 examples to avoid logging too frequently
skipping logging after 78176 examples to avoid logging too frequently
skipping logging after 78192 examples to avoid logging too frequently
train stats after 78208 examples: {'rewards_train/chosen': '0.53902', 'rewards_train/rejected': '-5.2373', 'rewards_train/margins': '5.5742', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21991', 'examples_per_second': '5.9866', 'grad_norm': '5.5938', 'counters/examples': 78208, 'counters/updates': 4888}
skipping logging after 78224 examples to avoid logging too frequently
skipping logging after 78240 examples to avoid logging too frequently
skipping logging after 78256 examples to avoid logging too frequently
train stats after 78272 examples: {'rewards_train/chosen': '0.46025', 'rewards_train/rejected': '-5.3314', 'rewards_train/margins': '5.8906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24945', 'examples_per_second': '4.955', 'grad_norm': '4.75', 'counters/examples': 78272, 'counters/updates': 4892}
skipping logging after 78288 examples to avoid logging too frequently
skipping logging after 78304 examples to avoid logging too frequently
skipping logging after 78320 examples to avoid logging too frequently
train stats after 78336 examples: {'rewards_train/chosen': '0.43643', 'rewards_train/rejected': '-6.7431', 'rewards_train/margins': '7.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23627', 'examples_per_second': '4.1525', 'grad_norm': '4.5', 'counters/examples': 78336, 'counters/updates': 4896}
skipping logging after 78352 examples to avoid logging too frequently
skipping logging after 78368 examples to avoid logging too frequently
skipping logging after 78384 examples to avoid logging too frequently
train stats after 78400 examples: {'rewards_train/chosen': '0.44312', 'rewards_train/rejected': '-5.2627', 'rewards_train/margins': '5.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22473', 'examples_per_second': '5.0264', 'grad_norm': '4.7812', 'counters/examples': 78400, 'counters/updates': 4900}
skipping logging after 78416 examples to avoid logging too frequently
skipping logging after 78432 examples to avoid logging too frequently
skipping logging after 78448 examples to avoid logging too frequently
train stats after 78464 examples: {'rewards_train/chosen': '0.46232', 'rewards_train/rejected': '-6.1396', 'rewards_train/margins': '6.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23651', 'examples_per_second': '5.879', 'grad_norm': '4.1875', 'counters/examples': 78464, 'counters/updates': 4904}
skipping logging after 78480 examples to avoid logging too frequently
skipping logging after 78496 examples to avoid logging too frequently
skipping logging after 78512 examples to avoid logging too frequently
train stats after 78528 examples: {'rewards_train/chosen': '0.64477', 'rewards_train/rejected': '-6.3194', 'rewards_train/margins': '6.8125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20203', 'examples_per_second': '4.6181', 'grad_norm': '4.6562', 'counters/examples': 78528, 'counters/updates': 4908}
skipping logging after 78544 examples to avoid logging too frequently
skipping logging after 78560 examples to avoid logging too frequently
skipping logging after 78576 examples to avoid logging too frequently
train stats after 78592 examples: {'rewards_train/chosen': '0.31227', 'rewards_train/rejected': '-5.7485', 'rewards_train/margins': '5.7812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23254', 'examples_per_second': '5.131', 'grad_norm': '5.4688', 'counters/examples': 78592, 'counters/updates': 4912}
skipping logging after 78608 examples to avoid logging too frequently
skipping logging after 78624 examples to avoid logging too frequently
skipping logging after 78640 examples to avoid logging too frequently
train stats after 78656 examples: {'rewards_train/chosen': '0.3635', 'rewards_train/rejected': '-4.8737', 'rewards_train/margins': '5.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23291', 'examples_per_second': '5.4551', 'grad_norm': '4.8125', 'counters/examples': 78656, 'counters/updates': 4916}
skipping logging after 78672 examples to avoid logging too frequently
skipping logging after 78688 examples to avoid logging too frequently
skipping logging after 78704 examples to avoid logging too frequently
train stats after 78720 examples: {'rewards_train/chosen': '0.66574', 'rewards_train/rejected': '-5.0608', 'rewards_train/margins': '5.8984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17896', 'examples_per_second': '4.2516', 'grad_norm': '4.2188', 'counters/examples': 78720, 'counters/updates': 4920}
skipping logging after 78736 examples to avoid logging too frequently
skipping logging after 78752 examples to avoid logging too frequently
skipping logging after 78768 examples to avoid logging too frequently
train stats after 78784 examples: {'rewards_train/chosen': '0.28387', 'rewards_train/rejected': '-5.6467', 'rewards_train/margins': '5.9766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24261', 'examples_per_second': '6.1799', 'grad_norm': '5.0625', 'counters/examples': 78784, 'counters/updates': 4924}
skipping logging after 78800 examples to avoid logging too frequently
skipping logging after 78816 examples to avoid logging too frequently
skipping logging after 78832 examples to avoid logging too frequently
train stats after 78848 examples: {'rewards_train/chosen': '0.52723', 'rewards_train/rejected': '-5.9086', 'rewards_train/margins': '6.2422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23834', 'examples_per_second': '4.9048', 'grad_norm': '5.2812', 'counters/examples': 78848, 'counters/updates': 4928}
skipping logging after 78864 examples to avoid logging too frequently
skipping logging after 78880 examples to avoid logging too frequently
skipping logging after 78896 examples to avoid logging too frequently
train stats after 78912 examples: {'rewards_train/chosen': '0.18823', 'rewards_train/rejected': '-5.7811', 'rewards_train/margins': '5.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23975', 'examples_per_second': '4.8336', 'grad_norm': '5.7188', 'counters/examples': 78912, 'counters/updates': 4932}
skipping logging after 78928 examples to avoid logging too frequently
skipping logging after 78944 examples to avoid logging too frequently
skipping logging after 78960 examples to avoid logging too frequently
train stats after 78976 examples: {'rewards_train/chosen': '0.3918', 'rewards_train/rejected': '-6.9707', 'rewards_train/margins': '7.5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27502', 'examples_per_second': '5.0098', 'grad_norm': '5.7188', 'counters/examples': 78976, 'counters/updates': 4936}
skipping logging after 78992 examples to avoid logging too frequently
skipping logging after 79008 examples to avoid logging too frequently
skipping logging after 79024 examples to avoid logging too frequently
train stats after 79040 examples: {'rewards_train/chosen': '0.4422', 'rewards_train/rejected': '-4.9328', 'rewards_train/margins': '5.2461', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24939', 'examples_per_second': '5.2252', 'grad_norm': '4.2812', 'counters/examples': 79040, 'counters/updates': 4940}
skipping logging after 79056 examples to avoid logging too frequently
skipping logging after 79072 examples to avoid logging too frequently
skipping logging after 79088 examples to avoid logging too frequently
train stats after 79104 examples: {'rewards_train/chosen': '0.47468', 'rewards_train/rejected': '-6.463', 'rewards_train/margins': '6.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23785', 'examples_per_second': '4.7983', 'grad_norm': '4.7812', 'counters/examples': 79104, 'counters/updates': 4944}
skipping logging after 79120 examples to avoid logging too frequently
skipping logging after 79136 examples to avoid logging too frequently
skipping logging after 79152 examples to avoid logging too frequently
train stats after 79168 examples: {'rewards_train/chosen': '0.13375', 'rewards_train/rejected': '-5.888', 'rewards_train/margins': '6', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24524', 'examples_per_second': '5.1633', 'grad_norm': '4.5312', 'counters/examples': 79168, 'counters/updates': 4948}
skipping logging after 79184 examples to avoid logging too frequently
skipping logging after 79200 examples to avoid logging too frequently
skipping logging after 79216 examples to avoid logging too frequently
train stats after 79232 examples: {'rewards_train/chosen': '0.56818', 'rewards_train/rejected': '-5.5106', 'rewards_train/margins': '6.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22705', 'examples_per_second': '5.7484', 'grad_norm': '4.4688', 'counters/examples': 79232, 'counters/updates': 4952}
skipping logging after 79248 examples to avoid logging too frequently
skipping logging after 79264 examples to avoid logging too frequently
skipping logging after 79280 examples to avoid logging too frequently
train stats after 79296 examples: {'rewards_train/chosen': '0.67867', 'rewards_train/rejected': '-5.189', 'rewards_train/margins': '5.8125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23505', 'examples_per_second': '5.1708', 'grad_norm': '5.0312', 'counters/examples': 79296, 'counters/updates': 4956}
skipping logging after 79312 examples to avoid logging too frequently
skipping logging after 79328 examples to avoid logging too frequently
skipping logging after 79344 examples to avoid logging too frequently
train stats after 79360 examples: {'rewards_train/chosen': '0.54679', 'rewards_train/rejected': '-5.3335', 'rewards_train/margins': '6.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21844', 'examples_per_second': '5.4251', 'grad_norm': '5.0938', 'counters/examples': 79360, 'counters/updates': 4960}
skipping logging after 79376 examples to avoid logging too frequently
skipping logging after 79392 examples to avoid logging too frequently
skipping logging after 79408 examples to avoid logging too frequently
train stats after 79424 examples: {'rewards_train/chosen': '0.54272', 'rewards_train/rejected': '-4.7865', 'rewards_train/margins': '5.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2619', 'examples_per_second': '5.7251', 'grad_norm': '6.1875', 'counters/examples': 79424, 'counters/updates': 4964}
skipping logging after 79440 examples to avoid logging too frequently
skipping logging after 79456 examples to avoid logging too frequently
skipping logging after 79472 examples to avoid logging too frequently
train stats after 79488 examples: {'rewards_train/chosen': '0.5605', 'rewards_train/rejected': '-4.8693', 'rewards_train/margins': '5.4219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19983', 'examples_per_second': '4.8386', 'grad_norm': '4.6875', 'counters/examples': 79488, 'counters/updates': 4968}
skipping logging after 79504 examples to avoid logging too frequently
skipping logging after 79520 examples to avoid logging too frequently
skipping logging after 79536 examples to avoid logging too frequently
train stats after 79552 examples: {'rewards_train/chosen': '0.6344', 'rewards_train/rejected': '-5.8264', 'rewards_train/margins': '6.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.15851', 'examples_per_second': '6.223', 'grad_norm': '3.6719', 'counters/examples': 79552, 'counters/updates': 4972}
skipping logging after 79568 examples to avoid logging too frequently
skipping logging after 79584 examples to avoid logging too frequently
skipping logging after 79600 examples to avoid logging too frequently
train stats after 79616 examples: {'rewards_train/chosen': '0.6789', 'rewards_train/rejected': '-5.7529', 'rewards_train/margins': '6.5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20831', 'examples_per_second': '5.3058', 'grad_norm': '4.6875', 'counters/examples': 79616, 'counters/updates': 4976}
skipping logging after 79632 examples to avoid logging too frequently
skipping logging after 79648 examples to avoid logging too frequently
skipping logging after 79664 examples to avoid logging too frequently
train stats after 79680 examples: {'rewards_train/chosen': '0.46293', 'rewards_train/rejected': '-5.5687', 'rewards_train/margins': '6.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25623', 'examples_per_second': '4.0917', 'grad_norm': '5.3438', 'counters/examples': 79680, 'counters/updates': 4980}
skipping logging after 79696 examples to avoid logging too frequently
skipping logging after 79712 examples to avoid logging too frequently
skipping logging after 79728 examples to avoid logging too frequently
train stats after 79744 examples: {'rewards_train/chosen': '0.46105', 'rewards_train/rejected': '-6.8689', 'rewards_train/margins': '7.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22565', 'examples_per_second': '4.4292', 'grad_norm': '4.7188', 'counters/examples': 79744, 'counters/updates': 4984}
skipping logging after 79760 examples to avoid logging too frequently
skipping logging after 79776 examples to avoid logging too frequently
skipping logging after 79792 examples to avoid logging too frequently
train stats after 79808 examples: {'rewards_train/chosen': '0.11202', 'rewards_train/rejected': '-4.6826', 'rewards_train/margins': '4.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1958', 'examples_per_second': '5.2625', 'grad_norm': '4.7188', 'counters/examples': 79808, 'counters/updates': 4988}
skipping logging after 79824 examples to avoid logging too frequently
skipping logging after 79840 examples to avoid logging too frequently
skipping logging after 79856 examples to avoid logging too frequently
train stats after 79872 examples: {'rewards_train/chosen': '0.43064', 'rewards_train/rejected': '-4.9496', 'rewards_train/margins': '5.2148', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22894', 'examples_per_second': '4.5594', 'grad_norm': '4.8438', 'counters/examples': 79872, 'counters/updates': 4992}
skipping logging after 79888 examples to avoid logging too frequently
skipping logging after 79904 examples to avoid logging too frequently
skipping logging after 79920 examples to avoid logging too frequently
train stats after 79936 examples: {'rewards_train/chosen': '0.70188', 'rewards_train/rejected': '-5.4555', 'rewards_train/margins': '6.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21094', 'examples_per_second': '5.7025', 'grad_norm': '4.9375', 'counters/examples': 79936, 'counters/updates': 4996}
skipping logging after 79952 examples to avoid logging too frequently
skipping logging after 79968 examples to avoid logging too frequently
skipping logging after 79984 examples to avoid logging too frequently
train stats after 80000 examples: {'rewards_train/chosen': '0.25391', 'rewards_train/rejected': '-6.0571', 'rewards_train/margins': '5.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23535', 'examples_per_second': '5.4514', 'grad_norm': '6.1562', 'counters/examples': 80000, 'counters/updates': 5000}
Running evaluation after 80000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.25s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.16s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:39,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.65s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.47s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:33,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.51s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.40s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:30,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:21<00:20,  1.28s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.42s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.20s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.18s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.31s/it]
eval after 80000: {'rewards_eval/chosen': '-5.4622', 'rewards_eval/rejected': '-5.8789', 'rewards_eval/margins': '0.27734', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46231'}
skipping logging after 80016 examples to avoid logging too frequently
skipping logging after 80032 examples to avoid logging too frequently
skipping logging after 80048 examples to avoid logging too frequently
train stats after 80064 examples: {'rewards_train/chosen': '0.486', 'rewards_train/rejected': '-4.9975', 'rewards_train/margins': '5.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21399', 'examples_per_second': '4.7592', 'grad_norm': '4.6562', 'counters/examples': 80064, 'counters/updates': 5004}
skipping logging after 80080 examples to avoid logging too frequently
skipping logging after 80096 examples to avoid logging too frequently
skipping logging after 80112 examples to avoid logging too frequently
train stats after 80128 examples: {'rewards_train/chosen': '0.34315', 'rewards_train/rejected': '-5.3041', 'rewards_train/margins': '5.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2738', 'examples_per_second': '5.9812', 'grad_norm': '5.8438', 'counters/examples': 80128, 'counters/updates': 5008}
skipping logging after 80144 examples to avoid logging too frequently
skipping logging after 80160 examples to avoid logging too frequently
skipping logging after 80176 examples to avoid logging too frequently
train stats after 80192 examples: {'rewards_train/chosen': '0.11268', 'rewards_train/rejected': '-6.4292', 'rewards_train/margins': '6.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21173', 'examples_per_second': '4.9725', 'grad_norm': '4.4688', 'counters/examples': 80192, 'counters/updates': 5012}
skipping logging after 80208 examples to avoid logging too frequently
skipping logging after 80224 examples to avoid logging too frequently
skipping logging after 80240 examples to avoid logging too frequently
train stats after 80256 examples: {'rewards_train/chosen': '0.56254', 'rewards_train/rejected': '-5.5992', 'rewards_train/margins': '6.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23505', 'examples_per_second': '5.4948', 'grad_norm': '4.9062', 'counters/examples': 80256, 'counters/updates': 5016}
skipping logging after 80272 examples to avoid logging too frequently
skipping logging after 80288 examples to avoid logging too frequently
skipping logging after 80304 examples to avoid logging too frequently
train stats after 80320 examples: {'rewards_train/chosen': '0.72898', 'rewards_train/rejected': '-4.7031', 'rewards_train/margins': '5.543', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21515', 'examples_per_second': '5.1061', 'grad_norm': '4.4688', 'counters/examples': 80320, 'counters/updates': 5020}
skipping logging after 80336 examples to avoid logging too frequently
skipping logging after 80352 examples to avoid logging too frequently
skipping logging after 80368 examples to avoid logging too frequently
train stats after 80384 examples: {'rewards_train/chosen': '0.75357', 'rewards_train/rejected': '-5.2827', 'rewards_train/margins': '5.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18561', 'examples_per_second': '5.8245', 'grad_norm': '5.375', 'counters/examples': 80384, 'counters/updates': 5024}
skipping logging after 80400 examples to avoid logging too frequently
skipping logging after 80416 examples to avoid logging too frequently
skipping logging after 80432 examples to avoid logging too frequently
train stats after 80448 examples: {'rewards_train/chosen': '0.53137', 'rewards_train/rejected': '-6.9031', 'rewards_train/margins': '7.6328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23132', 'examples_per_second': '4.2662', 'grad_norm': '5.2812', 'counters/examples': 80448, 'counters/updates': 5028}
skipping logging after 80464 examples to avoid logging too frequently
skipping logging after 80480 examples to avoid logging too frequently
skipping logging after 80496 examples to avoid logging too frequently
train stats after 80512 examples: {'rewards_train/chosen': '0.49634', 'rewards_train/rejected': '-6.5296', 'rewards_train/margins': '7.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22021', 'examples_per_second': '4.3851', 'grad_norm': '4.8438', 'counters/examples': 80512, 'counters/updates': 5032}
skipping logging after 80528 examples to avoid logging too frequently
skipping logging after 80544 examples to avoid logging too frequently
skipping logging after 80560 examples to avoid logging too frequently
train stats after 80576 examples: {'rewards_train/chosen': '0.42831', 'rewards_train/rejected': '-6.95', 'rewards_train/margins': '7.3594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21149', 'examples_per_second': '4.3963', 'grad_norm': '5.0938', 'counters/examples': 80576, 'counters/updates': 5036}
skipping logging after 80592 examples to avoid logging too frequently
skipping logging after 80608 examples to avoid logging too frequently
skipping logging after 80624 examples to avoid logging too frequently
train stats after 80640 examples: {'rewards_train/chosen': '0.76249', 'rewards_train/rejected': '-4.2884', 'rewards_train/margins': '5.0508', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24951', 'examples_per_second': '4.8276', 'grad_norm': '5.3438', 'counters/examples': 80640, 'counters/updates': 5040}
skipping logging after 80656 examples to avoid logging too frequently
skipping logging after 80672 examples to avoid logging too frequently
skipping logging after 80688 examples to avoid logging too frequently
train stats after 80704 examples: {'rewards_train/chosen': '0.6325', 'rewards_train/rejected': '-5.5362', 'rewards_train/margins': '6.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.237', 'examples_per_second': '3.8973', 'grad_norm': '5.3438', 'counters/examples': 80704, 'counters/updates': 5044}
skipping logging after 80720 examples to avoid logging too frequently
skipping logging after 80736 examples to avoid logging too frequently
skipping logging after 80752 examples to avoid logging too frequently
train stats after 80768 examples: {'rewards_train/chosen': '0.29845', 'rewards_train/rejected': '-6.6268', 'rewards_train/margins': '6.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24194', 'examples_per_second': '5.342', 'grad_norm': '4.2812', 'counters/examples': 80768, 'counters/updates': 5048}
skipping logging after 80784 examples to avoid logging too frequently
skipping logging after 80800 examples to avoid logging too frequently
skipping logging after 80816 examples to avoid logging too frequently
train stats after 80832 examples: {'rewards_train/chosen': '0.69931', 'rewards_train/rejected': '-5.9957', 'rewards_train/margins': '6.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21265', 'examples_per_second': '5.7458', 'grad_norm': '4.5625', 'counters/examples': 80832, 'counters/updates': 5052}
skipping logging after 80848 examples to avoid logging too frequently
skipping logging after 80864 examples to avoid logging too frequently
skipping logging after 80880 examples to avoid logging too frequently
train stats after 80896 examples: {'rewards_train/chosen': '0.52412', 'rewards_train/rejected': '-5.7075', 'rewards_train/margins': '5.9258', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23285', 'examples_per_second': '5.7414', 'grad_norm': '4.7812', 'counters/examples': 80896, 'counters/updates': 5056}
skipping logging after 80912 examples to avoid logging too frequently
skipping logging after 80928 examples to avoid logging too frequently
skipping logging after 80944 examples to avoid logging too frequently
train stats after 80960 examples: {'rewards_train/chosen': '0.57398', 'rewards_train/rejected': '-4.9432', 'rewards_train/margins': '5.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22638', 'examples_per_second': '5.9528', 'grad_norm': '5.2812', 'counters/examples': 80960, 'counters/updates': 5060}
skipping logging after 80976 examples to avoid logging too frequently
skipping logging after 80992 examples to avoid logging too frequently
skipping logging after 81008 examples to avoid logging too frequently
train stats after 81024 examples: {'rewards_train/chosen': '0.44164', 'rewards_train/rejected': '-4.6135', 'rewards_train/margins': '4.8164', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29657', 'examples_per_second': '4.7327', 'grad_norm': '5.7188', 'counters/examples': 81024, 'counters/updates': 5064}
skipping logging after 81040 examples to avoid logging too frequently
skipping logging after 81056 examples to avoid logging too frequently
skipping logging after 81072 examples to avoid logging too frequently
train stats after 81088 examples: {'rewards_train/chosen': '0.37582', 'rewards_train/rejected': '-5.5325', 'rewards_train/margins': '6', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22882', 'examples_per_second': '5.8501', 'grad_norm': '4.8438', 'counters/examples': 81088, 'counters/updates': 5068}
skipping logging after 81104 examples to avoid logging too frequently
skipping logging after 81120 examples to avoid logging too frequently
skipping logging after 81136 examples to avoid logging too frequently
train stats after 81152 examples: {'rewards_train/chosen': '0.47739', 'rewards_train/rejected': '-6.7219', 'rewards_train/margins': '7.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21924', 'examples_per_second': '5.7787', 'grad_norm': '4.1562', 'counters/examples': 81152, 'counters/updates': 5072}
skipping logging after 81168 examples to avoid logging too frequently
skipping logging after 81184 examples to avoid logging too frequently
skipping logging after 81200 examples to avoid logging too frequently
train stats after 81216 examples: {'rewards_train/chosen': '0.67432', 'rewards_train/rejected': '-3.9307', 'rewards_train/margins': '4.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25836', 'examples_per_second': '4.9563', 'grad_norm': '5.6875', 'counters/examples': 81216, 'counters/updates': 5076}
skipping logging after 81232 examples to avoid logging too frequently
skipping logging after 81248 examples to avoid logging too frequently
skipping logging after 81264 examples to avoid logging too frequently
train stats after 81280 examples: {'rewards_train/chosen': '0.39189', 'rewards_train/rejected': '-6.0215', 'rewards_train/margins': '6.4844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22705', 'examples_per_second': '4.3176', 'grad_norm': '5.7188', 'counters/examples': 81280, 'counters/updates': 5080}
skipping logging after 81296 examples to avoid logging too frequently
skipping logging after 81312 examples to avoid logging too frequently
skipping logging after 81328 examples to avoid logging too frequently
train stats after 81344 examples: {'rewards_train/chosen': '0.42478', 'rewards_train/rejected': '-4.8161', 'rewards_train/margins': '5.1406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24164', 'examples_per_second': '5.3492', 'grad_norm': '5.5', 'counters/examples': 81344, 'counters/updates': 5084}
skipping logging after 81360 examples to avoid logging too frequently
skipping logging after 81376 examples to avoid logging too frequently
skipping logging after 81392 examples to avoid logging too frequently
train stats after 81408 examples: {'rewards_train/chosen': '0.32892', 'rewards_train/rejected': '-7.7204', 'rewards_train/margins': '8.0156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21857', 'examples_per_second': '5.2589', 'grad_norm': '5.0938', 'counters/examples': 81408, 'counters/updates': 5088}
skipping logging after 81424 examples to avoid logging too frequently
skipping logging after 81440 examples to avoid logging too frequently
skipping logging after 81456 examples to avoid logging too frequently
train stats after 81472 examples: {'rewards_train/chosen': '0.3654', 'rewards_train/rejected': '-6.3026', 'rewards_train/margins': '6.6094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28113', 'examples_per_second': '4.9783', 'grad_norm': '4.7188', 'counters/examples': 81472, 'counters/updates': 5092}
skipping logging after 81488 examples to avoid logging too frequently
skipping logging after 81504 examples to avoid logging too frequently
skipping logging after 81520 examples to avoid logging too frequently
train stats after 81536 examples: {'rewards_train/chosen': '0.57193', 'rewards_train/rejected': '-6.9425', 'rewards_train/margins': '7.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19885', 'examples_per_second': '4.4826', 'grad_norm': '4.3438', 'counters/examples': 81536, 'counters/updates': 5096}
skipping logging after 81552 examples to avoid logging too frequently
skipping logging after 81568 examples to avoid logging too frequently
skipping logging after 81584 examples to avoid logging too frequently
train stats after 81600 examples: {'rewards_train/chosen': '0.13806', 'rewards_train/rejected': '-4.6737', 'rewards_train/margins': '4.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24402', 'examples_per_second': '5.5856', 'grad_norm': '5.0938', 'counters/examples': 81600, 'counters/updates': 5100}
skipping logging after 81616 examples to avoid logging too frequently
skipping logging after 81632 examples to avoid logging too frequently
skipping logging after 81648 examples to avoid logging too frequently
train stats after 81664 examples: {'rewards_train/chosen': '0.50133', 'rewards_train/rejected': '-6.5571', 'rewards_train/margins': '6.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23151', 'examples_per_second': '5.3253', 'grad_norm': '5.3125', 'counters/examples': 81664, 'counters/updates': 5104}
skipping logging after 81680 examples to avoid logging too frequently
skipping logging after 81696 examples to avoid logging too frequently
skipping logging after 81712 examples to avoid logging too frequently
train stats after 81728 examples: {'rewards_train/chosen': '0.43473', 'rewards_train/rejected': '-5.0265', 'rewards_train/margins': '5.418', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25134', 'examples_per_second': '5.0605', 'grad_norm': '5.3125', 'counters/examples': 81728, 'counters/updates': 5108}
skipping logging after 81744 examples to avoid logging too frequently
skipping logging after 81760 examples to avoid logging too frequently
skipping logging after 81776 examples to avoid logging too frequently
train stats after 81792 examples: {'rewards_train/chosen': '0.53432', 'rewards_train/rejected': '-5.3274', 'rewards_train/margins': '5.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23303', 'examples_per_second': '5.592', 'grad_norm': '5.9062', 'counters/examples': 81792, 'counters/updates': 5112}
skipping logging after 81808 examples to avoid logging too frequently
skipping logging after 81824 examples to avoid logging too frequently
skipping logging after 81840 examples to avoid logging too frequently
train stats after 81856 examples: {'rewards_train/chosen': '0.18329', 'rewards_train/rejected': '-6.8753', 'rewards_train/margins': '6.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28754', 'examples_per_second': '4.6455', 'grad_norm': '5.375', 'counters/examples': 81856, 'counters/updates': 5116}
skipping logging after 81872 examples to avoid logging too frequently
skipping logging after 81888 examples to avoid logging too frequently
skipping logging after 81904 examples to avoid logging too frequently
train stats after 81920 examples: {'rewards_train/chosen': '0.54181', 'rewards_train/rejected': '-4.8955', 'rewards_train/margins': '5.3203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25067', 'examples_per_second': '5.467', 'grad_norm': '5.5312', 'counters/examples': 81920, 'counters/updates': 5120}
skipping logging after 81936 examples to avoid logging too frequently
skipping logging after 81952 examples to avoid logging too frequently
skipping logging after 81968 examples to avoid logging too frequently
train stats after 81984 examples: {'rewards_train/chosen': '0.29659', 'rewards_train/rejected': '-5.1854', 'rewards_train/margins': '5.3594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21576', 'examples_per_second': '4.5706', 'grad_norm': '4.1562', 'counters/examples': 81984, 'counters/updates': 5124}
skipping logging after 82000 examples to avoid logging too frequently
skipping logging after 82016 examples to avoid logging too frequently
skipping logging after 82032 examples to avoid logging too frequently
train stats after 82048 examples: {'rewards_train/chosen': '0.19996', 'rewards_train/rejected': '-5.1025', 'rewards_train/margins': '5.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2384', 'examples_per_second': '5.3611', 'grad_norm': '4.7188', 'counters/examples': 82048, 'counters/updates': 5128}
skipping logging after 82064 examples to avoid logging too frequently
skipping logging after 82080 examples to avoid logging too frequently
skipping logging after 82096 examples to avoid logging too frequently
train stats after 82112 examples: {'rewards_train/chosen': '0.37721', 'rewards_train/rejected': '-6.2977', 'rewards_train/margins': '6.9297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2265', 'examples_per_second': '5.4455', 'grad_norm': '5.0625', 'counters/examples': 82112, 'counters/updates': 5132}
skipping logging after 82128 examples to avoid logging too frequently
skipping logging after 82144 examples to avoid logging too frequently
skipping logging after 82160 examples to avoid logging too frequently
train stats after 82176 examples: {'rewards_train/chosen': '0.33693', 'rewards_train/rejected': '-6.198', 'rewards_train/margins': '6.7578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21088', 'examples_per_second': '4.5867', 'grad_norm': '4.6562', 'counters/examples': 82176, 'counters/updates': 5136}
skipping logging after 82192 examples to avoid logging too frequently
skipping logging after 82208 examples to avoid logging too frequently
skipping logging after 82224 examples to avoid logging too frequently
train stats after 82240 examples: {'rewards_train/chosen': '0.39073', 'rewards_train/rejected': '-6.8223', 'rewards_train/margins': '7.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22791', 'examples_per_second': '5.0803', 'grad_norm': '4.2188', 'counters/examples': 82240, 'counters/updates': 5140}
skipping logging after 82256 examples to avoid logging too frequently
skipping logging after 82272 examples to avoid logging too frequently
skipping logging after 82288 examples to avoid logging too frequently
train stats after 82304 examples: {'rewards_train/chosen': '0.50021', 'rewards_train/rejected': '-6.1556', 'rewards_train/margins': '6.5469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20447', 'examples_per_second': '5.6368', 'grad_norm': '4.5938', 'counters/examples': 82304, 'counters/updates': 5144}
skipping logging after 82320 examples to avoid logging too frequently
skipping logging after 82336 examples to avoid logging too frequently
skipping logging after 82352 examples to avoid logging too frequently
train stats after 82368 examples: {'rewards_train/chosen': '0.41739', 'rewards_train/rejected': '-4.8362', 'rewards_train/margins': '5.0117', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2793', 'examples_per_second': '6.6839', 'grad_norm': '5.5312', 'counters/examples': 82368, 'counters/updates': 5148}
skipping logging after 82384 examples to avoid logging too frequently
skipping logging after 82400 examples to avoid logging too frequently
skipping logging after 82416 examples to avoid logging too frequently
train stats after 82432 examples: {'rewards_train/chosen': '0.6862', 'rewards_train/rejected': '-5.7489', 'rewards_train/margins': '6.3828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23291', 'examples_per_second': '4.8337', 'grad_norm': '5.2188', 'counters/examples': 82432, 'counters/updates': 5152}
skipping logging after 82448 examples to avoid logging too frequently
skipping logging after 82464 examples to avoid logging too frequently
skipping logging after 82480 examples to avoid logging too frequently
train stats after 82496 examples: {'rewards_train/chosen': '0.46038', 'rewards_train/rejected': '-5.1757', 'rewards_train/margins': '5.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28839', 'examples_per_second': '4.7091', 'grad_norm': '5.3438', 'counters/examples': 82496, 'counters/updates': 5156}
skipping logging after 82512 examples to avoid logging too frequently
skipping logging after 82528 examples to avoid logging too frequently
skipping logging after 82544 examples to avoid logging too frequently
train stats after 82560 examples: {'rewards_train/chosen': '0.48533', 'rewards_train/rejected': '-4.5445', 'rewards_train/margins': '5.1289', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24982', 'examples_per_second': '5.497', 'grad_norm': '5.0625', 'counters/examples': 82560, 'counters/updates': 5160}
skipping logging after 82576 examples to avoid logging too frequently
skipping logging after 82592 examples to avoid logging too frequently
skipping logging after 82608 examples to avoid logging too frequently
train stats after 82624 examples: {'rewards_train/chosen': '0.26764', 'rewards_train/rejected': '-4.5743', 'rewards_train/margins': '4.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25287', 'examples_per_second': '5.1471', 'grad_norm': '5.1875', 'counters/examples': 82624, 'counters/updates': 5164}
skipping logging after 82640 examples to avoid logging too frequently
skipping logging after 82656 examples to avoid logging too frequently
skipping logging after 82672 examples to avoid logging too frequently
train stats after 82688 examples: {'rewards_train/chosen': '0.19053', 'rewards_train/rejected': '-5.4695', 'rewards_train/margins': '5.8125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24237', 'examples_per_second': '4.2806', 'grad_norm': '4.4688', 'counters/examples': 82688, 'counters/updates': 5168}
skipping logging after 82704 examples to avoid logging too frequently
skipping logging after 82720 examples to avoid logging too frequently
skipping logging after 82736 examples to avoid logging too frequently
train stats after 82752 examples: {'rewards_train/chosen': '0.34146', 'rewards_train/rejected': '-6.6073', 'rewards_train/margins': '6.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24878', 'examples_per_second': '4.7416', 'grad_norm': '4.9062', 'counters/examples': 82752, 'counters/updates': 5172}
skipping logging after 82768 examples to avoid logging too frequently
skipping logging after 82784 examples to avoid logging too frequently
skipping logging after 82800 examples to avoid logging too frequently
train stats after 82816 examples: {'rewards_train/chosen': '0.6275', 'rewards_train/rejected': '-5.2303', 'rewards_train/margins': '5.8984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22791', 'examples_per_second': '4.3898', 'grad_norm': '4.7188', 'counters/examples': 82816, 'counters/updates': 5176}
skipping logging after 82832 examples to avoid logging too frequently
skipping logging after 82848 examples to avoid logging too frequently
skipping logging after 82864 examples to avoid logging too frequently
train stats after 82880 examples: {'rewards_train/chosen': '0.27225', 'rewards_train/rejected': '-5.9688', 'rewards_train/margins': '6.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23285', 'examples_per_second': '4.8744', 'grad_norm': '4.875', 'counters/examples': 82880, 'counters/updates': 5180}
skipping logging after 82896 examples to avoid logging too frequently
skipping logging after 82912 examples to avoid logging too frequently
skipping logging after 82928 examples to avoid logging too frequently
train stats after 82944 examples: {'rewards_train/chosen': '0.34519', 'rewards_train/rejected': '-4.0317', 'rewards_train/margins': '4.2344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24109', 'examples_per_second': '6.0052', 'grad_norm': '4.6562', 'counters/examples': 82944, 'counters/updates': 5184}
skipping logging after 82960 examples to avoid logging too frequently
skipping logging after 82976 examples to avoid logging too frequently
skipping logging after 82992 examples to avoid logging too frequently
train stats after 83008 examples: {'rewards_train/chosen': '0.31113', 'rewards_train/rejected': '-5.376', 'rewards_train/margins': '5.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25745', 'examples_per_second': '5.6927', 'grad_norm': '5.25', 'counters/examples': 83008, 'counters/updates': 5188}
skipping logging after 83024 examples to avoid logging too frequently
skipping logging after 83040 examples to avoid logging too frequently
skipping logging after 83056 examples to avoid logging too frequently
train stats after 83072 examples: {'rewards_train/chosen': '0.42085', 'rewards_train/rejected': '-5.1712', 'rewards_train/margins': '5.7891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2431', 'examples_per_second': '4.637', 'grad_norm': '4.9375', 'counters/examples': 83072, 'counters/updates': 5192}
skipping logging after 83088 examples to avoid logging too frequently
skipping logging after 83104 examples to avoid logging too frequently
skipping logging after 83120 examples to avoid logging too frequently
train stats after 83136 examples: {'rewards_train/chosen': '0.44703', 'rewards_train/rejected': '-6.9533', 'rewards_train/margins': '7.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21899', 'examples_per_second': '6.1671', 'grad_norm': '5.6875', 'counters/examples': 83136, 'counters/updates': 5196}
skipping logging after 83152 examples to avoid logging too frequently
skipping logging after 83168 examples to avoid logging too frequently
skipping logging after 83184 examples to avoid logging too frequently
train stats after 83200 examples: {'rewards_train/chosen': '0.5618', 'rewards_train/rejected': '-5.5721', 'rewards_train/margins': '6.1172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19861', 'examples_per_second': '5.6504', 'grad_norm': '4.9062', 'counters/examples': 83200, 'counters/updates': 5200}
skipping logging after 83216 examples to avoid logging too frequently
skipping logging after 83232 examples to avoid logging too frequently
skipping logging after 83248 examples to avoid logging too frequently
train stats after 83264 examples: {'rewards_train/chosen': '0.46617', 'rewards_train/rejected': '-5.6855', 'rewards_train/margins': '6.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21082', 'examples_per_second': '5.8407', 'grad_norm': '5', 'counters/examples': 83264, 'counters/updates': 5204}
skipping logging after 83280 examples to avoid logging too frequently
skipping logging after 83296 examples to avoid logging too frequently
skipping logging after 83312 examples to avoid logging too frequently
train stats after 83328 examples: {'rewards_train/chosen': '0.50556', 'rewards_train/rejected': '-5.9125', 'rewards_train/margins': '6.1953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21716', 'examples_per_second': '5.4465', 'grad_norm': '4.625', 'counters/examples': 83328, 'counters/updates': 5208}
skipping logging after 83344 examples to avoid logging too frequently
skipping logging after 83360 examples to avoid logging too frequently
skipping logging after 83376 examples to avoid logging too frequently
train stats after 83392 examples: {'rewards_train/chosen': '0.58806', 'rewards_train/rejected': '-5.5143', 'rewards_train/margins': '6.0859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23962', 'examples_per_second': '4.7117', 'grad_norm': '5.1562', 'counters/examples': 83392, 'counters/updates': 5212}
skipping logging after 83408 examples to avoid logging too frequently
skipping logging after 83424 examples to avoid logging too frequently
skipping logging after 83440 examples to avoid logging too frequently
train stats after 83456 examples: {'rewards_train/chosen': '0.05707', 'rewards_train/rejected': '-4.648', 'rewards_train/margins': '4.5938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29645', 'examples_per_second': '5.2353', 'grad_norm': '5.3125', 'counters/examples': 83456, 'counters/updates': 5216}
skipping logging after 83472 examples to avoid logging too frequently
skipping logging after 83488 examples to avoid logging too frequently
skipping logging after 83504 examples to avoid logging too frequently
train stats after 83520 examples: {'rewards_train/chosen': '0.52494', 'rewards_train/rejected': '-4.5845', 'rewards_train/margins': '5.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21954', 'examples_per_second': '4.3198', 'grad_norm': '5', 'counters/examples': 83520, 'counters/updates': 5220}
skipping logging after 83536 examples to avoid logging too frequently
skipping logging after 83552 examples to avoid logging too frequently
skipping logging after 83568 examples to avoid logging too frequently
train stats after 83584 examples: {'rewards_train/chosen': '0.55714', 'rewards_train/rejected': '-7.0117', 'rewards_train/margins': '7.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23767', 'examples_per_second': '6.2599', 'grad_norm': '4.7812', 'counters/examples': 83584, 'counters/updates': 5224}
skipping logging after 83600 examples to avoid logging too frequently
skipping logging after 83616 examples to avoid logging too frequently
skipping logging after 83632 examples to avoid logging too frequently
train stats after 83648 examples: {'rewards_train/chosen': '0.39146', 'rewards_train/rejected': '-5.3544', 'rewards_train/margins': '5.8906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18878', 'examples_per_second': '5.9653', 'grad_norm': '5', 'counters/examples': 83648, 'counters/updates': 5228}
skipping logging after 83664 examples to avoid logging too frequently
skipping logging after 83680 examples to avoid logging too frequently
skipping logging after 83696 examples to avoid logging too frequently
train stats after 83712 examples: {'rewards_train/chosen': '0.5442', 'rewards_train/rejected': '-7.4529', 'rewards_train/margins': '7.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20947', 'examples_per_second': '4.3463', 'grad_norm': '4.0938', 'counters/examples': 83712, 'counters/updates': 5232}
skipping logging after 83728 examples to avoid logging too frequently
skipping logging after 83744 examples to avoid logging too frequently
skipping logging after 83760 examples to avoid logging too frequently
train stats after 83776 examples: {'rewards_train/chosen': '0.71355', 'rewards_train/rejected': '-4.6536', 'rewards_train/margins': '5.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23254', 'examples_per_second': '6.6239', 'grad_norm': '4.8438', 'counters/examples': 83776, 'counters/updates': 5236}
skipping logging after 83792 examples to avoid logging too frequently
skipping logging after 83808 examples to avoid logging too frequently
skipping logging after 83824 examples to avoid logging too frequently
train stats after 83840 examples: {'rewards_train/chosen': '0.21296', 'rewards_train/rejected': '-5.1248', 'rewards_train/margins': '5.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23853', 'examples_per_second': '5.3734', 'grad_norm': '5.4062', 'counters/examples': 83840, 'counters/updates': 5240}
skipping logging after 83856 examples to avoid logging too frequently
skipping logging after 83872 examples to avoid logging too frequently
skipping logging after 83888 examples to avoid logging too frequently
train stats after 83904 examples: {'rewards_train/chosen': '0.59783', 'rewards_train/rejected': '-6.4248', 'rewards_train/margins': '7.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22711', 'examples_per_second': '5.0207', 'grad_norm': '4.7812', 'counters/examples': 83904, 'counters/updates': 5244}
skipping logging after 83920 examples to avoid logging too frequently
skipping logging after 83936 examples to avoid logging too frequently
skipping logging after 83952 examples to avoid logging too frequently
train stats after 83968 examples: {'rewards_train/chosen': '0.3709', 'rewards_train/rejected': '-5.9998', 'rewards_train/margins': '6.4219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23834', 'examples_per_second': '4.9554', 'grad_norm': '5.2188', 'counters/examples': 83968, 'counters/updates': 5248}
skipping logging after 83984 examples to avoid logging too frequently
skipping logging after 84000 examples to avoid logging too frequently
Running evaluation after 84000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:47,  1.54s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:41,  1.37s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:35,  1.23s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.47s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.68s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.49s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:34,  1.37s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.41s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.31s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.31s/it]
eval after 84000: {'rewards_eval/chosen': '-5.8199', 'rewards_eval/rejected': '-6.2437', 'rewards_eval/margins': '0.26221', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46246'}
skipping logging after 84016 examples to avoid logging too frequently
train stats after 84032 examples: {'rewards_train/chosen': '0.43435', 'rewards_train/rejected': '-5.9081', 'rewards_train/margins': '6.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21936', 'examples_per_second': '5.7342', 'grad_norm': '4.8125', 'counters/examples': 84032, 'counters/updates': 5252}
skipping logging after 84048 examples to avoid logging too frequently
skipping logging after 84064 examples to avoid logging too frequently
skipping logging after 84080 examples to avoid logging too frequently
train stats after 84096 examples: {'rewards_train/chosen': '0.58373', 'rewards_train/rejected': '-6.7715', 'rewards_train/margins': '7.3594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21332', 'examples_per_second': '3.9638', 'grad_norm': '4.125', 'counters/examples': 84096, 'counters/updates': 5256}
skipping logging after 84112 examples to avoid logging too frequently
skipping logging after 84128 examples to avoid logging too frequently
skipping logging after 84144 examples to avoid logging too frequently
train stats after 84160 examples: {'rewards_train/chosen': '0.23019', 'rewards_train/rejected': '-6.4264', 'rewards_train/margins': '6.7656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24048', 'examples_per_second': '5.2535', 'grad_norm': '4.9062', 'counters/examples': 84160, 'counters/updates': 5260}
skipping logging after 84176 examples to avoid logging too frequently
skipping logging after 84192 examples to avoid logging too frequently
skipping logging after 84208 examples to avoid logging too frequently
train stats after 84224 examples: {'rewards_train/chosen': '0.71099', 'rewards_train/rejected': '-5.5663', 'rewards_train/margins': '6', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23901', 'examples_per_second': '5.8263', 'grad_norm': '5.25', 'counters/examples': 84224, 'counters/updates': 5264}
skipping logging after 84240 examples to avoid logging too frequently
skipping logging after 84256 examples to avoid logging too frequently
skipping logging after 84272 examples to avoid logging too frequently
train stats after 84288 examples: {'rewards_train/chosen': '0.38341', 'rewards_train/rejected': '-4.464', 'rewards_train/margins': '4.8672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24493', 'examples_per_second': '7.2162', 'grad_norm': '5.125', 'counters/examples': 84288, 'counters/updates': 5268}
skipping logging after 84304 examples to avoid logging too frequently
skipping logging after 84320 examples to avoid logging too frequently
skipping logging after 84336 examples to avoid logging too frequently
train stats after 84352 examples: {'rewards_train/chosen': '0.57991', 'rewards_train/rejected': '-4.511', 'rewards_train/margins': '5.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24884', 'examples_per_second': '5.7488', 'grad_norm': '5.3438', 'counters/examples': 84352, 'counters/updates': 5272}
skipping logging after 84368 examples to avoid logging too frequently
skipping logging after 84384 examples to avoid logging too frequently
skipping logging after 84400 examples to avoid logging too frequently
train stats after 84416 examples: {'rewards_train/chosen': '0.12923', 'rewards_train/rejected': '-6.5723', 'rewards_train/margins': '6.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27832', 'examples_per_second': '4.6936', 'grad_norm': '5.4688', 'counters/examples': 84416, 'counters/updates': 5276}
skipping logging after 84432 examples to avoid logging too frequently
skipping logging after 84448 examples to avoid logging too frequently
skipping logging after 84464 examples to avoid logging too frequently
train stats after 84480 examples: {'rewards_train/chosen': '0.59831', 'rewards_train/rejected': '-4.6453', 'rewards_train/margins': '5.3281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24359', 'examples_per_second': '4.0574', 'grad_norm': '5.6875', 'counters/examples': 84480, 'counters/updates': 5280}
skipping logging after 84496 examples to avoid logging too frequently
skipping logging after 84512 examples to avoid logging too frequently
skipping logging after 84528 examples to avoid logging too frequently
train stats after 84544 examples: {'rewards_train/chosen': '0.45563', 'rewards_train/rejected': '-6.2436', 'rewards_train/margins': '6.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24646', 'examples_per_second': '4.9538', 'grad_norm': '5.3438', 'counters/examples': 84544, 'counters/updates': 5284}
skipping logging after 84560 examples to avoid logging too frequently
skipping logging after 84576 examples to avoid logging too frequently
skipping logging after 84592 examples to avoid logging too frequently
train stats after 84608 examples: {'rewards_train/chosen': '0.47184', 'rewards_train/rejected': '-5.8002', 'rewards_train/margins': '6.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21088', 'examples_per_second': '5.7462', 'grad_norm': '4.75', 'counters/examples': 84608, 'counters/updates': 5288}
skipping logging after 84624 examples to avoid logging too frequently
skipping logging after 84640 examples to avoid logging too frequently
skipping logging after 84656 examples to avoid logging too frequently
train stats after 84672 examples: {'rewards_train/chosen': '0.44499', 'rewards_train/rejected': '-5.6763', 'rewards_train/margins': '6.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27191', 'examples_per_second': '5.4691', 'grad_norm': '5.1875', 'counters/examples': 84672, 'counters/updates': 5292}
skipping logging after 84688 examples to avoid logging too frequently
skipping logging after 84704 examples to avoid logging too frequently
skipping logging after 84720 examples to avoid logging too frequently
train stats after 84736 examples: {'rewards_train/chosen': '0.31887', 'rewards_train/rejected': '-4.6088', 'rewards_train/margins': '4.8164', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22986', 'examples_per_second': '5.34', 'grad_norm': '5.5625', 'counters/examples': 84736, 'counters/updates': 5296}
skipping logging after 84752 examples to avoid logging too frequently
skipping logging after 84768 examples to avoid logging too frequently
skipping logging after 84784 examples to avoid logging too frequently
train stats after 84800 examples: {'rewards_train/chosen': '0.06092', 'rewards_train/rejected': '-5.4419', 'rewards_train/margins': '5.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21747', 'examples_per_second': '4.9098', 'grad_norm': '4.4375', 'counters/examples': 84800, 'counters/updates': 5300}
skipping logging after 84816 examples to avoid logging too frequently
skipping logging after 84832 examples to avoid logging too frequently
skipping logging after 84848 examples to avoid logging too frequently
train stats after 84864 examples: {'rewards_train/chosen': '0.63246', 'rewards_train/rejected': '-4.8523', 'rewards_train/margins': '5.4219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2157', 'examples_per_second': '6.1879', 'grad_norm': '5.2188', 'counters/examples': 84864, 'counters/updates': 5304}
skipping logging after 84880 examples to avoid logging too frequently
skipping logging after 84896 examples to avoid logging too frequently
skipping logging after 84912 examples to avoid logging too frequently
train stats after 84928 examples: {'rewards_train/chosen': '0.34249', 'rewards_train/rejected': '-5.3579', 'rewards_train/margins': '5.6602', 'rewards_train/KL_estimate': '0', 'loss/train': '0.224', 'examples_per_second': '6.1857', 'grad_norm': '4.2812', 'counters/examples': 84928, 'counters/updates': 5308}
skipping logging after 84944 examples to avoid logging too frequently
skipping logging after 84960 examples to avoid logging too frequently
skipping logging after 84976 examples to avoid logging too frequently
train stats after 84992 examples: {'rewards_train/chosen': '0.66201', 'rewards_train/rejected': '-5.4342', 'rewards_train/margins': '5.918', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22931', 'examples_per_second': '4.7883', 'grad_norm': '5.5', 'counters/examples': 84992, 'counters/updates': 5312}
skipping logging after 85008 examples to avoid logging too frequently
skipping logging after 85024 examples to avoid logging too frequently
skipping logging after 85040 examples to avoid logging too frequently
train stats after 85056 examples: {'rewards_train/chosen': '0.52508', 'rewards_train/rejected': '-5.6013', 'rewards_train/margins': '6.0234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26306', 'examples_per_second': '4.3183', 'grad_norm': '5.125', 'counters/examples': 85056, 'counters/updates': 5316}
skipping logging after 85072 examples to avoid logging too frequently
skipping logging after 85088 examples to avoid logging too frequently
skipping logging after 85104 examples to avoid logging too frequently
train stats after 85120 examples: {'rewards_train/chosen': '0.47788', 'rewards_train/rejected': '-5.8454', 'rewards_train/margins': '6.2266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22705', 'examples_per_second': '6.0842', 'grad_norm': '4.9688', 'counters/examples': 85120, 'counters/updates': 5320}
skipping logging after 85136 examples to avoid logging too frequently
skipping logging after 85152 examples to avoid logging too frequently
skipping logging after 85168 examples to avoid logging too frequently
train stats after 85184 examples: {'rewards_train/chosen': '0.40704', 'rewards_train/rejected': '-5.2373', 'rewards_train/margins': '5.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27087', 'examples_per_second': '5.5938', 'grad_norm': '5.2812', 'counters/examples': 85184, 'counters/updates': 5324}
skipping logging after 85200 examples to avoid logging too frequently
skipping logging after 85216 examples to avoid logging too frequently
skipping logging after 85232 examples to avoid logging too frequently
train stats after 85248 examples: {'rewards_train/chosen': '0.4921', 'rewards_train/rejected': '-5.5664', 'rewards_train/margins': '6.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19476', 'examples_per_second': '4.5362', 'grad_norm': '4.5', 'counters/examples': 85248, 'counters/updates': 5328}
skipping logging after 85264 examples to avoid logging too frequently
skipping logging after 85280 examples to avoid logging too frequently
skipping logging after 85296 examples to avoid logging too frequently
train stats after 85312 examples: {'rewards_train/chosen': '0.44982', 'rewards_train/rejected': '-5.5091', 'rewards_train/margins': '5.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21265', 'examples_per_second': '4.7651', 'grad_norm': '4.0625', 'counters/examples': 85312, 'counters/updates': 5332}
skipping logging after 85328 examples to avoid logging too frequently
skipping logging after 85344 examples to avoid logging too frequently
skipping logging after 85360 examples to avoid logging too frequently
train stats after 85376 examples: {'rewards_train/chosen': '0.27291', 'rewards_train/rejected': '-6.2808', 'rewards_train/margins': '6.0547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23792', 'examples_per_second': '5.8386', 'grad_norm': '5.4062', 'counters/examples': 85376, 'counters/updates': 5336}
skipping logging after 85392 examples to avoid logging too frequently
skipping logging after 85408 examples to avoid logging too frequently
skipping logging after 85424 examples to avoid logging too frequently
train stats after 85440 examples: {'rewards_train/chosen': '0.38054', 'rewards_train/rejected': '-5.5544', 'rewards_train/margins': '5.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24487', 'examples_per_second': '4.8289', 'grad_norm': '5.0938', 'counters/examples': 85440, 'counters/updates': 5340}
skipping logging after 85456 examples to avoid logging too frequently
skipping logging after 85472 examples to avoid logging too frequently
skipping logging after 85488 examples to avoid logging too frequently
train stats after 85504 examples: {'rewards_train/chosen': '0.4495', 'rewards_train/rejected': '-5.7791', 'rewards_train/margins': '6.4219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24805', 'examples_per_second': '4.7225', 'grad_norm': '6.0312', 'counters/examples': 85504, 'counters/updates': 5344}
skipping logging after 85520 examples to avoid logging too frequently
skipping logging after 85536 examples to avoid logging too frequently
skipping logging after 85552 examples to avoid logging too frequently
train stats after 85568 examples: {'rewards_train/chosen': '0.34794', 'rewards_train/rejected': '-5.9358', 'rewards_train/margins': '6.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22589', 'examples_per_second': '5.0803', 'grad_norm': '4.4688', 'counters/examples': 85568, 'counters/updates': 5348}
skipping logging after 85584 examples to avoid logging too frequently
skipping logging after 85600 examples to avoid logging too frequently
skipping logging after 85616 examples to avoid logging too frequently
train stats after 85632 examples: {'rewards_train/chosen': '0.58395', 'rewards_train/rejected': '-5.5856', 'rewards_train/margins': '6.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21802', 'examples_per_second': '5.6104', 'grad_norm': '4.9375', 'counters/examples': 85632, 'counters/updates': 5352}
skipping logging after 85648 examples to avoid logging too frequently
skipping logging after 85664 examples to avoid logging too frequently
skipping logging after 85680 examples to avoid logging too frequently
train stats after 85696 examples: {'rewards_train/chosen': '0.31462', 'rewards_train/rejected': '-6.384', 'rewards_train/margins': '6.8203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22443', 'examples_per_second': '4.3354', 'grad_norm': '5', 'counters/examples': 85696, 'counters/updates': 5356}
skipping logging after 85712 examples to avoid logging too frequently
skipping logging after 85728 examples to avoid logging too frequently
skipping logging after 85744 examples to avoid logging too frequently
train stats after 85760 examples: {'rewards_train/chosen': '0.28401', 'rewards_train/rejected': '-6.5823', 'rewards_train/margins': '6.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26111', 'examples_per_second': '4.8957', 'grad_norm': '5', 'counters/examples': 85760, 'counters/updates': 5360}
skipping logging after 85776 examples to avoid logging too frequently
skipping logging after 85792 examples to avoid logging too frequently
skipping logging after 85808 examples to avoid logging too frequently
train stats after 85824 examples: {'rewards_train/chosen': '0.5557', 'rewards_train/rejected': '-5.8095', 'rewards_train/margins': '6.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21576', 'examples_per_second': '5.2953', 'grad_norm': '4.5', 'counters/examples': 85824, 'counters/updates': 5364}
skipping logging after 85840 examples to avoid logging too frequently
skipping logging after 85856 examples to avoid logging too frequently
skipping logging after 85872 examples to avoid logging too frequently
train stats after 85888 examples: {'rewards_train/chosen': '0.50006', 'rewards_train/rejected': '-5.3941', 'rewards_train/margins': '5.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22455', 'examples_per_second': '4.9193', 'grad_norm': '5.8125', 'counters/examples': 85888, 'counters/updates': 5368}
skipping logging after 85904 examples to avoid logging too frequently
skipping logging after 85920 examples to avoid logging too frequently
skipping logging after 85936 examples to avoid logging too frequently
train stats after 85952 examples: {'rewards_train/chosen': '0.13431', 'rewards_train/rejected': '-6.6712', 'rewards_train/margins': '6.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28491', 'examples_per_second': '5.9222', 'grad_norm': '5.125', 'counters/examples': 85952, 'counters/updates': 5372}
skipping logging after 85968 examples to avoid logging too frequently
skipping logging after 85984 examples to avoid logging too frequently
skipping logging after 86000 examples to avoid logging too frequently
train stats after 86016 examples: {'rewards_train/chosen': '0.31729', 'rewards_train/rejected': '-4.7274', 'rewards_train/margins': '5.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29431', 'examples_per_second': '5.7923', 'grad_norm': '5.75', 'counters/examples': 86016, 'counters/updates': 5376}
skipping logging after 86032 examples to avoid logging too frequently
skipping logging after 86048 examples to avoid logging too frequently
skipping logging after 86064 examples to avoid logging too frequently
train stats after 86080 examples: {'rewards_train/chosen': '0.40246', 'rewards_train/rejected': '-5.5473', 'rewards_train/margins': '5.8906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18976', 'examples_per_second': '5.1734', 'grad_norm': '5.625', 'counters/examples': 86080, 'counters/updates': 5380}
skipping logging after 86096 examples to avoid logging too frequently
skipping logging after 86112 examples to avoid logging too frequently
skipping logging after 86128 examples to avoid logging too frequently
train stats after 86144 examples: {'rewards_train/chosen': '0.73199', 'rewards_train/rejected': '-5.8466', 'rewards_train/margins': '6.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19751', 'examples_per_second': '4.4802', 'grad_norm': '6', 'counters/examples': 86144, 'counters/updates': 5384}
skipping logging after 86160 examples to avoid logging too frequently
skipping logging after 86176 examples to avoid logging too frequently
skipping logging after 86192 examples to avoid logging too frequently
train stats after 86208 examples: {'rewards_train/chosen': '0.44372', 'rewards_train/rejected': '-6.3041', 'rewards_train/margins': '6.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25256', 'examples_per_second': '4.5973', 'grad_norm': '4.9688', 'counters/examples': 86208, 'counters/updates': 5388}
skipping logging after 86224 examples to avoid logging too frequently
skipping logging after 86240 examples to avoid logging too frequently
skipping logging after 86256 examples to avoid logging too frequently
train stats after 86272 examples: {'rewards_train/chosen': '0.58187', 'rewards_train/rejected': '-4.7918', 'rewards_train/margins': '5.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21796', 'examples_per_second': '4.6284', 'grad_norm': '4.7188', 'counters/examples': 86272, 'counters/updates': 5392}
skipping logging after 86288 examples to avoid logging too frequently
skipping logging after 86304 examples to avoid logging too frequently
skipping logging after 86320 examples to avoid logging too frequently
train stats after 86336 examples: {'rewards_train/chosen': '0.21341', 'rewards_train/rejected': '-5.6881', 'rewards_train/margins': '6.0352', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25476', 'examples_per_second': '5.9898', 'grad_norm': '5.2812', 'counters/examples': 86336, 'counters/updates': 5396}
skipping logging after 86352 examples to avoid logging too frequently
skipping logging after 86368 examples to avoid logging too frequently
skipping logging after 86384 examples to avoid logging too frequently
train stats after 86400 examples: {'rewards_train/chosen': '0.44258', 'rewards_train/rejected': '-6.2398', 'rewards_train/margins': '6.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25299', 'examples_per_second': '5.2749', 'grad_norm': '5.0938', 'counters/examples': 86400, 'counters/updates': 5400}
skipping logging after 86416 examples to avoid logging too frequently
skipping logging after 86432 examples to avoid logging too frequently
skipping logging after 86448 examples to avoid logging too frequently
train stats after 86464 examples: {'rewards_train/chosen': '0.0224', 'rewards_train/rejected': '-5.3312', 'rewards_train/margins': '5.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2403', 'examples_per_second': '5.3597', 'grad_norm': '4.4688', 'counters/examples': 86464, 'counters/updates': 5404}
skipping logging after 86480 examples to avoid logging too frequently
skipping logging after 86496 examples to avoid logging too frequently
skipping logging after 86512 examples to avoid logging too frequently
train stats after 86528 examples: {'rewards_train/chosen': '0.35721', 'rewards_train/rejected': '-6.0312', 'rewards_train/margins': '6.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19812', 'examples_per_second': '5.1344', 'grad_norm': '4.6562', 'counters/examples': 86528, 'counters/updates': 5408}
skipping logging after 86544 examples to avoid logging too frequently
skipping logging after 86560 examples to avoid logging too frequently
skipping logging after 86576 examples to avoid logging too frequently
train stats after 86592 examples: {'rewards_train/chosen': '0.10822', 'rewards_train/rejected': '-5.3187', 'rewards_train/margins': '5.3867', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27094', 'examples_per_second': '4.2875', 'grad_norm': '5.5312', 'counters/examples': 86592, 'counters/updates': 5412}
skipping logging after 86608 examples to avoid logging too frequently
skipping logging after 86624 examples to avoid logging too frequently
skipping logging after 86640 examples to avoid logging too frequently
train stats after 86656 examples: {'rewards_train/chosen': '0.35301', 'rewards_train/rejected': '-6.2852', 'rewards_train/margins': '6.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24475', 'examples_per_second': '4.3856', 'grad_norm': '3.8438', 'counters/examples': 86656, 'counters/updates': 5416}
skipping logging after 86672 examples to avoid logging too frequently
skipping logging after 86688 examples to avoid logging too frequently
skipping logging after 86704 examples to avoid logging too frequently
train stats after 86720 examples: {'rewards_train/chosen': '0.36092', 'rewards_train/rejected': '-5.9249', 'rewards_train/margins': '6.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23651', 'examples_per_second': '4.8281', 'grad_norm': '21.625', 'counters/examples': 86720, 'counters/updates': 5420}
skipping logging after 86736 examples to avoid logging too frequently
skipping logging after 86752 examples to avoid logging too frequently
skipping logging after 86768 examples to avoid logging too frequently
train stats after 86784 examples: {'rewards_train/chosen': '0.12814', 'rewards_train/rejected': '-5.6514', 'rewards_train/margins': '5.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20135', 'examples_per_second': '5.9007', 'grad_norm': '5.0625', 'counters/examples': 86784, 'counters/updates': 5424}
skipping logging after 86800 examples to avoid logging too frequently
skipping logging after 86816 examples to avoid logging too frequently
skipping logging after 86832 examples to avoid logging too frequently
train stats after 86848 examples: {'rewards_train/chosen': '0.62669', 'rewards_train/rejected': '-6.2505', 'rewards_train/margins': '6.7734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18695', 'examples_per_second': '4.5963', 'grad_norm': '4.5625', 'counters/examples': 86848, 'counters/updates': 5428}
skipping logging after 86864 examples to avoid logging too frequently
skipping logging after 86880 examples to avoid logging too frequently
skipping logging after 86896 examples to avoid logging too frequently
train stats after 86912 examples: {'rewards_train/chosen': '0.39678', 'rewards_train/rejected': '-5.2503', 'rewards_train/margins': '5.7891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26965', 'examples_per_second': '4.7291', 'grad_norm': '4.9688', 'counters/examples': 86912, 'counters/updates': 5432}
skipping logging after 86928 examples to avoid logging too frequently
skipping logging after 86944 examples to avoid logging too frequently
skipping logging after 86960 examples to avoid logging too frequently
train stats after 86976 examples: {'rewards_train/chosen': '0.36883', 'rewards_train/rejected': '-5.9971', 'rewards_train/margins': '6.7266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20831', 'examples_per_second': '5.4459', 'grad_norm': '10.562', 'counters/examples': 86976, 'counters/updates': 5436}
skipping logging after 86992 examples to avoid logging too frequently
skipping logging after 87008 examples to avoid logging too frequently
skipping logging after 87024 examples to avoid logging too frequently
train stats after 87040 examples: {'rewards_train/chosen': '0.3102', 'rewards_train/rejected': '-7.1887', 'rewards_train/margins': '7.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28485', 'examples_per_second': '4.6899', 'grad_norm': '6.7188', 'counters/examples': 87040, 'counters/updates': 5440}
skipping logging after 87056 examples to avoid logging too frequently
skipping logging after 87072 examples to avoid logging too frequently
skipping logging after 87088 examples to avoid logging too frequently
train stats after 87104 examples: {'rewards_train/chosen': '0.62415', 'rewards_train/rejected': '-4.9297', 'rewards_train/margins': '5.4492', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20306', 'examples_per_second': '5.4561', 'grad_norm': '5.4375', 'counters/examples': 87104, 'counters/updates': 5444}
skipping logging after 87120 examples to avoid logging too frequently
skipping logging after 87136 examples to avoid logging too frequently
skipping logging after 87152 examples to avoid logging too frequently
train stats after 87168 examples: {'rewards_train/chosen': '0.42157', 'rewards_train/rejected': '-5.8031', 'rewards_train/margins': '6.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24017', 'examples_per_second': '5.4152', 'grad_norm': '5.2188', 'counters/examples': 87168, 'counters/updates': 5448}
skipping logging after 87184 examples to avoid logging too frequently
skipping logging after 87200 examples to avoid logging too frequently
skipping logging after 87216 examples to avoid logging too frequently
train stats after 87232 examples: {'rewards_train/chosen': '0.2852', 'rewards_train/rejected': '-5.3778', 'rewards_train/margins': '5.1406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23895', 'examples_per_second': '5.2617', 'grad_norm': '4.9375', 'counters/examples': 87232, 'counters/updates': 5452}
skipping logging after 87248 examples to avoid logging too frequently
skipping logging after 87264 examples to avoid logging too frequently
skipping logging after 87280 examples to avoid logging too frequently
train stats after 87296 examples: {'rewards_train/chosen': '0.49797', 'rewards_train/rejected': '-6.3925', 'rewards_train/margins': '6.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18292', 'examples_per_second': '4.8823', 'grad_norm': '4.2188', 'counters/examples': 87296, 'counters/updates': 5456}
skipping logging after 87312 examples to avoid logging too frequently
skipping logging after 87328 examples to avoid logging too frequently
skipping logging after 87344 examples to avoid logging too frequently
train stats after 87360 examples: {'rewards_train/chosen': '0.17759', 'rewards_train/rejected': '-6.883', 'rewards_train/margins': '7.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17346', 'examples_per_second': '5.5979', 'grad_norm': '4.2812', 'counters/examples': 87360, 'counters/updates': 5460}
skipping logging after 87376 examples to avoid logging too frequently
skipping logging after 87392 examples to avoid logging too frequently
skipping logging after 87408 examples to avoid logging too frequently
train stats after 87424 examples: {'rewards_train/chosen': '0.58089', 'rewards_train/rejected': '-6.8189', 'rewards_train/margins': '7.4609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.16443', 'examples_per_second': '5.3165', 'grad_norm': '5.0312', 'counters/examples': 87424, 'counters/updates': 5464}
skipping logging after 87440 examples to avoid logging too frequently
skipping logging after 87456 examples to avoid logging too frequently
skipping logging after 87472 examples to avoid logging too frequently
train stats after 87488 examples: {'rewards_train/chosen': '0.70668', 'rewards_train/rejected': '-6.348', 'rewards_train/margins': '7.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19385', 'examples_per_second': '4.6806', 'grad_norm': '4.7188', 'counters/examples': 87488, 'counters/updates': 5468}
skipping logging after 87504 examples to avoid logging too frequently
skipping logging after 87520 examples to avoid logging too frequently
skipping logging after 87536 examples to avoid logging too frequently
train stats after 87552 examples: {'rewards_train/chosen': '0.38433', 'rewards_train/rejected': '-6.1047', 'rewards_train/margins': '6.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21307', 'examples_per_second': '4.5446', 'grad_norm': '5.375', 'counters/examples': 87552, 'counters/updates': 5472}
skipping logging after 87568 examples to avoid logging too frequently
skipping logging after 87584 examples to avoid logging too frequently
skipping logging after 87600 examples to avoid logging too frequently
train stats after 87616 examples: {'rewards_train/chosen': '0.31316', 'rewards_train/rejected': '-5.2589', 'rewards_train/margins': '5.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25977', 'examples_per_second': '5.7683', 'grad_norm': '5.125', 'counters/examples': 87616, 'counters/updates': 5476}
skipping logging after 87632 examples to avoid logging too frequently
skipping logging after 87648 examples to avoid logging too frequently
skipping logging after 87664 examples to avoid logging too frequently
train stats after 87680 examples: {'rewards_train/chosen': '0.071037', 'rewards_train/rejected': '-4.9004', 'rewards_train/margins': '4.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24518', 'examples_per_second': '5.0654', 'grad_norm': '5.4375', 'counters/examples': 87680, 'counters/updates': 5480}
skipping logging after 87696 examples to avoid logging too frequently
skipping logging after 87712 examples to avoid logging too frequently
skipping logging after 87728 examples to avoid logging too frequently
train stats after 87744 examples: {'rewards_train/chosen': '0.25082', 'rewards_train/rejected': '-4.6535', 'rewards_train/margins': '4.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24115', 'examples_per_second': '5.4211', 'grad_norm': '5.6562', 'counters/examples': 87744, 'counters/updates': 5484}
skipping logging after 87760 examples to avoid logging too frequently
skipping logging after 87776 examples to avoid logging too frequently
skipping logging after 87792 examples to avoid logging too frequently
train stats after 87808 examples: {'rewards_train/chosen': '0.65809', 'rewards_train/rejected': '-5.6171', 'rewards_train/margins': '6.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18884', 'examples_per_second': '4.3476', 'grad_norm': '4.9375', 'counters/examples': 87808, 'counters/updates': 5488}
skipping logging after 87824 examples to avoid logging too frequently
skipping logging after 87840 examples to avoid logging too frequently
skipping logging after 87856 examples to avoid logging too frequently
train stats after 87872 examples: {'rewards_train/chosen': '0.36552', 'rewards_train/rejected': '-5.4956', 'rewards_train/margins': '5.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27222', 'examples_per_second': '5.134', 'grad_norm': '5.25', 'counters/examples': 87872, 'counters/updates': 5492}
skipping logging after 87888 examples to avoid logging too frequently
skipping logging after 87904 examples to avoid logging too frequently
skipping logging after 87920 examples to avoid logging too frequently
train stats after 87936 examples: {'rewards_train/chosen': '0.087683', 'rewards_train/rejected': '-7.274', 'rewards_train/margins': '7.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26917', 'examples_per_second': '4.5794', 'grad_norm': '4.25', 'counters/examples': 87936, 'counters/updates': 5496}
skipping logging after 87952 examples to avoid logging too frequently
skipping logging after 87968 examples to avoid logging too frequently
skipping logging after 87984 examples to avoid logging too frequently
train stats after 88000 examples: {'rewards_train/chosen': '0.32827', 'rewards_train/rejected': '-6.3455', 'rewards_train/margins': '6.4219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24066', 'examples_per_second': '5.1386', 'grad_norm': '5.7188', 'counters/examples': 88000, 'counters/updates': 5500}
Running evaluation after 88000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.25s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.17s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:40,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.65s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.47s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:34,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.51s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.40s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.22s/it]Computing eval metrics:  50%|█████     | 16/32 [00:21<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.42s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.18s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.31s/it]
eval after 88000: {'rewards_eval/chosen': '-5.2728', 'rewards_eval/rejected': '-5.5491', 'rewards_eval/margins': '0.13721', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46723'}
skipping logging after 88016 examples to avoid logging too frequently
skipping logging after 88032 examples to avoid logging too frequently
skipping logging after 88048 examples to avoid logging too frequently
train stats after 88064 examples: {'rewards_train/chosen': '0.43487', 'rewards_train/rejected': '-4.9305', 'rewards_train/margins': '5.4141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21667', 'examples_per_second': '4.4506', 'grad_norm': '4.375', 'counters/examples': 88064, 'counters/updates': 5504}
skipping logging after 88080 examples to avoid logging too frequently
skipping logging after 88096 examples to avoid logging too frequently
skipping logging after 88112 examples to avoid logging too frequently
train stats after 88128 examples: {'rewards_train/chosen': '0.45869', 'rewards_train/rejected': '-5.7386', 'rewards_train/margins': '6.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25171', 'examples_per_second': '5.2722', 'grad_norm': '5.3438', 'counters/examples': 88128, 'counters/updates': 5508}
skipping logging after 88144 examples to avoid logging too frequently
skipping logging after 88160 examples to avoid logging too frequently
skipping logging after 88176 examples to avoid logging too frequently
train stats after 88192 examples: {'rewards_train/chosen': '0.66655', 'rewards_train/rejected': '-5.9655', 'rewards_train/margins': '6.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20258', 'examples_per_second': '5.2478', 'grad_norm': '4.25', 'counters/examples': 88192, 'counters/updates': 5512}
skipping logging after 88208 examples to avoid logging too frequently
skipping logging after 88224 examples to avoid logging too frequently
skipping logging after 88240 examples to avoid logging too frequently
train stats after 88256 examples: {'rewards_train/chosen': '0.34643', 'rewards_train/rejected': '-6.0819', 'rewards_train/margins': '6.0156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24719', 'examples_per_second': '5.3533', 'grad_norm': '5.5', 'counters/examples': 88256, 'counters/updates': 5516}
skipping logging after 88272 examples to avoid logging too frequently
skipping logging after 88288 examples to avoid logging too frequently
skipping logging after 88304 examples to avoid logging too frequently
train stats after 88320 examples: {'rewards_train/chosen': '0.31653', 'rewards_train/rejected': '-5.4977', 'rewards_train/margins': '5.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22736', 'examples_per_second': '4.8115', 'grad_norm': '4.7812', 'counters/examples': 88320, 'counters/updates': 5520}
skipping logging after 88336 examples to avoid logging too frequently
skipping logging after 88352 examples to avoid logging too frequently
skipping logging after 88368 examples to avoid logging too frequently
train stats after 88384 examples: {'rewards_train/chosen': '0.13406', 'rewards_train/rejected': '-4.5376', 'rewards_train/margins': '4.4961', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21307', 'examples_per_second': '5.979', 'grad_norm': '4.4688', 'counters/examples': 88384, 'counters/updates': 5524}
skipping logging after 88400 examples to avoid logging too frequently
skipping logging after 88416 examples to avoid logging too frequently
skipping logging after 88432 examples to avoid logging too frequently
train stats after 88448 examples: {'rewards_train/chosen': '0.51455', 'rewards_train/rejected': '-5.4713', 'rewards_train/margins': '5.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2442', 'examples_per_second': '4.7007', 'grad_norm': '5.5625', 'counters/examples': 88448, 'counters/updates': 5528}
skipping logging after 88464 examples to avoid logging too frequently
skipping logging after 88480 examples to avoid logging too frequently
skipping logging after 88496 examples to avoid logging too frequently
train stats after 88512 examples: {'rewards_train/chosen': '0.41489', 'rewards_train/rejected': '-5.2375', 'rewards_train/margins': '5.7109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23059', 'examples_per_second': '3.8286', 'grad_norm': '4.4375', 'counters/examples': 88512, 'counters/updates': 5532}
skipping logging after 88528 examples to avoid logging too frequently
skipping logging after 88544 examples to avoid logging too frequently
skipping logging after 88560 examples to avoid logging too frequently
train stats after 88576 examples: {'rewards_train/chosen': '0.21668', 'rewards_train/rejected': '-5.0107', 'rewards_train/margins': '5.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30872', 'examples_per_second': '5.8184', 'grad_norm': '5.125', 'counters/examples': 88576, 'counters/updates': 5536}
skipping logging after 88592 examples to avoid logging too frequently
skipping logging after 88608 examples to avoid logging too frequently
skipping logging after 88624 examples to avoid logging too frequently
train stats after 88640 examples: {'rewards_train/chosen': '0.29851', 'rewards_train/rejected': '-4.8672', 'rewards_train/margins': '5.1172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24707', 'examples_per_second': '5.2837', 'grad_norm': '5.7188', 'counters/examples': 88640, 'counters/updates': 5540}
skipping logging after 88656 examples to avoid logging too frequently
skipping logging after 88672 examples to avoid logging too frequently
skipping logging after 88688 examples to avoid logging too frequently
train stats after 88704 examples: {'rewards_train/chosen': '0.38592', 'rewards_train/rejected': '-4.5426', 'rewards_train/margins': '5.043', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25818', 'examples_per_second': '4.5089', 'grad_norm': '6.2188', 'counters/examples': 88704, 'counters/updates': 5544}
skipping logging after 88720 examples to avoid logging too frequently
skipping logging after 88736 examples to avoid logging too frequently
skipping logging after 88752 examples to avoid logging too frequently
train stats after 88768 examples: {'rewards_train/chosen': '0.33098', 'rewards_train/rejected': '-5.3994', 'rewards_train/margins': '5.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2572', 'examples_per_second': '5.4563', 'grad_norm': '4.9062', 'counters/examples': 88768, 'counters/updates': 5548}
skipping logging after 88784 examples to avoid logging too frequently
skipping logging after 88800 examples to avoid logging too frequently
skipping logging after 88816 examples to avoid logging too frequently
train stats after 88832 examples: {'rewards_train/chosen': '0.51429', 'rewards_train/rejected': '-5.3966', 'rewards_train/margins': '6.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17963', 'examples_per_second': '4.8374', 'grad_norm': '4.625', 'counters/examples': 88832, 'counters/updates': 5552}
skipping logging after 88848 examples to avoid logging too frequently
skipping logging after 88864 examples to avoid logging too frequently
skipping logging after 88880 examples to avoid logging too frequently
train stats after 88896 examples: {'rewards_train/chosen': '0.43175', 'rewards_train/rejected': '-5.6072', 'rewards_train/margins': '5.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1795', 'examples_per_second': '4.2611', 'grad_norm': '4', 'counters/examples': 88896, 'counters/updates': 5556}
skipping logging after 88912 examples to avoid logging too frequently
skipping logging after 88928 examples to avoid logging too frequently
skipping logging after 88944 examples to avoid logging too frequently
train stats after 88960 examples: {'rewards_train/chosen': '0.37615', 'rewards_train/rejected': '-4.3444', 'rewards_train/margins': '4.6641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25952', 'examples_per_second': '5.8227', 'grad_norm': '4.4688', 'counters/examples': 88960, 'counters/updates': 5560}
skipping logging after 88976 examples to avoid logging too frequently
skipping logging after 88992 examples to avoid logging too frequently
skipping logging after 89008 examples to avoid logging too frequently
train stats after 89024 examples: {'rewards_train/chosen': '0.33594', 'rewards_train/rejected': '-6.4716', 'rewards_train/margins': '6.7031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2381', 'examples_per_second': '5.1599', 'grad_norm': '6.6875', 'counters/examples': 89024, 'counters/updates': 5564}
skipping logging after 89040 examples to avoid logging too frequently
skipping logging after 89056 examples to avoid logging too frequently
skipping logging after 89072 examples to avoid logging too frequently
train stats after 89088 examples: {'rewards_train/chosen': '0.52043', 'rewards_train/rejected': '-5.0251', 'rewards_train/margins': '5.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20496', 'examples_per_second': '5.6269', 'grad_norm': '5.3125', 'counters/examples': 89088, 'counters/updates': 5568}
skipping logging after 89104 examples to avoid logging too frequently
skipping logging after 89120 examples to avoid logging too frequently
skipping logging after 89136 examples to avoid logging too frequently
train stats after 89152 examples: {'rewards_train/chosen': '0.22273', 'rewards_train/rejected': '-4.4993', 'rewards_train/margins': '4.7422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24457', 'examples_per_second': '7.1598', 'grad_norm': '5.7812', 'counters/examples': 89152, 'counters/updates': 5572}
skipping logging after 89168 examples to avoid logging too frequently
skipping logging after 89184 examples to avoid logging too frequently
skipping logging after 89200 examples to avoid logging too frequently
train stats after 89216 examples: {'rewards_train/chosen': '0.48577', 'rewards_train/rejected': '-6.2479', 'rewards_train/margins': '6.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23712', 'examples_per_second': '5.1444', 'grad_norm': '5.5', 'counters/examples': 89216, 'counters/updates': 5576}
skipping logging after 89232 examples to avoid logging too frequently
skipping logging after 89248 examples to avoid logging too frequently
skipping logging after 89264 examples to avoid logging too frequently
train stats after 89280 examples: {'rewards_train/chosen': '0.50491', 'rewards_train/rejected': '-5.1739', 'rewards_train/margins': '5.7031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19763', 'examples_per_second': '5.2664', 'grad_norm': '4.0625', 'counters/examples': 89280, 'counters/updates': 5580}
skipping logging after 89296 examples to avoid logging too frequently
skipping logging after 89312 examples to avoid logging too frequently
skipping logging after 89328 examples to avoid logging too frequently
train stats after 89344 examples: {'rewards_train/chosen': '0.53307', 'rewards_train/rejected': '-5.2635', 'rewards_train/margins': '5.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18762', 'examples_per_second': '4.9303', 'grad_norm': '4.9688', 'counters/examples': 89344, 'counters/updates': 5584}
skipping logging after 89360 examples to avoid logging too frequently
skipping logging after 89376 examples to avoid logging too frequently
skipping logging after 89392 examples to avoid logging too frequently
train stats after 89408 examples: {'rewards_train/chosen': '0.246', 'rewards_train/rejected': '-4.6829', 'rewards_train/margins': '4.7305', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25201', 'examples_per_second': '5.4921', 'grad_norm': '4.9062', 'counters/examples': 89408, 'counters/updates': 5588}
skipping logging after 89424 examples to avoid logging too frequently
skipping logging after 89440 examples to avoid logging too frequently
skipping logging after 89456 examples to avoid logging too frequently
train stats after 89472 examples: {'rewards_train/chosen': '0.60612', 'rewards_train/rejected': '-4.8803', 'rewards_train/margins': '5.1992', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21619', 'examples_per_second': '5.2505', 'grad_norm': '5.625', 'counters/examples': 89472, 'counters/updates': 5592}
skipping logging after 89488 examples to avoid logging too frequently
skipping logging after 89504 examples to avoid logging too frequently
skipping logging after 89520 examples to avoid logging too frequently
train stats after 89536 examples: {'rewards_train/chosen': '-0.055712', 'rewards_train/rejected': '-6.8044', 'rewards_train/margins': '6.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23401', 'examples_per_second': '5.1184', 'grad_norm': '3.75', 'counters/examples': 89536, 'counters/updates': 5596}
skipping logging after 89552 examples to avoid logging too frequently
skipping logging after 89568 examples to avoid logging too frequently
skipping logging after 89584 examples to avoid logging too frequently
train stats after 89600 examples: {'rewards_train/chosen': '0.39314', 'rewards_train/rejected': '-5.443', 'rewards_train/margins': '5.8125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23505', 'examples_per_second': '6.5923', 'grad_norm': '5.25', 'counters/examples': 89600, 'counters/updates': 5600}
skipping logging after 89616 examples to avoid logging too frequently
skipping logging after 89632 examples to avoid logging too frequently
skipping logging after 89648 examples to avoid logging too frequently
train stats after 89664 examples: {'rewards_train/chosen': '0.41061', 'rewards_train/rejected': '-5.9965', 'rewards_train/margins': '6.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18689', 'examples_per_second': '5.3566', 'grad_norm': '3.7031', 'counters/examples': 89664, 'counters/updates': 5604}
skipping logging after 89680 examples to avoid logging too frequently
skipping logging after 89696 examples to avoid logging too frequently
skipping logging after 89712 examples to avoid logging too frequently
train stats after 89728 examples: {'rewards_train/chosen': '0.40687', 'rewards_train/rejected': '-6.3617', 'rewards_train/margins': '6.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23236', 'examples_per_second': '5.7428', 'grad_norm': '4.6875', 'counters/examples': 89728, 'counters/updates': 5608}
skipping logging after 89744 examples to avoid logging too frequently
skipping logging after 89760 examples to avoid logging too frequently
skipping logging after 89776 examples to avoid logging too frequently
train stats after 89792 examples: {'rewards_train/chosen': '0.47661', 'rewards_train/rejected': '-5.7092', 'rewards_train/margins': '5.9141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22528', 'examples_per_second': '5.4443', 'grad_norm': '5.1562', 'counters/examples': 89792, 'counters/updates': 5612}
skipping logging after 89808 examples to avoid logging too frequently
skipping logging after 89824 examples to avoid logging too frequently
skipping logging after 89840 examples to avoid logging too frequently
train stats after 89856 examples: {'rewards_train/chosen': '0.74213', 'rewards_train/rejected': '-5.2877', 'rewards_train/margins': '6.0234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17444', 'examples_per_second': '5.3469', 'grad_norm': '4.2812', 'counters/examples': 89856, 'counters/updates': 5616}
skipping logging after 89872 examples to avoid logging too frequently
skipping logging after 89888 examples to avoid logging too frequently
skipping logging after 89904 examples to avoid logging too frequently
train stats after 89920 examples: {'rewards_train/chosen': '0.29434', 'rewards_train/rejected': '-5.8833', 'rewards_train/margins': '6.0234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25354', 'examples_per_second': '5.555', 'grad_norm': '5.1875', 'counters/examples': 89920, 'counters/updates': 5620}
skipping logging after 89936 examples to avoid logging too frequently
skipping logging after 89952 examples to avoid logging too frequently
skipping logging after 89968 examples to avoid logging too frequently
train stats after 89984 examples: {'rewards_train/chosen': '0.33151', 'rewards_train/rejected': '-5.2324', 'rewards_train/margins': '5.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25531', 'examples_per_second': '5.285', 'grad_norm': '4.7188', 'counters/examples': 89984, 'counters/updates': 5624}
skipping logging after 90000 examples to avoid logging too frequently
skipping logging after 90016 examples to avoid logging too frequently
skipping logging after 90032 examples to avoid logging too frequently
train stats after 90048 examples: {'rewards_train/chosen': '0.46163', 'rewards_train/rejected': '-5.4536', 'rewards_train/margins': '5.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20837', 'examples_per_second': '5.1531', 'grad_norm': '5.5625', 'counters/examples': 90048, 'counters/updates': 5628}
skipping logging after 90064 examples to avoid logging too frequently
skipping logging after 90080 examples to avoid logging too frequently
skipping logging after 90096 examples to avoid logging too frequently
train stats after 90112 examples: {'rewards_train/chosen': '0.36633', 'rewards_train/rejected': '-5.618', 'rewards_train/margins': '5.7812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24042', 'examples_per_second': '4.1261', 'grad_norm': '5.375', 'counters/examples': 90112, 'counters/updates': 5632}
skipping logging after 90128 examples to avoid logging too frequently
skipping logging after 90144 examples to avoid logging too frequently
skipping logging after 90160 examples to avoid logging too frequently
train stats after 90176 examples: {'rewards_train/chosen': '0.30186', 'rewards_train/rejected': '-7.6958', 'rewards_train/margins': '8.2344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23492', 'examples_per_second': '4.166', 'grad_norm': '5.1875', 'counters/examples': 90176, 'counters/updates': 5636}
skipping logging after 90192 examples to avoid logging too frequently
skipping logging after 90208 examples to avoid logging too frequently
skipping logging after 90224 examples to avoid logging too frequently
train stats after 90240 examples: {'rewards_train/chosen': '0.50337', 'rewards_train/rejected': '-6.4827', 'rewards_train/margins': '7.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19775', 'examples_per_second': '4.4126', 'grad_norm': '4.4688', 'counters/examples': 90240, 'counters/updates': 5640}
skipping logging after 90256 examples to avoid logging too frequently
skipping logging after 90272 examples to avoid logging too frequently
skipping logging after 90288 examples to avoid logging too frequently
train stats after 90304 examples: {'rewards_train/chosen': '0.45473', 'rewards_train/rejected': '-5.4043', 'rewards_train/margins': '5.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26416', 'examples_per_second': '4.5735', 'grad_norm': '5.3438', 'counters/examples': 90304, 'counters/updates': 5644}
skipping logging after 90320 examples to avoid logging too frequently
skipping logging after 90336 examples to avoid logging too frequently
skipping logging after 90352 examples to avoid logging too frequently
train stats after 90368 examples: {'rewards_train/chosen': '0.3229', 'rewards_train/rejected': '-5.436', 'rewards_train/margins': '5.6016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21405', 'examples_per_second': '4.5607', 'grad_norm': '5.8125', 'counters/examples': 90368, 'counters/updates': 5648}
skipping logging after 90384 examples to avoid logging too frequently
skipping logging after 90400 examples to avoid logging too frequently
skipping logging after 90416 examples to avoid logging too frequently
train stats after 90432 examples: {'rewards_train/chosen': '0.59355', 'rewards_train/rejected': '-4.9215', 'rewards_train/margins': '5.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20422', 'examples_per_second': '6.1346', 'grad_norm': '5.0625', 'counters/examples': 90432, 'counters/updates': 5652}
skipping logging after 90448 examples to avoid logging too frequently
skipping logging after 90464 examples to avoid logging too frequently
skipping logging after 90480 examples to avoid logging too frequently
train stats after 90496 examples: {'rewards_train/chosen': '0.67974', 'rewards_train/rejected': '-5.0885', 'rewards_train/margins': '5.6016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2356', 'examples_per_second': '5.9474', 'grad_norm': '6.4062', 'counters/examples': 90496, 'counters/updates': 5656}
skipping logging after 90512 examples to avoid logging too frequently
skipping logging after 90528 examples to avoid logging too frequently
skipping logging after 90544 examples to avoid logging too frequently
train stats after 90560 examples: {'rewards_train/chosen': '0.13866', 'rewards_train/rejected': '-5.7669', 'rewards_train/margins': '5.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24493', 'examples_per_second': '4.8267', 'grad_norm': '5.6875', 'counters/examples': 90560, 'counters/updates': 5660}
skipping logging after 90576 examples to avoid logging too frequently
skipping logging after 90592 examples to avoid logging too frequently
skipping logging after 90608 examples to avoid logging too frequently
train stats after 90624 examples: {'rewards_train/chosen': '0.075283', 'rewards_train/rejected': '-5.8114', 'rewards_train/margins': '5.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23627', 'examples_per_second': '4.9649', 'grad_norm': '4.5', 'counters/examples': 90624, 'counters/updates': 5664}
skipping logging after 90640 examples to avoid logging too frequently
skipping logging after 90656 examples to avoid logging too frequently
skipping logging after 90672 examples to avoid logging too frequently
train stats after 90688 examples: {'rewards_train/chosen': '0.45771', 'rewards_train/rejected': '-5.1825', 'rewards_train/margins': '5.3203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23242', 'examples_per_second': '4.7977', 'grad_norm': '5.8125', 'counters/examples': 90688, 'counters/updates': 5668}
skipping logging after 90704 examples to avoid logging too frequently
skipping logging after 90720 examples to avoid logging too frequently
skipping logging after 90736 examples to avoid logging too frequently
train stats after 90752 examples: {'rewards_train/chosen': '-0.0060216', 'rewards_train/rejected': '-7.6036', 'rewards_train/margins': '7.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27271', 'examples_per_second': '5.2966', 'grad_norm': '5.5', 'counters/examples': 90752, 'counters/updates': 5672}
skipping logging after 90768 examples to avoid logging too frequently
skipping logging after 90784 examples to avoid logging too frequently
skipping logging after 90800 examples to avoid logging too frequently
train stats after 90816 examples: {'rewards_train/chosen': '0.39532', 'rewards_train/rejected': '-4.7969', 'rewards_train/margins': '5.375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28625', 'examples_per_second': '5.2854', 'grad_norm': '4.4688', 'counters/examples': 90816, 'counters/updates': 5676}
skipping logging after 90832 examples to avoid logging too frequently
skipping logging after 90848 examples to avoid logging too frequently
skipping logging after 90864 examples to avoid logging too frequently
train stats after 90880 examples: {'rewards_train/chosen': '0.41818', 'rewards_train/rejected': '-6.7502', 'rewards_train/margins': '6.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27136', 'examples_per_second': '5.2092', 'grad_norm': '5.2812', 'counters/examples': 90880, 'counters/updates': 5680}
skipping logging after 90896 examples to avoid logging too frequently
skipping logging after 90912 examples to avoid logging too frequently
skipping logging after 90928 examples to avoid logging too frequently
train stats after 90944 examples: {'rewards_train/chosen': '0.42259', 'rewards_train/rejected': '-6.1169', 'rewards_train/margins': '6.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25098', 'examples_per_second': '5.4608', 'grad_norm': '6.25', 'counters/examples': 90944, 'counters/updates': 5684}
skipping logging after 90960 examples to avoid logging too frequently
skipping logging after 90976 examples to avoid logging too frequently
skipping logging after 90992 examples to avoid logging too frequently
train stats after 91008 examples: {'rewards_train/chosen': '0.31089', 'rewards_train/rejected': '-5.5531', 'rewards_train/margins': '6.1719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24353', 'examples_per_second': '5.7185', 'grad_norm': '4.1562', 'counters/examples': 91008, 'counters/updates': 5688}
skipping logging after 91024 examples to avoid logging too frequently
skipping logging after 91040 examples to avoid logging too frequently
skipping logging after 91056 examples to avoid logging too frequently
train stats after 91072 examples: {'rewards_train/chosen': '0.44377', 'rewards_train/rejected': '-5.616', 'rewards_train/margins': '5.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28107', 'examples_per_second': '5.2386', 'grad_norm': '4.0625', 'counters/examples': 91072, 'counters/updates': 5692}
skipping logging after 91088 examples to avoid logging too frequently
skipping logging after 91104 examples to avoid logging too frequently
skipping logging after 91120 examples to avoid logging too frequently
train stats after 91136 examples: {'rewards_train/chosen': '0.30976', 'rewards_train/rejected': '-5.7325', 'rewards_train/margins': '5.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25281', 'examples_per_second': '4.6929', 'grad_norm': '5.5625', 'counters/examples': 91136, 'counters/updates': 5696}
skipping logging after 91152 examples to avoid logging too frequently
skipping logging after 91168 examples to avoid logging too frequently
skipping logging after 91184 examples to avoid logging too frequently
train stats after 91200 examples: {'rewards_train/chosen': '0.25146', 'rewards_train/rejected': '-6.1616', 'rewards_train/margins': '6.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21613', 'examples_per_second': '5.4608', 'grad_norm': '3.7812', 'counters/examples': 91200, 'counters/updates': 5700}
skipping logging after 91216 examples to avoid logging too frequently
skipping logging after 91232 examples to avoid logging too frequently
skipping logging after 91248 examples to avoid logging too frequently
train stats after 91264 examples: {'rewards_train/chosen': '0.49408', 'rewards_train/rejected': '-5.0401', 'rewards_train/margins': '5.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23425', 'examples_per_second': '5.2443', 'grad_norm': '4.625', 'counters/examples': 91264, 'counters/updates': 5704}
skipping logging after 91280 examples to avoid logging too frequently
skipping logging after 91296 examples to avoid logging too frequently
skipping logging after 91312 examples to avoid logging too frequently
train stats after 91328 examples: {'rewards_train/chosen': '0.54933', 'rewards_train/rejected': '-6.0193', 'rewards_train/margins': '6.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22382', 'examples_per_second': '6.2608', 'grad_norm': '5.9375', 'counters/examples': 91328, 'counters/updates': 5708}
skipping logging after 91344 examples to avoid logging too frequently
skipping logging after 91360 examples to avoid logging too frequently
skipping logging after 91376 examples to avoid logging too frequently
train stats after 91392 examples: {'rewards_train/chosen': '0.45742', 'rewards_train/rejected': '-5.1272', 'rewards_train/margins': '5.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22583', 'examples_per_second': '4.6435', 'grad_norm': '5.0312', 'counters/examples': 91392, 'counters/updates': 5712}
skipping logging after 91408 examples to avoid logging too frequently
skipping logging after 91424 examples to avoid logging too frequently
skipping logging after 91440 examples to avoid logging too frequently
train stats after 91456 examples: {'rewards_train/chosen': '0.65604', 'rewards_train/rejected': '-5.9469', 'rewards_train/margins': '6.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21564', 'examples_per_second': '5.8835', 'grad_norm': '5.2188', 'counters/examples': 91456, 'counters/updates': 5716}
skipping logging after 91472 examples to avoid logging too frequently
skipping logging after 91488 examples to avoid logging too frequently
skipping logging after 91504 examples to avoid logging too frequently
train stats after 91520 examples: {'rewards_train/chosen': '0.21362', 'rewards_train/rejected': '-4.4573', 'rewards_train/margins': '4.6562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27899', 'examples_per_second': '6.0669', 'grad_norm': '5.9375', 'counters/examples': 91520, 'counters/updates': 5720}
skipping logging after 91536 examples to avoid logging too frequently
skipping logging after 91552 examples to avoid logging too frequently
skipping logging after 91568 examples to avoid logging too frequently
train stats after 91584 examples: {'rewards_train/chosen': '0.58334', 'rewards_train/rejected': '-6.1519', 'rewards_train/margins': '6.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19287', 'examples_per_second': '4.3385', 'grad_norm': '4.8125', 'counters/examples': 91584, 'counters/updates': 5724}
skipping logging after 91600 examples to avoid logging too frequently
skipping logging after 91616 examples to avoid logging too frequently
skipping logging after 91632 examples to avoid logging too frequently
train stats after 91648 examples: {'rewards_train/chosen': '0.42269', 'rewards_train/rejected': '-5.7418', 'rewards_train/margins': '6.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21545', 'examples_per_second': '5.4146', 'grad_norm': '5.8438', 'counters/examples': 91648, 'counters/updates': 5728}
skipping logging after 91664 examples to avoid logging too frequently
skipping logging after 91680 examples to avoid logging too frequently
skipping logging after 91696 examples to avoid logging too frequently
train stats after 91712 examples: {'rewards_train/chosen': '0.2847', 'rewards_train/rejected': '-3.8471', 'rewards_train/margins': '4.2148', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28564', 'examples_per_second': '5.6771', 'grad_norm': '5.0312', 'counters/examples': 91712, 'counters/updates': 5732}
skipping logging after 91728 examples to avoid logging too frequently
skipping logging after 91744 examples to avoid logging too frequently
skipping logging after 91760 examples to avoid logging too frequently
train stats after 91776 examples: {'rewards_train/chosen': '0.13899', 'rewards_train/rejected': '-5.6965', 'rewards_train/margins': '5.6562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22827', 'examples_per_second': '5.213', 'grad_norm': '4.9688', 'counters/examples': 91776, 'counters/updates': 5736}
skipping logging after 91792 examples to avoid logging too frequently
skipping logging after 91808 examples to avoid logging too frequently
skipping logging after 91824 examples to avoid logging too frequently
train stats after 91840 examples: {'rewards_train/chosen': '0.3634', 'rewards_train/rejected': '-5.8231', 'rewards_train/margins': '6.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24597', 'examples_per_second': '5.6045', 'grad_norm': '4.9688', 'counters/examples': 91840, 'counters/updates': 5740}
skipping logging after 91856 examples to avoid logging too frequently
skipping logging after 91872 examples to avoid logging too frequently
skipping logging after 91888 examples to avoid logging too frequently
train stats after 91904 examples: {'rewards_train/chosen': '0.45129', 'rewards_train/rejected': '-6.0829', 'rewards_train/margins': '6.5469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23492', 'examples_per_second': '5.8787', 'grad_norm': '4.5625', 'counters/examples': 91904, 'counters/updates': 5744}
skipping logging after 91920 examples to avoid logging too frequently
skipping logging after 91936 examples to avoid logging too frequently
skipping logging after 91952 examples to avoid logging too frequently
train stats after 91968 examples: {'rewards_train/chosen': '0.27795', 'rewards_train/rejected': '-4.9841', 'rewards_train/margins': '5.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22595', 'examples_per_second': '6.4941', 'grad_norm': '4.9688', 'counters/examples': 91968, 'counters/updates': 5748}
skipping logging after 91984 examples to avoid logging too frequently
skipping logging after 92000 examples to avoid logging too frequently
Running evaluation after 92000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:56,  1.83s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:44,  1.49s/it]Computing eval metrics:   9%|▉         | 3/32 [00:04<00:37,  1.29s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:42,  1.51s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:45,  1.70s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:09<00:39,  1.50s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:10<00:34,  1.38s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:12<00:36,  1.53s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.49s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:20<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:21<00:20,  1.22s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.13s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:27<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:28<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.17s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:12,  1.44s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.31s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:38<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:40<00:02,  1.18s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:41<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.12s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]
eval after 92000: {'rewards_eval/chosen': '-5.7576', 'rewards_eval/rejected': '-6.0719', 'rewards_eval/margins': '0.1499', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46675'}
skipping logging after 92016 examples to avoid logging too frequently
train stats after 92032 examples: {'rewards_train/chosen': '-0.15099', 'rewards_train/rejected': '-5.9366', 'rewards_train/margins': '5.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22284', 'examples_per_second': '5.8217', 'grad_norm': '4.5625', 'counters/examples': 92032, 'counters/updates': 5752}
skipping logging after 92048 examples to avoid logging too frequently
skipping logging after 92064 examples to avoid logging too frequently
skipping logging after 92080 examples to avoid logging too frequently
train stats after 92096 examples: {'rewards_train/chosen': '0.44499', 'rewards_train/rejected': '-5.8759', 'rewards_train/margins': '6.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25226', 'examples_per_second': '4.7959', 'grad_norm': '5.1562', 'counters/examples': 92096, 'counters/updates': 5756}
skipping logging after 92112 examples to avoid logging too frequently
skipping logging after 92128 examples to avoid logging too frequently
skipping logging after 92144 examples to avoid logging too frequently
train stats after 92160 examples: {'rewards_train/chosen': '0.48216', 'rewards_train/rejected': '-5.7574', 'rewards_train/margins': '6.3281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23126', 'examples_per_second': '4.4045', 'grad_norm': '4.4062', 'counters/examples': 92160, 'counters/updates': 5760}
skipping logging after 92176 examples to avoid logging too frequently
skipping logging after 92192 examples to avoid logging too frequently
skipping logging after 92208 examples to avoid logging too frequently
train stats after 92224 examples: {'rewards_train/chosen': '0.37945', 'rewards_train/rejected': '-4.8304', 'rewards_train/margins': '5.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26093', 'examples_per_second': '5.4285', 'grad_norm': '5.375', 'counters/examples': 92224, 'counters/updates': 5764}
skipping logging after 92240 examples to avoid logging too frequently
skipping logging after 92256 examples to avoid logging too frequently
skipping logging after 92272 examples to avoid logging too frequently
train stats after 92288 examples: {'rewards_train/chosen': '0.48467', 'rewards_train/rejected': '-5.7665', 'rewards_train/margins': '6.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26306', 'examples_per_second': '5.2727', 'grad_norm': '4.8438', 'counters/examples': 92288, 'counters/updates': 5768}
skipping logging after 92304 examples to avoid logging too frequently
skipping logging after 92320 examples to avoid logging too frequently
skipping logging after 92336 examples to avoid logging too frequently
train stats after 92352 examples: {'rewards_train/chosen': '0.55143', 'rewards_train/rejected': '-5.4347', 'rewards_train/margins': '6.0547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20654', 'examples_per_second': '5.6721', 'grad_norm': '4.6875', 'counters/examples': 92352, 'counters/updates': 5772}
skipping logging after 92368 examples to avoid logging too frequently
skipping logging after 92384 examples to avoid logging too frequently
skipping logging after 92400 examples to avoid logging too frequently
train stats after 92416 examples: {'rewards_train/chosen': '0.509', 'rewards_train/rejected': '-6.3244', 'rewards_train/margins': '6.8984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24744', 'examples_per_second': '5.5956', 'grad_norm': '5.4688', 'counters/examples': 92416, 'counters/updates': 5776}
skipping logging after 92432 examples to avoid logging too frequently
skipping logging after 92448 examples to avoid logging too frequently
skipping logging after 92464 examples to avoid logging too frequently
train stats after 92480 examples: {'rewards_train/chosen': '0.28026', 'rewards_train/rejected': '-5.86', 'rewards_train/margins': '6.2109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26483', 'examples_per_second': '4.8266', 'grad_norm': '5.125', 'counters/examples': 92480, 'counters/updates': 5780}
skipping logging after 92496 examples to avoid logging too frequently
skipping logging after 92512 examples to avoid logging too frequently
skipping logging after 92528 examples to avoid logging too frequently
train stats after 92544 examples: {'rewards_train/chosen': '0.52214', 'rewards_train/rejected': '-5.1695', 'rewards_train/margins': '5.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22729', 'examples_per_second': '5.9761', 'grad_norm': '4.4688', 'counters/examples': 92544, 'counters/updates': 5784}
skipping logging after 92560 examples to avoid logging too frequently
skipping logging after 92576 examples to avoid logging too frequently
skipping logging after 92592 examples to avoid logging too frequently
train stats after 92608 examples: {'rewards_train/chosen': '0.29583', 'rewards_train/rejected': '-5.9473', 'rewards_train/margins': '6.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27057', 'examples_per_second': '5.7367', 'grad_norm': '5.4375', 'counters/examples': 92608, 'counters/updates': 5788}
skipping logging after 92624 examples to avoid logging too frequently
skipping logging after 92640 examples to avoid logging too frequently
skipping logging after 92656 examples to avoid logging too frequently
train stats after 92672 examples: {'rewards_train/chosen': '0.613', 'rewards_train/rejected': '-5.0482', 'rewards_train/margins': '5.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22534', 'examples_per_second': '5.6013', 'grad_norm': '4.5312', 'counters/examples': 92672, 'counters/updates': 5792}
skipping logging after 92688 examples to avoid logging too frequently
skipping logging after 92704 examples to avoid logging too frequently
skipping logging after 92720 examples to avoid logging too frequently
train stats after 92736 examples: {'rewards_train/chosen': '0.55303', 'rewards_train/rejected': '-4.0707', 'rewards_train/margins': '4.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26758', 'examples_per_second': '5.5543', 'grad_norm': '5.6875', 'counters/examples': 92736, 'counters/updates': 5796}
skipping logging after 92752 examples to avoid logging too frequently
skipping logging after 92768 examples to avoid logging too frequently
skipping logging after 92784 examples to avoid logging too frequently
train stats after 92800 examples: {'rewards_train/chosen': '0.37184', 'rewards_train/rejected': '-4.5723', 'rewards_train/margins': '5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23535', 'examples_per_second': '4.7395', 'grad_norm': '4.5938', 'counters/examples': 92800, 'counters/updates': 5800}
skipping logging after 92816 examples to avoid logging too frequently
skipping logging after 92832 examples to avoid logging too frequently
skipping logging after 92848 examples to avoid logging too frequently
train stats after 92864 examples: {'rewards_train/chosen': '0.48053', 'rewards_train/rejected': '-6.1241', 'rewards_train/margins': '7.0234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25421', 'examples_per_second': '6.1139', 'grad_norm': '5.4062', 'counters/examples': 92864, 'counters/updates': 5804}
skipping logging after 92880 examples to avoid logging too frequently
skipping logging after 92896 examples to avoid logging too frequently
skipping logging after 92912 examples to avoid logging too frequently
train stats after 92928 examples: {'rewards_train/chosen': '-0.29124', 'rewards_train/rejected': '-5.5304', 'rewards_train/margins': '5.0742', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25848', 'examples_per_second': '4.5651', 'grad_norm': '5.125', 'counters/examples': 92928, 'counters/updates': 5808}
skipping logging after 92944 examples to avoid logging too frequently
skipping logging after 92960 examples to avoid logging too frequently
skipping logging after 92976 examples to avoid logging too frequently
train stats after 92992 examples: {'rewards_train/chosen': '0.50515', 'rewards_train/rejected': '-6.015', 'rewards_train/margins': '6.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22498', 'examples_per_second': '4.4484', 'grad_norm': '5.6875', 'counters/examples': 92992, 'counters/updates': 5812}
skipping logging after 93008 examples to avoid logging too frequently
skipping logging after 93024 examples to avoid logging too frequently
skipping logging after 93040 examples to avoid logging too frequently
train stats after 93056 examples: {'rewards_train/chosen': '0.31118', 'rewards_train/rejected': '-5.7871', 'rewards_train/margins': '5.9727', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22632', 'examples_per_second': '5.6293', 'grad_norm': '4.6562', 'counters/examples': 93056, 'counters/updates': 5816}
skipping logging after 93072 examples to avoid logging too frequently
skipping logging after 93088 examples to avoid logging too frequently
skipping logging after 93104 examples to avoid logging too frequently
train stats after 93120 examples: {'rewards_train/chosen': '0.20312', 'rewards_train/rejected': '-5.304', 'rewards_train/margins': '5.5781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25708', 'examples_per_second': '5.7997', 'grad_norm': '5.2188', 'counters/examples': 93120, 'counters/updates': 5820}
skipping logging after 93136 examples to avoid logging too frequently
skipping logging after 93152 examples to avoid logging too frequently
skipping logging after 93168 examples to avoid logging too frequently
train stats after 93184 examples: {'rewards_train/chosen': '0.57178', 'rewards_train/rejected': '-5.2804', 'rewards_train/margins': '5.6484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22156', 'examples_per_second': '4.5909', 'grad_norm': '5.2188', 'counters/examples': 93184, 'counters/updates': 5824}
skipping logging after 93200 examples to avoid logging too frequently
skipping logging after 93216 examples to avoid logging too frequently
skipping logging after 93232 examples to avoid logging too frequently
train stats after 93248 examples: {'rewards_train/chosen': '0.38467', 'rewards_train/rejected': '-4.889', 'rewards_train/margins': '5.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26709', 'examples_per_second': '6.0042', 'grad_norm': '4.5938', 'counters/examples': 93248, 'counters/updates': 5828}
skipping logging after 93264 examples to avoid logging too frequently
skipping logging after 93280 examples to avoid logging too frequently
skipping logging after 93296 examples to avoid logging too frequently
train stats after 93312 examples: {'rewards_train/chosen': '0.31653', 'rewards_train/rejected': '-5.2745', 'rewards_train/margins': '5.6914', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25684', 'examples_per_second': '5.6699', 'grad_norm': '6.0312', 'counters/examples': 93312, 'counters/updates': 5832}
skipping logging after 93328 examples to avoid logging too frequently
skipping logging after 93344 examples to avoid logging too frequently
skipping logging after 93360 examples to avoid logging too frequently
train stats after 93376 examples: {'rewards_train/chosen': '0.57219', 'rewards_train/rejected': '-3.6884', 'rewards_train/margins': '4.0859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26434', 'examples_per_second': '6.3792', 'grad_norm': '4.4688', 'counters/examples': 93376, 'counters/updates': 5836}
skipping logging after 93392 examples to avoid logging too frequently
skipping logging after 93408 examples to avoid logging too frequently
skipping logging after 93424 examples to avoid logging too frequently
train stats after 93440 examples: {'rewards_train/chosen': '0.49301', 'rewards_train/rejected': '-6.5024', 'rewards_train/margins': '7.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2049', 'examples_per_second': '6.1437', 'grad_norm': '4.75', 'counters/examples': 93440, 'counters/updates': 5840}
skipping logging after 93456 examples to avoid logging too frequently
skipping logging after 93472 examples to avoid logging too frequently
skipping logging after 93488 examples to avoid logging too frequently
train stats after 93504 examples: {'rewards_train/chosen': '0.31748', 'rewards_train/rejected': '-6.0948', 'rewards_train/margins': '6.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21637', 'examples_per_second': '4.8957', 'grad_norm': '4.5312', 'counters/examples': 93504, 'counters/updates': 5844}
skipping logging after 93520 examples to avoid logging too frequently
skipping logging after 93536 examples to avoid logging too frequently
skipping logging after 93552 examples to avoid logging too frequently
train stats after 93568 examples: {'rewards_train/chosen': '0.46478', 'rewards_train/rejected': '-6.7664', 'rewards_train/margins': '7.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24506', 'examples_per_second': '3.9509', 'grad_norm': '5.1562', 'counters/examples': 93568, 'counters/updates': 5848}
skipping logging after 93584 examples to avoid logging too frequently
skipping logging after 93600 examples to avoid logging too frequently
skipping logging after 93616 examples to avoid logging too frequently
train stats after 93632 examples: {'rewards_train/chosen': '0.33611', 'rewards_train/rejected': '-6.0642', 'rewards_train/margins': '6.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20575', 'examples_per_second': '4.5412', 'grad_norm': '4.4688', 'counters/examples': 93632, 'counters/updates': 5852}
skipping logging after 93648 examples to avoid logging too frequently
skipping logging after 93664 examples to avoid logging too frequently
skipping logging after 93680 examples to avoid logging too frequently
train stats after 93696 examples: {'rewards_train/chosen': '0.47974', 'rewards_train/rejected': '-5.9266', 'rewards_train/margins': '6.4844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20959', 'examples_per_second': '5.7076', 'grad_norm': '4.8125', 'counters/examples': 93696, 'counters/updates': 5856}
skipping logging after 93712 examples to avoid logging too frequently
skipping logging after 93728 examples to avoid logging too frequently
skipping logging after 93744 examples to avoid logging too frequently
train stats after 93760 examples: {'rewards_train/chosen': '0.044125', 'rewards_train/rejected': '-7.0522', 'rewards_train/margins': '7.1406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25049', 'examples_per_second': '7.016', 'grad_norm': '4.5938', 'counters/examples': 93760, 'counters/updates': 5860}
skipping logging after 93776 examples to avoid logging too frequently
skipping logging after 93792 examples to avoid logging too frequently
skipping logging after 93808 examples to avoid logging too frequently
train stats after 93824 examples: {'rewards_train/chosen': '0.46513', 'rewards_train/rejected': '-4.3238', 'rewards_train/margins': '4.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24347', 'examples_per_second': '6.1888', 'grad_norm': '5.5625', 'counters/examples': 93824, 'counters/updates': 5864}
skipping logging after 93840 examples to avoid logging too frequently
skipping logging after 93856 examples to avoid logging too frequently
skipping logging after 93872 examples to avoid logging too frequently
train stats after 93888 examples: {'rewards_train/chosen': '0.6289', 'rewards_train/rejected': '-5.0776', 'rewards_train/margins': '5.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22906', 'examples_per_second': '5.3659', 'grad_norm': '5.0938', 'counters/examples': 93888, 'counters/updates': 5868}
skipping logging after 93904 examples to avoid logging too frequently
skipping logging after 93920 examples to avoid logging too frequently
skipping logging after 93936 examples to avoid logging too frequently
train stats after 93952 examples: {'rewards_train/chosen': '0.3823', 'rewards_train/rejected': '-4.9436', 'rewards_train/margins': '5.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18188', 'examples_per_second': '5.4477', 'grad_norm': '5.25', 'counters/examples': 93952, 'counters/updates': 5872}
skipping logging after 93968 examples to avoid logging too frequently
skipping logging after 93984 examples to avoid logging too frequently
skipping logging after 94000 examples to avoid logging too frequently
train stats after 94016 examples: {'rewards_train/chosen': '0.20976', 'rewards_train/rejected': '-6.252', 'rewards_train/margins': '6.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23914', 'examples_per_second': '5.6083', 'grad_norm': '4.75', 'counters/examples': 94016, 'counters/updates': 5876}
skipping logging after 94032 examples to avoid logging too frequently
skipping logging after 94048 examples to avoid logging too frequently
skipping logging after 94064 examples to avoid logging too frequently
train stats after 94080 examples: {'rewards_train/chosen': '0.73536', 'rewards_train/rejected': '-4.71', 'rewards_train/margins': '5.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22968', 'examples_per_second': '5.4257', 'grad_norm': '4.8125', 'counters/examples': 94080, 'counters/updates': 5880}
skipping logging after 94096 examples to avoid logging too frequently
skipping logging after 94112 examples to avoid logging too frequently
skipping logging after 94128 examples to avoid logging too frequently
train stats after 94144 examples: {'rewards_train/chosen': '0.56653', 'rewards_train/rejected': '-4.9345', 'rewards_train/margins': '5.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25916', 'examples_per_second': '5.4176', 'grad_norm': '6.4062', 'counters/examples': 94144, 'counters/updates': 5884}
skipping logging after 94160 examples to avoid logging too frequently
skipping logging after 94176 examples to avoid logging too frequently
skipping logging after 94192 examples to avoid logging too frequently
train stats after 94208 examples: {'rewards_train/chosen': '0.46531', 'rewards_train/rejected': '-5.749', 'rewards_train/margins': '6.3203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17169', 'examples_per_second': '5.7616', 'grad_norm': '4.7812', 'counters/examples': 94208, 'counters/updates': 5888}
skipping logging after 94224 examples to avoid logging too frequently
skipping logging after 94240 examples to avoid logging too frequently
skipping logging after 94256 examples to avoid logging too frequently
train stats after 94272 examples: {'rewards_train/chosen': '0.69573', 'rewards_train/rejected': '-5.6313', 'rewards_train/margins': '6.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19952', 'examples_per_second': '4.7701', 'grad_norm': '3.7656', 'counters/examples': 94272, 'counters/updates': 5892}
skipping logging after 94288 examples to avoid logging too frequently
skipping logging after 94304 examples to avoid logging too frequently
skipping logging after 94320 examples to avoid logging too frequently
train stats after 94336 examples: {'rewards_train/chosen': '0.57609', 'rewards_train/rejected': '-5.8259', 'rewards_train/margins': '6.4844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22894', 'examples_per_second': '4.9022', 'grad_norm': '4.5312', 'counters/examples': 94336, 'counters/updates': 5896}
skipping logging after 94352 examples to avoid logging too frequently
skipping logging after 94368 examples to avoid logging too frequently
skipping logging after 94384 examples to avoid logging too frequently
train stats after 94400 examples: {'rewards_train/chosen': '0.5213', 'rewards_train/rejected': '-6.7351', 'rewards_train/margins': '7.125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2561', 'examples_per_second': '5.7361', 'grad_norm': '4.8125', 'counters/examples': 94400, 'counters/updates': 5900}
skipping logging after 94416 examples to avoid logging too frequently
skipping logging after 94432 examples to avoid logging too frequently
skipping logging after 94448 examples to avoid logging too frequently
train stats after 94464 examples: {'rewards_train/chosen': '0.41818', 'rewards_train/rejected': '-6.3165', 'rewards_train/margins': '6.9141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24017', 'examples_per_second': '4.3352', 'grad_norm': '4.4062', 'counters/examples': 94464, 'counters/updates': 5904}
skipping logging after 94480 examples to avoid logging too frequently
skipping logging after 94496 examples to avoid logging too frequently
skipping logging after 94512 examples to avoid logging too frequently
train stats after 94528 examples: {'rewards_train/chosen': '0.44689', 'rewards_train/rejected': '-5.4619', 'rewards_train/margins': '6.2344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21979', 'examples_per_second': '6.0495', 'grad_norm': '4.8438', 'counters/examples': 94528, 'counters/updates': 5908}
skipping logging after 94544 examples to avoid logging too frequently
skipping logging after 94560 examples to avoid logging too frequently
skipping logging after 94576 examples to avoid logging too frequently
train stats after 94592 examples: {'rewards_train/chosen': '0.57704', 'rewards_train/rejected': '-5.2672', 'rewards_train/margins': '5.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20648', 'examples_per_second': '6.8104', 'grad_norm': '4.5938', 'counters/examples': 94592, 'counters/updates': 5912}
skipping logging after 94608 examples to avoid logging too frequently
skipping logging after 94624 examples to avoid logging too frequently
skipping logging after 94640 examples to avoid logging too frequently
train stats after 94656 examples: {'rewards_train/chosen': '0.64891', 'rewards_train/rejected': '-6.6368', 'rewards_train/margins': '7.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1908', 'examples_per_second': '4.4186', 'grad_norm': '4.6875', 'counters/examples': 94656, 'counters/updates': 5916}
skipping logging after 94672 examples to avoid logging too frequently
skipping logging after 94688 examples to avoid logging too frequently
skipping logging after 94704 examples to avoid logging too frequently
train stats after 94720 examples: {'rewards_train/chosen': '0.41348', 'rewards_train/rejected': '-6.067', 'rewards_train/margins': '6.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28082', 'examples_per_second': '5.006', 'grad_norm': '6.0625', 'counters/examples': 94720, 'counters/updates': 5920}
skipping logging after 94736 examples to avoid logging too frequently
skipping logging after 94752 examples to avoid logging too frequently
skipping logging after 94768 examples to avoid logging too frequently
train stats after 94784 examples: {'rewards_train/chosen': '0.62861', 'rewards_train/rejected': '-5.9387', 'rewards_train/margins': '6.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22284', 'examples_per_second': '4.0216', 'grad_norm': '4.6562', 'counters/examples': 94784, 'counters/updates': 5924}
skipping logging after 94800 examples to avoid logging too frequently
skipping logging after 94816 examples to avoid logging too frequently
skipping logging after 94832 examples to avoid logging too frequently
train stats after 94848 examples: {'rewards_train/chosen': '0.27618', 'rewards_train/rejected': '-6.732', 'rewards_train/margins': '7.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22284', 'examples_per_second': '4.775', 'grad_norm': '4.1875', 'counters/examples': 94848, 'counters/updates': 5928}
skipping logging after 94864 examples to avoid logging too frequently
skipping logging after 94880 examples to avoid logging too frequently
skipping logging after 94896 examples to avoid logging too frequently
train stats after 94912 examples: {'rewards_train/chosen': '0.49975', 'rewards_train/rejected': '-5.6933', 'rewards_train/margins': '5.8906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21344', 'examples_per_second': '5.0676', 'grad_norm': '4.125', 'counters/examples': 94912, 'counters/updates': 5932}
skipping logging after 94928 examples to avoid logging too frequently
skipping logging after 94944 examples to avoid logging too frequently
skipping logging after 94960 examples to avoid logging too frequently
train stats after 94976 examples: {'rewards_train/chosen': '0.51077', 'rewards_train/rejected': '-4.1634', 'rewards_train/margins': '4.8867', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26849', 'examples_per_second': '6.1351', 'grad_norm': '5.25', 'counters/examples': 94976, 'counters/updates': 5936}
skipping logging after 94992 examples to avoid logging too frequently
skipping logging after 95008 examples to avoid logging too frequently
skipping logging after 95024 examples to avoid logging too frequently
train stats after 95040 examples: {'rewards_train/chosen': '0.60263', 'rewards_train/rejected': '-5.1411', 'rewards_train/margins': '5.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19537', 'examples_per_second': '5.5917', 'grad_norm': '4.7812', 'counters/examples': 95040, 'counters/updates': 5940}
skipping logging after 95056 examples to avoid logging too frequently
skipping logging after 95072 examples to avoid logging too frequently
skipping logging after 95088 examples to avoid logging too frequently
train stats after 95104 examples: {'rewards_train/chosen': '0.51921', 'rewards_train/rejected': '-6.5165', 'rewards_train/margins': '7.1719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22784', 'examples_per_second': '5.631', 'grad_norm': '4.9375', 'counters/examples': 95104, 'counters/updates': 5944}
skipping logging after 95120 examples to avoid logging too frequently
skipping logging after 95136 examples to avoid logging too frequently
skipping logging after 95152 examples to avoid logging too frequently
train stats after 95168 examples: {'rewards_train/chosen': '0.63669', 'rewards_train/rejected': '-5.9618', 'rewards_train/margins': '6.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23279', 'examples_per_second': '4.3996', 'grad_norm': '5.1875', 'counters/examples': 95168, 'counters/updates': 5948}
skipping logging after 95184 examples to avoid logging too frequently
skipping logging after 95200 examples to avoid logging too frequently
skipping logging after 95216 examples to avoid logging too frequently
train stats after 95232 examples: {'rewards_train/chosen': '0.62483', 'rewards_train/rejected': '-5.7268', 'rewards_train/margins': '6.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20178', 'examples_per_second': '5.3275', 'grad_norm': '4.0938', 'counters/examples': 95232, 'counters/updates': 5952}
skipping logging after 95248 examples to avoid logging too frequently
skipping logging after 95264 examples to avoid logging too frequently
skipping logging after 95280 examples to avoid logging too frequently
train stats after 95296 examples: {'rewards_train/chosen': '0.31897', 'rewards_train/rejected': '-6.2738', 'rewards_train/margins': '6.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25574', 'examples_per_second': '4.5888', 'grad_norm': '5.75', 'counters/examples': 95296, 'counters/updates': 5956}
skipping logging after 95312 examples to avoid logging too frequently
skipping logging after 95328 examples to avoid logging too frequently
skipping logging after 95344 examples to avoid logging too frequently
train stats after 95360 examples: {'rewards_train/chosen': '0.38541', 'rewards_train/rejected': '-6.3977', 'rewards_train/margins': '6.8672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2262', 'examples_per_second': '5.169', 'grad_norm': '5', 'counters/examples': 95360, 'counters/updates': 5960}
skipping logging after 95376 examples to avoid logging too frequently
skipping logging after 95392 examples to avoid logging too frequently
skipping logging after 95408 examples to avoid logging too frequently
train stats after 95424 examples: {'rewards_train/chosen': '0.52972', 'rewards_train/rejected': '-5.3609', 'rewards_train/margins': '5.7812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20831', 'examples_per_second': '4.8544', 'grad_norm': '4.9062', 'counters/examples': 95424, 'counters/updates': 5964}
skipping logging after 95440 examples to avoid logging too frequently
skipping logging after 95456 examples to avoid logging too frequently
skipping logging after 95472 examples to avoid logging too frequently
train stats after 95488 examples: {'rewards_train/chosen': '0.088411', 'rewards_train/rejected': '-4.8621', 'rewards_train/margins': '4.8789', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21777', 'examples_per_second': '5.6598', 'grad_norm': '5.9688', 'counters/examples': 95488, 'counters/updates': 5968}
skipping logging after 95504 examples to avoid logging too frequently
skipping logging after 95520 examples to avoid logging too frequently
skipping logging after 95536 examples to avoid logging too frequently
train stats after 95552 examples: {'rewards_train/chosen': '0.46548', 'rewards_train/rejected': '-4.6959', 'rewards_train/margins': '4.9297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21594', 'examples_per_second': '5.4404', 'grad_norm': '4.6875', 'counters/examples': 95552, 'counters/updates': 5972}
skipping logging after 95568 examples to avoid logging too frequently
skipping logging after 95584 examples to avoid logging too frequently
skipping logging after 95600 examples to avoid logging too frequently
train stats after 95616 examples: {'rewards_train/chosen': '0.33515', 'rewards_train/rejected': '-5.6222', 'rewards_train/margins': '5.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27802', 'examples_per_second': '6.238', 'grad_norm': '4.8438', 'counters/examples': 95616, 'counters/updates': 5976}
skipping logging after 95632 examples to avoid logging too frequently
skipping logging after 95648 examples to avoid logging too frequently
skipping logging after 95664 examples to avoid logging too frequently
train stats after 95680 examples: {'rewards_train/chosen': '0.38184', 'rewards_train/rejected': '-5.6555', 'rewards_train/margins': '6.0859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18506', 'examples_per_second': '4.74', 'grad_norm': '4.4375', 'counters/examples': 95680, 'counters/updates': 5980}
skipping logging after 95696 examples to avoid logging too frequently
skipping logging after 95712 examples to avoid logging too frequently
skipping logging after 95728 examples to avoid logging too frequently
train stats after 95744 examples: {'rewards_train/chosen': '0.56185', 'rewards_train/rejected': '-5.4224', 'rewards_train/margins': '6.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1983', 'examples_per_second': '4.8483', 'grad_norm': '5.2188', 'counters/examples': 95744, 'counters/updates': 5984}
skipping logging after 95760 examples to avoid logging too frequently
skipping logging after 95776 examples to avoid logging too frequently
skipping logging after 95792 examples to avoid logging too frequently
train stats after 95808 examples: {'rewards_train/chosen': '0.66691', 'rewards_train/rejected': '-4.922', 'rewards_train/margins': '5.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21509', 'examples_per_second': '5.656', 'grad_norm': '6.1562', 'counters/examples': 95808, 'counters/updates': 5988}
skipping logging after 95824 examples to avoid logging too frequently
skipping logging after 95840 examples to avoid logging too frequently
skipping logging after 95856 examples to avoid logging too frequently
train stats after 95872 examples: {'rewards_train/chosen': '0.43072', 'rewards_train/rejected': '-5.3434', 'rewards_train/margins': '5.6562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19916', 'examples_per_second': '4.7791', 'grad_norm': '5.5938', 'counters/examples': 95872, 'counters/updates': 5992}
skipping logging after 95888 examples to avoid logging too frequently
skipping logging after 95904 examples to avoid logging too frequently
skipping logging after 95920 examples to avoid logging too frequently
train stats after 95936 examples: {'rewards_train/chosen': '0.28253', 'rewards_train/rejected': '-4.6357', 'rewards_train/margins': '4.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23456', 'examples_per_second': '6.007', 'grad_norm': '4.5938', 'counters/examples': 95936, 'counters/updates': 5996}
skipping logging after 95952 examples to avoid logging too frequently
skipping logging after 95968 examples to avoid logging too frequently
skipping logging after 95984 examples to avoid logging too frequently
train stats after 96000 examples: {'rewards_train/chosen': '0.30043', 'rewards_train/rejected': '-6.8389', 'rewards_train/margins': '6.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24023', 'examples_per_second': '5.0176', 'grad_norm': '4.75', 'counters/examples': 96000, 'counters/updates': 6000}
Running evaluation after 96000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.25s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.17s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:40,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.65s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.47s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:33,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.51s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:33,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.40s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:30,  1.47s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.22s/it]Computing eval metrics:  50%|█████     | 16/32 [00:21<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.42s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.20s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.18s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.12s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]
eval after 96000: {'rewards_eval/chosen': '-5.5133', 'rewards_eval/rejected': '-5.9185', 'rewards_eval/margins': '0.29004', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46515'}
skipping logging after 96016 examples to avoid logging too frequently
skipping logging after 96032 examples to avoid logging too frequently
skipping logging after 96048 examples to avoid logging too frequently
train stats after 96064 examples: {'rewards_train/chosen': '0.23124', 'rewards_train/rejected': '-6.2962', 'rewards_train/margins': '6.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.224', 'examples_per_second': '4.8709', 'grad_norm': '4.9375', 'counters/examples': 96064, 'counters/updates': 6004}
skipping logging after 96080 examples to avoid logging too frequently
skipping logging after 96096 examples to avoid logging too frequently
skipping logging after 96112 examples to avoid logging too frequently
train stats after 96128 examples: {'rewards_train/chosen': '0.75696', 'rewards_train/rejected': '-5.6861', 'rewards_train/margins': '6.3594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18231', 'examples_per_second': '5.0503', 'grad_norm': '5.2188', 'counters/examples': 96128, 'counters/updates': 6008}
skipping logging after 96144 examples to avoid logging too frequently
skipping logging after 96160 examples to avoid logging too frequently
skipping logging after 96176 examples to avoid logging too frequently
train stats after 96192 examples: {'rewards_train/chosen': '0.31954', 'rewards_train/rejected': '-5.1808', 'rewards_train/margins': '5.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25665', 'examples_per_second': '5.6548', 'grad_norm': '6.5938', 'counters/examples': 96192, 'counters/updates': 6012}
skipping logging after 96208 examples to avoid logging too frequently
skipping logging after 96224 examples to avoid logging too frequently
skipping logging after 96240 examples to avoid logging too frequently
train stats after 96256 examples: {'rewards_train/chosen': '0.18727', 'rewards_train/rejected': '-4.3696', 'rewards_train/margins': '4.2969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25336', 'examples_per_second': '5.3139', 'grad_norm': '4.7812', 'counters/examples': 96256, 'counters/updates': 6016}
skipping logging after 96272 examples to avoid logging too frequently
skipping logging after 96288 examples to avoid logging too frequently
skipping logging after 96304 examples to avoid logging too frequently
train stats after 96320 examples: {'rewards_train/chosen': '0.30133', 'rewards_train/rejected': '-4.9758', 'rewards_train/margins': '5.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26031', 'examples_per_second': '5.7713', 'grad_norm': '5', 'counters/examples': 96320, 'counters/updates': 6020}
skipping logging after 96336 examples to avoid logging too frequently
skipping logging after 96352 examples to avoid logging too frequently
skipping logging after 96368 examples to avoid logging too frequently
train stats after 96384 examples: {'rewards_train/chosen': '0.22162', 'rewards_train/rejected': '-5.0562', 'rewards_train/margins': '4.9883', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28979', 'examples_per_second': '5.7652', 'grad_norm': '5.5', 'counters/examples': 96384, 'counters/updates': 6024}
skipping logging after 96400 examples to avoid logging too frequently
skipping logging after 96416 examples to avoid logging too frequently
skipping logging after 96432 examples to avoid logging too frequently
train stats after 96448 examples: {'rewards_train/chosen': '0.68462', 'rewards_train/rejected': '-5.2491', 'rewards_train/margins': '5.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19067', 'examples_per_second': '5.2984', 'grad_norm': '4.375', 'counters/examples': 96448, 'counters/updates': 6028}
skipping logging after 96464 examples to avoid logging too frequently
skipping logging after 96480 examples to avoid logging too frequently
skipping logging after 96496 examples to avoid logging too frequently
train stats after 96512 examples: {'rewards_train/chosen': '0.61985', 'rewards_train/rejected': '-6.0558', 'rewards_train/margins': '6.9297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17621', 'examples_per_second': '5.0443', 'grad_norm': '4.5', 'counters/examples': 96512, 'counters/updates': 6032}
skipping logging after 96528 examples to avoid logging too frequently
skipping logging after 96544 examples to avoid logging too frequently
skipping logging after 96560 examples to avoid logging too frequently
train stats after 96576 examples: {'rewards_train/chosen': '0.44223', 'rewards_train/rejected': '-6.2077', 'rewards_train/margins': '6.4531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24841', 'examples_per_second': '4.1613', 'grad_norm': '5.5938', 'counters/examples': 96576, 'counters/updates': 6036}
skipping logging after 96592 examples to avoid logging too frequently
skipping logging after 96608 examples to avoid logging too frequently
skipping logging after 96624 examples to avoid logging too frequently
train stats after 96640 examples: {'rewards_train/chosen': '0.57495', 'rewards_train/rejected': '-4.4626', 'rewards_train/margins': '5.0508', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21619', 'examples_per_second': '5.9853', 'grad_norm': '5.375', 'counters/examples': 96640, 'counters/updates': 6040}
skipping logging after 96656 examples to avoid logging too frequently
skipping logging after 96672 examples to avoid logging too frequently
skipping logging after 96688 examples to avoid logging too frequently
train stats after 96704 examples: {'rewards_train/chosen': '0.4288', 'rewards_train/rejected': '-5.6328', 'rewards_train/margins': '6.4141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23547', 'examples_per_second': '4.8309', 'grad_norm': '4.8438', 'counters/examples': 96704, 'counters/updates': 6044}
skipping logging after 96720 examples to avoid logging too frequently
skipping logging after 96736 examples to avoid logging too frequently
skipping logging after 96752 examples to avoid logging too frequently
train stats after 96768 examples: {'rewards_train/chosen': '0.41849', 'rewards_train/rejected': '-5.7914', 'rewards_train/margins': '6.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2334', 'examples_per_second': '5.0134', 'grad_norm': '4.6562', 'counters/examples': 96768, 'counters/updates': 6048}
skipping logging after 96784 examples to avoid logging too frequently
skipping logging after 96800 examples to avoid logging too frequently
skipping logging after 96816 examples to avoid logging too frequently
train stats after 96832 examples: {'rewards_train/chosen': '0.33971', 'rewards_train/rejected': '-5.4107', 'rewards_train/margins': '5.7578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21429', 'examples_per_second': '5.6022', 'grad_norm': '4.625', 'counters/examples': 96832, 'counters/updates': 6052}
skipping logging after 96848 examples to avoid logging too frequently
skipping logging after 96864 examples to avoid logging too frequently
skipping logging after 96880 examples to avoid logging too frequently
train stats after 96896 examples: {'rewards_train/chosen': '0.069949', 'rewards_train/rejected': '-5.3142', 'rewards_train/margins': '5.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26196', 'examples_per_second': '5.1207', 'grad_norm': '5.3125', 'counters/examples': 96896, 'counters/updates': 6056}
skipping logging after 96912 examples to avoid logging too frequently
skipping logging after 96928 examples to avoid logging too frequently
skipping logging after 96944 examples to avoid logging too frequently
train stats after 96960 examples: {'rewards_train/chosen': '0.35765', 'rewards_train/rejected': '-6.7043', 'rewards_train/margins': '7.5391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25537', 'examples_per_second': '5.1688', 'grad_norm': '4.9375', 'counters/examples': 96960, 'counters/updates': 6060}
skipping logging after 96976 examples to avoid logging too frequently
skipping logging after 96992 examples to avoid logging too frequently
skipping logging after 97008 examples to avoid logging too frequently
train stats after 97024 examples: {'rewards_train/chosen': '0.17671', 'rewards_train/rejected': '-6.6935', 'rewards_train/margins': '6.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26154', 'examples_per_second': '5.9035', 'grad_norm': '5.9688', 'counters/examples': 97024, 'counters/updates': 6064}
skipping logging after 97040 examples to avoid logging too frequently
skipping logging after 97056 examples to avoid logging too frequently
skipping logging after 97072 examples to avoid logging too frequently
train stats after 97088 examples: {'rewards_train/chosen': '0.32166', 'rewards_train/rejected': '-4.9935', 'rewards_train/margins': '5.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25171', 'examples_per_second': '4.946', 'grad_norm': '4.7188', 'counters/examples': 97088, 'counters/updates': 6068}
skipping logging after 97104 examples to avoid logging too frequently
skipping logging after 97120 examples to avoid logging too frequently
skipping logging after 97136 examples to avoid logging too frequently
train stats after 97152 examples: {'rewards_train/chosen': '0.45862', 'rewards_train/rejected': '-5.4612', 'rewards_train/margins': '5.8828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25494', 'examples_per_second': '4.5576', 'grad_norm': '5.4375', 'counters/examples': 97152, 'counters/updates': 6072}
skipping logging after 97168 examples to avoid logging too frequently
skipping logging after 97184 examples to avoid logging too frequently
skipping logging after 97200 examples to avoid logging too frequently
train stats after 97216 examples: {'rewards_train/chosen': '0.43063', 'rewards_train/rejected': '-5.4858', 'rewards_train/margins': '5.7734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23163', 'examples_per_second': '5.7305', 'grad_norm': '4.875', 'counters/examples': 97216, 'counters/updates': 6076}
skipping logging after 97232 examples to avoid logging too frequently
skipping logging after 97248 examples to avoid logging too frequently
skipping logging after 97264 examples to avoid logging too frequently
train stats after 97280 examples: {'rewards_train/chosen': '0.65886', 'rewards_train/rejected': '-5.799', 'rewards_train/margins': '6.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18549', 'examples_per_second': '5.4495', 'grad_norm': '4.3125', 'counters/examples': 97280, 'counters/updates': 6080}
skipping logging after 97296 examples to avoid logging too frequently
skipping logging after 97312 examples to avoid logging too frequently
skipping logging after 97328 examples to avoid logging too frequently
train stats after 97344 examples: {'rewards_train/chosen': '0.41232', 'rewards_train/rejected': '-5.599', 'rewards_train/margins': '5.7422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2218', 'examples_per_second': '4.4075', 'grad_norm': '4.8125', 'counters/examples': 97344, 'counters/updates': 6084}
skipping logging after 97360 examples to avoid logging too frequently
skipping logging after 97376 examples to avoid logging too frequently
skipping logging after 97392 examples to avoid logging too frequently
train stats after 97408 examples: {'rewards_train/chosen': '0.7125', 'rewards_train/rejected': '-5.5645', 'rewards_train/margins': '6.8672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21606', 'examples_per_second': '4.9526', 'grad_norm': '4.8438', 'counters/examples': 97408, 'counters/updates': 6088}
skipping logging after 97424 examples to avoid logging too frequently
skipping logging after 97440 examples to avoid logging too frequently
skipping logging after 97456 examples to avoid logging too frequently
train stats after 97472 examples: {'rewards_train/chosen': '0.51944', 'rewards_train/rejected': '-7.083', 'rewards_train/margins': '7.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22406', 'examples_per_second': '5.2837', 'grad_norm': '4.2812', 'counters/examples': 97472, 'counters/updates': 6092}
skipping logging after 97488 examples to avoid logging too frequently
skipping logging after 97504 examples to avoid logging too frequently
skipping logging after 97520 examples to avoid logging too frequently
train stats after 97536 examples: {'rewards_train/chosen': '0.5331', 'rewards_train/rejected': '-6.2889', 'rewards_train/margins': '6.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20782', 'examples_per_second': '4.5379', 'grad_norm': '5.7812', 'counters/examples': 97536, 'counters/updates': 6096}
skipping logging after 97552 examples to avoid logging too frequently
skipping logging after 97568 examples to avoid logging too frequently
skipping logging after 97584 examples to avoid logging too frequently
train stats after 97600 examples: {'rewards_train/chosen': '-0.098958', 'rewards_train/rejected': '-6.8431', 'rewards_train/margins': '6.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27496', 'examples_per_second': '5.9575', 'grad_norm': '5.5938', 'counters/examples': 97600, 'counters/updates': 6100}
skipping logging after 97616 examples to avoid logging too frequently
skipping logging after 97632 examples to avoid logging too frequently
skipping logging after 97648 examples to avoid logging too frequently
train stats after 97664 examples: {'rewards_train/chosen': '0.52098', 'rewards_train/rejected': '-5.7422', 'rewards_train/margins': '6.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23059', 'examples_per_second': '5.2244', 'grad_norm': '4.625', 'counters/examples': 97664, 'counters/updates': 6104}
skipping logging after 97680 examples to avoid logging too frequently
skipping logging after 97696 examples to avoid logging too frequently
skipping logging after 97712 examples to avoid logging too frequently
train stats after 97728 examples: {'rewards_train/chosen': '0.52147', 'rewards_train/rejected': '-4.0669', 'rewards_train/margins': '4.6289', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2395', 'examples_per_second': '4.7708', 'grad_norm': '4.9688', 'counters/examples': 97728, 'counters/updates': 6108}
skipping logging after 97744 examples to avoid logging too frequently
skipping logging after 97760 examples to avoid logging too frequently
skipping logging after 97776 examples to avoid logging too frequently
train stats after 97792 examples: {'rewards_train/chosen': '0.32203', 'rewards_train/rejected': '-6.396', 'rewards_train/margins': '6.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22711', 'examples_per_second': '5.1843', 'grad_norm': '4.5938', 'counters/examples': 97792, 'counters/updates': 6112}
skipping logging after 97808 examples to avoid logging too frequently
skipping logging after 97824 examples to avoid logging too frequently
skipping logging after 97840 examples to avoid logging too frequently
train stats after 97856 examples: {'rewards_train/chosen': '0.48556', 'rewards_train/rejected': '-6.727', 'rewards_train/margins': '7.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22144', 'examples_per_second': '5.2257', 'grad_norm': '5.2188', 'counters/examples': 97856, 'counters/updates': 6116}
skipping logging after 97872 examples to avoid logging too frequently
skipping logging after 97888 examples to avoid logging too frequently
skipping logging after 97904 examples to avoid logging too frequently
train stats after 97920 examples: {'rewards_train/chosen': '0.83836', 'rewards_train/rejected': '-6.1678', 'rewards_train/margins': '6.7578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23169', 'examples_per_second': '4.4977', 'grad_norm': '4.7812', 'counters/examples': 97920, 'counters/updates': 6120}
skipping logging after 97936 examples to avoid logging too frequently
skipping logging after 97952 examples to avoid logging too frequently
skipping logging after 97968 examples to avoid logging too frequently
train stats after 97984 examples: {'rewards_train/chosen': '0.30904', 'rewards_train/rejected': '-5.8061', 'rewards_train/margins': '6.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22156', 'examples_per_second': '4.8122', 'grad_norm': '4.5', 'counters/examples': 97984, 'counters/updates': 6124}
skipping logging after 98000 examples to avoid logging too frequently
skipping logging after 98016 examples to avoid logging too frequently
skipping logging after 98032 examples to avoid logging too frequently
train stats after 98048 examples: {'rewards_train/chosen': '0.37036', 'rewards_train/rejected': '-6.2816', 'rewards_train/margins': '6.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27271', 'examples_per_second': '4.5408', 'grad_norm': '5.5938', 'counters/examples': 98048, 'counters/updates': 6128}
skipping logging after 98064 examples to avoid logging too frequently
skipping logging after 98080 examples to avoid logging too frequently
skipping logging after 98096 examples to avoid logging too frequently
train stats after 98112 examples: {'rewards_train/chosen': '0.14663', 'rewards_train/rejected': '-5.9137', 'rewards_train/margins': '6.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20911', 'examples_per_second': '4.9218', 'grad_norm': '4.4375', 'counters/examples': 98112, 'counters/updates': 6132}
skipping logging after 98128 examples to avoid logging too frequently
skipping logging after 98144 examples to avoid logging too frequently
skipping logging after 98160 examples to avoid logging too frequently
train stats after 98176 examples: {'rewards_train/chosen': '0.44034', 'rewards_train/rejected': '-5.8475', 'rewards_train/margins': '6.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24579', 'examples_per_second': '5.5573', 'grad_norm': '5.3438', 'counters/examples': 98176, 'counters/updates': 6136}
skipping logging after 98192 examples to avoid logging too frequently
skipping logging after 98208 examples to avoid logging too frequently
skipping logging after 98224 examples to avoid logging too frequently
train stats after 98240 examples: {'rewards_train/chosen': '0.46581', 'rewards_train/rejected': '-4.2171', 'rewards_train/margins': '4.6289', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26544', 'examples_per_second': '6.2062', 'grad_norm': '5.4688', 'counters/examples': 98240, 'counters/updates': 6140}
skipping logging after 98256 examples to avoid logging too frequently
skipping logging after 98272 examples to avoid logging too frequently
skipping logging after 98288 examples to avoid logging too frequently
train stats after 98304 examples: {'rewards_train/chosen': '0.41384', 'rewards_train/rejected': '-5.8727', 'rewards_train/margins': '6.2422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22595', 'examples_per_second': '4.7866', 'grad_norm': '4.9375', 'counters/examples': 98304, 'counters/updates': 6144}
skipping logging after 98320 examples to avoid logging too frequently
skipping logging after 98336 examples to avoid logging too frequently
skipping logging after 98352 examples to avoid logging too frequently
train stats after 98368 examples: {'rewards_train/chosen': '0.4798', 'rewards_train/rejected': '-3.6293', 'rewards_train/margins': '3.8867', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28009', 'examples_per_second': '5.4668', 'grad_norm': '5.4688', 'counters/examples': 98368, 'counters/updates': 6148}
skipping logging after 98384 examples to avoid logging too frequently
skipping logging after 98400 examples to avoid logging too frequently
skipping logging after 98416 examples to avoid logging too frequently
train stats after 98432 examples: {'rewards_train/chosen': '0.45372', 'rewards_train/rejected': '-6.5795', 'rewards_train/margins': '6.707', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26318', 'examples_per_second': '4.5285', 'grad_norm': '5.4375', 'counters/examples': 98432, 'counters/updates': 6152}
skipping logging after 98448 examples to avoid logging too frequently
skipping logging after 98464 examples to avoid logging too frequently
skipping logging after 98480 examples to avoid logging too frequently
train stats after 98496 examples: {'rewards_train/chosen': '0.22207', 'rewards_train/rejected': '-4.9076', 'rewards_train/margins': '4.8086', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24084', 'examples_per_second': '5.9195', 'grad_norm': '4.9688', 'counters/examples': 98496, 'counters/updates': 6156}
skipping logging after 98512 examples to avoid logging too frequently
skipping logging after 98528 examples to avoid logging too frequently
skipping logging after 98544 examples to avoid logging too frequently
train stats after 98560 examples: {'rewards_train/chosen': '0.46396', 'rewards_train/rejected': '-5.4422', 'rewards_train/margins': '5.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23877', 'examples_per_second': '5.3792', 'grad_norm': '4.9375', 'counters/examples': 98560, 'counters/updates': 6160}
skipping logging after 98576 examples to avoid logging too frequently
skipping logging after 98592 examples to avoid logging too frequently
skipping logging after 98608 examples to avoid logging too frequently
train stats after 98624 examples: {'rewards_train/chosen': '0.4129', 'rewards_train/rejected': '-6.5316', 'rewards_train/margins': '7.0547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23645', 'examples_per_second': '6.1717', 'grad_norm': '4.7812', 'counters/examples': 98624, 'counters/updates': 6164}
skipping logging after 98640 examples to avoid logging too frequently
skipping logging after 98656 examples to avoid logging too frequently
skipping logging after 98672 examples to avoid logging too frequently
train stats after 98688 examples: {'rewards_train/chosen': '0.42529', 'rewards_train/rejected': '-5.6129', 'rewards_train/margins': '5.9023', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2489', 'examples_per_second': '5.1888', 'grad_norm': '5.3125', 'counters/examples': 98688, 'counters/updates': 6168}
skipping logging after 98704 examples to avoid logging too frequently
skipping logging after 98720 examples to avoid logging too frequently
skipping logging after 98736 examples to avoid logging too frequently
train stats after 98752 examples: {'rewards_train/chosen': '0.53967', 'rewards_train/rejected': '-5.6497', 'rewards_train/margins': '6.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19543', 'examples_per_second': '5.0453', 'grad_norm': '4.9688', 'counters/examples': 98752, 'counters/updates': 6172}
skipping logging after 98768 examples to avoid logging too frequently
skipping logging after 98784 examples to avoid logging too frequently
skipping logging after 98800 examples to avoid logging too frequently
train stats after 98816 examples: {'rewards_train/chosen': '0.50098', 'rewards_train/rejected': '-5.493', 'rewards_train/margins': '5.9023', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25', 'examples_per_second': '4.6339', 'grad_norm': '5.5625', 'counters/examples': 98816, 'counters/updates': 6176}
skipping logging after 98832 examples to avoid logging too frequently
skipping logging after 98848 examples to avoid logging too frequently
skipping logging after 98864 examples to avoid logging too frequently
train stats after 98880 examples: {'rewards_train/chosen': '0.1377', 'rewards_train/rejected': '-5.1405', 'rewards_train/margins': '5.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22198', 'examples_per_second': '5.8994', 'grad_norm': '4.7812', 'counters/examples': 98880, 'counters/updates': 6180}
skipping logging after 98896 examples to avoid logging too frequently
skipping logging after 98912 examples to avoid logging too frequently
skipping logging after 98928 examples to avoid logging too frequently
train stats after 98944 examples: {'rewards_train/chosen': '0.39539', 'rewards_train/rejected': '-5.6476', 'rewards_train/margins': '5.8984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28668', 'examples_per_second': '3.9576', 'grad_norm': '5.7188', 'counters/examples': 98944, 'counters/updates': 6184}
skipping logging after 98960 examples to avoid logging too frequently
skipping logging after 98976 examples to avoid logging too frequently
skipping logging after 98992 examples to avoid logging too frequently
train stats after 99008 examples: {'rewards_train/chosen': '0.64662', 'rewards_train/rejected': '-4.5676', 'rewards_train/margins': '5.375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25433', 'examples_per_second': '4.703', 'grad_norm': '4.5', 'counters/examples': 99008, 'counters/updates': 6188}
skipping logging after 99024 examples to avoid logging too frequently
skipping logging after 99040 examples to avoid logging too frequently
skipping logging after 99056 examples to avoid logging too frequently
train stats after 99072 examples: {'rewards_train/chosen': '0.33705', 'rewards_train/rejected': '-6.6946', 'rewards_train/margins': '7.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22302', 'examples_per_second': '4.909', 'grad_norm': '4.25', 'counters/examples': 99072, 'counters/updates': 6192}
skipping logging after 99088 examples to avoid logging too frequently
skipping logging after 99104 examples to avoid logging too frequently
skipping logging after 99120 examples to avoid logging too frequently
train stats after 99136 examples: {'rewards_train/chosen': '0.44781', 'rewards_train/rejected': '-5.2232', 'rewards_train/margins': '5.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19873', 'examples_per_second': '6.4471', 'grad_norm': '4.875', 'counters/examples': 99136, 'counters/updates': 6196}
skipping logging after 99152 examples to avoid logging too frequently
skipping logging after 99168 examples to avoid logging too frequently
skipping logging after 99184 examples to avoid logging too frequently
train stats after 99200 examples: {'rewards_train/chosen': '0.33003', 'rewards_train/rejected': '-6.2733', 'rewards_train/margins': '6.5938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24719', 'examples_per_second': '5.7425', 'grad_norm': '4.8125', 'counters/examples': 99200, 'counters/updates': 6200}
skipping logging after 99216 examples to avoid logging too frequently
skipping logging after 99232 examples to avoid logging too frequently
skipping logging after 99248 examples to avoid logging too frequently
train stats after 99264 examples: {'rewards_train/chosen': '0.3727', 'rewards_train/rejected': '-5.1026', 'rewards_train/margins': '5.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23987', 'examples_per_second': '6.5351', 'grad_norm': '5', 'counters/examples': 99264, 'counters/updates': 6204}
skipping logging after 99280 examples to avoid logging too frequently
skipping logging after 99296 examples to avoid logging too frequently
skipping logging after 99312 examples to avoid logging too frequently
train stats after 99328 examples: {'rewards_train/chosen': '0.55032', 'rewards_train/rejected': '-6.3323', 'rewards_train/margins': '7.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22418', 'examples_per_second': '4.6953', 'grad_norm': '4.5', 'counters/examples': 99328, 'counters/updates': 6208}
skipping logging after 99344 examples to avoid logging too frequently
skipping logging after 99360 examples to avoid logging too frequently
skipping logging after 99376 examples to avoid logging too frequently
train stats after 99392 examples: {'rewards_train/chosen': '0.20917', 'rewards_train/rejected': '-4.9883', 'rewards_train/margins': '5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24744', 'examples_per_second': '4.5956', 'grad_norm': '5.5312', 'counters/examples': 99392, 'counters/updates': 6212}
skipping logging after 99408 examples to avoid logging too frequently
skipping logging after 99424 examples to avoid logging too frequently
skipping logging after 99440 examples to avoid logging too frequently
train stats after 99456 examples: {'rewards_train/chosen': '-0.11783', 'rewards_train/rejected': '-5.7845', 'rewards_train/margins': '5.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26404', 'examples_per_second': '5.3445', 'grad_norm': '5.5312', 'counters/examples': 99456, 'counters/updates': 6216}
skipping logging after 99472 examples to avoid logging too frequently
skipping logging after 99488 examples to avoid logging too frequently
skipping logging after 99504 examples to avoid logging too frequently
train stats after 99520 examples: {'rewards_train/chosen': '0.38925', 'rewards_train/rejected': '-6.3335', 'rewards_train/margins': '6.6875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22284', 'examples_per_second': '6.0026', 'grad_norm': '4.0938', 'counters/examples': 99520, 'counters/updates': 6220}
skipping logging after 99536 examples to avoid logging too frequently
skipping logging after 99552 examples to avoid logging too frequently
skipping logging after 99568 examples to avoid logging too frequently
train stats after 99584 examples: {'rewards_train/chosen': '0.48236', 'rewards_train/rejected': '-6.814', 'rewards_train/margins': '7.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23297', 'examples_per_second': '5.9219', 'grad_norm': '4.5938', 'counters/examples': 99584, 'counters/updates': 6224}
skipping logging after 99600 examples to avoid logging too frequently
skipping logging after 99616 examples to avoid logging too frequently
skipping logging after 99632 examples to avoid logging too frequently
train stats after 99648 examples: {'rewards_train/chosen': '0.14089', 'rewards_train/rejected': '-6.0904', 'rewards_train/margins': '6.7852', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24268', 'examples_per_second': '5.1227', 'grad_norm': '5.5312', 'counters/examples': 99648, 'counters/updates': 6228}
skipping logging after 99664 examples to avoid logging too frequently
skipping logging after 99680 examples to avoid logging too frequently
skipping logging after 99696 examples to avoid logging too frequently
train stats after 99712 examples: {'rewards_train/chosen': '0.38497', 'rewards_train/rejected': '-5.8421', 'rewards_train/margins': '5.8633', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21869', 'examples_per_second': '4.5899', 'grad_norm': '4.6875', 'counters/examples': 99712, 'counters/updates': 6232}
skipping logging after 99728 examples to avoid logging too frequently
skipping logging after 99744 examples to avoid logging too frequently
skipping logging after 99760 examples to avoid logging too frequently
train stats after 99776 examples: {'rewards_train/chosen': '0.39312', 'rewards_train/rejected': '-5.0348', 'rewards_train/margins': '5.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21521', 'examples_per_second': '4.9584', 'grad_norm': '4.625', 'counters/examples': 99776, 'counters/updates': 6236}
skipping logging after 99792 examples to avoid logging too frequently
skipping logging after 99808 examples to avoid logging too frequently
skipping logging after 99824 examples to avoid logging too frequently
train stats after 99840 examples: {'rewards_train/chosen': '0.22448', 'rewards_train/rejected': '-4.9728', 'rewards_train/margins': '5.3672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26709', 'examples_per_second': '4.8625', 'grad_norm': '4.9062', 'counters/examples': 99840, 'counters/updates': 6240}
skipping logging after 99856 examples to avoid logging too frequently
skipping logging after 99872 examples to avoid logging too frequently
skipping logging after 99888 examples to avoid logging too frequently
train stats after 99904 examples: {'rewards_train/chosen': '0.34073', 'rewards_train/rejected': '-5.2667', 'rewards_train/margins': '5.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21533', 'examples_per_second': '5.7754', 'grad_norm': '5.25', 'counters/examples': 99904, 'counters/updates': 6244}
skipping logging after 99920 examples to avoid logging too frequently
skipping logging after 99936 examples to avoid logging too frequently
skipping logging after 99952 examples to avoid logging too frequently
train stats after 99968 examples: {'rewards_train/chosen': '0.17871', 'rewards_train/rejected': '-6.2324', 'rewards_train/margins': '6.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27582', 'examples_per_second': '4.5593', 'grad_norm': '4.4688', 'counters/examples': 99968, 'counters/updates': 6248}
skipping logging after 99984 examples to avoid logging too frequently
skipping logging after 100000 examples to avoid logging too frequently
Running evaluation after 100000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:53,  1.71s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:43,  1.45s/it]Computing eval metrics:   9%|▉         | 3/32 [00:04<00:36,  1.27s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.49s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.69s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:09<00:38,  1.50s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:10<00:34,  1.38s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:12<00:36,  1.53s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.49s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:31,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.41s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:20<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:21<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.28s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:28<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:40<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:41<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]
eval after 100000: {'rewards_eval/chosen': '-5.5282', 'rewards_eval/rejected': '-5.8752', 'rewards_eval/margins': '0.20801', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46444'}
skipping logging after 100016 examples to avoid logging too frequently
train stats after 100032 examples: {'rewards_train/chosen': '0.65544', 'rewards_train/rejected': '-5.7211', 'rewards_train/margins': '6.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18433', 'examples_per_second': '4.8699', 'grad_norm': '4.75', 'counters/examples': 100032, 'counters/updates': 6252}
skipping logging after 100048 examples to avoid logging too frequently
skipping logging after 100064 examples to avoid logging too frequently
skipping logging after 100080 examples to avoid logging too frequently
train stats after 100096 examples: {'rewards_train/chosen': '0.56493', 'rewards_train/rejected': '-7.2705', 'rewards_train/margins': '7.6016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22394', 'examples_per_second': '5.0433', 'grad_norm': '4.875', 'counters/examples': 100096, 'counters/updates': 6256}
skipping logging after 100112 examples to avoid logging too frequently
skipping logging after 100128 examples to avoid logging too frequently
skipping logging after 100144 examples to avoid logging too frequently
train stats after 100160 examples: {'rewards_train/chosen': '0.6272', 'rewards_train/rejected': '-5.012', 'rewards_train/margins': '5.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21515', 'examples_per_second': '4.5953', 'grad_norm': '5.2188', 'counters/examples': 100160, 'counters/updates': 6260}
skipping logging after 100176 examples to avoid logging too frequently
skipping logging after 100192 examples to avoid logging too frequently
skipping logging after 100208 examples to avoid logging too frequently
train stats after 100224 examples: {'rewards_train/chosen': '0.48143', 'rewards_train/rejected': '-5.9236', 'rewards_train/margins': '6.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22052', 'examples_per_second': '4.3542', 'grad_norm': '4.6562', 'counters/examples': 100224, 'counters/updates': 6264}
skipping logging after 100240 examples to avoid logging too frequently
skipping logging after 100256 examples to avoid logging too frequently
skipping logging after 100272 examples to avoid logging too frequently
train stats after 100288 examples: {'rewards_train/chosen': '0.5181', 'rewards_train/rejected': '-9.4674', 'rewards_train/margins': '10.078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24323', 'examples_per_second': '5.1526', 'grad_norm': '4.7188', 'counters/examples': 100288, 'counters/updates': 6268}
skipping logging after 100304 examples to avoid logging too frequently
skipping logging after 100320 examples to avoid logging too frequently
skipping logging after 100336 examples to avoid logging too frequently
train stats after 100352 examples: {'rewards_train/chosen': '0.49331', 'rewards_train/rejected': '-5.8076', 'rewards_train/margins': '6.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23547', 'examples_per_second': '4.277', 'grad_norm': '5.1875', 'counters/examples': 100352, 'counters/updates': 6272}
skipping logging after 100368 examples to avoid logging too frequently
skipping logging after 100384 examples to avoid logging too frequently
skipping logging after 100400 examples to avoid logging too frequently
train stats after 100416 examples: {'rewards_train/chosen': '0.29214', 'rewards_train/rejected': '-5.798', 'rewards_train/margins': '6.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26996', 'examples_per_second': '5.9765', 'grad_norm': '5.5', 'counters/examples': 100416, 'counters/updates': 6276}
skipping logging after 100432 examples to avoid logging too frequently
skipping logging after 100448 examples to avoid logging too frequently
skipping logging after 100464 examples to avoid logging too frequently
train stats after 100480 examples: {'rewards_train/chosen': '0.48365', 'rewards_train/rejected': '-5.4099', 'rewards_train/margins': '6.2344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26001', 'examples_per_second': '3.891', 'grad_norm': '5.5938', 'counters/examples': 100480, 'counters/updates': 6280}
skipping logging after 100496 examples to avoid logging too frequently
skipping logging after 100512 examples to avoid logging too frequently
skipping logging after 100528 examples to avoid logging too frequently
train stats after 100544 examples: {'rewards_train/chosen': '0.4217', 'rewards_train/rejected': '-5.5413', 'rewards_train/margins': '5.8086', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27655', 'examples_per_second': '5.6273', 'grad_norm': '5.5625', 'counters/examples': 100544, 'counters/updates': 6284}
skipping logging after 100560 examples to avoid logging too frequently
skipping logging after 100576 examples to avoid logging too frequently
skipping logging after 100592 examples to avoid logging too frequently
train stats after 100608 examples: {'rewards_train/chosen': '0.65735', 'rewards_train/rejected': '-4.8546', 'rewards_train/margins': '5.4531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21875', 'examples_per_second': '5.3201', 'grad_norm': '5.2188', 'counters/examples': 100608, 'counters/updates': 6288}
skipping logging after 100624 examples to avoid logging too frequently
skipping logging after 100640 examples to avoid logging too frequently
skipping logging after 100656 examples to avoid logging too frequently
train stats after 100672 examples: {'rewards_train/chosen': '0.35929', 'rewards_train/rejected': '-5.1698', 'rewards_train/margins': '5.6836', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21503', 'examples_per_second': '4.682', 'grad_norm': '5.4375', 'counters/examples': 100672, 'counters/updates': 6292}
skipping logging after 100688 examples to avoid logging too frequently
skipping logging after 100704 examples to avoid logging too frequently
skipping logging after 100720 examples to avoid logging too frequently
train stats after 100736 examples: {'rewards_train/chosen': '0.28831', 'rewards_train/rejected': '-5.0835', 'rewards_train/margins': '5.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25232', 'examples_per_second': '6.147', 'grad_norm': '4.6562', 'counters/examples': 100736, 'counters/updates': 6296}
skipping logging after 100752 examples to avoid logging too frequently
skipping logging after 100768 examples to avoid logging too frequently
skipping logging after 100784 examples to avoid logging too frequently
train stats after 100800 examples: {'rewards_train/chosen': '0.58873', 'rewards_train/rejected': '-5.9156', 'rewards_train/margins': '6.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20459', 'examples_per_second': '5.7318', 'grad_norm': '4.2812', 'counters/examples': 100800, 'counters/updates': 6300}
skipping logging after 100816 examples to avoid logging too frequently
skipping logging after 100832 examples to avoid logging too frequently
skipping logging after 100848 examples to avoid logging too frequently
train stats after 100864 examples: {'rewards_train/chosen': '0.38579', 'rewards_train/rejected': '-6.8187', 'rewards_train/margins': '7.1953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21753', 'examples_per_second': '4.8568', 'grad_norm': '4.4062', 'counters/examples': 100864, 'counters/updates': 6304}
skipping logging after 100880 examples to avoid logging too frequently
skipping logging after 100896 examples to avoid logging too frequently
skipping logging after 100912 examples to avoid logging too frequently
train stats after 100928 examples: {'rewards_train/chosen': '0.27638', 'rewards_train/rejected': '-5.9546', 'rewards_train/margins': '6.1719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22711', 'examples_per_second': '4.0248', 'grad_norm': '5.625', 'counters/examples': 100928, 'counters/updates': 6308}
skipping logging after 100944 examples to avoid logging too frequently
skipping logging after 100960 examples to avoid logging too frequently
skipping logging after 100976 examples to avoid logging too frequently
train stats after 100992 examples: {'rewards_train/chosen': '0.14941', 'rewards_train/rejected': '-4.8141', 'rewards_train/margins': '5.1172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29358', 'examples_per_second': '4.0045', 'grad_norm': '6', 'counters/examples': 100992, 'counters/updates': 6312}
skipping logging after 101008 examples to avoid logging too frequently
skipping logging after 101024 examples to avoid logging too frequently
skipping logging after 101040 examples to avoid logging too frequently
train stats after 101056 examples: {'rewards_train/chosen': '0.54508', 'rewards_train/rejected': '-5.2805', 'rewards_train/margins': '6.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24982', 'examples_per_second': '4.3975', 'grad_norm': '7.7188', 'counters/examples': 101056, 'counters/updates': 6316}
skipping logging after 101072 examples to avoid logging too frequently
skipping logging after 101088 examples to avoid logging too frequently
skipping logging after 101104 examples to avoid logging too frequently
train stats after 101120 examples: {'rewards_train/chosen': '0.22422', 'rewards_train/rejected': '-5.3225', 'rewards_train/margins': '5.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29724', 'examples_per_second': '4.6426', 'grad_norm': '4.2188', 'counters/examples': 101120, 'counters/updates': 6320}
skipping logging after 101136 examples to avoid logging too frequently
skipping logging after 101152 examples to avoid logging too frequently
skipping logging after 101168 examples to avoid logging too frequently
train stats after 101184 examples: {'rewards_train/chosen': '0.54554', 'rewards_train/rejected': '-4.4247', 'rewards_train/margins': '5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21112', 'examples_per_second': '4.7553', 'grad_norm': '4.4688', 'counters/examples': 101184, 'counters/updates': 6324}
skipping logging after 101200 examples to avoid logging too frequently
skipping logging after 101216 examples to avoid logging too frequently
skipping logging after 101232 examples to avoid logging too frequently
train stats after 101248 examples: {'rewards_train/chosen': '0.38073', 'rewards_train/rejected': '-5.7524', 'rewards_train/margins': '6.2422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23901', 'examples_per_second': '5.8776', 'grad_norm': '4.9688', 'counters/examples': 101248, 'counters/updates': 6328}
skipping logging after 101264 examples to avoid logging too frequently
skipping logging after 101280 examples to avoid logging too frequently
skipping logging after 101296 examples to avoid logging too frequently
train stats after 101312 examples: {'rewards_train/chosen': '0.54061', 'rewards_train/rejected': '-6.2637', 'rewards_train/margins': '6.7734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22418', 'examples_per_second': '5.2676', 'grad_norm': '4.875', 'counters/examples': 101312, 'counters/updates': 6332}
skipping logging after 101328 examples to avoid logging too frequently
skipping logging after 101344 examples to avoid logging too frequently
skipping logging after 101360 examples to avoid logging too frequently
train stats after 101376 examples: {'rewards_train/chosen': '0.40198', 'rewards_train/rejected': '-6.215', 'rewards_train/margins': '6.6562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26398', 'examples_per_second': '4.4626', 'grad_norm': '5.6562', 'counters/examples': 101376, 'counters/updates': 6336}
skipping logging after 101392 examples to avoid logging too frequently
skipping logging after 101408 examples to avoid logging too frequently
skipping logging after 101424 examples to avoid logging too frequently
train stats after 101440 examples: {'rewards_train/chosen': '0.42459', 'rewards_train/rejected': '-5.6606', 'rewards_train/margins': '6.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19946', 'examples_per_second': '6.9505', 'grad_norm': '4.625', 'counters/examples': 101440, 'counters/updates': 6340}
skipping logging after 101456 examples to avoid logging too frequently
skipping logging after 101472 examples to avoid logging too frequently
skipping logging after 101488 examples to avoid logging too frequently
train stats after 101504 examples: {'rewards_train/chosen': '0.52573', 'rewards_train/rejected': '-5.1349', 'rewards_train/margins': '5.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23834', 'examples_per_second': '5.0961', 'grad_norm': '5.5', 'counters/examples': 101504, 'counters/updates': 6344}
skipping logging after 101520 examples to avoid logging too frequently
skipping logging after 101536 examples to avoid logging too frequently
skipping logging after 101552 examples to avoid logging too frequently
train stats after 101568 examples: {'rewards_train/chosen': '0.27108', 'rewards_train/rejected': '-5.2308', 'rewards_train/margins': '5.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24939', 'examples_per_second': '4.636', 'grad_norm': '4.7812', 'counters/examples': 101568, 'counters/updates': 6348}
skipping logging after 101584 examples to avoid logging too frequently
skipping logging after 101600 examples to avoid logging too frequently
skipping logging after 101616 examples to avoid logging too frequently
train stats after 101632 examples: {'rewards_train/chosen': '0.58093', 'rewards_train/rejected': '-5.2456', 'rewards_train/margins': '5.6602', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23041', 'examples_per_second': '6.1001', 'grad_norm': '4.3125', 'counters/examples': 101632, 'counters/updates': 6352}
skipping logging after 101648 examples to avoid logging too frequently
skipping logging after 101664 examples to avoid logging too frequently
skipping logging after 101680 examples to avoid logging too frequently
train stats after 101696 examples: {'rewards_train/chosen': '0.29042', 'rewards_train/rejected': '-5.5581', 'rewards_train/margins': '5.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24237', 'examples_per_second': '5.0514', 'grad_norm': '5.3125', 'counters/examples': 101696, 'counters/updates': 6356}
skipping logging after 101712 examples to avoid logging too frequently
skipping logging after 101728 examples to avoid logging too frequently
skipping logging after 101744 examples to avoid logging too frequently
train stats after 101760 examples: {'rewards_train/chosen': '0.46717', 'rewards_train/rejected': '-4.4187', 'rewards_train/margins': '4.957', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24725', 'examples_per_second': '5.3531', 'grad_norm': '5.1875', 'counters/examples': 101760, 'counters/updates': 6360}
skipping logging after 101776 examples to avoid logging too frequently
skipping logging after 101792 examples to avoid logging too frequently
skipping logging after 101808 examples to avoid logging too frequently
train stats after 101824 examples: {'rewards_train/chosen': '0.50024', 'rewards_train/rejected': '-6.3203', 'rewards_train/margins': '6.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20697', 'examples_per_second': '5.4807', 'grad_norm': '4.1562', 'counters/examples': 101824, 'counters/updates': 6364}
skipping logging after 101840 examples to avoid logging too frequently
skipping logging after 101856 examples to avoid logging too frequently
skipping logging after 101872 examples to avoid logging too frequently
train stats after 101888 examples: {'rewards_train/chosen': '0.50351', 'rewards_train/rejected': '-5.4344', 'rewards_train/margins': '6.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20447', 'examples_per_second': '4.4777', 'grad_norm': '4.3125', 'counters/examples': 101888, 'counters/updates': 6368}
skipping logging after 101904 examples to avoid logging too frequently
skipping logging after 101920 examples to avoid logging too frequently
skipping logging after 101936 examples to avoid logging too frequently
train stats after 101952 examples: {'rewards_train/chosen': '0.18822', 'rewards_train/rejected': '-5.5788', 'rewards_train/margins': '5.3477', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22809', 'examples_per_second': '6.4206', 'grad_norm': '4.0312', 'counters/examples': 101952, 'counters/updates': 6372}
skipping logging after 101968 examples to avoid logging too frequently
skipping logging after 101984 examples to avoid logging too frequently
skipping logging after 102000 examples to avoid logging too frequently
train stats after 102016 examples: {'rewards_train/chosen': '0.26393', 'rewards_train/rejected': '-4.8853', 'rewards_train/margins': '5.082', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27899', 'examples_per_second': '6.2058', 'grad_norm': '5.9688', 'counters/examples': 102016, 'counters/updates': 6376}
skipping logging after 102032 examples to avoid logging too frequently
skipping logging after 102048 examples to avoid logging too frequently
skipping logging after 102064 examples to avoid logging too frequently
train stats after 102080 examples: {'rewards_train/chosen': '0.33334', 'rewards_train/rejected': '-5.6674', 'rewards_train/margins': '6.2109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20642', 'examples_per_second': '4.6711', 'grad_norm': '3.9375', 'counters/examples': 102080, 'counters/updates': 6380}
skipping logging after 102096 examples to avoid logging too frequently
skipping logging after 102112 examples to avoid logging too frequently
skipping logging after 102128 examples to avoid logging too frequently
train stats after 102144 examples: {'rewards_train/chosen': '0.40425', 'rewards_train/rejected': '-5.5233', 'rewards_train/margins': '6.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24792', 'examples_per_second': '5.1179', 'grad_norm': '6.2188', 'counters/examples': 102144, 'counters/updates': 6384}
skipping logging after 102160 examples to avoid logging too frequently
skipping logging after 102176 examples to avoid logging too frequently
skipping logging after 102192 examples to avoid logging too frequently
train stats after 102208 examples: {'rewards_train/chosen': '0.21211', 'rewards_train/rejected': '-4.6001', 'rewards_train/margins': '4.832', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2829', 'examples_per_second': '6.4951', 'grad_norm': '6.0938', 'counters/examples': 102208, 'counters/updates': 6388}
skipping logging after 102224 examples to avoid logging too frequently
skipping logging after 102240 examples to avoid logging too frequently
skipping logging after 102256 examples to avoid logging too frequently
train stats after 102272 examples: {'rewards_train/chosen': '0.38189', 'rewards_train/rejected': '-5.4401', 'rewards_train/margins': '5.8984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22815', 'examples_per_second': '4.5165', 'grad_norm': '5.3438', 'counters/examples': 102272, 'counters/updates': 6392}
skipping logging after 102288 examples to avoid logging too frequently
skipping logging after 102304 examples to avoid logging too frequently
skipping logging after 102320 examples to avoid logging too frequently
train stats after 102336 examples: {'rewards_train/chosen': '0.39625', 'rewards_train/rejected': '-4.4807', 'rewards_train/margins': '4.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24329', 'examples_per_second': '5.1531', 'grad_norm': '5.4375', 'counters/examples': 102336, 'counters/updates': 6396}
skipping logging after 102352 examples to avoid logging too frequently
skipping logging after 102368 examples to avoid logging too frequently
skipping logging after 102384 examples to avoid logging too frequently
train stats after 102400 examples: {'rewards_train/chosen': '0.63555', 'rewards_train/rejected': '-5.3079', 'rewards_train/margins': '5.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23242', 'examples_per_second': '4.2864', 'grad_norm': '4.5', 'counters/examples': 102400, 'counters/updates': 6400}
skipping logging after 102416 examples to avoid logging too frequently
skipping logging after 102432 examples to avoid logging too frequently
skipping logging after 102448 examples to avoid logging too frequently
train stats after 102464 examples: {'rewards_train/chosen': '0.4809', 'rewards_train/rejected': '-7.1085', 'rewards_train/margins': '8.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24213', 'examples_per_second': '4.716', 'grad_norm': '4.5938', 'counters/examples': 102464, 'counters/updates': 6404}
skipping logging after 102480 examples to avoid logging too frequently
skipping logging after 102496 examples to avoid logging too frequently
skipping logging after 102512 examples to avoid logging too frequently
train stats after 102528 examples: {'rewards_train/chosen': '0.3862', 'rewards_train/rejected': '-5.6746', 'rewards_train/margins': '6.0547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20618', 'examples_per_second': '5.4683', 'grad_norm': '4.5625', 'counters/examples': 102528, 'counters/updates': 6408}
skipping logging after 102544 examples to avoid logging too frequently
skipping logging after 102560 examples to avoid logging too frequently
skipping logging after 102576 examples to avoid logging too frequently
train stats after 102592 examples: {'rewards_train/chosen': '0.35073', 'rewards_train/rejected': '-5.4929', 'rewards_train/margins': '5.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23767', 'examples_per_second': '4.5466', 'grad_norm': '6.0312', 'counters/examples': 102592, 'counters/updates': 6412}
skipping logging after 102608 examples to avoid logging too frequently
skipping logging after 102624 examples to avoid logging too frequently
skipping logging after 102640 examples to avoid logging too frequently
train stats after 102656 examples: {'rewards_train/chosen': '0.34574', 'rewards_train/rejected': '-6.2355', 'rewards_train/margins': '6.6094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21375', 'examples_per_second': '5.2813', 'grad_norm': '4.7188', 'counters/examples': 102656, 'counters/updates': 6416}
skipping logging after 102672 examples to avoid logging too frequently
skipping logging after 102688 examples to avoid logging too frequently
skipping logging after 102704 examples to avoid logging too frequently
train stats after 102720 examples: {'rewards_train/chosen': '0.30804', 'rewards_train/rejected': '-6.5113', 'rewards_train/margins': '6.8203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24994', 'examples_per_second': '4.338', 'grad_norm': '5.4375', 'counters/examples': 102720, 'counters/updates': 6420}
skipping logging after 102736 examples to avoid logging too frequently
skipping logging after 102752 examples to avoid logging too frequently
skipping logging after 102768 examples to avoid logging too frequently
train stats after 102784 examples: {'rewards_train/chosen': '0.43877', 'rewards_train/rejected': '-4.8354', 'rewards_train/margins': '5.1719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24438', 'examples_per_second': '5.6192', 'grad_norm': '5.3438', 'counters/examples': 102784, 'counters/updates': 6424}
skipping logging after 102800 examples to avoid logging too frequently
skipping logging after 102816 examples to avoid logging too frequently
skipping logging after 102832 examples to avoid logging too frequently
train stats after 102848 examples: {'rewards_train/chosen': '0.31361', 'rewards_train/rejected': '-5.6195', 'rewards_train/margins': '5.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25232', 'examples_per_second': '5.2621', 'grad_norm': '4.875', 'counters/examples': 102848, 'counters/updates': 6428}
skipping logging after 102864 examples to avoid logging too frequently
skipping logging after 102880 examples to avoid logging too frequently
skipping logging after 102896 examples to avoid logging too frequently
train stats after 102912 examples: {'rewards_train/chosen': '0.24312', 'rewards_train/rejected': '-5.956', 'rewards_train/margins': '5.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25952', 'examples_per_second': '5.0455', 'grad_norm': '5.3125', 'counters/examples': 102912, 'counters/updates': 6432}
skipping logging after 102928 examples to avoid logging too frequently
skipping logging after 102944 examples to avoid logging too frequently
skipping logging after 102960 examples to avoid logging too frequently
train stats after 102976 examples: {'rewards_train/chosen': '0.4148', 'rewards_train/rejected': '-5.623', 'rewards_train/margins': '5.8984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21387', 'examples_per_second': '5.9694', 'grad_norm': '4.5312', 'counters/examples': 102976, 'counters/updates': 6436}
skipping logging after 102992 examples to avoid logging too frequently
skipping logging after 103008 examples to avoid logging too frequently
skipping logging after 103024 examples to avoid logging too frequently
train stats after 103040 examples: {'rewards_train/chosen': '0.58741', 'rewards_train/rejected': '-6.2876', 'rewards_train/margins': '6.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23535', 'examples_per_second': '4.7518', 'grad_norm': '4.2188', 'counters/examples': 103040, 'counters/updates': 6440}
skipping logging after 103056 examples to avoid logging too frequently
skipping logging after 103072 examples to avoid logging too frequently
skipping logging after 103088 examples to avoid logging too frequently
train stats after 103104 examples: {'rewards_train/chosen': '0.62736', 'rewards_train/rejected': '-5.7382', 'rewards_train/margins': '6.2344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20148', 'examples_per_second': '4.4676', 'grad_norm': '4.5938', 'counters/examples': 103104, 'counters/updates': 6444}
skipping logging after 103120 examples to avoid logging too frequently
skipping logging after 103136 examples to avoid logging too frequently
skipping logging after 103152 examples to avoid logging too frequently
train stats after 103168 examples: {'rewards_train/chosen': '0.58096', 'rewards_train/rejected': '-6.2532', 'rewards_train/margins': '6.9961', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24677', 'examples_per_second': '5.0577', 'grad_norm': '4.9375', 'counters/examples': 103168, 'counters/updates': 6448}
skipping logging after 103184 examples to avoid logging too frequently
skipping logging after 103200 examples to avoid logging too frequently
skipping logging after 103216 examples to avoid logging too frequently
train stats after 103232 examples: {'rewards_train/chosen': '0.52783', 'rewards_train/rejected': '-5.8638', 'rewards_train/margins': '6.375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17023', 'examples_per_second': '5.2482', 'grad_norm': '4.6562', 'counters/examples': 103232, 'counters/updates': 6452}
skipping logging after 103248 examples to avoid logging too frequently
skipping logging after 103264 examples to avoid logging too frequently
skipping logging after 103280 examples to avoid logging too frequently
train stats after 103296 examples: {'rewards_train/chosen': '0.29387', 'rewards_train/rejected': '-7.1388', 'rewards_train/margins': '6.4219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24841', 'examples_per_second': '4.9107', 'grad_norm': '6.625', 'counters/examples': 103296, 'counters/updates': 6456}
skipping logging after 103312 examples to avoid logging too frequently
skipping logging after 103328 examples to avoid logging too frequently
skipping logging after 103344 examples to avoid logging too frequently
train stats after 103360 examples: {'rewards_train/chosen': '0.48684', 'rewards_train/rejected': '-5.4217', 'rewards_train/margins': '6', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20447', 'examples_per_second': '6.2222', 'grad_norm': '4.625', 'counters/examples': 103360, 'counters/updates': 6460}
skipping logging after 103376 examples to avoid logging too frequently
skipping logging after 103392 examples to avoid logging too frequently
skipping logging after 103408 examples to avoid logging too frequently
train stats after 103424 examples: {'rewards_train/chosen': '0.61208', 'rewards_train/rejected': '-4.9423', 'rewards_train/margins': '6.1016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26605', 'examples_per_second': '4.3881', 'grad_norm': '5.4375', 'counters/examples': 103424, 'counters/updates': 6464}
skipping logging after 103440 examples to avoid logging too frequently
skipping logging after 103456 examples to avoid logging too frequently
skipping logging after 103472 examples to avoid logging too frequently
train stats after 103488 examples: {'rewards_train/chosen': '0.46931', 'rewards_train/rejected': '-4.4944', 'rewards_train/margins': '4.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26007', 'examples_per_second': '5.3882', 'grad_norm': '4.8438', 'counters/examples': 103488, 'counters/updates': 6468}
skipping logging after 103504 examples to avoid logging too frequently
skipping logging after 103520 examples to avoid logging too frequently
skipping logging after 103536 examples to avoid logging too frequently
train stats after 103552 examples: {'rewards_train/chosen': '0.88514', 'rewards_train/rejected': '-5.2477', 'rewards_train/margins': '5.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18567', 'examples_per_second': '5.6062', 'grad_norm': '5.4062', 'counters/examples': 103552, 'counters/updates': 6472}
skipping logging after 103568 examples to avoid logging too frequently
skipping logging after 103584 examples to avoid logging too frequently
skipping logging after 103600 examples to avoid logging too frequently
train stats after 103616 examples: {'rewards_train/chosen': '0.48537', 'rewards_train/rejected': '-6.2278', 'rewards_train/margins': '7.3594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23462', 'examples_per_second': '5.9009', 'grad_norm': '5.7188', 'counters/examples': 103616, 'counters/updates': 6476}
skipping logging after 103632 examples to avoid logging too frequently
skipping logging after 103648 examples to avoid logging too frequently
skipping logging after 103664 examples to avoid logging too frequently
train stats after 103680 examples: {'rewards_train/chosen': '0.12645', 'rewards_train/rejected': '-5.5787', 'rewards_train/margins': '5.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25201', 'examples_per_second': '5.0288', 'grad_norm': '5.1562', 'counters/examples': 103680, 'counters/updates': 6480}
skipping logging after 103696 examples to avoid logging too frequently
skipping logging after 103712 examples to avoid logging too frequently
skipping logging after 103728 examples to avoid logging too frequently
train stats after 103744 examples: {'rewards_train/chosen': '0.46279', 'rewards_train/rejected': '-6.0142', 'rewards_train/margins': '6.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21106', 'examples_per_second': '4.7891', 'grad_norm': '5.125', 'counters/examples': 103744, 'counters/updates': 6484}
skipping logging after 103760 examples to avoid logging too frequently
skipping logging after 103776 examples to avoid logging too frequently
skipping logging after 103792 examples to avoid logging too frequently
train stats after 103808 examples: {'rewards_train/chosen': '0.60571', 'rewards_train/rejected': '-4.9632', 'rewards_train/margins': '5.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22272', 'examples_per_second': '5.7221', 'grad_norm': '5.375', 'counters/examples': 103808, 'counters/updates': 6488}
skipping logging after 103824 examples to avoid logging too frequently
skipping logging after 103840 examples to avoid logging too frequently
skipping logging after 103856 examples to avoid logging too frequently
train stats after 103872 examples: {'rewards_train/chosen': '0.44759', 'rewards_train/rejected': '-6.1994', 'rewards_train/margins': '6.1621', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26752', 'examples_per_second': '5.0344', 'grad_norm': '5.0625', 'counters/examples': 103872, 'counters/updates': 6492}
skipping logging after 103888 examples to avoid logging too frequently
skipping logging after 103904 examples to avoid logging too frequently
skipping logging after 103920 examples to avoid logging too frequently
train stats after 103936 examples: {'rewards_train/chosen': '0.33243', 'rewards_train/rejected': '-5.1286', 'rewards_train/margins': '5.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25317', 'examples_per_second': '5.8935', 'grad_norm': '5.0312', 'counters/examples': 103936, 'counters/updates': 6496}
skipping logging after 103952 examples to avoid logging too frequently
skipping logging after 103968 examples to avoid logging too frequently
skipping logging after 103984 examples to avoid logging too frequently
train stats after 104000 examples: {'rewards_train/chosen': '0.20109', 'rewards_train/rejected': '-4.7367', 'rewards_train/margins': '5.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23145', 'examples_per_second': '4.5631', 'grad_norm': '4.75', 'counters/examples': 104000, 'counters/updates': 6500}
Running evaluation after 104000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.26s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.17s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:40,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.65s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.47s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:33,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.51s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.40s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:30,  1.47s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:21<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:13,  1.44s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]
eval after 104000: {'rewards_eval/chosen': '-5.7316', 'rewards_eval/rejected': '-6.0916', 'rewards_eval/margins': '0.23779', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46577'}
skipping logging after 104016 examples to avoid logging too frequently
skipping logging after 104032 examples to avoid logging too frequently
skipping logging after 104048 examples to avoid logging too frequently
train stats after 104064 examples: {'rewards_train/chosen': '0.28095', 'rewards_train/rejected': '-5.3629', 'rewards_train/margins': '5.5195', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22028', 'examples_per_second': '5.1756', 'grad_norm': '5.5625', 'counters/examples': 104064, 'counters/updates': 6504}
skipping logging after 104080 examples to avoid logging too frequently
skipping logging after 104096 examples to avoid logging too frequently
skipping logging after 104112 examples to avoid logging too frequently
train stats after 104128 examples: {'rewards_train/chosen': '-0.23409', 'rewards_train/rejected': '-5.697', 'rewards_train/margins': '5.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23456', 'examples_per_second': '4.6712', 'grad_norm': '5.2188', 'counters/examples': 104128, 'counters/updates': 6508}
skipping logging after 104144 examples to avoid logging too frequently
skipping logging after 104160 examples to avoid logging too frequently
skipping logging after 104176 examples to avoid logging too frequently
train stats after 104192 examples: {'rewards_train/chosen': '0.46831', 'rewards_train/rejected': '-4.9658', 'rewards_train/margins': '5.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23529', 'examples_per_second': '5.1882', 'grad_norm': '5.6875', 'counters/examples': 104192, 'counters/updates': 6512}
skipping logging after 104208 examples to avoid logging too frequently
skipping logging after 104224 examples to avoid logging too frequently
skipping logging after 104240 examples to avoid logging too frequently
train stats after 104256 examples: {'rewards_train/chosen': '0.5773', 'rewards_train/rejected': '-5.232', 'rewards_train/margins': '6.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23175', 'examples_per_second': '4.1231', 'grad_norm': '5.2188', 'counters/examples': 104256, 'counters/updates': 6516}
skipping logging after 104272 examples to avoid logging too frequently
skipping logging after 104288 examples to avoid logging too frequently
skipping logging after 104304 examples to avoid logging too frequently
train stats after 104320 examples: {'rewards_train/chosen': '0.3156', 'rewards_train/rejected': '-5.743', 'rewards_train/margins': '6.2266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23932', 'examples_per_second': '5.3633', 'grad_norm': '5.25', 'counters/examples': 104320, 'counters/updates': 6520}
skipping logging after 104336 examples to avoid logging too frequently
skipping logging after 104352 examples to avoid logging too frequently
skipping logging after 104368 examples to avoid logging too frequently
train stats after 104384 examples: {'rewards_train/chosen': '0.55404', 'rewards_train/rejected': '-6.9525', 'rewards_train/margins': '7.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19464', 'examples_per_second': '4.6648', 'grad_norm': '4.7188', 'counters/examples': 104384, 'counters/updates': 6524}
skipping logging after 104400 examples to avoid logging too frequently
skipping logging after 104416 examples to avoid logging too frequently
skipping logging after 104432 examples to avoid logging too frequently
train stats after 104448 examples: {'rewards_train/chosen': '0.70063', 'rewards_train/rejected': '-7.2255', 'rewards_train/margins': '8.0156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20227', 'examples_per_second': '4.2493', 'grad_norm': '6.7188', 'counters/examples': 104448, 'counters/updates': 6528}
skipping logging after 104464 examples to avoid logging too frequently
skipping logging after 104480 examples to avoid logging too frequently
skipping logging after 104496 examples to avoid logging too frequently
train stats after 104512 examples: {'rewards_train/chosen': '0.39005', 'rewards_train/rejected': '-6.7361', 'rewards_train/margins': '7.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22424', 'examples_per_second': '4.7243', 'grad_norm': '5.4688', 'counters/examples': 104512, 'counters/updates': 6532}
skipping logging after 104528 examples to avoid logging too frequently
skipping logging after 104544 examples to avoid logging too frequently
skipping logging after 104560 examples to avoid logging too frequently
train stats after 104576 examples: {'rewards_train/chosen': '-0.02305', 'rewards_train/rejected': '-6.7853', 'rewards_train/margins': '6.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23688', 'examples_per_second': '4.2825', 'grad_norm': '4.4375', 'counters/examples': 104576, 'counters/updates': 6536}
skipping logging after 104592 examples to avoid logging too frequently
skipping logging after 104608 examples to avoid logging too frequently
skipping logging after 104624 examples to avoid logging too frequently
train stats after 104640 examples: {'rewards_train/chosen': '0.18211', 'rewards_train/rejected': '-4.9581', 'rewards_train/margins': '5.0859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24438', 'examples_per_second': '7.2227', 'grad_norm': '5.0938', 'counters/examples': 104640, 'counters/updates': 6540}
skipping logging after 104656 examples to avoid logging too frequently
skipping logging after 104672 examples to avoid logging too frequently
skipping logging after 104688 examples to avoid logging too frequently
train stats after 104704 examples: {'rewards_train/chosen': '0.38316', 'rewards_train/rejected': '-5.2169', 'rewards_train/margins': '5.668', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2699', 'examples_per_second': '5.6514', 'grad_norm': '5.5', 'counters/examples': 104704, 'counters/updates': 6544}
skipping logging after 104720 examples to avoid logging too frequently
skipping logging after 104736 examples to avoid logging too frequently
skipping logging after 104752 examples to avoid logging too frequently
train stats after 104768 examples: {'rewards_train/chosen': '0.35285', 'rewards_train/rejected': '-3.6132', 'rewards_train/margins': '4.0234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2641', 'examples_per_second': '4.7057', 'grad_norm': '5.4062', 'counters/examples': 104768, 'counters/updates': 6548}
skipping logging after 104784 examples to avoid logging too frequently
skipping logging after 104800 examples to avoid logging too frequently
skipping logging after 104816 examples to avoid logging too frequently
train stats after 104832 examples: {'rewards_train/chosen': '0.46316', 'rewards_train/rejected': '-4.3693', 'rewards_train/margins': '4.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24066', 'examples_per_second': '5.0811', 'grad_norm': '4.8438', 'counters/examples': 104832, 'counters/updates': 6552}
skipping logging after 104848 examples to avoid logging too frequently
skipping logging after 104864 examples to avoid logging too frequently
skipping logging after 104880 examples to avoid logging too frequently
train stats after 104896 examples: {'rewards_train/chosen': '0.44456', 'rewards_train/rejected': '-4.4784', 'rewards_train/margins': '4.6914', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29169', 'examples_per_second': '4.7562', 'grad_norm': '5.5312', 'counters/examples': 104896, 'counters/updates': 6556}
skipping logging after 104912 examples to avoid logging too frequently
skipping logging after 104928 examples to avoid logging too frequently
skipping logging after 104944 examples to avoid logging too frequently
train stats after 104960 examples: {'rewards_train/chosen': '0.47147', 'rewards_train/rejected': '-5.5788', 'rewards_train/margins': '5.9297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2168', 'examples_per_second': '6.1015', 'grad_norm': '5.2812', 'counters/examples': 104960, 'counters/updates': 6560}
skipping logging after 104976 examples to avoid logging too frequently
skipping logging after 104992 examples to avoid logging too frequently
skipping logging after 105008 examples to avoid logging too frequently
train stats after 105024 examples: {'rewards_train/chosen': '0.46739', 'rewards_train/rejected': '-4.9439', 'rewards_train/margins': '5.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2417', 'examples_per_second': '5.5323', 'grad_norm': '5.4688', 'counters/examples': 105024, 'counters/updates': 6564}
skipping logging after 105040 examples to avoid logging too frequently
skipping logging after 105056 examples to avoid logging too frequently
skipping logging after 105072 examples to avoid logging too frequently
train stats after 105088 examples: {'rewards_train/chosen': '0.3296', 'rewards_train/rejected': '-5.6527', 'rewards_train/margins': '6.0312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24902', 'examples_per_second': '4.8932', 'grad_norm': '4.9062', 'counters/examples': 105088, 'counters/updates': 6568}
skipping logging after 105104 examples to avoid logging too frequently
skipping logging after 105120 examples to avoid logging too frequently
skipping logging after 105136 examples to avoid logging too frequently
train stats after 105152 examples: {'rewards_train/chosen': '0.41994', 'rewards_train/rejected': '-5.4908', 'rewards_train/margins': '5.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25696', 'examples_per_second': '5.4021', 'grad_norm': '4.9062', 'counters/examples': 105152, 'counters/updates': 6572}
skipping logging after 105168 examples to avoid logging too frequently
skipping logging after 105184 examples to avoid logging too frequently
skipping logging after 105200 examples to avoid logging too frequently
train stats after 105216 examples: {'rewards_train/chosen': '0.36943', 'rewards_train/rejected': '-4.1041', 'rewards_train/margins': '4.4531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28369', 'examples_per_second': '5.6894', 'grad_norm': '5.1562', 'counters/examples': 105216, 'counters/updates': 6576}
skipping logging after 105232 examples to avoid logging too frequently
skipping logging after 105248 examples to avoid logging too frequently
skipping logging after 105264 examples to avoid logging too frequently
train stats after 105280 examples: {'rewards_train/chosen': '0.64716', 'rewards_train/rejected': '-5.3867', 'rewards_train/margins': '6.0312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24866', 'examples_per_second': '5.2433', 'grad_norm': '4.9062', 'counters/examples': 105280, 'counters/updates': 6580}
skipping logging after 105296 examples to avoid logging too frequently
skipping logging after 105312 examples to avoid logging too frequently
skipping logging after 105328 examples to avoid logging too frequently
train stats after 105344 examples: {'rewards_train/chosen': '0.31014', 'rewards_train/rejected': '-6.8408', 'rewards_train/margins': '6.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.229', 'examples_per_second': '5.0639', 'grad_norm': '4.375', 'counters/examples': 105344, 'counters/updates': 6584}
skipping logging after 105360 examples to avoid logging too frequently
skipping logging after 105376 examples to avoid logging too frequently
skipping logging after 105392 examples to avoid logging too frequently
train stats after 105408 examples: {'rewards_train/chosen': '0.29494', 'rewards_train/rejected': '-6.278', 'rewards_train/margins': '6.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27905', 'examples_per_second': '4.9471', 'grad_norm': '5.25', 'counters/examples': 105408, 'counters/updates': 6588}
skipping logging after 105424 examples to avoid logging too frequently
skipping logging after 105440 examples to avoid logging too frequently
skipping logging after 105456 examples to avoid logging too frequently
train stats after 105472 examples: {'rewards_train/chosen': '0.39673', 'rewards_train/rejected': '-4.6552', 'rewards_train/margins': '4.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2572', 'examples_per_second': '4.94', 'grad_norm': '5.0625', 'counters/examples': 105472, 'counters/updates': 6592}
skipping logging after 105488 examples to avoid logging too frequently
skipping logging after 105504 examples to avoid logging too frequently
skipping logging after 105520 examples to avoid logging too frequently
train stats after 105536 examples: {'rewards_train/chosen': '0.49563', 'rewards_train/rejected': '-6.5579', 'rewards_train/margins': '6.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23181', 'examples_per_second': '5.1749', 'grad_norm': '5.5', 'counters/examples': 105536, 'counters/updates': 6596}
skipping logging after 105552 examples to avoid logging too frequently
skipping logging after 105568 examples to avoid logging too frequently
skipping logging after 105584 examples to avoid logging too frequently
train stats after 105600 examples: {'rewards_train/chosen': '0.27276', 'rewards_train/rejected': '-5.7846', 'rewards_train/margins': '6.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23926', 'examples_per_second': '4.6551', 'grad_norm': '4.7188', 'counters/examples': 105600, 'counters/updates': 6600}
skipping logging after 105616 examples to avoid logging too frequently
skipping logging after 105632 examples to avoid logging too frequently
skipping logging after 105648 examples to avoid logging too frequently
train stats after 105664 examples: {'rewards_train/chosen': '0.61357', 'rewards_train/rejected': '-6.5092', 'rewards_train/margins': '7.0547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23657', 'examples_per_second': '4.5618', 'grad_norm': '5.5312', 'counters/examples': 105664, 'counters/updates': 6604}
skipping logging after 105680 examples to avoid logging too frequently
skipping logging after 105696 examples to avoid logging too frequently
skipping logging after 105712 examples to avoid logging too frequently
train stats after 105728 examples: {'rewards_train/chosen': '0.54999', 'rewards_train/rejected': '-4.9934', 'rewards_train/margins': '5.5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2475', 'examples_per_second': '4.8099', 'grad_norm': '4.7812', 'counters/examples': 105728, 'counters/updates': 6608}
skipping logging after 105744 examples to avoid logging too frequently
skipping logging after 105760 examples to avoid logging too frequently
skipping logging after 105776 examples to avoid logging too frequently
train stats after 105792 examples: {'rewards_train/chosen': '0.34513', 'rewards_train/rejected': '-5.8488', 'rewards_train/margins': '6.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2207', 'examples_per_second': '6.1093', 'grad_norm': '5.1562', 'counters/examples': 105792, 'counters/updates': 6612}
skipping logging after 105808 examples to avoid logging too frequently
skipping logging after 105824 examples to avoid logging too frequently
skipping logging after 105840 examples to avoid logging too frequently
train stats after 105856 examples: {'rewards_train/chosen': '0.55477', 'rewards_train/rejected': '-4.5277', 'rewards_train/margins': '4.9961', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24121', 'examples_per_second': '4.7033', 'grad_norm': '5.9688', 'counters/examples': 105856, 'counters/updates': 6616}
skipping logging after 105872 examples to avoid logging too frequently
skipping logging after 105888 examples to avoid logging too frequently
skipping logging after 105904 examples to avoid logging too frequently
train stats after 105920 examples: {'rewards_train/chosen': '0.49417', 'rewards_train/rejected': '-4.8089', 'rewards_train/margins': '5.2422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22131', 'examples_per_second': '4.8879', 'grad_norm': '4.625', 'counters/examples': 105920, 'counters/updates': 6620}
skipping logging after 105936 examples to avoid logging too frequently
skipping logging after 105952 examples to avoid logging too frequently
skipping logging after 105968 examples to avoid logging too frequently
train stats after 105984 examples: {'rewards_train/chosen': '0.33255', 'rewards_train/rejected': '-4.2524', 'rewards_train/margins': '4.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2738', 'examples_per_second': '5.7865', 'grad_norm': '4.3125', 'counters/examples': 105984, 'counters/updates': 6624}
skipping logging after 106000 examples to avoid logging too frequently
skipping logging after 106016 examples to avoid logging too frequently
skipping logging after 106032 examples to avoid logging too frequently
train stats after 106048 examples: {'rewards_train/chosen': '0.53206', 'rewards_train/rejected': '-5.717', 'rewards_train/margins': '6.0234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22614', 'examples_per_second': '4.9918', 'grad_norm': '5', 'counters/examples': 106048, 'counters/updates': 6628}
skipping logging after 106064 examples to avoid logging too frequently
skipping logging after 106080 examples to avoid logging too frequently
skipping logging after 106096 examples to avoid logging too frequently
train stats after 106112 examples: {'rewards_train/chosen': '0.27421', 'rewards_train/rejected': '-6.2443', 'rewards_train/margins': '6.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27435', 'examples_per_second': '5.1433', 'grad_norm': '5.25', 'counters/examples': 106112, 'counters/updates': 6632}
skipping logging after 106128 examples to avoid logging too frequently
skipping logging after 106144 examples to avoid logging too frequently
skipping logging after 106160 examples to avoid logging too frequently
train stats after 106176 examples: {'rewards_train/chosen': '0.22282', 'rewards_train/rejected': '-6.6702', 'rewards_train/margins': '7.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29187', 'examples_per_second': '5.256', 'grad_norm': '5.3438', 'counters/examples': 106176, 'counters/updates': 6636}
skipping logging after 106192 examples to avoid logging too frequently
skipping logging after 106208 examples to avoid logging too frequently
skipping logging after 106224 examples to avoid logging too frequently
train stats after 106240 examples: {'rewards_train/chosen': '0.26385', 'rewards_train/rejected': '-6.7182', 'rewards_train/margins': '7.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24908', 'examples_per_second': '4.7604', 'grad_norm': '4.8438', 'counters/examples': 106240, 'counters/updates': 6640}
skipping logging after 106256 examples to avoid logging too frequently
skipping logging after 106272 examples to avoid logging too frequently
skipping logging after 106288 examples to avoid logging too frequently
train stats after 106304 examples: {'rewards_train/chosen': '0.51541', 'rewards_train/rejected': '-4.6523', 'rewards_train/margins': '5.2422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20514', 'examples_per_second': '5.7328', 'grad_norm': '4.4688', 'counters/examples': 106304, 'counters/updates': 6644}
skipping logging after 106320 examples to avoid logging too frequently
skipping logging after 106336 examples to avoid logging too frequently
skipping logging after 106352 examples to avoid logging too frequently
train stats after 106368 examples: {'rewards_train/chosen': '0.52449', 'rewards_train/rejected': '-6.0973', 'rewards_train/margins': '6.8125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20831', 'examples_per_second': '5.138', 'grad_norm': '4.5312', 'counters/examples': 106368, 'counters/updates': 6648}
skipping logging after 106384 examples to avoid logging too frequently
skipping logging after 106400 examples to avoid logging too frequently
skipping logging after 106416 examples to avoid logging too frequently
train stats after 106432 examples: {'rewards_train/chosen': '-0.13892', 'rewards_train/rejected': '-6.0974', 'rewards_train/margins': '6.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24304', 'examples_per_second': '4.8123', 'grad_norm': '4.6875', 'counters/examples': 106432, 'counters/updates': 6652}
skipping logging after 106448 examples to avoid logging too frequently
skipping logging after 106464 examples to avoid logging too frequently
skipping logging after 106480 examples to avoid logging too frequently
train stats after 106496 examples: {'rewards_train/chosen': '-0.0037731', 'rewards_train/rejected': '-5.5161', 'rewards_train/margins': '5.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21515', 'examples_per_second': '5.5992', 'grad_norm': '4.9375', 'counters/examples': 106496, 'counters/updates': 6656}
skipping logging after 106512 examples to avoid logging too frequently
skipping logging after 106528 examples to avoid logging too frequently
skipping logging after 106544 examples to avoid logging too frequently
train stats after 106560 examples: {'rewards_train/chosen': '0.30892', 'rewards_train/rejected': '-6.1212', 'rewards_train/margins': '6.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24835', 'examples_per_second': '4.6205', 'grad_norm': '5.25', 'counters/examples': 106560, 'counters/updates': 6660}
skipping logging after 106576 examples to avoid logging too frequently
skipping logging after 106592 examples to avoid logging too frequently
skipping logging after 106608 examples to avoid logging too frequently
train stats after 106624 examples: {'rewards_train/chosen': '0.6615', 'rewards_train/rejected': '-5.7896', 'rewards_train/margins': '6.5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21045', 'examples_per_second': '4.7249', 'grad_norm': '4.8125', 'counters/examples': 106624, 'counters/updates': 6664}
skipping logging after 106640 examples to avoid logging too frequently
skipping logging after 106656 examples to avoid logging too frequently
skipping logging after 106672 examples to avoid logging too frequently
train stats after 106688 examples: {'rewards_train/chosen': '0.41914', 'rewards_train/rejected': '-6.0465', 'rewards_train/margins': '7.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24152', 'examples_per_second': '5.0683', 'grad_norm': '4.9688', 'counters/examples': 106688, 'counters/updates': 6668}
skipping logging after 106704 examples to avoid logging too frequently
skipping logging after 106720 examples to avoid logging too frequently
skipping logging after 106736 examples to avoid logging too frequently
train stats after 106752 examples: {'rewards_train/chosen': '0.57611', 'rewards_train/rejected': '-4.7648', 'rewards_train/margins': '5.3711', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21484', 'examples_per_second': '5.2143', 'grad_norm': '5.5', 'counters/examples': 106752, 'counters/updates': 6672}
skipping logging after 106768 examples to avoid logging too frequently
skipping logging after 106784 examples to avoid logging too frequently
skipping logging after 106800 examples to avoid logging too frequently
train stats after 106816 examples: {'rewards_train/chosen': '0.71286', 'rewards_train/rejected': '-5.421', 'rewards_train/margins': '6.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22754', 'examples_per_second': '5.0615', 'grad_norm': '4.8438', 'counters/examples': 106816, 'counters/updates': 6676}
skipping logging after 106832 examples to avoid logging too frequently
skipping logging after 106848 examples to avoid logging too frequently
skipping logging after 106864 examples to avoid logging too frequently
train stats after 106880 examples: {'rewards_train/chosen': '0.38079', 'rewards_train/rejected': '-5.4239', 'rewards_train/margins': '5.6641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23627', 'examples_per_second': '5.9017', 'grad_norm': '5.7812', 'counters/examples': 106880, 'counters/updates': 6680}
skipping logging after 106896 examples to avoid logging too frequently
skipping logging after 106912 examples to avoid logging too frequently
skipping logging after 106928 examples to avoid logging too frequently
train stats after 106944 examples: {'rewards_train/chosen': '0.6048', 'rewards_train/rejected': '-5.0583', 'rewards_train/margins': '5.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23572', 'examples_per_second': '4.5408', 'grad_norm': '5.4688', 'counters/examples': 106944, 'counters/updates': 6684}
skipping logging after 106960 examples to avoid logging too frequently
skipping logging after 106976 examples to avoid logging too frequently
skipping logging after 106992 examples to avoid logging too frequently
train stats after 107008 examples: {'rewards_train/chosen': '0.48572', 'rewards_train/rejected': '-6.6315', 'rewards_train/margins': '6.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19592', 'examples_per_second': '5.5012', 'grad_norm': '4.5', 'counters/examples': 107008, 'counters/updates': 6688}
skipping logging after 107024 examples to avoid logging too frequently
skipping logging after 107040 examples to avoid logging too frequently
skipping logging after 107056 examples to avoid logging too frequently
train stats after 107072 examples: {'rewards_train/chosen': '0.43248', 'rewards_train/rejected': '-6.0615', 'rewards_train/margins': '6.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19824', 'examples_per_second': '5.6988', 'grad_norm': '5.7812', 'counters/examples': 107072, 'counters/updates': 6692}
skipping logging after 107088 examples to avoid logging too frequently
skipping logging after 107104 examples to avoid logging too frequently
skipping logging after 107120 examples to avoid logging too frequently
train stats after 107136 examples: {'rewards_train/chosen': '0.030318', 'rewards_train/rejected': '-5.3387', 'rewards_train/margins': '5.3281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2688', 'examples_per_second': '5.1515', 'grad_norm': '5.0312', 'counters/examples': 107136, 'counters/updates': 6696}
skipping logging after 107152 examples to avoid logging too frequently
skipping logging after 107168 examples to avoid logging too frequently
skipping logging after 107184 examples to avoid logging too frequently
train stats after 107200 examples: {'rewards_train/chosen': '0.44238', 'rewards_train/rejected': '-6.1899', 'rewards_train/margins': '6.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2514', 'examples_per_second': '5.6959', 'grad_norm': '5', 'counters/examples': 107200, 'counters/updates': 6700}
skipping logging after 107216 examples to avoid logging too frequently
skipping logging after 107232 examples to avoid logging too frequently
skipping logging after 107248 examples to avoid logging too frequently
train stats after 107264 examples: {'rewards_train/chosen': '0.55024', 'rewards_train/rejected': '-5.0281', 'rewards_train/margins': '5.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21466', 'examples_per_second': '6.1214', 'grad_norm': '4.875', 'counters/examples': 107264, 'counters/updates': 6704}
skipping logging after 107280 examples to avoid logging too frequently
skipping logging after 107296 examples to avoid logging too frequently
skipping logging after 107312 examples to avoid logging too frequently
train stats after 107328 examples: {'rewards_train/chosen': '0.28817', 'rewards_train/rejected': '-6.7383', 'rewards_train/margins': '7.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22699', 'examples_per_second': '5.2209', 'grad_norm': '5.2812', 'counters/examples': 107328, 'counters/updates': 6708}
skipping logging after 107344 examples to avoid logging too frequently
skipping logging after 107360 examples to avoid logging too frequently
skipping logging after 107376 examples to avoid logging too frequently
train stats after 107392 examples: {'rewards_train/chosen': '0.45155', 'rewards_train/rejected': '-6.627', 'rewards_train/margins': '7.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21692', 'examples_per_second': '4.5209', 'grad_norm': '5.2812', 'counters/examples': 107392, 'counters/updates': 6712}
skipping logging after 107408 examples to avoid logging too frequently
skipping logging after 107424 examples to avoid logging too frequently
skipping logging after 107440 examples to avoid logging too frequently
train stats after 107456 examples: {'rewards_train/chosen': '0.55609', 'rewards_train/rejected': '-7.3888', 'rewards_train/margins': '8.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24457', 'examples_per_second': '5.7912', 'grad_norm': '4.9688', 'counters/examples': 107456, 'counters/updates': 6716}
skipping logging after 107472 examples to avoid logging too frequently
skipping logging after 107488 examples to avoid logging too frequently
skipping logging after 107504 examples to avoid logging too frequently
train stats after 107520 examples: {'rewards_train/chosen': '0.4858', 'rewards_train/rejected': '-6.0463', 'rewards_train/margins': '6.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23065', 'examples_per_second': '4.7981', 'grad_norm': '4.4688', 'counters/examples': 107520, 'counters/updates': 6720}
skipping logging after 107536 examples to avoid logging too frequently
skipping logging after 107552 examples to avoid logging too frequently
skipping logging after 107568 examples to avoid logging too frequently
train stats after 107584 examples: {'rewards_train/chosen': '0.79438', 'rewards_train/rejected': '-5.5744', 'rewards_train/margins': '6.3594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18768', 'examples_per_second': '5.2119', 'grad_norm': '4.6562', 'counters/examples': 107584, 'counters/updates': 6724}
skipping logging after 107600 examples to avoid logging too frequently
skipping logging after 107616 examples to avoid logging too frequently
skipping logging after 107632 examples to avoid logging too frequently
train stats after 107648 examples: {'rewards_train/chosen': '0.082687', 'rewards_train/rejected': '-6.5433', 'rewards_train/margins': '6.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2002', 'examples_per_second': '5.4575', 'grad_norm': '5.5938', 'counters/examples': 107648, 'counters/updates': 6728}
skipping logging after 107664 examples to avoid logging too frequently
skipping logging after 107680 examples to avoid logging too frequently
skipping logging after 107696 examples to avoid logging too frequently
train stats after 107712 examples: {'rewards_train/chosen': '0.48156', 'rewards_train/rejected': '-5.2664', 'rewards_train/margins': '5.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21527', 'examples_per_second': '5.6435', 'grad_norm': '4.2812', 'counters/examples': 107712, 'counters/updates': 6732}
skipping logging after 107728 examples to avoid logging too frequently
skipping logging after 107744 examples to avoid logging too frequently
skipping logging after 107760 examples to avoid logging too frequently
train stats after 107776 examples: {'rewards_train/chosen': '0.33687', 'rewards_train/rejected': '-6.069', 'rewards_train/margins': '6.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23663', 'examples_per_second': '4.7925', 'grad_norm': '5.0938', 'counters/examples': 107776, 'counters/updates': 6736}
skipping logging after 107792 examples to avoid logging too frequently
skipping logging after 107808 examples to avoid logging too frequently
skipping logging after 107824 examples to avoid logging too frequently
train stats after 107840 examples: {'rewards_train/chosen': '0.59631', 'rewards_train/rejected': '-5.8771', 'rewards_train/margins': '6.4531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21576', 'examples_per_second': '4.2444', 'grad_norm': '4.5938', 'counters/examples': 107840, 'counters/updates': 6740}
skipping logging after 107856 examples to avoid logging too frequently
skipping logging after 107872 examples to avoid logging too frequently
skipping logging after 107888 examples to avoid logging too frequently
train stats after 107904 examples: {'rewards_train/chosen': '0.42681', 'rewards_train/rejected': '-4.4443', 'rewards_train/margins': '4.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22937', 'examples_per_second': '4.2959', 'grad_norm': '5.375', 'counters/examples': 107904, 'counters/updates': 6744}
skipping logging after 107920 examples to avoid logging too frequently
skipping logging after 107936 examples to avoid logging too frequently
skipping logging after 107952 examples to avoid logging too frequently
train stats after 107968 examples: {'rewards_train/chosen': '0.33086', 'rewards_train/rejected': '-4.4248', 'rewards_train/margins': '4.7617', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27704', 'examples_per_second': '5.5308', 'grad_norm': '6.3125', 'counters/examples': 107968, 'counters/updates': 6748}
skipping logging after 107984 examples to avoid logging too frequently
skipping logging after 108000 examples to avoid logging too frequently
Running evaluation after 108000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:54,  1.75s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:43,  1.46s/it]Computing eval metrics:   9%|▉         | 3/32 [00:04<00:37,  1.28s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.50s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.70s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:09<00:39,  1.50s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:10<00:34,  1.38s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:12<00:36,  1.53s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.49s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:31,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.41s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.39s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:20<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:21<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.28s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:28<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:12,  1.51s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:38<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.20s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:40<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:41<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]
eval after 108000: {'rewards_eval/chosen': '-5.4588', 'rewards_eval/rejected': '-5.7516', 'rewards_eval/margins': '0.16748', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46609'}
skipping logging after 108016 examples to avoid logging too frequently
train stats after 108032 examples: {'rewards_train/chosen': '0.42532', 'rewards_train/rejected': '-5.6705', 'rewards_train/margins': '5.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25818', 'examples_per_second': '5.8165', 'grad_norm': '5.0625', 'counters/examples': 108032, 'counters/updates': 6752}
skipping logging after 108048 examples to avoid logging too frequently
skipping logging after 108064 examples to avoid logging too frequently
skipping logging after 108080 examples to avoid logging too frequently
train stats after 108096 examples: {'rewards_train/chosen': '0.1493', 'rewards_train/rejected': '-4.9245', 'rewards_train/margins': '5.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25092', 'examples_per_second': '5.1673', 'grad_norm': '5.0938', 'counters/examples': 108096, 'counters/updates': 6756}
skipping logging after 108112 examples to avoid logging too frequently
skipping logging after 108128 examples to avoid logging too frequently
skipping logging after 108144 examples to avoid logging too frequently
train stats after 108160 examples: {'rewards_train/chosen': '0.49224', 'rewards_train/rejected': '-6.4062', 'rewards_train/margins': '6.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24017', 'examples_per_second': '4.7715', 'grad_norm': '5.375', 'counters/examples': 108160, 'counters/updates': 6760}
skipping logging after 108176 examples to avoid logging too frequently
skipping logging after 108192 examples to avoid logging too frequently
skipping logging after 108208 examples to avoid logging too frequently
train stats after 108224 examples: {'rewards_train/chosen': '0.4958', 'rewards_train/rejected': '-4.3929', 'rewards_train/margins': '4.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26044', 'examples_per_second': '4.8756', 'grad_norm': '5.0312', 'counters/examples': 108224, 'counters/updates': 6764}
skipping logging after 108240 examples to avoid logging too frequently
skipping logging after 108256 examples to avoid logging too frequently
skipping logging after 108272 examples to avoid logging too frequently
train stats after 108288 examples: {'rewards_train/chosen': '0.47201', 'rewards_train/rejected': '-7.4007', 'rewards_train/margins': '7.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2149', 'examples_per_second': '4.7252', 'grad_norm': '5', 'counters/examples': 108288, 'counters/updates': 6768}
skipping logging after 108304 examples to avoid logging too frequently
skipping logging after 108320 examples to avoid logging too frequently
skipping logging after 108336 examples to avoid logging too frequently
train stats after 108352 examples: {'rewards_train/chosen': '0.42694', 'rewards_train/rejected': '-5.8995', 'rewards_train/margins': '6.2305', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22107', 'examples_per_second': '4.8304', 'grad_norm': '4.4062', 'counters/examples': 108352, 'counters/updates': 6772}
skipping logging after 108368 examples to avoid logging too frequently
skipping logging after 108384 examples to avoid logging too frequently
skipping logging after 108400 examples to avoid logging too frequently
train stats after 108416 examples: {'rewards_train/chosen': '0.1807', 'rewards_train/rejected': '-5.8016', 'rewards_train/margins': '5.8984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23132', 'examples_per_second': '5.3687', 'grad_norm': '4.5625', 'counters/examples': 108416, 'counters/updates': 6776}
skipping logging after 108432 examples to avoid logging too frequently
skipping logging after 108448 examples to avoid logging too frequently
skipping logging after 108464 examples to avoid logging too frequently
train stats after 108480 examples: {'rewards_train/chosen': '0.353', 'rewards_train/rejected': '-4.1997', 'rewards_train/margins': '4.6367', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25085', 'examples_per_second': '5.4502', 'grad_norm': '5.375', 'counters/examples': 108480, 'counters/updates': 6780}
skipping logging after 108496 examples to avoid logging too frequently
skipping logging after 108512 examples to avoid logging too frequently
skipping logging after 108528 examples to avoid logging too frequently
train stats after 108544 examples: {'rewards_train/chosen': '0.48177', 'rewards_train/rejected': '-7.1581', 'rewards_train/margins': '7.5391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23724', 'examples_per_second': '5.3016', 'grad_norm': '4.9062', 'counters/examples': 108544, 'counters/updates': 6784}
skipping logging after 108560 examples to avoid logging too frequently
skipping logging after 108576 examples to avoid logging too frequently
skipping logging after 108592 examples to avoid logging too frequently
train stats after 108608 examples: {'rewards_train/chosen': '0.68858', 'rewards_train/rejected': '-5.7099', 'rewards_train/margins': '6.4141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19037', 'examples_per_second': '4.5259', 'grad_norm': '4.5', 'counters/examples': 108608, 'counters/updates': 6788}
skipping logging after 108624 examples to avoid logging too frequently
skipping logging after 108640 examples to avoid logging too frequently
skipping logging after 108656 examples to avoid logging too frequently
train stats after 108672 examples: {'rewards_train/chosen': '0.30991', 'rewards_train/rejected': '-5.4418', 'rewards_train/margins': '5.6758', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27966', 'examples_per_second': '5.5669', 'grad_norm': '4.5625', 'counters/examples': 108672, 'counters/updates': 6792}
skipping logging after 108688 examples to avoid logging too frequently
skipping logging after 108704 examples to avoid logging too frequently
skipping logging after 108720 examples to avoid logging too frequently
train stats after 108736 examples: {'rewards_train/chosen': '0.43987', 'rewards_train/rejected': '-4.1808', 'rewards_train/margins': '4.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23969', 'examples_per_second': '4.4935', 'grad_norm': '4.375', 'counters/examples': 108736, 'counters/updates': 6796}
skipping logging after 108752 examples to avoid logging too frequently
skipping logging after 108768 examples to avoid logging too frequently
skipping logging after 108784 examples to avoid logging too frequently
train stats after 108800 examples: {'rewards_train/chosen': '0.32163', 'rewards_train/rejected': '-5.8617', 'rewards_train/margins': '6.1953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21802', 'examples_per_second': '4.2812', 'grad_norm': '5.5', 'counters/examples': 108800, 'counters/updates': 6800}
skipping logging after 108816 examples to avoid logging too frequently
skipping logging after 108832 examples to avoid logging too frequently
skipping logging after 108848 examples to avoid logging too frequently
train stats after 108864 examples: {'rewards_train/chosen': '0.44842', 'rewards_train/rejected': '-6.9219', 'rewards_train/margins': '7.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21484', 'examples_per_second': '4.9846', 'grad_norm': '4.5312', 'counters/examples': 108864, 'counters/updates': 6804}
skipping logging after 108880 examples to avoid logging too frequently
skipping logging after 108896 examples to avoid logging too frequently
skipping logging after 108912 examples to avoid logging too frequently
train stats after 108928 examples: {'rewards_train/chosen': '0.65786', 'rewards_train/rejected': '-6.6835', 'rewards_train/margins': '6.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20801', 'examples_per_second': '4.4555', 'grad_norm': '4.5938', 'counters/examples': 108928, 'counters/updates': 6808}
skipping logging after 108944 examples to avoid logging too frequently
skipping logging after 108960 examples to avoid logging too frequently
skipping logging after 108976 examples to avoid logging too frequently
train stats after 108992 examples: {'rewards_train/chosen': '0.51574', 'rewards_train/rejected': '-6.8883', 'rewards_train/margins': '7.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1861', 'examples_per_second': '5.2815', 'grad_norm': '4.0625', 'counters/examples': 108992, 'counters/updates': 6812}
skipping logging after 109008 examples to avoid logging too frequently
skipping logging after 109024 examples to avoid logging too frequently
skipping logging after 109040 examples to avoid logging too frequently
train stats after 109056 examples: {'rewards_train/chosen': '0.66369', 'rewards_train/rejected': '-5.1044', 'rewards_train/margins': '5.9453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20074', 'examples_per_second': '4.4472', 'grad_norm': '4.1875', 'counters/examples': 109056, 'counters/updates': 6816}
skipping logging after 109072 examples to avoid logging too frequently
skipping logging after 109088 examples to avoid logging too frequently
skipping logging after 109104 examples to avoid logging too frequently
train stats after 109120 examples: {'rewards_train/chosen': '0.62898', 'rewards_train/rejected': '-6.0484', 'rewards_train/margins': '6.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.15057', 'examples_per_second': '4.461', 'grad_norm': '4.9375', 'counters/examples': 109120, 'counters/updates': 6820}
skipping logging after 109136 examples to avoid logging too frequently
skipping logging after 109152 examples to avoid logging too frequently
skipping logging after 109168 examples to avoid logging too frequently
train stats after 109184 examples: {'rewards_train/chosen': '0.056382', 'rewards_train/rejected': '-5.9253', 'rewards_train/margins': '6.0234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30493', 'examples_per_second': '5.4666', 'grad_norm': '4.9688', 'counters/examples': 109184, 'counters/updates': 6824}
skipping logging after 109200 examples to avoid logging too frequently
skipping logging after 109216 examples to avoid logging too frequently
skipping logging after 109232 examples to avoid logging too frequently
train stats after 109248 examples: {'rewards_train/chosen': '0.36019', 'rewards_train/rejected': '-6.8816', 'rewards_train/margins': '7.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21289', 'examples_per_second': '5.0577', 'grad_norm': '5', 'counters/examples': 109248, 'counters/updates': 6828}
skipping logging after 109264 examples to avoid logging too frequently
skipping logging after 109280 examples to avoid logging too frequently
skipping logging after 109296 examples to avoid logging too frequently
train stats after 109312 examples: {'rewards_train/chosen': '0.13107', 'rewards_train/rejected': '-5.6468', 'rewards_train/margins': '5.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23816', 'examples_per_second': '4.2879', 'grad_norm': '4.7188', 'counters/examples': 109312, 'counters/updates': 6832}
skipping logging after 109328 examples to avoid logging too frequently
skipping logging after 109344 examples to avoid logging too frequently
skipping logging after 109360 examples to avoid logging too frequently
train stats after 109376 examples: {'rewards_train/chosen': '0.60179', 'rewards_train/rejected': '-5.6195', 'rewards_train/margins': '6.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22162', 'examples_per_second': '5.6503', 'grad_norm': '4.7188', 'counters/examples': 109376, 'counters/updates': 6836}
skipping logging after 109392 examples to avoid logging too frequently
skipping logging after 109408 examples to avoid logging too frequently
skipping logging after 109424 examples to avoid logging too frequently
train stats after 109440 examples: {'rewards_train/chosen': '0.48652', 'rewards_train/rejected': '-6.721', 'rewards_train/margins': '7.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26508', 'examples_per_second': '4.6477', 'grad_norm': '5.1562', 'counters/examples': 109440, 'counters/updates': 6840}
skipping logging after 109456 examples to avoid logging too frequently
skipping logging after 109472 examples to avoid logging too frequently
skipping logging after 109488 examples to avoid logging too frequently
train stats after 109504 examples: {'rewards_train/chosen': '0.40088', 'rewards_train/rejected': '-5.966', 'rewards_train/margins': '6.8672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19586', 'examples_per_second': '4.7543', 'grad_norm': '4.7812', 'counters/examples': 109504, 'counters/updates': 6844}
skipping logging after 109520 examples to avoid logging too frequently
skipping logging after 109536 examples to avoid logging too frequently
skipping logging after 109552 examples to avoid logging too frequently
train stats after 109568 examples: {'rewards_train/chosen': '0.078258', 'rewards_train/rejected': '-7.1962', 'rewards_train/margins': '7.2344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23724', 'examples_per_second': '4.5044', 'grad_norm': '4.75', 'counters/examples': 109568, 'counters/updates': 6848}
skipping logging after 109584 examples to avoid logging too frequently
skipping logging after 109600 examples to avoid logging too frequently
skipping logging after 109616 examples to avoid logging too frequently
train stats after 109632 examples: {'rewards_train/chosen': '0.13007', 'rewards_train/rejected': '-5.5707', 'rewards_train/margins': '5.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2807', 'examples_per_second': '5.4516', 'grad_norm': '7.1562', 'counters/examples': 109632, 'counters/updates': 6852}
skipping logging after 109648 examples to avoid logging too frequently
skipping logging after 109664 examples to avoid logging too frequently
skipping logging after 109680 examples to avoid logging too frequently
train stats after 109696 examples: {'rewards_train/chosen': '0.21809', 'rewards_train/rejected': '-6.622', 'rewards_train/margins': '7.2344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24829', 'examples_per_second': '5.1627', 'grad_norm': '5.6562', 'counters/examples': 109696, 'counters/updates': 6856}
skipping logging after 109712 examples to avoid logging too frequently
skipping logging after 109728 examples to avoid logging too frequently
skipping logging after 109744 examples to avoid logging too frequently
train stats after 109760 examples: {'rewards_train/chosen': '0.35352', 'rewards_train/rejected': '-6.1366', 'rewards_train/margins': '6.4844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25928', 'examples_per_second': '5.6555', 'grad_norm': '4.2188', 'counters/examples': 109760, 'counters/updates': 6860}
skipping logging after 109776 examples to avoid logging too frequently
skipping logging after 109792 examples to avoid logging too frequently
skipping logging after 109808 examples to avoid logging too frequently
train stats after 109824 examples: {'rewards_train/chosen': '0.26655', 'rewards_train/rejected': '-5.6407', 'rewards_train/margins': '5.9297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2359', 'examples_per_second': '5.5887', 'grad_norm': '4.0312', 'counters/examples': 109824, 'counters/updates': 6864}
skipping logging after 109840 examples to avoid logging too frequently
skipping logging after 109856 examples to avoid logging too frequently
skipping logging after 109872 examples to avoid logging too frequently
train stats after 109888 examples: {'rewards_train/chosen': '0.34531', 'rewards_train/rejected': '-5.1053', 'rewards_train/margins': '5.5938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22357', 'examples_per_second': '4.7553', 'grad_norm': '4.125', 'counters/examples': 109888, 'counters/updates': 6868}
skipping logging after 109904 examples to avoid logging too frequently
skipping logging after 109920 examples to avoid logging too frequently
skipping logging after 109936 examples to avoid logging too frequently
train stats after 109952 examples: {'rewards_train/chosen': '0.15989', 'rewards_train/rejected': '-5.269', 'rewards_train/margins': '5.5391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26416', 'examples_per_second': '6.5382', 'grad_norm': '5.3438', 'counters/examples': 109952, 'counters/updates': 6872}
skipping logging after 109968 examples to avoid logging too frequently
skipping logging after 109984 examples to avoid logging too frequently
skipping logging after 110000 examples to avoid logging too frequently
train stats after 110016 examples: {'rewards_train/chosen': '0.6668', 'rewards_train/rejected': '-4.8393', 'rewards_train/margins': '5.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24768', 'examples_per_second': '4.5748', 'grad_norm': '4.2812', 'counters/examples': 110016, 'counters/updates': 6876}
skipping logging after 110032 examples to avoid logging too frequently
skipping logging after 110048 examples to avoid logging too frequently
skipping logging after 110064 examples to avoid logging too frequently
train stats after 110080 examples: {'rewards_train/chosen': '0.5519', 'rewards_train/rejected': '-5.8389', 'rewards_train/margins': '6.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24982', 'examples_per_second': '4.8607', 'grad_norm': '4.6875', 'counters/examples': 110080, 'counters/updates': 6880}
skipping logging after 110096 examples to avoid logging too frequently
skipping logging after 110112 examples to avoid logging too frequently
skipping logging after 110128 examples to avoid logging too frequently
train stats after 110144 examples: {'rewards_train/chosen': '0.53892', 'rewards_train/rejected': '-4.9946', 'rewards_train/margins': '5.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20837', 'examples_per_second': '4.7249', 'grad_norm': '5.6875', 'counters/examples': 110144, 'counters/updates': 6884}
skipping logging after 110160 examples to avoid logging too frequently
skipping logging after 110176 examples to avoid logging too frequently
skipping logging after 110192 examples to avoid logging too frequently
train stats after 110208 examples: {'rewards_train/chosen': '0.03798', 'rewards_train/rejected': '-5.3752', 'rewards_train/margins': '5.1523', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26465', 'examples_per_second': '3.9776', 'grad_norm': '5.0625', 'counters/examples': 110208, 'counters/updates': 6888}
skipping logging after 110224 examples to avoid logging too frequently
skipping logging after 110240 examples to avoid logging too frequently
skipping logging after 110256 examples to avoid logging too frequently
train stats after 110272 examples: {'rewards_train/chosen': '0.45446', 'rewards_train/rejected': '-5.3141', 'rewards_train/margins': '5.7109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21826', 'examples_per_second': '5.9214', 'grad_norm': '4.7812', 'counters/examples': 110272, 'counters/updates': 6892}
skipping logging after 110288 examples to avoid logging too frequently
skipping logging after 110304 examples to avoid logging too frequently
skipping logging after 110320 examples to avoid logging too frequently
train stats after 110336 examples: {'rewards_train/chosen': '0.49268', 'rewards_train/rejected': '-4.918', 'rewards_train/margins': '5.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23004', 'examples_per_second': '5.2182', 'grad_norm': '4.375', 'counters/examples': 110336, 'counters/updates': 6896}
skipping logging after 110352 examples to avoid logging too frequently
skipping logging after 110368 examples to avoid logging too frequently
skipping logging after 110384 examples to avoid logging too frequently
train stats after 110400 examples: {'rewards_train/chosen': '0.42919', 'rewards_train/rejected': '-5.3471', 'rewards_train/margins': '5.7656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23657', 'examples_per_second': '4.9562', 'grad_norm': '4.8438', 'counters/examples': 110400, 'counters/updates': 6900}
skipping logging after 110416 examples to avoid logging too frequently
skipping logging after 110432 examples to avoid logging too frequently
skipping logging after 110448 examples to avoid logging too frequently
train stats after 110464 examples: {'rewards_train/chosen': '0.35513', 'rewards_train/rejected': '-6.22', 'rewards_train/margins': '6.6484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25787', 'examples_per_second': '3.9451', 'grad_norm': '5.5312', 'counters/examples': 110464, 'counters/updates': 6904}
skipping logging after 110480 examples to avoid logging too frequently
skipping logging after 110496 examples to avoid logging too frequently
skipping logging after 110512 examples to avoid logging too frequently
train stats after 110528 examples: {'rewards_train/chosen': '0.5856', 'rewards_train/rejected': '-5.2154', 'rewards_train/margins': '5.9141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.258', 'examples_per_second': '5.4174', 'grad_norm': '4.9062', 'counters/examples': 110528, 'counters/updates': 6908}
skipping logging after 110544 examples to avoid logging too frequently
skipping logging after 110560 examples to avoid logging too frequently
skipping logging after 110576 examples to avoid logging too frequently
train stats after 110592 examples: {'rewards_train/chosen': '0.23018', 'rewards_train/rejected': '-5.8714', 'rewards_train/margins': '6.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22595', 'examples_per_second': '5.6151', 'grad_norm': '5.1875', 'counters/examples': 110592, 'counters/updates': 6912}
skipping logging after 110608 examples to avoid logging too frequently
skipping logging after 110624 examples to avoid logging too frequently
skipping logging after 110640 examples to avoid logging too frequently
train stats after 110656 examples: {'rewards_train/chosen': '0.056798', 'rewards_train/rejected': '-5.7149', 'rewards_train/margins': '5.7031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25629', 'examples_per_second': '5.0447', 'grad_norm': '5.5312', 'counters/examples': 110656, 'counters/updates': 6916}
skipping logging after 110672 examples to avoid logging too frequently
skipping logging after 110688 examples to avoid logging too frequently
skipping logging after 110704 examples to avoid logging too frequently
train stats after 110720 examples: {'rewards_train/chosen': '0.46804', 'rewards_train/rejected': '-6.4323', 'rewards_train/margins': '6.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17969', 'examples_per_second': '5.2883', 'grad_norm': '4.4062', 'counters/examples': 110720, 'counters/updates': 6920}
skipping logging after 110736 examples to avoid logging too frequently
skipping logging after 110752 examples to avoid logging too frequently
skipping logging after 110768 examples to avoid logging too frequently
train stats after 110784 examples: {'rewards_train/chosen': '0.51314', 'rewards_train/rejected': '-5.2796', 'rewards_train/margins': '5.6992', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24432', 'examples_per_second': '5.6927', 'grad_norm': '5.2188', 'counters/examples': 110784, 'counters/updates': 6924}
skipping logging after 110800 examples to avoid logging too frequently
skipping logging after 110816 examples to avoid logging too frequently
skipping logging after 110832 examples to avoid logging too frequently
train stats after 110848 examples: {'rewards_train/chosen': '0.24637', 'rewards_train/rejected': '-4.6123', 'rewards_train/margins': '4.457', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26721', 'examples_per_second': '5.2805', 'grad_norm': '5.5625', 'counters/examples': 110848, 'counters/updates': 6928}
skipping logging after 110864 examples to avoid logging too frequently
skipping logging after 110880 examples to avoid logging too frequently
skipping logging after 110896 examples to avoid logging too frequently
train stats after 110912 examples: {'rewards_train/chosen': '0.61635', 'rewards_train/rejected': '-7.004', 'rewards_train/margins': '7.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22687', 'examples_per_second': '5.7169', 'grad_norm': '4.9062', 'counters/examples': 110912, 'counters/updates': 6932}
skipping logging after 110928 examples to avoid logging too frequently
skipping logging after 110944 examples to avoid logging too frequently
skipping logging after 110960 examples to avoid logging too frequently
train stats after 110976 examples: {'rewards_train/chosen': '0.58196', 'rewards_train/rejected': '-4.8888', 'rewards_train/margins': '5.4414', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26489', 'examples_per_second': '6.1802', 'grad_norm': '5', 'counters/examples': 110976, 'counters/updates': 6936}
skipping logging after 110992 examples to avoid logging too frequently
skipping logging after 111008 examples to avoid logging too frequently
skipping logging after 111024 examples to avoid logging too frequently
train stats after 111040 examples: {'rewards_train/chosen': '0.70034', 'rewards_train/rejected': '-5.3786', 'rewards_train/margins': '6.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.16968', 'examples_per_second': '4.6713', 'grad_norm': '4.7188', 'counters/examples': 111040, 'counters/updates': 6940}
skipping logging after 111056 examples to avoid logging too frequently
skipping logging after 111072 examples to avoid logging too frequently
skipping logging after 111088 examples to avoid logging too frequently
train stats after 111104 examples: {'rewards_train/chosen': '0.45783', 'rewards_train/rejected': '-7.5512', 'rewards_train/margins': '7.9297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2403', 'examples_per_second': '5.7797', 'grad_norm': '5.5312', 'counters/examples': 111104, 'counters/updates': 6944}
skipping logging after 111120 examples to avoid logging too frequently
skipping logging after 111136 examples to avoid logging too frequently
skipping logging after 111152 examples to avoid logging too frequently
train stats after 111168 examples: {'rewards_train/chosen': '0.54008', 'rewards_train/rejected': '-5.9172', 'rewards_train/margins': '6.3281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25494', 'examples_per_second': '4.9092', 'grad_norm': '5.3438', 'counters/examples': 111168, 'counters/updates': 6948}
skipping logging after 111184 examples to avoid logging too frequently
skipping logging after 111200 examples to avoid logging too frequently
skipping logging after 111216 examples to avoid logging too frequently
train stats after 111232 examples: {'rewards_train/chosen': '0.44626', 'rewards_train/rejected': '-3.9619', 'rewards_train/margins': '5.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27997', 'examples_per_second': '7.0005', 'grad_norm': '5.75', 'counters/examples': 111232, 'counters/updates': 6952}
skipping logging after 111248 examples to avoid logging too frequently
skipping logging after 111264 examples to avoid logging too frequently
skipping logging after 111280 examples to avoid logging too frequently
train stats after 111296 examples: {'rewards_train/chosen': '0.27588', 'rewards_train/rejected': '-6.8827', 'rewards_train/margins': '7.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24072', 'examples_per_second': '4.7184', 'grad_norm': '6.0938', 'counters/examples': 111296, 'counters/updates': 6956}
skipping logging after 111312 examples to avoid logging too frequently
skipping logging after 111328 examples to avoid logging too frequently
skipping logging after 111344 examples to avoid logging too frequently
train stats after 111360 examples: {'rewards_train/chosen': '0.6235', 'rewards_train/rejected': '-6.2564', 'rewards_train/margins': '6.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23669', 'examples_per_second': '5.8214', 'grad_norm': '4.375', 'counters/examples': 111360, 'counters/updates': 6960}
skipping logging after 111376 examples to avoid logging too frequently
skipping logging after 111392 examples to avoid logging too frequently
skipping logging after 111408 examples to avoid logging too frequently
train stats after 111424 examples: {'rewards_train/chosen': '0.2583', 'rewards_train/rejected': '-5.8115', 'rewards_train/margins': '6.0234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21539', 'examples_per_second': '5.581', 'grad_norm': '5.9375', 'counters/examples': 111424, 'counters/updates': 6964}
skipping logging after 111440 examples to avoid logging too frequently
skipping logging after 111456 examples to avoid logging too frequently
skipping logging after 111472 examples to avoid logging too frequently
train stats after 111488 examples: {'rewards_train/chosen': '0.41919', 'rewards_train/rejected': '-5.4729', 'rewards_train/margins': '5.8906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25891', 'examples_per_second': '5.2801', 'grad_norm': '5.2812', 'counters/examples': 111488, 'counters/updates': 6968}
skipping logging after 111504 examples to avoid logging too frequently
skipping logging after 111520 examples to avoid logging too frequently
skipping logging after 111536 examples to avoid logging too frequently
train stats after 111552 examples: {'rewards_train/chosen': '0.39999', 'rewards_train/rejected': '-6.2356', 'rewards_train/margins': '6.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24554', 'examples_per_second': '5.8046', 'grad_norm': '4.6562', 'counters/examples': 111552, 'counters/updates': 6972}
skipping logging after 111568 examples to avoid logging too frequently
skipping logging after 111584 examples to avoid logging too frequently
skipping logging after 111600 examples to avoid logging too frequently
train stats after 111616 examples: {'rewards_train/chosen': '0.21099', 'rewards_train/rejected': '-6.0962', 'rewards_train/margins': '6.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24884', 'examples_per_second': '5.4901', 'grad_norm': '4.6875', 'counters/examples': 111616, 'counters/updates': 6976}
skipping logging after 111632 examples to avoid logging too frequently
skipping logging after 111648 examples to avoid logging too frequently
skipping logging after 111664 examples to avoid logging too frequently
train stats after 111680 examples: {'rewards_train/chosen': '0.66023', 'rewards_train/rejected': '-5.2626', 'rewards_train/margins': '5.9883', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22406', 'examples_per_second': '5.2789', 'grad_norm': '4.5625', 'counters/examples': 111680, 'counters/updates': 6980}
skipping logging after 111696 examples to avoid logging too frequently
skipping logging after 111712 examples to avoid logging too frequently
skipping logging after 111728 examples to avoid logging too frequently
train stats after 111744 examples: {'rewards_train/chosen': '0.00035881', 'rewards_train/rejected': '-6.0674', 'rewards_train/margins': '6.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2337', 'examples_per_second': '4.9554', 'grad_norm': '4.4688', 'counters/examples': 111744, 'counters/updates': 6984}
skipping logging after 111760 examples to avoid logging too frequently
skipping logging after 111776 examples to avoid logging too frequently
skipping logging after 111792 examples to avoid logging too frequently
train stats after 111808 examples: {'rewards_train/chosen': '0.31869', 'rewards_train/rejected': '-5.6296', 'rewards_train/margins': '5.6836', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27423', 'examples_per_second': '4.9977', 'grad_norm': '5.375', 'counters/examples': 111808, 'counters/updates': 6988}
skipping logging after 111824 examples to avoid logging too frequently
skipping logging after 111840 examples to avoid logging too frequently
skipping logging after 111856 examples to avoid logging too frequently
train stats after 111872 examples: {'rewards_train/chosen': '0.43201', 'rewards_train/rejected': '-6.5312', 'rewards_train/margins': '7.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2334', 'examples_per_second': '5.1814', 'grad_norm': '5.0312', 'counters/examples': 111872, 'counters/updates': 6992}
skipping logging after 111888 examples to avoid logging too frequently
skipping logging after 111904 examples to avoid logging too frequently
skipping logging after 111920 examples to avoid logging too frequently
train stats after 111936 examples: {'rewards_train/chosen': '0.6755', 'rewards_train/rejected': '-5.0248', 'rewards_train/margins': '5.5469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2428', 'examples_per_second': '4.6454', 'grad_norm': '5.8438', 'counters/examples': 111936, 'counters/updates': 6996}
skipping logging after 111952 examples to avoid logging too frequently
skipping logging after 111968 examples to avoid logging too frequently
skipping logging after 111984 examples to avoid logging too frequently
train stats after 112000 examples: {'rewards_train/chosen': '0.3327', 'rewards_train/rejected': '-7.5519', 'rewards_train/margins': '7.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23248', 'examples_per_second': '5.7455', 'grad_norm': '4.6562', 'counters/examples': 112000, 'counters/updates': 7000}
Running evaluation after 112000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.26s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.17s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:40,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.65s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.47s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:33,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.51s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:33,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.40s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:30,  1.47s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:21<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:13,  1.44s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.31s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]
eval after 112000: {'rewards_eval/chosen': '-5.5904', 'rewards_eval/rejected': '-5.9521', 'rewards_eval/margins': '0.22656', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46479'}
skipping logging after 112016 examples to avoid logging too frequently
skipping logging after 112032 examples to avoid logging too frequently
skipping logging after 112048 examples to avoid logging too frequently
train stats after 112064 examples: {'rewards_train/chosen': '0.24777', 'rewards_train/rejected': '-6.5377', 'rewards_train/margins': '6.5391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23175', 'examples_per_second': '4.1294', 'grad_norm': '6', 'counters/examples': 112064, 'counters/updates': 7004}
skipping logging after 112080 examples to avoid logging too frequently
skipping logging after 112096 examples to avoid logging too frequently
skipping logging after 112112 examples to avoid logging too frequently
train stats after 112128 examples: {'rewards_train/chosen': '0.62107', 'rewards_train/rejected': '-6.1001', 'rewards_train/margins': '6.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22052', 'examples_per_second': '4.287', 'grad_norm': '3.9688', 'counters/examples': 112128, 'counters/updates': 7008}
skipping logging after 112144 examples to avoid logging too frequently
skipping logging after 112160 examples to avoid logging too frequently
skipping logging after 112176 examples to avoid logging too frequently
train stats after 112192 examples: {'rewards_train/chosen': '0.58906', 'rewards_train/rejected': '-6.102', 'rewards_train/margins': '6.8672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17987', 'examples_per_second': '5.1663', 'grad_norm': '3.8438', 'counters/examples': 112192, 'counters/updates': 7012}
skipping logging after 112208 examples to avoid logging too frequently
skipping logging after 112224 examples to avoid logging too frequently
skipping logging after 112240 examples to avoid logging too frequently
train stats after 112256 examples: {'rewards_train/chosen': '0.34142', 'rewards_train/rejected': '-6.1946', 'rewards_train/margins': '6.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21021', 'examples_per_second': '5.1566', 'grad_norm': '4.2188', 'counters/examples': 112256, 'counters/updates': 7016}
skipping logging after 112272 examples to avoid logging too frequently
skipping logging after 112288 examples to avoid logging too frequently
skipping logging after 112304 examples to avoid logging too frequently
train stats after 112320 examples: {'rewards_train/chosen': '0.30149', 'rewards_train/rejected': '-5.9629', 'rewards_train/margins': '6.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22864', 'examples_per_second': '5.8635', 'grad_norm': '5.1875', 'counters/examples': 112320, 'counters/updates': 7020}
skipping logging after 112336 examples to avoid logging too frequently
skipping logging after 112352 examples to avoid logging too frequently
skipping logging after 112368 examples to avoid logging too frequently
train stats after 112384 examples: {'rewards_train/chosen': '0.45101', 'rewards_train/rejected': '-7.1619', 'rewards_train/margins': '7.7031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20911', 'examples_per_second': '4.9376', 'grad_norm': '4.6562', 'counters/examples': 112384, 'counters/updates': 7024}
skipping logging after 112400 examples to avoid logging too frequently
skipping logging after 112416 examples to avoid logging too frequently
skipping logging after 112432 examples to avoid logging too frequently
train stats after 112448 examples: {'rewards_train/chosen': '0.43515', 'rewards_train/rejected': '-5.7646', 'rewards_train/margins': '6.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22913', 'examples_per_second': '5.0428', 'grad_norm': '6.5312', 'counters/examples': 112448, 'counters/updates': 7028}
skipping logging after 112464 examples to avoid logging too frequently
skipping logging after 112480 examples to avoid logging too frequently
skipping logging after 112496 examples to avoid logging too frequently
train stats after 112512 examples: {'rewards_train/chosen': '0.4094', 'rewards_train/rejected': '-5.6269', 'rewards_train/margins': '6.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26086', 'examples_per_second': '4.3002', 'grad_norm': '4.375', 'counters/examples': 112512, 'counters/updates': 7032}
skipping logging after 112528 examples to avoid logging too frequently
skipping logging after 112544 examples to avoid logging too frequently
skipping logging after 112560 examples to avoid logging too frequently
train stats after 112576 examples: {'rewards_train/chosen': '0.40827', 'rewards_train/rejected': '-5.244', 'rewards_train/margins': '6.1953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29871', 'examples_per_second': '4.6857', 'grad_norm': '4.5938', 'counters/examples': 112576, 'counters/updates': 7036}
skipping logging after 112592 examples to avoid logging too frequently
skipping logging after 112608 examples to avoid logging too frequently
skipping logging after 112624 examples to avoid logging too frequently
train stats after 112640 examples: {'rewards_train/chosen': '0.78801', 'rewards_train/rejected': '-5.0719', 'rewards_train/margins': '5.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2113', 'examples_per_second': '5.6542', 'grad_norm': '5.125', 'counters/examples': 112640, 'counters/updates': 7040}
skipping logging after 112656 examples to avoid logging too frequently
skipping logging after 112672 examples to avoid logging too frequently
skipping logging after 112688 examples to avoid logging too frequently
train stats after 112704 examples: {'rewards_train/chosen': '0.21264', 'rewards_train/rejected': '-4.9831', 'rewards_train/margins': '5.4844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26672', 'examples_per_second': '4.7192', 'grad_norm': '5.3438', 'counters/examples': 112704, 'counters/updates': 7044}
skipping logging after 112720 examples to avoid logging too frequently
skipping logging after 112736 examples to avoid logging too frequently
skipping logging after 112752 examples to avoid logging too frequently
train stats after 112768 examples: {'rewards_train/chosen': '0.54146', 'rewards_train/rejected': '-5.8384', 'rewards_train/margins': '6.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18835', 'examples_per_second': '5.97', 'grad_norm': '4.625', 'counters/examples': 112768, 'counters/updates': 7048}
skipping logging after 112784 examples to avoid logging too frequently
skipping logging after 112800 examples to avoid logging too frequently
skipping logging after 112816 examples to avoid logging too frequently
train stats after 112832 examples: {'rewards_train/chosen': '0.11204', 'rewards_train/rejected': '-6.6807', 'rewards_train/margins': '6.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23694', 'examples_per_second': '5.6759', 'grad_norm': '4.9062', 'counters/examples': 112832, 'counters/updates': 7052}
skipping logging after 112848 examples to avoid logging too frequently
skipping logging after 112864 examples to avoid logging too frequently
skipping logging after 112880 examples to avoid logging too frequently
train stats after 112896 examples: {'rewards_train/chosen': '0.23928', 'rewards_train/rejected': '-6.3417', 'rewards_train/margins': '6.332', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20758', 'examples_per_second': '5.2188', 'grad_norm': '4.1875', 'counters/examples': 112896, 'counters/updates': 7056}
skipping logging after 112912 examples to avoid logging too frequently
skipping logging after 112928 examples to avoid logging too frequently
skipping logging after 112944 examples to avoid logging too frequently
train stats after 112960 examples: {'rewards_train/chosen': '0.45455', 'rewards_train/rejected': '-7.3199', 'rewards_train/margins': '7.8672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18945', 'examples_per_second': '4.3928', 'grad_norm': '4.6875', 'counters/examples': 112960, 'counters/updates': 7060}
skipping logging after 112976 examples to avoid logging too frequently
skipping logging after 112992 examples to avoid logging too frequently
skipping logging after 113008 examples to avoid logging too frequently
train stats after 113024 examples: {'rewards_train/chosen': '0.51602', 'rewards_train/rejected': '-5.9883', 'rewards_train/margins': '6.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20544', 'examples_per_second': '5.1132', 'grad_norm': '4.3125', 'counters/examples': 113024, 'counters/updates': 7064}
skipping logging after 113040 examples to avoid logging too frequently
skipping logging after 113056 examples to avoid logging too frequently
skipping logging after 113072 examples to avoid logging too frequently
train stats after 113088 examples: {'rewards_train/chosen': '0.37144', 'rewards_train/rejected': '-5.4139', 'rewards_train/margins': '5.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20624', 'examples_per_second': '5.8697', 'grad_norm': '4.7188', 'counters/examples': 113088, 'counters/updates': 7068}
skipping logging after 113104 examples to avoid logging too frequently
skipping logging after 113120 examples to avoid logging too frequently
skipping logging after 113136 examples to avoid logging too frequently
train stats after 113152 examples: {'rewards_train/chosen': '0.36362', 'rewards_train/rejected': '-7.2914', 'rewards_train/margins': '7.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19012', 'examples_per_second': '4.1994', 'grad_norm': '4.5938', 'counters/examples': 113152, 'counters/updates': 7072}
skipping logging after 113168 examples to avoid logging too frequently
skipping logging after 113184 examples to avoid logging too frequently
skipping logging after 113200 examples to avoid logging too frequently
train stats after 113216 examples: {'rewards_train/chosen': '0.31055', 'rewards_train/rejected': '-6.6053', 'rewards_train/margins': '6.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23199', 'examples_per_second': '4.4019', 'grad_norm': '5.4375', 'counters/examples': 113216, 'counters/updates': 7076}
skipping logging after 113232 examples to avoid logging too frequently
skipping logging after 113248 examples to avoid logging too frequently
skipping logging after 113264 examples to avoid logging too frequently
train stats after 113280 examples: {'rewards_train/chosen': '0.13822', 'rewards_train/rejected': '-6.0554', 'rewards_train/margins': '6.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25116', 'examples_per_second': '4.6982', 'grad_norm': '5.1562', 'counters/examples': 113280, 'counters/updates': 7080}
skipping logging after 113296 examples to avoid logging too frequently
skipping logging after 113312 examples to avoid logging too frequently
skipping logging after 113328 examples to avoid logging too frequently
train stats after 113344 examples: {'rewards_train/chosen': '0.18599', 'rewards_train/rejected': '-4.8666', 'rewards_train/margins': '4.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30078', 'examples_per_second': '5.9561', 'grad_norm': '5.125', 'counters/examples': 113344, 'counters/updates': 7084}
skipping logging after 113360 examples to avoid logging too frequently
skipping logging after 113376 examples to avoid logging too frequently
skipping logging after 113392 examples to avoid logging too frequently
train stats after 113408 examples: {'rewards_train/chosen': '0.33203', 'rewards_train/rejected': '-4.7822', 'rewards_train/margins': '5.043', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2251', 'examples_per_second': '5.5371', 'grad_norm': '4.9062', 'counters/examples': 113408, 'counters/updates': 7088}
skipping logging after 113424 examples to avoid logging too frequently
skipping logging after 113440 examples to avoid logging too frequently
skipping logging after 113456 examples to avoid logging too frequently
train stats after 113472 examples: {'rewards_train/chosen': '0.43297', 'rewards_train/rejected': '-6.2584', 'rewards_train/margins': '6.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24103', 'examples_per_second': '5.0415', 'grad_norm': '4.5', 'counters/examples': 113472, 'counters/updates': 7092}
skipping logging after 113488 examples to avoid logging too frequently
skipping logging after 113504 examples to avoid logging too frequently
skipping logging after 113520 examples to avoid logging too frequently
train stats after 113536 examples: {'rewards_train/chosen': '0.39001', 'rewards_train/rejected': '-4.2086', 'rewards_train/margins': '4.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24701', 'examples_per_second': '5.2285', 'grad_norm': '5.5312', 'counters/examples': 113536, 'counters/updates': 7096}
skipping logging after 113552 examples to avoid logging too frequently
skipping logging after 113568 examples to avoid logging too frequently
skipping logging after 113584 examples to avoid logging too frequently
train stats after 113600 examples: {'rewards_train/chosen': '0.51241', 'rewards_train/rejected': '-5.9875', 'rewards_train/margins': '6.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20117', 'examples_per_second': '5.6279', 'grad_norm': '4.8125', 'counters/examples': 113600, 'counters/updates': 7100}
skipping logging after 113616 examples to avoid logging too frequently
skipping logging after 113632 examples to avoid logging too frequently
skipping logging after 113648 examples to avoid logging too frequently
train stats after 113664 examples: {'rewards_train/chosen': '0.2848', 'rewards_train/rejected': '-5.1104', 'rewards_train/margins': '5.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26672', 'examples_per_second': '5.1739', 'grad_norm': '5.2812', 'counters/examples': 113664, 'counters/updates': 7104}
skipping logging after 113680 examples to avoid logging too frequently
skipping logging after 113696 examples to avoid logging too frequently
skipping logging after 113712 examples to avoid logging too frequently
train stats after 113728 examples: {'rewards_train/chosen': '0.32589', 'rewards_train/rejected': '-6.5054', 'rewards_train/margins': '6.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24524', 'examples_per_second': '4.5606', 'grad_norm': '5.3438', 'counters/examples': 113728, 'counters/updates': 7108}
skipping logging after 113744 examples to avoid logging too frequently
skipping logging after 113760 examples to avoid logging too frequently
skipping logging after 113776 examples to avoid logging too frequently
train stats after 113792 examples: {'rewards_train/chosen': '0.24205', 'rewards_train/rejected': '-5.3113', 'rewards_train/margins': '5.7266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20331', 'examples_per_second': '5.0395', 'grad_norm': '3.9375', 'counters/examples': 113792, 'counters/updates': 7112}
skipping logging after 113808 examples to avoid logging too frequently
skipping logging after 113824 examples to avoid logging too frequently
skipping logging after 113840 examples to avoid logging too frequently
train stats after 113856 examples: {'rewards_train/chosen': '0.60826', 'rewards_train/rejected': '-5.3135', 'rewards_train/margins': '5.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1875', 'examples_per_second': '5.069', 'grad_norm': '4.625', 'counters/examples': 113856, 'counters/updates': 7116}
skipping logging after 113872 examples to avoid logging too frequently
skipping logging after 113888 examples to avoid logging too frequently
skipping logging after 113904 examples to avoid logging too frequently
train stats after 113920 examples: {'rewards_train/chosen': '0.61278', 'rewards_train/rejected': '-6.4676', 'rewards_train/margins': '7.0312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21039', 'examples_per_second': '4.8452', 'grad_norm': '4.625', 'counters/examples': 113920, 'counters/updates': 7120}
skipping logging after 113936 examples to avoid logging too frequently
skipping logging after 113952 examples to avoid logging too frequently
skipping logging after 113968 examples to avoid logging too frequently
train stats after 113984 examples: {'rewards_train/chosen': '0.45284', 'rewards_train/rejected': '-5.5465', 'rewards_train/margins': '5.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26477', 'examples_per_second': '6.2274', 'grad_norm': '5.2188', 'counters/examples': 113984, 'counters/updates': 7124}
skipping logging after 114000 examples to avoid logging too frequently
skipping logging after 114016 examples to avoid logging too frequently
skipping logging after 114032 examples to avoid logging too frequently
train stats after 114048 examples: {'rewards_train/chosen': '0.29843', 'rewards_train/rejected': '-5.8049', 'rewards_train/margins': '5.7812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25977', 'examples_per_second': '5.8324', 'grad_norm': '4.75', 'counters/examples': 114048, 'counters/updates': 7128}
skipping logging after 114064 examples to avoid logging too frequently
skipping logging after 114080 examples to avoid logging too frequently
skipping logging after 114096 examples to avoid logging too frequently
train stats after 114112 examples: {'rewards_train/chosen': '0.56518', 'rewards_train/rejected': '-5.9549', 'rewards_train/margins': '6.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21442', 'examples_per_second': '5.3194', 'grad_norm': '5.1562', 'counters/examples': 114112, 'counters/updates': 7132}
skipping logging after 114128 examples to avoid logging too frequently
skipping logging after 114144 examples to avoid logging too frequently
skipping logging after 114160 examples to avoid logging too frequently
train stats after 114176 examples: {'rewards_train/chosen': '0.45083', 'rewards_train/rejected': '-5.095', 'rewards_train/margins': '5.2266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24902', 'examples_per_second': '4.8514', 'grad_norm': '4.9375', 'counters/examples': 114176, 'counters/updates': 7136}
skipping logging after 114192 examples to avoid logging too frequently
skipping logging after 114208 examples to avoid logging too frequently
skipping logging after 114224 examples to avoid logging too frequently
train stats after 114240 examples: {'rewards_train/chosen': '0.40105', 'rewards_train/rejected': '-5.7482', 'rewards_train/margins': '6.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23395', 'examples_per_second': '5.9825', 'grad_norm': '5.2812', 'counters/examples': 114240, 'counters/updates': 7140}
skipping logging after 114256 examples to avoid logging too frequently
skipping logging after 114272 examples to avoid logging too frequently
skipping logging after 114288 examples to avoid logging too frequently
train stats after 114304 examples: {'rewards_train/chosen': '0.76166', 'rewards_train/rejected': '-6.4914', 'rewards_train/margins': '7.3672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21259', 'examples_per_second': '4.7031', 'grad_norm': '4.8125', 'counters/examples': 114304, 'counters/updates': 7144}
skipping logging after 114320 examples to avoid logging too frequently
skipping logging after 114336 examples to avoid logging too frequently
skipping logging after 114352 examples to avoid logging too frequently
train stats after 114368 examples: {'rewards_train/chosen': '0.92534', 'rewards_train/rejected': '-5.4525', 'rewards_train/margins': '6.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.14276', 'examples_per_second': '4.5556', 'grad_norm': '5.125', 'counters/examples': 114368, 'counters/updates': 7148}
skipping logging after 114384 examples to avoid logging too frequently
skipping logging after 114400 examples to avoid logging too frequently
skipping logging after 114416 examples to avoid logging too frequently
train stats after 114432 examples: {'rewards_train/chosen': '0.58183', 'rewards_train/rejected': '-6.1849', 'rewards_train/margins': '6.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20502', 'examples_per_second': '4.946', 'grad_norm': '4.4688', 'counters/examples': 114432, 'counters/updates': 7152}
skipping logging after 114448 examples to avoid logging too frequently
skipping logging after 114464 examples to avoid logging too frequently
skipping logging after 114480 examples to avoid logging too frequently
train stats after 114496 examples: {'rewards_train/chosen': '0.36809', 'rewards_train/rejected': '-5.2676', 'rewards_train/margins': '5.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22046', 'examples_per_second': '5.515', 'grad_norm': '5.3125', 'counters/examples': 114496, 'counters/updates': 7156}
skipping logging after 114512 examples to avoid logging too frequently
skipping logging after 114528 examples to avoid logging too frequently
skipping logging after 114544 examples to avoid logging too frequently
train stats after 114560 examples: {'rewards_train/chosen': '0.30239', 'rewards_train/rejected': '-5.6499', 'rewards_train/margins': '5.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25409', 'examples_per_second': '6.7874', 'grad_norm': '5.1562', 'counters/examples': 114560, 'counters/updates': 7160}
skipping logging after 114576 examples to avoid logging too frequently
skipping logging after 114592 examples to avoid logging too frequently
skipping logging after 114608 examples to avoid logging too frequently
train stats after 114624 examples: {'rewards_train/chosen': '0.24382', 'rewards_train/rejected': '-6.5545', 'rewards_train/margins': '7.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18463', 'examples_per_second': '6.6844', 'grad_norm': '4.1875', 'counters/examples': 114624, 'counters/updates': 7164}
skipping logging after 114640 examples to avoid logging too frequently
skipping logging after 114656 examples to avoid logging too frequently
skipping logging after 114672 examples to avoid logging too frequently
train stats after 114688 examples: {'rewards_train/chosen': '0.53726', 'rewards_train/rejected': '-7.2544', 'rewards_train/margins': '7.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20135', 'examples_per_second': '5.0982', 'grad_norm': '5.7188', 'counters/examples': 114688, 'counters/updates': 7168}
skipping logging after 114704 examples to avoid logging too frequently
skipping logging after 114720 examples to avoid logging too frequently
skipping logging after 114736 examples to avoid logging too frequently
train stats after 114752 examples: {'rewards_train/chosen': '0.37635', 'rewards_train/rejected': '-5.6575', 'rewards_train/margins': '5.9766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25012', 'examples_per_second': '6.3655', 'grad_norm': '4.9375', 'counters/examples': 114752, 'counters/updates': 7172}
skipping logging after 114768 examples to avoid logging too frequently
skipping logging after 114784 examples to avoid logging too frequently
skipping logging after 114800 examples to avoid logging too frequently
train stats after 114816 examples: {'rewards_train/chosen': '0.42868', 'rewards_train/rejected': '-5.8291', 'rewards_train/margins': '6.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21973', 'examples_per_second': '5.3978', 'grad_norm': '4.9688', 'counters/examples': 114816, 'counters/updates': 7176}
skipping logging after 114832 examples to avoid logging too frequently
skipping logging after 114848 examples to avoid logging too frequently
skipping logging after 114864 examples to avoid logging too frequently
train stats after 114880 examples: {'rewards_train/chosen': '0.69287', 'rewards_train/rejected': '-6.1317', 'rewards_train/margins': '6.9141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24335', 'examples_per_second': '5.0161', 'grad_norm': '4.9688', 'counters/examples': 114880, 'counters/updates': 7180}
skipping logging after 114896 examples to avoid logging too frequently
skipping logging after 114912 examples to avoid logging too frequently
skipping logging after 114928 examples to avoid logging too frequently
train stats after 114944 examples: {'rewards_train/chosen': '0.66097', 'rewards_train/rejected': '-5.5175', 'rewards_train/margins': '6.1172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20227', 'examples_per_second': '4.7586', 'grad_norm': '4.5625', 'counters/examples': 114944, 'counters/updates': 7184}
skipping logging after 114960 examples to avoid logging too frequently
skipping logging after 114976 examples to avoid logging too frequently
skipping logging after 114992 examples to avoid logging too frequently
train stats after 115008 examples: {'rewards_train/chosen': '0.49487', 'rewards_train/rejected': '-6.5078', 'rewards_train/margins': '7.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24585', 'examples_per_second': '6.0145', 'grad_norm': '4.9062', 'counters/examples': 115008, 'counters/updates': 7188}
skipping logging after 115024 examples to avoid logging too frequently
skipping logging after 115040 examples to avoid logging too frequently
skipping logging after 115056 examples to avoid logging too frequently
train stats after 115072 examples: {'rewards_train/chosen': '0.28761', 'rewards_train/rejected': '-5.1301', 'rewards_train/margins': '5.4531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27197', 'examples_per_second': '5.2251', 'grad_norm': '5.4375', 'counters/examples': 115072, 'counters/updates': 7192}
skipping logging after 115088 examples to avoid logging too frequently
skipping logging after 115104 examples to avoid logging too frequently
skipping logging after 115120 examples to avoid logging too frequently
train stats after 115136 examples: {'rewards_train/chosen': '0.099273', 'rewards_train/rejected': '-4.8772', 'rewards_train/margins': '4.9277', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26843', 'examples_per_second': '5.0638', 'grad_norm': '4.8438', 'counters/examples': 115136, 'counters/updates': 7196}
skipping logging after 115152 examples to avoid logging too frequently
skipping logging after 115168 examples to avoid logging too frequently
skipping logging after 115184 examples to avoid logging too frequently
train stats after 115200 examples: {'rewards_train/chosen': '0.28241', 'rewards_train/rejected': '-4.1939', 'rewards_train/margins': '4.6133', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28326', 'examples_per_second': '5.4927', 'grad_norm': '5.7812', 'counters/examples': 115200, 'counters/updates': 7200}
skipping logging after 115216 examples to avoid logging too frequently
skipping logging after 115232 examples to avoid logging too frequently
skipping logging after 115248 examples to avoid logging too frequently
train stats after 115264 examples: {'rewards_train/chosen': '0.49539', 'rewards_train/rejected': '-5.2878', 'rewards_train/margins': '5.7578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2132', 'examples_per_second': '5.3104', 'grad_norm': '5.5625', 'counters/examples': 115264, 'counters/updates': 7204}
skipping logging after 115280 examples to avoid logging too frequently
skipping logging after 115296 examples to avoid logging too frequently
skipping logging after 115312 examples to avoid logging too frequently
train stats after 115328 examples: {'rewards_train/chosen': '0.40551', 'rewards_train/rejected': '-6.334', 'rewards_train/margins': '6.5938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2547', 'examples_per_second': '5.2003', 'grad_norm': '5.25', 'counters/examples': 115328, 'counters/updates': 7208}
skipping logging after 115344 examples to avoid logging too frequently
skipping logging after 115360 examples to avoid logging too frequently
skipping logging after 115376 examples to avoid logging too frequently
train stats after 115392 examples: {'rewards_train/chosen': '0.029394', 'rewards_train/rejected': '-6.4169', 'rewards_train/margins': '6.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26855', 'examples_per_second': '5.0886', 'grad_norm': '6.9062', 'counters/examples': 115392, 'counters/updates': 7212}
skipping logging after 115408 examples to avoid logging too frequently
skipping logging after 115424 examples to avoid logging too frequently
skipping logging after 115440 examples to avoid logging too frequently
train stats after 115456 examples: {'rewards_train/chosen': '0.61022', 'rewards_train/rejected': '-6.6343', 'rewards_train/margins': '7.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2384', 'examples_per_second': '4.8834', 'grad_norm': '4.8438', 'counters/examples': 115456, 'counters/updates': 7216}
skipping logging after 115472 examples to avoid logging too frequently
skipping logging after 115488 examples to avoid logging too frequently
skipping logging after 115504 examples to avoid logging too frequently
train stats after 115520 examples: {'rewards_train/chosen': '0.6113', 'rewards_train/rejected': '-4.4352', 'rewards_train/margins': '5.0352', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26776', 'examples_per_second': '5.1038', 'grad_norm': '4.8438', 'counters/examples': 115520, 'counters/updates': 7220}
skipping logging after 115536 examples to avoid logging too frequently
skipping logging after 115552 examples to avoid logging too frequently
skipping logging after 115568 examples to avoid logging too frequently
train stats after 115584 examples: {'rewards_train/chosen': '0.31777', 'rewards_train/rejected': '-5.2668', 'rewards_train/margins': '5.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24738', 'examples_per_second': '4.3464', 'grad_norm': '4.0625', 'counters/examples': 115584, 'counters/updates': 7224}
skipping logging after 115600 examples to avoid logging too frequently
skipping logging after 115616 examples to avoid logging too frequently
skipping logging after 115632 examples to avoid logging too frequently
train stats after 115648 examples: {'rewards_train/chosen': '0.92551', 'rewards_train/rejected': '-4.9408', 'rewards_train/margins': '5.8906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20581', 'examples_per_second': '5.8906', 'grad_norm': '5.4375', 'counters/examples': 115648, 'counters/updates': 7228}
skipping logging after 115664 examples to avoid logging too frequently
skipping logging after 115680 examples to avoid logging too frequently
skipping logging after 115696 examples to avoid logging too frequently
train stats after 115712 examples: {'rewards_train/chosen': '-0.067298', 'rewards_train/rejected': '-5.9789', 'rewards_train/margins': '5.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25366', 'examples_per_second': '4.8598', 'grad_norm': '5.0625', 'counters/examples': 115712, 'counters/updates': 7232}
skipping logging after 115728 examples to avoid logging too frequently
skipping logging after 115744 examples to avoid logging too frequently
skipping logging after 115760 examples to avoid logging too frequently
train stats after 115776 examples: {'rewards_train/chosen': '0.17565', 'rewards_train/rejected': '-4.7016', 'rewards_train/margins': '4.8203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22443', 'examples_per_second': '5.008', 'grad_norm': '4.5625', 'counters/examples': 115776, 'counters/updates': 7236}
skipping logging after 115792 examples to avoid logging too frequently
skipping logging after 115808 examples to avoid logging too frequently
skipping logging after 115824 examples to avoid logging too frequently
train stats after 115840 examples: {'rewards_train/chosen': '0.68632', 'rewards_train/rejected': '-6.0918', 'rewards_train/margins': '6.8203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20117', 'examples_per_second': '5.2789', 'grad_norm': '4.6562', 'counters/examples': 115840, 'counters/updates': 7240}
skipping logging after 115856 examples to avoid logging too frequently
skipping logging after 115872 examples to avoid logging too frequently
skipping logging after 115888 examples to avoid logging too frequently
train stats after 115904 examples: {'rewards_train/chosen': '0.42227', 'rewards_train/rejected': '-5.1455', 'rewards_train/margins': '5.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25604', 'examples_per_second': '5.4369', 'grad_norm': '5.4375', 'counters/examples': 115904, 'counters/updates': 7244}
skipping logging after 115920 examples to avoid logging too frequently
skipping logging after 115936 examples to avoid logging too frequently
skipping logging after 115952 examples to avoid logging too frequently
train stats after 115968 examples: {'rewards_train/chosen': '0.50127', 'rewards_train/rejected': '-6.005', 'rewards_train/margins': '6.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19659', 'examples_per_second': '4.5422', 'grad_norm': '4.9375', 'counters/examples': 115968, 'counters/updates': 7248}
skipping logging after 115984 examples to avoid logging too frequently
skipping logging after 116000 examples to avoid logging too frequently
Running evaluation after 116000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:45,  1.46s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:40,  1.34s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:35,  1.21s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:40,  1.45s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.67s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.48s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:34,  1.37s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.40s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:30,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.28s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.18s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.31s/it]
eval after 116000: {'rewards_eval/chosen': '-5.434', 'rewards_eval/rejected': '-5.8051', 'rewards_eval/margins': '0.24316', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46542'}
skipping logging after 116016 examples to avoid logging too frequently
train stats after 116032 examples: {'rewards_train/chosen': '0.64199', 'rewards_train/rejected': '-4.8609', 'rewards_train/margins': '5.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20013', 'examples_per_second': '5.5157', 'grad_norm': '4.9375', 'counters/examples': 116032, 'counters/updates': 7252}
skipping logging after 116048 examples to avoid logging too frequently
skipping logging after 116064 examples to avoid logging too frequently
skipping logging after 116080 examples to avoid logging too frequently
train stats after 116096 examples: {'rewards_train/chosen': '0.50491', 'rewards_train/rejected': '-6.826', 'rewards_train/margins': '7.6484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21179', 'examples_per_second': '5.2096', 'grad_norm': '4.4062', 'counters/examples': 116096, 'counters/updates': 7256}
skipping logging after 116112 examples to avoid logging too frequently
skipping logging after 116128 examples to avoid logging too frequently
skipping logging after 116144 examples to avoid logging too frequently
train stats after 116160 examples: {'rewards_train/chosen': '0.25019', 'rewards_train/rejected': '-4.6895', 'rewards_train/margins': '5.0156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25952', 'examples_per_second': '4.4132', 'grad_norm': '4.8125', 'counters/examples': 116160, 'counters/updates': 7260}
skipping logging after 116176 examples to avoid logging too frequently
skipping logging after 116192 examples to avoid logging too frequently
skipping logging after 116208 examples to avoid logging too frequently
train stats after 116224 examples: {'rewards_train/chosen': '0.53101', 'rewards_train/rejected': '-7.1175', 'rewards_train/margins': '7.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22711', 'examples_per_second': '5.4401', 'grad_norm': '4.9688', 'counters/examples': 116224, 'counters/updates': 7264}
skipping logging after 116240 examples to avoid logging too frequently
skipping logging after 116256 examples to avoid logging too frequently
skipping logging after 116272 examples to avoid logging too frequently
train stats after 116288 examples: {'rewards_train/chosen': '0.62703', 'rewards_train/rejected': '-5.2158', 'rewards_train/margins': '5.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20337', 'examples_per_second': '5.2739', 'grad_norm': '5.5938', 'counters/examples': 116288, 'counters/updates': 7268}
skipping logging after 116304 examples to avoid logging too frequently
skipping logging after 116320 examples to avoid logging too frequently
skipping logging after 116336 examples to avoid logging too frequently
train stats after 116352 examples: {'rewards_train/chosen': '0.50837', 'rewards_train/rejected': '-5.6323', 'rewards_train/margins': '6.4844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23346', 'examples_per_second': '4.7363', 'grad_norm': '5.5312', 'counters/examples': 116352, 'counters/updates': 7272}
skipping logging after 116368 examples to avoid logging too frequently
skipping logging after 116384 examples to avoid logging too frequently
skipping logging after 116400 examples to avoid logging too frequently
train stats after 116416 examples: {'rewards_train/chosen': '0.35387', 'rewards_train/rejected': '-5.0461', 'rewards_train/margins': '5.3828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24188', 'examples_per_second': '5.2137', 'grad_norm': '4.625', 'counters/examples': 116416, 'counters/updates': 7276}
skipping logging after 116432 examples to avoid logging too frequently
skipping logging after 116448 examples to avoid logging too frequently
skipping logging after 116464 examples to avoid logging too frequently
train stats after 116480 examples: {'rewards_train/chosen': '0.56338', 'rewards_train/rejected': '-6.0572', 'rewards_train/margins': '6.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18884', 'examples_per_second': '5.6249', 'grad_norm': '3.9375', 'counters/examples': 116480, 'counters/updates': 7280}
skipping logging after 116496 examples to avoid logging too frequently
skipping logging after 116512 examples to avoid logging too frequently
skipping logging after 116528 examples to avoid logging too frequently
train stats after 116544 examples: {'rewards_train/chosen': '0.31413', 'rewards_train/rejected': '-5.7425', 'rewards_train/margins': '5.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20422', 'examples_per_second': '5.7218', 'grad_norm': '4.9375', 'counters/examples': 116544, 'counters/updates': 7284}
skipping logging after 116560 examples to avoid logging too frequently
skipping logging after 116576 examples to avoid logging too frequently
skipping logging after 116592 examples to avoid logging too frequently
train stats after 116608 examples: {'rewards_train/chosen': '0.056787', 'rewards_train/rejected': '-4.4156', 'rewards_train/margins': '4.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28052', 'examples_per_second': '5.0678', 'grad_norm': '5.5', 'counters/examples': 116608, 'counters/updates': 7288}
skipping logging after 116624 examples to avoid logging too frequently
skipping logging after 116640 examples to avoid logging too frequently
skipping logging after 116656 examples to avoid logging too frequently
train stats after 116672 examples: {'rewards_train/chosen': '0.59927', 'rewards_train/rejected': '-4.9104', 'rewards_train/margins': '5.6758', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23755', 'examples_per_second': '5.6573', 'grad_norm': '5.6875', 'counters/examples': 116672, 'counters/updates': 7292}
skipping logging after 116688 examples to avoid logging too frequently
skipping logging after 116704 examples to avoid logging too frequently
skipping logging after 116720 examples to avoid logging too frequently
train stats after 116736 examples: {'rewards_train/chosen': '0.30739', 'rewards_train/rejected': '-7.3579', 'rewards_train/margins': '7.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28973', 'examples_per_second': '5.4032', 'grad_norm': '5.1875', 'counters/examples': 116736, 'counters/updates': 7296}
skipping logging after 116752 examples to avoid logging too frequently
skipping logging after 116768 examples to avoid logging too frequently
skipping logging after 116784 examples to avoid logging too frequently
train stats after 116800 examples: {'rewards_train/chosen': '0.12658', 'rewards_train/rejected': '-3.8254', 'rewards_train/margins': '4.1953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2793', 'examples_per_second': '4.8944', 'grad_norm': '4.8125', 'counters/examples': 116800, 'counters/updates': 7300}
skipping logging after 116816 examples to avoid logging too frequently
skipping logging after 116832 examples to avoid logging too frequently
skipping logging after 116848 examples to avoid logging too frequently
train stats after 116864 examples: {'rewards_train/chosen': '0.61808', 'rewards_train/rejected': '-6.3582', 'rewards_train/margins': '7.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22662', 'examples_per_second': '4.7287', 'grad_norm': '5.375', 'counters/examples': 116864, 'counters/updates': 7304}
skipping logging after 116880 examples to avoid logging too frequently
skipping logging after 116896 examples to avoid logging too frequently
skipping logging after 116912 examples to avoid logging too frequently
train stats after 116928 examples: {'rewards_train/chosen': '0.48031', 'rewards_train/rejected': '-5.8999', 'rewards_train/margins': '6.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22668', 'examples_per_second': '4.5893', 'grad_norm': '4.75', 'counters/examples': 116928, 'counters/updates': 7308}
skipping logging after 116944 examples to avoid logging too frequently
skipping logging after 116960 examples to avoid logging too frequently
skipping logging after 116976 examples to avoid logging too frequently
train stats after 116992 examples: {'rewards_train/chosen': '0.37287', 'rewards_train/rejected': '-5.1268', 'rewards_train/margins': '5.6133', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22601', 'examples_per_second': '5.9526', 'grad_norm': '4.4688', 'counters/examples': 116992, 'counters/updates': 7312}
skipping logging after 117008 examples to avoid logging too frequently
skipping logging after 117024 examples to avoid logging too frequently
skipping logging after 117040 examples to avoid logging too frequently
train stats after 117056 examples: {'rewards_train/chosen': '0.38596', 'rewards_train/rejected': '-5.7058', 'rewards_train/margins': '6.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23676', 'examples_per_second': '5.8453', 'grad_norm': '4.6562', 'counters/examples': 117056, 'counters/updates': 7316}
skipping logging after 117072 examples to avoid logging too frequently
skipping logging after 117088 examples to avoid logging too frequently
skipping logging after 117104 examples to avoid logging too frequently
train stats after 117120 examples: {'rewards_train/chosen': '0.58514', 'rewards_train/rejected': '-6.0634', 'rewards_train/margins': '6.7266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20062', 'examples_per_second': '5.4411', 'grad_norm': '4.4375', 'counters/examples': 117120, 'counters/updates': 7320}
skipping logging after 117136 examples to avoid logging too frequently
skipping logging after 117152 examples to avoid logging too frequently
skipping logging after 117168 examples to avoid logging too frequently
train stats after 117184 examples: {'rewards_train/chosen': '0.71978', 'rewards_train/rejected': '-6.2775', 'rewards_train/margins': '7.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18298', 'examples_per_second': '5.4338', 'grad_norm': '3.9375', 'counters/examples': 117184, 'counters/updates': 7324}
skipping logging after 117200 examples to avoid logging too frequently
skipping logging after 117216 examples to avoid logging too frequently
skipping logging after 117232 examples to avoid logging too frequently
train stats after 117248 examples: {'rewards_train/chosen': '0.61946', 'rewards_train/rejected': '-5.5696', 'rewards_train/margins': '6.4609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23065', 'examples_per_second': '5.6103', 'grad_norm': '5.4062', 'counters/examples': 117248, 'counters/updates': 7328}
skipping logging after 117264 examples to avoid logging too frequently
skipping logging after 117280 examples to avoid logging too frequently
skipping logging after 117296 examples to avoid logging too frequently
train stats after 117312 examples: {'rewards_train/chosen': '0.35486', 'rewards_train/rejected': '-4.4362', 'rewards_train/margins': '4.6875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24323', 'examples_per_second': '5.2869', 'grad_norm': '5.0938', 'counters/examples': 117312, 'counters/updates': 7332}
skipping logging after 117328 examples to avoid logging too frequently
skipping logging after 117344 examples to avoid logging too frequently
skipping logging after 117360 examples to avoid logging too frequently
train stats after 117376 examples: {'rewards_train/chosen': '0.61196', 'rewards_train/rejected': '-6.7119', 'rewards_train/margins': '7.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23376', 'examples_per_second': '4.2744', 'grad_norm': '5.0938', 'counters/examples': 117376, 'counters/updates': 7336}
skipping logging after 117392 examples to avoid logging too frequently
skipping logging after 117408 examples to avoid logging too frequently
skipping logging after 117424 examples to avoid logging too frequently
train stats after 117440 examples: {'rewards_train/chosen': '0.34629', 'rewards_train/rejected': '-4.8493', 'rewards_train/margins': '5.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22473', 'examples_per_second': '5.787', 'grad_norm': '5.2188', 'counters/examples': 117440, 'counters/updates': 7340}
skipping logging after 117456 examples to avoid logging too frequently
skipping logging after 117472 examples to avoid logging too frequently
skipping logging after 117488 examples to avoid logging too frequently
train stats after 117504 examples: {'rewards_train/chosen': '0.49935', 'rewards_train/rejected': '-5.5651', 'rewards_train/margins': '6.125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20001', 'examples_per_second': '5.1112', 'grad_norm': '6.2812', 'counters/examples': 117504, 'counters/updates': 7344}
skipping logging after 117520 examples to avoid logging too frequently
skipping logging after 117536 examples to avoid logging too frequently
skipping logging after 117552 examples to avoid logging too frequently
train stats after 117568 examples: {'rewards_train/chosen': '0.29321', 'rewards_train/rejected': '-5.3102', 'rewards_train/margins': '5.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25372', 'examples_per_second': '5.574', 'grad_norm': '5.625', 'counters/examples': 117568, 'counters/updates': 7348}
skipping logging after 117584 examples to avoid logging too frequently
skipping logging after 117600 examples to avoid logging too frequently
skipping logging after 117616 examples to avoid logging too frequently
train stats after 117632 examples: {'rewards_train/chosen': '0.097478', 'rewards_train/rejected': '-6.2365', 'rewards_train/margins': '6.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2569', 'examples_per_second': '5.0962', 'grad_norm': '4.9062', 'counters/examples': 117632, 'counters/updates': 7352}
skipping logging after 117648 examples to avoid logging too frequently
skipping logging after 117664 examples to avoid logging too frequently
skipping logging after 117680 examples to avoid logging too frequently
train stats after 117696 examples: {'rewards_train/chosen': '0.39679', 'rewards_train/rejected': '-6.1363', 'rewards_train/margins': '6.5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26764', 'examples_per_second': '4.645', 'grad_norm': '5.2188', 'counters/examples': 117696, 'counters/updates': 7356}
skipping logging after 117712 examples to avoid logging too frequently
skipping logging after 117728 examples to avoid logging too frequently
skipping logging after 117744 examples to avoid logging too frequently
train stats after 117760 examples: {'rewards_train/chosen': '0.31214', 'rewards_train/rejected': '-5.9285', 'rewards_train/margins': '6.1016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25824', 'examples_per_second': '5.0821', 'grad_norm': '4.4375', 'counters/examples': 117760, 'counters/updates': 7360}
skipping logging after 117776 examples to avoid logging too frequently
skipping logging after 117792 examples to avoid logging too frequently
skipping logging after 117808 examples to avoid logging too frequently
train stats after 117824 examples: {'rewards_train/chosen': '0.39672', 'rewards_train/rejected': '-3.9255', 'rewards_train/margins': '4.3789', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24353', 'examples_per_second': '4.9638', 'grad_norm': '5.8438', 'counters/examples': 117824, 'counters/updates': 7364}
skipping logging after 117840 examples to avoid logging too frequently
skipping logging after 117856 examples to avoid logging too frequently
skipping logging after 117872 examples to avoid logging too frequently
train stats after 117888 examples: {'rewards_train/chosen': '0.11779', 'rewards_train/rejected': '-5.1545', 'rewards_train/margins': '5.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26129', 'examples_per_second': '4.6633', 'grad_norm': '5.25', 'counters/examples': 117888, 'counters/updates': 7368}
skipping logging after 117904 examples to avoid logging too frequently
skipping logging after 117920 examples to avoid logging too frequently
skipping logging after 117936 examples to avoid logging too frequently
train stats after 117952 examples: {'rewards_train/chosen': '0.27575', 'rewards_train/rejected': '-3.8542', 'rewards_train/margins': '4.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22974', 'examples_per_second': '6.1167', 'grad_norm': '4.9688', 'counters/examples': 117952, 'counters/updates': 7372}
skipping logging after 117968 examples to avoid logging too frequently
skipping logging after 117984 examples to avoid logging too frequently
skipping logging after 118000 examples to avoid logging too frequently
train stats after 118016 examples: {'rewards_train/chosen': '0.19314', 'rewards_train/rejected': '-6.323', 'rewards_train/margins': '6.4727', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19629', 'examples_per_second': '4.6991', 'grad_norm': '5.375', 'counters/examples': 118016, 'counters/updates': 7376}
skipping logging after 118032 examples to avoid logging too frequently
skipping logging after 118048 examples to avoid logging too frequently
skipping logging after 118064 examples to avoid logging too frequently
train stats after 118080 examples: {'rewards_train/chosen': '0.42406', 'rewards_train/rejected': '-6.3262', 'rewards_train/margins': '6.8125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20703', 'examples_per_second': '5.1859', 'grad_norm': '4.6875', 'counters/examples': 118080, 'counters/updates': 7380}
skipping logging after 118096 examples to avoid logging too frequently
skipping logging after 118112 examples to avoid logging too frequently
skipping logging after 118128 examples to avoid logging too frequently
train stats after 118144 examples: {'rewards_train/chosen': '0.41247', 'rewards_train/rejected': '-6.9459', 'rewards_train/margins': '7.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24475', 'examples_per_second': '4.2587', 'grad_norm': '4.3125', 'counters/examples': 118144, 'counters/updates': 7384}
skipping logging after 118160 examples to avoid logging too frequently
skipping logging after 118176 examples to avoid logging too frequently
skipping logging after 118192 examples to avoid logging too frequently
train stats after 118208 examples: {'rewards_train/chosen': '0.53131', 'rewards_train/rejected': '-7.2025', 'rewards_train/margins': '7.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1756', 'examples_per_second': '4.9912', 'grad_norm': '4.7188', 'counters/examples': 118208, 'counters/updates': 7388}
skipping logging after 118224 examples to avoid logging too frequently
skipping logging after 118240 examples to avoid logging too frequently
skipping logging after 118256 examples to avoid logging too frequently
train stats after 118272 examples: {'rewards_train/chosen': '0.073063', 'rewards_train/rejected': '-5.8869', 'rewards_train/margins': '6.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26044', 'examples_per_second': '5.9994', 'grad_norm': '4.375', 'counters/examples': 118272, 'counters/updates': 7392}
skipping logging after 118288 examples to avoid logging too frequently
skipping logging after 118304 examples to avoid logging too frequently
skipping logging after 118320 examples to avoid logging too frequently
train stats after 118336 examples: {'rewards_train/chosen': '-0.047856', 'rewards_train/rejected': '-5.499', 'rewards_train/margins': '5.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23682', 'examples_per_second': '5.0491', 'grad_norm': '5.0625', 'counters/examples': 118336, 'counters/updates': 7396}
skipping logging after 118352 examples to avoid logging too frequently
skipping logging after 118368 examples to avoid logging too frequently
skipping logging after 118384 examples to avoid logging too frequently
train stats after 118400 examples: {'rewards_train/chosen': '0.48187', 'rewards_train/rejected': '-5.8764', 'rewards_train/margins': '6.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.16608', 'examples_per_second': '5.2495', 'grad_norm': '5.1562', 'counters/examples': 118400, 'counters/updates': 7400}
skipping logging after 118416 examples to avoid logging too frequently
skipping logging after 118432 examples to avoid logging too frequently
skipping logging after 118448 examples to avoid logging too frequently
train stats after 118464 examples: {'rewards_train/chosen': '0.21062', 'rewards_train/rejected': '-6.3479', 'rewards_train/margins': '6.6641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2182', 'examples_per_second': '6.24', 'grad_norm': '3.9844', 'counters/examples': 118464, 'counters/updates': 7404}
skipping logging after 118480 examples to avoid logging too frequently
skipping logging after 118496 examples to avoid logging too frequently
skipping logging after 118512 examples to avoid logging too frequently
train stats after 118528 examples: {'rewards_train/chosen': '0.27045', 'rewards_train/rejected': '-5.786', 'rewards_train/margins': '5.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23804', 'examples_per_second': '4.2053', 'grad_norm': '4.8125', 'counters/examples': 118528, 'counters/updates': 7408}
skipping logging after 118544 examples to avoid logging too frequently
skipping logging after 118560 examples to avoid logging too frequently
skipping logging after 118576 examples to avoid logging too frequently
train stats after 118592 examples: {'rewards_train/chosen': '-0.10924', 'rewards_train/rejected': '-4.6079', 'rewards_train/margins': '4.6055', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26166', 'examples_per_second': '5.2237', 'grad_norm': '4.6562', 'counters/examples': 118592, 'counters/updates': 7412}
skipping logging after 118608 examples to avoid logging too frequently
skipping logging after 118624 examples to avoid logging too frequently
skipping logging after 118640 examples to avoid logging too frequently
train stats after 118656 examples: {'rewards_train/chosen': '0.18847', 'rewards_train/rejected': '-6.9712', 'rewards_train/margins': '7.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23102', 'examples_per_second': '4.4151', 'grad_norm': '5.4375', 'counters/examples': 118656, 'counters/updates': 7416}
skipping logging after 118672 examples to avoid logging too frequently
skipping logging after 118688 examples to avoid logging too frequently
skipping logging after 118704 examples to avoid logging too frequently
train stats after 118720 examples: {'rewards_train/chosen': '0.10246', 'rewards_train/rejected': '-5.9817', 'rewards_train/margins': '5.7578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27325', 'examples_per_second': '6.15', 'grad_norm': '4.8438', 'counters/examples': 118720, 'counters/updates': 7420}
skipping logging after 118736 examples to avoid logging too frequently
skipping logging after 118752 examples to avoid logging too frequently
skipping logging after 118768 examples to avoid logging too frequently
train stats after 118784 examples: {'rewards_train/chosen': '0.43883', 'rewards_train/rejected': '-5.3002', 'rewards_train/margins': '5.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22357', 'examples_per_second': '5.1351', 'grad_norm': '5.2812', 'counters/examples': 118784, 'counters/updates': 7424}
skipping logging after 118800 examples to avoid logging too frequently
skipping logging after 118816 examples to avoid logging too frequently
skipping logging after 118832 examples to avoid logging too frequently
train stats after 118848 examples: {'rewards_train/chosen': '0.040234', 'rewards_train/rejected': '-6.1999', 'rewards_train/margins': '6.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30615', 'examples_per_second': '4.7629', 'grad_norm': '4.5625', 'counters/examples': 118848, 'counters/updates': 7428}
skipping logging after 118864 examples to avoid logging too frequently
skipping logging after 118880 examples to avoid logging too frequently
skipping logging after 118896 examples to avoid logging too frequently
train stats after 118912 examples: {'rewards_train/chosen': '0.23425', 'rewards_train/rejected': '-5.4949', 'rewards_train/margins': '5.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25269', 'examples_per_second': '5.7332', 'grad_norm': '5.0625', 'counters/examples': 118912, 'counters/updates': 7432}
skipping logging after 118928 examples to avoid logging too frequently
skipping logging after 118944 examples to avoid logging too frequently
skipping logging after 118960 examples to avoid logging too frequently
train stats after 118976 examples: {'rewards_train/chosen': '0.64089', 'rewards_train/rejected': '-6.7212', 'rewards_train/margins': '7.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18115', 'examples_per_second': '5.2381', 'grad_norm': '4.5625', 'counters/examples': 118976, 'counters/updates': 7436}
skipping logging after 118992 examples to avoid logging too frequently
skipping logging after 119008 examples to avoid logging too frequently
skipping logging after 119024 examples to avoid logging too frequently
train stats after 119040 examples: {'rewards_train/chosen': '0.38951', 'rewards_train/rejected': '-6.1572', 'rewards_train/margins': '6.8203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25293', 'examples_per_second': '5.5031', 'grad_norm': '5', 'counters/examples': 119040, 'counters/updates': 7440}
skipping logging after 119056 examples to avoid logging too frequently
skipping logging after 119072 examples to avoid logging too frequently
skipping logging after 119088 examples to avoid logging too frequently
train stats after 119104 examples: {'rewards_train/chosen': '0.28204', 'rewards_train/rejected': '-5.283', 'rewards_train/margins': '5.4531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24603', 'examples_per_second': '4.672', 'grad_norm': '5.2812', 'counters/examples': 119104, 'counters/updates': 7444}
skipping logging after 119120 examples to avoid logging too frequently
skipping logging after 119136 examples to avoid logging too frequently
skipping logging after 119152 examples to avoid logging too frequently
train stats after 119168 examples: {'rewards_train/chosen': '0.16388', 'rewards_train/rejected': '-5.8915', 'rewards_train/margins': '6.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21741', 'examples_per_second': '4.7778', 'grad_norm': '4.6562', 'counters/examples': 119168, 'counters/updates': 7448}
skipping logging after 119184 examples to avoid logging too frequently
skipping logging after 119200 examples to avoid logging too frequently
skipping logging after 119216 examples to avoid logging too frequently
train stats after 119232 examples: {'rewards_train/chosen': '0.077664', 'rewards_train/rejected': '-6.269', 'rewards_train/margins': '6.2969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22375', 'examples_per_second': '5.819', 'grad_norm': '4.1875', 'counters/examples': 119232, 'counters/updates': 7452}
skipping logging after 119248 examples to avoid logging too frequently
skipping logging after 119264 examples to avoid logging too frequently
skipping logging after 119280 examples to avoid logging too frequently
train stats after 119296 examples: {'rewards_train/chosen': '0.53143', 'rewards_train/rejected': '-5.1395', 'rewards_train/margins': '5.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24066', 'examples_per_second': '5.0498', 'grad_norm': '5.4375', 'counters/examples': 119296, 'counters/updates': 7456}
skipping logging after 119312 examples to avoid logging too frequently
skipping logging after 119328 examples to avoid logging too frequently
skipping logging after 119344 examples to avoid logging too frequently
train stats after 119360 examples: {'rewards_train/chosen': '0.49468', 'rewards_train/rejected': '-4.7053', 'rewards_train/margins': '5.2344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24628', 'examples_per_second': '5.0881', 'grad_norm': '5', 'counters/examples': 119360, 'counters/updates': 7460}
skipping logging after 119376 examples to avoid logging too frequently
skipping logging after 119392 examples to avoid logging too frequently
skipping logging after 119408 examples to avoid logging too frequently
train stats after 119424 examples: {'rewards_train/chosen': '0.52322', 'rewards_train/rejected': '-7.866', 'rewards_train/margins': '8.6562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23358', 'examples_per_second': '5.706', 'grad_norm': '5.375', 'counters/examples': 119424, 'counters/updates': 7464}
skipping logging after 119440 examples to avoid logging too frequently
skipping logging after 119456 examples to avoid logging too frequently
skipping logging after 119472 examples to avoid logging too frequently
train stats after 119488 examples: {'rewards_train/chosen': '0.27599', 'rewards_train/rejected': '-4.8438', 'rewards_train/margins': '5.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23334', 'examples_per_second': '4.9498', 'grad_norm': '4.875', 'counters/examples': 119488, 'counters/updates': 7468}
skipping logging after 119504 examples to avoid logging too frequently
skipping logging after 119520 examples to avoid logging too frequently
skipping logging after 119536 examples to avoid logging too frequently
train stats after 119552 examples: {'rewards_train/chosen': '0.50753', 'rewards_train/rejected': '-6.0272', 'rewards_train/margins': '6.4844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20801', 'examples_per_second': '5.0506', 'grad_norm': '4.8125', 'counters/examples': 119552, 'counters/updates': 7472}
skipping logging after 119568 examples to avoid logging too frequently
skipping logging after 119584 examples to avoid logging too frequently
skipping logging after 119600 examples to avoid logging too frequently
train stats after 119616 examples: {'rewards_train/chosen': '0.27569', 'rewards_train/rejected': '-8.5595', 'rewards_train/margins': '8.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27124', 'examples_per_second': '4.5189', 'grad_norm': '5.9688', 'counters/examples': 119616, 'counters/updates': 7476}
skipping logging after 119632 examples to avoid logging too frequently
skipping logging after 119648 examples to avoid logging too frequently
skipping logging after 119664 examples to avoid logging too frequently
train stats after 119680 examples: {'rewards_train/chosen': '0.49841', 'rewards_train/rejected': '-7.2576', 'rewards_train/margins': '7.7578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22229', 'examples_per_second': '4.4992', 'grad_norm': '5.125', 'counters/examples': 119680, 'counters/updates': 7480}
skipping logging after 119696 examples to avoid logging too frequently
skipping logging after 119712 examples to avoid logging too frequently
skipping logging after 119728 examples to avoid logging too frequently
train stats after 119744 examples: {'rewards_train/chosen': '0.32025', 'rewards_train/rejected': '-4.4755', 'rewards_train/margins': '4.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25531', 'examples_per_second': '6.3067', 'grad_norm': '5.875', 'counters/examples': 119744, 'counters/updates': 7484}
skipping logging after 119760 examples to avoid logging too frequently
skipping logging after 119776 examples to avoid logging too frequently
skipping logging after 119792 examples to avoid logging too frequently
train stats after 119808 examples: {'rewards_train/chosen': '0.52755', 'rewards_train/rejected': '-5.7668', 'rewards_train/margins': '6.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23871', 'examples_per_second': '5.8366', 'grad_norm': '5.4062', 'counters/examples': 119808, 'counters/updates': 7488}
skipping logging after 119824 examples to avoid logging too frequently
skipping logging after 119840 examples to avoid logging too frequently
skipping logging after 119856 examples to avoid logging too frequently
train stats after 119872 examples: {'rewards_train/chosen': '0.19509', 'rewards_train/rejected': '-6.4166', 'rewards_train/margins': '6.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27271', 'examples_per_second': '5.271', 'grad_norm': '4.2188', 'counters/examples': 119872, 'counters/updates': 7492}
skipping logging after 119888 examples to avoid logging too frequently
skipping logging after 119904 examples to avoid logging too frequently
skipping logging after 119920 examples to avoid logging too frequently
train stats after 119936 examples: {'rewards_train/chosen': '0.6402', 'rewards_train/rejected': '-5.3688', 'rewards_train/margins': '5.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22284', 'examples_per_second': '5.2791', 'grad_norm': '4.7812', 'counters/examples': 119936, 'counters/updates': 7496}
skipping logging after 119952 examples to avoid logging too frequently
skipping logging after 119968 examples to avoid logging too frequently
skipping logging after 119984 examples to avoid logging too frequently
train stats after 120000 examples: {'rewards_train/chosen': '-1.1065', 'rewards_train/rejected': '-5.5081', 'rewards_train/margins': '4.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2489', 'examples_per_second': '5.2681', 'grad_norm': '5.125', 'counters/examples': 120000, 'counters/updates': 7500}
Running evaluation after 120000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.25s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.17s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:40,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.66s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.48s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:34,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.28s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.31s/it]
eval after 120000: {'rewards_eval/chosen': '-5.8086', 'rewards_eval/rejected': '-6.1824', 'rewards_eval/margins': '0.22314', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46312'}
skipping logging after 120016 examples to avoid logging too frequently
skipping logging after 120032 examples to avoid logging too frequently
skipping logging after 120048 examples to avoid logging too frequently
train stats after 120064 examples: {'rewards_train/chosen': '0.50686', 'rewards_train/rejected': '-5.5182', 'rewards_train/margins': '6.2109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22211', 'examples_per_second': '4.6215', 'grad_norm': '4.9375', 'counters/examples': 120064, 'counters/updates': 7504}
skipping logging after 120080 examples to avoid logging too frequently
skipping logging after 120096 examples to avoid logging too frequently
skipping logging after 120112 examples to avoid logging too frequently
train stats after 120128 examples: {'rewards_train/chosen': '0.25265', 'rewards_train/rejected': '-6.0341', 'rewards_train/margins': '6.0859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22723', 'examples_per_second': '5.0878', 'grad_norm': '5.5', 'counters/examples': 120128, 'counters/updates': 7508}
skipping logging after 120144 examples to avoid logging too frequently
skipping logging after 120160 examples to avoid logging too frequently
skipping logging after 120176 examples to avoid logging too frequently
train stats after 120192 examples: {'rewards_train/chosen': '-0.0076746', 'rewards_train/rejected': '-6.1056', 'rewards_train/margins': '6.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24359', 'examples_per_second': '5.1977', 'grad_norm': '5.4062', 'counters/examples': 120192, 'counters/updates': 7512}
skipping logging after 120208 examples to avoid logging too frequently
skipping logging after 120224 examples to avoid logging too frequently
skipping logging after 120240 examples to avoid logging too frequently
train stats after 120256 examples: {'rewards_train/chosen': '0.22577', 'rewards_train/rejected': '-6.383', 'rewards_train/margins': '6.5781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20966', 'examples_per_second': '5.433', 'grad_norm': '4.875', 'counters/examples': 120256, 'counters/updates': 7516}
skipping logging after 120272 examples to avoid logging too frequently
skipping logging after 120288 examples to avoid logging too frequently
skipping logging after 120304 examples to avoid logging too frequently
train stats after 120320 examples: {'rewards_train/chosen': '0.24712', 'rewards_train/rejected': '-5.5861', 'rewards_train/margins': '5.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25037', 'examples_per_second': '5.1425', 'grad_norm': '5.6875', 'counters/examples': 120320, 'counters/updates': 7520}
skipping logging after 120336 examples to avoid logging too frequently
skipping logging after 120352 examples to avoid logging too frequently
skipping logging after 120368 examples to avoid logging too frequently
train stats after 120384 examples: {'rewards_train/chosen': '0.53267', 'rewards_train/rejected': '-4.4385', 'rewards_train/margins': '5.125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25165', 'examples_per_second': '5.6274', 'grad_norm': '6.25', 'counters/examples': 120384, 'counters/updates': 7524}
skipping logging after 120400 examples to avoid logging too frequently
skipping logging after 120416 examples to avoid logging too frequently
skipping logging after 120432 examples to avoid logging too frequently
train stats after 120448 examples: {'rewards_train/chosen': '0.50265', 'rewards_train/rejected': '-4.9125', 'rewards_train/margins': '5.9141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2572', 'examples_per_second': '6.3764', 'grad_norm': '4.6875', 'counters/examples': 120448, 'counters/updates': 7528}
skipping logging after 120464 examples to avoid logging too frequently
skipping logging after 120480 examples to avoid logging too frequently
skipping logging after 120496 examples to avoid logging too frequently
train stats after 120512 examples: {'rewards_train/chosen': '0.46333', 'rewards_train/rejected': '-4.5995', 'rewards_train/margins': '5.0547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25806', 'examples_per_second': '6.2566', 'grad_norm': '5.9375', 'counters/examples': 120512, 'counters/updates': 7532}
skipping logging after 120528 examples to avoid logging too frequently
skipping logging after 120544 examples to avoid logging too frequently
skipping logging after 120560 examples to avoid logging too frequently
train stats after 120576 examples: {'rewards_train/chosen': '0.47485', 'rewards_train/rejected': '-5.1152', 'rewards_train/margins': '6.1172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22076', 'examples_per_second': '5.3279', 'grad_norm': '5.1875', 'counters/examples': 120576, 'counters/updates': 7536}
skipping logging after 120592 examples to avoid logging too frequently
skipping logging after 120608 examples to avoid logging too frequently
skipping logging after 120624 examples to avoid logging too frequently
train stats after 120640 examples: {'rewards_train/chosen': '0.39987', 'rewards_train/rejected': '-4.7191', 'rewards_train/margins': '5.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25659', 'examples_per_second': '5.1575', 'grad_norm': '5.0938', 'counters/examples': 120640, 'counters/updates': 7540}
skipping logging after 120656 examples to avoid logging too frequently
skipping logging after 120672 examples to avoid logging too frequently
skipping logging after 120688 examples to avoid logging too frequently
train stats after 120704 examples: {'rewards_train/chosen': '-0.15371', 'rewards_train/rejected': '-5.3695', 'rewards_train/margins': '5.1523', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25934', 'examples_per_second': '5.9218', 'grad_norm': '4.7812', 'counters/examples': 120704, 'counters/updates': 7544}
skipping logging after 120720 examples to avoid logging too frequently
skipping logging after 120736 examples to avoid logging too frequently
skipping logging after 120752 examples to avoid logging too frequently
train stats after 120768 examples: {'rewards_train/chosen': '0.54492', 'rewards_train/rejected': '-5.7141', 'rewards_train/margins': '6.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21399', 'examples_per_second': '4.287', 'grad_norm': '5.1562', 'counters/examples': 120768, 'counters/updates': 7548}
skipping logging after 120784 examples to avoid logging too frequently
skipping logging after 120800 examples to avoid logging too frequently
skipping logging after 120816 examples to avoid logging too frequently
train stats after 120832 examples: {'rewards_train/chosen': '0.54464', 'rewards_train/rejected': '-5.8935', 'rewards_train/margins': '6.2109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18396', 'examples_per_second': '4.273', 'grad_norm': '4.625', 'counters/examples': 120832, 'counters/updates': 7552}
skipping logging after 120848 examples to avoid logging too frequently
skipping logging after 120864 examples to avoid logging too frequently
skipping logging after 120880 examples to avoid logging too frequently
train stats after 120896 examples: {'rewards_train/chosen': '0.39512', 'rewards_train/rejected': '-6.426', 'rewards_train/margins': '6.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23041', 'examples_per_second': '5.1078', 'grad_norm': '4.5312', 'counters/examples': 120896, 'counters/updates': 7556}
skipping logging after 120912 examples to avoid logging too frequently
skipping logging after 120928 examples to avoid logging too frequently
skipping logging after 120944 examples to avoid logging too frequently
train stats after 120960 examples: {'rewards_train/chosen': '-0.06686', 'rewards_train/rejected': '-5.278', 'rewards_train/margins': '5.4023', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22363', 'examples_per_second': '5.3202', 'grad_norm': '4.7188', 'counters/examples': 120960, 'counters/updates': 7560}
skipping logging after 120976 examples to avoid logging too frequently
skipping logging after 120992 examples to avoid logging too frequently
skipping logging after 121008 examples to avoid logging too frequently
train stats after 121024 examples: {'rewards_train/chosen': '0.10736', 'rewards_train/rejected': '-6.3795', 'rewards_train/margins': '6.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26538', 'examples_per_second': '4.534', 'grad_norm': '5.1562', 'counters/examples': 121024, 'counters/updates': 7564}
skipping logging after 121040 examples to avoid logging too frequently
skipping logging after 121056 examples to avoid logging too frequently
skipping logging after 121072 examples to avoid logging too frequently
train stats after 121088 examples: {'rewards_train/chosen': '0.43578', 'rewards_train/rejected': '-6.0353', 'rewards_train/margins': '6.3828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.245', 'examples_per_second': '4.8354', 'grad_norm': '4.7812', 'counters/examples': 121088, 'counters/updates': 7568}
skipping logging after 121104 examples to avoid logging too frequently
skipping logging after 121120 examples to avoid logging too frequently
skipping logging after 121136 examples to avoid logging too frequently
train stats after 121152 examples: {'rewards_train/chosen': '0.4838', 'rewards_train/rejected': '-5.37', 'rewards_train/margins': '5.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20447', 'examples_per_second': '4.6639', 'grad_norm': '4.4375', 'counters/examples': 121152, 'counters/updates': 7572}
skipping logging after 121168 examples to avoid logging too frequently
skipping logging after 121184 examples to avoid logging too frequently
skipping logging after 121200 examples to avoid logging too frequently
train stats after 121216 examples: {'rewards_train/chosen': '0.43237', 'rewards_train/rejected': '-5.934', 'rewards_train/margins': '6.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21478', 'examples_per_second': '4.1987', 'grad_norm': '4.8125', 'counters/examples': 121216, 'counters/updates': 7576}
skipping logging after 121232 examples to avoid logging too frequently
skipping logging after 121248 examples to avoid logging too frequently
skipping logging after 121264 examples to avoid logging too frequently
train stats after 121280 examples: {'rewards_train/chosen': '0.22186', 'rewards_train/rejected': '-5.8155', 'rewards_train/margins': '6.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22272', 'examples_per_second': '6.0307', 'grad_norm': '5.25', 'counters/examples': 121280, 'counters/updates': 7580}
skipping logging after 121296 examples to avoid logging too frequently
skipping logging after 121312 examples to avoid logging too frequently
skipping logging after 121328 examples to avoid logging too frequently
train stats after 121344 examples: {'rewards_train/chosen': '0.30631', 'rewards_train/rejected': '-6.7103', 'rewards_train/margins': '7.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23596', 'examples_per_second': '5.1178', 'grad_norm': '5.125', 'counters/examples': 121344, 'counters/updates': 7584}
skipping logging after 121360 examples to avoid logging too frequently
skipping logging after 121376 examples to avoid logging too frequently
skipping logging after 121392 examples to avoid logging too frequently
train stats after 121408 examples: {'rewards_train/chosen': '0.60994', 'rewards_train/rejected': '-5.2314', 'rewards_train/margins': '5.8828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18738', 'examples_per_second': '5.3153', 'grad_norm': '4.6875', 'counters/examples': 121408, 'counters/updates': 7588}
skipping logging after 121424 examples to avoid logging too frequently
skipping logging after 121440 examples to avoid logging too frequently
skipping logging after 121456 examples to avoid logging too frequently
train stats after 121472 examples: {'rewards_train/chosen': '0.57981', 'rewards_train/rejected': '-6.4064', 'rewards_train/margins': '7.1016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22827', 'examples_per_second': '5.754', 'grad_norm': '4.9375', 'counters/examples': 121472, 'counters/updates': 7592}
skipping logging after 121488 examples to avoid logging too frequently
skipping logging after 121504 examples to avoid logging too frequently
skipping logging after 121520 examples to avoid logging too frequently
train stats after 121536 examples: {'rewards_train/chosen': '0.34033', 'rewards_train/rejected': '-3.9642', 'rewards_train/margins': '4.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26178', 'examples_per_second': '4.7577', 'grad_norm': '6.9375', 'counters/examples': 121536, 'counters/updates': 7596}
skipping logging after 121552 examples to avoid logging too frequently
skipping logging after 121568 examples to avoid logging too frequently
skipping logging after 121584 examples to avoid logging too frequently
train stats after 121600 examples: {'rewards_train/chosen': '0.28507', 'rewards_train/rejected': '-5.6016', 'rewards_train/margins': '6.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24493', 'examples_per_second': '5.3198', 'grad_norm': '4.8125', 'counters/examples': 121600, 'counters/updates': 7600}
skipping logging after 121616 examples to avoid logging too frequently
skipping logging after 121632 examples to avoid logging too frequently
skipping logging after 121648 examples to avoid logging too frequently
train stats after 121664 examples: {'rewards_train/chosen': '0.38076', 'rewards_train/rejected': '-6.1493', 'rewards_train/margins': '6.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2442', 'examples_per_second': '4.8383', 'grad_norm': '4.75', 'counters/examples': 121664, 'counters/updates': 7604}
skipping logging after 121680 examples to avoid logging too frequently
skipping logging after 121696 examples to avoid logging too frequently
skipping logging after 121712 examples to avoid logging too frequently
train stats after 121728 examples: {'rewards_train/chosen': '0.69409', 'rewards_train/rejected': '-6.1489', 'rewards_train/margins': '7.0547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21539', 'examples_per_second': '4.5285', 'grad_norm': '4.4375', 'counters/examples': 121728, 'counters/updates': 7608}
skipping logging after 121744 examples to avoid logging too frequently
skipping logging after 121760 examples to avoid logging too frequently
skipping logging after 121776 examples to avoid logging too frequently
train stats after 121792 examples: {'rewards_train/chosen': '0.23924', 'rewards_train/rejected': '-6.7767', 'rewards_train/margins': '6.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26086', 'examples_per_second': '5.1594', 'grad_norm': '5.1562', 'counters/examples': 121792, 'counters/updates': 7612}
skipping logging after 121808 examples to avoid logging too frequently
skipping logging after 121824 examples to avoid logging too frequently
skipping logging after 121840 examples to avoid logging too frequently
train stats after 121856 examples: {'rewards_train/chosen': '0.33438', 'rewards_train/rejected': '-5.3567', 'rewards_train/margins': '5.8828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27032', 'examples_per_second': '4.3396', 'grad_norm': '4.7812', 'counters/examples': 121856, 'counters/updates': 7616}
skipping logging after 121872 examples to avoid logging too frequently
skipping logging after 121888 examples to avoid logging too frequently
skipping logging after 121904 examples to avoid logging too frequently
train stats after 121920 examples: {'rewards_train/chosen': '0.59191', 'rewards_train/rejected': '-6.4575', 'rewards_train/margins': '7.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1994', 'examples_per_second': '5.1373', 'grad_norm': '4.5312', 'counters/examples': 121920, 'counters/updates': 7620}
skipping logging after 121936 examples to avoid logging too frequently
skipping logging after 121952 examples to avoid logging too frequently
skipping logging after 121968 examples to avoid logging too frequently
train stats after 121984 examples: {'rewards_train/chosen': '0.28342', 'rewards_train/rejected': '-6.1711', 'rewards_train/margins': '6.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27722', 'examples_per_second': '4.9807', 'grad_norm': '6.125', 'counters/examples': 121984, 'counters/updates': 7624}
skipping logging after 122000 examples to avoid logging too frequently
skipping logging after 122016 examples to avoid logging too frequently
skipping logging after 122032 examples to avoid logging too frequently
train stats after 122048 examples: {'rewards_train/chosen': '0.60949', 'rewards_train/rejected': '-5.5607', 'rewards_train/margins': '6.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23608', 'examples_per_second': '4.5687', 'grad_norm': '5.1875', 'counters/examples': 122048, 'counters/updates': 7628}
skipping logging after 122064 examples to avoid logging too frequently
skipping logging after 122080 examples to avoid logging too frequently
skipping logging after 122096 examples to avoid logging too frequently
train stats after 122112 examples: {'rewards_train/chosen': '0.51039', 'rewards_train/rejected': '-4.7611', 'rewards_train/margins': '5.1367', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2774', 'examples_per_second': '4.8365', 'grad_norm': '5.5312', 'counters/examples': 122112, 'counters/updates': 7632}
skipping logging after 122128 examples to avoid logging too frequently
skipping logging after 122144 examples to avoid logging too frequently
skipping logging after 122160 examples to avoid logging too frequently
train stats after 122176 examples: {'rewards_train/chosen': '0.75998', 'rewards_train/rejected': '-4.7646', 'rewards_train/margins': '5.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20227', 'examples_per_second': '5.3311', 'grad_norm': '5.1562', 'counters/examples': 122176, 'counters/updates': 7636}
skipping logging after 122192 examples to avoid logging too frequently
skipping logging after 122208 examples to avoid logging too frequently
skipping logging after 122224 examples to avoid logging too frequently
train stats after 122240 examples: {'rewards_train/chosen': '0.0043509', 'rewards_train/rejected': '-5.1524', 'rewards_train/margins': '5.1445', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29376', 'examples_per_second': '6.1579', 'grad_norm': '5.875', 'counters/examples': 122240, 'counters/updates': 7640}
skipping logging after 122256 examples to avoid logging too frequently
skipping logging after 122272 examples to avoid logging too frequently
skipping logging after 122288 examples to avoid logging too frequently
train stats after 122304 examples: {'rewards_train/chosen': '0.52963', 'rewards_train/rejected': '-6.2354', 'rewards_train/margins': '6.6914', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21643', 'examples_per_second': '6.2821', 'grad_norm': '5.5', 'counters/examples': 122304, 'counters/updates': 7644}
skipping logging after 122320 examples to avoid logging too frequently
skipping logging after 122336 examples to avoid logging too frequently
skipping logging after 122352 examples to avoid logging too frequently
train stats after 122368 examples: {'rewards_train/chosen': '0.64244', 'rewards_train/rejected': '-5.4111', 'rewards_train/margins': '5.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20398', 'examples_per_second': '5.0281', 'grad_norm': '4.5625', 'counters/examples': 122368, 'counters/updates': 7648}
skipping logging after 122384 examples to avoid logging too frequently
skipping logging after 122400 examples to avoid logging too frequently
skipping logging after 122416 examples to avoid logging too frequently
train stats after 122432 examples: {'rewards_train/chosen': '0.51873', 'rewards_train/rejected': '-5.6757', 'rewards_train/margins': '6.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21021', 'examples_per_second': '5.1076', 'grad_norm': '4.5312', 'counters/examples': 122432, 'counters/updates': 7652}
skipping logging after 122448 examples to avoid logging too frequently
skipping logging after 122464 examples to avoid logging too frequently
skipping logging after 122480 examples to avoid logging too frequently
train stats after 122496 examples: {'rewards_train/chosen': '0.35813', 'rewards_train/rejected': '-5.251', 'rewards_train/margins': '5.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23773', 'examples_per_second': '5.1677', 'grad_norm': '5.0625', 'counters/examples': 122496, 'counters/updates': 7656}
skipping logging after 122512 examples to avoid logging too frequently
skipping logging after 122528 examples to avoid logging too frequently
skipping logging after 122544 examples to avoid logging too frequently
train stats after 122560 examples: {'rewards_train/chosen': '0.57695', 'rewards_train/rejected': '-7.9294', 'rewards_train/margins': '8.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21246', 'examples_per_second': '5.4611', 'grad_norm': '4.3438', 'counters/examples': 122560, 'counters/updates': 7660}
skipping logging after 122576 examples to avoid logging too frequently
skipping logging after 122592 examples to avoid logging too frequently
skipping logging after 122608 examples to avoid logging too frequently
train stats after 122624 examples: {'rewards_train/chosen': '0.63907', 'rewards_train/rejected': '-6.6967', 'rewards_train/margins': '7.4844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21094', 'examples_per_second': '4.6673', 'grad_norm': '4.4375', 'counters/examples': 122624, 'counters/updates': 7664}
skipping logging after 122640 examples to avoid logging too frequently
skipping logging after 122656 examples to avoid logging too frequently
skipping logging after 122672 examples to avoid logging too frequently
train stats after 122688 examples: {'rewards_train/chosen': '0.21335', 'rewards_train/rejected': '-5.9276', 'rewards_train/margins': '5.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27936', 'examples_per_second': '5.6696', 'grad_norm': '6.125', 'counters/examples': 122688, 'counters/updates': 7668}
skipping logging after 122704 examples to avoid logging too frequently
skipping logging after 122720 examples to avoid logging too frequently
skipping logging after 122736 examples to avoid logging too frequently
train stats after 122752 examples: {'rewards_train/chosen': '0.23052', 'rewards_train/rejected': '-5.3962', 'rewards_train/margins': '5.7695', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22186', 'examples_per_second': '3.9802', 'grad_norm': '4.4062', 'counters/examples': 122752, 'counters/updates': 7672}
skipping logging after 122768 examples to avoid logging too frequently
skipping logging after 122784 examples to avoid logging too frequently
skipping logging after 122800 examples to avoid logging too frequently
train stats after 122816 examples: {'rewards_train/chosen': '0.086901', 'rewards_train/rejected': '-5.101', 'rewards_train/margins': '5.3828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29541', 'examples_per_second': '6.5149', 'grad_norm': '5.2812', 'counters/examples': 122816, 'counters/updates': 7676}
skipping logging after 122832 examples to avoid logging too frequently
skipping logging after 122848 examples to avoid logging too frequently
skipping logging after 122864 examples to avoid logging too frequently
train stats after 122880 examples: {'rewards_train/chosen': '0.21818', 'rewards_train/rejected': '-5.4573', 'rewards_train/margins': '5.8477', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25427', 'examples_per_second': '4.8909', 'grad_norm': '5.9688', 'counters/examples': 122880, 'counters/updates': 7680}
skipping logging after 122896 examples to avoid logging too frequently
skipping logging after 122912 examples to avoid logging too frequently
skipping logging after 122928 examples to avoid logging too frequently
train stats after 122944 examples: {'rewards_train/chosen': '0.42573', 'rewards_train/rejected': '-5.4802', 'rewards_train/margins': '6.0547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26111', 'examples_per_second': '4.318', 'grad_norm': '4.25', 'counters/examples': 122944, 'counters/updates': 7684}
skipping logging after 122960 examples to avoid logging too frequently
skipping logging after 122976 examples to avoid logging too frequently
skipping logging after 122992 examples to avoid logging too frequently
train stats after 123008 examples: {'rewards_train/chosen': '0.62784', 'rewards_train/rejected': '-4.7072', 'rewards_train/margins': '5.2109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22894', 'examples_per_second': '4.9279', 'grad_norm': '5.7188', 'counters/examples': 123008, 'counters/updates': 7688}
skipping logging after 123024 examples to avoid logging too frequently
skipping logging after 123040 examples to avoid logging too frequently
skipping logging after 123056 examples to avoid logging too frequently
train stats after 123072 examples: {'rewards_train/chosen': '0.54215', 'rewards_train/rejected': '-6.5371', 'rewards_train/margins': '6.9453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24451', 'examples_per_second': '4.3505', 'grad_norm': '4.5938', 'counters/examples': 123072, 'counters/updates': 7692}
skipping logging after 123088 examples to avoid logging too frequently
skipping logging after 123104 examples to avoid logging too frequently
skipping logging after 123120 examples to avoid logging too frequently
train stats after 123136 examples: {'rewards_train/chosen': '0.51689', 'rewards_train/rejected': '-5.0809', 'rewards_train/margins': '5.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2207', 'examples_per_second': '5.8768', 'grad_norm': '4.5625', 'counters/examples': 123136, 'counters/updates': 7696}
skipping logging after 123152 examples to avoid logging too frequently
skipping logging after 123168 examples to avoid logging too frequently
skipping logging after 123184 examples to avoid logging too frequently
train stats after 123200 examples: {'rewards_train/chosen': '0.4595', 'rewards_train/rejected': '-5.6146', 'rewards_train/margins': '6.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.16949', 'examples_per_second': '6.0605', 'grad_norm': '4.5312', 'counters/examples': 123200, 'counters/updates': 7700}
skipping logging after 123216 examples to avoid logging too frequently
skipping logging after 123232 examples to avoid logging too frequently
skipping logging after 123248 examples to avoid logging too frequently
train stats after 123264 examples: {'rewards_train/chosen': '0.19809', 'rewards_train/rejected': '-5.9344', 'rewards_train/margins': '5.8906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27148', 'examples_per_second': '5.4848', 'grad_norm': '5.9062', 'counters/examples': 123264, 'counters/updates': 7704}
skipping logging after 123280 examples to avoid logging too frequently
skipping logging after 123296 examples to avoid logging too frequently
skipping logging after 123312 examples to avoid logging too frequently
train stats after 123328 examples: {'rewards_train/chosen': '0.33061', 'rewards_train/rejected': '-5.6598', 'rewards_train/margins': '5.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2475', 'examples_per_second': '5.1244', 'grad_norm': '5.1875', 'counters/examples': 123328, 'counters/updates': 7708}
skipping logging after 123344 examples to avoid logging too frequently
skipping logging after 123360 examples to avoid logging too frequently
skipping logging after 123376 examples to avoid logging too frequently
train stats after 123392 examples: {'rewards_train/chosen': '0.47238', 'rewards_train/rejected': '-4.9396', 'rewards_train/margins': '5.8672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24158', 'examples_per_second': '6.5273', 'grad_norm': '4.8438', 'counters/examples': 123392, 'counters/updates': 7712}
skipping logging after 123408 examples to avoid logging too frequently
skipping logging after 123424 examples to avoid logging too frequently
skipping logging after 123440 examples to avoid logging too frequently
train stats after 123456 examples: {'rewards_train/chosen': '-0.055725', 'rewards_train/rejected': '-4.6875', 'rewards_train/margins': '4.6211', 'rewards_train/KL_estimate': '0', 'loss/train': '0.31262', 'examples_per_second': '5.7113', 'grad_norm': '4.7812', 'counters/examples': 123456, 'counters/updates': 7716}
skipping logging after 123472 examples to avoid logging too frequently
skipping logging after 123488 examples to avoid logging too frequently
skipping logging after 123504 examples to avoid logging too frequently
train stats after 123520 examples: {'rewards_train/chosen': '0.569', 'rewards_train/rejected': '-6.1761', 'rewards_train/margins': '6.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19965', 'examples_per_second': '4.8959', 'grad_norm': '4.7188', 'counters/examples': 123520, 'counters/updates': 7720}
skipping logging after 123536 examples to avoid logging too frequently
skipping logging after 123552 examples to avoid logging too frequently
skipping logging after 123568 examples to avoid logging too frequently
train stats after 123584 examples: {'rewards_train/chosen': '0.34035', 'rewards_train/rejected': '-5.8367', 'rewards_train/margins': '5.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19855', 'examples_per_second': '4.5924', 'grad_norm': '4.5938', 'counters/examples': 123584, 'counters/updates': 7724}
skipping logging after 123600 examples to avoid logging too frequently
skipping logging after 123616 examples to avoid logging too frequently
skipping logging after 123632 examples to avoid logging too frequently
train stats after 123648 examples: {'rewards_train/chosen': '0.39432', 'rewards_train/rejected': '-5.4338', 'rewards_train/margins': '5.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25354', 'examples_per_second': '6.0799', 'grad_norm': '5.0938', 'counters/examples': 123648, 'counters/updates': 7728}
skipping logging after 123664 examples to avoid logging too frequently
skipping logging after 123680 examples to avoid logging too frequently
skipping logging after 123696 examples to avoid logging too frequently
train stats after 123712 examples: {'rewards_train/chosen': '0.42824', 'rewards_train/rejected': '-6.1606', 'rewards_train/margins': '6.7578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24628', 'examples_per_second': '5.3423', 'grad_norm': '5.875', 'counters/examples': 123712, 'counters/updates': 7732}
skipping logging after 123728 examples to avoid logging too frequently
skipping logging after 123744 examples to avoid logging too frequently
skipping logging after 123760 examples to avoid logging too frequently
train stats after 123776 examples: {'rewards_train/chosen': '0.58233', 'rewards_train/rejected': '-6.5432', 'rewards_train/margins': '7.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23566', 'examples_per_second': '4.8548', 'grad_norm': '5.2812', 'counters/examples': 123776, 'counters/updates': 7736}
skipping logging after 123792 examples to avoid logging too frequently
skipping logging after 123808 examples to avoid logging too frequently
skipping logging after 123824 examples to avoid logging too frequently
train stats after 123840 examples: {'rewards_train/chosen': '0.20153', 'rewards_train/rejected': '-4.9447', 'rewards_train/margins': '5.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29877', 'examples_per_second': '4.2363', 'grad_norm': '5.25', 'counters/examples': 123840, 'counters/updates': 7740}
skipping logging after 123856 examples to avoid logging too frequently
skipping logging after 123872 examples to avoid logging too frequently
skipping logging after 123888 examples to avoid logging too frequently
train stats after 123904 examples: {'rewards_train/chosen': '0.2264', 'rewards_train/rejected': '-5.1682', 'rewards_train/margins': '5.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24567', 'examples_per_second': '5.0525', 'grad_norm': '4.4375', 'counters/examples': 123904, 'counters/updates': 7744}
skipping logging after 123920 examples to avoid logging too frequently
skipping logging after 123936 examples to avoid logging too frequently
skipping logging after 123952 examples to avoid logging too frequently
train stats after 123968 examples: {'rewards_train/chosen': '0.45852', 'rewards_train/rejected': '-6.158', 'rewards_train/margins': '6.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25824', 'examples_per_second': '5.4146', 'grad_norm': '5.5', 'counters/examples': 123968, 'counters/updates': 7748}
skipping logging after 123984 examples to avoid logging too frequently
skipping logging after 124000 examples to avoid logging too frequently
Running evaluation after 124000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:48,  1.58s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:41,  1.39s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:35,  1.24s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.48s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.68s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.49s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:10<00:34,  1.37s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.49s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.41s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.22s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.20s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:41<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]
eval after 124000: {'rewards_eval/chosen': '-5.3146', 'rewards_eval/rejected': '-5.6603', 'rewards_eval/margins': '0.22607', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46511'}
skipping logging after 124016 examples to avoid logging too frequently
train stats after 124032 examples: {'rewards_train/chosen': '0.40285', 'rewards_train/rejected': '-5.1779', 'rewards_train/margins': '5.5391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24792', 'examples_per_second': '5.2182', 'grad_norm': '4.4688', 'counters/examples': 124032, 'counters/updates': 7752}
skipping logging after 124048 examples to avoid logging too frequently
skipping logging after 124064 examples to avoid logging too frequently
skipping logging after 124080 examples to avoid logging too frequently
train stats after 124096 examples: {'rewards_train/chosen': '0.49494', 'rewards_train/rejected': '-5.3941', 'rewards_train/margins': '5.4609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27765', 'examples_per_second': '5.1712', 'grad_norm': '5.6875', 'counters/examples': 124096, 'counters/updates': 7756}
skipping logging after 124112 examples to avoid logging too frequently
skipping logging after 124128 examples to avoid logging too frequently
skipping logging after 124144 examples to avoid logging too frequently
train stats after 124160 examples: {'rewards_train/chosen': '0.53563', 'rewards_train/rejected': '-5.6468', 'rewards_train/margins': '6.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22015', 'examples_per_second': '4.7499', 'grad_norm': '4.7812', 'counters/examples': 124160, 'counters/updates': 7760}
skipping logging after 124176 examples to avoid logging too frequently
skipping logging after 124192 examples to avoid logging too frequently
skipping logging after 124208 examples to avoid logging too frequently
train stats after 124224 examples: {'rewards_train/chosen': '0.42229', 'rewards_train/rejected': '-5.5101', 'rewards_train/margins': '5.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24158', 'examples_per_second': '5.0485', 'grad_norm': '4.8125', 'counters/examples': 124224, 'counters/updates': 7764}
skipping logging after 124240 examples to avoid logging too frequently
skipping logging after 124256 examples to avoid logging too frequently
skipping logging after 124272 examples to avoid logging too frequently
train stats after 124288 examples: {'rewards_train/chosen': '0.60975', 'rewards_train/rejected': '-6.0684', 'rewards_train/margins': '6.7031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23962', 'examples_per_second': '4.4237', 'grad_norm': '5.875', 'counters/examples': 124288, 'counters/updates': 7768}
skipping logging after 124304 examples to avoid logging too frequently
skipping logging after 124320 examples to avoid logging too frequently
skipping logging after 124336 examples to avoid logging too frequently
train stats after 124352 examples: {'rewards_train/chosen': '0.38615', 'rewards_train/rejected': '-6.3897', 'rewards_train/margins': '6.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21124', 'examples_per_second': '4.3759', 'grad_norm': '4.7188', 'counters/examples': 124352, 'counters/updates': 7772}
skipping logging after 124368 examples to avoid logging too frequently
skipping logging after 124384 examples to avoid logging too frequently
skipping logging after 124400 examples to avoid logging too frequently
train stats after 124416 examples: {'rewards_train/chosen': '0.30712', 'rewards_train/rejected': '-5.8589', 'rewards_train/margins': '6.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20557', 'examples_per_second': '5.6327', 'grad_norm': '5.1562', 'counters/examples': 124416, 'counters/updates': 7776}
skipping logging after 124432 examples to avoid logging too frequently
skipping logging after 124448 examples to avoid logging too frequently
skipping logging after 124464 examples to avoid logging too frequently
train stats after 124480 examples: {'rewards_train/chosen': '0.48402', 'rewards_train/rejected': '-6.5598', 'rewards_train/margins': '6.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2514', 'examples_per_second': '5.4506', 'grad_norm': '5.4062', 'counters/examples': 124480, 'counters/updates': 7780}
skipping logging after 124496 examples to avoid logging too frequently
skipping logging after 124512 examples to avoid logging too frequently
skipping logging after 124528 examples to avoid logging too frequently
train stats after 124544 examples: {'rewards_train/chosen': '0.67479', 'rewards_train/rejected': '-5.4641', 'rewards_train/margins': '6.0156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18036', 'examples_per_second': '4.7933', 'grad_norm': '4.75', 'counters/examples': 124544, 'counters/updates': 7784}
skipping logging after 124560 examples to avoid logging too frequently
skipping logging after 124576 examples to avoid logging too frequently
skipping logging after 124592 examples to avoid logging too frequently
train stats after 124608 examples: {'rewards_train/chosen': '0.35429', 'rewards_train/rejected': '-6.2315', 'rewards_train/margins': '6.8008', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26611', 'examples_per_second': '4.9439', 'grad_norm': '4.7188', 'counters/examples': 124608, 'counters/updates': 7788}
skipping logging after 124624 examples to avoid logging too frequently
skipping logging after 124640 examples to avoid logging too frequently
skipping logging after 124656 examples to avoid logging too frequently
train stats after 124672 examples: {'rewards_train/chosen': '0.50396', 'rewards_train/rejected': '-5.6548', 'rewards_train/margins': '6.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20905', 'examples_per_second': '4.7475', 'grad_norm': '5.375', 'counters/examples': 124672, 'counters/updates': 7792}
skipping logging after 124688 examples to avoid logging too frequently
skipping logging after 124704 examples to avoid logging too frequently
skipping logging after 124720 examples to avoid logging too frequently
train stats after 124736 examples: {'rewards_train/chosen': '0.63004', 'rewards_train/rejected': '-6.2559', 'rewards_train/margins': '6.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2309', 'examples_per_second': '3.9995', 'grad_norm': '4.7188', 'counters/examples': 124736, 'counters/updates': 7796}
skipping logging after 124752 examples to avoid logging too frequently
skipping logging after 124768 examples to avoid logging too frequently
skipping logging after 124784 examples to avoid logging too frequently
train stats after 124800 examples: {'rewards_train/chosen': '0.32692', 'rewards_train/rejected': '-5.011', 'rewards_train/margins': '5.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28094', 'examples_per_second': '5.192', 'grad_norm': '5.25', 'counters/examples': 124800, 'counters/updates': 7800}
skipping logging after 124816 examples to avoid logging too frequently
skipping logging after 124832 examples to avoid logging too frequently
skipping logging after 124848 examples to avoid logging too frequently
train stats after 124864 examples: {'rewards_train/chosen': '0.2483', 'rewards_train/rejected': '-5.9074', 'rewards_train/margins': '6.1172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24603', 'examples_per_second': '4.6861', 'grad_norm': '4.9688', 'counters/examples': 124864, 'counters/updates': 7804}
skipping logging after 124880 examples to avoid logging too frequently
skipping logging after 124896 examples to avoid logging too frequently
skipping logging after 124912 examples to avoid logging too frequently
train stats after 124928 examples: {'rewards_train/chosen': '0.32678', 'rewards_train/rejected': '-6.9891', 'rewards_train/margins': '7.4219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27185', 'examples_per_second': '4.9148', 'grad_norm': '6.0625', 'counters/examples': 124928, 'counters/updates': 7808}
skipping logging after 124944 examples to avoid logging too frequently
skipping logging after 124960 examples to avoid logging too frequently
skipping logging after 124976 examples to avoid logging too frequently
train stats after 124992 examples: {'rewards_train/chosen': '0.33133', 'rewards_train/rejected': '-5.4308', 'rewards_train/margins': '5.8125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21527', 'examples_per_second': '4.7652', 'grad_norm': '4.5625', 'counters/examples': 124992, 'counters/updates': 7812}
skipping logging after 125008 examples to avoid logging too frequently
skipping logging after 125024 examples to avoid logging too frequently
skipping logging after 125040 examples to avoid logging too frequently
train stats after 125056 examples: {'rewards_train/chosen': '0.24679', 'rewards_train/rejected': '-6.045', 'rewards_train/margins': '6.2969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.258', 'examples_per_second': '4.8553', 'grad_norm': '4.7188', 'counters/examples': 125056, 'counters/updates': 7816}
skipping logging after 125072 examples to avoid logging too frequently
skipping logging after 125088 examples to avoid logging too frequently
skipping logging after 125104 examples to avoid logging too frequently
train stats after 125120 examples: {'rewards_train/chosen': '0.56367', 'rewards_train/rejected': '-5.283', 'rewards_train/margins': '5.8906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25122', 'examples_per_second': '5.4359', 'grad_norm': '6.2188', 'counters/examples': 125120, 'counters/updates': 7820}
skipping logging after 125136 examples to avoid logging too frequently
skipping logging after 125152 examples to avoid logging too frequently
skipping logging after 125168 examples to avoid logging too frequently
train stats after 125184 examples: {'rewards_train/chosen': '0.5167', 'rewards_train/rejected': '-4.7729', 'rewards_train/margins': '5.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22009', 'examples_per_second': '5.0349', 'grad_norm': '4.5', 'counters/examples': 125184, 'counters/updates': 7824}
skipping logging after 125200 examples to avoid logging too frequently
skipping logging after 125216 examples to avoid logging too frequently
skipping logging after 125232 examples to avoid logging too frequently
train stats after 125248 examples: {'rewards_train/chosen': '0.32735', 'rewards_train/rejected': '-5.7056', 'rewards_train/margins': '5.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2807', 'examples_per_second': '4.8811', 'grad_norm': '5.6562', 'counters/examples': 125248, 'counters/updates': 7828}
skipping logging after 125264 examples to avoid logging too frequently
skipping logging after 125280 examples to avoid logging too frequently
skipping logging after 125296 examples to avoid logging too frequently
train stats after 125312 examples: {'rewards_train/chosen': '0.6168', 'rewards_train/rejected': '-5.9168', 'rewards_train/margins': '6.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20483', 'examples_per_second': '3.9935', 'grad_norm': '4.6562', 'counters/examples': 125312, 'counters/updates': 7832}
skipping logging after 125328 examples to avoid logging too frequently
skipping logging after 125344 examples to avoid logging too frequently
skipping logging after 125360 examples to avoid logging too frequently
train stats after 125376 examples: {'rewards_train/chosen': '0.18483', 'rewards_train/rejected': '-5.418', 'rewards_train/margins': '5.6094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24457', 'examples_per_second': '5.5341', 'grad_norm': '5.25', 'counters/examples': 125376, 'counters/updates': 7836}
skipping logging after 125392 examples to avoid logging too frequently
skipping logging after 125408 examples to avoid logging too frequently
skipping logging after 125424 examples to avoid logging too frequently
train stats after 125440 examples: {'rewards_train/chosen': '0.68187', 'rewards_train/rejected': '-6.6797', 'rewards_train/margins': '6.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20715', 'examples_per_second': '5.8039', 'grad_norm': '4.2188', 'counters/examples': 125440, 'counters/updates': 7840}
skipping logging after 125456 examples to avoid logging too frequently
skipping logging after 125472 examples to avoid logging too frequently
skipping logging after 125488 examples to avoid logging too frequently
train stats after 125504 examples: {'rewards_train/chosen': '0.42298', 'rewards_train/rejected': '-5.9422', 'rewards_train/margins': '6.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27386', 'examples_per_second': '4.9069', 'grad_norm': '5.8125', 'counters/examples': 125504, 'counters/updates': 7844}
skipping logging after 125520 examples to avoid logging too frequently
skipping logging after 125536 examples to avoid logging too frequently
skipping logging after 125552 examples to avoid logging too frequently
train stats after 125568 examples: {'rewards_train/chosen': '0.084812', 'rewards_train/rejected': '-5.4018', 'rewards_train/margins': '5.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23749', 'examples_per_second': '5.6329', 'grad_norm': '4.625', 'counters/examples': 125568, 'counters/updates': 7848}
skipping logging after 125584 examples to avoid logging too frequently
skipping logging after 125600 examples to avoid logging too frequently
skipping logging after 125616 examples to avoid logging too frequently
train stats after 125632 examples: {'rewards_train/chosen': '0.54684', 'rewards_train/rejected': '-7.4269', 'rewards_train/margins': '7.8828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20825', 'examples_per_second': '5.6817', 'grad_norm': '4.6562', 'counters/examples': 125632, 'counters/updates': 7852}
skipping logging after 125648 examples to avoid logging too frequently
skipping logging after 125664 examples to avoid logging too frequently
skipping logging after 125680 examples to avoid logging too frequently
train stats after 125696 examples: {'rewards_train/chosen': '0.48105', 'rewards_train/rejected': '-4.225', 'rewards_train/margins': '4.793', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22205', 'examples_per_second': '5.4495', 'grad_norm': '5.3438', 'counters/examples': 125696, 'counters/updates': 7856}
skipping logging after 125712 examples to avoid logging too frequently
skipping logging after 125728 examples to avoid logging too frequently
skipping logging after 125744 examples to avoid logging too frequently
train stats after 125760 examples: {'rewards_train/chosen': '0.43971', 'rewards_train/rejected': '-5.6543', 'rewards_train/margins': '6.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21411', 'examples_per_second': '5.0888', 'grad_norm': '4.9688', 'counters/examples': 125760, 'counters/updates': 7860}
skipping logging after 125776 examples to avoid logging too frequently
skipping logging after 125792 examples to avoid logging too frequently
skipping logging after 125808 examples to avoid logging too frequently
train stats after 125824 examples: {'rewards_train/chosen': '-0.14144', 'rewards_train/rejected': '-6.3591', 'rewards_train/margins': '6.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28131', 'examples_per_second': '4.8309', 'grad_norm': '5.5625', 'counters/examples': 125824, 'counters/updates': 7864}
skipping logging after 125840 examples to avoid logging too frequently
skipping logging after 125856 examples to avoid logging too frequently
skipping logging after 125872 examples to avoid logging too frequently
train stats after 125888 examples: {'rewards_train/chosen': '0.3212', 'rewards_train/rejected': '-6.7885', 'rewards_train/margins': '7.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24927', 'examples_per_second': '4.9016', 'grad_norm': '5.5938', 'counters/examples': 125888, 'counters/updates': 7868}
skipping logging after 125904 examples to avoid logging too frequently
skipping logging after 125920 examples to avoid logging too frequently
skipping logging after 125936 examples to avoid logging too frequently
train stats after 125952 examples: {'rewards_train/chosen': '-0.1039', 'rewards_train/rejected': '-6.5627', 'rewards_train/margins': '6.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24207', 'examples_per_second': '4.8491', 'grad_norm': '5.5312', 'counters/examples': 125952, 'counters/updates': 7872}
skipping logging after 125968 examples to avoid logging too frequently
skipping logging after 125984 examples to avoid logging too frequently
skipping logging after 126000 examples to avoid logging too frequently
train stats after 126016 examples: {'rewards_train/chosen': '0.359', 'rewards_train/rejected': '-5.0874', 'rewards_train/margins': '5.5781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22345', 'examples_per_second': '5.8375', 'grad_norm': '4.6875', 'counters/examples': 126016, 'counters/updates': 7876}
skipping logging after 126032 examples to avoid logging too frequently
skipping logging after 126048 examples to avoid logging too frequently
skipping logging after 126064 examples to avoid logging too frequently
train stats after 126080 examples: {'rewards_train/chosen': '0.60697', 'rewards_train/rejected': '-6.2392', 'rewards_train/margins': '7.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24146', 'examples_per_second': '4.2719', 'grad_norm': '5.3125', 'counters/examples': 126080, 'counters/updates': 7880}
skipping logging after 126096 examples to avoid logging too frequently
skipping logging after 126112 examples to avoid logging too frequently
skipping logging after 126128 examples to avoid logging too frequently
train stats after 126144 examples: {'rewards_train/chosen': '0.31878', 'rewards_train/rejected': '-6.7951', 'rewards_train/margins': '6.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26355', 'examples_per_second': '5.0461', 'grad_norm': '6.1562', 'counters/examples': 126144, 'counters/updates': 7884}
skipping logging after 126160 examples to avoid logging too frequently
skipping logging after 126176 examples to avoid logging too frequently
skipping logging after 126192 examples to avoid logging too frequently
train stats after 126208 examples: {'rewards_train/chosen': '0.64471', 'rewards_train/rejected': '-7.2372', 'rewards_train/margins': '7.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24225', 'examples_per_second': '4.3685', 'grad_norm': '5.2812', 'counters/examples': 126208, 'counters/updates': 7888}
skipping logging after 126224 examples to avoid logging too frequently
skipping logging after 126240 examples to avoid logging too frequently
skipping logging after 126256 examples to avoid logging too frequently
train stats after 126272 examples: {'rewards_train/chosen': '0.39108', 'rewards_train/rejected': '-5.6566', 'rewards_train/margins': '6.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21918', 'examples_per_second': '4.7601', 'grad_norm': '5.0625', 'counters/examples': 126272, 'counters/updates': 7892}
skipping logging after 126288 examples to avoid logging too frequently
skipping logging after 126304 examples to avoid logging too frequently
skipping logging after 126320 examples to avoid logging too frequently
train stats after 126336 examples: {'rewards_train/chosen': '0.45343', 'rewards_train/rejected': '-6.0156', 'rewards_train/margins': '6.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25293', 'examples_per_second': '5.3755', 'grad_norm': '5.7812', 'counters/examples': 126336, 'counters/updates': 7896}
skipping logging after 126352 examples to avoid logging too frequently
skipping logging after 126368 examples to avoid logging too frequently
skipping logging after 126384 examples to avoid logging too frequently
train stats after 126400 examples: {'rewards_train/chosen': '0.57386', 'rewards_train/rejected': '-6.2721', 'rewards_train/margins': '6.7031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22516', 'examples_per_second': '5.8469', 'grad_norm': '5.2812', 'counters/examples': 126400, 'counters/updates': 7900}
skipping logging after 126416 examples to avoid logging too frequently
skipping logging after 126432 examples to avoid logging too frequently
skipping logging after 126448 examples to avoid logging too frequently
train stats after 126464 examples: {'rewards_train/chosen': '0.16299', 'rewards_train/rejected': '-4.8875', 'rewards_train/margins': '4.9766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23718', 'examples_per_second': '5.1602', 'grad_norm': '5.2188', 'counters/examples': 126464, 'counters/updates': 7904}
skipping logging after 126480 examples to avoid logging too frequently
skipping logging after 126496 examples to avoid logging too frequently
skipping logging after 126512 examples to avoid logging too frequently
train stats after 126528 examples: {'rewards_train/chosen': '0.78987', 'rewards_train/rejected': '-5.4875', 'rewards_train/margins': '6.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21503', 'examples_per_second': '5.2259', 'grad_norm': '4.9688', 'counters/examples': 126528, 'counters/updates': 7908}
skipping logging after 126544 examples to avoid logging too frequently
skipping logging after 126560 examples to avoid logging too frequently
skipping logging after 126576 examples to avoid logging too frequently
train stats after 126592 examples: {'rewards_train/chosen': '-0.063238', 'rewards_train/rejected': '-5.8438', 'rewards_train/margins': '5.7422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26367', 'examples_per_second': '4.7568', 'grad_norm': '5.3438', 'counters/examples': 126592, 'counters/updates': 7912}
skipping logging after 126608 examples to avoid logging too frequently
skipping logging after 126624 examples to avoid logging too frequently
skipping logging after 126640 examples to avoid logging too frequently
train stats after 126656 examples: {'rewards_train/chosen': '0.48746', 'rewards_train/rejected': '-4.8801', 'rewards_train/margins': '5.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18738', 'examples_per_second': '5.0134', 'grad_norm': '4.3125', 'counters/examples': 126656, 'counters/updates': 7916}
skipping logging after 126672 examples to avoid logging too frequently
skipping logging after 126688 examples to avoid logging too frequently
skipping logging after 126704 examples to avoid logging too frequently
train stats after 126720 examples: {'rewards_train/chosen': '0.37041', 'rewards_train/rejected': '-7.2097', 'rewards_train/margins': '7.7031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1958', 'examples_per_second': '4.837', 'grad_norm': '4.9062', 'counters/examples': 126720, 'counters/updates': 7920}
skipping logging after 126736 examples to avoid logging too frequently
skipping logging after 126752 examples to avoid logging too frequently
skipping logging after 126768 examples to avoid logging too frequently
train stats after 126784 examples: {'rewards_train/chosen': '0.31376', 'rewards_train/rejected': '-6.7495', 'rewards_train/margins': '7.0156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21735', 'examples_per_second': '5.1037', 'grad_norm': '4.3438', 'counters/examples': 126784, 'counters/updates': 7924}
skipping logging after 126800 examples to avoid logging too frequently
skipping logging after 126816 examples to avoid logging too frequently
skipping logging after 126832 examples to avoid logging too frequently
train stats after 126848 examples: {'rewards_train/chosen': '0.48155', 'rewards_train/rejected': '-4.4366', 'rewards_train/margins': '4.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24585', 'examples_per_second': '6.1548', 'grad_norm': '4.9062', 'counters/examples': 126848, 'counters/updates': 7928}
skipping logging after 126864 examples to avoid logging too frequently
skipping logging after 126880 examples to avoid logging too frequently
skipping logging after 126896 examples to avoid logging too frequently
train stats after 126912 examples: {'rewards_train/chosen': '0.48503', 'rewards_train/rejected': '-5.2267', 'rewards_train/margins': '6.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24164', 'examples_per_second': '5.8719', 'grad_norm': '5.5312', 'counters/examples': 126912, 'counters/updates': 7932}
skipping logging after 126928 examples to avoid logging too frequently
skipping logging after 126944 examples to avoid logging too frequently
skipping logging after 126960 examples to avoid logging too frequently
train stats after 126976 examples: {'rewards_train/chosen': '0.30369', 'rewards_train/rejected': '-5.6457', 'rewards_train/margins': '5.6133', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22345', 'examples_per_second': '4.2604', 'grad_norm': '5.1875', 'counters/examples': 126976, 'counters/updates': 7936}
skipping logging after 126992 examples to avoid logging too frequently
skipping logging after 127008 examples to avoid logging too frequently
skipping logging after 127024 examples to avoid logging too frequently
train stats after 127040 examples: {'rewards_train/chosen': '0.24322', 'rewards_train/rejected': '-4.9283', 'rewards_train/margins': '4.8887', 'rewards_train/KL_estimate': '0.78125', 'loss/train': '0.27051', 'examples_per_second': '6.2476', 'grad_norm': '4.875', 'counters/examples': 127040, 'counters/updates': 7940}
skipping logging after 127056 examples to avoid logging too frequently
skipping logging after 127072 examples to avoid logging too frequently
skipping logging after 127088 examples to avoid logging too frequently
train stats after 127104 examples: {'rewards_train/chosen': '0.52253', 'rewards_train/rejected': '-6.5305', 'rewards_train/margins': '7.1172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22192', 'examples_per_second': '4.6506', 'grad_norm': '5.2188', 'counters/examples': 127104, 'counters/updates': 7944}
skipping logging after 127120 examples to avoid logging too frequently
skipping logging after 127136 examples to avoid logging too frequently
skipping logging after 127152 examples to avoid logging too frequently
train stats after 127168 examples: {'rewards_train/chosen': '0.27143', 'rewards_train/rejected': '-6.0659', 'rewards_train/margins': '6.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22766', 'examples_per_second': '5.4754', 'grad_norm': '5.875', 'counters/examples': 127168, 'counters/updates': 7948}
skipping logging after 127184 examples to avoid logging too frequently
skipping logging after 127200 examples to avoid logging too frequently
skipping logging after 127216 examples to avoid logging too frequently
train stats after 127232 examples: {'rewards_train/chosen': '0.84664', 'rewards_train/rejected': '-6.1324', 'rewards_train/margins': '6.9727', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20056', 'examples_per_second': '5.7692', 'grad_norm': '5.375', 'counters/examples': 127232, 'counters/updates': 7952}
skipping logging after 127248 examples to avoid logging too frequently
skipping logging after 127264 examples to avoid logging too frequently
skipping logging after 127280 examples to avoid logging too frequently
train stats after 127296 examples: {'rewards_train/chosen': '0.62558', 'rewards_train/rejected': '-7.4', 'rewards_train/margins': '8.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20477', 'examples_per_second': '5.2636', 'grad_norm': '5.5', 'counters/examples': 127296, 'counters/updates': 7956}
skipping logging after 127312 examples to avoid logging too frequently
skipping logging after 127328 examples to avoid logging too frequently
skipping logging after 127344 examples to avoid logging too frequently
train stats after 127360 examples: {'rewards_train/chosen': '0.24285', 'rewards_train/rejected': '-5.4677', 'rewards_train/margins': '5.7266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28625', 'examples_per_second': '5.1315', 'grad_norm': '5.1875', 'counters/examples': 127360, 'counters/updates': 7960}
skipping logging after 127376 examples to avoid logging too frequently
skipping logging after 127392 examples to avoid logging too frequently
skipping logging after 127408 examples to avoid logging too frequently
train stats after 127424 examples: {'rewards_train/chosen': '0.92638', 'rewards_train/rejected': '-4.4869', 'rewards_train/margins': '5.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21973', 'examples_per_second': '4.0053', 'grad_norm': '5.1875', 'counters/examples': 127424, 'counters/updates': 7964}
skipping logging after 127440 examples to avoid logging too frequently
skipping logging after 127456 examples to avoid logging too frequently
skipping logging after 127472 examples to avoid logging too frequently
train stats after 127488 examples: {'rewards_train/chosen': '0.31865', 'rewards_train/rejected': '-5.6549', 'rewards_train/margins': '5.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25024', 'examples_per_second': '4.4748', 'grad_norm': '5.4062', 'counters/examples': 127488, 'counters/updates': 7968}
skipping logging after 127504 examples to avoid logging too frequently
skipping logging after 127520 examples to avoid logging too frequently
skipping logging after 127536 examples to avoid logging too frequently
train stats after 127552 examples: {'rewards_train/chosen': '0.36794', 'rewards_train/rejected': '-5.2512', 'rewards_train/margins': '5.3711', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27374', 'examples_per_second': '4.3578', 'grad_norm': '5.5938', 'counters/examples': 127552, 'counters/updates': 7972}
skipping logging after 127568 examples to avoid logging too frequently
skipping logging after 127584 examples to avoid logging too frequently
skipping logging after 127600 examples to avoid logging too frequently
train stats after 127616 examples: {'rewards_train/chosen': '0.45015', 'rewards_train/rejected': '-5.6216', 'rewards_train/margins': '6.2266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22546', 'examples_per_second': '5.9502', 'grad_norm': '5.25', 'counters/examples': 127616, 'counters/updates': 7976}
skipping logging after 127632 examples to avoid logging too frequently
skipping logging after 127648 examples to avoid logging too frequently
skipping logging after 127664 examples to avoid logging too frequently
train stats after 127680 examples: {'rewards_train/chosen': '0.65542', 'rewards_train/rejected': '-5.1708', 'rewards_train/margins': '5.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20721', 'examples_per_second': '5.4894', 'grad_norm': '4.4375', 'counters/examples': 127680, 'counters/updates': 7980}
skipping logging after 127696 examples to avoid logging too frequently
skipping logging after 127712 examples to avoid logging too frequently
skipping logging after 127728 examples to avoid logging too frequently
train stats after 127744 examples: {'rewards_train/chosen': '0.24977', 'rewards_train/rejected': '-5.2426', 'rewards_train/margins': '5.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30402', 'examples_per_second': '5.8362', 'grad_norm': '6.0312', 'counters/examples': 127744, 'counters/updates': 7984}
skipping logging after 127760 examples to avoid logging too frequently
skipping logging after 127776 examples to avoid logging too frequently
skipping logging after 127792 examples to avoid logging too frequently
train stats after 127808 examples: {'rewards_train/chosen': '0.34465', 'rewards_train/rejected': '-6.4775', 'rewards_train/margins': '6.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25354', 'examples_per_second': '5.0762', 'grad_norm': '4.875', 'counters/examples': 127808, 'counters/updates': 7988}
skipping logging after 127824 examples to avoid logging too frequently
skipping logging after 127840 examples to avoid logging too frequently
skipping logging after 127856 examples to avoid logging too frequently
train stats after 127872 examples: {'rewards_train/chosen': '0.15752', 'rewards_train/rejected': '-4.9269', 'rewards_train/margins': '4.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27173', 'examples_per_second': '4.926', 'grad_norm': '5.9688', 'counters/examples': 127872, 'counters/updates': 7992}
skipping logging after 127888 examples to avoid logging too frequently
skipping logging after 127904 examples to avoid logging too frequently
skipping logging after 127920 examples to avoid logging too frequently
train stats after 127936 examples: {'rewards_train/chosen': '0.42657', 'rewards_train/rejected': '-6.9086', 'rewards_train/margins': '7.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22498', 'examples_per_second': '4.8184', 'grad_norm': '4.9375', 'counters/examples': 127936, 'counters/updates': 7996}
skipping logging after 127952 examples to avoid logging too frequently
skipping logging after 127968 examples to avoid logging too frequently
skipping logging after 127984 examples to avoid logging too frequently
train stats after 128000 examples: {'rewards_train/chosen': '0.41779', 'rewards_train/rejected': '-6.6026', 'rewards_train/margins': '7.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21362', 'examples_per_second': '4.4703', 'grad_norm': '4', 'counters/examples': 128000, 'counters/updates': 8000}
Running evaluation after 128000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.25s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.16s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:39,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.65s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.47s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:33,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.22s/it]Computing eval metrics:  50%|█████     | 16/32 [00:21<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]
eval after 128000: {'rewards_eval/chosen': '-5.242', 'rewards_eval/rejected': '-5.5274', 'rewards_eval/margins': '0.18213', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46617'}
skipping logging after 128016 examples to avoid logging too frequently
skipping logging after 128032 examples to avoid logging too frequently
skipping logging after 128048 examples to avoid logging too frequently
train stats after 128064 examples: {'rewards_train/chosen': '0.36874', 'rewards_train/rejected': '-5.5505', 'rewards_train/margins': '6.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21075', 'examples_per_second': '4.7291', 'grad_norm': '4.375', 'counters/examples': 128064, 'counters/updates': 8004}
skipping logging after 128080 examples to avoid logging too frequently
skipping logging after 128096 examples to avoid logging too frequently
skipping logging after 128112 examples to avoid logging too frequently
train stats after 128128 examples: {'rewards_train/chosen': '0.64831', 'rewards_train/rejected': '-4.7193', 'rewards_train/margins': '5.2266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21759', 'examples_per_second': '4.6693', 'grad_norm': '4.625', 'counters/examples': 128128, 'counters/updates': 8008}
skipping logging after 128144 examples to avoid logging too frequently
skipping logging after 128160 examples to avoid logging too frequently
skipping logging after 128176 examples to avoid logging too frequently
train stats after 128192 examples: {'rewards_train/chosen': '0.17378', 'rewards_train/rejected': '-5.7129', 'rewards_train/margins': '6.0156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24365', 'examples_per_second': '5.5719', 'grad_norm': '4.9375', 'counters/examples': 128192, 'counters/updates': 8012}
skipping logging after 128208 examples to avoid logging too frequently
skipping logging after 128224 examples to avoid logging too frequently
skipping logging after 128240 examples to avoid logging too frequently
train stats after 128256 examples: {'rewards_train/chosen': '0.31111', 'rewards_train/rejected': '-5.1772', 'rewards_train/margins': '5.2227', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27045', 'examples_per_second': '6.5136', 'grad_norm': '4.4688', 'counters/examples': 128256, 'counters/updates': 8016}
skipping logging after 128272 examples to avoid logging too frequently
skipping logging after 128288 examples to avoid logging too frequently
skipping logging after 128304 examples to avoid logging too frequently
train stats after 128320 examples: {'rewards_train/chosen': '0.38031', 'rewards_train/rejected': '-6.5006', 'rewards_train/margins': '6.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22034', 'examples_per_second': '5.4028', 'grad_norm': '4.2812', 'counters/examples': 128320, 'counters/updates': 8020}
skipping logging after 128336 examples to avoid logging too frequently
skipping logging after 128352 examples to avoid logging too frequently
skipping logging after 128368 examples to avoid logging too frequently
train stats after 128384 examples: {'rewards_train/chosen': '0.13692', 'rewards_train/rejected': '-6.1228', 'rewards_train/margins': '6.2969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23596', 'examples_per_second': '4.7145', 'grad_norm': '4.9688', 'counters/examples': 128384, 'counters/updates': 8024}
skipping logging after 128400 examples to avoid logging too frequently
skipping logging after 128416 examples to avoid logging too frequently
skipping logging after 128432 examples to avoid logging too frequently
train stats after 128448 examples: {'rewards_train/chosen': '0.60901', 'rewards_train/rejected': '-6.8923', 'rewards_train/margins': '7.5781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19891', 'examples_per_second': '4.0216', 'grad_norm': '4.125', 'counters/examples': 128448, 'counters/updates': 8028}
skipping logging after 128464 examples to avoid logging too frequently
skipping logging after 128480 examples to avoid logging too frequently
skipping logging after 128496 examples to avoid logging too frequently
train stats after 128512 examples: {'rewards_train/chosen': '0.37122', 'rewards_train/rejected': '-5.3023', 'rewards_train/margins': '5.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25208', 'examples_per_second': '5.5592', 'grad_norm': '4.75', 'counters/examples': 128512, 'counters/updates': 8032}
skipping logging after 128528 examples to avoid logging too frequently
skipping logging after 128544 examples to avoid logging too frequently
skipping logging after 128560 examples to avoid logging too frequently
train stats after 128576 examples: {'rewards_train/chosen': '0.11605', 'rewards_train/rejected': '-5.3342', 'rewards_train/margins': '5.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27649', 'examples_per_second': '4.552', 'grad_norm': '6.2188', 'counters/examples': 128576, 'counters/updates': 8036}
skipping logging after 128592 examples to avoid logging too frequently
skipping logging after 128608 examples to avoid logging too frequently
skipping logging after 128624 examples to avoid logging too frequently
train stats after 128640 examples: {'rewards_train/chosen': '0.35229', 'rewards_train/rejected': '-6.2663', 'rewards_train/margins': '6.6562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19965', 'examples_per_second': '6.2655', 'grad_norm': '4.2812', 'counters/examples': 128640, 'counters/updates': 8040}
skipping logging after 128656 examples to avoid logging too frequently
skipping logging after 128672 examples to avoid logging too frequently
skipping logging after 128688 examples to avoid logging too frequently
train stats after 128704 examples: {'rewards_train/chosen': '0.35357', 'rewards_train/rejected': '-6.8903', 'rewards_train/margins': '7.3672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27905', 'examples_per_second': '4.6669', 'grad_norm': '5.75', 'counters/examples': 128704, 'counters/updates': 8044}
skipping logging after 128720 examples to avoid logging too frequently
skipping logging after 128736 examples to avoid logging too frequently
skipping logging after 128752 examples to avoid logging too frequently
train stats after 128768 examples: {'rewards_train/chosen': '0.37412', 'rewards_train/rejected': '-5.223', 'rewards_train/margins': '5.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21045', 'examples_per_second': '4.9082', 'grad_norm': '4.5625', 'counters/examples': 128768, 'counters/updates': 8048}
skipping logging after 128784 examples to avoid logging too frequently
skipping logging after 128800 examples to avoid logging too frequently
skipping logging after 128816 examples to avoid logging too frequently
train stats after 128832 examples: {'rewards_train/chosen': '0.33175', 'rewards_train/rejected': '-4.9935', 'rewards_train/margins': '5.2969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25073', 'examples_per_second': '4.6455', 'grad_norm': '5.1875', 'counters/examples': 128832, 'counters/updates': 8052}
skipping logging after 128848 examples to avoid logging too frequently
skipping logging after 128864 examples to avoid logging too frequently
skipping logging after 128880 examples to avoid logging too frequently
train stats after 128896 examples: {'rewards_train/chosen': '0.45613', 'rewards_train/rejected': '-4.8539', 'rewards_train/margins': '5.4844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25671', 'examples_per_second': '5.6406', 'grad_norm': '6.4062', 'counters/examples': 128896, 'counters/updates': 8056}
skipping logging after 128912 examples to avoid logging too frequently
skipping logging after 128928 examples to avoid logging too frequently
skipping logging after 128944 examples to avoid logging too frequently
train stats after 128960 examples: {'rewards_train/chosen': '0.52778', 'rewards_train/rejected': '-5.1627', 'rewards_train/margins': '5.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19257', 'examples_per_second': '4.8671', 'grad_norm': '4.5312', 'counters/examples': 128960, 'counters/updates': 8060}
skipping logging after 128976 examples to avoid logging too frequently
skipping logging after 128992 examples to avoid logging too frequently
skipping logging after 129008 examples to avoid logging too frequently
train stats after 129024 examples: {'rewards_train/chosen': '0.41331', 'rewards_train/rejected': '-6.0663', 'rewards_train/margins': '6.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24091', 'examples_per_second': '4.7582', 'grad_norm': '4.0312', 'counters/examples': 129024, 'counters/updates': 8064}
skipping logging after 129040 examples to avoid logging too frequently
skipping logging after 129056 examples to avoid logging too frequently
skipping logging after 129072 examples to avoid logging too frequently
train stats after 129088 examples: {'rewards_train/chosen': '0.22978', 'rewards_train/rejected': '-6.1202', 'rewards_train/margins': '6.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17206', 'examples_per_second': '4.6683', 'grad_norm': '4.4062', 'counters/examples': 129088, 'counters/updates': 8068}
skipping logging after 129104 examples to avoid logging too frequently
skipping logging after 129120 examples to avoid logging too frequently
skipping logging after 129136 examples to avoid logging too frequently
train stats after 129152 examples: {'rewards_train/chosen': '0.52232', 'rewards_train/rejected': '-5.2423', 'rewards_train/margins': '5.8125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22162', 'examples_per_second': '4.7068', 'grad_norm': '4.4688', 'counters/examples': 129152, 'counters/updates': 8072}
skipping logging after 129168 examples to avoid logging too frequently
skipping logging after 129184 examples to avoid logging too frequently
skipping logging after 129200 examples to avoid logging too frequently
train stats after 129216 examples: {'rewards_train/chosen': '0.25087', 'rewards_train/rejected': '-5.7719', 'rewards_train/margins': '6.1016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2063', 'examples_per_second': '5.3836', 'grad_norm': '4.625', 'counters/examples': 129216, 'counters/updates': 8076}
skipping logging after 129232 examples to avoid logging too frequently
skipping logging after 129248 examples to avoid logging too frequently
skipping logging after 129264 examples to avoid logging too frequently
train stats after 129280 examples: {'rewards_train/chosen': '0.3359', 'rewards_train/rejected': '-8.1591', 'rewards_train/margins': '8.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22839', 'examples_per_second': '4.8989', 'grad_norm': '4.5938', 'counters/examples': 129280, 'counters/updates': 8080}
skipping logging after 129296 examples to avoid logging too frequently
skipping logging after 129312 examples to avoid logging too frequently
skipping logging after 129328 examples to avoid logging too frequently
train stats after 129344 examples: {'rewards_train/chosen': '0.15238', 'rewards_train/rejected': '-6.7369', 'rewards_train/margins': '6.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27209', 'examples_per_second': '4.4744', 'grad_norm': '6.5938', 'counters/examples': 129344, 'counters/updates': 8084}
skipping logging after 129360 examples to avoid logging too frequently
skipping logging after 129376 examples to avoid logging too frequently
skipping logging after 129392 examples to avoid logging too frequently
train stats after 129408 examples: {'rewards_train/chosen': '0.47126', 'rewards_train/rejected': '-5.5061', 'rewards_train/margins': '5.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21509', 'examples_per_second': '5.7041', 'grad_norm': '4.4375', 'counters/examples': 129408, 'counters/updates': 8088}
skipping logging after 129424 examples to avoid logging too frequently
skipping logging after 129440 examples to avoid logging too frequently
skipping logging after 129456 examples to avoid logging too frequently
train stats after 129472 examples: {'rewards_train/chosen': '0.5195', 'rewards_train/rejected': '-5.2492', 'rewards_train/margins': '5.8477', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22113', 'examples_per_second': '4.4876', 'grad_norm': '6.2812', 'counters/examples': 129472, 'counters/updates': 8092}
skipping logging after 129488 examples to avoid logging too frequently
skipping logging after 129504 examples to avoid logging too frequently
skipping logging after 129520 examples to avoid logging too frequently
train stats after 129536 examples: {'rewards_train/chosen': '0.28501', 'rewards_train/rejected': '-6.2572', 'rewards_train/margins': '6.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24805', 'examples_per_second': '4.9966', 'grad_norm': '4.5938', 'counters/examples': 129536, 'counters/updates': 8096}
skipping logging after 129552 examples to avoid logging too frequently
skipping logging after 129568 examples to avoid logging too frequently
skipping logging after 129584 examples to avoid logging too frequently
train stats after 129600 examples: {'rewards_train/chosen': '0.46176', 'rewards_train/rejected': '-7.0348', 'rewards_train/margins': '7.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24384', 'examples_per_second': '4.574', 'grad_norm': '4.7188', 'counters/examples': 129600, 'counters/updates': 8100}
skipping logging after 129616 examples to avoid logging too frequently
skipping logging after 129632 examples to avoid logging too frequently
skipping logging after 129648 examples to avoid logging too frequently
train stats after 129664 examples: {'rewards_train/chosen': '0.52496', 'rewards_train/rejected': '-6.181', 'rewards_train/margins': '6.6562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27972', 'examples_per_second': '4.8253', 'grad_norm': '4.625', 'counters/examples': 129664, 'counters/updates': 8104}
skipping logging after 129680 examples to avoid logging too frequently
skipping logging after 129696 examples to avoid logging too frequently
skipping logging after 129712 examples to avoid logging too frequently
train stats after 129728 examples: {'rewards_train/chosen': '0.26147', 'rewards_train/rejected': '-5.3693', 'rewards_train/margins': '5.5898', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2832', 'examples_per_second': '5.6556', 'grad_norm': '5.8438', 'counters/examples': 129728, 'counters/updates': 8108}
skipping logging after 129744 examples to avoid logging too frequently
skipping logging after 129760 examples to avoid logging too frequently
skipping logging after 129776 examples to avoid logging too frequently
train stats after 129792 examples: {'rewards_train/chosen': '0.72825', 'rewards_train/rejected': '-8.0208', 'rewards_train/margins': '8.6562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23236', 'examples_per_second': '4.7287', 'grad_norm': '4.5312', 'counters/examples': 129792, 'counters/updates': 8112}
skipping logging after 129808 examples to avoid logging too frequently
skipping logging after 129824 examples to avoid logging too frequently
skipping logging after 129840 examples to avoid logging too frequently
train stats after 129856 examples: {'rewards_train/chosen': '0.5044', 'rewards_train/rejected': '-5.9897', 'rewards_train/margins': '6.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19427', 'examples_per_second': '4.7317', 'grad_norm': '4.3438', 'counters/examples': 129856, 'counters/updates': 8116}
skipping logging after 129872 examples to avoid logging too frequently
skipping logging after 129888 examples to avoid logging too frequently
skipping logging after 129904 examples to avoid logging too frequently
train stats after 129920 examples: {'rewards_train/chosen': '0.57978', 'rewards_train/rejected': '-4.2951', 'rewards_train/margins': '4.7852', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24512', 'examples_per_second': '5.4734', 'grad_norm': '5.1562', 'counters/examples': 129920, 'counters/updates': 8120}
skipping logging after 129936 examples to avoid logging too frequently
skipping logging after 129952 examples to avoid logging too frequently
skipping logging after 129968 examples to avoid logging too frequently
train stats after 129984 examples: {'rewards_train/chosen': '0.6518', 'rewards_train/rejected': '-5.3566', 'rewards_train/margins': '5.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21942', 'examples_per_second': '5.9415', 'grad_norm': '4.5312', 'counters/examples': 129984, 'counters/updates': 8124}
skipping logging after 130000 examples to avoid logging too frequently
skipping logging after 130016 examples to avoid logging too frequently
skipping logging after 130032 examples to avoid logging too frequently
train stats after 130048 examples: {'rewards_train/chosen': '0.45413', 'rewards_train/rejected': '-5.352', 'rewards_train/margins': '5.8984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23474', 'examples_per_second': '5.0001', 'grad_norm': '5.75', 'counters/examples': 130048, 'counters/updates': 8128}
skipping logging after 130064 examples to avoid logging too frequently
skipping logging after 130080 examples to avoid logging too frequently
skipping logging after 130096 examples to avoid logging too frequently
train stats after 130112 examples: {'rewards_train/chosen': '0.21855', 'rewards_train/rejected': '-6.2127', 'rewards_train/margins': '6.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25928', 'examples_per_second': '4.7539', 'grad_norm': '5.5938', 'counters/examples': 130112, 'counters/updates': 8132}
skipping logging after 130128 examples to avoid logging too frequently
skipping logging after 130144 examples to avoid logging too frequently
skipping logging after 130160 examples to avoid logging too frequently
train stats after 130176 examples: {'rewards_train/chosen': '0.22377', 'rewards_train/rejected': '-5.6355', 'rewards_train/margins': '5.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25409', 'examples_per_second': '4.7956', 'grad_norm': '5.2188', 'counters/examples': 130176, 'counters/updates': 8136}
skipping logging after 130192 examples to avoid logging too frequently
skipping logging after 130208 examples to avoid logging too frequently
skipping logging after 130224 examples to avoid logging too frequently
train stats after 130240 examples: {'rewards_train/chosen': '0.47595', 'rewards_train/rejected': '-4.1704', 'rewards_train/margins': '4.8711', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29785', 'examples_per_second': '6.0195', 'grad_norm': '5.5', 'counters/examples': 130240, 'counters/updates': 8140}
skipping logging after 130256 examples to avoid logging too frequently
skipping logging after 130272 examples to avoid logging too frequently
skipping logging after 130288 examples to avoid logging too frequently
train stats after 130304 examples: {'rewards_train/chosen': '0.50915', 'rewards_train/rejected': '-5.7229', 'rewards_train/margins': '6.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2674', 'examples_per_second': '4.6641', 'grad_norm': '5.9375', 'counters/examples': 130304, 'counters/updates': 8144}
skipping logging after 130320 examples to avoid logging too frequently
skipping logging after 130336 examples to avoid logging too frequently
skipping logging after 130352 examples to avoid logging too frequently
train stats after 130368 examples: {'rewards_train/chosen': '0.33658', 'rewards_train/rejected': '-4.7485', 'rewards_train/margins': '4.8828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23419', 'examples_per_second': '4.5916', 'grad_norm': '4.5938', 'counters/examples': 130368, 'counters/updates': 8148}
skipping logging after 130384 examples to avoid logging too frequently
skipping logging after 130400 examples to avoid logging too frequently
skipping logging after 130416 examples to avoid logging too frequently
train stats after 130432 examples: {'rewards_train/chosen': '0.34422', 'rewards_train/rejected': '-5.3882', 'rewards_train/margins': '5.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26379', 'examples_per_second': '5.2305', 'grad_norm': '5.0938', 'counters/examples': 130432, 'counters/updates': 8152}
skipping logging after 130448 examples to avoid logging too frequently
skipping logging after 130464 examples to avoid logging too frequently
skipping logging after 130480 examples to avoid logging too frequently
train stats after 130496 examples: {'rewards_train/chosen': '0.33612', 'rewards_train/rejected': '-4.7177', 'rewards_train/margins': '5.2266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26624', 'examples_per_second': '4.7163', 'grad_norm': '4.3125', 'counters/examples': 130496, 'counters/updates': 8156}
skipping logging after 130512 examples to avoid logging too frequently
skipping logging after 130528 examples to avoid logging too frequently
skipping logging after 130544 examples to avoid logging too frequently
train stats after 130560 examples: {'rewards_train/chosen': '0.41962', 'rewards_train/rejected': '-5.3375', 'rewards_train/margins': '5.8125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25348', 'examples_per_second': '5.6139', 'grad_norm': '4.2188', 'counters/examples': 130560, 'counters/updates': 8160}
skipping logging after 130576 examples to avoid logging too frequently
skipping logging after 130592 examples to avoid logging too frequently
skipping logging after 130608 examples to avoid logging too frequently
train stats after 130624 examples: {'rewards_train/chosen': '0.43962', 'rewards_train/rejected': '-6.6239', 'rewards_train/margins': '6.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2171', 'examples_per_second': '6.0155', 'grad_norm': '4.5625', 'counters/examples': 130624, 'counters/updates': 8164}
skipping logging after 130640 examples to avoid logging too frequently
skipping logging after 130656 examples to avoid logging too frequently
skipping logging after 130672 examples to avoid logging too frequently
train stats after 130688 examples: {'rewards_train/chosen': '0.29209', 'rewards_train/rejected': '-5.835', 'rewards_train/margins': '6.0859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25525', 'examples_per_second': '5.2171', 'grad_norm': '5.3125', 'counters/examples': 130688, 'counters/updates': 8168}
skipping logging after 130704 examples to avoid logging too frequently
skipping logging after 130720 examples to avoid logging too frequently
skipping logging after 130736 examples to avoid logging too frequently
train stats after 130752 examples: {'rewards_train/chosen': '0.1606', 'rewards_train/rejected': '-5.8719', 'rewards_train/margins': '6.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.216', 'examples_per_second': '4.5931', 'grad_norm': '4.0938', 'counters/examples': 130752, 'counters/updates': 8172}
skipping logging after 130768 examples to avoid logging too frequently
skipping logging after 130784 examples to avoid logging too frequently
skipping logging after 130800 examples to avoid logging too frequently
train stats after 130816 examples: {'rewards_train/chosen': '0.43877', 'rewards_train/rejected': '-5.4426', 'rewards_train/margins': '6.1172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23981', 'examples_per_second': '5.7841', 'grad_norm': '5.1562', 'counters/examples': 130816, 'counters/updates': 8176}
skipping logging after 130832 examples to avoid logging too frequently
skipping logging after 130848 examples to avoid logging too frequently
skipping logging after 130864 examples to avoid logging too frequently
train stats after 130880 examples: {'rewards_train/chosen': '0.17211', 'rewards_train/rejected': '-6.3165', 'rewards_train/margins': '6.3828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27545', 'examples_per_second': '4.7844', 'grad_norm': '5.4375', 'counters/examples': 130880, 'counters/updates': 8180}
skipping logging after 130896 examples to avoid logging too frequently
skipping logging after 130912 examples to avoid logging too frequently
skipping logging after 130928 examples to avoid logging too frequently
train stats after 130944 examples: {'rewards_train/chosen': '0.28744', 'rewards_train/rejected': '-5.0465', 'rewards_train/margins': '5.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26642', 'examples_per_second': '5.7741', 'grad_norm': '4.7812', 'counters/examples': 130944, 'counters/updates': 8184}
skipping logging after 130960 examples to avoid logging too frequently
skipping logging after 130976 examples to avoid logging too frequently
skipping logging after 130992 examples to avoid logging too frequently
train stats after 131008 examples: {'rewards_train/chosen': '0.51051', 'rewards_train/rejected': '-4.91', 'rewards_train/margins': '5.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26074', 'examples_per_second': '5.034', 'grad_norm': '5.9375', 'counters/examples': 131008, 'counters/updates': 8188}
skipping logging after 131024 examples to avoid logging too frequently
skipping logging after 131040 examples to avoid logging too frequently
skipping logging after 131056 examples to avoid logging too frequently
train stats after 131072 examples: {'rewards_train/chosen': '0.61123', 'rewards_train/rejected': '-6.6735', 'rewards_train/margins': '7.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2243', 'examples_per_second': '5.2329', 'grad_norm': '4.3125', 'counters/examples': 131072, 'counters/updates': 8192}
skipping logging after 131088 examples to avoid logging too frequently
skipping logging after 131104 examples to avoid logging too frequently
skipping logging after 131120 examples to avoid logging too frequently
train stats after 131136 examples: {'rewards_train/chosen': '0.47437', 'rewards_train/rejected': '-5.1694', 'rewards_train/margins': '5.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26215', 'examples_per_second': '4.3228', 'grad_norm': '5.625', 'counters/examples': 131136, 'counters/updates': 8196}
skipping logging after 131152 examples to avoid logging too frequently
skipping logging after 131168 examples to avoid logging too frequently
skipping logging after 131184 examples to avoid logging too frequently
train stats after 131200 examples: {'rewards_train/chosen': '0.56859', 'rewards_train/rejected': '-6.1258', 'rewards_train/margins': '6.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22028', 'examples_per_second': '4.8233', 'grad_norm': '4.6562', 'counters/examples': 131200, 'counters/updates': 8200}
skipping logging after 131216 examples to avoid logging too frequently
skipping logging after 131232 examples to avoid logging too frequently
skipping logging after 131248 examples to avoid logging too frequently
train stats after 131264 examples: {'rewards_train/chosen': '0.52682', 'rewards_train/rejected': '-5.8484', 'rewards_train/margins': '6.2109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21887', 'examples_per_second': '5.51', 'grad_norm': '4.6875', 'counters/examples': 131264, 'counters/updates': 8204}
skipping logging after 131280 examples to avoid logging too frequently
skipping logging after 131296 examples to avoid logging too frequently
skipping logging after 131312 examples to avoid logging too frequently
train stats after 131328 examples: {'rewards_train/chosen': '0.36673', 'rewards_train/rejected': '-5.0636', 'rewards_train/margins': '5.125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24774', 'examples_per_second': '5.4326', 'grad_norm': '5.5312', 'counters/examples': 131328, 'counters/updates': 8208}
skipping logging after 131344 examples to avoid logging too frequently
skipping logging after 131360 examples to avoid logging too frequently
skipping logging after 131376 examples to avoid logging too frequently
train stats after 131392 examples: {'rewards_train/chosen': '0.2459', 'rewards_train/rejected': '-6.0477', 'rewards_train/margins': '6.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21741', 'examples_per_second': '5.461', 'grad_norm': '5.5312', 'counters/examples': 131392, 'counters/updates': 8212}
skipping logging after 131408 examples to avoid logging too frequently
skipping logging after 131424 examples to avoid logging too frequently
skipping logging after 131440 examples to avoid logging too frequently
train stats after 131456 examples: {'rewards_train/chosen': '0.51366', 'rewards_train/rejected': '-5.1414', 'rewards_train/margins': '5.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24805', 'examples_per_second': '4.8965', 'grad_norm': '5.5312', 'counters/examples': 131456, 'counters/updates': 8216}
skipping logging after 131472 examples to avoid logging too frequently
skipping logging after 131488 examples to avoid logging too frequently
skipping logging after 131504 examples to avoid logging too frequently
train stats after 131520 examples: {'rewards_train/chosen': '0.81843', 'rewards_train/rejected': '-7.13', 'rewards_train/margins': '7.7812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18134', 'examples_per_second': '5.0069', 'grad_norm': '4.4375', 'counters/examples': 131520, 'counters/updates': 8220}
skipping logging after 131536 examples to avoid logging too frequently
skipping logging after 131552 examples to avoid logging too frequently
skipping logging after 131568 examples to avoid logging too frequently
train stats after 131584 examples: {'rewards_train/chosen': '0.40119', 'rewards_train/rejected': '-6.6385', 'rewards_train/margins': '6.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23578', 'examples_per_second': '5.3233', 'grad_norm': '4.875', 'counters/examples': 131584, 'counters/updates': 8224}
skipping logging after 131600 examples to avoid logging too frequently
skipping logging after 131616 examples to avoid logging too frequently
skipping logging after 131632 examples to avoid logging too frequently
train stats after 131648 examples: {'rewards_train/chosen': '0.55479', 'rewards_train/rejected': '-5.6704', 'rewards_train/margins': '6.2969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19623', 'examples_per_second': '5.3188', 'grad_norm': '4.3125', 'counters/examples': 131648, 'counters/updates': 8228}
skipping logging after 131664 examples to avoid logging too frequently
skipping logging after 131680 examples to avoid logging too frequently
skipping logging after 131696 examples to avoid logging too frequently
train stats after 131712 examples: {'rewards_train/chosen': '0.52551', 'rewards_train/rejected': '-6.1923', 'rewards_train/margins': '6.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17517', 'examples_per_second': '5.0074', 'grad_norm': '4.2812', 'counters/examples': 131712, 'counters/updates': 8232}
skipping logging after 131728 examples to avoid logging too frequently
skipping logging after 131744 examples to avoid logging too frequently
skipping logging after 131760 examples to avoid logging too frequently
train stats after 131776 examples: {'rewards_train/chosen': '0.24175', 'rewards_train/rejected': '-5.0226', 'rewards_train/margins': '5.1953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23376', 'examples_per_second': '4.2893', 'grad_norm': '4.9688', 'counters/examples': 131776, 'counters/updates': 8236}
skipping logging after 131792 examples to avoid logging too frequently
skipping logging after 131808 examples to avoid logging too frequently
skipping logging after 131824 examples to avoid logging too frequently
train stats after 131840 examples: {'rewards_train/chosen': '0.55938', 'rewards_train/rejected': '-6.7547', 'rewards_train/margins': '7.5469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24384', 'examples_per_second': '5.1084', 'grad_norm': '5.0938', 'counters/examples': 131840, 'counters/updates': 8240}
skipping logging after 131856 examples to avoid logging too frequently
skipping logging after 131872 examples to avoid logging too frequently
skipping logging after 131888 examples to avoid logging too frequently
train stats after 131904 examples: {'rewards_train/chosen': '0.40732', 'rewards_train/rejected': '-4.3684', 'rewards_train/margins': '4.6211', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25372', 'examples_per_second': '4.3593', 'grad_norm': '5.7188', 'counters/examples': 131904, 'counters/updates': 8244}
skipping logging after 131920 examples to avoid logging too frequently
skipping logging after 131936 examples to avoid logging too frequently
skipping logging after 131952 examples to avoid logging too frequently
train stats after 131968 examples: {'rewards_train/chosen': '0.58791', 'rewards_train/rejected': '-5.2582', 'rewards_train/margins': '5.6211', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24805', 'examples_per_second': '5.365', 'grad_norm': '5.375', 'counters/examples': 131968, 'counters/updates': 8248}
skipping logging after 131984 examples to avoid logging too frequently
skipping logging after 132000 examples to avoid logging too frequently
Running evaluation after 132000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:49,  1.60s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:41,  1.40s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:36,  1.25s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.48s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.68s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.49s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:10<00:34,  1.37s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.49s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.41s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:12,  1.44s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.31s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:41<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]
eval after 132000: {'rewards_eval/chosen': '-5.5628', 'rewards_eval/rejected': '-5.8999', 'rewards_eval/margins': '0.20459', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46296'}
skipping logging after 132016 examples to avoid logging too frequently
train stats after 132032 examples: {'rewards_train/chosen': '0.32414', 'rewards_train/rejected': '-4.9893', 'rewards_train/margins': '5.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22961', 'examples_per_second': '5.341', 'grad_norm': '4.1562', 'counters/examples': 132032, 'counters/updates': 8252}
skipping logging after 132048 examples to avoid logging too frequently
skipping logging after 132064 examples to avoid logging too frequently
skipping logging after 132080 examples to avoid logging too frequently
train stats after 132096 examples: {'rewards_train/chosen': '0.23272', 'rewards_train/rejected': '-7.3986', 'rewards_train/margins': '7.5469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24054', 'examples_per_second': '4.9738', 'grad_norm': '4.3125', 'counters/examples': 132096, 'counters/updates': 8256}
skipping logging after 132112 examples to avoid logging too frequently
skipping logging after 132128 examples to avoid logging too frequently
skipping logging after 132144 examples to avoid logging too frequently
train stats after 132160 examples: {'rewards_train/chosen': '0.49937', 'rewards_train/rejected': '-6.9254', 'rewards_train/margins': '7.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20142', 'examples_per_second': '5.018', 'grad_norm': '4.5938', 'counters/examples': 132160, 'counters/updates': 8260}
skipping logging after 132176 examples to avoid logging too frequently
skipping logging after 132192 examples to avoid logging too frequently
skipping logging after 132208 examples to avoid logging too frequently
train stats after 132224 examples: {'rewards_train/chosen': '0.46974', 'rewards_train/rejected': '-6.2088', 'rewards_train/margins': '6.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27588', 'examples_per_second': '4.6845', 'grad_norm': '5.75', 'counters/examples': 132224, 'counters/updates': 8264}
skipping logging after 132240 examples to avoid logging too frequently
skipping logging after 132256 examples to avoid logging too frequently
skipping logging after 132272 examples to avoid logging too frequently
train stats after 132288 examples: {'rewards_train/chosen': '0.43914', 'rewards_train/rejected': '-6.2467', 'rewards_train/margins': '6.8203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21985', 'examples_per_second': '5.5839', 'grad_norm': '5', 'counters/examples': 132288, 'counters/updates': 8268}
skipping logging after 132304 examples to avoid logging too frequently
skipping logging after 132320 examples to avoid logging too frequently
skipping logging after 132336 examples to avoid logging too frequently
train stats after 132352 examples: {'rewards_train/chosen': '0.32106', 'rewards_train/rejected': '-5.1165', 'rewards_train/margins': '5.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23462', 'examples_per_second': '5.1947', 'grad_norm': '4.6562', 'counters/examples': 132352, 'counters/updates': 8272}
skipping logging after 132368 examples to avoid logging too frequently
skipping logging after 132384 examples to avoid logging too frequently
skipping logging after 132400 examples to avoid logging too frequently
train stats after 132416 examples: {'rewards_train/chosen': '0.32043', 'rewards_train/rejected': '-5.7873', 'rewards_train/margins': '6.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25031', 'examples_per_second': '5.6602', 'grad_norm': '4.9375', 'counters/examples': 132416, 'counters/updates': 8276}
skipping logging after 132432 examples to avoid logging too frequently
skipping logging after 132448 examples to avoid logging too frequently
skipping logging after 132464 examples to avoid logging too frequently
train stats after 132480 examples: {'rewards_train/chosen': '0.13653', 'rewards_train/rejected': '-5.9237', 'rewards_train/margins': '6.3594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.229', 'examples_per_second': '5.9284', 'grad_norm': '4.4375', 'counters/examples': 132480, 'counters/updates': 8280}
skipping logging after 132496 examples to avoid logging too frequently
skipping logging after 132512 examples to avoid logging too frequently
skipping logging after 132528 examples to avoid logging too frequently
train stats after 132544 examples: {'rewards_train/chosen': '0.30915', 'rewards_train/rejected': '-4.3519', 'rewards_train/margins': '4.6914', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28638', 'examples_per_second': '4.661', 'grad_norm': '5.5625', 'counters/examples': 132544, 'counters/updates': 8284}
skipping logging after 132560 examples to avoid logging too frequently
skipping logging after 132576 examples to avoid logging too frequently
skipping logging after 132592 examples to avoid logging too frequently
train stats after 132608 examples: {'rewards_train/chosen': '0.5048', 'rewards_train/rejected': '-5.3196', 'rewards_train/margins': '5.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25781', 'examples_per_second': '4.4711', 'grad_norm': '4.875', 'counters/examples': 132608, 'counters/updates': 8288}
skipping logging after 132624 examples to avoid logging too frequently
skipping logging after 132640 examples to avoid logging too frequently
skipping logging after 132656 examples to avoid logging too frequently
train stats after 132672 examples: {'rewards_train/chosen': '0.43068', 'rewards_train/rejected': '-6.2424', 'rewards_train/margins': '6.7656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21277', 'examples_per_second': '5.9144', 'grad_norm': '5.25', 'counters/examples': 132672, 'counters/updates': 8292}
skipping logging after 132688 examples to avoid logging too frequently
skipping logging after 132704 examples to avoid logging too frequently
skipping logging after 132720 examples to avoid logging too frequently
train stats after 132736 examples: {'rewards_train/chosen': '0.54317', 'rewards_train/rejected': '-5.2843', 'rewards_train/margins': '5.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23157', 'examples_per_second': '4.2765', 'grad_norm': '5.5938', 'counters/examples': 132736, 'counters/updates': 8296}
skipping logging after 132752 examples to avoid logging too frequently
skipping logging after 132768 examples to avoid logging too frequently
skipping logging after 132784 examples to avoid logging too frequently
train stats after 132800 examples: {'rewards_train/chosen': '0.42998', 'rewards_train/rejected': '-6.9929', 'rewards_train/margins': '7.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22229', 'examples_per_second': '5.952', 'grad_norm': '5.0938', 'counters/examples': 132800, 'counters/updates': 8300}
skipping logging after 132816 examples to avoid logging too frequently
skipping logging after 132832 examples to avoid logging too frequently
skipping logging after 132848 examples to avoid logging too frequently
train stats after 132864 examples: {'rewards_train/chosen': '0.52326', 'rewards_train/rejected': '-5.5749', 'rewards_train/margins': '6.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2254', 'examples_per_second': '3.7', 'grad_norm': '4.2812', 'counters/examples': 132864, 'counters/updates': 8304}
skipping logging after 132880 examples to avoid logging too frequently
skipping logging after 132896 examples to avoid logging too frequently
skipping logging after 132912 examples to avoid logging too frequently
train stats after 132928 examples: {'rewards_train/chosen': '0.6176', 'rewards_train/rejected': '-6.1698', 'rewards_train/margins': '6.7422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20532', 'examples_per_second': '4.8973', 'grad_norm': '5.9062', 'counters/examples': 132928, 'counters/updates': 8308}
skipping logging after 132944 examples to avoid logging too frequently
skipping logging after 132960 examples to avoid logging too frequently
skipping logging after 132976 examples to avoid logging too frequently
train stats after 132992 examples: {'rewards_train/chosen': '0.40869', 'rewards_train/rejected': '-5.7174', 'rewards_train/margins': '5.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23102', 'examples_per_second': '4.6024', 'grad_norm': '5.0312', 'counters/examples': 132992, 'counters/updates': 8312}
skipping logging after 133008 examples to avoid logging too frequently
skipping logging after 133024 examples to avoid logging too frequently
skipping logging after 133040 examples to avoid logging too frequently
train stats after 133056 examples: {'rewards_train/chosen': '0.43511', 'rewards_train/rejected': '-5.673', 'rewards_train/margins': '6.1406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23907', 'examples_per_second': '5.8609', 'grad_norm': '5.4375', 'counters/examples': 133056, 'counters/updates': 8316}
skipping logging after 133072 examples to avoid logging too frequently
skipping logging after 133088 examples to avoid logging too frequently
skipping logging after 133104 examples to avoid logging too frequently
train stats after 133120 examples: {'rewards_train/chosen': '0.51639', 'rewards_train/rejected': '-5.1084', 'rewards_train/margins': '5.7266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19397', 'examples_per_second': '5.7086', 'grad_norm': '4.7812', 'counters/examples': 133120, 'counters/updates': 8320}
skipping logging after 133136 examples to avoid logging too frequently
skipping logging after 133152 examples to avoid logging too frequently
skipping logging after 133168 examples to avoid logging too frequently
train stats after 133184 examples: {'rewards_train/chosen': '-0.38293', 'rewards_train/rejected': '-5.8652', 'rewards_train/margins': '5.7305', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20471', 'examples_per_second': '4.5328', 'grad_norm': '4.375', 'counters/examples': 133184, 'counters/updates': 8324}
skipping logging after 133200 examples to avoid logging too frequently
skipping logging after 133216 examples to avoid logging too frequently
skipping logging after 133232 examples to avoid logging too frequently
train stats after 133248 examples: {'rewards_train/chosen': '0.4042', 'rewards_train/rejected': '-7.5806', 'rewards_train/margins': '7.9766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22443', 'examples_per_second': '5.09', 'grad_norm': '7.125', 'counters/examples': 133248, 'counters/updates': 8328}
skipping logging after 133264 examples to avoid logging too frequently
skipping logging after 133280 examples to avoid logging too frequently
skipping logging after 133296 examples to avoid logging too frequently
train stats after 133312 examples: {'rewards_train/chosen': '0.25685', 'rewards_train/rejected': '-6.1116', 'rewards_train/margins': '6.2266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23212', 'examples_per_second': '5.4359', 'grad_norm': '5.0938', 'counters/examples': 133312, 'counters/updates': 8332}
skipping logging after 133328 examples to avoid logging too frequently
skipping logging after 133344 examples to avoid logging too frequently
skipping logging after 133360 examples to avoid logging too frequently
train stats after 133376 examples: {'rewards_train/chosen': '0.45782', 'rewards_train/rejected': '-5.6756', 'rewards_train/margins': '6.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23767', 'examples_per_second': '4.9692', 'grad_norm': '5.0938', 'counters/examples': 133376, 'counters/updates': 8336}
skipping logging after 133392 examples to avoid logging too frequently
skipping logging after 133408 examples to avoid logging too frequently
skipping logging after 133424 examples to avoid logging too frequently
train stats after 133440 examples: {'rewards_train/chosen': '0.55418', 'rewards_train/rejected': '-6.0181', 'rewards_train/margins': '6.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21606', 'examples_per_second': '5.8791', 'grad_norm': '4.6875', 'counters/examples': 133440, 'counters/updates': 8340}
skipping logging after 133456 examples to avoid logging too frequently
skipping logging after 133472 examples to avoid logging too frequently
skipping logging after 133488 examples to avoid logging too frequently
train stats after 133504 examples: {'rewards_train/chosen': '0.65081', 'rewards_train/rejected': '-5.3139', 'rewards_train/margins': '5.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20111', 'examples_per_second': '5.5163', 'grad_norm': '4.1875', 'counters/examples': 133504, 'counters/updates': 8344}
skipping logging after 133520 examples to avoid logging too frequently
skipping logging after 133536 examples to avoid logging too frequently
skipping logging after 133552 examples to avoid logging too frequently
train stats after 133568 examples: {'rewards_train/chosen': '0.27746', 'rewards_train/rejected': '-4.0689', 'rewards_train/margins': '4.3203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26428', 'examples_per_second': '5.6106', 'grad_norm': '5.375', 'counters/examples': 133568, 'counters/updates': 8348}
skipping logging after 133584 examples to avoid logging too frequently
skipping logging after 133600 examples to avoid logging too frequently
skipping logging after 133616 examples to avoid logging too frequently
train stats after 133632 examples: {'rewards_train/chosen': '0.37548', 'rewards_train/rejected': '-6.9739', 'rewards_train/margins': '7.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25244', 'examples_per_second': '5.1942', 'grad_norm': '4.8125', 'counters/examples': 133632, 'counters/updates': 8352}
skipping logging after 133648 examples to avoid logging too frequently
skipping logging after 133664 examples to avoid logging too frequently
skipping logging after 133680 examples to avoid logging too frequently
train stats after 133696 examples: {'rewards_train/chosen': '0.37413', 'rewards_train/rejected': '-6.2182', 'rewards_train/margins': '6.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21729', 'examples_per_second': '7.2607', 'grad_norm': '4.9375', 'counters/examples': 133696, 'counters/updates': 8356}
skipping logging after 133712 examples to avoid logging too frequently
skipping logging after 133728 examples to avoid logging too frequently
skipping logging after 133744 examples to avoid logging too frequently
train stats after 133760 examples: {'rewards_train/chosen': '0.3158', 'rewards_train/rejected': '-6.48', 'rewards_train/margins': '6.4141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21771', 'examples_per_second': '5.5251', 'grad_norm': '5.4688', 'counters/examples': 133760, 'counters/updates': 8360}
skipping logging after 133776 examples to avoid logging too frequently
skipping logging after 133792 examples to avoid logging too frequently
skipping logging after 133808 examples to avoid logging too frequently
train stats after 133824 examples: {'rewards_train/chosen': '0.54932', 'rewards_train/rejected': '-5.8644', 'rewards_train/margins': '6.4609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17548', 'examples_per_second': '4.316', 'grad_norm': '4.6562', 'counters/examples': 133824, 'counters/updates': 8364}
skipping logging after 133840 examples to avoid logging too frequently
skipping logging after 133856 examples to avoid logging too frequently
skipping logging after 133872 examples to avoid logging too frequently
train stats after 133888 examples: {'rewards_train/chosen': '0.52629', 'rewards_train/rejected': '-5.0356', 'rewards_train/margins': '5.332', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25854', 'examples_per_second': '5.0412', 'grad_norm': '6.125', 'counters/examples': 133888, 'counters/updates': 8368}
skipping logging after 133904 examples to avoid logging too frequently
skipping logging after 133920 examples to avoid logging too frequently
skipping logging after 133936 examples to avoid logging too frequently
train stats after 133952 examples: {'rewards_train/chosen': '0.030792', 'rewards_train/rejected': '-5.7759', 'rewards_train/margins': '6.3242', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28265', 'examples_per_second': '5.2832', 'grad_norm': '5.1562', 'counters/examples': 133952, 'counters/updates': 8372}
skipping logging after 133968 examples to avoid logging too frequently
skipping logging after 133984 examples to avoid logging too frequently
skipping logging after 134000 examples to avoid logging too frequently
train stats after 134016 examples: {'rewards_train/chosen': '0.49553', 'rewards_train/rejected': '-5.6411', 'rewards_train/margins': '6.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24207', 'examples_per_second': '4.4957', 'grad_norm': '5.1562', 'counters/examples': 134016, 'counters/updates': 8376}
skipping logging after 134032 examples to avoid logging too frequently
skipping logging after 134048 examples to avoid logging too frequently
skipping logging after 134064 examples to avoid logging too frequently
train stats after 134080 examples: {'rewards_train/chosen': '0.23955', 'rewards_train/rejected': '-6.2178', 'rewards_train/margins': '6.4531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27435', 'examples_per_second': '4.5235', 'grad_norm': '6.1562', 'counters/examples': 134080, 'counters/updates': 8380}
skipping logging after 134096 examples to avoid logging too frequently
skipping logging after 134112 examples to avoid logging too frequently
skipping logging after 134128 examples to avoid logging too frequently
train stats after 134144 examples: {'rewards_train/chosen': '0.20302', 'rewards_train/rejected': '-5.3313', 'rewards_train/margins': '5.6445', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21674', 'examples_per_second': '5.2532', 'grad_norm': '4.5625', 'counters/examples': 134144, 'counters/updates': 8384}
skipping logging after 134160 examples to avoid logging too frequently
skipping logging after 134176 examples to avoid logging too frequently
skipping logging after 134192 examples to avoid logging too frequently
train stats after 134208 examples: {'rewards_train/chosen': '0.60669', 'rewards_train/rejected': '-4.9711', 'rewards_train/margins': '5.6641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21735', 'examples_per_second': '5.0593', 'grad_norm': '5.375', 'counters/examples': 134208, 'counters/updates': 8388}
skipping logging after 134224 examples to avoid logging too frequently
skipping logging after 134240 examples to avoid logging too frequently
skipping logging after 134256 examples to avoid logging too frequently
train stats after 134272 examples: {'rewards_train/chosen': '0.52866', 'rewards_train/rejected': '-6.0381', 'rewards_train/margins': '6.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20679', 'examples_per_second': '5.4742', 'grad_norm': '4.7812', 'counters/examples': 134272, 'counters/updates': 8392}
skipping logging after 134288 examples to avoid logging too frequently
skipping logging after 134304 examples to avoid logging too frequently
skipping logging after 134320 examples to avoid logging too frequently
train stats after 134336 examples: {'rewards_train/chosen': '0.23275', 'rewards_train/rejected': '-7.3273', 'rewards_train/margins': '7.5938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24347', 'examples_per_second': '6.6066', 'grad_norm': '4.9375', 'counters/examples': 134336, 'counters/updates': 8396}
skipping logging after 134352 examples to avoid logging too frequently
skipping logging after 134368 examples to avoid logging too frequently
skipping logging after 134384 examples to avoid logging too frequently
train stats after 134400 examples: {'rewards_train/chosen': '0.53119', 'rewards_train/rejected': '-5.6055', 'rewards_train/margins': '5.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25995', 'examples_per_second': '5.8014', 'grad_norm': '5.5625', 'counters/examples': 134400, 'counters/updates': 8400}
skipping logging after 134416 examples to avoid logging too frequently
skipping logging after 134432 examples to avoid logging too frequently
skipping logging after 134448 examples to avoid logging too frequently
train stats after 134464 examples: {'rewards_train/chosen': '0.39627', 'rewards_train/rejected': '-6.5306', 'rewards_train/margins': '6.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22205', 'examples_per_second': '4.3762', 'grad_norm': '4.4375', 'counters/examples': 134464, 'counters/updates': 8404}
skipping logging after 134480 examples to avoid logging too frequently
skipping logging after 134496 examples to avoid logging too frequently
skipping logging after 134512 examples to avoid logging too frequently
train stats after 134528 examples: {'rewards_train/chosen': '0.46547', 'rewards_train/rejected': '-5.158', 'rewards_train/margins': '5.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25751', 'examples_per_second': '4.6747', 'grad_norm': '5.3125', 'counters/examples': 134528, 'counters/updates': 8408}
skipping logging after 134544 examples to avoid logging too frequently
skipping logging after 134560 examples to avoid logging too frequently
skipping logging after 134576 examples to avoid logging too frequently
train stats after 134592 examples: {'rewards_train/chosen': '0.23028', 'rewards_train/rejected': '-5.226', 'rewards_train/margins': '5.4141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22778', 'examples_per_second': '5.4511', 'grad_norm': '4.7188', 'counters/examples': 134592, 'counters/updates': 8412}
skipping logging after 134608 examples to avoid logging too frequently
skipping logging after 134624 examples to avoid logging too frequently
skipping logging after 134640 examples to avoid logging too frequently
train stats after 134656 examples: {'rewards_train/chosen': '0.32451', 'rewards_train/rejected': '-6.9671', 'rewards_train/margins': '7.4609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22437', 'examples_per_second': '4.8305', 'grad_norm': '4.8125', 'counters/examples': 134656, 'counters/updates': 8416}
skipping logging after 134672 examples to avoid logging too frequently
skipping logging after 134688 examples to avoid logging too frequently
skipping logging after 134704 examples to avoid logging too frequently
train stats after 134720 examples: {'rewards_train/chosen': '0.12422', 'rewards_train/rejected': '-7.2092', 'rewards_train/margins': '7.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25409', 'examples_per_second': '4.8462', 'grad_norm': '5.75', 'counters/examples': 134720, 'counters/updates': 8420}
skipping logging after 134736 examples to avoid logging too frequently
skipping logging after 134752 examples to avoid logging too frequently
skipping logging after 134768 examples to avoid logging too frequently
train stats after 134784 examples: {'rewards_train/chosen': '0.18691', 'rewards_train/rejected': '-4.0159', 'rewards_train/margins': '4.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24695', 'examples_per_second': '5.9103', 'grad_norm': '4.9062', 'counters/examples': 134784, 'counters/updates': 8424}
skipping logging after 134800 examples to avoid logging too frequently
skipping logging after 134816 examples to avoid logging too frequently
skipping logging after 134832 examples to avoid logging too frequently
train stats after 134848 examples: {'rewards_train/chosen': '0.48793', 'rewards_train/rejected': '-5.4165', 'rewards_train/margins': '6', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24194', 'examples_per_second': '5.9017', 'grad_norm': '5.1562', 'counters/examples': 134848, 'counters/updates': 8428}
skipping logging after 134864 examples to avoid logging too frequently
skipping logging after 134880 examples to avoid logging too frequently
skipping logging after 134896 examples to avoid logging too frequently
train stats after 134912 examples: {'rewards_train/chosen': '0.44405', 'rewards_train/rejected': '-6.2592', 'rewards_train/margins': '6.6875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22778', 'examples_per_second': '5.3905', 'grad_norm': '4.4688', 'counters/examples': 134912, 'counters/updates': 8432}
skipping logging after 134928 examples to avoid logging too frequently
skipping logging after 134944 examples to avoid logging too frequently
skipping logging after 134960 examples to avoid logging too frequently
train stats after 134976 examples: {'rewards_train/chosen': '0.33148', 'rewards_train/rejected': '-5.5547', 'rewards_train/margins': '5.8203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22418', 'examples_per_second': '4.6979', 'grad_norm': '4.5312', 'counters/examples': 134976, 'counters/updates': 8436}
skipping logging after 134992 examples to avoid logging too frequently
skipping logging after 135008 examples to avoid logging too frequently
skipping logging after 135024 examples to avoid logging too frequently
train stats after 135040 examples: {'rewards_train/chosen': '0.66168', 'rewards_train/rejected': '-5.4', 'rewards_train/margins': '5.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19275', 'examples_per_second': '4.2365', 'grad_norm': '4.2188', 'counters/examples': 135040, 'counters/updates': 8440}
skipping logging after 135056 examples to avoid logging too frequently
skipping logging after 135072 examples to avoid logging too frequently
skipping logging after 135088 examples to avoid logging too frequently
train stats after 135104 examples: {'rewards_train/chosen': '0.074578', 'rewards_train/rejected': '-4.8619', 'rewards_train/margins': '4.8672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26477', 'examples_per_second': '5.1663', 'grad_norm': '5.0312', 'counters/examples': 135104, 'counters/updates': 8444}
skipping logging after 135120 examples to avoid logging too frequently
skipping logging after 135136 examples to avoid logging too frequently
skipping logging after 135152 examples to avoid logging too frequently
train stats after 135168 examples: {'rewards_train/chosen': '0.20972', 'rewards_train/rejected': '-5.442', 'rewards_train/margins': '5.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23621', 'examples_per_second': '3.9816', 'grad_norm': '5.1875', 'counters/examples': 135168, 'counters/updates': 8448}
skipping logging after 135184 examples to avoid logging too frequently
skipping logging after 135200 examples to avoid logging too frequently
skipping logging after 135216 examples to avoid logging too frequently
train stats after 135232 examples: {'rewards_train/chosen': '0.39948', 'rewards_train/rejected': '-6.1389', 'rewards_train/margins': '6.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18768', 'examples_per_second': '5.6474', 'grad_norm': '4', 'counters/examples': 135232, 'counters/updates': 8452}
skipping logging after 135248 examples to avoid logging too frequently
skipping logging after 135264 examples to avoid logging too frequently
skipping logging after 135280 examples to avoid logging too frequently
train stats after 135296 examples: {'rewards_train/chosen': '0.3862', 'rewards_train/rejected': '-7.6052', 'rewards_train/margins': '8.0859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23187', 'examples_per_second': '4.4022', 'grad_norm': '4.8125', 'counters/examples': 135296, 'counters/updates': 8456}
skipping logging after 135312 examples to avoid logging too frequently
skipping logging after 135328 examples to avoid logging too frequently
skipping logging after 135344 examples to avoid logging too frequently
train stats after 135360 examples: {'rewards_train/chosen': '0.49719', 'rewards_train/rejected': '-5.5959', 'rewards_train/margins': '6.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25824', 'examples_per_second': '5.442', 'grad_norm': '5.3438', 'counters/examples': 135360, 'counters/updates': 8460}
skipping logging after 135376 examples to avoid logging too frequently
skipping logging after 135392 examples to avoid logging too frequently
skipping logging after 135408 examples to avoid logging too frequently
train stats after 135424 examples: {'rewards_train/chosen': '0.43031', 'rewards_train/rejected': '-6.5093', 'rewards_train/margins': '7.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21729', 'examples_per_second': '5.0644', 'grad_norm': '5.4062', 'counters/examples': 135424, 'counters/updates': 8464}
skipping logging after 135440 examples to avoid logging too frequently
skipping logging after 135456 examples to avoid logging too frequently
skipping logging after 135472 examples to avoid logging too frequently
train stats after 135488 examples: {'rewards_train/chosen': '0.51661', 'rewards_train/rejected': '-6.4013', 'rewards_train/margins': '6.8984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26526', 'examples_per_second': '5.2219', 'grad_norm': '5.6562', 'counters/examples': 135488, 'counters/updates': 8468}
skipping logging after 135504 examples to avoid logging too frequently
skipping logging after 135520 examples to avoid logging too frequently
skipping logging after 135536 examples to avoid logging too frequently
train stats after 135552 examples: {'rewards_train/chosen': '0.76444', 'rewards_train/rejected': '-6.0777', 'rewards_train/margins': '6.9453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20032', 'examples_per_second': '4.0623', 'grad_norm': '4.6875', 'counters/examples': 135552, 'counters/updates': 8472}
skipping logging after 135568 examples to avoid logging too frequently
skipping logging after 135584 examples to avoid logging too frequently
skipping logging after 135600 examples to avoid logging too frequently
train stats after 135616 examples: {'rewards_train/chosen': '0.47196', 'rewards_train/rejected': '-6.7349', 'rewards_train/margins': '6.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1568', 'examples_per_second': '4.6994', 'grad_norm': '5.375', 'counters/examples': 135616, 'counters/updates': 8476}
skipping logging after 135632 examples to avoid logging too frequently
skipping logging after 135648 examples to avoid logging too frequently
skipping logging after 135664 examples to avoid logging too frequently
train stats after 135680 examples: {'rewards_train/chosen': '0.24403', 'rewards_train/rejected': '-5.7662', 'rewards_train/margins': '6.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20844', 'examples_per_second': '6.0909', 'grad_norm': '4.5312', 'counters/examples': 135680, 'counters/updates': 8480}
skipping logging after 135696 examples to avoid logging too frequently
skipping logging after 135712 examples to avoid logging too frequently
skipping logging after 135728 examples to avoid logging too frequently
train stats after 135744 examples: {'rewards_train/chosen': '0.23748', 'rewards_train/rejected': '-6.1696', 'rewards_train/margins': '6.1719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22546', 'examples_per_second': '5.1639', 'grad_norm': '3.8906', 'counters/examples': 135744, 'counters/updates': 8484}
skipping logging after 135760 examples to avoid logging too frequently
skipping logging after 135776 examples to avoid logging too frequently
skipping logging after 135792 examples to avoid logging too frequently
train stats after 135808 examples: {'rewards_train/chosen': '0.22252', 'rewards_train/rejected': '-5.8549', 'rewards_train/margins': '6.375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26324', 'examples_per_second': '5.235', 'grad_norm': '5.375', 'counters/examples': 135808, 'counters/updates': 8488}
skipping logging after 135824 examples to avoid logging too frequently
skipping logging after 135840 examples to avoid logging too frequently
skipping logging after 135856 examples to avoid logging too frequently
train stats after 135872 examples: {'rewards_train/chosen': '0.44239', 'rewards_train/rejected': '-6.8657', 'rewards_train/margins': '7.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22357', 'examples_per_second': '5.2684', 'grad_norm': '4.9375', 'counters/examples': 135872, 'counters/updates': 8492}
skipping logging after 135888 examples to avoid logging too frequently
skipping logging after 135904 examples to avoid logging too frequently
skipping logging after 135920 examples to avoid logging too frequently
train stats after 135936 examples: {'rewards_train/chosen': '0.039364', 'rewards_train/rejected': '-5.0711', 'rewards_train/margins': '5.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27502', 'examples_per_second': '6.2295', 'grad_norm': '4.625', 'counters/examples': 135936, 'counters/updates': 8496}
skipping logging after 135952 examples to avoid logging too frequently
skipping logging after 135968 examples to avoid logging too frequently
skipping logging after 135984 examples to avoid logging too frequently
train stats after 136000 examples: {'rewards_train/chosen': '0.3686', 'rewards_train/rejected': '-5.9289', 'rewards_train/margins': '6.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17877', 'examples_per_second': '4.2738', 'grad_norm': '4.8125', 'counters/examples': 136000, 'counters/updates': 8500}
Running evaluation after 136000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.25s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.16s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:39,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.65s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.47s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:33,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.51s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.40s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:30,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:21<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.31s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.18s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]
eval after 136000: {'rewards_eval/chosen': '-5.9264', 'rewards_eval/rejected': '-6.314', 'rewards_eval/margins': '0.22852', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46047'}
skipping logging after 136016 examples to avoid logging too frequently
skipping logging after 136032 examples to avoid logging too frequently
skipping logging after 136048 examples to avoid logging too frequently
train stats after 136064 examples: {'rewards_train/chosen': '0.29548', 'rewards_train/rejected': '-6.0647', 'rewards_train/margins': '6.3242', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25385', 'examples_per_second': '6.6805', 'grad_norm': '5.1875', 'counters/examples': 136064, 'counters/updates': 8504}
skipping logging after 136080 examples to avoid logging too frequently
skipping logging after 136096 examples to avoid logging too frequently
skipping logging after 136112 examples to avoid logging too frequently
train stats after 136128 examples: {'rewards_train/chosen': '0.58948', 'rewards_train/rejected': '-6.1408', 'rewards_train/margins': '6.7656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23712', 'examples_per_second': '4.7844', 'grad_norm': '6.0312', 'counters/examples': 136128, 'counters/updates': 8508}
skipping logging after 136144 examples to avoid logging too frequently
skipping logging after 136160 examples to avoid logging too frequently
skipping logging after 136176 examples to avoid logging too frequently
train stats after 136192 examples: {'rewards_train/chosen': '0.18042', 'rewards_train/rejected': '-4.9536', 'rewards_train/margins': '5.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2428', 'examples_per_second': '5.6416', 'grad_norm': '5.3438', 'counters/examples': 136192, 'counters/updates': 8512}
skipping logging after 136208 examples to avoid logging too frequently
skipping logging after 136224 examples to avoid logging too frequently
skipping logging after 136240 examples to avoid logging too frequently
train stats after 136256 examples: {'rewards_train/chosen': '0.35004', 'rewards_train/rejected': '-5.4198', 'rewards_train/margins': '5.6211', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20911', 'examples_per_second': '5.7866', 'grad_norm': '5.1562', 'counters/examples': 136256, 'counters/updates': 8516}
skipping logging after 136272 examples to avoid logging too frequently
skipping logging after 136288 examples to avoid logging too frequently
skipping logging after 136304 examples to avoid logging too frequently
train stats after 136320 examples: {'rewards_train/chosen': '0.35068', 'rewards_train/rejected': '-6.8757', 'rewards_train/margins': '7.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22107', 'examples_per_second': '5.4889', 'grad_norm': '5.3438', 'counters/examples': 136320, 'counters/updates': 8520}
skipping logging after 136336 examples to avoid logging too frequently
skipping logging after 136352 examples to avoid logging too frequently
skipping logging after 136368 examples to avoid logging too frequently
train stats after 136384 examples: {'rewards_train/chosen': '0.51717', 'rewards_train/rejected': '-5.3463', 'rewards_train/margins': '6.125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24304', 'examples_per_second': '5.8448', 'grad_norm': '6.0312', 'counters/examples': 136384, 'counters/updates': 8524}
skipping logging after 136400 examples to avoid logging too frequently
skipping logging after 136416 examples to avoid logging too frequently
skipping logging after 136432 examples to avoid logging too frequently
train stats after 136448 examples: {'rewards_train/chosen': '0.3707', 'rewards_train/rejected': '-6.5935', 'rewards_train/margins': '7.0234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19232', 'examples_per_second': '4.07', 'grad_norm': '6.3438', 'counters/examples': 136448, 'counters/updates': 8528}
skipping logging after 136464 examples to avoid logging too frequently
skipping logging after 136480 examples to avoid logging too frequently
skipping logging after 136496 examples to avoid logging too frequently
train stats after 136512 examples: {'rewards_train/chosen': '0.5617', 'rewards_train/rejected': '-4.5799', 'rewards_train/margins': '5.207', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20386', 'examples_per_second': '4.7726', 'grad_norm': '4.3438', 'counters/examples': 136512, 'counters/updates': 8532}
skipping logging after 136528 examples to avoid logging too frequently
skipping logging after 136544 examples to avoid logging too frequently
skipping logging after 136560 examples to avoid logging too frequently
train stats after 136576 examples: {'rewards_train/chosen': '0.084085', 'rewards_train/rejected': '-5.3787', 'rewards_train/margins': '5.4648', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24445', 'examples_per_second': '5.3728', 'grad_norm': '5.2812', 'counters/examples': 136576, 'counters/updates': 8536}
skipping logging after 136592 examples to avoid logging too frequently
skipping logging after 136608 examples to avoid logging too frequently
skipping logging after 136624 examples to avoid logging too frequently
train stats after 136640 examples: {'rewards_train/chosen': '-0.079902', 'rewards_train/rejected': '-7.3318', 'rewards_train/margins': '7.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26306', 'examples_per_second': '4.4856', 'grad_norm': '6.0312', 'counters/examples': 136640, 'counters/updates': 8540}
skipping logging after 136656 examples to avoid logging too frequently
skipping logging after 136672 examples to avoid logging too frequently
skipping logging after 136688 examples to avoid logging too frequently
train stats after 136704 examples: {'rewards_train/chosen': '0.60593', 'rewards_train/rejected': '-6.8726', 'rewards_train/margins': '7.4219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23181', 'examples_per_second': '4.6', 'grad_norm': '5.4375', 'counters/examples': 136704, 'counters/updates': 8544}
skipping logging after 136720 examples to avoid logging too frequently
skipping logging after 136736 examples to avoid logging too frequently
skipping logging after 136752 examples to avoid logging too frequently
train stats after 136768 examples: {'rewards_train/chosen': '0.30836', 'rewards_train/rejected': '-5.0603', 'rewards_train/margins': '5.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28772', 'examples_per_second': '4.9773', 'grad_norm': '5.375', 'counters/examples': 136768, 'counters/updates': 8548}
skipping logging after 136784 examples to avoid logging too frequently
skipping logging after 136800 examples to avoid logging too frequently
skipping logging after 136816 examples to avoid logging too frequently
train stats after 136832 examples: {'rewards_train/chosen': '0.34178', 'rewards_train/rejected': '-5.5314', 'rewards_train/margins': '5.4141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21307', 'examples_per_second': '5.8601', 'grad_norm': '4.8125', 'counters/examples': 136832, 'counters/updates': 8552}
skipping logging after 136848 examples to avoid logging too frequently
skipping logging after 136864 examples to avoid logging too frequently
skipping logging after 136880 examples to avoid logging too frequently
train stats after 136896 examples: {'rewards_train/chosen': '0.21508', 'rewards_train/rejected': '-5.7466', 'rewards_train/margins': '5.9766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2348', 'examples_per_second': '5.8532', 'grad_norm': '4.9062', 'counters/examples': 136896, 'counters/updates': 8556}
skipping logging after 136912 examples to avoid logging too frequently
skipping logging after 136928 examples to avoid logging too frequently
skipping logging after 136944 examples to avoid logging too frequently
train stats after 136960 examples: {'rewards_train/chosen': '0.091734', 'rewards_train/rejected': '-6.1396', 'rewards_train/margins': '6.125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2644', 'examples_per_second': '4.7171', 'grad_norm': '5.375', 'counters/examples': 136960, 'counters/updates': 8560}
skipping logging after 136976 examples to avoid logging too frequently
skipping logging after 136992 examples to avoid logging too frequently
skipping logging after 137008 examples to avoid logging too frequently
train stats after 137024 examples: {'rewards_train/chosen': '0.21394', 'rewards_train/rejected': '-5.5536', 'rewards_train/margins': '5.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24548', 'examples_per_second': '5.3653', 'grad_norm': '4.5625', 'counters/examples': 137024, 'counters/updates': 8564}
skipping logging after 137040 examples to avoid logging too frequently
skipping logging after 137056 examples to avoid logging too frequently
skipping logging after 137072 examples to avoid logging too frequently
train stats after 137088 examples: {'rewards_train/chosen': '0.023696', 'rewards_train/rejected': '-4.9034', 'rewards_train/margins': '4.8164', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27679', 'examples_per_second': '4.8538', 'grad_norm': '5.2812', 'counters/examples': 137088, 'counters/updates': 8568}
skipping logging after 137104 examples to avoid logging too frequently
skipping logging after 137120 examples to avoid logging too frequently
skipping logging after 137136 examples to avoid logging too frequently
train stats after 137152 examples: {'rewards_train/chosen': '0.29578', 'rewards_train/rejected': '-4.9935', 'rewards_train/margins': '5.332', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26776', 'examples_per_second': '4.8391', 'grad_norm': '4.9062', 'counters/examples': 137152, 'counters/updates': 8572}
skipping logging after 137168 examples to avoid logging too frequently
skipping logging after 137184 examples to avoid logging too frequently
skipping logging after 137200 examples to avoid logging too frequently
train stats after 137216 examples: {'rewards_train/chosen': '0.5038', 'rewards_train/rejected': '-6.1954', 'rewards_train/margins': '6.5938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27209', 'examples_per_second': '4.6957', 'grad_norm': '5.1875', 'counters/examples': 137216, 'counters/updates': 8576}
skipping logging after 137232 examples to avoid logging too frequently
skipping logging after 137248 examples to avoid logging too frequently
skipping logging after 137264 examples to avoid logging too frequently
train stats after 137280 examples: {'rewards_train/chosen': '-0.12919', 'rewards_train/rejected': '-5.4889', 'rewards_train/margins': '5.3633', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26141', 'examples_per_second': '5.4341', 'grad_norm': '4.3438', 'counters/examples': 137280, 'counters/updates': 8580}
skipping logging after 137296 examples to avoid logging too frequently
skipping logging after 137312 examples to avoid logging too frequently
skipping logging after 137328 examples to avoid logging too frequently
train stats after 137344 examples: {'rewards_train/chosen': '0.23778', 'rewards_train/rejected': '-7.3751', 'rewards_train/margins': '7.6328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24597', 'examples_per_second': '6.5201', 'grad_norm': '5.0938', 'counters/examples': 137344, 'counters/updates': 8584}
skipping logging after 137360 examples to avoid logging too frequently
skipping logging after 137376 examples to avoid logging too frequently
skipping logging after 137392 examples to avoid logging too frequently
train stats after 137408 examples: {'rewards_train/chosen': '0.27908', 'rewards_train/rejected': '-5.9933', 'rewards_train/margins': '6.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25977', 'examples_per_second': '5.4443', 'grad_norm': '4.75', 'counters/examples': 137408, 'counters/updates': 8588}
skipping logging after 137424 examples to avoid logging too frequently
skipping logging after 137440 examples to avoid logging too frequently
skipping logging after 137456 examples to avoid logging too frequently
train stats after 137472 examples: {'rewards_train/chosen': '0.80542', 'rewards_train/rejected': '-6.2919', 'rewards_train/margins': '7.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.16272', 'examples_per_second': '4.1629', 'grad_norm': '4.0938', 'counters/examples': 137472, 'counters/updates': 8592}
skipping logging after 137488 examples to avoid logging too frequently
skipping logging after 137504 examples to avoid logging too frequently
skipping logging after 137520 examples to avoid logging too frequently
train stats after 137536 examples: {'rewards_train/chosen': '0.36964', 'rewards_train/rejected': '-4.8591', 'rewards_train/margins': '5.2266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26306', 'examples_per_second': '5.4312', 'grad_norm': '4.5312', 'counters/examples': 137536, 'counters/updates': 8596}
skipping logging after 137552 examples to avoid logging too frequently
skipping logging after 137568 examples to avoid logging too frequently
skipping logging after 137584 examples to avoid logging too frequently
train stats after 137600 examples: {'rewards_train/chosen': '0.54235', 'rewards_train/rejected': '-5.5338', 'rewards_train/margins': '6.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18701', 'examples_per_second': '4.8623', 'grad_norm': '4.8125', 'counters/examples': 137600, 'counters/updates': 8600}
skipping logging after 137616 examples to avoid logging too frequently
skipping logging after 137632 examples to avoid logging too frequently
skipping logging after 137648 examples to avoid logging too frequently
train stats after 137664 examples: {'rewards_train/chosen': '0.36117', 'rewards_train/rejected': '-5.5717', 'rewards_train/margins': '5.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22186', 'examples_per_second': '5.4307', 'grad_norm': '5.2812', 'counters/examples': 137664, 'counters/updates': 8604}
skipping logging after 137680 examples to avoid logging too frequently
skipping logging after 137696 examples to avoid logging too frequently
skipping logging after 137712 examples to avoid logging too frequently
train stats after 137728 examples: {'rewards_train/chosen': '0.64153', 'rewards_train/rejected': '-6.0211', 'rewards_train/margins': '6.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20148', 'examples_per_second': '4.6364', 'grad_norm': '5.5938', 'counters/examples': 137728, 'counters/updates': 8608}
skipping logging after 137744 examples to avoid logging too frequently
skipping logging after 137760 examples to avoid logging too frequently
skipping logging after 137776 examples to avoid logging too frequently
train stats after 137792 examples: {'rewards_train/chosen': '0.45604', 'rewards_train/rejected': '-6.9464', 'rewards_train/margins': '7.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1994', 'examples_per_second': '5.5485', 'grad_norm': '4.75', 'counters/examples': 137792, 'counters/updates': 8612}
skipping logging after 137808 examples to avoid logging too frequently
skipping logging after 137824 examples to avoid logging too frequently
skipping logging after 137840 examples to avoid logging too frequently
train stats after 137856 examples: {'rewards_train/chosen': '0.21102', 'rewards_train/rejected': '-6.3197', 'rewards_train/margins': '6.4258', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24646', 'examples_per_second': '5.4932', 'grad_norm': '4.5625', 'counters/examples': 137856, 'counters/updates': 8616}
skipping logging after 137872 examples to avoid logging too frequently
skipping logging after 137888 examples to avoid logging too frequently
skipping logging after 137904 examples to avoid logging too frequently
train stats after 137920 examples: {'rewards_train/chosen': '0.41738', 'rewards_train/rejected': '-5.3803', 'rewards_train/margins': '5.7578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23755', 'examples_per_second': '5.7929', 'grad_norm': '4.7812', 'counters/examples': 137920, 'counters/updates': 8620}
skipping logging after 137936 examples to avoid logging too frequently
skipping logging after 137952 examples to avoid logging too frequently
skipping logging after 137968 examples to avoid logging too frequently
train stats after 137984 examples: {'rewards_train/chosen': '-0.023067', 'rewards_train/rejected': '-6.0101', 'rewards_train/margins': '6.0547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23987', 'examples_per_second': '4.3605', 'grad_norm': '5.4062', 'counters/examples': 137984, 'counters/updates': 8624}
skipping logging after 138000 examples to avoid logging too frequently
skipping logging after 138016 examples to avoid logging too frequently
skipping logging after 138032 examples to avoid logging too frequently
train stats after 138048 examples: {'rewards_train/chosen': '0.51357', 'rewards_train/rejected': '-6.8647', 'rewards_train/margins': '7.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20728', 'examples_per_second': '4.6743', 'grad_norm': '4.375', 'counters/examples': 138048, 'counters/updates': 8628}
skipping logging after 138064 examples to avoid logging too frequently
skipping logging after 138080 examples to avoid logging too frequently
skipping logging after 138096 examples to avoid logging too frequently
train stats after 138112 examples: {'rewards_train/chosen': '0.41296', 'rewards_train/rejected': '-6.3596', 'rewards_train/margins': '6.7422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18768', 'examples_per_second': '5.4226', 'grad_norm': '4.75', 'counters/examples': 138112, 'counters/updates': 8632}
skipping logging after 138128 examples to avoid logging too frequently
skipping logging after 138144 examples to avoid logging too frequently
skipping logging after 138160 examples to avoid logging too frequently
train stats after 138176 examples: {'rewards_train/chosen': '0.16198', 'rewards_train/rejected': '-6.6358', 'rewards_train/margins': '6.7852', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26111', 'examples_per_second': '4.9328', 'grad_norm': '5.9375', 'counters/examples': 138176, 'counters/updates': 8636}
skipping logging after 138192 examples to avoid logging too frequently
skipping logging after 138208 examples to avoid logging too frequently
skipping logging after 138224 examples to avoid logging too frequently
train stats after 138240 examples: {'rewards_train/chosen': '0.13728', 'rewards_train/rejected': '-6.1253', 'rewards_train/margins': '6.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23627', 'examples_per_second': '5.9022', 'grad_norm': '6.4375', 'counters/examples': 138240, 'counters/updates': 8640}
skipping logging after 138256 examples to avoid logging too frequently
skipping logging after 138272 examples to avoid logging too frequently
skipping logging after 138288 examples to avoid logging too frequently
train stats after 138304 examples: {'rewards_train/chosen': '0.083071', 'rewards_train/rejected': '-5.3538', 'rewards_train/margins': '5.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26593', 'examples_per_second': '4.9875', 'grad_norm': '5.4688', 'counters/examples': 138304, 'counters/updates': 8644}
skipping logging after 138320 examples to avoid logging too frequently
skipping logging after 138336 examples to avoid logging too frequently
skipping logging after 138352 examples to avoid logging too frequently
train stats after 138368 examples: {'rewards_train/chosen': '0.47208', 'rewards_train/rejected': '-6.4851', 'rewards_train/margins': '7.8203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28955', 'examples_per_second': '6.7804', 'grad_norm': '5.1875', 'counters/examples': 138368, 'counters/updates': 8648}
skipping logging after 138384 examples to avoid logging too frequently
skipping logging after 138400 examples to avoid logging too frequently
skipping logging after 138416 examples to avoid logging too frequently
train stats after 138432 examples: {'rewards_train/chosen': '0.54179', 'rewards_train/rejected': '-4.9717', 'rewards_train/margins': '5.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22583', 'examples_per_second': '4.9573', 'grad_norm': '4.5312', 'counters/examples': 138432, 'counters/updates': 8652}
skipping logging after 138448 examples to avoid logging too frequently
skipping logging after 138464 examples to avoid logging too frequently
skipping logging after 138480 examples to avoid logging too frequently
train stats after 138496 examples: {'rewards_train/chosen': '0.21091', 'rewards_train/rejected': '-5.8324', 'rewards_train/margins': '5.6328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23492', 'examples_per_second': '4.2535', 'grad_norm': '4.3438', 'counters/examples': 138496, 'counters/updates': 8656}
skipping logging after 138512 examples to avoid logging too frequently
skipping logging after 138528 examples to avoid logging too frequently
skipping logging after 138544 examples to avoid logging too frequently
train stats after 138560 examples: {'rewards_train/chosen': '0.50749', 'rewards_train/rejected': '-6.5909', 'rewards_train/margins': '7.1016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19647', 'examples_per_second': '4.4274', 'grad_norm': '4.625', 'counters/examples': 138560, 'counters/updates': 8660}
skipping logging after 138576 examples to avoid logging too frequently
skipping logging after 138592 examples to avoid logging too frequently
skipping logging after 138608 examples to avoid logging too frequently
train stats after 138624 examples: {'rewards_train/chosen': '0.31072', 'rewards_train/rejected': '-6.1386', 'rewards_train/margins': '6.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23273', 'examples_per_second': '4.5623', 'grad_norm': '5.375', 'counters/examples': 138624, 'counters/updates': 8664}
skipping logging after 138640 examples to avoid logging too frequently
skipping logging after 138656 examples to avoid logging too frequently
skipping logging after 138672 examples to avoid logging too frequently
train stats after 138688 examples: {'rewards_train/chosen': '-0.047339', 'rewards_train/rejected': '-6.6022', 'rewards_train/margins': '6.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.31689', 'examples_per_second': '5.0297', 'grad_norm': '6.2188', 'counters/examples': 138688, 'counters/updates': 8668}
skipping logging after 138704 examples to avoid logging too frequently
skipping logging after 138720 examples to avoid logging too frequently
skipping logging after 138736 examples to avoid logging too frequently
train stats after 138752 examples: {'rewards_train/chosen': '0.55145', 'rewards_train/rejected': '-4.5773', 'rewards_train/margins': '5.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2066', 'examples_per_second': '5.9211', 'grad_norm': '4.2812', 'counters/examples': 138752, 'counters/updates': 8672}
skipping logging after 138768 examples to avoid logging too frequently
skipping logging after 138784 examples to avoid logging too frequently
skipping logging after 138800 examples to avoid logging too frequently
train stats after 138816 examples: {'rewards_train/chosen': '0.40852', 'rewards_train/rejected': '-4.5777', 'rewards_train/margins': '4.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2652', 'examples_per_second': '6.6841', 'grad_norm': '5.375', 'counters/examples': 138816, 'counters/updates': 8676}
skipping logging after 138832 examples to avoid logging too frequently
skipping logging after 138848 examples to avoid logging too frequently
skipping logging after 138864 examples to avoid logging too frequently
train stats after 138880 examples: {'rewards_train/chosen': '0.3514', 'rewards_train/rejected': '-6.5031', 'rewards_train/margins': '7.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19348', 'examples_per_second': '5.3037', 'grad_norm': '4.8125', 'counters/examples': 138880, 'counters/updates': 8680}
skipping logging after 138896 examples to avoid logging too frequently
skipping logging after 138912 examples to avoid logging too frequently
skipping logging after 138928 examples to avoid logging too frequently
train stats after 138944 examples: {'rewards_train/chosen': '0.40912', 'rewards_train/rejected': '-6.9662', 'rewards_train/margins': '7.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24554', 'examples_per_second': '4.522', 'grad_norm': '4.6562', 'counters/examples': 138944, 'counters/updates': 8684}
skipping logging after 138960 examples to avoid logging too frequently
skipping logging after 138976 examples to avoid logging too frequently
skipping logging after 138992 examples to avoid logging too frequently
train stats after 139008 examples: {'rewards_train/chosen': '0.13525', 'rewards_train/rejected': '-5.8975', 'rewards_train/margins': '6.0547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26825', 'examples_per_second': '5.6103', 'grad_norm': '4.5938', 'counters/examples': 139008, 'counters/updates': 8688}
skipping logging after 139024 examples to avoid logging too frequently
skipping logging after 139040 examples to avoid logging too frequently
skipping logging after 139056 examples to avoid logging too frequently
train stats after 139072 examples: {'rewards_train/chosen': '0.53464', 'rewards_train/rejected': '-4.8578', 'rewards_train/margins': '5.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22418', 'examples_per_second': '6.099', 'grad_norm': '4.4688', 'counters/examples': 139072, 'counters/updates': 8692}
skipping logging after 139088 examples to avoid logging too frequently
skipping logging after 139104 examples to avoid logging too frequently
skipping logging after 139120 examples to avoid logging too frequently
train stats after 139136 examples: {'rewards_train/chosen': '0.15145', 'rewards_train/rejected': '-7.9962', 'rewards_train/margins': '8.0234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27985', 'examples_per_second': '5.8084', 'grad_norm': '5.4062', 'counters/examples': 139136, 'counters/updates': 8696}
skipping logging after 139152 examples to avoid logging too frequently
skipping logging after 139168 examples to avoid logging too frequently
skipping logging after 139184 examples to avoid logging too frequently
train stats after 139200 examples: {'rewards_train/chosen': '0.60249', 'rewards_train/rejected': '-5.5882', 'rewards_train/margins': '6.2227', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23944', 'examples_per_second': '4.8535', 'grad_norm': '5.1875', 'counters/examples': 139200, 'counters/updates': 8700}
skipping logging after 139216 examples to avoid logging too frequently
skipping logging after 139232 examples to avoid logging too frequently
skipping logging after 139248 examples to avoid logging too frequently
train stats after 139264 examples: {'rewards_train/chosen': '0.15511', 'rewards_train/rejected': '-4.8606', 'rewards_train/margins': '5.1133', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29138', 'examples_per_second': '4.9534', 'grad_norm': '5.6562', 'counters/examples': 139264, 'counters/updates': 8704}
skipping logging after 139280 examples to avoid logging too frequently
skipping logging after 139296 examples to avoid logging too frequently
skipping logging after 139312 examples to avoid logging too frequently
train stats after 139328 examples: {'rewards_train/chosen': '0.063851', 'rewards_train/rejected': '-6.0929', 'rewards_train/margins': '6.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27008', 'examples_per_second': '6.0853', 'grad_norm': '5.1875', 'counters/examples': 139328, 'counters/updates': 8708}
skipping logging after 139344 examples to avoid logging too frequently
skipping logging after 139360 examples to avoid logging too frequently
skipping logging after 139376 examples to avoid logging too frequently
train stats after 139392 examples: {'rewards_train/chosen': '-0.095928', 'rewards_train/rejected': '-5.0777', 'rewards_train/margins': '5.1055', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28674', 'examples_per_second': '4.1018', 'grad_norm': '4.875', 'counters/examples': 139392, 'counters/updates': 8712}
skipping logging after 139408 examples to avoid logging too frequently
skipping logging after 139424 examples to avoid logging too frequently
skipping logging after 139440 examples to avoid logging too frequently
train stats after 139456 examples: {'rewards_train/chosen': '-0.0013987', 'rewards_train/rejected': '-5.2261', 'rewards_train/margins': '5.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22974', 'examples_per_second': '5.4485', 'grad_norm': '4.625', 'counters/examples': 139456, 'counters/updates': 8716}
skipping logging after 139472 examples to avoid logging too frequently
skipping logging after 139488 examples to avoid logging too frequently
skipping logging after 139504 examples to avoid logging too frequently
train stats after 139520 examples: {'rewards_train/chosen': '0.4933', 'rewards_train/rejected': '-5.8733', 'rewards_train/margins': '6.3594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21454', 'examples_per_second': '4.8257', 'grad_norm': '5.6562', 'counters/examples': 139520, 'counters/updates': 8720}
skipping logging after 139536 examples to avoid logging too frequently
skipping logging after 139552 examples to avoid logging too frequently
skipping logging after 139568 examples to avoid logging too frequently
train stats after 139584 examples: {'rewards_train/chosen': '0.25746', 'rewards_train/rejected': '-6.084', 'rewards_train/margins': '6.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26099', 'examples_per_second': '5.7565', 'grad_norm': '4.5938', 'counters/examples': 139584, 'counters/updates': 8724}
skipping logging after 139600 examples to avoid logging too frequently
skipping logging after 139616 examples to avoid logging too frequently
skipping logging after 139632 examples to avoid logging too frequently
train stats after 139648 examples: {'rewards_train/chosen': '0.38505', 'rewards_train/rejected': '-6.7797', 'rewards_train/margins': '7.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22217', 'examples_per_second': '5.2069', 'grad_norm': '3.9062', 'counters/examples': 139648, 'counters/updates': 8728}
skipping logging after 139664 examples to avoid logging too frequently
skipping logging after 139680 examples to avoid logging too frequently
skipping logging after 139696 examples to avoid logging too frequently
train stats after 139712 examples: {'rewards_train/chosen': '0.52725', 'rewards_train/rejected': '-5.251', 'rewards_train/margins': '5.707', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23047', 'examples_per_second': '5.1611', 'grad_norm': '4.625', 'counters/examples': 139712, 'counters/updates': 8732}
skipping logging after 139728 examples to avoid logging too frequently
skipping logging after 139744 examples to avoid logging too frequently
skipping logging after 139760 examples to avoid logging too frequently
train stats after 139776 examples: {'rewards_train/chosen': '0.15847', 'rewards_train/rejected': '-6.542', 'rewards_train/margins': '6.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26709', 'examples_per_second': '4.6033', 'grad_norm': '5.0938', 'counters/examples': 139776, 'counters/updates': 8736}
skipping logging after 139792 examples to avoid logging too frequently
skipping logging after 139808 examples to avoid logging too frequently
skipping logging after 139824 examples to avoid logging too frequently
train stats after 139840 examples: {'rewards_train/chosen': '0.14234', 'rewards_train/rejected': '-5.1971', 'rewards_train/margins': '5.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20612', 'examples_per_second': '4.7195', 'grad_norm': '4.4688', 'counters/examples': 139840, 'counters/updates': 8740}
skipping logging after 139856 examples to avoid logging too frequently
skipping logging after 139872 examples to avoid logging too frequently
skipping logging after 139888 examples to avoid logging too frequently
train stats after 139904 examples: {'rewards_train/chosen': '0.28961', 'rewards_train/rejected': '-6.9051', 'rewards_train/margins': '6.6367', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28058', 'examples_per_second': '5.4779', 'grad_norm': '5.5938', 'counters/examples': 139904, 'counters/updates': 8744}
skipping logging after 139920 examples to avoid logging too frequently
skipping logging after 139936 examples to avoid logging too frequently
skipping logging after 139952 examples to avoid logging too frequently
train stats after 139968 examples: {'rewards_train/chosen': '0.042766', 'rewards_train/rejected': '-6.0526', 'rewards_train/margins': '6.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30206', 'examples_per_second': '6.1982', 'grad_norm': '5.4062', 'counters/examples': 139968, 'counters/updates': 8748}
skipping logging after 139984 examples to avoid logging too frequently
skipping logging after 140000 examples to avoid logging too frequently
Running evaluation after 140000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:49,  1.60s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:41,  1.39s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:35,  1.24s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.47s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.68s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.49s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:10<00:34,  1.37s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.53s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.49s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:31,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.28s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.31s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:41<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]
eval after 140000: {'rewards_eval/chosen': '-5.3346', 'rewards_eval/rejected': '-5.649', 'rewards_eval/margins': '0.1709', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46241'}
skipping logging after 140016 examples to avoid logging too frequently
train stats after 140032 examples: {'rewards_train/chosen': '0.44001', 'rewards_train/rejected': '-5.2478', 'rewards_train/margins': '5.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21472', 'examples_per_second': '5.297', 'grad_norm': '5.3438', 'counters/examples': 140032, 'counters/updates': 8752}
skipping logging after 140048 examples to avoid logging too frequently
skipping logging after 140064 examples to avoid logging too frequently
skipping logging after 140080 examples to avoid logging too frequently
train stats after 140096 examples: {'rewards_train/chosen': '0.33922', 'rewards_train/rejected': '-5.8739', 'rewards_train/margins': '6.1172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26501', 'examples_per_second': '5.0179', 'grad_norm': '4.9375', 'counters/examples': 140096, 'counters/updates': 8756}
skipping logging after 140112 examples to avoid logging too frequently
skipping logging after 140128 examples to avoid logging too frequently
skipping logging after 140144 examples to avoid logging too frequently
train stats after 140160 examples: {'rewards_train/chosen': '0.39073', 'rewards_train/rejected': '-5.1118', 'rewards_train/margins': '5.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22217', 'examples_per_second': '5.6588', 'grad_norm': '5.2812', 'counters/examples': 140160, 'counters/updates': 8760}
skipping logging after 140176 examples to avoid logging too frequently
skipping logging after 140192 examples to avoid logging too frequently
skipping logging after 140208 examples to avoid logging too frequently
train stats after 140224 examples: {'rewards_train/chosen': '0.41674', 'rewards_train/rejected': '-7.5838', 'rewards_train/margins': '8.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23749', 'examples_per_second': '5.4554', 'grad_norm': '5.1562', 'counters/examples': 140224, 'counters/updates': 8764}
skipping logging after 140240 examples to avoid logging too frequently
skipping logging after 140256 examples to avoid logging too frequently
skipping logging after 140272 examples to avoid logging too frequently
train stats after 140288 examples: {'rewards_train/chosen': '0.066586', 'rewards_train/rejected': '-5.2006', 'rewards_train/margins': '5.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28204', 'examples_per_second': '5.5431', 'grad_norm': '5.7812', 'counters/examples': 140288, 'counters/updates': 8768}
skipping logging after 140304 examples to avoid logging too frequently
skipping logging after 140320 examples to avoid logging too frequently
skipping logging after 140336 examples to avoid logging too frequently
train stats after 140352 examples: {'rewards_train/chosen': '0.20293', 'rewards_train/rejected': '-7.3333', 'rewards_train/margins': '7.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2417', 'examples_per_second': '5.414', 'grad_norm': '5.4375', 'counters/examples': 140352, 'counters/updates': 8772}
skipping logging after 140368 examples to avoid logging too frequently
skipping logging after 140384 examples to avoid logging too frequently
skipping logging after 140400 examples to avoid logging too frequently
train stats after 140416 examples: {'rewards_train/chosen': '0.085882', 'rewards_train/rejected': '-5.3602', 'rewards_train/margins': '5.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27368', 'examples_per_second': '5.8886', 'grad_norm': '5.5312', 'counters/examples': 140416, 'counters/updates': 8776}
skipping logging after 140432 examples to avoid logging too frequently
skipping logging after 140448 examples to avoid logging too frequently
skipping logging after 140464 examples to avoid logging too frequently
train stats after 140480 examples: {'rewards_train/chosen': '0.56651', 'rewards_train/rejected': '-4.7185', 'rewards_train/margins': '5.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25659', 'examples_per_second': '6.2039', 'grad_norm': '5.4062', 'counters/examples': 140480, 'counters/updates': 8780}
skipping logging after 140496 examples to avoid logging too frequently
skipping logging after 140512 examples to avoid logging too frequently
skipping logging after 140528 examples to avoid logging too frequently
train stats after 140544 examples: {'rewards_train/chosen': '0.51547', 'rewards_train/rejected': '-5.0424', 'rewards_train/margins': '5.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19434', 'examples_per_second': '5.2597', 'grad_norm': '4.4375', 'counters/examples': 140544, 'counters/updates': 8784}
skipping logging after 140560 examples to avoid logging too frequently
skipping logging after 140576 examples to avoid logging too frequently
skipping logging after 140592 examples to avoid logging too frequently
train stats after 140608 examples: {'rewards_train/chosen': '0.1562', 'rewards_train/rejected': '-6.2968', 'rewards_train/margins': '6.3594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27234', 'examples_per_second': '5.0242', 'grad_norm': '5.375', 'counters/examples': 140608, 'counters/updates': 8788}
skipping logging after 140624 examples to avoid logging too frequently
skipping logging after 140640 examples to avoid logging too frequently
skipping logging after 140656 examples to avoid logging too frequently
train stats after 140672 examples: {'rewards_train/chosen': '0.17098', 'rewards_train/rejected': '-5.1909', 'rewards_train/margins': '5.2617', 'rewards_train/KL_estimate': '0', 'loss/train': '0.297', 'examples_per_second': '4.9316', 'grad_norm': '5.4688', 'counters/examples': 140672, 'counters/updates': 8792}
skipping logging after 140688 examples to avoid logging too frequently
skipping logging after 140704 examples to avoid logging too frequently
skipping logging after 140720 examples to avoid logging too frequently
train stats after 140736 examples: {'rewards_train/chosen': '0.15635', 'rewards_train/rejected': '-5.6682', 'rewards_train/margins': '5.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20386', 'examples_per_second': '5.4969', 'grad_norm': '3.9219', 'counters/examples': 140736, 'counters/updates': 8796}
skipping logging after 140752 examples to avoid logging too frequently
skipping logging after 140768 examples to avoid logging too frequently
skipping logging after 140784 examples to avoid logging too frequently
train stats after 140800 examples: {'rewards_train/chosen': '0.54889', 'rewards_train/rejected': '-5.2902', 'rewards_train/margins': '5.793', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20709', 'examples_per_second': '4.9686', 'grad_norm': '5.4062', 'counters/examples': 140800, 'counters/updates': 8800}
skipping logging after 140816 examples to avoid logging too frequently
skipping logging after 140832 examples to avoid logging too frequently
skipping logging after 140848 examples to avoid logging too frequently
train stats after 140864 examples: {'rewards_train/chosen': '0.20109', 'rewards_train/rejected': '-6.812', 'rewards_train/margins': '6.9766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25629', 'examples_per_second': '4.8187', 'grad_norm': '4.9062', 'counters/examples': 140864, 'counters/updates': 8804}
skipping logging after 140880 examples to avoid logging too frequently
skipping logging after 140896 examples to avoid logging too frequently
skipping logging after 140912 examples to avoid logging too frequently
train stats after 140928 examples: {'rewards_train/chosen': '0.54192', 'rewards_train/rejected': '-7.0833', 'rewards_train/margins': '7.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17908', 'examples_per_second': '4.474', 'grad_norm': '3.6094', 'counters/examples': 140928, 'counters/updates': 8808}
skipping logging after 140944 examples to avoid logging too frequently
skipping logging after 140960 examples to avoid logging too frequently
skipping logging after 140976 examples to avoid logging too frequently
train stats after 140992 examples: {'rewards_train/chosen': '0.19911', 'rewards_train/rejected': '-4.7783', 'rewards_train/margins': '5.082', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28741', 'examples_per_second': '6.1864', 'grad_norm': '7.875', 'counters/examples': 140992, 'counters/updates': 8812}
skipping logging after 141008 examples to avoid logging too frequently
skipping logging after 141024 examples to avoid logging too frequently
skipping logging after 141040 examples to avoid logging too frequently
train stats after 141056 examples: {'rewards_train/chosen': '0.17959', 'rewards_train/rejected': '-5.8276', 'rewards_train/margins': '6.0859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2337', 'examples_per_second': '4.9149', 'grad_norm': '5.8125', 'counters/examples': 141056, 'counters/updates': 8816}
skipping logging after 141072 examples to avoid logging too frequently
skipping logging after 141088 examples to avoid logging too frequently
skipping logging after 141104 examples to avoid logging too frequently
train stats after 141120 examples: {'rewards_train/chosen': '0.69168', 'rewards_train/rejected': '-6.13', 'rewards_train/margins': '6.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20575', 'examples_per_second': '4.655', 'grad_norm': '3.9531', 'counters/examples': 141120, 'counters/updates': 8820}
skipping logging after 141136 examples to avoid logging too frequently
skipping logging after 141152 examples to avoid logging too frequently
skipping logging after 141168 examples to avoid logging too frequently
train stats after 141184 examples: {'rewards_train/chosen': '0.053583', 'rewards_train/rejected': '-5.5159', 'rewards_train/margins': '5.5391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25238', 'examples_per_second': '6.1519', 'grad_norm': '5.4062', 'counters/examples': 141184, 'counters/updates': 8824}
skipping logging after 141200 examples to avoid logging too frequently
skipping logging after 141216 examples to avoid logging too frequently
skipping logging after 141232 examples to avoid logging too frequently
train stats after 141248 examples: {'rewards_train/chosen': '0.20448', 'rewards_train/rejected': '-4.8305', 'rewards_train/margins': '5.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26025', 'examples_per_second': '5.0358', 'grad_norm': '4.9062', 'counters/examples': 141248, 'counters/updates': 8828}
skipping logging after 141264 examples to avoid logging too frequently
skipping logging after 141280 examples to avoid logging too frequently
skipping logging after 141296 examples to avoid logging too frequently
train stats after 141312 examples: {'rewards_train/chosen': '0.075307', 'rewards_train/rejected': '-6.2335', 'rewards_train/margins': '6.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30029', 'examples_per_second': '4.9539', 'grad_norm': '5.5', 'counters/examples': 141312, 'counters/updates': 8832}
skipping logging after 141328 examples to avoid logging too frequently
skipping logging after 141344 examples to avoid logging too frequently
skipping logging after 141360 examples to avoid logging too frequently
train stats after 141376 examples: {'rewards_train/chosen': '0.53192', 'rewards_train/rejected': '-5.5619', 'rewards_train/margins': '5.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20581', 'examples_per_second': '4.7422', 'grad_norm': '4.0938', 'counters/examples': 141376, 'counters/updates': 8836}
skipping logging after 141392 examples to avoid logging too frequently
skipping logging after 141408 examples to avoid logging too frequently
skipping logging after 141424 examples to avoid logging too frequently
train stats after 141440 examples: {'rewards_train/chosen': '0.23642', 'rewards_train/rejected': '-6.4236', 'rewards_train/margins': '6.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24622', 'examples_per_second': '4.7663', 'grad_norm': '4.8125', 'counters/examples': 141440, 'counters/updates': 8840}
skipping logging after 141456 examples to avoid logging too frequently
skipping logging after 141472 examples to avoid logging too frequently
skipping logging after 141488 examples to avoid logging too frequently
train stats after 141504 examples: {'rewards_train/chosen': '0.51427', 'rewards_train/rejected': '-5.5793', 'rewards_train/margins': '5.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24506', 'examples_per_second': '4.8579', 'grad_norm': '5.125', 'counters/examples': 141504, 'counters/updates': 8844}
skipping logging after 141520 examples to avoid logging too frequently
skipping logging after 141536 examples to avoid logging too frequently
skipping logging after 141552 examples to avoid logging too frequently
train stats after 141568 examples: {'rewards_train/chosen': '0.50943', 'rewards_train/rejected': '-5.2148', 'rewards_train/margins': '5.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22015', 'examples_per_second': '6.2117', 'grad_norm': '4.4688', 'counters/examples': 141568, 'counters/updates': 8848}
skipping logging after 141584 examples to avoid logging too frequently
skipping logging after 141600 examples to avoid logging too frequently
skipping logging after 141616 examples to avoid logging too frequently
train stats after 141632 examples: {'rewards_train/chosen': '0.19449', 'rewards_train/rejected': '-6.1375', 'rewards_train/margins': '6.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21417', 'examples_per_second': '5.8364', 'grad_norm': '5.5', 'counters/examples': 141632, 'counters/updates': 8852}
skipping logging after 141648 examples to avoid logging too frequently
skipping logging after 141664 examples to avoid logging too frequently
skipping logging after 141680 examples to avoid logging too frequently
train stats after 141696 examples: {'rewards_train/chosen': '0.3344', 'rewards_train/rejected': '-5.8919', 'rewards_train/margins': '6.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24548', 'examples_per_second': '5.7243', 'grad_norm': '5', 'counters/examples': 141696, 'counters/updates': 8856}
skipping logging after 141712 examples to avoid logging too frequently
skipping logging after 141728 examples to avoid logging too frequently
skipping logging after 141744 examples to avoid logging too frequently
train stats after 141760 examples: {'rewards_train/chosen': '0.72016', 'rewards_train/rejected': '-5.5616', 'rewards_train/margins': '6.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19965', 'examples_per_second': '4.5762', 'grad_norm': '5.0312', 'counters/examples': 141760, 'counters/updates': 8860}
skipping logging after 141776 examples to avoid logging too frequently
skipping logging after 141792 examples to avoid logging too frequently
skipping logging after 141808 examples to avoid logging too frequently
train stats after 141824 examples: {'rewards_train/chosen': '0.56175', 'rewards_train/rejected': '-4.9982', 'rewards_train/margins': '5.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24347', 'examples_per_second': '5.88', 'grad_norm': '5.5938', 'counters/examples': 141824, 'counters/updates': 8864}
skipping logging after 141840 examples to avoid logging too frequently
skipping logging after 141856 examples to avoid logging too frequently
skipping logging after 141872 examples to avoid logging too frequently
train stats after 141888 examples: {'rewards_train/chosen': '0.71266', 'rewards_train/rejected': '-5.4503', 'rewards_train/margins': '6.125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2373', 'examples_per_second': '5.1005', 'grad_norm': '5.3438', 'counters/examples': 141888, 'counters/updates': 8868}
skipping logging after 141904 examples to avoid logging too frequently
skipping logging after 141920 examples to avoid logging too frequently
skipping logging after 141936 examples to avoid logging too frequently
train stats after 141952 examples: {'rewards_train/chosen': '0.38185', 'rewards_train/rejected': '-4.7214', 'rewards_train/margins': '5.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24664', 'examples_per_second': '5.7534', 'grad_norm': '5.0312', 'counters/examples': 141952, 'counters/updates': 8872}
skipping logging after 141968 examples to avoid logging too frequently
skipping logging after 141984 examples to avoid logging too frequently
skipping logging after 142000 examples to avoid logging too frequently
train stats after 142016 examples: {'rewards_train/chosen': '0.3026', 'rewards_train/rejected': '-5.9598', 'rewards_train/margins': '6.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21436', 'examples_per_second': '5.4773', 'grad_norm': '5.5312', 'counters/examples': 142016, 'counters/updates': 8876}
skipping logging after 142032 examples to avoid logging too frequently
skipping logging after 142048 examples to avoid logging too frequently
skipping logging after 142064 examples to avoid logging too frequently
train stats after 142080 examples: {'rewards_train/chosen': '0.57275', 'rewards_train/rejected': '-5.1186', 'rewards_train/margins': '5.6641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21747', 'examples_per_second': '5.2864', 'grad_norm': '4.1875', 'counters/examples': 142080, 'counters/updates': 8880}
skipping logging after 142096 examples to avoid logging too frequently
skipping logging after 142112 examples to avoid logging too frequently
skipping logging after 142128 examples to avoid logging too frequently
train stats after 142144 examples: {'rewards_train/chosen': '0.53169', 'rewards_train/rejected': '-6.7531', 'rewards_train/margins': '7.2109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18085', 'examples_per_second': '5.1979', 'grad_norm': '3.9688', 'counters/examples': 142144, 'counters/updates': 8884}
skipping logging after 142160 examples to avoid logging too frequently
skipping logging after 142176 examples to avoid logging too frequently
skipping logging after 142192 examples to avoid logging too frequently
train stats after 142208 examples: {'rewards_train/chosen': '0.3836', 'rewards_train/rejected': '-6.0535', 'rewards_train/margins': '6.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22662', 'examples_per_second': '5.0327', 'grad_norm': '5.5938', 'counters/examples': 142208, 'counters/updates': 8888}
skipping logging after 142224 examples to avoid logging too frequently
skipping logging after 142240 examples to avoid logging too frequently
skipping logging after 142256 examples to avoid logging too frequently
train stats after 142272 examples: {'rewards_train/chosen': '-0.076277', 'rewards_train/rejected': '-6.5789', 'rewards_train/margins': '6.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29596', 'examples_per_second': '5.5365', 'grad_norm': '5.375', 'counters/examples': 142272, 'counters/updates': 8892}
skipping logging after 142288 examples to avoid logging too frequently
skipping logging after 142304 examples to avoid logging too frequently
skipping logging after 142320 examples to avoid logging too frequently
train stats after 142336 examples: {'rewards_train/chosen': '0.015538', 'rewards_train/rejected': '-5.1667', 'rewards_train/margins': '4.9453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22559', 'examples_per_second': '5.8448', 'grad_norm': '4.5312', 'counters/examples': 142336, 'counters/updates': 8896}
skipping logging after 142352 examples to avoid logging too frequently
skipping logging after 142368 examples to avoid logging too frequently
skipping logging after 142384 examples to avoid logging too frequently
train stats after 142400 examples: {'rewards_train/chosen': '0.10781', 'rewards_train/rejected': '-6.5042', 'rewards_train/margins': '6.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2359', 'examples_per_second': '4.6939', 'grad_norm': '4.5', 'counters/examples': 142400, 'counters/updates': 8900}
skipping logging after 142416 examples to avoid logging too frequently
skipping logging after 142432 examples to avoid logging too frequently
skipping logging after 142448 examples to avoid logging too frequently
train stats after 142464 examples: {'rewards_train/chosen': '0.2939', 'rewards_train/rejected': '-5.6744', 'rewards_train/margins': '5.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24994', 'examples_per_second': '6.5104', 'grad_norm': '4.75', 'counters/examples': 142464, 'counters/updates': 8904}
skipping logging after 142480 examples to avoid logging too frequently
skipping logging after 142496 examples to avoid logging too frequently
skipping logging after 142512 examples to avoid logging too frequently
train stats after 142528 examples: {'rewards_train/chosen': '0.34596', 'rewards_train/rejected': '-5.2795', 'rewards_train/margins': '5.6016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22998', 'examples_per_second': '4.9285', 'grad_norm': '6.2812', 'counters/examples': 142528, 'counters/updates': 8908}
skipping logging after 142544 examples to avoid logging too frequently
skipping logging after 142560 examples to avoid logging too frequently
skipping logging after 142576 examples to avoid logging too frequently
train stats after 142592 examples: {'rewards_train/chosen': '0.50917', 'rewards_train/rejected': '-5.4919', 'rewards_train/margins': '6.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20563', 'examples_per_second': '5.2009', 'grad_norm': '4.3438', 'counters/examples': 142592, 'counters/updates': 8912}
skipping logging after 142608 examples to avoid logging too frequently
skipping logging after 142624 examples to avoid logging too frequently
skipping logging after 142640 examples to avoid logging too frequently
train stats after 142656 examples: {'rewards_train/chosen': '0.27461', 'rewards_train/rejected': '-6.4194', 'rewards_train/margins': '6.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2536', 'examples_per_second': '4.8631', 'grad_norm': '5.4062', 'counters/examples': 142656, 'counters/updates': 8916}
skipping logging after 142672 examples to avoid logging too frequently
skipping logging after 142688 examples to avoid logging too frequently
skipping logging after 142704 examples to avoid logging too frequently
train stats after 142720 examples: {'rewards_train/chosen': '0.087148', 'rewards_train/rejected': '-6.5055', 'rewards_train/margins': '6.5469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2478', 'examples_per_second': '5.7383', 'grad_norm': '4.9375', 'counters/examples': 142720, 'counters/updates': 8920}
skipping logging after 142736 examples to avoid logging too frequently
skipping logging after 142752 examples to avoid logging too frequently
skipping logging after 142768 examples to avoid logging too frequently
train stats after 142784 examples: {'rewards_train/chosen': '0.627', 'rewards_train/rejected': '-5.5524', 'rewards_train/margins': '6.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21393', 'examples_per_second': '5.5751', 'grad_norm': '5.0312', 'counters/examples': 142784, 'counters/updates': 8924}
skipping logging after 142800 examples to avoid logging too frequently
skipping logging after 142816 examples to avoid logging too frequently
skipping logging after 142832 examples to avoid logging too frequently
train stats after 142848 examples: {'rewards_train/chosen': '0.52524', 'rewards_train/rejected': '-6.0487', 'rewards_train/margins': '6.5391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23608', 'examples_per_second': '5.2408', 'grad_norm': '5.2812', 'counters/examples': 142848, 'counters/updates': 8928}
skipping logging after 142864 examples to avoid logging too frequently
skipping logging after 142880 examples to avoid logging too frequently
skipping logging after 142896 examples to avoid logging too frequently
train stats after 142912 examples: {'rewards_train/chosen': '0.20837', 'rewards_train/rejected': '-5.7182', 'rewards_train/margins': '5.9492', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23944', 'examples_per_second': '5.2948', 'grad_norm': '4.3438', 'counters/examples': 142912, 'counters/updates': 8932}
skipping logging after 142928 examples to avoid logging too frequently
skipping logging after 142944 examples to avoid logging too frequently
skipping logging after 142960 examples to avoid logging too frequently
train stats after 142976 examples: {'rewards_train/chosen': '0.38596', 'rewards_train/rejected': '-5.9762', 'rewards_train/margins': '6.3828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23358', 'examples_per_second': '4.7092', 'grad_norm': '4.6562', 'counters/examples': 142976, 'counters/updates': 8936}
skipping logging after 142992 examples to avoid logging too frequently
skipping logging after 143008 examples to avoid logging too frequently
skipping logging after 143024 examples to avoid logging too frequently
train stats after 143040 examples: {'rewards_train/chosen': '0.33416', 'rewards_train/rejected': '-5.5348', 'rewards_train/margins': '6.4414', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25635', 'examples_per_second': '6.2343', 'grad_norm': '5.5', 'counters/examples': 143040, 'counters/updates': 8940}
skipping logging after 143056 examples to avoid logging too frequently
skipping logging after 143072 examples to avoid logging too frequently
skipping logging after 143088 examples to avoid logging too frequently
train stats after 143104 examples: {'rewards_train/chosen': '0.5994', 'rewards_train/rejected': '-5.1638', 'rewards_train/margins': '5.2852', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2843', 'examples_per_second': '5.0247', 'grad_norm': '5', 'counters/examples': 143104, 'counters/updates': 8944}
skipping logging after 143120 examples to avoid logging too frequently
skipping logging after 143136 examples to avoid logging too frequently
skipping logging after 143152 examples to avoid logging too frequently
train stats after 143168 examples: {'rewards_train/chosen': '0.46516', 'rewards_train/rejected': '-6.7915', 'rewards_train/margins': '7.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20239', 'examples_per_second': '4.5941', 'grad_norm': '5.3438', 'counters/examples': 143168, 'counters/updates': 8948}
skipping logging after 143184 examples to avoid logging too frequently
skipping logging after 143200 examples to avoid logging too frequently
skipping logging after 143216 examples to avoid logging too frequently
train stats after 143232 examples: {'rewards_train/chosen': '0.6623', 'rewards_train/rejected': '-5.2059', 'rewards_train/margins': '5.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20612', 'examples_per_second': '5.1994', 'grad_norm': '5.0312', 'counters/examples': 143232, 'counters/updates': 8952}
skipping logging after 143248 examples to avoid logging too frequently
skipping logging after 143264 examples to avoid logging too frequently
skipping logging after 143280 examples to avoid logging too frequently
train stats after 143296 examples: {'rewards_train/chosen': '0.18897', 'rewards_train/rejected': '-6.4228', 'rewards_train/margins': '6.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26416', 'examples_per_second': '4.7208', 'grad_norm': '4.5625', 'counters/examples': 143296, 'counters/updates': 8956}
skipping logging after 143312 examples to avoid logging too frequently
skipping logging after 143328 examples to avoid logging too frequently
skipping logging after 143344 examples to avoid logging too frequently
train stats after 143360 examples: {'rewards_train/chosen': '0.083391', 'rewards_train/rejected': '-5.3585', 'rewards_train/margins': '5.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.3064', 'examples_per_second': '4.6858', 'grad_norm': '4.8125', 'counters/examples': 143360, 'counters/updates': 8960}
skipping logging after 143376 examples to avoid logging too frequently
skipping logging after 143392 examples to avoid logging too frequently
skipping logging after 143408 examples to avoid logging too frequently
train stats after 143424 examples: {'rewards_train/chosen': '0.45019', 'rewards_train/rejected': '-5.1391', 'rewards_train/margins': '5.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25366', 'examples_per_second': '4.4759', 'grad_norm': '5.6875', 'counters/examples': 143424, 'counters/updates': 8964}
skipping logging after 143440 examples to avoid logging too frequently
skipping logging after 143456 examples to avoid logging too frequently
skipping logging after 143472 examples to avoid logging too frequently
train stats after 143488 examples: {'rewards_train/chosen': '0.33354', 'rewards_train/rejected': '-5.8422', 'rewards_train/margins': '6.1875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21887', 'examples_per_second': '5.0869', 'grad_norm': '4.5', 'counters/examples': 143488, 'counters/updates': 8968}
skipping logging after 143504 examples to avoid logging too frequently
skipping logging after 143520 examples to avoid logging too frequently
skipping logging after 143536 examples to avoid logging too frequently
train stats after 143552 examples: {'rewards_train/chosen': '0.35081', 'rewards_train/rejected': '-7.1571', 'rewards_train/margins': '7.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21478', 'examples_per_second': '4.563', 'grad_norm': '5.25', 'counters/examples': 143552, 'counters/updates': 8972}
skipping logging after 143568 examples to avoid logging too frequently
skipping logging after 143584 examples to avoid logging too frequently
skipping logging after 143600 examples to avoid logging too frequently
train stats after 143616 examples: {'rewards_train/chosen': '0.38527', 'rewards_train/rejected': '-4.9464', 'rewards_train/margins': '5.1445', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26282', 'examples_per_second': '5.2268', 'grad_norm': '4.625', 'counters/examples': 143616, 'counters/updates': 8976}
skipping logging after 143632 examples to avoid logging too frequently
skipping logging after 143648 examples to avoid logging too frequently
skipping logging after 143664 examples to avoid logging too frequently
train stats after 143680 examples: {'rewards_train/chosen': '0.54979', 'rewards_train/rejected': '-7.0755', 'rewards_train/margins': '7.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.271', 'examples_per_second': '4.5208', 'grad_norm': '5.0938', 'counters/examples': 143680, 'counters/updates': 8980}
skipping logging after 143696 examples to avoid logging too frequently
skipping logging after 143712 examples to avoid logging too frequently
skipping logging after 143728 examples to avoid logging too frequently
train stats after 143744 examples: {'rewards_train/chosen': '0.39244', 'rewards_train/rejected': '-5.9301', 'rewards_train/margins': '6.4219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25671', 'examples_per_second': '5.4798', 'grad_norm': '4.8125', 'counters/examples': 143744, 'counters/updates': 8984}
skipping logging after 143760 examples to avoid logging too frequently
skipping logging after 143776 examples to avoid logging too frequently
skipping logging after 143792 examples to avoid logging too frequently
train stats after 143808 examples: {'rewards_train/chosen': '0.50606', 'rewards_train/rejected': '-6.8031', 'rewards_train/margins': '7.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22058', 'examples_per_second': '5.7678', 'grad_norm': '5.7812', 'counters/examples': 143808, 'counters/updates': 8988}
skipping logging after 143824 examples to avoid logging too frequently
skipping logging after 143840 examples to avoid logging too frequently
skipping logging after 143856 examples to avoid logging too frequently
train stats after 143872 examples: {'rewards_train/chosen': '0.61324', 'rewards_train/rejected': '-8.0342', 'rewards_train/margins': '8.5781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22894', 'examples_per_second': '4.9002', 'grad_norm': '4.875', 'counters/examples': 143872, 'counters/updates': 8992}
skipping logging after 143888 examples to avoid logging too frequently
skipping logging after 143904 examples to avoid logging too frequently
skipping logging after 143920 examples to avoid logging too frequently
train stats after 143936 examples: {'rewards_train/chosen': '0.67276', 'rewards_train/rejected': '-6.0729', 'rewards_train/margins': '6.6875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20166', 'examples_per_second': '5.7329', 'grad_norm': '4.6875', 'counters/examples': 143936, 'counters/updates': 8996}
skipping logging after 143952 examples to avoid logging too frequently
skipping logging after 143968 examples to avoid logging too frequently
skipping logging after 143984 examples to avoid logging too frequently
train stats after 144000 examples: {'rewards_train/chosen': '0.36095', 'rewards_train/rejected': '-5.5165', 'rewards_train/margins': '6.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19568', 'examples_per_second': '5.5', 'grad_norm': '4.9375', 'counters/examples': 144000, 'counters/updates': 9000}
Running evaluation after 144000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.26s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.17s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:40,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.65s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.48s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:34,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.41s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.39s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.28s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.51s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.20s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.31s/it]
eval after 144000: {'rewards_eval/chosen': '-5.7016', 'rewards_eval/rejected': '-6.0853', 'rewards_eval/margins': '0.2334', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46189'}
skipping logging after 144016 examples to avoid logging too frequently
skipping logging after 144032 examples to avoid logging too frequently
skipping logging after 144048 examples to avoid logging too frequently
train stats after 144064 examples: {'rewards_train/chosen': '0.35267', 'rewards_train/rejected': '-6.1826', 'rewards_train/margins': '6.5469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26917', 'examples_per_second': '5.5902', 'grad_norm': '5.5', 'counters/examples': 144064, 'counters/updates': 9004}
skipping logging after 144080 examples to avoid logging too frequently
skipping logging after 144096 examples to avoid logging too frequently
skipping logging after 144112 examples to avoid logging too frequently
train stats after 144128 examples: {'rewards_train/chosen': '0.47193', 'rewards_train/rejected': '-7.07', 'rewards_train/margins': '7.7109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2699', 'examples_per_second': '5.0123', 'grad_norm': '5.3125', 'counters/examples': 144128, 'counters/updates': 9008}
skipping logging after 144144 examples to avoid logging too frequently
skipping logging after 144160 examples to avoid logging too frequently
skipping logging after 144176 examples to avoid logging too frequently
train stats after 144192 examples: {'rewards_train/chosen': '0.44475', 'rewards_train/rejected': '-5.6374', 'rewards_train/margins': '6.0156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20532', 'examples_per_second': '5.9947', 'grad_norm': '5', 'counters/examples': 144192, 'counters/updates': 9012}
skipping logging after 144208 examples to avoid logging too frequently
skipping logging after 144224 examples to avoid logging too frequently
skipping logging after 144240 examples to avoid logging too frequently
train stats after 144256 examples: {'rewards_train/chosen': '0.43078', 'rewards_train/rejected': '-5.6368', 'rewards_train/margins': '6.0547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22766', 'examples_per_second': '4.2232', 'grad_norm': '5.2188', 'counters/examples': 144256, 'counters/updates': 9016}
skipping logging after 144272 examples to avoid logging too frequently
skipping logging after 144288 examples to avoid logging too frequently
skipping logging after 144304 examples to avoid logging too frequently
train stats after 144320 examples: {'rewards_train/chosen': '0.051988', 'rewards_train/rejected': '-6.7207', 'rewards_train/margins': '6.7578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30432', 'examples_per_second': '4.5692', 'grad_norm': '5.3125', 'counters/examples': 144320, 'counters/updates': 9020}
skipping logging after 144336 examples to avoid logging too frequently
skipping logging after 144352 examples to avoid logging too frequently
skipping logging after 144368 examples to avoid logging too frequently
train stats after 144384 examples: {'rewards_train/chosen': '0.54274', 'rewards_train/rejected': '-5.2975', 'rewards_train/margins': '6.0312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22705', 'examples_per_second': '4.3359', 'grad_norm': '4.75', 'counters/examples': 144384, 'counters/updates': 9024}
skipping logging after 144400 examples to avoid logging too frequently
skipping logging after 144416 examples to avoid logging too frequently
skipping logging after 144432 examples to avoid logging too frequently
train stats after 144448 examples: {'rewards_train/chosen': '0.47065', 'rewards_train/rejected': '-5.9701', 'rewards_train/margins': '6.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21863', 'examples_per_second': '5.0818', 'grad_norm': '4.4688', 'counters/examples': 144448, 'counters/updates': 9028}
skipping logging after 144464 examples to avoid logging too frequently
skipping logging after 144480 examples to avoid logging too frequently
skipping logging after 144496 examples to avoid logging too frequently
train stats after 144512 examples: {'rewards_train/chosen': '0.47884', 'rewards_train/rejected': '-5.7981', 'rewards_train/margins': '6.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21045', 'examples_per_second': '6.423', 'grad_norm': '4.375', 'counters/examples': 144512, 'counters/updates': 9032}
skipping logging after 144528 examples to avoid logging too frequently
skipping logging after 144544 examples to avoid logging too frequently
skipping logging after 144560 examples to avoid logging too frequently
train stats after 144576 examples: {'rewards_train/chosen': '0.46822', 'rewards_train/rejected': '-5.5357', 'rewards_train/margins': '5.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23413', 'examples_per_second': '5.7337', 'grad_norm': '3.9531', 'counters/examples': 144576, 'counters/updates': 9036}
skipping logging after 144592 examples to avoid logging too frequently
skipping logging after 144608 examples to avoid logging too frequently
skipping logging after 144624 examples to avoid logging too frequently
train stats after 144640 examples: {'rewards_train/chosen': '0.26085', 'rewards_train/rejected': '-5.8779', 'rewards_train/margins': '6.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22888', 'examples_per_second': '5.0961', 'grad_norm': '4.4375', 'counters/examples': 144640, 'counters/updates': 9040}
skipping logging after 144656 examples to avoid logging too frequently
skipping logging after 144672 examples to avoid logging too frequently
skipping logging after 144688 examples to avoid logging too frequently
train stats after 144704 examples: {'rewards_train/chosen': '0.36877', 'rewards_train/rejected': '-6.0132', 'rewards_train/margins': '6.207', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24042', 'examples_per_second': '5.3802', 'grad_norm': '4.4688', 'counters/examples': 144704, 'counters/updates': 9044}
skipping logging after 144720 examples to avoid logging too frequently
skipping logging after 144736 examples to avoid logging too frequently
skipping logging after 144752 examples to avoid logging too frequently
train stats after 144768 examples: {'rewards_train/chosen': '0.44641', 'rewards_train/rejected': '-6.5356', 'rewards_train/margins': '6.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2536', 'examples_per_second': '4.9025', 'grad_norm': '5.5625', 'counters/examples': 144768, 'counters/updates': 9048}
skipping logging after 144784 examples to avoid logging too frequently
skipping logging after 144800 examples to avoid logging too frequently
skipping logging after 144816 examples to avoid logging too frequently
train stats after 144832 examples: {'rewards_train/chosen': '0.2444', 'rewards_train/rejected': '-6.4512', 'rewards_train/margins': '6.8008', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2572', 'examples_per_second': '5.6453', 'grad_norm': '4.7812', 'counters/examples': 144832, 'counters/updates': 9052}
skipping logging after 144848 examples to avoid logging too frequently
skipping logging after 144864 examples to avoid logging too frequently
skipping logging after 144880 examples to avoid logging too frequently
train stats after 144896 examples: {'rewards_train/chosen': '0.23251', 'rewards_train/rejected': '-7.3506', 'rewards_train/margins': '7.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21649', 'examples_per_second': '5.0205', 'grad_norm': '6.4688', 'counters/examples': 144896, 'counters/updates': 9056}
skipping logging after 144912 examples to avoid logging too frequently
skipping logging after 144928 examples to avoid logging too frequently
skipping logging after 144944 examples to avoid logging too frequently
train stats after 144960 examples: {'rewards_train/chosen': '0.46696', 'rewards_train/rejected': '-6.197', 'rewards_train/margins': '6.3164', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25305', 'examples_per_second': '4.5255', 'grad_norm': '5.3438', 'counters/examples': 144960, 'counters/updates': 9060}
skipping logging after 144976 examples to avoid logging too frequently
skipping logging after 144992 examples to avoid logging too frequently
skipping logging after 145008 examples to avoid logging too frequently
train stats after 145024 examples: {'rewards_train/chosen': '0.26337', 'rewards_train/rejected': '-5.1072', 'rewards_train/margins': '5.3672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26172', 'examples_per_second': '4.4062', 'grad_norm': '5.4375', 'counters/examples': 145024, 'counters/updates': 9064}
skipping logging after 145040 examples to avoid logging too frequently
skipping logging after 145056 examples to avoid logging too frequently
skipping logging after 145072 examples to avoid logging too frequently
train stats after 145088 examples: {'rewards_train/chosen': '-0.043717', 'rewards_train/rejected': '-4.6178', 'rewards_train/margins': '4.4492', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26013', 'examples_per_second': '5.5525', 'grad_norm': '4.5938', 'counters/examples': 145088, 'counters/updates': 9068}
skipping logging after 145104 examples to avoid logging too frequently
skipping logging after 145120 examples to avoid logging too frequently
skipping logging after 145136 examples to avoid logging too frequently
train stats after 145152 examples: {'rewards_train/chosen': '0.77443', 'rewards_train/rejected': '-5.0843', 'rewards_train/margins': '5.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19647', 'examples_per_second': '5.5651', 'grad_norm': '4.8438', 'counters/examples': 145152, 'counters/updates': 9072}
skipping logging after 145168 examples to avoid logging too frequently
skipping logging after 145184 examples to avoid logging too frequently
skipping logging after 145200 examples to avoid logging too frequently
train stats after 145216 examples: {'rewards_train/chosen': '0.5283', 'rewards_train/rejected': '-7.3511', 'rewards_train/margins': '7.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18085', 'examples_per_second': '5.0557', 'grad_norm': '3.7344', 'counters/examples': 145216, 'counters/updates': 9076}
skipping logging after 145232 examples to avoid logging too frequently
skipping logging after 145248 examples to avoid logging too frequently
skipping logging after 145264 examples to avoid logging too frequently
train stats after 145280 examples: {'rewards_train/chosen': '0.2303', 'rewards_train/rejected': '-6.9685', 'rewards_train/margins': '7.1953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24323', 'examples_per_second': '6.2733', 'grad_norm': '5.1875', 'counters/examples': 145280, 'counters/updates': 9080}
skipping logging after 145296 examples to avoid logging too frequently
skipping logging after 145312 examples to avoid logging too frequently
skipping logging after 145328 examples to avoid logging too frequently
train stats after 145344 examples: {'rewards_train/chosen': '0.87168', 'rewards_train/rejected': '-6.05', 'rewards_train/margins': '6.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.15198', 'examples_per_second': '5.0327', 'grad_norm': '4', 'counters/examples': 145344, 'counters/updates': 9084}
skipping logging after 145360 examples to avoid logging too frequently
skipping logging after 145376 examples to avoid logging too frequently
skipping logging after 145392 examples to avoid logging too frequently
train stats after 145408 examples: {'rewards_train/chosen': '0.5262', 'rewards_train/rejected': '-5.7223', 'rewards_train/margins': '6.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21106', 'examples_per_second': '4.8386', 'grad_norm': '5.0938', 'counters/examples': 145408, 'counters/updates': 9088}
skipping logging after 145424 examples to avoid logging too frequently
skipping logging after 145440 examples to avoid logging too frequently
skipping logging after 145456 examples to avoid logging too frequently
train stats after 145472 examples: {'rewards_train/chosen': '0.40825', 'rewards_train/rejected': '-5.3092', 'rewards_train/margins': '5.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20148', 'examples_per_second': '5.8735', 'grad_norm': '4.3438', 'counters/examples': 145472, 'counters/updates': 9092}
skipping logging after 145488 examples to avoid logging too frequently
skipping logging after 145504 examples to avoid logging too frequently
skipping logging after 145520 examples to avoid logging too frequently
train stats after 145536 examples: {'rewards_train/chosen': '0.54741', 'rewards_train/rejected': '-7.2544', 'rewards_train/margins': '7.8086', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20721', 'examples_per_second': '6.4137', 'grad_norm': '4.875', 'counters/examples': 145536, 'counters/updates': 9096}
skipping logging after 145552 examples to avoid logging too frequently
skipping logging after 145568 examples to avoid logging too frequently
skipping logging after 145584 examples to avoid logging too frequently
train stats after 145600 examples: {'rewards_train/chosen': '0.55638', 'rewards_train/rejected': '-7.7733', 'rewards_train/margins': '8.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20087', 'examples_per_second': '4.8174', 'grad_norm': '5.5', 'counters/examples': 145600, 'counters/updates': 9100}
skipping logging after 145616 examples to avoid logging too frequently
skipping logging after 145632 examples to avoid logging too frequently
skipping logging after 145648 examples to avoid logging too frequently
train stats after 145664 examples: {'rewards_train/chosen': '0.36898', 'rewards_train/rejected': '-6.2232', 'rewards_train/margins': '6.6328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23993', 'examples_per_second': '4.9951', 'grad_norm': '4.8125', 'counters/examples': 145664, 'counters/updates': 9104}
skipping logging after 145680 examples to avoid logging too frequently
skipping logging after 145696 examples to avoid logging too frequently
skipping logging after 145712 examples to avoid logging too frequently
train stats after 145728 examples: {'rewards_train/chosen': '0.35123', 'rewards_train/rejected': '-5.8005', 'rewards_train/margins': '6.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21399', 'examples_per_second': '4.9517', 'grad_norm': '4.3438', 'counters/examples': 145728, 'counters/updates': 9108}
skipping logging after 145744 examples to avoid logging too frequently
skipping logging after 145760 examples to avoid logging too frequently
skipping logging after 145776 examples to avoid logging too frequently
train stats after 145792 examples: {'rewards_train/chosen': '0.36548', 'rewards_train/rejected': '-6.4598', 'rewards_train/margins': '6.7031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25232', 'examples_per_second': '5.7084', 'grad_norm': '5.1562', 'counters/examples': 145792, 'counters/updates': 9112}
skipping logging after 145808 examples to avoid logging too frequently
skipping logging after 145824 examples to avoid logging too frequently
skipping logging after 145840 examples to avoid logging too frequently
train stats after 145856 examples: {'rewards_train/chosen': '0.53962', 'rewards_train/rejected': '-6.3537', 'rewards_train/margins': '6.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23102', 'examples_per_second': '5.2542', 'grad_norm': '5.5625', 'counters/examples': 145856, 'counters/updates': 9116}
skipping logging after 145872 examples to avoid logging too frequently
skipping logging after 145888 examples to avoid logging too frequently
skipping logging after 145904 examples to avoid logging too frequently
train stats after 145920 examples: {'rewards_train/chosen': '0.58643', 'rewards_train/rejected': '-5.759', 'rewards_train/margins': '6.7383', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20978', 'examples_per_second': '4.6399', 'grad_norm': '4.0625', 'counters/examples': 145920, 'counters/updates': 9120}
skipping logging after 145936 examples to avoid logging too frequently
skipping logging after 145952 examples to avoid logging too frequently
skipping logging after 145968 examples to avoid logging too frequently
train stats after 145984 examples: {'rewards_train/chosen': '0.45875', 'rewards_train/rejected': '-6.6465', 'rewards_train/margins': '7.1875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23944', 'examples_per_second': '5.1385', 'grad_norm': '6', 'counters/examples': 145984, 'counters/updates': 9124}
skipping logging after 146000 examples to avoid logging too frequently
skipping logging after 146016 examples to avoid logging too frequently
skipping logging after 146032 examples to avoid logging too frequently
train stats after 146048 examples: {'rewards_train/chosen': '0.45864', 'rewards_train/rejected': '-5.6207', 'rewards_train/margins': '6.3164', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2428', 'examples_per_second': '5.6271', 'grad_norm': '5.0312', 'counters/examples': 146048, 'counters/updates': 9128}
skipping logging after 146064 examples to avoid logging too frequently
skipping logging after 146080 examples to avoid logging too frequently
skipping logging after 146096 examples to avoid logging too frequently
train stats after 146112 examples: {'rewards_train/chosen': '0.27908', 'rewards_train/rejected': '-5.6285', 'rewards_train/margins': '5.8984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21838', 'examples_per_second': '5.4008', 'grad_norm': '4.3438', 'counters/examples': 146112, 'counters/updates': 9132}
skipping logging after 146128 examples to avoid logging too frequently
skipping logging after 146144 examples to avoid logging too frequently
skipping logging after 146160 examples to avoid logging too frequently
train stats after 146176 examples: {'rewards_train/chosen': '0.49827', 'rewards_train/rejected': '-7.2589', 'rewards_train/margins': '7.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19556', 'examples_per_second': '5.0006', 'grad_norm': '4.8125', 'counters/examples': 146176, 'counters/updates': 9136}
skipping logging after 146192 examples to avoid logging too frequently
skipping logging after 146208 examples to avoid logging too frequently
skipping logging after 146224 examples to avoid logging too frequently
train stats after 146240 examples: {'rewards_train/chosen': '0.3336', 'rewards_train/rejected': '-5.9604', 'rewards_train/margins': '6.1953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22858', 'examples_per_second': '5.8093', 'grad_norm': '4.5625', 'counters/examples': 146240, 'counters/updates': 9140}
skipping logging after 146256 examples to avoid logging too frequently
skipping logging after 146272 examples to avoid logging too frequently
skipping logging after 146288 examples to avoid logging too frequently
train stats after 146304 examples: {'rewards_train/chosen': '0.49849', 'rewards_train/rejected': '-7.0986', 'rewards_train/margins': '7.4844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26221', 'examples_per_second': '5.5627', 'grad_norm': '5.5312', 'counters/examples': 146304, 'counters/updates': 9144}
skipping logging after 146320 examples to avoid logging too frequently
skipping logging after 146336 examples to avoid logging too frequently
skipping logging after 146352 examples to avoid logging too frequently
train stats after 146368 examples: {'rewards_train/chosen': '0.31584', 'rewards_train/rejected': '-5.3261', 'rewards_train/margins': '5.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28735', 'examples_per_second': '5.6543', 'grad_norm': '4.9062', 'counters/examples': 146368, 'counters/updates': 9148}
skipping logging after 146384 examples to avoid logging too frequently
skipping logging after 146400 examples to avoid logging too frequently
skipping logging after 146416 examples to avoid logging too frequently
train stats after 146432 examples: {'rewards_train/chosen': '0.35972', 'rewards_train/rejected': '-6.9634', 'rewards_train/margins': '7.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21979', 'examples_per_second': '4.7447', 'grad_norm': '4.625', 'counters/examples': 146432, 'counters/updates': 9152}
skipping logging after 146448 examples to avoid logging too frequently
skipping logging after 146464 examples to avoid logging too frequently
skipping logging after 146480 examples to avoid logging too frequently
train stats after 146496 examples: {'rewards_train/chosen': '0.59852', 'rewards_train/rejected': '-5.4721', 'rewards_train/margins': '5.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22052', 'examples_per_second': '5.7068', 'grad_norm': '5.1562', 'counters/examples': 146496, 'counters/updates': 9156}
skipping logging after 146512 examples to avoid logging too frequently
skipping logging after 146528 examples to avoid logging too frequently
skipping logging after 146544 examples to avoid logging too frequently
train stats after 146560 examples: {'rewards_train/chosen': '0.42648', 'rewards_train/rejected': '-6.8578', 'rewards_train/margins': '7.4219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24103', 'examples_per_second': '4.5252', 'grad_norm': '4.9375', 'counters/examples': 146560, 'counters/updates': 9160}
skipping logging after 146576 examples to avoid logging too frequently
skipping logging after 146592 examples to avoid logging too frequently
skipping logging after 146608 examples to avoid logging too frequently
train stats after 146624 examples: {'rewards_train/chosen': '0.0072285', 'rewards_train/rejected': '-5.475', 'rewards_train/margins': '5.457', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28632', 'examples_per_second': '5.3326', 'grad_norm': '4.6562', 'counters/examples': 146624, 'counters/updates': 9164}
skipping logging after 146640 examples to avoid logging too frequently
skipping logging after 146656 examples to avoid logging too frequently
skipping logging after 146672 examples to avoid logging too frequently
train stats after 146688 examples: {'rewards_train/chosen': '0.62544', 'rewards_train/rejected': '-5.4766', 'rewards_train/margins': '7.0312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22382', 'examples_per_second': '5.29', 'grad_norm': '5.1875', 'counters/examples': 146688, 'counters/updates': 9168}
skipping logging after 146704 examples to avoid logging too frequently
skipping logging after 146720 examples to avoid logging too frequently
skipping logging after 146736 examples to avoid logging too frequently
train stats after 146752 examples: {'rewards_train/chosen': '0.18282', 'rewards_train/rejected': '-5.3678', 'rewards_train/margins': '5.3672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23529', 'examples_per_second': '4.946', 'grad_norm': '4.5', 'counters/examples': 146752, 'counters/updates': 9172}
skipping logging after 146768 examples to avoid logging too frequently
skipping logging after 146784 examples to avoid logging too frequently
skipping logging after 146800 examples to avoid logging too frequently
train stats after 146816 examples: {'rewards_train/chosen': '0.22137', 'rewards_train/rejected': '-6.4803', 'rewards_train/margins': '6.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25092', 'examples_per_second': '6.1013', 'grad_norm': '4.4375', 'counters/examples': 146816, 'counters/updates': 9176}
skipping logging after 146832 examples to avoid logging too frequently
skipping logging after 146848 examples to avoid logging too frequently
skipping logging after 146864 examples to avoid logging too frequently
train stats after 146880 examples: {'rewards_train/chosen': '0.56739', 'rewards_train/rejected': '-5.1793', 'rewards_train/margins': '5.6055', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1889', 'examples_per_second': '4.8448', 'grad_norm': '5', 'counters/examples': 146880, 'counters/updates': 9180}
skipping logging after 146896 examples to avoid logging too frequently
skipping logging after 146912 examples to avoid logging too frequently
skipping logging after 146928 examples to avoid logging too frequently
train stats after 146944 examples: {'rewards_train/chosen': '0.34929', 'rewards_train/rejected': '-4.8215', 'rewards_train/margins': '5.3086', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17139', 'examples_per_second': '5.0061', 'grad_norm': '4', 'counters/examples': 146944, 'counters/updates': 9184}
skipping logging after 146960 examples to avoid logging too frequently
skipping logging after 146976 examples to avoid logging too frequently
skipping logging after 146992 examples to avoid logging too frequently
train stats after 147008 examples: {'rewards_train/chosen': '0.44312', 'rewards_train/rejected': '-6.0198', 'rewards_train/margins': '6.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20581', 'examples_per_second': '4.3597', 'grad_norm': '4.6875', 'counters/examples': 147008, 'counters/updates': 9188}
skipping logging after 147024 examples to avoid logging too frequently
skipping logging after 147040 examples to avoid logging too frequently
skipping logging after 147056 examples to avoid logging too frequently
train stats after 147072 examples: {'rewards_train/chosen': '0.49771', 'rewards_train/rejected': '-5.6162', 'rewards_train/margins': '6.0234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22052', 'examples_per_second': '3.9779', 'grad_norm': '5.8438', 'counters/examples': 147072, 'counters/updates': 9192}
skipping logging after 147088 examples to avoid logging too frequently
skipping logging after 147104 examples to avoid logging too frequently
skipping logging after 147120 examples to avoid logging too frequently
train stats after 147136 examples: {'rewards_train/chosen': '0.48544', 'rewards_train/rejected': '-7.5101', 'rewards_train/margins': '7.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21777', 'examples_per_second': '5.1309', 'grad_norm': '5.0312', 'counters/examples': 147136, 'counters/updates': 9196}
skipping logging after 147152 examples to avoid logging too frequently
skipping logging after 147168 examples to avoid logging too frequently
skipping logging after 147184 examples to avoid logging too frequently
train stats after 147200 examples: {'rewards_train/chosen': '0.38628', 'rewards_train/rejected': '-7.5879', 'rewards_train/margins': '8.0312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21881', 'examples_per_second': '4.8617', 'grad_norm': '4.5938', 'counters/examples': 147200, 'counters/updates': 9200}
skipping logging after 147216 examples to avoid logging too frequently
skipping logging after 147232 examples to avoid logging too frequently
skipping logging after 147248 examples to avoid logging too frequently
train stats after 147264 examples: {'rewards_train/chosen': '0.24414', 'rewards_train/rejected': '-5.332', 'rewards_train/margins': '5.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22998', 'examples_per_second': '4.3042', 'grad_norm': '5.9062', 'counters/examples': 147264, 'counters/updates': 9204}
skipping logging after 147280 examples to avoid logging too frequently
skipping logging after 147296 examples to avoid logging too frequently
skipping logging after 147312 examples to avoid logging too frequently
train stats after 147328 examples: {'rewards_train/chosen': '0.25323', 'rewards_train/rejected': '-6.2382', 'rewards_train/margins': '6.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2182', 'examples_per_second': '4.631', 'grad_norm': '5.3438', 'counters/examples': 147328, 'counters/updates': 9208}
skipping logging after 147344 examples to avoid logging too frequently
skipping logging after 147360 examples to avoid logging too frequently
skipping logging after 147376 examples to avoid logging too frequently
train stats after 147392 examples: {'rewards_train/chosen': '0.55562', 'rewards_train/rejected': '-6.2956', 'rewards_train/margins': '6.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.15021', 'examples_per_second': '5.1134', 'grad_norm': '4.0312', 'counters/examples': 147392, 'counters/updates': 9212}
skipping logging after 147408 examples to avoid logging too frequently
skipping logging after 147424 examples to avoid logging too frequently
skipping logging after 147440 examples to avoid logging too frequently
train stats after 147456 examples: {'rewards_train/chosen': '-0.0025454', 'rewards_train/rejected': '-6.1624', 'rewards_train/margins': '5.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21832', 'examples_per_second': '6.1884', 'grad_norm': '4.4062', 'counters/examples': 147456, 'counters/updates': 9216}
skipping logging after 147472 examples to avoid logging too frequently
skipping logging after 147488 examples to avoid logging too frequently
skipping logging after 147504 examples to avoid logging too frequently
train stats after 147520 examples: {'rewards_train/chosen': '0.30893', 'rewards_train/rejected': '-5.9632', 'rewards_train/margins': '6.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18872', 'examples_per_second': '6.0624', 'grad_norm': '4.9375', 'counters/examples': 147520, 'counters/updates': 9220}
skipping logging after 147536 examples to avoid logging too frequently
skipping logging after 147552 examples to avoid logging too frequently
skipping logging after 147568 examples to avoid logging too frequently
train stats after 147584 examples: {'rewards_train/chosen': '0.38761', 'rewards_train/rejected': '-8.9308', 'rewards_train/margins': '9.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22797', 'examples_per_second': '4.0466', 'grad_norm': '4.4688', 'counters/examples': 147584, 'counters/updates': 9224}
skipping logging after 147600 examples to avoid logging too frequently
skipping logging after 147616 examples to avoid logging too frequently
skipping logging after 147632 examples to avoid logging too frequently
train stats after 147648 examples: {'rewards_train/chosen': '0.43285', 'rewards_train/rejected': '-5.4478', 'rewards_train/margins': '5.8125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21301', 'examples_per_second': '4.6057', 'grad_norm': '4.6875', 'counters/examples': 147648, 'counters/updates': 9228}
skipping logging after 147664 examples to avoid logging too frequently
skipping logging after 147680 examples to avoid logging too frequently
skipping logging after 147696 examples to avoid logging too frequently
train stats after 147712 examples: {'rewards_train/chosen': '0.44928', 'rewards_train/rejected': '-6.1441', 'rewards_train/margins': '6.5469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21442', 'examples_per_second': '4.9205', 'grad_norm': '4.5', 'counters/examples': 147712, 'counters/updates': 9232}
skipping logging after 147728 examples to avoid logging too frequently
skipping logging after 147744 examples to avoid logging too frequently
skipping logging after 147760 examples to avoid logging too frequently
train stats after 147776 examples: {'rewards_train/chosen': '0.28776', 'rewards_train/rejected': '-5.7275', 'rewards_train/margins': '5.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2312', 'examples_per_second': '5.88', 'grad_norm': '4.7188', 'counters/examples': 147776, 'counters/updates': 9236}
skipping logging after 147792 examples to avoid logging too frequently
skipping logging after 147808 examples to avoid logging too frequently
skipping logging after 147824 examples to avoid logging too frequently
train stats after 147840 examples: {'rewards_train/chosen': '0.024147', 'rewards_train/rejected': '-8.4228', 'rewards_train/margins': '8.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28345', 'examples_per_second': '6.8508', 'grad_norm': '6.2188', 'counters/examples': 147840, 'counters/updates': 9240}
skipping logging after 147856 examples to avoid logging too frequently
skipping logging after 147872 examples to avoid logging too frequently
skipping logging after 147888 examples to avoid logging too frequently
train stats after 147904 examples: {'rewards_train/chosen': '0.10606', 'rewards_train/rejected': '-6.108', 'rewards_train/margins': '6.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25208', 'examples_per_second': '6.0882', 'grad_norm': '4.6562', 'counters/examples': 147904, 'counters/updates': 9244}
skipping logging after 147920 examples to avoid logging too frequently
skipping logging after 147936 examples to avoid logging too frequently
skipping logging after 147952 examples to avoid logging too frequently
train stats after 147968 examples: {'rewards_train/chosen': '0.63171', 'rewards_train/rejected': '-4.5326', 'rewards_train/margins': '5.2266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24554', 'examples_per_second': '5.2936', 'grad_norm': '5.3438', 'counters/examples': 147968, 'counters/updates': 9248}
skipping logging after 147984 examples to avoid logging too frequently
skipping logging after 148000 examples to avoid logging too frequently
Running evaluation after 148000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:49,  1.60s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:41,  1.39s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:35,  1.24s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.47s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.68s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.49s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:10<00:34,  1.37s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.40s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:30,  1.47s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.42s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.20s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:41<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]
eval after 148000: {'rewards_eval/chosen': '-5.3944', 'rewards_eval/rejected': '-5.7968', 'rewards_eval/margins': '0.27344', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.45892'}
skipping logging after 148016 examples to avoid logging too frequently
train stats after 148032 examples: {'rewards_train/chosen': '0.5617', 'rewards_train/rejected': '-6.7103', 'rewards_train/margins': '7.1016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21161', 'examples_per_second': '5.4007', 'grad_norm': '4.75', 'counters/examples': 148032, 'counters/updates': 9252}
skipping logging after 148048 examples to avoid logging too frequently
skipping logging after 148064 examples to avoid logging too frequently
skipping logging after 148080 examples to avoid logging too frequently
train stats after 148096 examples: {'rewards_train/chosen': '0.58178', 'rewards_train/rejected': '-4.8467', 'rewards_train/margins': '5.4609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23669', 'examples_per_second': '5.3333', 'grad_norm': '4.8438', 'counters/examples': 148096, 'counters/updates': 9256}
skipping logging after 148112 examples to avoid logging too frequently
skipping logging after 148128 examples to avoid logging too frequently
skipping logging after 148144 examples to avoid logging too frequently
train stats after 148160 examples: {'rewards_train/chosen': '0.32388', 'rewards_train/rejected': '-5.4965', 'rewards_train/margins': '5.7812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27802', 'examples_per_second': '4.8135', 'grad_norm': '6.75', 'counters/examples': 148160, 'counters/updates': 9260}
skipping logging after 148176 examples to avoid logging too frequently
skipping logging after 148192 examples to avoid logging too frequently
skipping logging after 148208 examples to avoid logging too frequently
train stats after 148224 examples: {'rewards_train/chosen': '0.41557', 'rewards_train/rejected': '-5.3122', 'rewards_train/margins': '5.9141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24011', 'examples_per_second': '5.4823', 'grad_norm': '5.7812', 'counters/examples': 148224, 'counters/updates': 9264}
skipping logging after 148240 examples to avoid logging too frequently
skipping logging after 148256 examples to avoid logging too frequently
skipping logging after 148272 examples to avoid logging too frequently
train stats after 148288 examples: {'rewards_train/chosen': '0.32011', 'rewards_train/rejected': '-6.3952', 'rewards_train/margins': '6.9141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21039', 'examples_per_second': '5.2798', 'grad_norm': '4.0938', 'counters/examples': 148288, 'counters/updates': 9268}
skipping logging after 148304 examples to avoid logging too frequently
skipping logging after 148320 examples to avoid logging too frequently
skipping logging after 148336 examples to avoid logging too frequently
train stats after 148352 examples: {'rewards_train/chosen': '0.62727', 'rewards_train/rejected': '-4.6293', 'rewards_train/margins': '5.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2312', 'examples_per_second': '5.0445', 'grad_norm': '4.375', 'counters/examples': 148352, 'counters/updates': 9272}
skipping logging after 148368 examples to avoid logging too frequently
skipping logging after 148384 examples to avoid logging too frequently
skipping logging after 148400 examples to avoid logging too frequently
train stats after 148416 examples: {'rewards_train/chosen': '-0.23692', 'rewards_train/rejected': '-5.598', 'rewards_train/margins': '5.3828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27136', 'examples_per_second': '5.8761', 'grad_norm': '5.625', 'counters/examples': 148416, 'counters/updates': 9276}
skipping logging after 148432 examples to avoid logging too frequently
skipping logging after 148448 examples to avoid logging too frequently
skipping logging after 148464 examples to avoid logging too frequently
train stats after 148480 examples: {'rewards_train/chosen': '0.15326', 'rewards_train/rejected': '-7.3308', 'rewards_train/margins': '7.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26666', 'examples_per_second': '5.2132', 'grad_norm': '5.8125', 'counters/examples': 148480, 'counters/updates': 9280}
skipping logging after 148496 examples to avoid logging too frequently
skipping logging after 148512 examples to avoid logging too frequently
skipping logging after 148528 examples to avoid logging too frequently
train stats after 148544 examples: {'rewards_train/chosen': '0.35623', 'rewards_train/rejected': '-5.8098', 'rewards_train/margins': '6.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24878', 'examples_per_second': '5.7457', 'grad_norm': '5.5312', 'counters/examples': 148544, 'counters/updates': 9284}
skipping logging after 148560 examples to avoid logging too frequently
skipping logging after 148576 examples to avoid logging too frequently
skipping logging after 148592 examples to avoid logging too frequently
train stats after 148608 examples: {'rewards_train/chosen': '0.58599', 'rewards_train/rejected': '-6.7011', 'rewards_train/margins': '7.375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1582', 'examples_per_second': '5.0062', 'grad_norm': '5.625', 'counters/examples': 148608, 'counters/updates': 9288}
skipping logging after 148624 examples to avoid logging too frequently
skipping logging after 148640 examples to avoid logging too frequently
skipping logging after 148656 examples to avoid logging too frequently
train stats after 148672 examples: {'rewards_train/chosen': '0.31677', 'rewards_train/rejected': '-5.3726', 'rewards_train/margins': '5.8203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23566', 'examples_per_second': '4.7852', 'grad_norm': '5', 'counters/examples': 148672, 'counters/updates': 9292}
skipping logging after 148688 examples to avoid logging too frequently
skipping logging after 148704 examples to avoid logging too frequently
skipping logging after 148720 examples to avoid logging too frequently
train stats after 148736 examples: {'rewards_train/chosen': '0.59599', 'rewards_train/rejected': '-6.7182', 'rewards_train/margins': '7.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18604', 'examples_per_second': '4.9339', 'grad_norm': '4.125', 'counters/examples': 148736, 'counters/updates': 9296}
skipping logging after 148752 examples to avoid logging too frequently
skipping logging after 148768 examples to avoid logging too frequently
skipping logging after 148784 examples to avoid logging too frequently
train stats after 148800 examples: {'rewards_train/chosen': '0.39638', 'rewards_train/rejected': '-6.7084', 'rewards_train/margins': '7.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2536', 'examples_per_second': '4.3558', 'grad_norm': '4.8125', 'counters/examples': 148800, 'counters/updates': 9300}
skipping logging after 148816 examples to avoid logging too frequently
skipping logging after 148832 examples to avoid logging too frequently
skipping logging after 148848 examples to avoid logging too frequently
train stats after 148864 examples: {'rewards_train/chosen': '0.58868', 'rewards_train/rejected': '-5.276', 'rewards_train/margins': '5.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22864', 'examples_per_second': '6.165', 'grad_norm': '4.625', 'counters/examples': 148864, 'counters/updates': 9304}
skipping logging after 148880 examples to avoid logging too frequently
skipping logging after 148896 examples to avoid logging too frequently
skipping logging after 148912 examples to avoid logging too frequently
train stats after 148928 examples: {'rewards_train/chosen': '0.15955', 'rewards_train/rejected': '-6.9432', 'rewards_train/margins': '7.1719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2522', 'examples_per_second': '4.6792', 'grad_norm': '4.8125', 'counters/examples': 148928, 'counters/updates': 9308}
skipping logging after 148944 examples to avoid logging too frequently
skipping logging after 148960 examples to avoid logging too frequently
skipping logging after 148976 examples to avoid logging too frequently
train stats after 148992 examples: {'rewards_train/chosen': '0.23535', 'rewards_train/rejected': '-6.7523', 'rewards_train/margins': '7.3281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22968', 'examples_per_second': '5.5458', 'grad_norm': '5.5', 'counters/examples': 148992, 'counters/updates': 9312}
skipping logging after 149008 examples to avoid logging too frequently
skipping logging after 149024 examples to avoid logging too frequently
skipping logging after 149040 examples to avoid logging too frequently
train stats after 149056 examples: {'rewards_train/chosen': '0.071638', 'rewards_train/rejected': '-6.0348', 'rewards_train/margins': '6.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24091', 'examples_per_second': '5.4154', 'grad_norm': '4.875', 'counters/examples': 149056, 'counters/updates': 9316}
skipping logging after 149072 examples to avoid logging too frequently
skipping logging after 149088 examples to avoid logging too frequently
skipping logging after 149104 examples to avoid logging too frequently
train stats after 149120 examples: {'rewards_train/chosen': '-0.0054722', 'rewards_train/rejected': '-4.6281', 'rewards_train/margins': '4.7539', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28583', 'examples_per_second': '5.6114', 'grad_norm': '5.9375', 'counters/examples': 149120, 'counters/updates': 9320}
skipping logging after 149136 examples to avoid logging too frequently
skipping logging after 149152 examples to avoid logging too frequently
skipping logging after 149168 examples to avoid logging too frequently
train stats after 149184 examples: {'rewards_train/chosen': '0.40002', 'rewards_train/rejected': '-7.9567', 'rewards_train/margins': '8.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22949', 'examples_per_second': '4.2868', 'grad_norm': '3.9844', 'counters/examples': 149184, 'counters/updates': 9324}
skipping logging after 149200 examples to avoid logging too frequently
skipping logging after 149216 examples to avoid logging too frequently
skipping logging after 149232 examples to avoid logging too frequently
train stats after 149248 examples: {'rewards_train/chosen': '0.36641', 'rewards_train/rejected': '-5.8292', 'rewards_train/margins': '6.2969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25671', 'examples_per_second': '5.9946', 'grad_norm': '5.1562', 'counters/examples': 149248, 'counters/updates': 9328}
skipping logging after 149264 examples to avoid logging too frequently
skipping logging after 149280 examples to avoid logging too frequently
skipping logging after 149296 examples to avoid logging too frequently
train stats after 149312 examples: {'rewards_train/chosen': '0.22004', 'rewards_train/rejected': '-5.2038', 'rewards_train/margins': '5.4219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23486', 'examples_per_second': '5.4832', 'grad_norm': '5', 'counters/examples': 149312, 'counters/updates': 9332}
skipping logging after 149328 examples to avoid logging too frequently
skipping logging after 149344 examples to avoid logging too frequently
skipping logging after 149360 examples to avoid logging too frequently
train stats after 149376 examples: {'rewards_train/chosen': '0.35688', 'rewards_train/rejected': '-4.0623', 'rewards_train/margins': '4.4531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28113', 'examples_per_second': '5.7974', 'grad_norm': '5.0312', 'counters/examples': 149376, 'counters/updates': 9336}
skipping logging after 149392 examples to avoid logging too frequently
skipping logging after 149408 examples to avoid logging too frequently
skipping logging after 149424 examples to avoid logging too frequently
train stats after 149440 examples: {'rewards_train/chosen': '0.37803', 'rewards_train/rejected': '-5.7274', 'rewards_train/margins': '6.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19427', 'examples_per_second': '5.5094', 'grad_norm': '4.9688', 'counters/examples': 149440, 'counters/updates': 9340}
skipping logging after 149456 examples to avoid logging too frequently
skipping logging after 149472 examples to avoid logging too frequently
skipping logging after 149488 examples to avoid logging too frequently
train stats after 149504 examples: {'rewards_train/chosen': '0.45064', 'rewards_train/rejected': '-5.2768', 'rewards_train/margins': '5.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23193', 'examples_per_second': '5.9783', 'grad_norm': '4.875', 'counters/examples': 149504, 'counters/updates': 9344}
skipping logging after 149520 examples to avoid logging too frequently
skipping logging after 149536 examples to avoid logging too frequently
skipping logging after 149552 examples to avoid logging too frequently
train stats after 149568 examples: {'rewards_train/chosen': '0.56127', 'rewards_train/rejected': '-6.3848', 'rewards_train/margins': '6.8672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23615', 'examples_per_second': '5.7037', 'grad_norm': '5.25', 'counters/examples': 149568, 'counters/updates': 9348}
skipping logging after 149584 examples to avoid logging too frequently
skipping logging after 149600 examples to avoid logging too frequently
skipping logging after 149616 examples to avoid logging too frequently
train stats after 149632 examples: {'rewards_train/chosen': '0.31166', 'rewards_train/rejected': '-4.8975', 'rewards_train/margins': '5.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26086', 'examples_per_second': '5.2943', 'grad_norm': '5.5312', 'counters/examples': 149632, 'counters/updates': 9352}
skipping logging after 149648 examples to avoid logging too frequently
skipping logging after 149664 examples to avoid logging too frequently
skipping logging after 149680 examples to avoid logging too frequently
train stats after 149696 examples: {'rewards_train/chosen': '0.19816', 'rewards_train/rejected': '-5.0494', 'rewards_train/margins': '5.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28186', 'examples_per_second': '6.4215', 'grad_norm': '5.9062', 'counters/examples': 149696, 'counters/updates': 9356}
skipping logging after 149712 examples to avoid logging too frequently
skipping logging after 149728 examples to avoid logging too frequently
skipping logging after 149744 examples to avoid logging too frequently
train stats after 149760 examples: {'rewards_train/chosen': '0.39848', 'rewards_train/rejected': '-4.8852', 'rewards_train/margins': '5.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28302', 'examples_per_second': '5.6675', 'grad_norm': '6.2188', 'counters/examples': 149760, 'counters/updates': 9360}
skipping logging after 149776 examples to avoid logging too frequently
skipping logging after 149792 examples to avoid logging too frequently
skipping logging after 149808 examples to avoid logging too frequently
train stats after 149824 examples: {'rewards_train/chosen': '0.35457', 'rewards_train/rejected': '-6.5603', 'rewards_train/margins': '6.9453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25317', 'examples_per_second': '4.6296', 'grad_norm': '5.75', 'counters/examples': 149824, 'counters/updates': 9364}
skipping logging after 149840 examples to avoid logging too frequently
skipping logging after 149856 examples to avoid logging too frequently
skipping logging after 149872 examples to avoid logging too frequently
train stats after 149888 examples: {'rewards_train/chosen': '0.38721', 'rewards_train/rejected': '-5.9089', 'rewards_train/margins': '6.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17987', 'examples_per_second': '4.4098', 'grad_norm': '4.4688', 'counters/examples': 149888, 'counters/updates': 9368}
skipping logging after 149904 examples to avoid logging too frequently
skipping logging after 149920 examples to avoid logging too frequently
skipping logging after 149936 examples to avoid logging too frequently
train stats after 149952 examples: {'rewards_train/chosen': '0.51562', 'rewards_train/rejected': '-4.4854', 'rewards_train/margins': '5.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23145', 'examples_per_second': '5.1483', 'grad_norm': '6.1875', 'counters/examples': 149952, 'counters/updates': 9372}
skipping logging after 149968 examples to avoid logging too frequently
skipping logging after 149984 examples to avoid logging too frequently
skipping logging after 150000 examples to avoid logging too frequently
train stats after 150016 examples: {'rewards_train/chosen': '0.29651', 'rewards_train/rejected': '-7.099', 'rewards_train/margins': '7.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24896', 'examples_per_second': '4.8756', 'grad_norm': '4.8438', 'counters/examples': 150016, 'counters/updates': 9376}
skipping logging after 150032 examples to avoid logging too frequently
skipping logging after 150048 examples to avoid logging too frequently
skipping logging after 150064 examples to avoid logging too frequently
train stats after 150080 examples: {'rewards_train/chosen': '0.53813', 'rewards_train/rejected': '-6.0891', 'rewards_train/margins': '6.6641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23395', 'examples_per_second': '6.1056', 'grad_norm': '4.7188', 'counters/examples': 150080, 'counters/updates': 9380}
skipping logging after 150096 examples to avoid logging too frequently
skipping logging after 150112 examples to avoid logging too frequently
skipping logging after 150128 examples to avoid logging too frequently
train stats after 150144 examples: {'rewards_train/chosen': '0.43631', 'rewards_train/rejected': '-5.4103', 'rewards_train/margins': '5.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21417', 'examples_per_second': '5.3772', 'grad_norm': '5.2812', 'counters/examples': 150144, 'counters/updates': 9384}
skipping logging after 150160 examples to avoid logging too frequently
skipping logging after 150176 examples to avoid logging too frequently
skipping logging after 150192 examples to avoid logging too frequently
train stats after 150208 examples: {'rewards_train/chosen': '0.42625', 'rewards_train/rejected': '-4.6977', 'rewards_train/margins': '5.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23944', 'examples_per_second': '4.9907', 'grad_norm': '4.5', 'counters/examples': 150208, 'counters/updates': 9388}
skipping logging after 150224 examples to avoid logging too frequently
skipping logging after 150240 examples to avoid logging too frequently
skipping logging after 150256 examples to avoid logging too frequently
train stats after 150272 examples: {'rewards_train/chosen': '0.35096', 'rewards_train/rejected': '-5.6256', 'rewards_train/margins': '5.9297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23737', 'examples_per_second': '5.7592', 'grad_norm': '5.6562', 'counters/examples': 150272, 'counters/updates': 9392}
skipping logging after 150288 examples to avoid logging too frequently
skipping logging after 150304 examples to avoid logging too frequently
skipping logging after 150320 examples to avoid logging too frequently
train stats after 150336 examples: {'rewards_train/chosen': '0.38511', 'rewards_train/rejected': '-6.288', 'rewards_train/margins': '6.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23535', 'examples_per_second': '4.7146', 'grad_norm': '5', 'counters/examples': 150336, 'counters/updates': 9396}
skipping logging after 150352 examples to avoid logging too frequently
skipping logging after 150368 examples to avoid logging too frequently
skipping logging after 150384 examples to avoid logging too frequently
train stats after 150400 examples: {'rewards_train/chosen': '0.12679', 'rewards_train/rejected': '-7.5505', 'rewards_train/margins': '7.9766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27893', 'examples_per_second': '4.9253', 'grad_norm': '5', 'counters/examples': 150400, 'counters/updates': 9400}
skipping logging after 150416 examples to avoid logging too frequently
skipping logging after 150432 examples to avoid logging too frequently
skipping logging after 150448 examples to avoid logging too frequently
train stats after 150464 examples: {'rewards_train/chosen': '0.67094', 'rewards_train/rejected': '-5.1805', 'rewards_train/margins': '5.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2196', 'examples_per_second': '4.1861', 'grad_norm': '5.5938', 'counters/examples': 150464, 'counters/updates': 9404}
skipping logging after 150480 examples to avoid logging too frequently
skipping logging after 150496 examples to avoid logging too frequently
skipping logging after 150512 examples to avoid logging too frequently
train stats after 150528 examples: {'rewards_train/chosen': '0.4447', 'rewards_train/rejected': '-5.3796', 'rewards_train/margins': '5.7148', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24438', 'examples_per_second': '5.3372', 'grad_norm': '4.7812', 'counters/examples': 150528, 'counters/updates': 9408}
skipping logging after 150544 examples to avoid logging too frequently
skipping logging after 150560 examples to avoid logging too frequently
skipping logging after 150576 examples to avoid logging too frequently
train stats after 150592 examples: {'rewards_train/chosen': '0.37781', 'rewards_train/rejected': '-6.1034', 'rewards_train/margins': '6.7656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23309', 'examples_per_second': '5.4932', 'grad_norm': '5', 'counters/examples': 150592, 'counters/updates': 9412}
skipping logging after 150608 examples to avoid logging too frequently
skipping logging after 150624 examples to avoid logging too frequently
skipping logging after 150640 examples to avoid logging too frequently
train stats after 150656 examples: {'rewards_train/chosen': '0.4479', 'rewards_train/rejected': '-6.1372', 'rewards_train/margins': '6.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2016', 'examples_per_second': '5.013', 'grad_norm': '4.0312', 'counters/examples': 150656, 'counters/updates': 9416}
skipping logging after 150672 examples to avoid logging too frequently
skipping logging after 150688 examples to avoid logging too frequently
skipping logging after 150704 examples to avoid logging too frequently
train stats after 150720 examples: {'rewards_train/chosen': '0.2835', 'rewards_train/rejected': '-6.8279', 'rewards_train/margins': '7.0547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26611', 'examples_per_second': '4.8022', 'grad_norm': '6.25', 'counters/examples': 150720, 'counters/updates': 9420}
skipping logging after 150736 examples to avoid logging too frequently
skipping logging after 150752 examples to avoid logging too frequently
skipping logging after 150768 examples to avoid logging too frequently
train stats after 150784 examples: {'rewards_train/chosen': '0.34455', 'rewards_train/rejected': '-4.6818', 'rewards_train/margins': '5.125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2663', 'examples_per_second': '4.9146', 'grad_norm': '6.75', 'counters/examples': 150784, 'counters/updates': 9424}
skipping logging after 150800 examples to avoid logging too frequently
skipping logging after 150816 examples to avoid logging too frequently
skipping logging after 150832 examples to avoid logging too frequently
train stats after 150848 examples: {'rewards_train/chosen': '0.46737', 'rewards_train/rejected': '-6.5187', 'rewards_train/margins': '6.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2323', 'examples_per_second': '4.5105', 'grad_norm': '5.4688', 'counters/examples': 150848, 'counters/updates': 9428}
skipping logging after 150864 examples to avoid logging too frequently
skipping logging after 150880 examples to avoid logging too frequently
skipping logging after 150896 examples to avoid logging too frequently
train stats after 150912 examples: {'rewards_train/chosen': '0.45064', 'rewards_train/rejected': '-6.1178', 'rewards_train/margins': '6.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22614', 'examples_per_second': '5.7082', 'grad_norm': '5.4062', 'counters/examples': 150912, 'counters/updates': 9432}
skipping logging after 150928 examples to avoid logging too frequently
skipping logging after 150944 examples to avoid logging too frequently
skipping logging after 150960 examples to avoid logging too frequently
train stats after 150976 examples: {'rewards_train/chosen': '0.65227', 'rewards_train/rejected': '-6.09', 'rewards_train/margins': '6.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21948', 'examples_per_second': '4.4004', 'grad_norm': '4.75', 'counters/examples': 150976, 'counters/updates': 9436}
skipping logging after 150992 examples to avoid logging too frequently
skipping logging after 151008 examples to avoid logging too frequently
skipping logging after 151024 examples to avoid logging too frequently
train stats after 151040 examples: {'rewards_train/chosen': '0.46961', 'rewards_train/rejected': '-4.9859', 'rewards_train/margins': '5.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24548', 'examples_per_second': '5.4105', 'grad_norm': '4.8438', 'counters/examples': 151040, 'counters/updates': 9440}
skipping logging after 151056 examples to avoid logging too frequently
skipping logging after 151072 examples to avoid logging too frequently
skipping logging after 151088 examples to avoid logging too frequently
train stats after 151104 examples: {'rewards_train/chosen': '0.24863', 'rewards_train/rejected': '-5.5562', 'rewards_train/margins': '5.7812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23425', 'examples_per_second': '5.2904', 'grad_norm': '4.375', 'counters/examples': 151104, 'counters/updates': 9444}
skipping logging after 151120 examples to avoid logging too frequently
skipping logging after 151136 examples to avoid logging too frequently
skipping logging after 151152 examples to avoid logging too frequently
train stats after 151168 examples: {'rewards_train/chosen': '0.52126', 'rewards_train/rejected': '-6.7388', 'rewards_train/margins': '7.4531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21674', 'examples_per_second': '5.7949', 'grad_norm': '5.1562', 'counters/examples': 151168, 'counters/updates': 9448}
skipping logging after 151184 examples to avoid logging too frequently
skipping logging after 151200 examples to avoid logging too frequently
skipping logging after 151216 examples to avoid logging too frequently
train stats after 151232 examples: {'rewards_train/chosen': '0.40509', 'rewards_train/rejected': '-5.0471', 'rewards_train/margins': '5.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19287', 'examples_per_second': '5.5387', 'grad_norm': '3.9062', 'counters/examples': 151232, 'counters/updates': 9452}
skipping logging after 151248 examples to avoid logging too frequently
skipping logging after 151264 examples to avoid logging too frequently
skipping logging after 151280 examples to avoid logging too frequently
train stats after 151296 examples: {'rewards_train/chosen': '0.20264', 'rewards_train/rejected': '-7.0996', 'rewards_train/margins': '6.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29053', 'examples_per_second': '6.238', 'grad_norm': '6.1875', 'counters/examples': 151296, 'counters/updates': 9456}
skipping logging after 151312 examples to avoid logging too frequently
skipping logging after 151328 examples to avoid logging too frequently
skipping logging after 151344 examples to avoid logging too frequently
train stats after 151360 examples: {'rewards_train/chosen': '0.01062', 'rewards_train/rejected': '-5.232', 'rewards_train/margins': '5.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21381', 'examples_per_second': '5.6577', 'grad_norm': '4.3438', 'counters/examples': 151360, 'counters/updates': 9460}
skipping logging after 151376 examples to avoid logging too frequently
skipping logging after 151392 examples to avoid logging too frequently
skipping logging after 151408 examples to avoid logging too frequently
train stats after 151424 examples: {'rewards_train/chosen': '0.20433', 'rewards_train/rejected': '-7.3179', 'rewards_train/margins': '7.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27716', 'examples_per_second': '6.114', 'grad_norm': '5.5312', 'counters/examples': 151424, 'counters/updates': 9464}
skipping logging after 151440 examples to avoid logging too frequently
skipping logging after 151456 examples to avoid logging too frequently
skipping logging after 151472 examples to avoid logging too frequently
train stats after 151488 examples: {'rewards_train/chosen': '0.19277', 'rewards_train/rejected': '-6.293', 'rewards_train/margins': '6.4531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2796', 'examples_per_second': '4.1634', 'grad_norm': '5.2812', 'counters/examples': 151488, 'counters/updates': 9468}
skipping logging after 151504 examples to avoid logging too frequently
skipping logging after 151520 examples to avoid logging too frequently
skipping logging after 151536 examples to avoid logging too frequently
train stats after 151552 examples: {'rewards_train/chosen': '0.14488', 'rewards_train/rejected': '-5.0748', 'rewards_train/margins': '5.1172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27472', 'examples_per_second': '4.9729', 'grad_norm': '5.25', 'counters/examples': 151552, 'counters/updates': 9472}
skipping logging after 151568 examples to avoid logging too frequently
skipping logging after 151584 examples to avoid logging too frequently
skipping logging after 151600 examples to avoid logging too frequently
train stats after 151616 examples: {'rewards_train/chosen': '0.61088', 'rewards_train/rejected': '-5.3623', 'rewards_train/margins': '5.9766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21826', 'examples_per_second': '4.8538', 'grad_norm': '5.375', 'counters/examples': 151616, 'counters/updates': 9476}
skipping logging after 151632 examples to avoid logging too frequently
skipping logging after 151648 examples to avoid logging too frequently
skipping logging after 151664 examples to avoid logging too frequently
train stats after 151680 examples: {'rewards_train/chosen': '0.50451', 'rewards_train/rejected': '-5.3997', 'rewards_train/margins': '5.7266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2594', 'examples_per_second': '4.4484', 'grad_norm': '6.4375', 'counters/examples': 151680, 'counters/updates': 9480}
skipping logging after 151696 examples to avoid logging too frequently
skipping logging after 151712 examples to avoid logging too frequently
skipping logging after 151728 examples to avoid logging too frequently
train stats after 151744 examples: {'rewards_train/chosen': '0.36727', 'rewards_train/rejected': '-6.1086', 'rewards_train/margins': '6.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24603', 'examples_per_second': '4.2943', 'grad_norm': '6.2188', 'counters/examples': 151744, 'counters/updates': 9484}
skipping logging after 151760 examples to avoid logging too frequently
skipping logging after 151776 examples to avoid logging too frequently
skipping logging after 151792 examples to avoid logging too frequently
train stats after 151808 examples: {'rewards_train/chosen': '0.25007', 'rewards_train/rejected': '-5.459', 'rewards_train/margins': '5.3867', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25482', 'examples_per_second': '5.8933', 'grad_norm': '4.7812', 'counters/examples': 151808, 'counters/updates': 9488}
skipping logging after 151824 examples to avoid logging too frequently
skipping logging after 151840 examples to avoid logging too frequently
skipping logging after 151856 examples to avoid logging too frequently
train stats after 151872 examples: {'rewards_train/chosen': '0.3972', 'rewards_train/rejected': '-5.8703', 'rewards_train/margins': '6.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25262', 'examples_per_second': '4.9753', 'grad_norm': '4.625', 'counters/examples': 151872, 'counters/updates': 9492}
skipping logging after 151888 examples to avoid logging too frequently
skipping logging after 151904 examples to avoid logging too frequently
skipping logging after 151920 examples to avoid logging too frequently
train stats after 151936 examples: {'rewards_train/chosen': '0.48793', 'rewards_train/rejected': '-6.1608', 'rewards_train/margins': '6.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19586', 'examples_per_second': '3.8461', 'grad_norm': '5.4062', 'counters/examples': 151936, 'counters/updates': 9496}
skipping logging after 151952 examples to avoid logging too frequently
skipping logging after 151968 examples to avoid logging too frequently
skipping logging after 151984 examples to avoid logging too frequently
train stats after 152000 examples: {'rewards_train/chosen': '0.29496', 'rewards_train/rejected': '-5.6083', 'rewards_train/margins': '5.9766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2674', 'examples_per_second': '4.7381', 'grad_norm': '5.75', 'counters/examples': 152000, 'counters/updates': 9500}
Running evaluation after 152000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.25s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.16s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:39,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.65s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.47s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:33,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.51s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:33,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.40s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:30,  1.47s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:27,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.22s/it]Computing eval metrics:  50%|█████     | 16/32 [00:21<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.31s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.12s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]
eval after 152000: {'rewards_eval/chosen': '-5.432', 'rewards_eval/rejected': '-5.8593', 'rewards_eval/margins': '0.29688', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46036'}
skipping logging after 152016 examples to avoid logging too frequently
skipping logging after 152032 examples to avoid logging too frequently
skipping logging after 152048 examples to avoid logging too frequently
train stats after 152064 examples: {'rewards_train/chosen': '0.48684', 'rewards_train/rejected': '-6.0195', 'rewards_train/margins': '6.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20374', 'examples_per_second': '4.3109', 'grad_norm': '5.4688', 'counters/examples': 152064, 'counters/updates': 9504}
skipping logging after 152080 examples to avoid logging too frequently
skipping logging after 152096 examples to avoid logging too frequently
skipping logging after 152112 examples to avoid logging too frequently
train stats after 152128 examples: {'rewards_train/chosen': '0.49737', 'rewards_train/rejected': '-6.5156', 'rewards_train/margins': '7.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.16309', 'examples_per_second': '5.1904', 'grad_norm': '4.5938', 'counters/examples': 152128, 'counters/updates': 9508}
skipping logging after 152144 examples to avoid logging too frequently
skipping logging after 152160 examples to avoid logging too frequently
skipping logging after 152176 examples to avoid logging too frequently
train stats after 152192 examples: {'rewards_train/chosen': '0.31277', 'rewards_train/rejected': '-7.216', 'rewards_train/margins': '7.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25385', 'examples_per_second': '5.5813', 'grad_norm': '5.25', 'counters/examples': 152192, 'counters/updates': 9512}
skipping logging after 152208 examples to avoid logging too frequently
skipping logging after 152224 examples to avoid logging too frequently
skipping logging after 152240 examples to avoid logging too frequently
train stats after 152256 examples: {'rewards_train/chosen': '0.2081', 'rewards_train/rejected': '-6.7115', 'rewards_train/margins': '6.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21344', 'examples_per_second': '4.856', 'grad_norm': '4.7188', 'counters/examples': 152256, 'counters/updates': 9516}
skipping logging after 152272 examples to avoid logging too frequently
skipping logging after 152288 examples to avoid logging too frequently
skipping logging after 152304 examples to avoid logging too frequently
train stats after 152320 examples: {'rewards_train/chosen': '0.40028', 'rewards_train/rejected': '-5.2998', 'rewards_train/margins': '5.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2525', 'examples_per_second': '5.5802', 'grad_norm': '5.0312', 'counters/examples': 152320, 'counters/updates': 9520}
skipping logging after 152336 examples to avoid logging too frequently
skipping logging after 152352 examples to avoid logging too frequently
skipping logging after 152368 examples to avoid logging too frequently
train stats after 152384 examples: {'rewards_train/chosen': '0.23286', 'rewards_train/rejected': '-5.2478', 'rewards_train/margins': '5.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24823', 'examples_per_second': '4.6896', 'grad_norm': '6.25', 'counters/examples': 152384, 'counters/updates': 9524}
skipping logging after 152400 examples to avoid logging too frequently
skipping logging after 152416 examples to avoid logging too frequently
skipping logging after 152432 examples to avoid logging too frequently
train stats after 152448 examples: {'rewards_train/chosen': '0.010642', 'rewards_train/rejected': '-7.2838', 'rewards_train/margins': '6.6992', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26373', 'examples_per_second': '4.7393', 'grad_norm': '5.0312', 'counters/examples': 152448, 'counters/updates': 9528}
skipping logging after 152464 examples to avoid logging too frequently
skipping logging after 152480 examples to avoid logging too frequently
skipping logging after 152496 examples to avoid logging too frequently
train stats after 152512 examples: {'rewards_train/chosen': '0.58834', 'rewards_train/rejected': '-6.5804', 'rewards_train/margins': '7.2344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19897', 'examples_per_second': '4.483', 'grad_norm': '5.0312', 'counters/examples': 152512, 'counters/updates': 9532}
skipping logging after 152528 examples to avoid logging too frequently
skipping logging after 152544 examples to avoid logging too frequently
skipping logging after 152560 examples to avoid logging too frequently
train stats after 152576 examples: {'rewards_train/chosen': '0.57273', 'rewards_train/rejected': '-6.1468', 'rewards_train/margins': '6.7109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.16315', 'examples_per_second': '4.2935', 'grad_norm': '4.0938', 'counters/examples': 152576, 'counters/updates': 9536}
skipping logging after 152592 examples to avoid logging too frequently
skipping logging after 152608 examples to avoid logging too frequently
skipping logging after 152624 examples to avoid logging too frequently
train stats after 152640 examples: {'rewards_train/chosen': '-0.10837', 'rewards_train/rejected': '-6.0705', 'rewards_train/margins': '5.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20465', 'examples_per_second': '5.4067', 'grad_norm': '4.875', 'counters/examples': 152640, 'counters/updates': 9540}
skipping logging after 152656 examples to avoid logging too frequently
skipping logging after 152672 examples to avoid logging too frequently
skipping logging after 152688 examples to avoid logging too frequently
train stats after 152704 examples: {'rewards_train/chosen': '0.4307', 'rewards_train/rejected': '-6.345', 'rewards_train/margins': '6.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22791', 'examples_per_second': '4.5215', 'grad_norm': '4.75', 'counters/examples': 152704, 'counters/updates': 9544}
skipping logging after 152720 examples to avoid logging too frequently
skipping logging after 152736 examples to avoid logging too frequently
skipping logging after 152752 examples to avoid logging too frequently
train stats after 152768 examples: {'rewards_train/chosen': '0.31201', 'rewards_train/rejected': '-5.4903', 'rewards_train/margins': '5.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20807', 'examples_per_second': '5.3243', 'grad_norm': '3.7344', 'counters/examples': 152768, 'counters/updates': 9548}
skipping logging after 152784 examples to avoid logging too frequently
skipping logging after 152800 examples to avoid logging too frequently
skipping logging after 152816 examples to avoid logging too frequently
train stats after 152832 examples: {'rewards_train/chosen': '0.22672', 'rewards_train/rejected': '-4.427', 'rewards_train/margins': '4.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26422', 'examples_per_second': '4.3782', 'grad_norm': '5.75', 'counters/examples': 152832, 'counters/updates': 9552}
skipping logging after 152848 examples to avoid logging too frequently
skipping logging after 152864 examples to avoid logging too frequently
skipping logging after 152880 examples to avoid logging too frequently
train stats after 152896 examples: {'rewards_train/chosen': '0.46701', 'rewards_train/rejected': '-5.7275', 'rewards_train/margins': '6.2109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20142', 'examples_per_second': '5.9223', 'grad_norm': '4.8125', 'counters/examples': 152896, 'counters/updates': 9556}
skipping logging after 152912 examples to avoid logging too frequently
skipping logging after 152928 examples to avoid logging too frequently
skipping logging after 152944 examples to avoid logging too frequently
train stats after 152960 examples: {'rewards_train/chosen': '0.27342', 'rewards_train/rejected': '-5.831', 'rewards_train/margins': '5.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23596', 'examples_per_second': '4.3906', 'grad_norm': '5.4375', 'counters/examples': 152960, 'counters/updates': 9560}
skipping logging after 152976 examples to avoid logging too frequently
skipping logging after 152992 examples to avoid logging too frequently
skipping logging after 153008 examples to avoid logging too frequently
train stats after 153024 examples: {'rewards_train/chosen': '0.29244', 'rewards_train/rejected': '-5.0919', 'rewards_train/margins': '5.5898', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27722', 'examples_per_second': '4.724', 'grad_norm': '5.1562', 'counters/examples': 153024, 'counters/updates': 9564}
skipping logging after 153040 examples to avoid logging too frequently
skipping logging after 153056 examples to avoid logging too frequently
skipping logging after 153072 examples to avoid logging too frequently
train stats after 153088 examples: {'rewards_train/chosen': '0.39089', 'rewards_train/rejected': '-5.6031', 'rewards_train/margins': '6.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23102', 'examples_per_second': '4.5781', 'grad_norm': '4.9688', 'counters/examples': 153088, 'counters/updates': 9568}
skipping logging after 153104 examples to avoid logging too frequently
skipping logging after 153120 examples to avoid logging too frequently
skipping logging after 153136 examples to avoid logging too frequently
train stats after 153152 examples: {'rewards_train/chosen': '0.46163', 'rewards_train/rejected': '-5.3917', 'rewards_train/margins': '5.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22198', 'examples_per_second': '4.8334', 'grad_norm': '4.375', 'counters/examples': 153152, 'counters/updates': 9572}
skipping logging after 153168 examples to avoid logging too frequently
skipping logging after 153184 examples to avoid logging too frequently
skipping logging after 153200 examples to avoid logging too frequently
train stats after 153216 examples: {'rewards_train/chosen': '0.93086', 'rewards_train/rejected': '-5.7557', 'rewards_train/margins': '6.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17212', 'examples_per_second': '4.6856', 'grad_norm': '4.7812', 'counters/examples': 153216, 'counters/updates': 9576}
skipping logging after 153232 examples to avoid logging too frequently
skipping logging after 153248 examples to avoid logging too frequently
skipping logging after 153264 examples to avoid logging too frequently
train stats after 153280 examples: {'rewards_train/chosen': '0.33131', 'rewards_train/rejected': '-6.2156', 'rewards_train/margins': '6.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25928', 'examples_per_second': '4.5477', 'grad_norm': '5.0938', 'counters/examples': 153280, 'counters/updates': 9580}
skipping logging after 153296 examples to avoid logging too frequently
skipping logging after 153312 examples to avoid logging too frequently
skipping logging after 153328 examples to avoid logging too frequently
train stats after 153344 examples: {'rewards_train/chosen': '0.4773', 'rewards_train/rejected': '-7.0534', 'rewards_train/margins': '7.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20599', 'examples_per_second': '5.1405', 'grad_norm': '5.3438', 'counters/examples': 153344, 'counters/updates': 9584}
skipping logging after 153360 examples to avoid logging too frequently
skipping logging after 153376 examples to avoid logging too frequently
skipping logging after 153392 examples to avoid logging too frequently
train stats after 153408 examples: {'rewards_train/chosen': '0.30572', 'rewards_train/rejected': '-6.5073', 'rewards_train/margins': '7.0547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22925', 'examples_per_second': '5.0224', 'grad_norm': '4.5', 'counters/examples': 153408, 'counters/updates': 9588}
skipping logging after 153424 examples to avoid logging too frequently
skipping logging after 153440 examples to avoid logging too frequently
skipping logging after 153456 examples to avoid logging too frequently
train stats after 153472 examples: {'rewards_train/chosen': '0.73814', 'rewards_train/rejected': '-5.528', 'rewards_train/margins': '6.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18915', 'examples_per_second': '5.0747', 'grad_norm': '4.4688', 'counters/examples': 153472, 'counters/updates': 9592}
skipping logging after 153488 examples to avoid logging too frequently
skipping logging after 153504 examples to avoid logging too frequently
skipping logging after 153520 examples to avoid logging too frequently
train stats after 153536 examples: {'rewards_train/chosen': '0.48318', 'rewards_train/rejected': '-7.0138', 'rewards_train/margins': '7.5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2478', 'examples_per_second': '5.2094', 'grad_norm': '5.8125', 'counters/examples': 153536, 'counters/updates': 9596}
skipping logging after 153552 examples to avoid logging too frequently
skipping logging after 153568 examples to avoid logging too frequently
skipping logging after 153584 examples to avoid logging too frequently
train stats after 153600 examples: {'rewards_train/chosen': '0.46675', 'rewards_train/rejected': '-6.6496', 'rewards_train/margins': '7.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24451', 'examples_per_second': '5.4971', 'grad_norm': '4.875', 'counters/examples': 153600, 'counters/updates': 9600}
skipping logging after 153616 examples to avoid logging too frequently
skipping logging after 153632 examples to avoid logging too frequently
skipping logging after 153648 examples to avoid logging too frequently
train stats after 153664 examples: {'rewards_train/chosen': '0.86151', 'rewards_train/rejected': '-5.8375', 'rewards_train/margins': '6.7812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17877', 'examples_per_second': '4.3394', 'grad_norm': '4.2188', 'counters/examples': 153664, 'counters/updates': 9604}
skipping logging after 153680 examples to avoid logging too frequently
skipping logging after 153696 examples to avoid logging too frequently
skipping logging after 153712 examples to avoid logging too frequently
train stats after 153728 examples: {'rewards_train/chosen': '0.44071', 'rewards_train/rejected': '-6.7576', 'rewards_train/margins': '7.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.16278', 'examples_per_second': '5.083', 'grad_norm': '4.0625', 'counters/examples': 153728, 'counters/updates': 9608}
skipping logging after 153744 examples to avoid logging too frequently
skipping logging after 153760 examples to avoid logging too frequently
skipping logging after 153776 examples to avoid logging too frequently
train stats after 153792 examples: {'rewards_train/chosen': '0.5151', 'rewards_train/rejected': '-6.1078', 'rewards_train/margins': '6.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23499', 'examples_per_second': '5.0724', 'grad_norm': '5.0312', 'counters/examples': 153792, 'counters/updates': 9612}
skipping logging after 153808 examples to avoid logging too frequently
skipping logging after 153824 examples to avoid logging too frequently
skipping logging after 153840 examples to avoid logging too frequently
train stats after 153856 examples: {'rewards_train/chosen': '0.1252', 'rewards_train/rejected': '-5.3934', 'rewards_train/margins': '5.3789', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29871', 'examples_per_second': '5.1749', 'grad_norm': '5.3438', 'counters/examples': 153856, 'counters/updates': 9616}
skipping logging after 153872 examples to avoid logging too frequently
skipping logging after 153888 examples to avoid logging too frequently
skipping logging after 153904 examples to avoid logging too frequently
train stats after 153920 examples: {'rewards_train/chosen': '0.4736', 'rewards_train/rejected': '-6.3163', 'rewards_train/margins': '6.8906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24097', 'examples_per_second': '4.7496', 'grad_norm': '6.0625', 'counters/examples': 153920, 'counters/updates': 9620}
skipping logging after 153936 examples to avoid logging too frequently
skipping logging after 153952 examples to avoid logging too frequently
skipping logging after 153968 examples to avoid logging too frequently
train stats after 153984 examples: {'rewards_train/chosen': '0.49797', 'rewards_train/rejected': '-5.2646', 'rewards_train/margins': '5.8086', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24866', 'examples_per_second': '5.0599', 'grad_norm': '4.6562', 'counters/examples': 153984, 'counters/updates': 9624}
skipping logging after 154000 examples to avoid logging too frequently
skipping logging after 154016 examples to avoid logging too frequently
skipping logging after 154032 examples to avoid logging too frequently
train stats after 154048 examples: {'rewards_train/chosen': '0.38302', 'rewards_train/rejected': '-5.158', 'rewards_train/margins': '5.5977', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25775', 'examples_per_second': '5.5532', 'grad_norm': '6.0625', 'counters/examples': 154048, 'counters/updates': 9628}
skipping logging after 154064 examples to avoid logging too frequently
skipping logging after 154080 examples to avoid logging too frequently
skipping logging after 154096 examples to avoid logging too frequently
train stats after 154112 examples: {'rewards_train/chosen': '0.45905', 'rewards_train/rejected': '-6.3242', 'rewards_train/margins': '5.9453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26495', 'examples_per_second': '4.0839', 'grad_norm': '5.8438', 'counters/examples': 154112, 'counters/updates': 9632}
skipping logging after 154128 examples to avoid logging too frequently
skipping logging after 154144 examples to avoid logging too frequently
skipping logging after 154160 examples to avoid logging too frequently
train stats after 154176 examples: {'rewards_train/chosen': '0.65172', 'rewards_train/rejected': '-4.5834', 'rewards_train/margins': '5.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21808', 'examples_per_second': '4.9839', 'grad_norm': '4.625', 'counters/examples': 154176, 'counters/updates': 9636}
skipping logging after 154192 examples to avoid logging too frequently
skipping logging after 154208 examples to avoid logging too frequently
skipping logging after 154224 examples to avoid logging too frequently
train stats after 154240 examples: {'rewards_train/chosen': '0.33937', 'rewards_train/rejected': '-4.8025', 'rewards_train/margins': '5.1406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22473', 'examples_per_second': '5.6253', 'grad_norm': '5.0312', 'counters/examples': 154240, 'counters/updates': 9640}
skipping logging after 154256 examples to avoid logging too frequently
skipping logging after 154272 examples to avoid logging too frequently
skipping logging after 154288 examples to avoid logging too frequently
train stats after 154304 examples: {'rewards_train/chosen': '0.43483', 'rewards_train/rejected': '-5.201', 'rewards_train/margins': '5.6641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24554', 'examples_per_second': '5.1468', 'grad_norm': '4.6562', 'counters/examples': 154304, 'counters/updates': 9644}
skipping logging after 154320 examples to avoid logging too frequently
skipping logging after 154336 examples to avoid logging too frequently
skipping logging after 154352 examples to avoid logging too frequently
train stats after 154368 examples: {'rewards_train/chosen': '0.23976', 'rewards_train/rejected': '-5.2348', 'rewards_train/margins': '5.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27307', 'examples_per_second': '5.4962', 'grad_norm': '9', 'counters/examples': 154368, 'counters/updates': 9648}
skipping logging after 154384 examples to avoid logging too frequently
skipping logging after 154400 examples to avoid logging too frequently
skipping logging after 154416 examples to avoid logging too frequently
train stats after 154432 examples: {'rewards_train/chosen': '0.56538', 'rewards_train/rejected': '-6.0895', 'rewards_train/margins': '6.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19891', 'examples_per_second': '4.2307', 'grad_norm': '5.25', 'counters/examples': 154432, 'counters/updates': 9652}
skipping logging after 154448 examples to avoid logging too frequently
skipping logging after 154464 examples to avoid logging too frequently
skipping logging after 154480 examples to avoid logging too frequently
train stats after 154496 examples: {'rewards_train/chosen': '0.46431', 'rewards_train/rejected': '-5.6686', 'rewards_train/margins': '6.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22192', 'examples_per_second': '4.9856', 'grad_norm': '5.25', 'counters/examples': 154496, 'counters/updates': 9656}
skipping logging after 154512 examples to avoid logging too frequently
skipping logging after 154528 examples to avoid logging too frequently
skipping logging after 154544 examples to avoid logging too frequently
train stats after 154560 examples: {'rewards_train/chosen': '0.40696', 'rewards_train/rejected': '-5.8252', 'rewards_train/margins': '6.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26599', 'examples_per_second': '5.9074', 'grad_norm': '5.1875', 'counters/examples': 154560, 'counters/updates': 9660}
skipping logging after 154576 examples to avoid logging too frequently
skipping logging after 154592 examples to avoid logging too frequently
skipping logging after 154608 examples to avoid logging too frequently
train stats after 154624 examples: {'rewards_train/chosen': '0.30587', 'rewards_train/rejected': '-5.8014', 'rewards_train/margins': '6.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19757', 'examples_per_second': '4.4287', 'grad_norm': '4.8125', 'counters/examples': 154624, 'counters/updates': 9664}
skipping logging after 154640 examples to avoid logging too frequently
skipping logging after 154656 examples to avoid logging too frequently
skipping logging after 154672 examples to avoid logging too frequently
train stats after 154688 examples: {'rewards_train/chosen': '0.27551', 'rewards_train/rejected': '-4.5212', 'rewards_train/margins': '4.6328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25873', 'examples_per_second': '5.2883', 'grad_norm': '4.625', 'counters/examples': 154688, 'counters/updates': 9668}
skipping logging after 154704 examples to avoid logging too frequently
skipping logging after 154720 examples to avoid logging too frequently
skipping logging after 154736 examples to avoid logging too frequently
train stats after 154752 examples: {'rewards_train/chosen': '0.55379', 'rewards_train/rejected': '-5.4045', 'rewards_train/margins': '5.7734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24237', 'examples_per_second': '5.3503', 'grad_norm': '5.3438', 'counters/examples': 154752, 'counters/updates': 9672}
skipping logging after 154768 examples to avoid logging too frequently
skipping logging after 154784 examples to avoid logging too frequently
skipping logging after 154800 examples to avoid logging too frequently
train stats after 154816 examples: {'rewards_train/chosen': '-0.062317', 'rewards_train/rejected': '-5.5537', 'rewards_train/margins': '5.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25073', 'examples_per_second': '5.2921', 'grad_norm': '5.5', 'counters/examples': 154816, 'counters/updates': 9676}
skipping logging after 154832 examples to avoid logging too frequently
skipping logging after 154848 examples to avoid logging too frequently
skipping logging after 154864 examples to avoid logging too frequently
train stats after 154880 examples: {'rewards_train/chosen': '0.42967', 'rewards_train/rejected': '-5.872', 'rewards_train/margins': '6.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27045', 'examples_per_second': '4.8758', 'grad_norm': '6.375', 'counters/examples': 154880, 'counters/updates': 9680}
skipping logging after 154896 examples to avoid logging too frequently
skipping logging after 154912 examples to avoid logging too frequently
skipping logging after 154928 examples to avoid logging too frequently
train stats after 154944 examples: {'rewards_train/chosen': '0.16543', 'rewards_train/rejected': '-5.2175', 'rewards_train/margins': '5.4844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26825', 'examples_per_second': '4.7455', 'grad_norm': '4.8438', 'counters/examples': 154944, 'counters/updates': 9684}
skipping logging after 154960 examples to avoid logging too frequently
skipping logging after 154976 examples to avoid logging too frequently
skipping logging after 154992 examples to avoid logging too frequently
train stats after 155008 examples: {'rewards_train/chosen': '0.50312', 'rewards_train/rejected': '-5.1482', 'rewards_train/margins': '5.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19171', 'examples_per_second': '5.807', 'grad_norm': '4.375', 'counters/examples': 155008, 'counters/updates': 9688}
skipping logging after 155024 examples to avoid logging too frequently
skipping logging after 155040 examples to avoid logging too frequently
skipping logging after 155056 examples to avoid logging too frequently
train stats after 155072 examples: {'rewards_train/chosen': '0.13513', 'rewards_train/rejected': '-5.5556', 'rewards_train/margins': '5.668', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24457', 'examples_per_second': '5.0386', 'grad_norm': '4.7812', 'counters/examples': 155072, 'counters/updates': 9692}
skipping logging after 155088 examples to avoid logging too frequently
skipping logging after 155104 examples to avoid logging too frequently
skipping logging after 155120 examples to avoid logging too frequently
train stats after 155136 examples: {'rewards_train/chosen': '0.088812', 'rewards_train/rejected': '-5.5575', 'rewards_train/margins': '5.6328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2168', 'examples_per_second': '5.3701', 'grad_norm': '4.4062', 'counters/examples': 155136, 'counters/updates': 9696}
skipping logging after 155152 examples to avoid logging too frequently
skipping logging after 155168 examples to avoid logging too frequently
skipping logging after 155184 examples to avoid logging too frequently
train stats after 155200 examples: {'rewards_train/chosen': '0.34123', 'rewards_train/rejected': '-5.9133', 'rewards_train/margins': '6.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23676', 'examples_per_second': '5.4111', 'grad_norm': '4.625', 'counters/examples': 155200, 'counters/updates': 9700}
skipping logging after 155216 examples to avoid logging too frequently
skipping logging after 155232 examples to avoid logging too frequently
skipping logging after 155248 examples to avoid logging too frequently
train stats after 155264 examples: {'rewards_train/chosen': '0.15708', 'rewards_train/rejected': '-6.1914', 'rewards_train/margins': '6.4219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24762', 'examples_per_second': '5.7655', 'grad_norm': '5.1562', 'counters/examples': 155264, 'counters/updates': 9704}
skipping logging after 155280 examples to avoid logging too frequently
skipping logging after 155296 examples to avoid logging too frequently
skipping logging after 155312 examples to avoid logging too frequently
train stats after 155328 examples: {'rewards_train/chosen': '0.27589', 'rewards_train/rejected': '-5.2288', 'rewards_train/margins': '5.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24683', 'examples_per_second': '5.3374', 'grad_norm': '5.125', 'counters/examples': 155328, 'counters/updates': 9708}
skipping logging after 155344 examples to avoid logging too frequently
skipping logging after 155360 examples to avoid logging too frequently
skipping logging after 155376 examples to avoid logging too frequently
train stats after 155392 examples: {'rewards_train/chosen': '0.16125', 'rewards_train/rejected': '-6.7963', 'rewards_train/margins': '7.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21527', 'examples_per_second': '5.5945', 'grad_norm': '4.7812', 'counters/examples': 155392, 'counters/updates': 9712}
skipping logging after 155408 examples to avoid logging too frequently
skipping logging after 155424 examples to avoid logging too frequently
skipping logging after 155440 examples to avoid logging too frequently
train stats after 155456 examples: {'rewards_train/chosen': '0.48233', 'rewards_train/rejected': '-5.8765', 'rewards_train/margins': '6.3672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20105', 'examples_per_second': '5.0764', 'grad_norm': '4.4062', 'counters/examples': 155456, 'counters/updates': 9716}
skipping logging after 155472 examples to avoid logging too frequently
skipping logging after 155488 examples to avoid logging too frequently
skipping logging after 155504 examples to avoid logging too frequently
train stats after 155520 examples: {'rewards_train/chosen': '0.57288', 'rewards_train/rejected': '-5.2447', 'rewards_train/margins': '5.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23224', 'examples_per_second': '5.4824', 'grad_norm': '5.7188', 'counters/examples': 155520, 'counters/updates': 9720}
skipping logging after 155536 examples to avoid logging too frequently
skipping logging after 155552 examples to avoid logging too frequently
skipping logging after 155568 examples to avoid logging too frequently
train stats after 155584 examples: {'rewards_train/chosen': '0.38426', 'rewards_train/rejected': '-5.532', 'rewards_train/margins': '6.0312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23962', 'examples_per_second': '5.9171', 'grad_norm': '6.0625', 'counters/examples': 155584, 'counters/updates': 9724}
skipping logging after 155600 examples to avoid logging too frequently
skipping logging after 155616 examples to avoid logging too frequently
skipping logging after 155632 examples to avoid logging too frequently
train stats after 155648 examples: {'rewards_train/chosen': '0.10891', 'rewards_train/rejected': '-5.8747', 'rewards_train/margins': '6.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30823', 'examples_per_second': '5.2339', 'grad_norm': '6.2188', 'counters/examples': 155648, 'counters/updates': 9728}
skipping logging after 155664 examples to avoid logging too frequently
skipping logging after 155680 examples to avoid logging too frequently
skipping logging after 155696 examples to avoid logging too frequently
train stats after 155712 examples: {'rewards_train/chosen': '0.025139', 'rewards_train/rejected': '-5.984', 'rewards_train/margins': '6.1016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27802', 'examples_per_second': '4.7554', 'grad_norm': '4.7188', 'counters/examples': 155712, 'counters/updates': 9732}
skipping logging after 155728 examples to avoid logging too frequently
skipping logging after 155744 examples to avoid logging too frequently
skipping logging after 155760 examples to avoid logging too frequently
train stats after 155776 examples: {'rewards_train/chosen': '0.38717', 'rewards_train/rejected': '-4.9895', 'rewards_train/margins': '5.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25507', 'examples_per_second': '4.9393', 'grad_norm': '4.4688', 'counters/examples': 155776, 'counters/updates': 9736}
skipping logging after 155792 examples to avoid logging too frequently
skipping logging after 155808 examples to avoid logging too frequently
skipping logging after 155824 examples to avoid logging too frequently
train stats after 155840 examples: {'rewards_train/chosen': '0.20402', 'rewards_train/rejected': '-6.0192', 'rewards_train/margins': '6.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2558', 'examples_per_second': '4.834', 'grad_norm': '5.4062', 'counters/examples': 155840, 'counters/updates': 9740}
skipping logging after 155856 examples to avoid logging too frequently
skipping logging after 155872 examples to avoid logging too frequently
skipping logging after 155888 examples to avoid logging too frequently
train stats after 155904 examples: {'rewards_train/chosen': '0.59627', 'rewards_train/rejected': '-6.2913', 'rewards_train/margins': '6.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20465', 'examples_per_second': '4.8289', 'grad_norm': '4.375', 'counters/examples': 155904, 'counters/updates': 9744}
skipping logging after 155920 examples to avoid logging too frequently
skipping logging after 155936 examples to avoid logging too frequently
skipping logging after 155952 examples to avoid logging too frequently
train stats after 155968 examples: {'rewards_train/chosen': '0.45197', 'rewards_train/rejected': '-5.1326', 'rewards_train/margins': '5.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21649', 'examples_per_second': '6.1608', 'grad_norm': '5.0625', 'counters/examples': 155968, 'counters/updates': 9748}
skipping logging after 155984 examples to avoid logging too frequently
skipping logging after 156000 examples to avoid logging too frequently
Running evaluation after 156000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:53,  1.74s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:43,  1.45s/it]Computing eval metrics:   9%|▉         | 3/32 [00:04<00:36,  1.27s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.49s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.69s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:09<00:38,  1.50s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:10<00:34,  1.37s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:12<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:20<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:21<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:28<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.31s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:40<00:02,  1.18s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:41<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.12s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]
eval after 156000: {'rewards_eval/chosen': '-5.6734', 'rewards_eval/rejected': '-6.061', 'rewards_eval/margins': '0.25', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46072'}
skipping logging after 156016 examples to avoid logging too frequently
train stats after 156032 examples: {'rewards_train/chosen': '0.22649', 'rewards_train/rejected': '-5.9229', 'rewards_train/margins': '6.2969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22534', 'examples_per_second': '6.3441', 'grad_norm': '4.7812', 'counters/examples': 156032, 'counters/updates': 9752}
skipping logging after 156048 examples to avoid logging too frequently
skipping logging after 156064 examples to avoid logging too frequently
skipping logging after 156080 examples to avoid logging too frequently
train stats after 156096 examples: {'rewards_train/chosen': '0.43683', 'rewards_train/rejected': '-6.2404', 'rewards_train/margins': '6.7734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23407', 'examples_per_second': '5.7161', 'grad_norm': '5.0312', 'counters/examples': 156096, 'counters/updates': 9756}
skipping logging after 156112 examples to avoid logging too frequently
skipping logging after 156128 examples to avoid logging too frequently
skipping logging after 156144 examples to avoid logging too frequently
train stats after 156160 examples: {'rewards_train/chosen': '0.49746', 'rewards_train/rejected': '-5.3204', 'rewards_train/margins': '5.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23676', 'examples_per_second': '5.4068', 'grad_norm': '4.75', 'counters/examples': 156160, 'counters/updates': 9760}
skipping logging after 156176 examples to avoid logging too frequently
skipping logging after 156192 examples to avoid logging too frequently
skipping logging after 156208 examples to avoid logging too frequently
train stats after 156224 examples: {'rewards_train/chosen': '0.31956', 'rewards_train/rejected': '-5.7746', 'rewards_train/margins': '6.5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26306', 'examples_per_second': '6.6291', 'grad_norm': '5.625', 'counters/examples': 156224, 'counters/updates': 9764}
skipping logging after 156240 examples to avoid logging too frequently
skipping logging after 156256 examples to avoid logging too frequently
skipping logging after 156272 examples to avoid logging too frequently
train stats after 156288 examples: {'rewards_train/chosen': '0.4838', 'rewards_train/rejected': '-3.6234', 'rewards_train/margins': '4.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23761', 'examples_per_second': '6.347', 'grad_norm': '4.8125', 'counters/examples': 156288, 'counters/updates': 9768}
skipping logging after 156304 examples to avoid logging too frequently
skipping logging after 156320 examples to avoid logging too frequently
skipping logging after 156336 examples to avoid logging too frequently
train stats after 156352 examples: {'rewards_train/chosen': '0.25424', 'rewards_train/rejected': '-6.9307', 'rewards_train/margins': '7.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18958', 'examples_per_second': '4.8669', 'grad_norm': '4.4375', 'counters/examples': 156352, 'counters/updates': 9772}
skipping logging after 156368 examples to avoid logging too frequently
skipping logging after 156384 examples to avoid logging too frequently
skipping logging after 156400 examples to avoid logging too frequently
train stats after 156416 examples: {'rewards_train/chosen': '0.25316', 'rewards_train/rejected': '-5.4882', 'rewards_train/margins': '5.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23932', 'examples_per_second': '4.6007', 'grad_norm': '4.5312', 'counters/examples': 156416, 'counters/updates': 9776}
skipping logging after 156432 examples to avoid logging too frequently
skipping logging after 156448 examples to avoid logging too frequently
skipping logging after 156464 examples to avoid logging too frequently
train stats after 156480 examples: {'rewards_train/chosen': '0.48215', 'rewards_train/rejected': '-6.2568', 'rewards_train/margins': '6.7031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22699', 'examples_per_second': '5.1873', 'grad_norm': '4.4688', 'counters/examples': 156480, 'counters/updates': 9780}
skipping logging after 156496 examples to avoid logging too frequently
skipping logging after 156512 examples to avoid logging too frequently
skipping logging after 156528 examples to avoid logging too frequently
train stats after 156544 examples: {'rewards_train/chosen': '0.34351', 'rewards_train/rejected': '-5.7261', 'rewards_train/margins': '5.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2594', 'examples_per_second': '4.9679', 'grad_norm': '5.375', 'counters/examples': 156544, 'counters/updates': 9784}
skipping logging after 156560 examples to avoid logging too frequently
skipping logging after 156576 examples to avoid logging too frequently
skipping logging after 156592 examples to avoid logging too frequently
train stats after 156608 examples: {'rewards_train/chosen': '0.55336', 'rewards_train/rejected': '-7.5571', 'rewards_train/margins': '8.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20764', 'examples_per_second': '4.8234', 'grad_norm': '5.25', 'counters/examples': 156608, 'counters/updates': 9788}
skipping logging after 156624 examples to avoid logging too frequently
skipping logging after 156640 examples to avoid logging too frequently
skipping logging after 156656 examples to avoid logging too frequently
train stats after 156672 examples: {'rewards_train/chosen': '0.31334', 'rewards_train/rejected': '-5.1948', 'rewards_train/margins': '5.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23187', 'examples_per_second': '5.8876', 'grad_norm': '4.5312', 'counters/examples': 156672, 'counters/updates': 9792}
skipping logging after 156688 examples to avoid logging too frequently
skipping logging after 156704 examples to avoid logging too frequently
skipping logging after 156720 examples to avoid logging too frequently
train stats after 156736 examples: {'rewards_train/chosen': '0.54114', 'rewards_train/rejected': '-6.1035', 'rewards_train/margins': '6.7734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20685', 'examples_per_second': '4.9047', 'grad_norm': '4.4688', 'counters/examples': 156736, 'counters/updates': 9796}
skipping logging after 156752 examples to avoid logging too frequently
skipping logging after 156768 examples to avoid logging too frequently
skipping logging after 156784 examples to avoid logging too frequently
train stats after 156800 examples: {'rewards_train/chosen': '-0.0009492', 'rewards_train/rejected': '-6.3191', 'rewards_train/margins': '6.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23779', 'examples_per_second': '5.3555', 'grad_norm': '5.3438', 'counters/examples': 156800, 'counters/updates': 9800}
skipping logging after 156816 examples to avoid logging too frequently
skipping logging after 156832 examples to avoid logging too frequently
skipping logging after 156848 examples to avoid logging too frequently
train stats after 156864 examples: {'rewards_train/chosen': '0.54046', 'rewards_train/rejected': '-5.5385', 'rewards_train/margins': '5.3672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1615', 'examples_per_second': '5.2893', 'grad_norm': '4.0312', 'counters/examples': 156864, 'counters/updates': 9804}
skipping logging after 156880 examples to avoid logging too frequently
skipping logging after 156896 examples to avoid logging too frequently
skipping logging after 156912 examples to avoid logging too frequently
train stats after 156928 examples: {'rewards_train/chosen': '0.25477', 'rewards_train/rejected': '-5.5381', 'rewards_train/margins': '5.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22253', 'examples_per_second': '4.6916', 'grad_norm': '4.3125', 'counters/examples': 156928, 'counters/updates': 9808}
skipping logging after 156944 examples to avoid logging too frequently
skipping logging after 156960 examples to avoid logging too frequently
skipping logging after 156976 examples to avoid logging too frequently
train stats after 156992 examples: {'rewards_train/chosen': '0.31545', 'rewards_train/rejected': '-5.9653', 'rewards_train/margins': '6.1719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.276', 'examples_per_second': '5.9378', 'grad_norm': '5.3125', 'counters/examples': 156992, 'counters/updates': 9812}
skipping logging after 157008 examples to avoid logging too frequently
skipping logging after 157024 examples to avoid logging too frequently
skipping logging after 157040 examples to avoid logging too frequently
train stats after 157056 examples: {'rewards_train/chosen': '0.19108', 'rewards_train/rejected': '-5.4304', 'rewards_train/margins': '5.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25507', 'examples_per_second': '5.0594', 'grad_norm': '5.6875', 'counters/examples': 157056, 'counters/updates': 9816}
skipping logging after 157072 examples to avoid logging too frequently
skipping logging after 157088 examples to avoid logging too frequently
skipping logging after 157104 examples to avoid logging too frequently
train stats after 157120 examples: {'rewards_train/chosen': '0.37784', 'rewards_train/rejected': '-6.1779', 'rewards_train/margins': '6.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21613', 'examples_per_second': '5.506', 'grad_norm': '4.5', 'counters/examples': 157120, 'counters/updates': 9820}
skipping logging after 157136 examples to avoid logging too frequently
skipping logging after 157152 examples to avoid logging too frequently
skipping logging after 157168 examples to avoid logging too frequently
train stats after 157184 examples: {'rewards_train/chosen': '0.55017', 'rewards_train/rejected': '-5.8051', 'rewards_train/margins': '6.2227', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19769', 'examples_per_second': '5.0268', 'grad_norm': '4.9062', 'counters/examples': 157184, 'counters/updates': 9824}
skipping logging after 157200 examples to avoid logging too frequently
skipping logging after 157216 examples to avoid logging too frequently
skipping logging after 157232 examples to avoid logging too frequently
train stats after 157248 examples: {'rewards_train/chosen': '0.3242', 'rewards_train/rejected': '-6.303', 'rewards_train/margins': '6.8652', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28033', 'examples_per_second': '6.383', 'grad_norm': '5.7188', 'counters/examples': 157248, 'counters/updates': 9828}
skipping logging after 157264 examples to avoid logging too frequently
skipping logging after 157280 examples to avoid logging too frequently
skipping logging after 157296 examples to avoid logging too frequently
train stats after 157312 examples: {'rewards_train/chosen': '0.54886', 'rewards_train/rejected': '-5.3256', 'rewards_train/margins': '5.8828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20435', 'examples_per_second': '5.0712', 'grad_norm': '4.875', 'counters/examples': 157312, 'counters/updates': 9832}
skipping logging after 157328 examples to avoid logging too frequently
skipping logging after 157344 examples to avoid logging too frequently
skipping logging after 157360 examples to avoid logging too frequently
train stats after 157376 examples: {'rewards_train/chosen': '0.37863', 'rewards_train/rejected': '-4.3297', 'rewards_train/margins': '4.7422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25262', 'examples_per_second': '4.6399', 'grad_norm': '5.875', 'counters/examples': 157376, 'counters/updates': 9836}
skipping logging after 157392 examples to avoid logging too frequently
skipping logging after 157408 examples to avoid logging too frequently
skipping logging after 157424 examples to avoid logging too frequently
train stats after 157440 examples: {'rewards_train/chosen': '0.64516', 'rewards_train/rejected': '-7.0925', 'rewards_train/margins': '7.7266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18494', 'examples_per_second': '4.9825', 'grad_norm': '4.875', 'counters/examples': 157440, 'counters/updates': 9840}
skipping logging after 157456 examples to avoid logging too frequently
skipping logging after 157472 examples to avoid logging too frequently
skipping logging after 157488 examples to avoid logging too frequently
train stats after 157504 examples: {'rewards_train/chosen': '0.41251', 'rewards_train/rejected': '-5.9746', 'rewards_train/margins': '6.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22375', 'examples_per_second': '5.1553', 'grad_norm': '5.0625', 'counters/examples': 157504, 'counters/updates': 9844}
skipping logging after 157520 examples to avoid logging too frequently
skipping logging after 157536 examples to avoid logging too frequently
skipping logging after 157552 examples to avoid logging too frequently
train stats after 157568 examples: {'rewards_train/chosen': '0.44265', 'rewards_train/rejected': '-6.812', 'rewards_train/margins': '7.3594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24091', 'examples_per_second': '4.5588', 'grad_norm': '5.125', 'counters/examples': 157568, 'counters/updates': 9848}
skipping logging after 157584 examples to avoid logging too frequently
skipping logging after 157600 examples to avoid logging too frequently
skipping logging after 157616 examples to avoid logging too frequently
train stats after 157632 examples: {'rewards_train/chosen': '0.64613', 'rewards_train/rejected': '-5.5911', 'rewards_train/margins': '6.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21704', 'examples_per_second': '4.5025', 'grad_norm': '5.0625', 'counters/examples': 157632, 'counters/updates': 9852}
skipping logging after 157648 examples to avoid logging too frequently
skipping logging after 157664 examples to avoid logging too frequently
skipping logging after 157680 examples to avoid logging too frequently
train stats after 157696 examples: {'rewards_train/chosen': '-0.11286', 'rewards_train/rejected': '-4.4331', 'rewards_train/margins': '4.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22113', 'examples_per_second': '5.7249', 'grad_norm': '5.0938', 'counters/examples': 157696, 'counters/updates': 9856}
skipping logging after 157712 examples to avoid logging too frequently
skipping logging after 157728 examples to avoid logging too frequently
skipping logging after 157744 examples to avoid logging too frequently
train stats after 157760 examples: {'rewards_train/chosen': '0.083285', 'rewards_train/rejected': '-4.8896', 'rewards_train/margins': '5.1875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24927', 'examples_per_second': '5.4727', 'grad_norm': '4.9688', 'counters/examples': 157760, 'counters/updates': 9860}
skipping logging after 157776 examples to avoid logging too frequently
skipping logging after 157792 examples to avoid logging too frequently
skipping logging after 157808 examples to avoid logging too frequently
train stats after 157824 examples: {'rewards_train/chosen': '0.35731', 'rewards_train/rejected': '-6.5525', 'rewards_train/margins': '6.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.216', 'examples_per_second': '5.5153', 'grad_norm': '4.4062', 'counters/examples': 157824, 'counters/updates': 9864}
skipping logging after 157840 examples to avoid logging too frequently
skipping logging after 157856 examples to avoid logging too frequently
skipping logging after 157872 examples to avoid logging too frequently
train stats after 157888 examples: {'rewards_train/chosen': '0.46944', 'rewards_train/rejected': '-6.5623', 'rewards_train/margins': '7.1406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23041', 'examples_per_second': '5.2564', 'grad_norm': '3.8594', 'counters/examples': 157888, 'counters/updates': 9868}
skipping logging after 157904 examples to avoid logging too frequently
skipping logging after 157920 examples to avoid logging too frequently
skipping logging after 157936 examples to avoid logging too frequently
train stats after 157952 examples: {'rewards_train/chosen': '0.023076', 'rewards_train/rejected': '-5.4055', 'rewards_train/margins': '5.2227', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24579', 'examples_per_second': '4.5723', 'grad_norm': '5.4062', 'counters/examples': 157952, 'counters/updates': 9872}
skipping logging after 157968 examples to avoid logging too frequently
skipping logging after 157984 examples to avoid logging too frequently
skipping logging after 158000 examples to avoid logging too frequently
train stats after 158016 examples: {'rewards_train/chosen': '0.46686', 'rewards_train/rejected': '-5.6344', 'rewards_train/margins': '6.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27637', 'examples_per_second': '4.9474', 'grad_norm': '5.9375', 'counters/examples': 158016, 'counters/updates': 9876}
skipping logging after 158032 examples to avoid logging too frequently
skipping logging after 158048 examples to avoid logging too frequently
skipping logging after 158064 examples to avoid logging too frequently
train stats after 158080 examples: {'rewards_train/chosen': '0.51904', 'rewards_train/rejected': '-5.2718', 'rewards_train/margins': '5.8867', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20898', 'examples_per_second': '5.54', 'grad_norm': '4.7812', 'counters/examples': 158080, 'counters/updates': 9880}
skipping logging after 158096 examples to avoid logging too frequently
skipping logging after 158112 examples to avoid logging too frequently
skipping logging after 158128 examples to avoid logging too frequently
train stats after 158144 examples: {'rewards_train/chosen': '0.49746', 'rewards_train/rejected': '-5.6794', 'rewards_train/margins': '6.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23596', 'examples_per_second': '5.2505', 'grad_norm': '8.1875', 'counters/examples': 158144, 'counters/updates': 9884}
skipping logging after 158160 examples to avoid logging too frequently
skipping logging after 158176 examples to avoid logging too frequently
skipping logging after 158192 examples to avoid logging too frequently
train stats after 158208 examples: {'rewards_train/chosen': '0.29325', 'rewards_train/rejected': '-5.8185', 'rewards_train/margins': '6.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24591', 'examples_per_second': '6.4973', 'grad_norm': '5.0312', 'counters/examples': 158208, 'counters/updates': 9888}
skipping logging after 158224 examples to avoid logging too frequently
skipping logging after 158240 examples to avoid logging too frequently
skipping logging after 158256 examples to avoid logging too frequently
train stats after 158272 examples: {'rewards_train/chosen': '0.24694', 'rewards_train/rejected': '-4.9013', 'rewards_train/margins': '5.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29089', 'examples_per_second': '5.7153', 'grad_norm': '5.2188', 'counters/examples': 158272, 'counters/updates': 9892}
skipping logging after 158288 examples to avoid logging too frequently
skipping logging after 158304 examples to avoid logging too frequently
skipping logging after 158320 examples to avoid logging too frequently
train stats after 158336 examples: {'rewards_train/chosen': '0.45609', 'rewards_train/rejected': '-6.2292', 'rewards_train/margins': '6.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25104', 'examples_per_second': '4.5972', 'grad_norm': '4.75', 'counters/examples': 158336, 'counters/updates': 9896}
skipping logging after 158352 examples to avoid logging too frequently
skipping logging after 158368 examples to avoid logging too frequently
skipping logging after 158384 examples to avoid logging too frequently
train stats after 158400 examples: {'rewards_train/chosen': '0.57287', 'rewards_train/rejected': '-4.6396', 'rewards_train/margins': '5.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19873', 'examples_per_second': '6.2852', 'grad_norm': '4.875', 'counters/examples': 158400, 'counters/updates': 9900}
skipping logging after 158416 examples to avoid logging too frequently
skipping logging after 158432 examples to avoid logging too frequently
skipping logging after 158448 examples to avoid logging too frequently
train stats after 158464 examples: {'rewards_train/chosen': '0.48663', 'rewards_train/rejected': '-6.3503', 'rewards_train/margins': '6.6875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19781', 'examples_per_second': '4.8437', 'grad_norm': '4.5938', 'counters/examples': 158464, 'counters/updates': 9904}
skipping logging after 158480 examples to avoid logging too frequently
skipping logging after 158496 examples to avoid logging too frequently
skipping logging after 158512 examples to avoid logging too frequently
train stats after 158528 examples: {'rewards_train/chosen': '0.28239', 'rewards_train/rejected': '-6.2886', 'rewards_train/margins': '6.5391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22571', 'examples_per_second': '4.9127', 'grad_norm': '5.4062', 'counters/examples': 158528, 'counters/updates': 9908}
skipping logging after 158544 examples to avoid logging too frequently
skipping logging after 158560 examples to avoid logging too frequently
skipping logging after 158576 examples to avoid logging too frequently
train stats after 158592 examples: {'rewards_train/chosen': '0.31347', 'rewards_train/rejected': '-6.1319', 'rewards_train/margins': '6.5391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24536', 'examples_per_second': '5.4764', 'grad_norm': '4.5938', 'counters/examples': 158592, 'counters/updates': 9912}
skipping logging after 158608 examples to avoid logging too frequently
skipping logging after 158624 examples to avoid logging too frequently
skipping logging after 158640 examples to avoid logging too frequently
train stats after 158656 examples: {'rewards_train/chosen': '0.4348', 'rewards_train/rejected': '-5.9369', 'rewards_train/margins': '6.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20959', 'examples_per_second': '4.501', 'grad_norm': '5.5312', 'counters/examples': 158656, 'counters/updates': 9916}
skipping logging after 158672 examples to avoid logging too frequently
skipping logging after 158688 examples to avoid logging too frequently
skipping logging after 158704 examples to avoid logging too frequently
train stats after 158720 examples: {'rewards_train/chosen': '0.51353', 'rewards_train/rejected': '-5.9046', 'rewards_train/margins': '6.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20911', 'examples_per_second': '5.3485', 'grad_norm': '5.0312', 'counters/examples': 158720, 'counters/updates': 9920}
skipping logging after 158736 examples to avoid logging too frequently
skipping logging after 158752 examples to avoid logging too frequently
skipping logging after 158768 examples to avoid logging too frequently
train stats after 158784 examples: {'rewards_train/chosen': '0.66657', 'rewards_train/rejected': '-5.9895', 'rewards_train/margins': '6.5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20618', 'examples_per_second': '5.5956', 'grad_norm': '5.5625', 'counters/examples': 158784, 'counters/updates': 9924}
skipping logging after 158800 examples to avoid logging too frequently
skipping logging after 158816 examples to avoid logging too frequently
skipping logging after 158832 examples to avoid logging too frequently
train stats after 158848 examples: {'rewards_train/chosen': '0.4793', 'rewards_train/rejected': '-7.545', 'rewards_train/margins': '8.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20374', 'examples_per_second': '4.6083', 'grad_norm': '6.0938', 'counters/examples': 158848, 'counters/updates': 9928}
skipping logging after 158864 examples to avoid logging too frequently
skipping logging after 158880 examples to avoid logging too frequently
skipping logging after 158896 examples to avoid logging too frequently
train stats after 158912 examples: {'rewards_train/chosen': '0.38146', 'rewards_train/rejected': '-5.4605', 'rewards_train/margins': '6.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25183', 'examples_per_second': '5.4147', 'grad_norm': '5.2812', 'counters/examples': 158912, 'counters/updates': 9932}
skipping logging after 158928 examples to avoid logging too frequently
skipping logging after 158944 examples to avoid logging too frequently
skipping logging after 158960 examples to avoid logging too frequently
train stats after 158976 examples: {'rewards_train/chosen': '0.29853', 'rewards_train/rejected': '-6.5406', 'rewards_train/margins': '7.0156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27539', 'examples_per_second': '4.8483', 'grad_norm': '5.4375', 'counters/examples': 158976, 'counters/updates': 9936}
skipping logging after 158992 examples to avoid logging too frequently
skipping logging after 159008 examples to avoid logging too frequently
skipping logging after 159024 examples to avoid logging too frequently
train stats after 159040 examples: {'rewards_train/chosen': '0.1875', 'rewards_train/rejected': '-6.1534', 'rewards_train/margins': '6.4141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22406', 'examples_per_second': '4.5803', 'grad_norm': '5.3438', 'counters/examples': 159040, 'counters/updates': 9940}
skipping logging after 159056 examples to avoid logging too frequently
skipping logging after 159072 examples to avoid logging too frequently
skipping logging after 159088 examples to avoid logging too frequently
train stats after 159104 examples: {'rewards_train/chosen': '0.069336', 'rewards_train/rejected': '-6.5749', 'rewards_train/margins': '6.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25171', 'examples_per_second': '5.0978', 'grad_norm': '5.1562', 'counters/examples': 159104, 'counters/updates': 9944}
skipping logging after 159120 examples to avoid logging too frequently
skipping logging after 159136 examples to avoid logging too frequently
skipping logging after 159152 examples to avoid logging too frequently
train stats after 159168 examples: {'rewards_train/chosen': '0.27769', 'rewards_train/rejected': '-6.0188', 'rewards_train/margins': '6.375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21155', 'examples_per_second': '5.6279', 'grad_norm': '3.8281', 'counters/examples': 159168, 'counters/updates': 9948}
skipping logging after 159184 examples to avoid logging too frequently
skipping logging after 159200 examples to avoid logging too frequently
skipping logging after 159216 examples to avoid logging too frequently
train stats after 159232 examples: {'rewards_train/chosen': '0.59002', 'rewards_train/rejected': '-5.7939', 'rewards_train/margins': '6.3477', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22852', 'examples_per_second': '4.3948', 'grad_norm': '4.9375', 'counters/examples': 159232, 'counters/updates': 9952}
skipping logging after 159248 examples to avoid logging too frequently
skipping logging after 159264 examples to avoid logging too frequently
skipping logging after 159280 examples to avoid logging too frequently
train stats after 159296 examples: {'rewards_train/chosen': '0.35831', 'rewards_train/rejected': '-5.4757', 'rewards_train/margins': '5.8125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27295', 'examples_per_second': '4.6977', 'grad_norm': '4.9375', 'counters/examples': 159296, 'counters/updates': 9956}
skipping logging after 159312 examples to avoid logging too frequently
skipping logging after 159328 examples to avoid logging too frequently
skipping logging after 159344 examples to avoid logging too frequently
train stats after 159360 examples: {'rewards_train/chosen': '0.25602', 'rewards_train/rejected': '-4.8048', 'rewards_train/margins': '4.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2749', 'examples_per_second': '5.2875', 'grad_norm': '5.4375', 'counters/examples': 159360, 'counters/updates': 9960}
skipping logging after 159376 examples to avoid logging too frequently
skipping logging after 159392 examples to avoid logging too frequently
skipping logging after 159408 examples to avoid logging too frequently
train stats after 159424 examples: {'rewards_train/chosen': '0.24162', 'rewards_train/rejected': '-5.2169', 'rewards_train/margins': '5.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25696', 'examples_per_second': '5.6453', 'grad_norm': '5.25', 'counters/examples': 159424, 'counters/updates': 9964}
skipping logging after 159440 examples to avoid logging too frequently
skipping logging after 159456 examples to avoid logging too frequently
skipping logging after 159472 examples to avoid logging too frequently
train stats after 159488 examples: {'rewards_train/chosen': '0.39003', 'rewards_train/rejected': '-5.9636', 'rewards_train/margins': '6.1406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2641', 'examples_per_second': '4.9614', 'grad_norm': '5.0312', 'counters/examples': 159488, 'counters/updates': 9968}
skipping logging after 159504 examples to avoid logging too frequently
skipping logging after 159520 examples to avoid logging too frequently
skipping logging after 159536 examples to avoid logging too frequently
train stats after 159552 examples: {'rewards_train/chosen': '0.44384', 'rewards_train/rejected': '-6.4743', 'rewards_train/margins': '6.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25287', 'examples_per_second': '4.4317', 'grad_norm': '4.875', 'counters/examples': 159552, 'counters/updates': 9972}
skipping logging after 159568 examples to avoid logging too frequently
skipping logging after 159584 examples to avoid logging too frequently
skipping logging after 159600 examples to avoid logging too frequently
train stats after 159616 examples: {'rewards_train/chosen': '0.33838', 'rewards_train/rejected': '-5.8213', 'rewards_train/margins': '6.2344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22778', 'examples_per_second': '4.4275', 'grad_norm': '6.0312', 'counters/examples': 159616, 'counters/updates': 9976}
skipping logging after 159632 examples to avoid logging too frequently
skipping logging after 159648 examples to avoid logging too frequently
skipping logging after 159664 examples to avoid logging too frequently
train stats after 159680 examples: {'rewards_train/chosen': '-0.068375', 'rewards_train/rejected': '-5.8963', 'rewards_train/margins': '5.543', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24371', 'examples_per_second': '5.1244', 'grad_norm': '4.0312', 'counters/examples': 159680, 'counters/updates': 9980}
skipping logging after 159696 examples to avoid logging too frequently
skipping logging after 159712 examples to avoid logging too frequently
skipping logging after 159728 examples to avoid logging too frequently
train stats after 159744 examples: {'rewards_train/chosen': '0.34324', 'rewards_train/rejected': '-6.6737', 'rewards_train/margins': '7.2109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24548', 'examples_per_second': '6.0056', 'grad_norm': '4.8438', 'counters/examples': 159744, 'counters/updates': 9984}
skipping logging after 159760 examples to avoid logging too frequently
skipping logging after 159776 examples to avoid logging too frequently
skipping logging after 159792 examples to avoid logging too frequently
train stats after 159808 examples: {'rewards_train/chosen': '0.096623', 'rewards_train/rejected': '-8.1129', 'rewards_train/margins': '8.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2226', 'examples_per_second': '4.4564', 'grad_norm': '3.9688', 'counters/examples': 159808, 'counters/updates': 9988}
skipping logging after 159824 examples to avoid logging too frequently
skipping logging after 159840 examples to avoid logging too frequently
skipping logging after 159856 examples to avoid logging too frequently
train stats after 159872 examples: {'rewards_train/chosen': '0.48121', 'rewards_train/rejected': '-4.4635', 'rewards_train/margins': '5.0234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21283', 'examples_per_second': '5.8724', 'grad_norm': '5.4062', 'counters/examples': 159872, 'counters/updates': 9992}
skipping logging after 159888 examples to avoid logging too frequently
skipping logging after 159904 examples to avoid logging too frequently
skipping logging after 159920 examples to avoid logging too frequently
train stats after 159936 examples: {'rewards_train/chosen': '0.17574', 'rewards_train/rejected': '-5.7434', 'rewards_train/margins': '6.0312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19244', 'examples_per_second': '4.6529', 'grad_norm': '4.5625', 'counters/examples': 159936, 'counters/updates': 9996}
skipping logging after 159952 examples to avoid logging too frequently
skipping logging after 159968 examples to avoid logging too frequently
skipping logging after 159984 examples to avoid logging too frequently
train stats after 160000 examples: {'rewards_train/chosen': '0.39865', 'rewards_train/rejected': '-5.9651', 'rewards_train/margins': '6.3594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22412', 'examples_per_second': '5.544', 'grad_norm': '5.5312', 'counters/examples': 160000, 'counters/updates': 10000}
Running evaluation after 160000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.26s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.17s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:40,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.66s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.48s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:34,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.41s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.39s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.28s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.51s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.37s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.42s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.20s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.31s/it]
eval after 160000: {'rewards_eval/chosen': '-6.0519', 'rewards_eval/rejected': '-6.5151', 'rewards_eval/margins': '0.30615', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.45947'}
skipping logging after 160016 examples to avoid logging too frequently
skipping logging after 160032 examples to avoid logging too frequently
skipping logging after 160048 examples to avoid logging too frequently
train stats after 160064 examples: {'rewards_train/chosen': '0.42764', 'rewards_train/rejected': '-7.2717', 'rewards_train/margins': '7.7578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24542', 'examples_per_second': '5.1154', 'grad_norm': '5.5312', 'counters/examples': 160064, 'counters/updates': 10004}
skipping logging after 160080 examples to avoid logging too frequently
skipping logging after 160096 examples to avoid logging too frequently
skipping logging after 160112 examples to avoid logging too frequently
train stats after 160128 examples: {'rewards_train/chosen': '0.45244', 'rewards_train/rejected': '-5.6651', 'rewards_train/margins': '6.1289', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22058', 'examples_per_second': '5.0064', 'grad_norm': '3.75', 'counters/examples': 160128, 'counters/updates': 10008}
skipping logging after 160144 examples to avoid logging too frequently
skipping logging after 160160 examples to avoid logging too frequently
skipping logging after 160176 examples to avoid logging too frequently
train stats after 160192 examples: {'rewards_train/chosen': '0.318', 'rewards_train/rejected': '-6.6119', 'rewards_train/margins': '6.8984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21503', 'examples_per_second': '5.3326', 'grad_norm': '5.625', 'counters/examples': 160192, 'counters/updates': 10012}
skipping logging after 160208 examples to avoid logging too frequently
skipping logging after 160224 examples to avoid logging too frequently
skipping logging after 160240 examples to avoid logging too frequently
train stats after 160256 examples: {'rewards_train/chosen': '0.30057', 'rewards_train/rejected': '-5.2774', 'rewards_train/margins': '5.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23969', 'examples_per_second': '6.7119', 'grad_norm': '4.9688', 'counters/examples': 160256, 'counters/updates': 10016}
skipping logging after 160272 examples to avoid logging too frequently
skipping logging after 160288 examples to avoid logging too frequently
skipping logging after 160304 examples to avoid logging too frequently
train stats after 160320 examples: {'rewards_train/chosen': '0.38778', 'rewards_train/rejected': '-5.2402', 'rewards_train/margins': '5.5938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25464', 'examples_per_second': '5.3495', 'grad_norm': '4.75', 'counters/examples': 160320, 'counters/updates': 10020}
skipping logging after 160336 examples to avoid logging too frequently
skipping logging after 160352 examples to avoid logging too frequently
skipping logging after 160368 examples to avoid logging too frequently
train stats after 160384 examples: {'rewards_train/chosen': '0.21938', 'rewards_train/rejected': '-5.646', 'rewards_train/margins': '5.7656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25977', 'examples_per_second': '4.1674', 'grad_norm': '5.1875', 'counters/examples': 160384, 'counters/updates': 10024}
skipping logging after 160400 examples to avoid logging too frequently
skipping logging after 160416 examples to avoid logging too frequently
skipping logging after 160432 examples to avoid logging too frequently
train stats after 160448 examples: {'rewards_train/chosen': '0.58137', 'rewards_train/rejected': '-6.7518', 'rewards_train/margins': '7.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21838', 'examples_per_second': '4.921', 'grad_norm': '4.7812', 'counters/examples': 160448, 'counters/updates': 10028}
skipping logging after 160464 examples to avoid logging too frequently
skipping logging after 160480 examples to avoid logging too frequently
skipping logging after 160496 examples to avoid logging too frequently
train stats after 160512 examples: {'rewards_train/chosen': '0.43185', 'rewards_train/rejected': '-6.4166', 'rewards_train/margins': '6.8828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20288', 'examples_per_second': '4.401', 'grad_norm': '4.7812', 'counters/examples': 160512, 'counters/updates': 10032}
skipping logging after 160528 examples to avoid logging too frequently
skipping logging after 160544 examples to avoid logging too frequently
skipping logging after 160560 examples to avoid logging too frequently
train stats after 160576 examples: {'rewards_train/chosen': '-0.3064', 'rewards_train/rejected': '-6.3533', 'rewards_train/margins': '6.0859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26764', 'examples_per_second': '6.2292', 'grad_norm': '5.3125', 'counters/examples': 160576, 'counters/updates': 10036}
skipping logging after 160592 examples to avoid logging too frequently
skipping logging after 160608 examples to avoid logging too frequently
skipping logging after 160624 examples to avoid logging too frequently
train stats after 160640 examples: {'rewards_train/chosen': '0.39335', 'rewards_train/rejected': '-6.7749', 'rewards_train/margins': '7.1719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20801', 'examples_per_second': '5.4794', 'grad_norm': '4.4375', 'counters/examples': 160640, 'counters/updates': 10040}
skipping logging after 160656 examples to avoid logging too frequently
skipping logging after 160672 examples to avoid logging too frequently
skipping logging after 160688 examples to avoid logging too frequently
train stats after 160704 examples: {'rewards_train/chosen': '0.087246', 'rewards_train/rejected': '-6.6968', 'rewards_train/margins': '6.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25812', 'examples_per_second': '4.3557', 'grad_norm': '5.1875', 'counters/examples': 160704, 'counters/updates': 10044}
skipping logging after 160720 examples to avoid logging too frequently
skipping logging after 160736 examples to avoid logging too frequently
skipping logging after 160752 examples to avoid logging too frequently
train stats after 160768 examples: {'rewards_train/chosen': '0.65094', 'rewards_train/rejected': '-4.7959', 'rewards_train/margins': '5.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22614', 'examples_per_second': '4.7885', 'grad_norm': '5.5312', 'counters/examples': 160768, 'counters/updates': 10048}
skipping logging after 160784 examples to avoid logging too frequently
skipping logging after 160800 examples to avoid logging too frequently
skipping logging after 160816 examples to avoid logging too frequently
train stats after 160832 examples: {'rewards_train/chosen': '0.26111', 'rewards_train/rejected': '-6.1851', 'rewards_train/margins': '6.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25806', 'examples_per_second': '5.6267', 'grad_norm': '5.7812', 'counters/examples': 160832, 'counters/updates': 10052}
skipping logging after 160848 examples to avoid logging too frequently
skipping logging after 160864 examples to avoid logging too frequently
skipping logging after 160880 examples to avoid logging too frequently
train stats after 160896 examples: {'rewards_train/chosen': '0.099825', 'rewards_train/rejected': '-4.9986', 'rewards_train/margins': '5.3008', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29095', 'examples_per_second': '6.7206', 'grad_norm': '4.8125', 'counters/examples': 160896, 'counters/updates': 10056}
skipping logging after 160912 examples to avoid logging too frequently
skipping logging after 160928 examples to avoid logging too frequently
skipping logging after 160944 examples to avoid logging too frequently
train stats after 160960 examples: {'rewards_train/chosen': '0.71821', 'rewards_train/rejected': '-5.2412', 'rewards_train/margins': '5.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20508', 'examples_per_second': '5.6947', 'grad_norm': '4.6875', 'counters/examples': 160960, 'counters/updates': 10060}
skipping logging after 160976 examples to avoid logging too frequently
skipping logging after 160992 examples to avoid logging too frequently
skipping logging after 161008 examples to avoid logging too frequently
train stats after 161024 examples: {'rewards_train/chosen': '0.13627', 'rewards_train/rejected': '-6.0631', 'rewards_train/margins': '6.1172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2345', 'examples_per_second': '4.8036', 'grad_norm': '4.75', 'counters/examples': 161024, 'counters/updates': 10064}
skipping logging after 161040 examples to avoid logging too frequently
skipping logging after 161056 examples to avoid logging too frequently
skipping logging after 161072 examples to avoid logging too frequently
train stats after 161088 examples: {'rewards_train/chosen': '0.28861', 'rewards_train/rejected': '-6.3918', 'rewards_train/margins': '7.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26178', 'examples_per_second': '5.999', 'grad_norm': '4.5625', 'counters/examples': 161088, 'counters/updates': 10068}
skipping logging after 161104 examples to avoid logging too frequently
skipping logging after 161120 examples to avoid logging too frequently
skipping logging after 161136 examples to avoid logging too frequently
train stats after 161152 examples: {'rewards_train/chosen': '0.39391', 'rewards_train/rejected': '-5.2805', 'rewards_train/margins': '5.6367', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24713', 'examples_per_second': '5.5357', 'grad_norm': '5.3438', 'counters/examples': 161152, 'counters/updates': 10072}
skipping logging after 161168 examples to avoid logging too frequently
skipping logging after 161184 examples to avoid logging too frequently
skipping logging after 161200 examples to avoid logging too frequently
train stats after 161216 examples: {'rewards_train/chosen': '0.2777', 'rewards_train/rejected': '-5.4076', 'rewards_train/margins': '5.5898', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25623', 'examples_per_second': '5.2071', 'grad_norm': '5.2188', 'counters/examples': 161216, 'counters/updates': 10076}
skipping logging after 161232 examples to avoid logging too frequently
skipping logging after 161248 examples to avoid logging too frequently
skipping logging after 161264 examples to avoid logging too frequently
train stats after 161280 examples: {'rewards_train/chosen': '0.15377', 'rewards_train/rejected': '-6.3232', 'rewards_train/margins': '6.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2594', 'examples_per_second': '5.0254', 'grad_norm': '5.2812', 'counters/examples': 161280, 'counters/updates': 10080}
skipping logging after 161296 examples to avoid logging too frequently
skipping logging after 161312 examples to avoid logging too frequently
skipping logging after 161328 examples to avoid logging too frequently
train stats after 161344 examples: {'rewards_train/chosen': '0.61914', 'rewards_train/rejected': '-5.9721', 'rewards_train/margins': '6.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21283', 'examples_per_second': '4.9386', 'grad_norm': '4.6875', 'counters/examples': 161344, 'counters/updates': 10084}
skipping logging after 161360 examples to avoid logging too frequently
skipping logging after 161376 examples to avoid logging too frequently
skipping logging after 161392 examples to avoid logging too frequently
train stats after 161408 examples: {'rewards_train/chosen': '0.24629', 'rewards_train/rejected': '-5.2291', 'rewards_train/margins': '5.4844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18774', 'examples_per_second': '5.7704', 'grad_norm': '4.25', 'counters/examples': 161408, 'counters/updates': 10088}
skipping logging after 161424 examples to avoid logging too frequently
skipping logging after 161440 examples to avoid logging too frequently
skipping logging after 161456 examples to avoid logging too frequently
train stats after 161472 examples: {'rewards_train/chosen': '0.37709', 'rewards_train/rejected': '-5.3504', 'rewards_train/margins': '5.8906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1579', 'examples_per_second': '6.2293', 'grad_norm': '4.6562', 'counters/examples': 161472, 'counters/updates': 10092}
skipping logging after 161488 examples to avoid logging too frequently
skipping logging after 161504 examples to avoid logging too frequently
skipping logging after 161520 examples to avoid logging too frequently
train stats after 161536 examples: {'rewards_train/chosen': '0.45604', 'rewards_train/rejected': '-6.5961', 'rewards_train/margins': '7.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17389', 'examples_per_second': '5.3806', 'grad_norm': '4.6562', 'counters/examples': 161536, 'counters/updates': 10096}
skipping logging after 161552 examples to avoid logging too frequently
skipping logging after 161568 examples to avoid logging too frequently
skipping logging after 161584 examples to avoid logging too frequently
train stats after 161600 examples: {'rewards_train/chosen': '0.39499', 'rewards_train/rejected': '-7.0417', 'rewards_train/margins': '7.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21826', 'examples_per_second': '5.7339', 'grad_norm': '4.9375', 'counters/examples': 161600, 'counters/updates': 10100}
skipping logging after 161616 examples to avoid logging too frequently
skipping logging after 161632 examples to avoid logging too frequently
skipping logging after 161648 examples to avoid logging too frequently
train stats after 161664 examples: {'rewards_train/chosen': '0.43461', 'rewards_train/rejected': '-6.5539', 'rewards_train/margins': '7.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23132', 'examples_per_second': '4.5849', 'grad_norm': '4.8125', 'counters/examples': 161664, 'counters/updates': 10104}
skipping logging after 161680 examples to avoid logging too frequently
skipping logging after 161696 examples to avoid logging too frequently
skipping logging after 161712 examples to avoid logging too frequently
train stats after 161728 examples: {'rewards_train/chosen': '0.48317', 'rewards_train/rejected': '-6.8797', 'rewards_train/margins': '7.4531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22144', 'examples_per_second': '6.429', 'grad_norm': '4.4375', 'counters/examples': 161728, 'counters/updates': 10108}
skipping logging after 161744 examples to avoid logging too frequently
skipping logging after 161760 examples to avoid logging too frequently
skipping logging after 161776 examples to avoid logging too frequently
train stats after 161792 examples: {'rewards_train/chosen': '-0.11543', 'rewards_train/rejected': '-5.3498', 'rewards_train/margins': '5.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23145', 'examples_per_second': '5.6215', 'grad_norm': '5.3438', 'counters/examples': 161792, 'counters/updates': 10112}
skipping logging after 161808 examples to avoid logging too frequently
skipping logging after 161824 examples to avoid logging too frequently
skipping logging after 161840 examples to avoid logging too frequently
train stats after 161856 examples: {'rewards_train/chosen': '0.23249', 'rewards_train/rejected': '-6.0071', 'rewards_train/margins': '6.1445', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27252', 'examples_per_second': '4.9876', 'grad_norm': '5.5938', 'counters/examples': 161856, 'counters/updates': 10116}
skipping logging after 161872 examples to avoid logging too frequently
skipping logging after 161888 examples to avoid logging too frequently
skipping logging after 161904 examples to avoid logging too frequently
train stats after 161920 examples: {'rewards_train/chosen': '0.58416', 'rewards_train/rejected': '-5.5397', 'rewards_train/margins': '6.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21667', 'examples_per_second': '4.5904', 'grad_norm': '5', 'counters/examples': 161920, 'counters/updates': 10120}
skipping logging after 161936 examples to avoid logging too frequently
skipping logging after 161952 examples to avoid logging too frequently
skipping logging after 161968 examples to avoid logging too frequently
train stats after 161984 examples: {'rewards_train/chosen': '0.85913', 'rewards_train/rejected': '-4.9504', 'rewards_train/margins': '5.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18158', 'examples_per_second': '4.6025', 'grad_norm': '5', 'counters/examples': 161984, 'counters/updates': 10124}
skipping logging after 162000 examples to avoid logging too frequently
skipping logging after 162016 examples to avoid logging too frequently
skipping logging after 162032 examples to avoid logging too frequently
train stats after 162048 examples: {'rewards_train/chosen': '0.20111', 'rewards_train/rejected': '-5.8586', 'rewards_train/margins': '6.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21301', 'examples_per_second': '4.1875', 'grad_norm': '4.7188', 'counters/examples': 162048, 'counters/updates': 10128}
skipping logging after 162064 examples to avoid logging too frequently
skipping logging after 162080 examples to avoid logging too frequently
skipping logging after 162096 examples to avoid logging too frequently
train stats after 162112 examples: {'rewards_train/chosen': '0.33936', 'rewards_train/rejected': '-7.7372', 'rewards_train/margins': '8.0547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22705', 'examples_per_second': '4.6142', 'grad_norm': '5.0938', 'counters/examples': 162112, 'counters/updates': 10132}
skipping logging after 162128 examples to avoid logging too frequently
skipping logging after 162144 examples to avoid logging too frequently
skipping logging after 162160 examples to avoid logging too frequently
train stats after 162176 examples: {'rewards_train/chosen': '0.2867', 'rewards_train/rejected': '-5.7361', 'rewards_train/margins': '5.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23724', 'examples_per_second': '5.1739', 'grad_norm': '6.0938', 'counters/examples': 162176, 'counters/updates': 10136}
skipping logging after 162192 examples to avoid logging too frequently
skipping logging after 162208 examples to avoid logging too frequently
skipping logging after 162224 examples to avoid logging too frequently
train stats after 162240 examples: {'rewards_train/chosen': '0.34751', 'rewards_train/rejected': '-5.7905', 'rewards_train/margins': '6.2109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2572', 'examples_per_second': '5.1162', 'grad_norm': '5.0938', 'counters/examples': 162240, 'counters/updates': 10140}
skipping logging after 162256 examples to avoid logging too frequently
skipping logging after 162272 examples to avoid logging too frequently
skipping logging after 162288 examples to avoid logging too frequently
train stats after 162304 examples: {'rewards_train/chosen': '0.33966', 'rewards_train/rejected': '-4.9791', 'rewards_train/margins': '5.3086', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23578', 'examples_per_second': '5.1607', 'grad_norm': '4.4688', 'counters/examples': 162304, 'counters/updates': 10144}
skipping logging after 162320 examples to avoid logging too frequently
skipping logging after 162336 examples to avoid logging too frequently
skipping logging after 162352 examples to avoid logging too frequently
train stats after 162368 examples: {'rewards_train/chosen': '0.48811', 'rewards_train/rejected': '-5.7079', 'rewards_train/margins': '6.4844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22034', 'examples_per_second': '5.341', 'grad_norm': '4.8438', 'counters/examples': 162368, 'counters/updates': 10148}
skipping logging after 162384 examples to avoid logging too frequently
skipping logging after 162400 examples to avoid logging too frequently
skipping logging after 162416 examples to avoid logging too frequently
train stats after 162432 examples: {'rewards_train/chosen': '0.026706', 'rewards_train/rejected': '-7.2821', 'rewards_train/margins': '7.2109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28186', 'examples_per_second': '4.7782', 'grad_norm': '5.2188', 'counters/examples': 162432, 'counters/updates': 10152}
skipping logging after 162448 examples to avoid logging too frequently
skipping logging after 162464 examples to avoid logging too frequently
skipping logging after 162480 examples to avoid logging too frequently
train stats after 162496 examples: {'rewards_train/chosen': '0.39274', 'rewards_train/rejected': '-6.3164', 'rewards_train/margins': '6.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20221', 'examples_per_second': '4.8449', 'grad_norm': '4.1875', 'counters/examples': 162496, 'counters/updates': 10156}
skipping logging after 162512 examples to avoid logging too frequently
skipping logging after 162528 examples to avoid logging too frequently
skipping logging after 162544 examples to avoid logging too frequently
train stats after 162560 examples: {'rewards_train/chosen': '0.50372', 'rewards_train/rejected': '-5.4193', 'rewards_train/margins': '5.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23083', 'examples_per_second': '5.5948', 'grad_norm': '5.0312', 'counters/examples': 162560, 'counters/updates': 10160}
skipping logging after 162576 examples to avoid logging too frequently
skipping logging after 162592 examples to avoid logging too frequently
skipping logging after 162608 examples to avoid logging too frequently
train stats after 162624 examples: {'rewards_train/chosen': '0.55982', 'rewards_train/rejected': '-5.9735', 'rewards_train/margins': '6.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2218', 'examples_per_second': '4.7816', 'grad_norm': '4.5625', 'counters/examples': 162624, 'counters/updates': 10164}
skipping logging after 162640 examples to avoid logging too frequently
skipping logging after 162656 examples to avoid logging too frequently
skipping logging after 162672 examples to avoid logging too frequently
train stats after 162688 examples: {'rewards_train/chosen': '0.3527', 'rewards_train/rejected': '-6.4916', 'rewards_train/margins': '6.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24731', 'examples_per_second': '4.9877', 'grad_norm': '5.5312', 'counters/examples': 162688, 'counters/updates': 10168}
skipping logging after 162704 examples to avoid logging too frequently
skipping logging after 162720 examples to avoid logging too frequently
skipping logging after 162736 examples to avoid logging too frequently
train stats after 162752 examples: {'rewards_train/chosen': '0.4042', 'rewards_train/rejected': '-5.6264', 'rewards_train/margins': '5.8828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26141', 'examples_per_second': '5.9524', 'grad_norm': '5.4688', 'counters/examples': 162752, 'counters/updates': 10172}
skipping logging after 162768 examples to avoid logging too frequently
skipping logging after 162784 examples to avoid logging too frequently
skipping logging after 162800 examples to avoid logging too frequently
train stats after 162816 examples: {'rewards_train/chosen': '0.3058', 'rewards_train/rejected': '-5.8511', 'rewards_train/margins': '5.9102', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25836', 'examples_per_second': '5.4247', 'grad_norm': '5.2188', 'counters/examples': 162816, 'counters/updates': 10176}
skipping logging after 162832 examples to avoid logging too frequently
skipping logging after 162848 examples to avoid logging too frequently
skipping logging after 162864 examples to avoid logging too frequently
train stats after 162880 examples: {'rewards_train/chosen': '0.40767', 'rewards_train/rejected': '-6.4857', 'rewards_train/margins': '6.8203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2478', 'examples_per_second': '4.4241', 'grad_norm': '4.4375', 'counters/examples': 162880, 'counters/updates': 10180}
skipping logging after 162896 examples to avoid logging too frequently
skipping logging after 162912 examples to avoid logging too frequently
skipping logging after 162928 examples to avoid logging too frequently
train stats after 162944 examples: {'rewards_train/chosen': '0.36246', 'rewards_train/rejected': '-6.3573', 'rewards_train/margins': '7', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23523', 'examples_per_second': '4.9736', 'grad_norm': '3.9375', 'counters/examples': 162944, 'counters/updates': 10184}
skipping logging after 162960 examples to avoid logging too frequently
skipping logging after 162976 examples to avoid logging too frequently
skipping logging after 162992 examples to avoid logging too frequently
train stats after 163008 examples: {'rewards_train/chosen': '0.45893', 'rewards_train/rejected': '-5.6351', 'rewards_train/margins': '6.3203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24481', 'examples_per_second': '5.9486', 'grad_norm': '4.7812', 'counters/examples': 163008, 'counters/updates': 10188}
skipping logging after 163024 examples to avoid logging too frequently
skipping logging after 163040 examples to avoid logging too frequently
skipping logging after 163056 examples to avoid logging too frequently
train stats after 163072 examples: {'rewards_train/chosen': '0.12115', 'rewards_train/rejected': '-4.9224', 'rewards_train/margins': '5.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26489', 'examples_per_second': '4.3893', 'grad_norm': '6.25', 'counters/examples': 163072, 'counters/updates': 10192}
skipping logging after 163088 examples to avoid logging too frequently
skipping logging after 163104 examples to avoid logging too frequently
skipping logging after 163120 examples to avoid logging too frequently
train stats after 163136 examples: {'rewards_train/chosen': '0.1637', 'rewards_train/rejected': '-5.5574', 'rewards_train/margins': '5.7031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23926', 'examples_per_second': '4.247', 'grad_norm': '4.9688', 'counters/examples': 163136, 'counters/updates': 10196}
skipping logging after 163152 examples to avoid logging too frequently
skipping logging after 163168 examples to avoid logging too frequently
skipping logging after 163184 examples to avoid logging too frequently
train stats after 163200 examples: {'rewards_train/chosen': '0.24456', 'rewards_train/rejected': '-5.4251', 'rewards_train/margins': '5.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24908', 'examples_per_second': '5.1586', 'grad_norm': '4.375', 'counters/examples': 163200, 'counters/updates': 10200}
skipping logging after 163216 examples to avoid logging too frequently
skipping logging after 163232 examples to avoid logging too frequently
skipping logging after 163248 examples to avoid logging too frequently
train stats after 163264 examples: {'rewards_train/chosen': '0.53856', 'rewards_train/rejected': '-4.5803', 'rewards_train/margins': '5.1016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23401', 'examples_per_second': '5.1285', 'grad_norm': '4.5625', 'counters/examples': 163264, 'counters/updates': 10204}
skipping logging after 163280 examples to avoid logging too frequently
skipping logging after 163296 examples to avoid logging too frequently
skipping logging after 163312 examples to avoid logging too frequently
train stats after 163328 examples: {'rewards_train/chosen': '0.2839', 'rewards_train/rejected': '-6.9017', 'rewards_train/margins': '7.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25946', 'examples_per_second': '4.9498', 'grad_norm': '5.4062', 'counters/examples': 163328, 'counters/updates': 10208}
skipping logging after 163344 examples to avoid logging too frequently
skipping logging after 163360 examples to avoid logging too frequently
skipping logging after 163376 examples to avoid logging too frequently
train stats after 163392 examples: {'rewards_train/chosen': '0.60136', 'rewards_train/rejected': '-6.5607', 'rewards_train/margins': '7.125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21265', 'examples_per_second': '4.6707', 'grad_norm': '4.125', 'counters/examples': 163392, 'counters/updates': 10212}
skipping logging after 163408 examples to avoid logging too frequently
skipping logging after 163424 examples to avoid logging too frequently
skipping logging after 163440 examples to avoid logging too frequently
train stats after 163456 examples: {'rewards_train/chosen': '0.41292', 'rewards_train/rejected': '-5.2328', 'rewards_train/margins': '5.7812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23236', 'examples_per_second': '5.5838', 'grad_norm': '5.125', 'counters/examples': 163456, 'counters/updates': 10216}
skipping logging after 163472 examples to avoid logging too frequently
skipping logging after 163488 examples to avoid logging too frequently
skipping logging after 163504 examples to avoid logging too frequently
train stats after 163520 examples: {'rewards_train/chosen': '0.066549', 'rewards_train/rejected': '-7.3527', 'rewards_train/margins': '7.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23395', 'examples_per_second': '5.3992', 'grad_norm': '5.5312', 'counters/examples': 163520, 'counters/updates': 10220}
skipping logging after 163536 examples to avoid logging too frequently
skipping logging after 163552 examples to avoid logging too frequently
skipping logging after 163568 examples to avoid logging too frequently
train stats after 163584 examples: {'rewards_train/chosen': '0.636', 'rewards_train/rejected': '-7.5115', 'rewards_train/margins': '7.9297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20813', 'examples_per_second': '4.454', 'grad_norm': '4.4688', 'counters/examples': 163584, 'counters/updates': 10224}
skipping logging after 163600 examples to avoid logging too frequently
skipping logging after 163616 examples to avoid logging too frequently
skipping logging after 163632 examples to avoid logging too frequently
train stats after 163648 examples: {'rewards_train/chosen': '0.17726', 'rewards_train/rejected': '-8.1593', 'rewards_train/margins': '8.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23376', 'examples_per_second': '5.19', 'grad_norm': '5.625', 'counters/examples': 163648, 'counters/updates': 10228}
skipping logging after 163664 examples to avoid logging too frequently
skipping logging after 163680 examples to avoid logging too frequently
skipping logging after 163696 examples to avoid logging too frequently
train stats after 163712 examples: {'rewards_train/chosen': '0.48254', 'rewards_train/rejected': '-5.75', 'rewards_train/margins': '6.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26666', 'examples_per_second': '6.2254', 'grad_norm': '4.2188', 'counters/examples': 163712, 'counters/updates': 10232}
skipping logging after 163728 examples to avoid logging too frequently
skipping logging after 163744 examples to avoid logging too frequently
skipping logging after 163760 examples to avoid logging too frequently
train stats after 163776 examples: {'rewards_train/chosen': '0.70305', 'rewards_train/rejected': '-7.4153', 'rewards_train/margins': '8.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19128', 'examples_per_second': '4.5715', 'grad_norm': '4.2188', 'counters/examples': 163776, 'counters/updates': 10236}
skipping logging after 163792 examples to avoid logging too frequently
skipping logging after 163808 examples to avoid logging too frequently
skipping logging after 163824 examples to avoid logging too frequently
train stats after 163840 examples: {'rewards_train/chosen': '0.43458', 'rewards_train/rejected': '-4.847', 'rewards_train/margins': '5.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24591', 'examples_per_second': '6.2178', 'grad_norm': '5.8438', 'counters/examples': 163840, 'counters/updates': 10240}
skipping logging after 163856 examples to avoid logging too frequently
skipping logging after 163872 examples to avoid logging too frequently
skipping logging after 163888 examples to avoid logging too frequently
train stats after 163904 examples: {'rewards_train/chosen': '0.33338', 'rewards_train/rejected': '-5.3075', 'rewards_train/margins': '5.4414', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30811', 'examples_per_second': '5.7035', 'grad_norm': '5.9062', 'counters/examples': 163904, 'counters/updates': 10244}
skipping logging after 163920 examples to avoid logging too frequently
skipping logging after 163936 examples to avoid logging too frequently
skipping logging after 163952 examples to avoid logging too frequently
train stats after 163968 examples: {'rewards_train/chosen': '0.54279', 'rewards_train/rejected': '-6.1612', 'rewards_train/margins': '6.8203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23431', 'examples_per_second': '5.266', 'grad_norm': '6.7812', 'counters/examples': 163968, 'counters/updates': 10248}
skipping logging after 163984 examples to avoid logging too frequently
skipping logging after 164000 examples to avoid logging too frequently
Running evaluation after 164000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:47,  1.52s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:40,  1.37s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:35,  1.23s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.47s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.68s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.49s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:34,  1.37s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.41s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.39s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.28s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.42s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.20s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:41<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]
eval after 164000: {'rewards_eval/chosen': '-5.4752', 'rewards_eval/rejected': '-5.8201', 'rewards_eval/margins': '0.22559', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.4617'}
skipping logging after 164016 examples to avoid logging too frequently
train stats after 164032 examples: {'rewards_train/chosen': '0.71433', 'rewards_train/rejected': '-5.3574', 'rewards_train/margins': '5.9766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22314', 'examples_per_second': '5.7728', 'grad_norm': '4.9688', 'counters/examples': 164032, 'counters/updates': 10252}
skipping logging after 164048 examples to avoid logging too frequently
skipping logging after 164064 examples to avoid logging too frequently
skipping logging after 164080 examples to avoid logging too frequently
train stats after 164096 examples: {'rewards_train/chosen': '0.15333', 'rewards_train/rejected': '-7.5312', 'rewards_train/margins': '7.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25446', 'examples_per_second': '6.019', 'grad_norm': '4.9688', 'counters/examples': 164096, 'counters/updates': 10256}
skipping logging after 164112 examples to avoid logging too frequently
skipping logging after 164128 examples to avoid logging too frequently
skipping logging after 164144 examples to avoid logging too frequently
train stats after 164160 examples: {'rewards_train/chosen': '0.39554', 'rewards_train/rejected': '-5.0922', 'rewards_train/margins': '5.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2735', 'examples_per_second': '4.9774', 'grad_norm': '4.8438', 'counters/examples': 164160, 'counters/updates': 10260}
skipping logging after 164176 examples to avoid logging too frequently
skipping logging after 164192 examples to avoid logging too frequently
skipping logging after 164208 examples to avoid logging too frequently
train stats after 164224 examples: {'rewards_train/chosen': '0.40537', 'rewards_train/rejected': '-7.1284', 'rewards_train/margins': '7.6016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17419', 'examples_per_second': '4.7466', 'grad_norm': '4.5938', 'counters/examples': 164224, 'counters/updates': 10264}
skipping logging after 164240 examples to avoid logging too frequently
skipping logging after 164256 examples to avoid logging too frequently
skipping logging after 164272 examples to avoid logging too frequently
train stats after 164288 examples: {'rewards_train/chosen': '0.1339', 'rewards_train/rejected': '-6.056', 'rewards_train/margins': '6.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23157', 'examples_per_second': '6.1113', 'grad_norm': '4.8125', 'counters/examples': 164288, 'counters/updates': 10268}
skipping logging after 164304 examples to avoid logging too frequently
skipping logging after 164320 examples to avoid logging too frequently
skipping logging after 164336 examples to avoid logging too frequently
train stats after 164352 examples: {'rewards_train/chosen': '0.22464', 'rewards_train/rejected': '-7.2214', 'rewards_train/margins': '7.4531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26691', 'examples_per_second': '5.5734', 'grad_norm': '5.3438', 'counters/examples': 164352, 'counters/updates': 10272}
skipping logging after 164368 examples to avoid logging too frequently
skipping logging after 164384 examples to avoid logging too frequently
skipping logging after 164400 examples to avoid logging too frequently
train stats after 164416 examples: {'rewards_train/chosen': '0.3548', 'rewards_train/rejected': '-6.2491', 'rewards_train/margins': '6.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19373', 'examples_per_second': '4.9372', 'grad_norm': '4.0938', 'counters/examples': 164416, 'counters/updates': 10276}
skipping logging after 164432 examples to avoid logging too frequently
skipping logging after 164448 examples to avoid logging too frequently
skipping logging after 164464 examples to avoid logging too frequently
train stats after 164480 examples: {'rewards_train/chosen': '0.54377', 'rewards_train/rejected': '-5.2881', 'rewards_train/margins': '6.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21985', 'examples_per_second': '4.5109', 'grad_norm': '5.1562', 'counters/examples': 164480, 'counters/updates': 10280}
skipping logging after 164496 examples to avoid logging too frequently
skipping logging after 164512 examples to avoid logging too frequently
skipping logging after 164528 examples to avoid logging too frequently
train stats after 164544 examples: {'rewards_train/chosen': '0.51841', 'rewards_train/rejected': '-7.3554', 'rewards_train/margins': '7.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21716', 'examples_per_second': '5.5152', 'grad_norm': '4.5312', 'counters/examples': 164544, 'counters/updates': 10284}
skipping logging after 164560 examples to avoid logging too frequently
skipping logging after 164576 examples to avoid logging too frequently
skipping logging after 164592 examples to avoid logging too frequently
train stats after 164608 examples: {'rewards_train/chosen': '0.38154', 'rewards_train/rejected': '-5.0082', 'rewards_train/margins': '5.3828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26703', 'examples_per_second': '5.9343', 'grad_norm': '5.3125', 'counters/examples': 164608, 'counters/updates': 10288}
skipping logging after 164624 examples to avoid logging too frequently
skipping logging after 164640 examples to avoid logging too frequently
skipping logging after 164656 examples to avoid logging too frequently
train stats after 164672 examples: {'rewards_train/chosen': '0.65344', 'rewards_train/rejected': '-6.0376', 'rewards_train/margins': '6.1133', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23071', 'examples_per_second': '4.6437', 'grad_norm': '5.2812', 'counters/examples': 164672, 'counters/updates': 10292}
skipping logging after 164688 examples to avoid logging too frequently
skipping logging after 164704 examples to avoid logging too frequently
skipping logging after 164720 examples to avoid logging too frequently
train stats after 164736 examples: {'rewards_train/chosen': '0.14195', 'rewards_train/rejected': '-6.5413', 'rewards_train/margins': '6.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24902', 'examples_per_second': '5.2671', 'grad_norm': '4.8125', 'counters/examples': 164736, 'counters/updates': 10296}
skipping logging after 164752 examples to avoid logging too frequently
skipping logging after 164768 examples to avoid logging too frequently
skipping logging after 164784 examples to avoid logging too frequently
train stats after 164800 examples: {'rewards_train/chosen': '0.25712', 'rewards_train/rejected': '-5.3531', 'rewards_train/margins': '5.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28308', 'examples_per_second': '4.799', 'grad_norm': '6.75', 'counters/examples': 164800, 'counters/updates': 10300}
skipping logging after 164816 examples to avoid logging too frequently
skipping logging after 164832 examples to avoid logging too frequently
skipping logging after 164848 examples to avoid logging too frequently
train stats after 164864 examples: {'rewards_train/chosen': '0.52397', 'rewards_train/rejected': '-6.2828', 'rewards_train/margins': '6.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22772', 'examples_per_second': '4.946', 'grad_norm': '4.0625', 'counters/examples': 164864, 'counters/updates': 10304}
skipping logging after 164880 examples to avoid logging too frequently
skipping logging after 164896 examples to avoid logging too frequently
skipping logging after 164912 examples to avoid logging too frequently
train stats after 164928 examples: {'rewards_train/chosen': '0.10879', 'rewards_train/rejected': '-6.0808', 'rewards_train/margins': '6.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22839', 'examples_per_second': '5.2989', 'grad_norm': '5.0938', 'counters/examples': 164928, 'counters/updates': 10308}
skipping logging after 164944 examples to avoid logging too frequently
skipping logging after 164960 examples to avoid logging too frequently
skipping logging after 164976 examples to avoid logging too frequently
train stats after 164992 examples: {'rewards_train/chosen': '0.29272', 'rewards_train/rejected': '-5.8735', 'rewards_train/margins': '6', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23944', 'examples_per_second': '5.4303', 'grad_norm': '4.5938', 'counters/examples': 164992, 'counters/updates': 10312}
skipping logging after 165008 examples to avoid logging too frequently
skipping logging after 165024 examples to avoid logging too frequently
skipping logging after 165040 examples to avoid logging too frequently
train stats after 165056 examples: {'rewards_train/chosen': '0.59172', 'rewards_train/rejected': '-6.8834', 'rewards_train/margins': '7.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17822', 'examples_per_second': '5.2637', 'grad_norm': '3.9062', 'counters/examples': 165056, 'counters/updates': 10316}
skipping logging after 165072 examples to avoid logging too frequently
skipping logging after 165088 examples to avoid logging too frequently
skipping logging after 165104 examples to avoid logging too frequently
train stats after 165120 examples: {'rewards_train/chosen': '0.34391', 'rewards_train/rejected': '-6.1593', 'rewards_train/margins': '6.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23309', 'examples_per_second': '5.0797', 'grad_norm': '4.8125', 'counters/examples': 165120, 'counters/updates': 10320}
skipping logging after 165136 examples to avoid logging too frequently
skipping logging after 165152 examples to avoid logging too frequently
skipping logging after 165168 examples to avoid logging too frequently
train stats after 165184 examples: {'rewards_train/chosen': '0.17182', 'rewards_train/rejected': '-5.1873', 'rewards_train/margins': '5.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19165', 'examples_per_second': '5.0258', 'grad_norm': '4.9062', 'counters/examples': 165184, 'counters/updates': 10324}
skipping logging after 165200 examples to avoid logging too frequently
skipping logging after 165216 examples to avoid logging too frequently
skipping logging after 165232 examples to avoid logging too frequently
train stats after 165248 examples: {'rewards_train/chosen': '-0.29451', 'rewards_train/rejected': '-6.3714', 'rewards_train/margins': '5.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20001', 'examples_per_second': '5.2489', 'grad_norm': '5.5938', 'counters/examples': 165248, 'counters/updates': 10328}
skipping logging after 165264 examples to avoid logging too frequently
skipping logging after 165280 examples to avoid logging too frequently
skipping logging after 165296 examples to avoid logging too frequently
train stats after 165312 examples: {'rewards_train/chosen': '0.35906', 'rewards_train/rejected': '-6.3683', 'rewards_train/margins': '6.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22339', 'examples_per_second': '4.4574', 'grad_norm': '5.0938', 'counters/examples': 165312, 'counters/updates': 10332}
skipping logging after 165328 examples to avoid logging too frequently
skipping logging after 165344 examples to avoid logging too frequently
skipping logging after 165360 examples to avoid logging too frequently
train stats after 165376 examples: {'rewards_train/chosen': '0.3974', 'rewards_train/rejected': '-5.9919', 'rewards_train/margins': '6.1953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25616', 'examples_per_second': '5.587', 'grad_norm': '5.25', 'counters/examples': 165376, 'counters/updates': 10336}
skipping logging after 165392 examples to avoid logging too frequently
skipping logging after 165408 examples to avoid logging too frequently
skipping logging after 165424 examples to avoid logging too frequently
train stats after 165440 examples: {'rewards_train/chosen': '0.53957', 'rewards_train/rejected': '-5.6102', 'rewards_train/margins': '6.2422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23022', 'examples_per_second': '5.7673', 'grad_norm': '4.75', 'counters/examples': 165440, 'counters/updates': 10340}
skipping logging after 165456 examples to avoid logging too frequently
skipping logging after 165472 examples to avoid logging too frequently
skipping logging after 165488 examples to avoid logging too frequently
train stats after 165504 examples: {'rewards_train/chosen': '0.23756', 'rewards_train/rejected': '-6.1208', 'rewards_train/margins': '6.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26825', 'examples_per_second': '5.1579', 'grad_norm': '5.25', 'counters/examples': 165504, 'counters/updates': 10344}
skipping logging after 165520 examples to avoid logging too frequently
skipping logging after 165536 examples to avoid logging too frequently
skipping logging after 165552 examples to avoid logging too frequently
train stats after 165568 examples: {'rewards_train/chosen': '0.54403', 'rewards_train/rejected': '-5.6162', 'rewards_train/margins': '6.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20685', 'examples_per_second': '5.843', 'grad_norm': '4.7812', 'counters/examples': 165568, 'counters/updates': 10348}
skipping logging after 165584 examples to avoid logging too frequently
skipping logging after 165600 examples to avoid logging too frequently
skipping logging after 165616 examples to avoid logging too frequently
train stats after 165632 examples: {'rewards_train/chosen': '0.24603', 'rewards_train/rejected': '-5.1069', 'rewards_train/margins': '5.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27594', 'examples_per_second': '4.9286', 'grad_norm': '5.125', 'counters/examples': 165632, 'counters/updates': 10352}
skipping logging after 165648 examples to avoid logging too frequently
skipping logging after 165664 examples to avoid logging too frequently
skipping logging after 165680 examples to avoid logging too frequently
train stats after 165696 examples: {'rewards_train/chosen': '0.66354', 'rewards_train/rejected': '-7.1153', 'rewards_train/margins': '7.7266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20782', 'examples_per_second': '5.3347', 'grad_norm': '5.1875', 'counters/examples': 165696, 'counters/updates': 10356}
skipping logging after 165712 examples to avoid logging too frequently
skipping logging after 165728 examples to avoid logging too frequently
skipping logging after 165744 examples to avoid logging too frequently
train stats after 165760 examples: {'rewards_train/chosen': '0.76195', 'rewards_train/rejected': '-5.8678', 'rewards_train/margins': '6.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23688', 'examples_per_second': '4.7006', 'grad_norm': '5.0312', 'counters/examples': 165760, 'counters/updates': 10360}
skipping logging after 165776 examples to avoid logging too frequently
skipping logging after 165792 examples to avoid logging too frequently
skipping logging after 165808 examples to avoid logging too frequently
train stats after 165824 examples: {'rewards_train/chosen': '0.48564', 'rewards_train/rejected': '-6.8382', 'rewards_train/margins': '7.6641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.16809', 'examples_per_second': '4.4394', 'grad_norm': '3.7812', 'counters/examples': 165824, 'counters/updates': 10364}
skipping logging after 165840 examples to avoid logging too frequently
skipping logging after 165856 examples to avoid logging too frequently
skipping logging after 165872 examples to avoid logging too frequently
train stats after 165888 examples: {'rewards_train/chosen': '0.71798', 'rewards_train/rejected': '-5.4561', 'rewards_train/margins': '6.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2215', 'examples_per_second': '4.6048', 'grad_norm': '4.8438', 'counters/examples': 165888, 'counters/updates': 10368}
skipping logging after 165904 examples to avoid logging too frequently
skipping logging after 165920 examples to avoid logging too frequently
skipping logging after 165936 examples to avoid logging too frequently
train stats after 165952 examples: {'rewards_train/chosen': '0.45399', 'rewards_train/rejected': '-6.4622', 'rewards_train/margins': '6.8828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20398', 'examples_per_second': '5.4956', 'grad_norm': '4.7188', 'counters/examples': 165952, 'counters/updates': 10372}
skipping logging after 165968 examples to avoid logging too frequently
skipping logging after 165984 examples to avoid logging too frequently
skipping logging after 166000 examples to avoid logging too frequently
train stats after 166016 examples: {'rewards_train/chosen': '0.33152', 'rewards_train/rejected': '-6.2355', 'rewards_train/margins': '6.6875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21973', 'examples_per_second': '6.0413', 'grad_norm': '4.4688', 'counters/examples': 166016, 'counters/updates': 10376}
skipping logging after 166032 examples to avoid logging too frequently
skipping logging after 166048 examples to avoid logging too frequently
skipping logging after 166064 examples to avoid logging too frequently
train stats after 166080 examples: {'rewards_train/chosen': '0.45736', 'rewards_train/rejected': '-6.0086', 'rewards_train/margins': '6.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24658', 'examples_per_second': '6.1648', 'grad_norm': '5.375', 'counters/examples': 166080, 'counters/updates': 10380}
skipping logging after 166096 examples to avoid logging too frequently
skipping logging after 166112 examples to avoid logging too frequently
skipping logging after 166128 examples to avoid logging too frequently
train stats after 166144 examples: {'rewards_train/chosen': '0.51561', 'rewards_train/rejected': '-6.7972', 'rewards_train/margins': '7.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19647', 'examples_per_second': '4.066', 'grad_norm': '4.8125', 'counters/examples': 166144, 'counters/updates': 10384}
skipping logging after 166160 examples to avoid logging too frequently
skipping logging after 166176 examples to avoid logging too frequently
skipping logging after 166192 examples to avoid logging too frequently
train stats after 166208 examples: {'rewards_train/chosen': '0.33979', 'rewards_train/rejected': '-5.2053', 'rewards_train/margins': '5.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22803', 'examples_per_second': '5.7389', 'grad_norm': '5.9375', 'counters/examples': 166208, 'counters/updates': 10388}
skipping logging after 166224 examples to avoid logging too frequently
skipping logging after 166240 examples to avoid logging too frequently
skipping logging after 166256 examples to avoid logging too frequently
train stats after 166272 examples: {'rewards_train/chosen': '0.034446', 'rewards_train/rejected': '-6.4338', 'rewards_train/margins': '6.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27509', 'examples_per_second': '5.0928', 'grad_norm': '5.25', 'counters/examples': 166272, 'counters/updates': 10392}
skipping logging after 166288 examples to avoid logging too frequently
skipping logging after 166304 examples to avoid logging too frequently
skipping logging after 166320 examples to avoid logging too frequently
train stats after 166336 examples: {'rewards_train/chosen': '0.45662', 'rewards_train/rejected': '-6.6963', 'rewards_train/margins': '7.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17847', 'examples_per_second': '4.7455', 'grad_norm': '3.9688', 'counters/examples': 166336, 'counters/updates': 10396}
skipping logging after 166352 examples to avoid logging too frequently
skipping logging after 166368 examples to avoid logging too frequently
skipping logging after 166384 examples to avoid logging too frequently
train stats after 166400 examples: {'rewards_train/chosen': '-0.12645', 'rewards_train/rejected': '-5.7393', 'rewards_train/margins': '5.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30249', 'examples_per_second': '5.6919', 'grad_norm': '6.0625', 'counters/examples': 166400, 'counters/updates': 10400}
skipping logging after 166416 examples to avoid logging too frequently
skipping logging after 166432 examples to avoid logging too frequently
skipping logging after 166448 examples to avoid logging too frequently
train stats after 166464 examples: {'rewards_train/chosen': '0.32133', 'rewards_train/rejected': '-4.8454', 'rewards_train/margins': '4.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22882', 'examples_per_second': '4.5313', 'grad_norm': '4.25', 'counters/examples': 166464, 'counters/updates': 10404}
skipping logging after 166480 examples to avoid logging too frequently
skipping logging after 166496 examples to avoid logging too frequently
skipping logging after 166512 examples to avoid logging too frequently
train stats after 166528 examples: {'rewards_train/chosen': '0.38258', 'rewards_train/rejected': '-5.8273', 'rewards_train/margins': '6.5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26501', 'examples_per_second': '5.6599', 'grad_norm': '5.5938', 'counters/examples': 166528, 'counters/updates': 10408}
skipping logging after 166544 examples to avoid logging too frequently
skipping logging after 166560 examples to avoid logging too frequently
skipping logging after 166576 examples to avoid logging too frequently
train stats after 166592 examples: {'rewards_train/chosen': '0.35463', 'rewards_train/rejected': '-5.1854', 'rewards_train/margins': '5.6016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23944', 'examples_per_second': '5.3996', 'grad_norm': '4.875', 'counters/examples': 166592, 'counters/updates': 10412}
skipping logging after 166608 examples to avoid logging too frequently
skipping logging after 166624 examples to avoid logging too frequently
skipping logging after 166640 examples to avoid logging too frequently
train stats after 166656 examples: {'rewards_train/chosen': '0.20306', 'rewards_train/rejected': '-6.1503', 'rewards_train/margins': '5.957', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22791', 'examples_per_second': '5.9032', 'grad_norm': '4.5938', 'counters/examples': 166656, 'counters/updates': 10416}
skipping logging after 166672 examples to avoid logging too frequently
skipping logging after 166688 examples to avoid logging too frequently
skipping logging after 166704 examples to avoid logging too frequently
train stats after 166720 examples: {'rewards_train/chosen': '-0.049465', 'rewards_train/rejected': '-5.2717', 'rewards_train/margins': '5.1953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2345', 'examples_per_second': '7.4153', 'grad_norm': '4.6875', 'counters/examples': 166720, 'counters/updates': 10420}
skipping logging after 166736 examples to avoid logging too frequently
skipping logging after 166752 examples to avoid logging too frequently
skipping logging after 166768 examples to avoid logging too frequently
train stats after 166784 examples: {'rewards_train/chosen': '0.29834', 'rewards_train/rejected': '-5.5307', 'rewards_train/margins': '5.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25891', 'examples_per_second': '5.4671', 'grad_norm': '5.2812', 'counters/examples': 166784, 'counters/updates': 10424}
skipping logging after 166800 examples to avoid logging too frequently
skipping logging after 166816 examples to avoid logging too frequently
skipping logging after 166832 examples to avoid logging too frequently
train stats after 166848 examples: {'rewards_train/chosen': '0.41077', 'rewards_train/rejected': '-5.6298', 'rewards_train/margins': '5.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23438', 'examples_per_second': '5.5593', 'grad_norm': '5.6562', 'counters/examples': 166848, 'counters/updates': 10428}
skipping logging after 166864 examples to avoid logging too frequently
skipping logging after 166880 examples to avoid logging too frequently
skipping logging after 166896 examples to avoid logging too frequently
train stats after 166912 examples: {'rewards_train/chosen': '0.55905', 'rewards_train/rejected': '-4.1971', 'rewards_train/margins': '4.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24994', 'examples_per_second': '5.2128', 'grad_norm': '5.8125', 'counters/examples': 166912, 'counters/updates': 10432}
skipping logging after 166928 examples to avoid logging too frequently
skipping logging after 166944 examples to avoid logging too frequently
skipping logging after 166960 examples to avoid logging too frequently
train stats after 166976 examples: {'rewards_train/chosen': '0.32742', 'rewards_train/rejected': '-6.4763', 'rewards_train/margins': '6.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25494', 'examples_per_second': '5.2701', 'grad_norm': '5.375', 'counters/examples': 166976, 'counters/updates': 10436}
skipping logging after 166992 examples to avoid logging too frequently
skipping logging after 167008 examples to avoid logging too frequently
skipping logging after 167024 examples to avoid logging too frequently
train stats after 167040 examples: {'rewards_train/chosen': '0.61303', 'rewards_train/rejected': '-6.8111', 'rewards_train/margins': '7.8203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21704', 'examples_per_second': '5.8026', 'grad_norm': '4.3438', 'counters/examples': 167040, 'counters/updates': 10440}
skipping logging after 167056 examples to avoid logging too frequently
skipping logging after 167072 examples to avoid logging too frequently
skipping logging after 167088 examples to avoid logging too frequently
train stats after 167104 examples: {'rewards_train/chosen': '0.54267', 'rewards_train/rejected': '-5.698', 'rewards_train/margins': '6.4531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2099', 'examples_per_second': '4.6821', 'grad_norm': '4.5625', 'counters/examples': 167104, 'counters/updates': 10444}
skipping logging after 167120 examples to avoid logging too frequently
skipping logging after 167136 examples to avoid logging too frequently
skipping logging after 167152 examples to avoid logging too frequently
train stats after 167168 examples: {'rewards_train/chosen': '0.55365', 'rewards_train/rejected': '-6.2928', 'rewards_train/margins': '6.8203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22125', 'examples_per_second': '4.8746', 'grad_norm': '4.8125', 'counters/examples': 167168, 'counters/updates': 10448}
skipping logging after 167184 examples to avoid logging too frequently
skipping logging after 167200 examples to avoid logging too frequently
skipping logging after 167216 examples to avoid logging too frequently
train stats after 167232 examples: {'rewards_train/chosen': '0.48433', 'rewards_train/rejected': '-6.3415', 'rewards_train/margins': '7.1875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20496', 'examples_per_second': '5.3332', 'grad_norm': '5.3438', 'counters/examples': 167232, 'counters/updates': 10452}
skipping logging after 167248 examples to avoid logging too frequently
skipping logging after 167264 examples to avoid logging too frequently
skipping logging after 167280 examples to avoid logging too frequently
train stats after 167296 examples: {'rewards_train/chosen': '0.23989', 'rewards_train/rejected': '-5.5508', 'rewards_train/margins': '6.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23126', 'examples_per_second': '4.8835', 'grad_norm': '4.3438', 'counters/examples': 167296, 'counters/updates': 10456}
skipping logging after 167312 examples to avoid logging too frequently
skipping logging after 167328 examples to avoid logging too frequently
skipping logging after 167344 examples to avoid logging too frequently
train stats after 167360 examples: {'rewards_train/chosen': '0.53971', 'rewards_train/rejected': '-4.6214', 'rewards_train/margins': '4.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26611', 'examples_per_second': '3.9821', 'grad_norm': '5.0938', 'counters/examples': 167360, 'counters/updates': 10460}
skipping logging after 167376 examples to avoid logging too frequently
skipping logging after 167392 examples to avoid logging too frequently
skipping logging after 167408 examples to avoid logging too frequently
train stats after 167424 examples: {'rewards_train/chosen': '0.52486', 'rewards_train/rejected': '-5.5647', 'rewards_train/margins': '6.418', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2276', 'examples_per_second': '5.1768', 'grad_norm': '4.3125', 'counters/examples': 167424, 'counters/updates': 10464}
skipping logging after 167440 examples to avoid logging too frequently
skipping logging after 167456 examples to avoid logging too frequently
skipping logging after 167472 examples to avoid logging too frequently
train stats after 167488 examples: {'rewards_train/chosen': '0.17862', 'rewards_train/rejected': '-8.3045', 'rewards_train/margins': '8.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22845', 'examples_per_second': '5.2655', 'grad_norm': '4.625', 'counters/examples': 167488, 'counters/updates': 10468}
skipping logging after 167504 examples to avoid logging too frequently
skipping logging after 167520 examples to avoid logging too frequently
skipping logging after 167536 examples to avoid logging too frequently
train stats after 167552 examples: {'rewards_train/chosen': '0.084159', 'rewards_train/rejected': '-6.2682', 'rewards_train/margins': '6.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27679', 'examples_per_second': '5.2706', 'grad_norm': '4.7188', 'counters/examples': 167552, 'counters/updates': 10472}
skipping logging after 167568 examples to avoid logging too frequently
skipping logging after 167584 examples to avoid logging too frequently
skipping logging after 167600 examples to avoid logging too frequently
train stats after 167616 examples: {'rewards_train/chosen': '0.42309', 'rewards_train/rejected': '-6.301', 'rewards_train/margins': '6.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.255', 'examples_per_second': '5.5302', 'grad_norm': '5.375', 'counters/examples': 167616, 'counters/updates': 10476}
skipping logging after 167632 examples to avoid logging too frequently
skipping logging after 167648 examples to avoid logging too frequently
skipping logging after 167664 examples to avoid logging too frequently
train stats after 167680 examples: {'rewards_train/chosen': '0.40635', 'rewards_train/rejected': '-5.0492', 'rewards_train/margins': '5.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27368', 'examples_per_second': '4.0153', 'grad_norm': '4.6562', 'counters/examples': 167680, 'counters/updates': 10480}
skipping logging after 167696 examples to avoid logging too frequently
skipping logging after 167712 examples to avoid logging too frequently
skipping logging after 167728 examples to avoid logging too frequently
train stats after 167744 examples: {'rewards_train/chosen': '0.70035', 'rewards_train/rejected': '-5.5901', 'rewards_train/margins': '6.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19293', 'examples_per_second': '5.2101', 'grad_norm': '5.5625', 'counters/examples': 167744, 'counters/updates': 10484}
skipping logging after 167760 examples to avoid logging too frequently
skipping logging after 167776 examples to avoid logging too frequently
skipping logging after 167792 examples to avoid logging too frequently
train stats after 167808 examples: {'rewards_train/chosen': '0.85104', 'rewards_train/rejected': '-6.3554', 'rewards_train/margins': '7.1953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21167', 'examples_per_second': '4.5249', 'grad_norm': '5.2188', 'counters/examples': 167808, 'counters/updates': 10488}
skipping logging after 167824 examples to avoid logging too frequently
skipping logging after 167840 examples to avoid logging too frequently
skipping logging after 167856 examples to avoid logging too frequently
train stats after 167872 examples: {'rewards_train/chosen': '0.40213', 'rewards_train/rejected': '-6.3069', 'rewards_train/margins': '6.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20276', 'examples_per_second': '5.3748', 'grad_norm': '3.9844', 'counters/examples': 167872, 'counters/updates': 10492}
skipping logging after 167888 examples to avoid logging too frequently
skipping logging after 167904 examples to avoid logging too frequently
skipping logging after 167920 examples to avoid logging too frequently
train stats after 167936 examples: {'rewards_train/chosen': '0.26766', 'rewards_train/rejected': '-6.1864', 'rewards_train/margins': '6.4961', 'rewards_train/KL_estimate': '0', 'loss/train': '0.16895', 'examples_per_second': '5.0661', 'grad_norm': '3.9688', 'counters/examples': 167936, 'counters/updates': 10496}
skipping logging after 167952 examples to avoid logging too frequently
skipping logging after 167968 examples to avoid logging too frequently
skipping logging after 167984 examples to avoid logging too frequently
train stats after 168000 examples: {'rewards_train/chosen': '0.1378', 'rewards_train/rejected': '-5.6235', 'rewards_train/margins': '5.7734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20947', 'examples_per_second': '4.8775', 'grad_norm': '5.375', 'counters/examples': 168000, 'counters/updates': 10500}
Running evaluation after 168000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.24s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.25s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.16s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:39,  1.42s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.65s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.47s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:33,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.51s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.40s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:30,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:21<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.51s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.31s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.18s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]
eval after 168000: {'rewards_eval/chosen': '-6.4386', 'rewards_eval/rejected': '-7.0242', 'rewards_eval/margins': '0.43213', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.4603'}
skipping logging after 168016 examples to avoid logging too frequently
skipping logging after 168032 examples to avoid logging too frequently
skipping logging after 168048 examples to avoid logging too frequently
train stats after 168064 examples: {'rewards_train/chosen': '0.048847', 'rewards_train/rejected': '-6.209', 'rewards_train/margins': '6.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27161', 'examples_per_second': '5.8598', 'grad_norm': '6.5', 'counters/examples': 168064, 'counters/updates': 10504}
skipping logging after 168080 examples to avoid logging too frequently
skipping logging after 168096 examples to avoid logging too frequently
skipping logging after 168112 examples to avoid logging too frequently
train stats after 168128 examples: {'rewards_train/chosen': '0.69308', 'rewards_train/rejected': '-6.8339', 'rewards_train/margins': '7.5938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1864', 'examples_per_second': '5.5983', 'grad_norm': '4.5625', 'counters/examples': 168128, 'counters/updates': 10508}
skipping logging after 168144 examples to avoid logging too frequently
skipping logging after 168160 examples to avoid logging too frequently
skipping logging after 168176 examples to avoid logging too frequently
train stats after 168192 examples: {'rewards_train/chosen': '0.33662', 'rewards_train/rejected': '-5.5559', 'rewards_train/margins': '5.9141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23047', 'examples_per_second': '5.072', 'grad_norm': '4.3125', 'counters/examples': 168192, 'counters/updates': 10512}
skipping logging after 168208 examples to avoid logging too frequently
skipping logging after 168224 examples to avoid logging too frequently
skipping logging after 168240 examples to avoid logging too frequently
train stats after 168256 examples: {'rewards_train/chosen': '0.55424', 'rewards_train/rejected': '-6.2311', 'rewards_train/margins': '6.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21265', 'examples_per_second': '4.3726', 'grad_norm': '4.5', 'counters/examples': 168256, 'counters/updates': 10516}
skipping logging after 168272 examples to avoid logging too frequently
skipping logging after 168288 examples to avoid logging too frequently
skipping logging after 168304 examples to avoid logging too frequently
train stats after 168320 examples: {'rewards_train/chosen': '0.40869', 'rewards_train/rejected': '-6.0893', 'rewards_train/margins': '6.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2298', 'examples_per_second': '6.5945', 'grad_norm': '5.8125', 'counters/examples': 168320, 'counters/updates': 10520}
skipping logging after 168336 examples to avoid logging too frequently
skipping logging after 168352 examples to avoid logging too frequently
skipping logging after 168368 examples to avoid logging too frequently
train stats after 168384 examples: {'rewards_train/chosen': '0.086689', 'rewards_train/rejected': '-7.244', 'rewards_train/margins': '7.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26007', 'examples_per_second': '5.7075', 'grad_norm': '4.6562', 'counters/examples': 168384, 'counters/updates': 10524}
skipping logging after 168400 examples to avoid logging too frequently
skipping logging after 168416 examples to avoid logging too frequently
skipping logging after 168432 examples to avoid logging too frequently
train stats after 168448 examples: {'rewards_train/chosen': '0.53694', 'rewards_train/rejected': '-5.6277', 'rewards_train/margins': '6.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22833', 'examples_per_second': '5.9749', 'grad_norm': '4.1875', 'counters/examples': 168448, 'counters/updates': 10528}
skipping logging after 168464 examples to avoid logging too frequently
skipping logging after 168480 examples to avoid logging too frequently
skipping logging after 168496 examples to avoid logging too frequently
train stats after 168512 examples: {'rewards_train/chosen': '0.25035', 'rewards_train/rejected': '-5.8542', 'rewards_train/margins': '6.3828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24609', 'examples_per_second': '5.6892', 'grad_norm': '5.2812', 'counters/examples': 168512, 'counters/updates': 10532}
skipping logging after 168528 examples to avoid logging too frequently
skipping logging after 168544 examples to avoid logging too frequently
skipping logging after 168560 examples to avoid logging too frequently
train stats after 168576 examples: {'rewards_train/chosen': '0.13385', 'rewards_train/rejected': '-6.742', 'rewards_train/margins': '6.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23431', 'examples_per_second': '5.1891', 'grad_norm': '5.5312', 'counters/examples': 168576, 'counters/updates': 10536}
skipping logging after 168592 examples to avoid logging too frequently
skipping logging after 168608 examples to avoid logging too frequently
skipping logging after 168624 examples to avoid logging too frequently
train stats after 168640 examples: {'rewards_train/chosen': '0.27549', 'rewards_train/rejected': '-5.9239', 'rewards_train/margins': '6.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28906', 'examples_per_second': '5.1483', 'grad_norm': '4.875', 'counters/examples': 168640, 'counters/updates': 10540}
skipping logging after 168656 examples to avoid logging too frequently
skipping logging after 168672 examples to avoid logging too frequently
skipping logging after 168688 examples to avoid logging too frequently
train stats after 168704 examples: {'rewards_train/chosen': '0.4231', 'rewards_train/rejected': '-5.3725', 'rewards_train/margins': '5.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23096', 'examples_per_second': '6.1518', 'grad_norm': '4.9688', 'counters/examples': 168704, 'counters/updates': 10544}
skipping logging after 168720 examples to avoid logging too frequently
skipping logging after 168736 examples to avoid logging too frequently
skipping logging after 168752 examples to avoid logging too frequently
train stats after 168768 examples: {'rewards_train/chosen': '0.4957', 'rewards_train/rejected': '-4.8933', 'rewards_train/margins': '5.6602', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26715', 'examples_per_second': '6.2355', 'grad_norm': '5.3125', 'counters/examples': 168768, 'counters/updates': 10548}
skipping logging after 168784 examples to avoid logging too frequently
skipping logging after 168800 examples to avoid logging too frequently
skipping logging after 168816 examples to avoid logging too frequently
train stats after 168832 examples: {'rewards_train/chosen': '0.32057', 'rewards_train/rejected': '-4.8905', 'rewards_train/margins': '5.2969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25806', 'examples_per_second': '4.5924', 'grad_norm': '5.25', 'counters/examples': 168832, 'counters/updates': 10552}
skipping logging after 168848 examples to avoid logging too frequently
skipping logging after 168864 examples to avoid logging too frequently
skipping logging after 168880 examples to avoid logging too frequently
train stats after 168896 examples: {'rewards_train/chosen': '0.22796', 'rewards_train/rejected': '-3.5367', 'rewards_train/margins': '4', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29498', 'examples_per_second': '4.9922', 'grad_norm': '5.1562', 'counters/examples': 168896, 'counters/updates': 10556}
skipping logging after 168912 examples to avoid logging too frequently
skipping logging after 168928 examples to avoid logging too frequently
skipping logging after 168944 examples to avoid logging too frequently
train stats after 168960 examples: {'rewards_train/chosen': '0.22685', 'rewards_train/rejected': '-6.9461', 'rewards_train/margins': '7.1875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18152', 'examples_per_second': '4.6404', 'grad_norm': '5', 'counters/examples': 168960, 'counters/updates': 10560}
skipping logging after 168976 examples to avoid logging too frequently
skipping logging after 168992 examples to avoid logging too frequently
skipping logging after 169008 examples to avoid logging too frequently
train stats after 169024 examples: {'rewards_train/chosen': '0.41271', 'rewards_train/rejected': '-6.8871', 'rewards_train/margins': '7.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20831', 'examples_per_second': '4.7067', 'grad_norm': '4.9375', 'counters/examples': 169024, 'counters/updates': 10564}
skipping logging after 169040 examples to avoid logging too frequently
skipping logging after 169056 examples to avoid logging too frequently
skipping logging after 169072 examples to avoid logging too frequently
train stats after 169088 examples: {'rewards_train/chosen': '0.04248', 'rewards_train/rejected': '-6.9232', 'rewards_train/margins': '6.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21912', 'examples_per_second': '5.8356', 'grad_norm': '4.6875', 'counters/examples': 169088, 'counters/updates': 10568}
skipping logging after 169104 examples to avoid logging too frequently
skipping logging after 169120 examples to avoid logging too frequently
skipping logging after 169136 examples to avoid logging too frequently
train stats after 169152 examples: {'rewards_train/chosen': '0.1632', 'rewards_train/rejected': '-6.8958', 'rewards_train/margins': '7.1406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2597', 'examples_per_second': '5.5599', 'grad_norm': '6.1562', 'counters/examples': 169152, 'counters/updates': 10572}
skipping logging after 169168 examples to avoid logging too frequently
skipping logging after 169184 examples to avoid logging too frequently
skipping logging after 169200 examples to avoid logging too frequently
train stats after 169216 examples: {'rewards_train/chosen': '0.11868', 'rewards_train/rejected': '-6.8949', 'rewards_train/margins': '6.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21838', 'examples_per_second': '4.8657', 'grad_norm': '4.1875', 'counters/examples': 169216, 'counters/updates': 10576}
skipping logging after 169232 examples to avoid logging too frequently
skipping logging after 169248 examples to avoid logging too frequently
skipping logging after 169264 examples to avoid logging too frequently
train stats after 169280 examples: {'rewards_train/chosen': '0.18986', 'rewards_train/rejected': '-5.7015', 'rewards_train/margins': '5.6836', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26312', 'examples_per_second': '4.2588', 'grad_norm': '6.5938', 'counters/examples': 169280, 'counters/updates': 10580}
skipping logging after 169296 examples to avoid logging too frequently
skipping logging after 169312 examples to avoid logging too frequently
skipping logging after 169328 examples to avoid logging too frequently
train stats after 169344 examples: {'rewards_train/chosen': '0.40525', 'rewards_train/rejected': '-5.7049', 'rewards_train/margins': '6.0859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22491', 'examples_per_second': '4.3327', 'grad_norm': '5.5625', 'counters/examples': 169344, 'counters/updates': 10584}
skipping logging after 169360 examples to avoid logging too frequently
skipping logging after 169376 examples to avoid logging too frequently
skipping logging after 169392 examples to avoid logging too frequently
train stats after 169408 examples: {'rewards_train/chosen': '-0.18661', 'rewards_train/rejected': '-6.4367', 'rewards_train/margins': '6.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24414', 'examples_per_second': '4.7583', 'grad_norm': '5.4062', 'counters/examples': 169408, 'counters/updates': 10588}
skipping logging after 169424 examples to avoid logging too frequently
skipping logging after 169440 examples to avoid logging too frequently
skipping logging after 169456 examples to avoid logging too frequently
train stats after 169472 examples: {'rewards_train/chosen': '0.22497', 'rewards_train/rejected': '-6.9783', 'rewards_train/margins': '6.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24994', 'examples_per_second': '4.7881', 'grad_norm': '6.75', 'counters/examples': 169472, 'counters/updates': 10592}
skipping logging after 169488 examples to avoid logging too frequently
skipping logging after 169504 examples to avoid logging too frequently
skipping logging after 169520 examples to avoid logging too frequently
train stats after 169536 examples: {'rewards_train/chosen': '0.36738', 'rewards_train/rejected': '-6.2514', 'rewards_train/margins': '6.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20081', 'examples_per_second': '5.8335', 'grad_norm': '4.9062', 'counters/examples': 169536, 'counters/updates': 10596}
skipping logging after 169552 examples to avoid logging too frequently
skipping logging after 169568 examples to avoid logging too frequently
skipping logging after 169584 examples to avoid logging too frequently
train stats after 169600 examples: {'rewards_train/chosen': '0.41098', 'rewards_train/rejected': '-5.0334', 'rewards_train/margins': '5.3633', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22552', 'examples_per_second': '6.0923', 'grad_norm': '5.3438', 'counters/examples': 169600, 'counters/updates': 10600}
skipping logging after 169616 examples to avoid logging too frequently
skipping logging after 169632 examples to avoid logging too frequently
skipping logging after 169648 examples to avoid logging too frequently
train stats after 169664 examples: {'rewards_train/chosen': '0.54182', 'rewards_train/rejected': '-5.6897', 'rewards_train/margins': '6.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21954', 'examples_per_second': '5.2327', 'grad_norm': '4.75', 'counters/examples': 169664, 'counters/updates': 10604}
skipping logging after 169680 examples to avoid logging too frequently
skipping logging after 169696 examples to avoid logging too frequently
skipping logging after 169712 examples to avoid logging too frequently
train stats after 169728 examples: {'rewards_train/chosen': '0.30426', 'rewards_train/rejected': '-6.1574', 'rewards_train/margins': '6.3828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2511', 'examples_per_second': '4.801', 'grad_norm': '5.625', 'counters/examples': 169728, 'counters/updates': 10608}
skipping logging after 169744 examples to avoid logging too frequently
skipping logging after 169760 examples to avoid logging too frequently
skipping logging after 169776 examples to avoid logging too frequently
train stats after 169792 examples: {'rewards_train/chosen': '0.21348', 'rewards_train/rejected': '-6.013', 'rewards_train/margins': '6.0273', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24707', 'examples_per_second': '5.0166', 'grad_norm': '5.0312', 'counters/examples': 169792, 'counters/updates': 10612}
skipping logging after 169808 examples to avoid logging too frequently
skipping logging after 169824 examples to avoid logging too frequently
skipping logging after 169840 examples to avoid logging too frequently
train stats after 169856 examples: {'rewards_train/chosen': '0.56068', 'rewards_train/rejected': '-6.4766', 'rewards_train/margins': '7.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22815', 'examples_per_second': '4.6934', 'grad_norm': '5.2812', 'counters/examples': 169856, 'counters/updates': 10616}
skipping logging after 169872 examples to avoid logging too frequently
skipping logging after 169888 examples to avoid logging too frequently
skipping logging after 169904 examples to avoid logging too frequently
train stats after 169920 examples: {'rewards_train/chosen': '0.32804', 'rewards_train/rejected': '-6.4205', 'rewards_train/margins': '6.4609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28748', 'examples_per_second': '4.7984', 'grad_norm': '6.3125', 'counters/examples': 169920, 'counters/updates': 10620}
skipping logging after 169936 examples to avoid logging too frequently
skipping logging after 169952 examples to avoid logging too frequently
skipping logging after 169968 examples to avoid logging too frequently
train stats after 169984 examples: {'rewards_train/chosen': '0.56336', 'rewards_train/rejected': '-5.4671', 'rewards_train/margins': '6.0234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25208', 'examples_per_second': '5.1639', 'grad_norm': '5.4375', 'counters/examples': 169984, 'counters/updates': 10624}
skipping logging after 170000 examples to avoid logging too frequently
skipping logging after 170016 examples to avoid logging too frequently
skipping logging after 170032 examples to avoid logging too frequently
train stats after 170048 examples: {'rewards_train/chosen': '0.11242', 'rewards_train/rejected': '-4.9695', 'rewards_train/margins': '4.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26373', 'examples_per_second': '4.7142', 'grad_norm': '4.4688', 'counters/examples': 170048, 'counters/updates': 10628}
skipping logging after 170064 examples to avoid logging too frequently
skipping logging after 170080 examples to avoid logging too frequently
skipping logging after 170096 examples to avoid logging too frequently
train stats after 170112 examples: {'rewards_train/chosen': '0.26363', 'rewards_train/rejected': '-5.368', 'rewards_train/margins': '5.6094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24048', 'examples_per_second': '5.8884', 'grad_norm': '4.875', 'counters/examples': 170112, 'counters/updates': 10632}
skipping logging after 170128 examples to avoid logging too frequently
skipping logging after 170144 examples to avoid logging too frequently
skipping logging after 170160 examples to avoid logging too frequently
train stats after 170176 examples: {'rewards_train/chosen': '0.27961', 'rewards_train/rejected': '-6.1792', 'rewards_train/margins': '6.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24463', 'examples_per_second': '5.9737', 'grad_norm': '4.5', 'counters/examples': 170176, 'counters/updates': 10636}
skipping logging after 170192 examples to avoid logging too frequently
skipping logging after 170208 examples to avoid logging too frequently
skipping logging after 170224 examples to avoid logging too frequently
train stats after 170240 examples: {'rewards_train/chosen': '0.3877', 'rewards_train/rejected': '-5.5038', 'rewards_train/margins': '5.5117', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26868', 'examples_per_second': '4.9296', 'grad_norm': '9.5', 'counters/examples': 170240, 'counters/updates': 10640}
skipping logging after 170256 examples to avoid logging too frequently
skipping logging after 170272 examples to avoid logging too frequently
skipping logging after 170288 examples to avoid logging too frequently
train stats after 170304 examples: {'rewards_train/chosen': '-0.016194', 'rewards_train/rejected': '-5.7741', 'rewards_train/margins': '5.6484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22961', 'examples_per_second': '4.7693', 'grad_norm': '4.5312', 'counters/examples': 170304, 'counters/updates': 10644}
skipping logging after 170320 examples to avoid logging too frequently
skipping logging after 170336 examples to avoid logging too frequently
skipping logging after 170352 examples to avoid logging too frequently
train stats after 170368 examples: {'rewards_train/chosen': '0.48657', 'rewards_train/rejected': '-6.7769', 'rewards_train/margins': '7.2422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19965', 'examples_per_second': '4.6343', 'grad_norm': '4.1875', 'counters/examples': 170368, 'counters/updates': 10648}
skipping logging after 170384 examples to avoid logging too frequently
skipping logging after 170400 examples to avoid logging too frequently
skipping logging after 170416 examples to avoid logging too frequently
train stats after 170432 examples: {'rewards_train/chosen': '0.41111', 'rewards_train/rejected': '-5.221', 'rewards_train/margins': '5.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28162', 'examples_per_second': '5.2141', 'grad_norm': '4.875', 'counters/examples': 170432, 'counters/updates': 10652}
skipping logging after 170448 examples to avoid logging too frequently
skipping logging after 170464 examples to avoid logging too frequently
skipping logging after 170480 examples to avoid logging too frequently
train stats after 170496 examples: {'rewards_train/chosen': '0.5604', 'rewards_train/rejected': '-4.6539', 'rewards_train/margins': '5.0859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21838', 'examples_per_second': '5.2611', 'grad_norm': '4.9062', 'counters/examples': 170496, 'counters/updates': 10656}
skipping logging after 170512 examples to avoid logging too frequently
skipping logging after 170528 examples to avoid logging too frequently
skipping logging after 170544 examples to avoid logging too frequently
train stats after 170560 examples: {'rewards_train/chosen': '0.15026', 'rewards_train/rejected': '-6.1775', 'rewards_train/margins': '6.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2594', 'examples_per_second': '4.8069', 'grad_norm': '5', 'counters/examples': 170560, 'counters/updates': 10660}
skipping logging after 170576 examples to avoid logging too frequently
skipping logging after 170592 examples to avoid logging too frequently
skipping logging after 170608 examples to avoid logging too frequently
train stats after 170624 examples: {'rewards_train/chosen': '0.27212', 'rewards_train/rejected': '-6.4522', 'rewards_train/margins': '6.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20801', 'examples_per_second': '5.4642', 'grad_norm': '4.375', 'counters/examples': 170624, 'counters/updates': 10664}
skipping logging after 170640 examples to avoid logging too frequently
skipping logging after 170656 examples to avoid logging too frequently
skipping logging after 170672 examples to avoid logging too frequently
train stats after 170688 examples: {'rewards_train/chosen': '0.52465', 'rewards_train/rejected': '-7.1039', 'rewards_train/margins': '7.7109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24841', 'examples_per_second': '4.8258', 'grad_norm': '4.7812', 'counters/examples': 170688, 'counters/updates': 10668}
skipping logging after 170704 examples to avoid logging too frequently
skipping logging after 170720 examples to avoid logging too frequently
skipping logging after 170736 examples to avoid logging too frequently
train stats after 170752 examples: {'rewards_train/chosen': '0.51526', 'rewards_train/rejected': '-5.8446', 'rewards_train/margins': '6.3867', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25983', 'examples_per_second': '5.3835', 'grad_norm': '5.5938', 'counters/examples': 170752, 'counters/updates': 10672}
skipping logging after 170768 examples to avoid logging too frequently
skipping logging after 170784 examples to avoid logging too frequently
skipping logging after 170800 examples to avoid logging too frequently
train stats after 170816 examples: {'rewards_train/chosen': '0.11951', 'rewards_train/rejected': '-6.2111', 'rewards_train/margins': '6.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26819', 'examples_per_second': '4.7422', 'grad_norm': '5.1875', 'counters/examples': 170816, 'counters/updates': 10676}
skipping logging after 170832 examples to avoid logging too frequently
skipping logging after 170848 examples to avoid logging too frequently
skipping logging after 170864 examples to avoid logging too frequently
train stats after 170880 examples: {'rewards_train/chosen': '0.30877', 'rewards_train/rejected': '-5.3435', 'rewards_train/margins': '5.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23163', 'examples_per_second': '5.3309', 'grad_norm': '4.5625', 'counters/examples': 170880, 'counters/updates': 10680}
skipping logging after 170896 examples to avoid logging too frequently
skipping logging after 170912 examples to avoid logging too frequently
skipping logging after 170928 examples to avoid logging too frequently
train stats after 170944 examples: {'rewards_train/chosen': '0.35266', 'rewards_train/rejected': '-6.18', 'rewards_train/margins': '6.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22729', 'examples_per_second': '4.6425', 'grad_norm': '4.9688', 'counters/examples': 170944, 'counters/updates': 10684}
skipping logging after 170960 examples to avoid logging too frequently
skipping logging after 170976 examples to avoid logging too frequently
skipping logging after 170992 examples to avoid logging too frequently
train stats after 171008 examples: {'rewards_train/chosen': '0.42748', 'rewards_train/rejected': '-7.8244', 'rewards_train/margins': '8.2422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22717', 'examples_per_second': '4.8292', 'grad_norm': '5.4375', 'counters/examples': 171008, 'counters/updates': 10688}
skipping logging after 171024 examples to avoid logging too frequently
skipping logging after 171040 examples to avoid logging too frequently
skipping logging after 171056 examples to avoid logging too frequently
train stats after 171072 examples: {'rewards_train/chosen': '0.50102', 'rewards_train/rejected': '-6.6424', 'rewards_train/margins': '7.4219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24469', 'examples_per_second': '4.6331', 'grad_norm': '4.5938', 'counters/examples': 171072, 'counters/updates': 10692}
skipping logging after 171088 examples to avoid logging too frequently
skipping logging after 171104 examples to avoid logging too frequently
skipping logging after 171120 examples to avoid logging too frequently
train stats after 171136 examples: {'rewards_train/chosen': '0.24894', 'rewards_train/rejected': '-5.9308', 'rewards_train/margins': '5.5977', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23779', 'examples_per_second': '5.135', 'grad_norm': '4.4688', 'counters/examples': 171136, 'counters/updates': 10696}
skipping logging after 171152 examples to avoid logging too frequently
skipping logging after 171168 examples to avoid logging too frequently
skipping logging after 171184 examples to avoid logging too frequently
train stats after 171200 examples: {'rewards_train/chosen': '0.26694', 'rewards_train/rejected': '-5.9122', 'rewards_train/margins': '5.8203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25964', 'examples_per_second': '5.7128', 'grad_norm': '4.75', 'counters/examples': 171200, 'counters/updates': 10700}
skipping logging after 171216 examples to avoid logging too frequently
skipping logging after 171232 examples to avoid logging too frequently
skipping logging after 171248 examples to avoid logging too frequently
train stats after 171264 examples: {'rewards_train/chosen': '0.49623', 'rewards_train/rejected': '-5.882', 'rewards_train/margins': '6.3203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19568', 'examples_per_second': '4.6297', 'grad_norm': '3.8125', 'counters/examples': 171264, 'counters/updates': 10704}
skipping logging after 171280 examples to avoid logging too frequently
skipping logging after 171296 examples to avoid logging too frequently
skipping logging after 171312 examples to avoid logging too frequently
train stats after 171328 examples: {'rewards_train/chosen': '0.3015', 'rewards_train/rejected': '-6.4381', 'rewards_train/margins': '6.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26038', 'examples_per_second': '5.595', 'grad_norm': '5.375', 'counters/examples': 171328, 'counters/updates': 10708}
skipping logging after 171344 examples to avoid logging too frequently
skipping logging after 171360 examples to avoid logging too frequently
skipping logging after 171376 examples to avoid logging too frequently
train stats after 171392 examples: {'rewards_train/chosen': '0.49972', 'rewards_train/rejected': '-7.8729', 'rewards_train/margins': '8.0312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22968', 'examples_per_second': '4.1956', 'grad_norm': '4.5938', 'counters/examples': 171392, 'counters/updates': 10712}
skipping logging after 171408 examples to avoid logging too frequently
skipping logging after 171424 examples to avoid logging too frequently
skipping logging after 171440 examples to avoid logging too frequently
train stats after 171456 examples: {'rewards_train/chosen': '0.37244', 'rewards_train/rejected': '-6.0781', 'rewards_train/margins': '6.3594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20007', 'examples_per_second': '5.0134', 'grad_norm': '4.6875', 'counters/examples': 171456, 'counters/updates': 10716}
skipping logging after 171472 examples to avoid logging too frequently
skipping logging after 171488 examples to avoid logging too frequently
skipping logging after 171504 examples to avoid logging too frequently
train stats after 171520 examples: {'rewards_train/chosen': '0.41288', 'rewards_train/rejected': '-6.2656', 'rewards_train/margins': '6.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17432', 'examples_per_second': '4.7624', 'grad_norm': '3.7344', 'counters/examples': 171520, 'counters/updates': 10720}
skipping logging after 171536 examples to avoid logging too frequently
skipping logging after 171552 examples to avoid logging too frequently
skipping logging after 171568 examples to avoid logging too frequently
train stats after 171584 examples: {'rewards_train/chosen': '0.24524', 'rewards_train/rejected': '-5.1562', 'rewards_train/margins': '5.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26062', 'examples_per_second': '5.063', 'grad_norm': '5.125', 'counters/examples': 171584, 'counters/updates': 10724}
skipping logging after 171600 examples to avoid logging too frequently
skipping logging after 171616 examples to avoid logging too frequently
skipping logging after 171632 examples to avoid logging too frequently
train stats after 171648 examples: {'rewards_train/chosen': '0.57236', 'rewards_train/rejected': '-5.5326', 'rewards_train/margins': '5.9141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20221', 'examples_per_second': '6.07', 'grad_norm': '4.2812', 'counters/examples': 171648, 'counters/updates': 10728}
skipping logging after 171664 examples to avoid logging too frequently
skipping logging after 171680 examples to avoid logging too frequently
skipping logging after 171696 examples to avoid logging too frequently
train stats after 171712 examples: {'rewards_train/chosen': '0.49005', 'rewards_train/rejected': '-6.0108', 'rewards_train/margins': '6.5938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20721', 'examples_per_second': '5.4564', 'grad_norm': '5.125', 'counters/examples': 171712, 'counters/updates': 10732}
skipping logging after 171728 examples to avoid logging too frequently
skipping logging after 171744 examples to avoid logging too frequently
skipping logging after 171760 examples to avoid logging too frequently
train stats after 171776 examples: {'rewards_train/chosen': '0.76311', 'rewards_train/rejected': '-5.2707', 'rewards_train/margins': '6.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22504', 'examples_per_second': '4.5997', 'grad_norm': '5.2188', 'counters/examples': 171776, 'counters/updates': 10736}
skipping logging after 171792 examples to avoid logging too frequently
skipping logging after 171808 examples to avoid logging too frequently
skipping logging after 171824 examples to avoid logging too frequently
train stats after 171840 examples: {'rewards_train/chosen': '0.40919', 'rewards_train/rejected': '-6.1713', 'rewards_train/margins': '6.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26154', 'examples_per_second': '5.313', 'grad_norm': '5.625', 'counters/examples': 171840, 'counters/updates': 10740}
skipping logging after 171856 examples to avoid logging too frequently
skipping logging after 171872 examples to avoid logging too frequently
skipping logging after 171888 examples to avoid logging too frequently
train stats after 171904 examples: {'rewards_train/chosen': '0.17811', 'rewards_train/rejected': '-5.2918', 'rewards_train/margins': '5.6562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29248', 'examples_per_second': '5.0703', 'grad_norm': '6.75', 'counters/examples': 171904, 'counters/updates': 10744}
skipping logging after 171920 examples to avoid logging too frequently
skipping logging after 171936 examples to avoid logging too frequently
skipping logging after 171952 examples to avoid logging too frequently
train stats after 171968 examples: {'rewards_train/chosen': '0.46211', 'rewards_train/rejected': '-5.9311', 'rewards_train/margins': '6.2422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23328', 'examples_per_second': '5.4376', 'grad_norm': '6.0312', 'counters/examples': 171968, 'counters/updates': 10748}
skipping logging after 171984 examples to avoid logging too frequently
skipping logging after 172000 examples to avoid logging too frequently
Running evaluation after 172000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:53,  1.73s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:43,  1.45s/it]Computing eval metrics:   9%|▉         | 3/32 [00:04<00:36,  1.27s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.49s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.69s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:09<00:38,  1.50s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:10<00:34,  1.38s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:12<00:36,  1.53s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.49s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:31,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:20<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:21<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:28<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:12,  1.44s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.20s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:40<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:41<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]
eval after 172000: {'rewards_eval/chosen': '-5.063', 'rewards_eval/rejected': '-5.57', 'rewards_eval/margins': '0.38623', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.45824'}
skipping logging after 172016 examples to avoid logging too frequently
train stats after 172032 examples: {'rewards_train/chosen': '0.44516', 'rewards_train/rejected': '-4.7523', 'rewards_train/margins': '5.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24481', 'examples_per_second': '4.9775', 'grad_norm': '4.5312', 'counters/examples': 172032, 'counters/updates': 10752}
skipping logging after 172048 examples to avoid logging too frequently
skipping logging after 172064 examples to avoid logging too frequently
skipping logging after 172080 examples to avoid logging too frequently
train stats after 172096 examples: {'rewards_train/chosen': '0.033646', 'rewards_train/rejected': '-5.4787', 'rewards_train/margins': '5.6641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28406', 'examples_per_second': '4.8064', 'grad_norm': '4.9688', 'counters/examples': 172096, 'counters/updates': 10756}
skipping logging after 172112 examples to avoid logging too frequently
skipping logging after 172128 examples to avoid logging too frequently
skipping logging after 172144 examples to avoid logging too frequently
train stats after 172160 examples: {'rewards_train/chosen': '0.21788', 'rewards_train/rejected': '-6.0414', 'rewards_train/margins': '6.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23712', 'examples_per_second': '5.5489', 'grad_norm': '4.5312', 'counters/examples': 172160, 'counters/updates': 10760}
skipping logging after 172176 examples to avoid logging too frequently
skipping logging after 172192 examples to avoid logging too frequently
skipping logging after 172208 examples to avoid logging too frequently
train stats after 172224 examples: {'rewards_train/chosen': '0.17482', 'rewards_train/rejected': '-4.6616', 'rewards_train/margins': '4.8984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22217', 'examples_per_second': '6.0021', 'grad_norm': '4.2812', 'counters/examples': 172224, 'counters/updates': 10764}
skipping logging after 172240 examples to avoid logging too frequently
skipping logging after 172256 examples to avoid logging too frequently
skipping logging after 172272 examples to avoid logging too frequently
train stats after 172288 examples: {'rewards_train/chosen': '0.55849', 'rewards_train/rejected': '-5.3393', 'rewards_train/margins': '5.9453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24072', 'examples_per_second': '5.1072', 'grad_norm': '4.9688', 'counters/examples': 172288, 'counters/updates': 10768}
skipping logging after 172304 examples to avoid logging too frequently
skipping logging after 172320 examples to avoid logging too frequently
skipping logging after 172336 examples to avoid logging too frequently
train stats after 172352 examples: {'rewards_train/chosen': '0.45473', 'rewards_train/rejected': '-6.2749', 'rewards_train/margins': '6.5469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18744', 'examples_per_second': '4.828', 'grad_norm': '4.9375', 'counters/examples': 172352, 'counters/updates': 10772}
skipping logging after 172368 examples to avoid logging too frequently
skipping logging after 172384 examples to avoid logging too frequently
skipping logging after 172400 examples to avoid logging too frequently
train stats after 172416 examples: {'rewards_train/chosen': '-0.15319', 'rewards_train/rejected': '-5.5956', 'rewards_train/margins': '5.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.32812', 'examples_per_second': '4.8573', 'grad_norm': '6.25', 'counters/examples': 172416, 'counters/updates': 10776}
skipping logging after 172432 examples to avoid logging too frequently
skipping logging after 172448 examples to avoid logging too frequently
skipping logging after 172464 examples to avoid logging too frequently
train stats after 172480 examples: {'rewards_train/chosen': '0.41739', 'rewards_train/rejected': '-5.9009', 'rewards_train/margins': '6.2266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1994', 'examples_per_second': '5.6578', 'grad_norm': '4.7188', 'counters/examples': 172480, 'counters/updates': 10780}
skipping logging after 172496 examples to avoid logging too frequently
skipping logging after 172512 examples to avoid logging too frequently
skipping logging after 172528 examples to avoid logging too frequently
train stats after 172544 examples: {'rewards_train/chosen': '0.37146', 'rewards_train/rejected': '-5.5857', 'rewards_train/margins': '5.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25446', 'examples_per_second': '4.899', 'grad_norm': '4.5312', 'counters/examples': 172544, 'counters/updates': 10784}
skipping logging after 172560 examples to avoid logging too frequently
skipping logging after 172576 examples to avoid logging too frequently
skipping logging after 172592 examples to avoid logging too frequently
train stats after 172608 examples: {'rewards_train/chosen': '0.60766', 'rewards_train/rejected': '-6.8077', 'rewards_train/margins': '7.3281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19147', 'examples_per_second': '5.62', 'grad_norm': '4.375', 'counters/examples': 172608, 'counters/updates': 10788}
skipping logging after 172624 examples to avoid logging too frequently
skipping logging after 172640 examples to avoid logging too frequently
skipping logging after 172656 examples to avoid logging too frequently
train stats after 172672 examples: {'rewards_train/chosen': '0.4155', 'rewards_train/rejected': '-5.3499', 'rewards_train/margins': '5.7578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19623', 'examples_per_second': '6.707', 'grad_norm': '4.375', 'counters/examples': 172672, 'counters/updates': 10792}
skipping logging after 172688 examples to avoid logging too frequently
skipping logging after 172704 examples to avoid logging too frequently
skipping logging after 172720 examples to avoid logging too frequently
train stats after 172736 examples: {'rewards_train/chosen': '0.20129', 'rewards_train/rejected': '-6.5729', 'rewards_train/margins': '6.5781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24994', 'examples_per_second': '6.0519', 'grad_norm': '4.875', 'counters/examples': 172736, 'counters/updates': 10796}
skipping logging after 172752 examples to avoid logging too frequently
skipping logging after 172768 examples to avoid logging too frequently
skipping logging after 172784 examples to avoid logging too frequently
train stats after 172800 examples: {'rewards_train/chosen': '0.22316', 'rewards_train/rejected': '-5.1339', 'rewards_train/margins': '5.5273', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26807', 'examples_per_second': '4.3085', 'grad_norm': '5.25', 'counters/examples': 172800, 'counters/updates': 10800}
skipping logging after 172816 examples to avoid logging too frequently
skipping logging after 172832 examples to avoid logging too frequently
skipping logging after 172848 examples to avoid logging too frequently
train stats after 172864 examples: {'rewards_train/chosen': '0.34856', 'rewards_train/rejected': '-6.0512', 'rewards_train/margins': '6.1875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26544', 'examples_per_second': '6.6344', 'grad_norm': '4.9688', 'counters/examples': 172864, 'counters/updates': 10804}
skipping logging after 172880 examples to avoid logging too frequently
skipping logging after 172896 examples to avoid logging too frequently
skipping logging after 172912 examples to avoid logging too frequently
train stats after 172928 examples: {'rewards_train/chosen': '0.37702', 'rewards_train/rejected': '-6.1009', 'rewards_train/margins': '6.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18951', 'examples_per_second': '6.2825', 'grad_norm': '4.4062', 'counters/examples': 172928, 'counters/updates': 10808}
skipping logging after 172944 examples to avoid logging too frequently
skipping logging after 172960 examples to avoid logging too frequently
skipping logging after 172976 examples to avoid logging too frequently
train stats after 172992 examples: {'rewards_train/chosen': '0.39769', 'rewards_train/rejected': '-5.47', 'rewards_train/margins': '5.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25153', 'examples_per_second': '4.9845', 'grad_norm': '5.25', 'counters/examples': 172992, 'counters/updates': 10812}
skipping logging after 173008 examples to avoid logging too frequently
skipping logging after 173024 examples to avoid logging too frequently
skipping logging after 173040 examples to avoid logging too frequently
train stats after 173056 examples: {'rewards_train/chosen': '0.4099', 'rewards_train/rejected': '-4.9219', 'rewards_train/margins': '5.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23682', 'examples_per_second': '4.3464', 'grad_norm': '5.5', 'counters/examples': 173056, 'counters/updates': 10816}
skipping logging after 173072 examples to avoid logging too frequently
skipping logging after 173088 examples to avoid logging too frequently
skipping logging after 173104 examples to avoid logging too frequently
train stats after 173120 examples: {'rewards_train/chosen': '0.38484', 'rewards_train/rejected': '-5.8387', 'rewards_train/margins': '6.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19879', 'examples_per_second': '5.532', 'grad_norm': '5.3125', 'counters/examples': 173120, 'counters/updates': 10820}
skipping logging after 173136 examples to avoid logging too frequently
skipping logging after 173152 examples to avoid logging too frequently
skipping logging after 173168 examples to avoid logging too frequently
train stats after 173184 examples: {'rewards_train/chosen': '0.23169', 'rewards_train/rejected': '-6.2134', 'rewards_train/margins': '6.4219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2312', 'examples_per_second': '5.3179', 'grad_norm': '4.875', 'counters/examples': 173184, 'counters/updates': 10824}
skipping logging after 173200 examples to avoid logging too frequently
skipping logging after 173216 examples to avoid logging too frequently
skipping logging after 173232 examples to avoid logging too frequently
train stats after 173248 examples: {'rewards_train/chosen': '0.79499', 'rewards_train/rejected': '-6.1296', 'rewards_train/margins': '7.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20575', 'examples_per_second': '4.6774', 'grad_norm': '4.0312', 'counters/examples': 173248, 'counters/updates': 10828}
skipping logging after 173264 examples to avoid logging too frequently
skipping logging after 173280 examples to avoid logging too frequently
skipping logging after 173296 examples to avoid logging too frequently
train stats after 173312 examples: {'rewards_train/chosen': '0.58623', 'rewards_train/rejected': '-6.7936', 'rewards_train/margins': '7.1953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2207', 'examples_per_second': '5.0224', 'grad_norm': '4', 'counters/examples': 173312, 'counters/updates': 10832}
skipping logging after 173328 examples to avoid logging too frequently
skipping logging after 173344 examples to avoid logging too frequently
skipping logging after 173360 examples to avoid logging too frequently
train stats after 173376 examples: {'rewards_train/chosen': '0.26426', 'rewards_train/rejected': '-8.7815', 'rewards_train/margins': '9.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21069', 'examples_per_second': '4.6447', 'grad_norm': '4.5625', 'counters/examples': 173376, 'counters/updates': 10836}
skipping logging after 173392 examples to avoid logging too frequently
skipping logging after 173408 examples to avoid logging too frequently
skipping logging after 173424 examples to avoid logging too frequently
train stats after 173440 examples: {'rewards_train/chosen': '0.26265', 'rewards_train/rejected': '-7.9183', 'rewards_train/margins': '8.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22247', 'examples_per_second': '4.5122', 'grad_norm': '5.4688', 'counters/examples': 173440, 'counters/updates': 10840}
skipping logging after 173456 examples to avoid logging too frequently
skipping logging after 173472 examples to avoid logging too frequently
skipping logging after 173488 examples to avoid logging too frequently
train stats after 173504 examples: {'rewards_train/chosen': '0.59383', 'rewards_train/rejected': '-4.8526', 'rewards_train/margins': '5.4141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19336', 'examples_per_second': '5.0239', 'grad_norm': '4.8125', 'counters/examples': 173504, 'counters/updates': 10844}
skipping logging after 173520 examples to avoid logging too frequently
skipping logging after 173536 examples to avoid logging too frequently
skipping logging after 173552 examples to avoid logging too frequently
train stats after 173568 examples: {'rewards_train/chosen': '0.62679', 'rewards_train/rejected': '-6.5936', 'rewards_train/margins': '6.7461', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24792', 'examples_per_second': '4.5262', 'grad_norm': '4.8125', 'counters/examples': 173568, 'counters/updates': 10848}
skipping logging after 173584 examples to avoid logging too frequently
skipping logging after 173600 examples to avoid logging too frequently
skipping logging after 173616 examples to avoid logging too frequently
train stats after 173632 examples: {'rewards_train/chosen': '0.4527', 'rewards_train/rejected': '-5.9784', 'rewards_train/margins': '6.375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25281', 'examples_per_second': '4.8002', 'grad_norm': '4.4375', 'counters/examples': 173632, 'counters/updates': 10852}
skipping logging after 173648 examples to avoid logging too frequently
skipping logging after 173664 examples to avoid logging too frequently
skipping logging after 173680 examples to avoid logging too frequently
train stats after 173696 examples: {'rewards_train/chosen': '0.3064', 'rewards_train/rejected': '-7.8634', 'rewards_train/margins': '7.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28387', 'examples_per_second': '5.2188', 'grad_norm': '5.0625', 'counters/examples': 173696, 'counters/updates': 10856}
skipping logging after 173712 examples to avoid logging too frequently
skipping logging after 173728 examples to avoid logging too frequently
skipping logging after 173744 examples to avoid logging too frequently
train stats after 173760 examples: {'rewards_train/chosen': '0.47567', 'rewards_train/rejected': '-5.8861', 'rewards_train/margins': '6.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23138', 'examples_per_second': '5.7089', 'grad_norm': '5.125', 'counters/examples': 173760, 'counters/updates': 10860}
skipping logging after 173776 examples to avoid logging too frequently
skipping logging after 173792 examples to avoid logging too frequently
skipping logging after 173808 examples to avoid logging too frequently
train stats after 173824 examples: {'rewards_train/chosen': '0.39117', 'rewards_train/rejected': '-6.6115', 'rewards_train/margins': '6.7266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21259', 'examples_per_second': '5.6805', 'grad_norm': '4.25', 'counters/examples': 173824, 'counters/updates': 10864}
skipping logging after 173840 examples to avoid logging too frequently
skipping logging after 173856 examples to avoid logging too frequently
skipping logging after 173872 examples to avoid logging too frequently
train stats after 173888 examples: {'rewards_train/chosen': '0.50691', 'rewards_train/rejected': '-5.8935', 'rewards_train/margins': '6.375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24298', 'examples_per_second': '5.029', 'grad_norm': '5.0938', 'counters/examples': 173888, 'counters/updates': 10868}
skipping logging after 173904 examples to avoid logging too frequently
skipping logging after 173920 examples to avoid logging too frequently
skipping logging after 173936 examples to avoid logging too frequently
train stats after 173952 examples: {'rewards_train/chosen': '0.21477', 'rewards_train/rejected': '-6.6199', 'rewards_train/margins': '6.8828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20331', 'examples_per_second': '4.5891', 'grad_norm': '5', 'counters/examples': 173952, 'counters/updates': 10872}
skipping logging after 173968 examples to avoid logging too frequently
skipping logging after 173984 examples to avoid logging too frequently
skipping logging after 174000 examples to avoid logging too frequently
train stats after 174016 examples: {'rewards_train/chosen': '0.47296', 'rewards_train/rejected': '-5.5291', 'rewards_train/margins': '5.7422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2417', 'examples_per_second': '4.3841', 'grad_norm': '5.4062', 'counters/examples': 174016, 'counters/updates': 10876}
skipping logging after 174032 examples to avoid logging too frequently
skipping logging after 174048 examples to avoid logging too frequently
skipping logging after 174064 examples to avoid logging too frequently
train stats after 174080 examples: {'rewards_train/chosen': '0.56062', 'rewards_train/rejected': '-6.6756', 'rewards_train/margins': '7.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22729', 'examples_per_second': '6.2918', 'grad_norm': '4.9688', 'counters/examples': 174080, 'counters/updates': 10880}
skipping logging after 174096 examples to avoid logging too frequently
skipping logging after 174112 examples to avoid logging too frequently
skipping logging after 174128 examples to avoid logging too frequently
train stats after 174144 examples: {'rewards_train/chosen': '0.021399', 'rewards_train/rejected': '-6.1264', 'rewards_train/margins': '5.7305', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28363', 'examples_per_second': '4.6175', 'grad_norm': '4.9688', 'counters/examples': 174144, 'counters/updates': 10884}
skipping logging after 174160 examples to avoid logging too frequently
skipping logging after 174176 examples to avoid logging too frequently
skipping logging after 174192 examples to avoid logging too frequently
train stats after 174208 examples: {'rewards_train/chosen': '0.67961', 'rewards_train/rejected': '-4.5675', 'rewards_train/margins': '5.2422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18433', 'examples_per_second': '5.0225', 'grad_norm': '4.6875', 'counters/examples': 174208, 'counters/updates': 10888}
skipping logging after 174224 examples to avoid logging too frequently
skipping logging after 174240 examples to avoid logging too frequently
skipping logging after 174256 examples to avoid logging too frequently
train stats after 174272 examples: {'rewards_train/chosen': '0.5037', 'rewards_train/rejected': '-5.3473', 'rewards_train/margins': '5.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22736', 'examples_per_second': '4.7778', 'grad_norm': '5.5625', 'counters/examples': 174272, 'counters/updates': 10892}
skipping logging after 174288 examples to avoid logging too frequently
skipping logging after 174304 examples to avoid logging too frequently
skipping logging after 174320 examples to avoid logging too frequently
train stats after 174336 examples: {'rewards_train/chosen': '0.28483', 'rewards_train/rejected': '-5.0837', 'rewards_train/margins': '5.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28717', 'examples_per_second': '5.6548', 'grad_norm': '5.75', 'counters/examples': 174336, 'counters/updates': 10896}
skipping logging after 174352 examples to avoid logging too frequently
skipping logging after 174368 examples to avoid logging too frequently
skipping logging after 174384 examples to avoid logging too frequently
train stats after 174400 examples: {'rewards_train/chosen': '0.16856', 'rewards_train/rejected': '-6.0566', 'rewards_train/margins': '6.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25092', 'examples_per_second': '4.4806', 'grad_norm': '4.4062', 'counters/examples': 174400, 'counters/updates': 10900}
skipping logging after 174416 examples to avoid logging too frequently
skipping logging after 174432 examples to avoid logging too frequently
skipping logging after 174448 examples to avoid logging too frequently
train stats after 174464 examples: {'rewards_train/chosen': '0.35549', 'rewards_train/rejected': '-5.9592', 'rewards_train/margins': '6.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25159', 'examples_per_second': '5.1536', 'grad_norm': '5.375', 'counters/examples': 174464, 'counters/updates': 10904}
skipping logging after 174480 examples to avoid logging too frequently
skipping logging after 174496 examples to avoid logging too frequently
skipping logging after 174512 examples to avoid logging too frequently
train stats after 174528 examples: {'rewards_train/chosen': '0.40355', 'rewards_train/rejected': '-5.9935', 'rewards_train/margins': '6.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27441', 'examples_per_second': '5.5666', 'grad_norm': '4.7188', 'counters/examples': 174528, 'counters/updates': 10908}
skipping logging after 174544 examples to avoid logging too frequently
skipping logging after 174560 examples to avoid logging too frequently
skipping logging after 174576 examples to avoid logging too frequently
train stats after 174592 examples: {'rewards_train/chosen': '0.58008', 'rewards_train/rejected': '-6.7416', 'rewards_train/margins': '6.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26178', 'examples_per_second': '4.7323', 'grad_norm': '5.0938', 'counters/examples': 174592, 'counters/updates': 10912}
skipping logging after 174608 examples to avoid logging too frequently
skipping logging after 174624 examples to avoid logging too frequently
skipping logging after 174640 examples to avoid logging too frequently
train stats after 174656 examples: {'rewards_train/chosen': '0.19085', 'rewards_train/rejected': '-5.9363', 'rewards_train/margins': '6.0508', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23999', 'examples_per_second': '4.8204', 'grad_norm': '5.7812', 'counters/examples': 174656, 'counters/updates': 10916}
skipping logging after 174672 examples to avoid logging too frequently
skipping logging after 174688 examples to avoid logging too frequently
skipping logging after 174704 examples to avoid logging too frequently
train stats after 174720 examples: {'rewards_train/chosen': '0.25823', 'rewards_train/rejected': '-6.114', 'rewards_train/margins': '6.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24988', 'examples_per_second': '4.6868', 'grad_norm': '4.75', 'counters/examples': 174720, 'counters/updates': 10920}
skipping logging after 174736 examples to avoid logging too frequently
skipping logging after 174752 examples to avoid logging too frequently
skipping logging after 174768 examples to avoid logging too frequently
train stats after 174784 examples: {'rewards_train/chosen': '0.38643', 'rewards_train/rejected': '-6.7879', 'rewards_train/margins': '7.1172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23615', 'examples_per_second': '5.9378', 'grad_norm': '5.4688', 'counters/examples': 174784, 'counters/updates': 10924}
skipping logging after 174800 examples to avoid logging too frequently
skipping logging after 174816 examples to avoid logging too frequently
skipping logging after 174832 examples to avoid logging too frequently
train stats after 174848 examples: {'rewards_train/chosen': '0.24108', 'rewards_train/rejected': '-6.2541', 'rewards_train/margins': '6.4844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23511', 'examples_per_second': '4.7999', 'grad_norm': '4.0938', 'counters/examples': 174848, 'counters/updates': 10928}
skipping logging after 174864 examples to avoid logging too frequently
skipping logging after 174880 examples to avoid logging too frequently
skipping logging after 174896 examples to avoid logging too frequently
train stats after 174912 examples: {'rewards_train/chosen': '0.73664', 'rewards_train/rejected': '-4.5848', 'rewards_train/margins': '5.0547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23108', 'examples_per_second': '4.8587', 'grad_norm': '5.7812', 'counters/examples': 174912, 'counters/updates': 10932}
skipping logging after 174928 examples to avoid logging too frequently
skipping logging after 174944 examples to avoid logging too frequently
skipping logging after 174960 examples to avoid logging too frequently
train stats after 174976 examples: {'rewards_train/chosen': '0.57053', 'rewards_train/rejected': '-7.8675', 'rewards_train/margins': '8.3203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19562', 'examples_per_second': '5.2435', 'grad_norm': '4.6562', 'counters/examples': 174976, 'counters/updates': 10936}
skipping logging after 174992 examples to avoid logging too frequently
skipping logging after 175008 examples to avoid logging too frequently
skipping logging after 175024 examples to avoid logging too frequently
train stats after 175040 examples: {'rewards_train/chosen': '0.35227', 'rewards_train/rejected': '-5.7777', 'rewards_train/margins': '6.0859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23743', 'examples_per_second': '5.3436', 'grad_norm': '4.4688', 'counters/examples': 175040, 'counters/updates': 10940}
skipping logging after 175056 examples to avoid logging too frequently
skipping logging after 175072 examples to avoid logging too frequently
skipping logging after 175088 examples to avoid logging too frequently
train stats after 175104 examples: {'rewards_train/chosen': '0.41924', 'rewards_train/rejected': '-5.0521', 'rewards_train/margins': '5.4531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21887', 'examples_per_second': '4.8808', 'grad_norm': '5.0938', 'counters/examples': 175104, 'counters/updates': 10944}
skipping logging after 175120 examples to avoid logging too frequently
skipping logging after 175136 examples to avoid logging too frequently
skipping logging after 175152 examples to avoid logging too frequently
train stats after 175168 examples: {'rewards_train/chosen': '0.40912', 'rewards_train/rejected': '-7.2777', 'rewards_train/margins': '7.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20868', 'examples_per_second': '5.0199', 'grad_norm': '5.125', 'counters/examples': 175168, 'counters/updates': 10948}
skipping logging after 175184 examples to avoid logging too frequently
skipping logging after 175200 examples to avoid logging too frequently
skipping logging after 175216 examples to avoid logging too frequently
train stats after 175232 examples: {'rewards_train/chosen': '0.17799', 'rewards_train/rejected': '-7.2796', 'rewards_train/margins': '7.6016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23761', 'examples_per_second': '5.4926', 'grad_norm': '5.0938', 'counters/examples': 175232, 'counters/updates': 10952}
skipping logging after 175248 examples to avoid logging too frequently
skipping logging after 175264 examples to avoid logging too frequently
skipping logging after 175280 examples to avoid logging too frequently
train stats after 175296 examples: {'rewards_train/chosen': '0.42121', 'rewards_train/rejected': '-5.8335', 'rewards_train/margins': '6.2266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19672', 'examples_per_second': '5.2114', 'grad_norm': '4.625', 'counters/examples': 175296, 'counters/updates': 10956}
skipping logging after 175312 examples to avoid logging too frequently
skipping logging after 175328 examples to avoid logging too frequently
skipping logging after 175344 examples to avoid logging too frequently
train stats after 175360 examples: {'rewards_train/chosen': '0.39997', 'rewards_train/rejected': '-7.339', 'rewards_train/margins': '7.8828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21869', 'examples_per_second': '5.842', 'grad_norm': '5.4062', 'counters/examples': 175360, 'counters/updates': 10960}
skipping logging after 175376 examples to avoid logging too frequently
skipping logging after 175392 examples to avoid logging too frequently
skipping logging after 175408 examples to avoid logging too frequently
train stats after 175424 examples: {'rewards_train/chosen': '0.16619', 'rewards_train/rejected': '-6.9347', 'rewards_train/margins': '7.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26086', 'examples_per_second': '5.2036', 'grad_norm': '4.5', 'counters/examples': 175424, 'counters/updates': 10964}
skipping logging after 175440 examples to avoid logging too frequently
skipping logging after 175456 examples to avoid logging too frequently
skipping logging after 175472 examples to avoid logging too frequently
train stats after 175488 examples: {'rewards_train/chosen': '0.46821', 'rewards_train/rejected': '-5.3572', 'rewards_train/margins': '5.4727', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25415', 'examples_per_second': '4.7443', 'grad_norm': '6.9375', 'counters/examples': 175488, 'counters/updates': 10968}
skipping logging after 175504 examples to avoid logging too frequently
skipping logging after 175520 examples to avoid logging too frequently
skipping logging after 175536 examples to avoid logging too frequently
train stats after 175552 examples: {'rewards_train/chosen': '0.5874', 'rewards_train/rejected': '-4.7865', 'rewards_train/margins': '5.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.216', 'examples_per_second': '5.7626', 'grad_norm': '5.0938', 'counters/examples': 175552, 'counters/updates': 10972}
skipping logging after 175568 examples to avoid logging too frequently
skipping logging after 175584 examples to avoid logging too frequently
skipping logging after 175600 examples to avoid logging too frequently
train stats after 175616 examples: {'rewards_train/chosen': '-0.32803', 'rewards_train/rejected': '-5.6171', 'rewards_train/margins': '5.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25208', 'examples_per_second': '5.7367', 'grad_norm': '4.5938', 'counters/examples': 175616, 'counters/updates': 10976}
skipping logging after 175632 examples to avoid logging too frequently
skipping logging after 175648 examples to avoid logging too frequently
skipping logging after 175664 examples to avoid logging too frequently
train stats after 175680 examples: {'rewards_train/chosen': '0.5083', 'rewards_train/rejected': '-6.4563', 'rewards_train/margins': '7.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2182', 'examples_per_second': '6.4631', 'grad_norm': '4.8125', 'counters/examples': 175680, 'counters/updates': 10980}
skipping logging after 175696 examples to avoid logging too frequently
skipping logging after 175712 examples to avoid logging too frequently
skipping logging after 175728 examples to avoid logging too frequently
train stats after 175744 examples: {'rewards_train/chosen': '0.2705', 'rewards_train/rejected': '-6.5249', 'rewards_train/margins': '6.9141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25769', 'examples_per_second': '6.3', 'grad_norm': '5.0625', 'counters/examples': 175744, 'counters/updates': 10984}
skipping logging after 175760 examples to avoid logging too frequently
skipping logging after 175776 examples to avoid logging too frequently
skipping logging after 175792 examples to avoid logging too frequently
train stats after 175808 examples: {'rewards_train/chosen': '0.41357', 'rewards_train/rejected': '-6.9875', 'rewards_train/margins': '6.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21466', 'examples_per_second': '4.6586', 'grad_norm': '4.9062', 'counters/examples': 175808, 'counters/updates': 10988}
skipping logging after 175824 examples to avoid logging too frequently
skipping logging after 175840 examples to avoid logging too frequently
skipping logging after 175856 examples to avoid logging too frequently
train stats after 175872 examples: {'rewards_train/chosen': '0.33223', 'rewards_train/rejected': '-5.2661', 'rewards_train/margins': '5.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23309', 'examples_per_second': '4.3102', 'grad_norm': '4.6875', 'counters/examples': 175872, 'counters/updates': 10992}
skipping logging after 175888 examples to avoid logging too frequently
skipping logging after 175904 examples to avoid logging too frequently
skipping logging after 175920 examples to avoid logging too frequently
train stats after 175936 examples: {'rewards_train/chosen': '0.41571', 'rewards_train/rejected': '-5.2323', 'rewards_train/margins': '5.4141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27844', 'examples_per_second': '5.7776', 'grad_norm': '5.25', 'counters/examples': 175936, 'counters/updates': 10996}
skipping logging after 175952 examples to avoid logging too frequently
skipping logging after 175968 examples to avoid logging too frequently
skipping logging after 175984 examples to avoid logging too frequently
train stats after 176000 examples: {'rewards_train/chosen': '0.6095', 'rewards_train/rejected': '-4.6297', 'rewards_train/margins': '5.5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24915', 'examples_per_second': '5.0148', 'grad_norm': '4.5625', 'counters/examples': 176000, 'counters/updates': 11000}
Running evaluation after 176000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.25s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.16s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:39,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.65s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.47s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:33,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.51s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:33,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.40s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:30,  1.47s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.22s/it]Computing eval metrics:  50%|█████     | 16/32 [00:21<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.31s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.18s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.12s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]
eval after 176000: {'rewards_eval/chosen': '-5.6727', 'rewards_eval/rejected': '-6.2029', 'rewards_eval/margins': '0.37158', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.45956'}
skipping logging after 176016 examples to avoid logging too frequently
skipping logging after 176032 examples to avoid logging too frequently
skipping logging after 176048 examples to avoid logging too frequently
train stats after 176064 examples: {'rewards_train/chosen': '0.46956', 'rewards_train/rejected': '-7.0096', 'rewards_train/margins': '7.1875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22827', 'examples_per_second': '5.2194', 'grad_norm': '4.8125', 'counters/examples': 176064, 'counters/updates': 11004}
skipping logging after 176080 examples to avoid logging too frequently
skipping logging after 176096 examples to avoid logging too frequently
skipping logging after 176112 examples to avoid logging too frequently
train stats after 176128 examples: {'rewards_train/chosen': '0.35811', 'rewards_train/rejected': '-5.9039', 'rewards_train/margins': '6.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2099', 'examples_per_second': '4.7747', 'grad_norm': '5.2188', 'counters/examples': 176128, 'counters/updates': 11008}
skipping logging after 176144 examples to avoid logging too frequently
skipping logging after 176160 examples to avoid logging too frequently
skipping logging after 176176 examples to avoid logging too frequently
train stats after 176192 examples: {'rewards_train/chosen': '0.21747', 'rewards_train/rejected': '-7.04', 'rewards_train/margins': '6.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24927', 'examples_per_second': '4.893', 'grad_norm': '4.7188', 'counters/examples': 176192, 'counters/updates': 11012}
skipping logging after 176208 examples to avoid logging too frequently
skipping logging after 176224 examples to avoid logging too frequently
skipping logging after 176240 examples to avoid logging too frequently
train stats after 176256 examples: {'rewards_train/chosen': '0.16745', 'rewards_train/rejected': '-4.6452', 'rewards_train/margins': '4.7305', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28949', 'examples_per_second': '5.037', 'grad_norm': '6.3125', 'counters/examples': 176256, 'counters/updates': 11016}
skipping logging after 176272 examples to avoid logging too frequently
skipping logging after 176288 examples to avoid logging too frequently
skipping logging after 176304 examples to avoid logging too frequently
train stats after 176320 examples: {'rewards_train/chosen': '0.40076', 'rewards_train/rejected': '-4.1429', 'rewards_train/margins': '4.2383', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25958', 'examples_per_second': '5.0695', 'grad_norm': '5.7812', 'counters/examples': 176320, 'counters/updates': 11020}
skipping logging after 176336 examples to avoid logging too frequently
skipping logging after 176352 examples to avoid logging too frequently
skipping logging after 176368 examples to avoid logging too frequently
train stats after 176384 examples: {'rewards_train/chosen': '0.49436', 'rewards_train/rejected': '-6.4483', 'rewards_train/margins': '6.9375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21014', 'examples_per_second': '5.5323', 'grad_norm': '4.1562', 'counters/examples': 176384, 'counters/updates': 11024}
skipping logging after 176400 examples to avoid logging too frequently
skipping logging after 176416 examples to avoid logging too frequently
skipping logging after 176432 examples to avoid logging too frequently
train stats after 176448 examples: {'rewards_train/chosen': '0.18984', 'rewards_train/rejected': '-6.0802', 'rewards_train/margins': '5.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29498', 'examples_per_second': '6.0342', 'grad_norm': '5.8125', 'counters/examples': 176448, 'counters/updates': 11028}
skipping logging after 176464 examples to avoid logging too frequently
skipping logging after 176480 examples to avoid logging too frequently
skipping logging after 176496 examples to avoid logging too frequently
train stats after 176512 examples: {'rewards_train/chosen': '0.48793', 'rewards_train/rejected': '-5.7136', 'rewards_train/margins': '5.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25427', 'examples_per_second': '4.6721', 'grad_norm': '5.1875', 'counters/examples': 176512, 'counters/updates': 11032}
skipping logging after 176528 examples to avoid logging too frequently
skipping logging after 176544 examples to avoid logging too frequently
skipping logging after 176560 examples to avoid logging too frequently
train stats after 176576 examples: {'rewards_train/chosen': '0.70281', 'rewards_train/rejected': '-6.3859', 'rewards_train/margins': '6.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.13843', 'examples_per_second': '4.3635', 'grad_norm': '4.2188', 'counters/examples': 176576, 'counters/updates': 11036}
skipping logging after 176592 examples to avoid logging too frequently
skipping logging after 176608 examples to avoid logging too frequently
skipping logging after 176624 examples to avoid logging too frequently
train stats after 176640 examples: {'rewards_train/chosen': '0.52152', 'rewards_train/rejected': '-5.8836', 'rewards_train/margins': '6.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24622', 'examples_per_second': '5.4044', 'grad_norm': '5.25', 'counters/examples': 176640, 'counters/updates': 11040}
skipping logging after 176656 examples to avoid logging too frequently
skipping logging after 176672 examples to avoid logging too frequently
skipping logging after 176688 examples to avoid logging too frequently
train stats after 176704 examples: {'rewards_train/chosen': '0.41618', 'rewards_train/rejected': '-5.6953', 'rewards_train/margins': '6.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20563', 'examples_per_second': '5.3106', 'grad_norm': '5.1562', 'counters/examples': 176704, 'counters/updates': 11044}
skipping logging after 176720 examples to avoid logging too frequently
skipping logging after 176736 examples to avoid logging too frequently
skipping logging after 176752 examples to avoid logging too frequently
train stats after 176768 examples: {'rewards_train/chosen': '0.28405', 'rewards_train/rejected': '-6.5425', 'rewards_train/margins': '6.7422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2085', 'examples_per_second': '5.1621', 'grad_norm': '5.0312', 'counters/examples': 176768, 'counters/updates': 11048}
skipping logging after 176784 examples to avoid logging too frequently
skipping logging after 176800 examples to avoid logging too frequently
skipping logging after 176816 examples to avoid logging too frequently
train stats after 176832 examples: {'rewards_train/chosen': '0.35924', 'rewards_train/rejected': '-6.9698', 'rewards_train/margins': '7.1719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22418', 'examples_per_second': '4.5505', 'grad_norm': '4.8438', 'counters/examples': 176832, 'counters/updates': 11052}
skipping logging after 176848 examples to avoid logging too frequently
skipping logging after 176864 examples to avoid logging too frequently
skipping logging after 176880 examples to avoid logging too frequently
train stats after 176896 examples: {'rewards_train/chosen': '0.18906', 'rewards_train/rejected': '-5.5335', 'rewards_train/margins': '5.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21173', 'examples_per_second': '5.1829', 'grad_norm': '4.6562', 'counters/examples': 176896, 'counters/updates': 11056}
skipping logging after 176912 examples to avoid logging too frequently
skipping logging after 176928 examples to avoid logging too frequently
skipping logging after 176944 examples to avoid logging too frequently
train stats after 176960 examples: {'rewards_train/chosen': '0.38893', 'rewards_train/rejected': '-5.9944', 'rewards_train/margins': '6.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22247', 'examples_per_second': '5.2494', 'grad_norm': '5.5', 'counters/examples': 176960, 'counters/updates': 11060}
skipping logging after 176976 examples to avoid logging too frequently
skipping logging after 176992 examples to avoid logging too frequently
skipping logging after 177008 examples to avoid logging too frequently
train stats after 177024 examples: {'rewards_train/chosen': '0.35599', 'rewards_train/rejected': '-6.7294', 'rewards_train/margins': '6.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27625', 'examples_per_second': '5.2516', 'grad_norm': '4.5625', 'counters/examples': 177024, 'counters/updates': 11064}
skipping logging after 177040 examples to avoid logging too frequently
skipping logging after 177056 examples to avoid logging too frequently
skipping logging after 177072 examples to avoid logging too frequently
train stats after 177088 examples: {'rewards_train/chosen': '0.47984', 'rewards_train/rejected': '-5.8952', 'rewards_train/margins': '5.9492', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22662', 'examples_per_second': '4.5685', 'grad_norm': '5.2188', 'counters/examples': 177088, 'counters/updates': 11068}
skipping logging after 177104 examples to avoid logging too frequently
skipping logging after 177120 examples to avoid logging too frequently
skipping logging after 177136 examples to avoid logging too frequently
train stats after 177152 examples: {'rewards_train/chosen': '0.47239', 'rewards_train/rejected': '-5.4673', 'rewards_train/margins': '6.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2514', 'examples_per_second': '4.8893', 'grad_norm': '5.375', 'counters/examples': 177152, 'counters/updates': 11072}
skipping logging after 177168 examples to avoid logging too frequently
skipping logging after 177184 examples to avoid logging too frequently
skipping logging after 177200 examples to avoid logging too frequently
train stats after 177216 examples: {'rewards_train/chosen': '0.25574', 'rewards_train/rejected': '-5.2792', 'rewards_train/margins': '5.6211', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23926', 'examples_per_second': '4.9154', 'grad_norm': '4.3438', 'counters/examples': 177216, 'counters/updates': 11076}
skipping logging after 177232 examples to avoid logging too frequently
skipping logging after 177248 examples to avoid logging too frequently
skipping logging after 177264 examples to avoid logging too frequently
train stats after 177280 examples: {'rewards_train/chosen': '0.35161', 'rewards_train/rejected': '-6.0981', 'rewards_train/margins': '6.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25391', 'examples_per_second': '5.9625', 'grad_norm': '4.9375', 'counters/examples': 177280, 'counters/updates': 11080}
skipping logging after 177296 examples to avoid logging too frequently
skipping logging after 177312 examples to avoid logging too frequently
skipping logging after 177328 examples to avoid logging too frequently
train stats after 177344 examples: {'rewards_train/chosen': '0.17433', 'rewards_train/rejected': '-6.2434', 'rewards_train/margins': '6.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28278', 'examples_per_second': '4.7496', 'grad_norm': '5.25', 'counters/examples': 177344, 'counters/updates': 11084}
skipping logging after 177360 examples to avoid logging too frequently
skipping logging after 177376 examples to avoid logging too frequently
skipping logging after 177392 examples to avoid logging too frequently
train stats after 177408 examples: {'rewards_train/chosen': '0.29905', 'rewards_train/rejected': '-5.923', 'rewards_train/margins': '6.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2121', 'examples_per_second': '5.1066', 'grad_norm': '4.9688', 'counters/examples': 177408, 'counters/updates': 11088}
skipping logging after 177424 examples to avoid logging too frequently
skipping logging after 177440 examples to avoid logging too frequently
skipping logging after 177456 examples to avoid logging too frequently
train stats after 177472 examples: {'rewards_train/chosen': '0.63196', 'rewards_train/rejected': '-6.0151', 'rewards_train/margins': '6.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20636', 'examples_per_second': '5.6815', 'grad_norm': '4.9375', 'counters/examples': 177472, 'counters/updates': 11092}
skipping logging after 177488 examples to avoid logging too frequently
skipping logging after 177504 examples to avoid logging too frequently
skipping logging after 177520 examples to avoid logging too frequently
train stats after 177536 examples: {'rewards_train/chosen': '0.44599', 'rewards_train/rejected': '-4.8478', 'rewards_train/margins': '5.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22223', 'examples_per_second': '4.8122', 'grad_norm': '4.625', 'counters/examples': 177536, 'counters/updates': 11096}
skipping logging after 177552 examples to avoid logging too frequently
skipping logging after 177568 examples to avoid logging too frequently
skipping logging after 177584 examples to avoid logging too frequently
train stats after 177600 examples: {'rewards_train/chosen': '0.34844', 'rewards_train/rejected': '-5.4375', 'rewards_train/margins': '5.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25037', 'examples_per_second': '4.9812', 'grad_norm': '5.6562', 'counters/examples': 177600, 'counters/updates': 11100}
skipping logging after 177616 examples to avoid logging too frequently
skipping logging after 177632 examples to avoid logging too frequently
skipping logging after 177648 examples to avoid logging too frequently
train stats after 177664 examples: {'rewards_train/chosen': '0.37141', 'rewards_train/rejected': '-4.9845', 'rewards_train/margins': '5.3828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20679', 'examples_per_second': '5.2843', 'grad_norm': '5.4375', 'counters/examples': 177664, 'counters/updates': 11104}
skipping logging after 177680 examples to avoid logging too frequently
skipping logging after 177696 examples to avoid logging too frequently
skipping logging after 177712 examples to avoid logging too frequently
train stats after 177728 examples: {'rewards_train/chosen': '0.28089', 'rewards_train/rejected': '-6.4234', 'rewards_train/margins': '7.0547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.31012', 'examples_per_second': '4.342', 'grad_norm': '6', 'counters/examples': 177728, 'counters/updates': 11108}
skipping logging after 177744 examples to avoid logging too frequently
skipping logging after 177760 examples to avoid logging too frequently
skipping logging after 177776 examples to avoid logging too frequently
train stats after 177792 examples: {'rewards_train/chosen': '0.47064', 'rewards_train/rejected': '-4.8446', 'rewards_train/margins': '5.6562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21686', 'examples_per_second': '6.3406', 'grad_norm': '5.4062', 'counters/examples': 177792, 'counters/updates': 11112}
skipping logging after 177808 examples to avoid logging too frequently
skipping logging after 177824 examples to avoid logging too frequently
skipping logging after 177840 examples to avoid logging too frequently
train stats after 177856 examples: {'rewards_train/chosen': '0.16684', 'rewards_train/rejected': '-6.3086', 'rewards_train/margins': '6.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23761', 'examples_per_second': '4.1363', 'grad_norm': '4.5312', 'counters/examples': 177856, 'counters/updates': 11116}
skipping logging after 177872 examples to avoid logging too frequently
skipping logging after 177888 examples to avoid logging too frequently
skipping logging after 177904 examples to avoid logging too frequently
train stats after 177920 examples: {'rewards_train/chosen': '0.21795', 'rewards_train/rejected': '-6.1044', 'rewards_train/margins': '5.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26959', 'examples_per_second': '5.6157', 'grad_norm': '5.7188', 'counters/examples': 177920, 'counters/updates': 11120}
skipping logging after 177936 examples to avoid logging too frequently
skipping logging after 177952 examples to avoid logging too frequently
skipping logging after 177968 examples to avoid logging too frequently
train stats after 177984 examples: {'rewards_train/chosen': '0.41658', 'rewards_train/rejected': '-5.4363', 'rewards_train/margins': '6.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25006', 'examples_per_second': '4.9708', 'grad_norm': '5.5', 'counters/examples': 177984, 'counters/updates': 11124}
skipping logging after 178000 examples to avoid logging too frequently
skipping logging after 178016 examples to avoid logging too frequently
skipping logging after 178032 examples to avoid logging too frequently
train stats after 178048 examples: {'rewards_train/chosen': '0.46871', 'rewards_train/rejected': '-4.5837', 'rewards_train/margins': '5.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23944', 'examples_per_second': '6.2811', 'grad_norm': '5.6562', 'counters/examples': 178048, 'counters/updates': 11128}
skipping logging after 178064 examples to avoid logging too frequently
skipping logging after 178080 examples to avoid logging too frequently
skipping logging after 178096 examples to avoid logging too frequently
train stats after 178112 examples: {'rewards_train/chosen': '0.37367', 'rewards_train/rejected': '-7.8187', 'rewards_train/margins': '8.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23224', 'examples_per_second': '4.7983', 'grad_norm': '5.3438', 'counters/examples': 178112, 'counters/updates': 11132}
skipping logging after 178128 examples to avoid logging too frequently
skipping logging after 178144 examples to avoid logging too frequently
skipping logging after 178160 examples to avoid logging too frequently
train stats after 178176 examples: {'rewards_train/chosen': '0.38669', 'rewards_train/rejected': '-6.6904', 'rewards_train/margins': '7.4219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26605', 'examples_per_second': '7.149', 'grad_norm': '4.6875', 'counters/examples': 178176, 'counters/updates': 11136}
skipping logging after 178192 examples to avoid logging too frequently
skipping logging after 178208 examples to avoid logging too frequently
skipping logging after 178224 examples to avoid logging too frequently
train stats after 178240 examples: {'rewards_train/chosen': '0.32462', 'rewards_train/rejected': '-5.8139', 'rewards_train/margins': '6.3203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2597', 'examples_per_second': '5.0963', 'grad_norm': '4.0625', 'counters/examples': 178240, 'counters/updates': 11140}
skipping logging after 178256 examples to avoid logging too frequently
skipping logging after 178272 examples to avoid logging too frequently
skipping logging after 178288 examples to avoid logging too frequently
train stats after 178304 examples: {'rewards_train/chosen': '0.39771', 'rewards_train/rejected': '-7.2317', 'rewards_train/margins': '7.9766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21399', 'examples_per_second': '4.2371', 'grad_norm': '5.7812', 'counters/examples': 178304, 'counters/updates': 11144}
skipping logging after 178320 examples to avoid logging too frequently
skipping logging after 178336 examples to avoid logging too frequently
skipping logging after 178352 examples to avoid logging too frequently
train stats after 178368 examples: {'rewards_train/chosen': '0.023138', 'rewards_train/rejected': '-5.2425', 'rewards_train/margins': '5.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24402', 'examples_per_second': '5.8911', 'grad_norm': '5.375', 'counters/examples': 178368, 'counters/updates': 11148}
skipping logging after 178384 examples to avoid logging too frequently
skipping logging after 178400 examples to avoid logging too frequently
skipping logging after 178416 examples to avoid logging too frequently
train stats after 178432 examples: {'rewards_train/chosen': '0.30516', 'rewards_train/rejected': '-5.5533', 'rewards_train/margins': '5.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28571', 'examples_per_second': '5.4319', 'grad_norm': '5.4062', 'counters/examples': 178432, 'counters/updates': 11152}
skipping logging after 178448 examples to avoid logging too frequently
skipping logging after 178464 examples to avoid logging too frequently
skipping logging after 178480 examples to avoid logging too frequently
train stats after 178496 examples: {'rewards_train/chosen': '0.65957', 'rewards_train/rejected': '-6.6181', 'rewards_train/margins': '7.6328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20587', 'examples_per_second': '4.7603', 'grad_norm': '4.5938', 'counters/examples': 178496, 'counters/updates': 11156}
skipping logging after 178512 examples to avoid logging too frequently
skipping logging after 178528 examples to avoid logging too frequently
skipping logging after 178544 examples to avoid logging too frequently
train stats after 178560 examples: {'rewards_train/chosen': '0.55848', 'rewards_train/rejected': '-6.639', 'rewards_train/margins': '7.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23889', 'examples_per_second': '5.6075', 'grad_norm': '4.4062', 'counters/examples': 178560, 'counters/updates': 11160}
skipping logging after 178576 examples to avoid logging too frequently
skipping logging after 178592 examples to avoid logging too frequently
skipping logging after 178608 examples to avoid logging too frequently
train stats after 178624 examples: {'rewards_train/chosen': '0.93244', 'rewards_train/rejected': '-5.3421', 'rewards_train/margins': '6.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17548', 'examples_per_second': '4.0543', 'grad_norm': '4.25', 'counters/examples': 178624, 'counters/updates': 11164}
skipping logging after 178640 examples to avoid logging too frequently
skipping logging after 178656 examples to avoid logging too frequently
skipping logging after 178672 examples to avoid logging too frequently
train stats after 178688 examples: {'rewards_train/chosen': '0.82458', 'rewards_train/rejected': '-6.9429', 'rewards_train/margins': '8.3203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19965', 'examples_per_second': '5.3504', 'grad_norm': '5.0938', 'counters/examples': 178688, 'counters/updates': 11168}
skipping logging after 178704 examples to avoid logging too frequently
skipping logging after 178720 examples to avoid logging too frequently
skipping logging after 178736 examples to avoid logging too frequently
train stats after 178752 examples: {'rewards_train/chosen': '0.080895', 'rewards_train/rejected': '-6.551', 'rewards_train/margins': '6.6875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22522', 'examples_per_second': '5.5404', 'grad_norm': '5.6875', 'counters/examples': 178752, 'counters/updates': 11172}
skipping logging after 178768 examples to avoid logging too frequently
skipping logging after 178784 examples to avoid logging too frequently
skipping logging after 178800 examples to avoid logging too frequently
train stats after 178816 examples: {'rewards_train/chosen': '0.52576', 'rewards_train/rejected': '-6.4127', 'rewards_train/margins': '6.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20526', 'examples_per_second': '4.1025', 'grad_norm': '4.4375', 'counters/examples': 178816, 'counters/updates': 11176}
skipping logging after 178832 examples to avoid logging too frequently
skipping logging after 178848 examples to avoid logging too frequently
skipping logging after 178864 examples to avoid logging too frequently
train stats after 178880 examples: {'rewards_train/chosen': '0.34735', 'rewards_train/rejected': '-5.2793', 'rewards_train/margins': '5.4609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25238', 'examples_per_second': '5.1482', 'grad_norm': '4.75', 'counters/examples': 178880, 'counters/updates': 11180}
skipping logging after 178896 examples to avoid logging too frequently
skipping logging after 178912 examples to avoid logging too frequently
skipping logging after 178928 examples to avoid logging too frequently
train stats after 178944 examples: {'rewards_train/chosen': '0.3734', 'rewards_train/rejected': '-5.6447', 'rewards_train/margins': '5.7422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26825', 'examples_per_second': '6.3739', 'grad_norm': '5', 'counters/examples': 178944, 'counters/updates': 11184}
skipping logging after 178960 examples to avoid logging too frequently
skipping logging after 178976 examples to avoid logging too frequently
skipping logging after 178992 examples to avoid logging too frequently
train stats after 179008 examples: {'rewards_train/chosen': '0.28735', 'rewards_train/rejected': '-5.8301', 'rewards_train/margins': '6.125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24585', 'examples_per_second': '6.0858', 'grad_norm': '5.5625', 'counters/examples': 179008, 'counters/updates': 11188}
skipping logging after 179024 examples to avoid logging too frequently
skipping logging after 179040 examples to avoid logging too frequently
skipping logging after 179056 examples to avoid logging too frequently
train stats after 179072 examples: {'rewards_train/chosen': '0.26959', 'rewards_train/rejected': '-7.6057', 'rewards_train/margins': '8.1406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2326', 'examples_per_second': '4.5837', 'grad_norm': '5.0938', 'counters/examples': 179072, 'counters/updates': 11192}
skipping logging after 179088 examples to avoid logging too frequently
skipping logging after 179104 examples to avoid logging too frequently
skipping logging after 179120 examples to avoid logging too frequently
train stats after 179136 examples: {'rewards_train/chosen': '0.38039', 'rewards_train/rejected': '-5.3227', 'rewards_train/margins': '6.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26648', 'examples_per_second': '5.2048', 'grad_norm': '5', 'counters/examples': 179136, 'counters/updates': 11196}
skipping logging after 179152 examples to avoid logging too frequently
skipping logging after 179168 examples to avoid logging too frequently
skipping logging after 179184 examples to avoid logging too frequently
train stats after 179200 examples: {'rewards_train/chosen': '0.020336', 'rewards_train/rejected': '-5.3033', 'rewards_train/margins': '5.2148', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23755', 'examples_per_second': '5.1487', 'grad_norm': '4.6875', 'counters/examples': 179200, 'counters/updates': 11200}
skipping logging after 179216 examples to avoid logging too frequently
skipping logging after 179232 examples to avoid logging too frequently
skipping logging after 179248 examples to avoid logging too frequently
train stats after 179264 examples: {'rewards_train/chosen': '0.39849', 'rewards_train/rejected': '-5.7616', 'rewards_train/margins': '6.0742', 'rewards_train/KL_estimate': '0', 'loss/train': '0.216', 'examples_per_second': '5.7264', 'grad_norm': '4.5625', 'counters/examples': 179264, 'counters/updates': 11204}
skipping logging after 179280 examples to avoid logging too frequently
skipping logging after 179296 examples to avoid logging too frequently
skipping logging after 179312 examples to avoid logging too frequently
train stats after 179328 examples: {'rewards_train/chosen': '0.33518', 'rewards_train/rejected': '-5.9032', 'rewards_train/margins': '6.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24084', 'examples_per_second': '5.874', 'grad_norm': '5.25', 'counters/examples': 179328, 'counters/updates': 11208}
skipping logging after 179344 examples to avoid logging too frequently
skipping logging after 179360 examples to avoid logging too frequently
skipping logging after 179376 examples to avoid logging too frequently
train stats after 179392 examples: {'rewards_train/chosen': '0.50578', 'rewards_train/rejected': '-5.1572', 'rewards_train/margins': '5.7266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21942', 'examples_per_second': '4.7139', 'grad_norm': '4.9375', 'counters/examples': 179392, 'counters/updates': 11212}
skipping logging after 179408 examples to avoid logging too frequently
skipping logging after 179424 examples to avoid logging too frequently
skipping logging after 179440 examples to avoid logging too frequently
train stats after 179456 examples: {'rewards_train/chosen': '0.40295', 'rewards_train/rejected': '-6.1554', 'rewards_train/margins': '6.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18927', 'examples_per_second': '4.8885', 'grad_norm': '5.0312', 'counters/examples': 179456, 'counters/updates': 11216}
skipping logging after 179472 examples to avoid logging too frequently
skipping logging after 179488 examples to avoid logging too frequently
skipping logging after 179504 examples to avoid logging too frequently
train stats after 179520 examples: {'rewards_train/chosen': '0.5141', 'rewards_train/rejected': '-6.2577', 'rewards_train/margins': '6.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19269', 'examples_per_second': '4.6957', 'grad_norm': '4.125', 'counters/examples': 179520, 'counters/updates': 11220}
skipping logging after 179536 examples to avoid logging too frequently
skipping logging after 179552 examples to avoid logging too frequently
skipping logging after 179568 examples to avoid logging too frequently
train stats after 179584 examples: {'rewards_train/chosen': '0.54203', 'rewards_train/rejected': '-6.0098', 'rewards_train/margins': '6.2461', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21857', 'examples_per_second': '5.2548', 'grad_norm': '4.75', 'counters/examples': 179584, 'counters/updates': 11224}
skipping logging after 179600 examples to avoid logging too frequently
skipping logging after 179616 examples to avoid logging too frequently
skipping logging after 179632 examples to avoid logging too frequently
train stats after 179648 examples: {'rewards_train/chosen': '0.39036', 'rewards_train/rejected': '-5.8531', 'rewards_train/margins': '6.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25616', 'examples_per_second': '4.8637', 'grad_norm': '5.375', 'counters/examples': 179648, 'counters/updates': 11228}
skipping logging after 179664 examples to avoid logging too frequently
skipping logging after 179680 examples to avoid logging too frequently
skipping logging after 179696 examples to avoid logging too frequently
train stats after 179712 examples: {'rewards_train/chosen': '0.29451', 'rewards_train/rejected': '-5.8609', 'rewards_train/margins': '6.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22925', 'examples_per_second': '4.6125', 'grad_norm': '4.875', 'counters/examples': 179712, 'counters/updates': 11232}
skipping logging after 179728 examples to avoid logging too frequently
skipping logging after 179744 examples to avoid logging too frequently
skipping logging after 179760 examples to avoid logging too frequently
train stats after 179776 examples: {'rewards_train/chosen': '0.26551', 'rewards_train/rejected': '-7.4541', 'rewards_train/margins': '7.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26245', 'examples_per_second': '5.1241', 'grad_norm': '5.0938', 'counters/examples': 179776, 'counters/updates': 11236}
skipping logging after 179792 examples to avoid logging too frequently
skipping logging after 179808 examples to avoid logging too frequently
skipping logging after 179824 examples to avoid logging too frequently
train stats after 179840 examples: {'rewards_train/chosen': '0.42227', 'rewards_train/rejected': '-4.3383', 'rewards_train/margins': '4.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25', 'examples_per_second': '5.3986', 'grad_norm': '5.0312', 'counters/examples': 179840, 'counters/updates': 11240}
skipping logging after 179856 examples to avoid logging too frequently
skipping logging after 179872 examples to avoid logging too frequently
skipping logging after 179888 examples to avoid logging too frequently
train stats after 179904 examples: {'rewards_train/chosen': '0.2485', 'rewards_train/rejected': '-5.8024', 'rewards_train/margins': '5.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26477', 'examples_per_second': '5.8809', 'grad_norm': '5.7812', 'counters/examples': 179904, 'counters/updates': 11244}
skipping logging after 179920 examples to avoid logging too frequently
skipping logging after 179936 examples to avoid logging too frequently
skipping logging after 179952 examples to avoid logging too frequently
train stats after 179968 examples: {'rewards_train/chosen': '0.60923', 'rewards_train/rejected': '-5.8786', 'rewards_train/margins': '6.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23712', 'examples_per_second': '4.4759', 'grad_norm': '4.4062', 'counters/examples': 179968, 'counters/updates': 11248}
skipping logging after 179984 examples to avoid logging too frequently
skipping logging after 180000 examples to avoid logging too frequently
Running evaluation after 180000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:51,  1.67s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:42,  1.43s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:36,  1.26s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.49s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.69s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.49s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:10<00:34,  1.37s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:20<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:21<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.28s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:28<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.51s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.20s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:40<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:41<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]
eval after 180000: {'rewards_eval/chosen': '-5.5001', 'rewards_eval/rejected': '-6.1236', 'rewards_eval/margins': '0.48438', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.45937'}
skipping logging after 180016 examples to avoid logging too frequently
train stats after 180032 examples: {'rewards_train/chosen': '0.50104', 'rewards_train/rejected': '-5.093', 'rewards_train/margins': '5.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2301', 'examples_per_second': '5.7241', 'grad_norm': '4.8125', 'counters/examples': 180032, 'counters/updates': 11252}
skipping logging after 180048 examples to avoid logging too frequently
skipping logging after 180064 examples to avoid logging too frequently
skipping logging after 180080 examples to avoid logging too frequently
train stats after 180096 examples: {'rewards_train/chosen': '0.19651', 'rewards_train/rejected': '-6.7091', 'rewards_train/margins': '6.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28625', 'examples_per_second': '4.0605', 'grad_norm': '5.4375', 'counters/examples': 180096, 'counters/updates': 11256}
skipping logging after 180112 examples to avoid logging too frequently
skipping logging after 180128 examples to avoid logging too frequently
skipping logging after 180144 examples to avoid logging too frequently
train stats after 180160 examples: {'rewards_train/chosen': '0.31425', 'rewards_train/rejected': '-5.0945', 'rewards_train/margins': '5.4141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25024', 'examples_per_second': '5.0403', 'grad_norm': '5.4062', 'counters/examples': 180160, 'counters/updates': 11260}
skipping logging after 180176 examples to avoid logging too frequently
skipping logging after 180192 examples to avoid logging too frequently
skipping logging after 180208 examples to avoid logging too frequently
train stats after 180224 examples: {'rewards_train/chosen': '0.31328', 'rewards_train/rejected': '-5.2637', 'rewards_train/margins': '5.6094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20929', 'examples_per_second': '5.6232', 'grad_norm': '4.0312', 'counters/examples': 180224, 'counters/updates': 11264}
skipping logging after 180240 examples to avoid logging too frequently
skipping logging after 180256 examples to avoid logging too frequently
skipping logging after 180272 examples to avoid logging too frequently
train stats after 180288 examples: {'rewards_train/chosen': '0.43897', 'rewards_train/rejected': '-5.594', 'rewards_train/margins': '6.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24622', 'examples_per_second': '4.7505', 'grad_norm': '5.1875', 'counters/examples': 180288, 'counters/updates': 11268}
skipping logging after 180304 examples to avoid logging too frequently
skipping logging after 180320 examples to avoid logging too frequently
skipping logging after 180336 examples to avoid logging too frequently
train stats after 180352 examples: {'rewards_train/chosen': '0.44672', 'rewards_train/rejected': '-6.6013', 'rewards_train/margins': '6.8672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21484', 'examples_per_second': '5.4868', 'grad_norm': '5', 'counters/examples': 180352, 'counters/updates': 11272}
skipping logging after 180368 examples to avoid logging too frequently
skipping logging after 180384 examples to avoid logging too frequently
skipping logging after 180400 examples to avoid logging too frequently
train stats after 180416 examples: {'rewards_train/chosen': '-0.055664', 'rewards_train/rejected': '-6.8905', 'rewards_train/margins': '6.6562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22034', 'examples_per_second': '5.2555', 'grad_norm': '4.8438', 'counters/examples': 180416, 'counters/updates': 11276}
skipping logging after 180432 examples to avoid logging too frequently
skipping logging after 180448 examples to avoid logging too frequently
skipping logging after 180464 examples to avoid logging too frequently
train stats after 180480 examples: {'rewards_train/chosen': '-0.057529', 'rewards_train/rejected': '-4.9411', 'rewards_train/margins': '4.7734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27386', 'examples_per_second': '5.3883', 'grad_norm': '5.2188', 'counters/examples': 180480, 'counters/updates': 11280}
skipping logging after 180496 examples to avoid logging too frequently
skipping logging after 180512 examples to avoid logging too frequently
skipping logging after 180528 examples to avoid logging too frequently
train stats after 180544 examples: {'rewards_train/chosen': '0.6915', 'rewards_train/rejected': '-4.6952', 'rewards_train/margins': '5.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25714', 'examples_per_second': '4.8253', 'grad_norm': '5.3438', 'counters/examples': 180544, 'counters/updates': 11284}
skipping logging after 180560 examples to avoid logging too frequently
skipping logging after 180576 examples to avoid logging too frequently
skipping logging after 180592 examples to avoid logging too frequently
train stats after 180608 examples: {'rewards_train/chosen': '0.3195', 'rewards_train/rejected': '-8.215', 'rewards_train/margins': '8.2422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23206', 'examples_per_second': '4.5056', 'grad_norm': '5.4375', 'counters/examples': 180608, 'counters/updates': 11288}
skipping logging after 180624 examples to avoid logging too frequently
skipping logging after 180640 examples to avoid logging too frequently
skipping logging after 180656 examples to avoid logging too frequently
train stats after 180672 examples: {'rewards_train/chosen': '0.028535', 'rewards_train/rejected': '-6.3949', 'rewards_train/margins': '6.4844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25739', 'examples_per_second': '5.1434', 'grad_norm': '5.7812', 'counters/examples': 180672, 'counters/updates': 11292}
skipping logging after 180688 examples to avoid logging too frequently
skipping logging after 180704 examples to avoid logging too frequently
skipping logging after 180720 examples to avoid logging too frequently
train stats after 180736 examples: {'rewards_train/chosen': '-0.19081', 'rewards_train/rejected': '-6.5293', 'rewards_train/margins': '6.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30292', 'examples_per_second': '5.1997', 'grad_norm': '5.0938', 'counters/examples': 180736, 'counters/updates': 11296}
skipping logging after 180752 examples to avoid logging too frequently
skipping logging after 180768 examples to avoid logging too frequently
skipping logging after 180784 examples to avoid logging too frequently
train stats after 180800 examples: {'rewards_train/chosen': '0.28384', 'rewards_train/rejected': '-6.1522', 'rewards_train/margins': '6.5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22186', 'examples_per_second': '4.6067', 'grad_norm': '4.5938', 'counters/examples': 180800, 'counters/updates': 11300}
skipping logging after 180816 examples to avoid logging too frequently
skipping logging after 180832 examples to avoid logging too frequently
skipping logging after 180848 examples to avoid logging too frequently
train stats after 180864 examples: {'rewards_train/chosen': '0.35861', 'rewards_train/rejected': '-5.0286', 'rewards_train/margins': '5.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21234', 'examples_per_second': '4.9549', 'grad_norm': '4.4375', 'counters/examples': 180864, 'counters/updates': 11304}
skipping logging after 180880 examples to avoid logging too frequently
skipping logging after 180896 examples to avoid logging too frequently
skipping logging after 180912 examples to avoid logging too frequently
train stats after 180928 examples: {'rewards_train/chosen': '0.67061', 'rewards_train/rejected': '-4.6955', 'rewards_train/margins': '5.3477', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24036', 'examples_per_second': '5.0125', 'grad_norm': '4.7188', 'counters/examples': 180928, 'counters/updates': 11308}
skipping logging after 180944 examples to avoid logging too frequently
skipping logging after 180960 examples to avoid logging too frequently
skipping logging after 180976 examples to avoid logging too frequently
train stats after 180992 examples: {'rewards_train/chosen': '0.20595', 'rewards_train/rejected': '-6.0993', 'rewards_train/margins': '6.6289', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24255', 'examples_per_second': '5.4665', 'grad_norm': '4.5312', 'counters/examples': 180992, 'counters/updates': 11312}
skipping logging after 181008 examples to avoid logging too frequently
skipping logging after 181024 examples to avoid logging too frequently
skipping logging after 181040 examples to avoid logging too frequently
train stats after 181056 examples: {'rewards_train/chosen': '0.58216', 'rewards_train/rejected': '-5.6098', 'rewards_train/margins': '6.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20898', 'examples_per_second': '5.1068', 'grad_norm': '4.3438', 'counters/examples': 181056, 'counters/updates': 11316}
skipping logging after 181072 examples to avoid logging too frequently
skipping logging after 181088 examples to avoid logging too frequently
skipping logging after 181104 examples to avoid logging too frequently
train stats after 181120 examples: {'rewards_train/chosen': '0.16914', 'rewards_train/rejected': '-6.6206', 'rewards_train/margins': '6.6641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28003', 'examples_per_second': '5.5776', 'grad_norm': '5.2812', 'counters/examples': 181120, 'counters/updates': 11320}
skipping logging after 181136 examples to avoid logging too frequently
skipping logging after 181152 examples to avoid logging too frequently
skipping logging after 181168 examples to avoid logging too frequently
train stats after 181184 examples: {'rewards_train/chosen': '0.15643', 'rewards_train/rejected': '-5.6704', 'rewards_train/margins': '5.8555', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26898', 'examples_per_second': '6.1678', 'grad_norm': '4.7812', 'counters/examples': 181184, 'counters/updates': 11324}
skipping logging after 181200 examples to avoid logging too frequently
skipping logging after 181216 examples to avoid logging too frequently
skipping logging after 181232 examples to avoid logging too frequently
train stats after 181248 examples: {'rewards_train/chosen': '0.13212', 'rewards_train/rejected': '-5.7189', 'rewards_train/margins': '5.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23175', 'examples_per_second': '5.0564', 'grad_norm': '4.7188', 'counters/examples': 181248, 'counters/updates': 11328}
skipping logging after 181264 examples to avoid logging too frequently
skipping logging after 181280 examples to avoid logging too frequently
skipping logging after 181296 examples to avoid logging too frequently
train stats after 181312 examples: {'rewards_train/chosen': '0.37948', 'rewards_train/rejected': '-6.6672', 'rewards_train/margins': '7.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23199', 'examples_per_second': '5.8754', 'grad_norm': '4.7812', 'counters/examples': 181312, 'counters/updates': 11332}
skipping logging after 181328 examples to avoid logging too frequently
skipping logging after 181344 examples to avoid logging too frequently
skipping logging after 181360 examples to avoid logging too frequently
train stats after 181376 examples: {'rewards_train/chosen': '0.49945', 'rewards_train/rejected': '-6.207', 'rewards_train/margins': '6.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22015', 'examples_per_second': '5.1038', 'grad_norm': '5.3438', 'counters/examples': 181376, 'counters/updates': 11336}
skipping logging after 181392 examples to avoid logging too frequently
skipping logging after 181408 examples to avoid logging too frequently
skipping logging after 181424 examples to avoid logging too frequently
train stats after 181440 examples: {'rewards_train/chosen': '0.25728', 'rewards_train/rejected': '-6.6694', 'rewards_train/margins': '6.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23785', 'examples_per_second': '5.7587', 'grad_norm': '4.5938', 'counters/examples': 181440, 'counters/updates': 11340}
skipping logging after 181456 examples to avoid logging too frequently
skipping logging after 181472 examples to avoid logging too frequently
skipping logging after 181488 examples to avoid logging too frequently
train stats after 181504 examples: {'rewards_train/chosen': '0.31254', 'rewards_train/rejected': '-6.0453', 'rewards_train/margins': '6.4609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24969', 'examples_per_second': '5.7535', 'grad_norm': '5.125', 'counters/examples': 181504, 'counters/updates': 11344}
skipping logging after 181520 examples to avoid logging too frequently
skipping logging after 181536 examples to avoid logging too frequently
skipping logging after 181552 examples to avoid logging too frequently
train stats after 181568 examples: {'rewards_train/chosen': '0.50235', 'rewards_train/rejected': '-6.2471', 'rewards_train/margins': '6.7266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20874', 'examples_per_second': '6.1629', 'grad_norm': '5.4375', 'counters/examples': 181568, 'counters/updates': 11348}
skipping logging after 181584 examples to avoid logging too frequently
skipping logging after 181600 examples to avoid logging too frequently
skipping logging after 181616 examples to avoid logging too frequently
train stats after 181632 examples: {'rewards_train/chosen': '0.30318', 'rewards_train/rejected': '-6.7523', 'rewards_train/margins': '7.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2439', 'examples_per_second': '5.453', 'grad_norm': '5.0625', 'counters/examples': 181632, 'counters/updates': 11352}
skipping logging after 181648 examples to avoid logging too frequently
skipping logging after 181664 examples to avoid logging too frequently
skipping logging after 181680 examples to avoid logging too frequently
train stats after 181696 examples: {'rewards_train/chosen': '0.35857', 'rewards_train/rejected': '-5.0629', 'rewards_train/margins': '5.418', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25134', 'examples_per_second': '5.9347', 'grad_norm': '5.0625', 'counters/examples': 181696, 'counters/updates': 11356}
skipping logging after 181712 examples to avoid logging too frequently
skipping logging after 181728 examples to avoid logging too frequently
skipping logging after 181744 examples to avoid logging too frequently
train stats after 181760 examples: {'rewards_train/chosen': '0.034558', 'rewards_train/rejected': '-5.7226', 'rewards_train/margins': '5.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25659', 'examples_per_second': '4.1343', 'grad_norm': '6.2188', 'counters/examples': 181760, 'counters/updates': 11360}
skipping logging after 181776 examples to avoid logging too frequently
skipping logging after 181792 examples to avoid logging too frequently
skipping logging after 181808 examples to avoid logging too frequently
train stats after 181824 examples: {'rewards_train/chosen': '0.24117', 'rewards_train/rejected': '-6.2341', 'rewards_train/margins': '6.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24261', 'examples_per_second': '6.0491', 'grad_norm': '4.7812', 'counters/examples': 181824, 'counters/updates': 11364}
skipping logging after 181840 examples to avoid logging too frequently
skipping logging after 181856 examples to avoid logging too frequently
skipping logging after 181872 examples to avoid logging too frequently
train stats after 181888 examples: {'rewards_train/chosen': '0.35009', 'rewards_train/rejected': '-4.845', 'rewards_train/margins': '5.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23175', 'examples_per_second': '4.5901', 'grad_norm': '4.6562', 'counters/examples': 181888, 'counters/updates': 11368}
skipping logging after 181904 examples to avoid logging too frequently
skipping logging after 181920 examples to avoid logging too frequently
skipping logging after 181936 examples to avoid logging too frequently
train stats after 181952 examples: {'rewards_train/chosen': '0.33264', 'rewards_train/rejected': '-5.8568', 'rewards_train/margins': '6.5469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22443', 'examples_per_second': '4.8817', 'grad_norm': '4.4062', 'counters/examples': 181952, 'counters/updates': 11372}
skipping logging after 181968 examples to avoid logging too frequently
skipping logging after 181984 examples to avoid logging too frequently
skipping logging after 182000 examples to avoid logging too frequently
train stats after 182016 examples: {'rewards_train/chosen': '0.075043', 'rewards_train/rejected': '-5.368', 'rewards_train/margins': '5.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26819', 'examples_per_second': '5.2841', 'grad_norm': '5.1875', 'counters/examples': 182016, 'counters/updates': 11376}
skipping logging after 182032 examples to avoid logging too frequently
skipping logging after 182048 examples to avoid logging too frequently
skipping logging after 182064 examples to avoid logging too frequently
train stats after 182080 examples: {'rewards_train/chosen': '0.4096', 'rewards_train/rejected': '-5.6864', 'rewards_train/margins': '6.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23749', 'examples_per_second': '5.659', 'grad_norm': '5.5625', 'counters/examples': 182080, 'counters/updates': 11380}
skipping logging after 182096 examples to avoid logging too frequently
skipping logging after 182112 examples to avoid logging too frequently
skipping logging after 182128 examples to avoid logging too frequently
train stats after 182144 examples: {'rewards_train/chosen': '-0.17748', 'rewards_train/rejected': '-6.1052', 'rewards_train/margins': '6.1133', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23596', 'examples_per_second': '5.5712', 'grad_norm': '4.5', 'counters/examples': 182144, 'counters/updates': 11384}
skipping logging after 182160 examples to avoid logging too frequently
skipping logging after 182176 examples to avoid logging too frequently
skipping logging after 182192 examples to avoid logging too frequently
train stats after 182208 examples: {'rewards_train/chosen': '0.27897', 'rewards_train/rejected': '-4.3579', 'rewards_train/margins': '4.6016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28754', 'examples_per_second': '4.9753', 'grad_norm': '4.8438', 'counters/examples': 182208, 'counters/updates': 11388}
skipping logging after 182224 examples to avoid logging too frequently
skipping logging after 182240 examples to avoid logging too frequently
skipping logging after 182256 examples to avoid logging too frequently
train stats after 182272 examples: {'rewards_train/chosen': '0.024197', 'rewards_train/rejected': '-4.574', 'rewards_train/margins': '5.0195', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22388', 'examples_per_second': '5.8447', 'grad_norm': '4.375', 'counters/examples': 182272, 'counters/updates': 11392}
skipping logging after 182288 examples to avoid logging too frequently
skipping logging after 182304 examples to avoid logging too frequently
skipping logging after 182320 examples to avoid logging too frequently
train stats after 182336 examples: {'rewards_train/chosen': '0.028639', 'rewards_train/rejected': '-5.0604', 'rewards_train/margins': '5.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24927', 'examples_per_second': '4.9723', 'grad_norm': '4.9062', 'counters/examples': 182336, 'counters/updates': 11396}
skipping logging after 182352 examples to avoid logging too frequently
skipping logging after 182368 examples to avoid logging too frequently
skipping logging after 182384 examples to avoid logging too frequently
train stats after 182400 examples: {'rewards_train/chosen': '0.53586', 'rewards_train/rejected': '-6.1036', 'rewards_train/margins': '6.3555', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23987', 'examples_per_second': '5.6345', 'grad_norm': '6.25', 'counters/examples': 182400, 'counters/updates': 11400}
skipping logging after 182416 examples to avoid logging too frequently
skipping logging after 182432 examples to avoid logging too frequently
skipping logging after 182448 examples to avoid logging too frequently
train stats after 182464 examples: {'rewards_train/chosen': '0.27793', 'rewards_train/rejected': '-5.9283', 'rewards_train/margins': '6.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24078', 'examples_per_second': '4.4452', 'grad_norm': '4.7188', 'counters/examples': 182464, 'counters/updates': 11404}
skipping logging after 182480 examples to avoid logging too frequently
skipping logging after 182496 examples to avoid logging too frequently
skipping logging after 182512 examples to avoid logging too frequently
train stats after 182528 examples: {'rewards_train/chosen': '0.61128', 'rewards_train/rejected': '-5.9878', 'rewards_train/margins': '6.6094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2074', 'examples_per_second': '4.7131', 'grad_norm': '5.0625', 'counters/examples': 182528, 'counters/updates': 11408}
skipping logging after 182544 examples to avoid logging too frequently
skipping logging after 182560 examples to avoid logging too frequently
skipping logging after 182576 examples to avoid logging too frequently
train stats after 182592 examples: {'rewards_train/chosen': '0.55189', 'rewards_train/rejected': '-4.3339', 'rewards_train/margins': '4.8633', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21887', 'examples_per_second': '4.6362', 'grad_norm': '5.5', 'counters/examples': 182592, 'counters/updates': 11412}
skipping logging after 182608 examples to avoid logging too frequently
skipping logging after 182624 examples to avoid logging too frequently
skipping logging after 182640 examples to avoid logging too frequently
train stats after 182656 examples: {'rewards_train/chosen': '0.62997', 'rewards_train/rejected': '-6.1232', 'rewards_train/margins': '6.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20538', 'examples_per_second': '5.1492', 'grad_norm': '5.0312', 'counters/examples': 182656, 'counters/updates': 11416}
skipping logging after 182672 examples to avoid logging too frequently
skipping logging after 182688 examples to avoid logging too frequently
skipping logging after 182704 examples to avoid logging too frequently
train stats after 182720 examples: {'rewards_train/chosen': '-0.057345', 'rewards_train/rejected': '-5.2424', 'rewards_train/margins': '5.2344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23718', 'examples_per_second': '5.1722', 'grad_norm': '4.875', 'counters/examples': 182720, 'counters/updates': 11420}
skipping logging after 182736 examples to avoid logging too frequently
skipping logging after 182752 examples to avoid logging too frequently
skipping logging after 182768 examples to avoid logging too frequently
train stats after 182784 examples: {'rewards_train/chosen': '0.15004', 'rewards_train/rejected': '-6.0668', 'rewards_train/margins': '6.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26361', 'examples_per_second': '4.3756', 'grad_norm': '4.625', 'counters/examples': 182784, 'counters/updates': 11424}
skipping logging after 182800 examples to avoid logging too frequently
skipping logging after 182816 examples to avoid logging too frequently
skipping logging after 182832 examples to avoid logging too frequently
train stats after 182848 examples: {'rewards_train/chosen': '0.21147', 'rewards_train/rejected': '-5.9781', 'rewards_train/margins': '6.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24744', 'examples_per_second': '5.2825', 'grad_norm': '4.8125', 'counters/examples': 182848, 'counters/updates': 11428}
skipping logging after 182864 examples to avoid logging too frequently
skipping logging after 182880 examples to avoid logging too frequently
skipping logging after 182896 examples to avoid logging too frequently
train stats after 182912 examples: {'rewards_train/chosen': '0.39614', 'rewards_train/rejected': '-6.0183', 'rewards_train/margins': '6.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23773', 'examples_per_second': '5.2466', 'grad_norm': '5.3125', 'counters/examples': 182912, 'counters/updates': 11432}
skipping logging after 182928 examples to avoid logging too frequently
skipping logging after 182944 examples to avoid logging too frequently
skipping logging after 182960 examples to avoid logging too frequently
train stats after 182976 examples: {'rewards_train/chosen': '0.49003', 'rewards_train/rejected': '-5.9885', 'rewards_train/margins': '6.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23193', 'examples_per_second': '4.8149', 'grad_norm': '4.625', 'counters/examples': 182976, 'counters/updates': 11436}
skipping logging after 182992 examples to avoid logging too frequently
skipping logging after 183008 examples to avoid logging too frequently
skipping logging after 183024 examples to avoid logging too frequently
train stats after 183040 examples: {'rewards_train/chosen': '0.17937', 'rewards_train/rejected': '-6.503', 'rewards_train/margins': '6.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27234', 'examples_per_second': '5.506', 'grad_norm': '5.2812', 'counters/examples': 183040, 'counters/updates': 11440}
skipping logging after 183056 examples to avoid logging too frequently
skipping logging after 183072 examples to avoid logging too frequently
skipping logging after 183088 examples to avoid logging too frequently
train stats after 183104 examples: {'rewards_train/chosen': '0.20928', 'rewards_train/rejected': '-7.627', 'rewards_train/margins': '7.7422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20001', 'examples_per_second': '4.7287', 'grad_norm': '5.0312', 'counters/examples': 183104, 'counters/updates': 11444}
skipping logging after 183120 examples to avoid logging too frequently
skipping logging after 183136 examples to avoid logging too frequently
skipping logging after 183152 examples to avoid logging too frequently
train stats after 183168 examples: {'rewards_train/chosen': '0.38931', 'rewards_train/rejected': '-6.0919', 'rewards_train/margins': '6.2148', 'rewards_train/KL_estimate': '0', 'loss/train': '0.255', 'examples_per_second': '5.7496', 'grad_norm': '4.9688', 'counters/examples': 183168, 'counters/updates': 11448}
skipping logging after 183184 examples to avoid logging too frequently
skipping logging after 183200 examples to avoid logging too frequently
skipping logging after 183216 examples to avoid logging too frequently
train stats after 183232 examples: {'rewards_train/chosen': '0.58151', 'rewards_train/rejected': '-5.3355', 'rewards_train/margins': '5.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21332', 'examples_per_second': '4.6977', 'grad_norm': '5.0938', 'counters/examples': 183232, 'counters/updates': 11452}
skipping logging after 183248 examples to avoid logging too frequently
skipping logging after 183264 examples to avoid logging too frequently
skipping logging after 183280 examples to avoid logging too frequently
train stats after 183296 examples: {'rewards_train/chosen': '0.14952', 'rewards_train/rejected': '-5.4733', 'rewards_train/margins': '5.3281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19965', 'examples_per_second': '5.2629', 'grad_norm': '4.4062', 'counters/examples': 183296, 'counters/updates': 11456}
skipping logging after 183312 examples to avoid logging too frequently
skipping logging after 183328 examples to avoid logging too frequently
skipping logging after 183344 examples to avoid logging too frequently
train stats after 183360 examples: {'rewards_train/chosen': '0.72388', 'rewards_train/rejected': '-6.9976', 'rewards_train/margins': '7.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18921', 'examples_per_second': '5.0575', 'grad_norm': '4.7188', 'counters/examples': 183360, 'counters/updates': 11460}
skipping logging after 183376 examples to avoid logging too frequently
skipping logging after 183392 examples to avoid logging too frequently
skipping logging after 183408 examples to avoid logging too frequently
train stats after 183424 examples: {'rewards_train/chosen': '0.42939', 'rewards_train/rejected': '-7.6354', 'rewards_train/margins': '7.5938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21088', 'examples_per_second': '4.6772', 'grad_norm': '5.4062', 'counters/examples': 183424, 'counters/updates': 11464}
skipping logging after 183440 examples to avoid logging too frequently
skipping logging after 183456 examples to avoid logging too frequently
skipping logging after 183472 examples to avoid logging too frequently
train stats after 183488 examples: {'rewards_train/chosen': '0.19232', 'rewards_train/rejected': '-6.4978', 'rewards_train/margins': '6.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21729', 'examples_per_second': '5.6349', 'grad_norm': '5.125', 'counters/examples': 183488, 'counters/updates': 11468}
skipping logging after 183504 examples to avoid logging too frequently
skipping logging after 183520 examples to avoid logging too frequently
skipping logging after 183536 examples to avoid logging too frequently
train stats after 183552 examples: {'rewards_train/chosen': '0.2837', 'rewards_train/rejected': '-5.5102', 'rewards_train/margins': '5.7891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25317', 'examples_per_second': '5.8138', 'grad_norm': '6.0625', 'counters/examples': 183552, 'counters/updates': 11472}
skipping logging after 183568 examples to avoid logging too frequently
skipping logging after 183584 examples to avoid logging too frequently
skipping logging after 183600 examples to avoid logging too frequently
train stats after 183616 examples: {'rewards_train/chosen': '0.1179', 'rewards_train/rejected': '-5.4724', 'rewards_train/margins': '5.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30536', 'examples_per_second': '5.3158', 'grad_norm': '4.9375', 'counters/examples': 183616, 'counters/updates': 11476}
skipping logging after 183632 examples to avoid logging too frequently
skipping logging after 183648 examples to avoid logging too frequently
skipping logging after 183664 examples to avoid logging too frequently
train stats after 183680 examples: {'rewards_train/chosen': '0.23699', 'rewards_train/rejected': '-5.1151', 'rewards_train/margins': '5.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22827', 'examples_per_second': '4.6605', 'grad_norm': '4.9688', 'counters/examples': 183680, 'counters/updates': 11480}
skipping logging after 183696 examples to avoid logging too frequently
skipping logging after 183712 examples to avoid logging too frequently
skipping logging after 183728 examples to avoid logging too frequently
train stats after 183744 examples: {'rewards_train/chosen': '0.56993', 'rewards_train/rejected': '-7.6209', 'rewards_train/margins': '7.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.263', 'examples_per_second': '4.6629', 'grad_norm': '5.6875', 'counters/examples': 183744, 'counters/updates': 11484}
skipping logging after 183760 examples to avoid logging too frequently
skipping logging after 183776 examples to avoid logging too frequently
skipping logging after 183792 examples to avoid logging too frequently
train stats after 183808 examples: {'rewards_train/chosen': '-0.049618', 'rewards_train/rejected': '-6.4806', 'rewards_train/margins': '6.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26471', 'examples_per_second': '5.098', 'grad_norm': '4.5625', 'counters/examples': 183808, 'counters/updates': 11488}
skipping logging after 183824 examples to avoid logging too frequently
skipping logging after 183840 examples to avoid logging too frequently
skipping logging after 183856 examples to avoid logging too frequently
train stats after 183872 examples: {'rewards_train/chosen': '0.24036', 'rewards_train/rejected': '-6.5784', 'rewards_train/margins': '6.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28851', 'examples_per_second': '4.7918', 'grad_norm': '4.5312', 'counters/examples': 183872, 'counters/updates': 11492}
skipping logging after 183888 examples to avoid logging too frequently
skipping logging after 183904 examples to avoid logging too frequently
skipping logging after 183920 examples to avoid logging too frequently
train stats after 183936 examples: {'rewards_train/chosen': '0.51073', 'rewards_train/rejected': '-5.0406', 'rewards_train/margins': '5.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24756', 'examples_per_second': '4.0268', 'grad_norm': '5.8125', 'counters/examples': 183936, 'counters/updates': 11496}
skipping logging after 183952 examples to avoid logging too frequently
skipping logging after 183968 examples to avoid logging too frequently
skipping logging after 183984 examples to avoid logging too frequently
train stats after 184000 examples: {'rewards_train/chosen': '0.3264', 'rewards_train/rejected': '-5.8958', 'rewards_train/margins': '6.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24591', 'examples_per_second': '4.1972', 'grad_norm': '5.3438', 'counters/examples': 184000, 'counters/updates': 11500}
Running evaluation after 184000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.25s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.16s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:39,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.65s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.47s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:33,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.51s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.41s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.39s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:21<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.51s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.20s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.31s/it]
eval after 184000: {'rewards_eval/chosen': '-5.806', 'rewards_eval/rejected': '-6.5049', 'rewards_eval/margins': '0.55371', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.45766'}
skipping logging after 184016 examples to avoid logging too frequently
skipping logging after 184032 examples to avoid logging too frequently
skipping logging after 184048 examples to avoid logging too frequently
train stats after 184064 examples: {'rewards_train/chosen': '0.080441', 'rewards_train/rejected': '-6.9557', 'rewards_train/margins': '7.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26215', 'examples_per_second': '5.7172', 'grad_norm': '4.6562', 'counters/examples': 184064, 'counters/updates': 11504}
skipping logging after 184080 examples to avoid logging too frequently
skipping logging after 184096 examples to avoid logging too frequently
skipping logging after 184112 examples to avoid logging too frequently
train stats after 184128 examples: {'rewards_train/chosen': '0.59019', 'rewards_train/rejected': '-6.2052', 'rewards_train/margins': '6.7891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.16797', 'examples_per_second': '5.7926', 'grad_norm': '4.5312', 'counters/examples': 184128, 'counters/updates': 11508}
skipping logging after 184144 examples to avoid logging too frequently
skipping logging after 184160 examples to avoid logging too frequently
skipping logging after 184176 examples to avoid logging too frequently
train stats after 184192 examples: {'rewards_train/chosen': '0.37966', 'rewards_train/rejected': '-6.2658', 'rewards_train/margins': '6.7656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24847', 'examples_per_second': '4.5644', 'grad_norm': '4.7188', 'counters/examples': 184192, 'counters/updates': 11512}
skipping logging after 184208 examples to avoid logging too frequently
skipping logging after 184224 examples to avoid logging too frequently
skipping logging after 184240 examples to avoid logging too frequently
train stats after 184256 examples: {'rewards_train/chosen': '0.44409', 'rewards_train/rejected': '-6.2793', 'rewards_train/margins': '6.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21899', 'examples_per_second': '4.6753', 'grad_norm': '5.25', 'counters/examples': 184256, 'counters/updates': 11516}
skipping logging after 184272 examples to avoid logging too frequently
skipping logging after 184288 examples to avoid logging too frequently
skipping logging after 184304 examples to avoid logging too frequently
train stats after 184320 examples: {'rewards_train/chosen': '0.44867', 'rewards_train/rejected': '-5.6604', 'rewards_train/margins': '6.125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23425', 'examples_per_second': '6.3395', 'grad_norm': '4.7188', 'counters/examples': 184320, 'counters/updates': 11520}
skipping logging after 184336 examples to avoid logging too frequently
skipping logging after 184352 examples to avoid logging too frequently
skipping logging after 184368 examples to avoid logging too frequently
train stats after 184384 examples: {'rewards_train/chosen': '0.12175', 'rewards_train/rejected': '-6.7183', 'rewards_train/margins': '6.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24493', 'examples_per_second': '5.231', 'grad_norm': '4.375', 'counters/examples': 184384, 'counters/updates': 11524}
skipping logging after 184400 examples to avoid logging too frequently
skipping logging after 184416 examples to avoid logging too frequently
skipping logging after 184432 examples to avoid logging too frequently
train stats after 184448 examples: {'rewards_train/chosen': '0.28322', 'rewards_train/rejected': '-6.9938', 'rewards_train/margins': '7.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21497', 'examples_per_second': '5.8573', 'grad_norm': '4.5938', 'counters/examples': 184448, 'counters/updates': 11528}
skipping logging after 184464 examples to avoid logging too frequently
skipping logging after 184480 examples to avoid logging too frequently
skipping logging after 184496 examples to avoid logging too frequently
train stats after 184512 examples: {'rewards_train/chosen': '0.15922', 'rewards_train/rejected': '-6.1108', 'rewards_train/margins': '6.2969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24445', 'examples_per_second': '5.6364', 'grad_norm': '4.9688', 'counters/examples': 184512, 'counters/updates': 11532}
skipping logging after 184528 examples to avoid logging too frequently
skipping logging after 184544 examples to avoid logging too frequently
skipping logging after 184560 examples to avoid logging too frequently
train stats after 184576 examples: {'rewards_train/chosen': '0.44606', 'rewards_train/rejected': '-7.5931', 'rewards_train/margins': '7.9453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20239', 'examples_per_second': '5.9441', 'grad_norm': '5.0938', 'counters/examples': 184576, 'counters/updates': 11536}
skipping logging after 184592 examples to avoid logging too frequently
skipping logging after 184608 examples to avoid logging too frequently
skipping logging after 184624 examples to avoid logging too frequently
train stats after 184640 examples: {'rewards_train/chosen': '0.31449', 'rewards_train/rejected': '-4.4867', 'rewards_train/margins': '4.9297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26105', 'examples_per_second': '4.7588', 'grad_norm': '4.9062', 'counters/examples': 184640, 'counters/updates': 11540}
skipping logging after 184656 examples to avoid logging too frequently
skipping logging after 184672 examples to avoid logging too frequently
skipping logging after 184688 examples to avoid logging too frequently
train stats after 184704 examples: {'rewards_train/chosen': '0.52647', 'rewards_train/rejected': '-5.9325', 'rewards_train/margins': '6.7734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25769', 'examples_per_second': '3.975', 'grad_norm': '5.6562', 'counters/examples': 184704, 'counters/updates': 11544}
skipping logging after 184720 examples to avoid logging too frequently
skipping logging after 184736 examples to avoid logging too frequently
skipping logging after 184752 examples to avoid logging too frequently
train stats after 184768 examples: {'rewards_train/chosen': '0.63791', 'rewards_train/rejected': '-7.1132', 'rewards_train/margins': '8.3281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18237', 'examples_per_second': '4.3328', 'grad_norm': '4.2812', 'counters/examples': 184768, 'counters/updates': 11548}
skipping logging after 184784 examples to avoid logging too frequently
skipping logging after 184800 examples to avoid logging too frequently
skipping logging after 184816 examples to avoid logging too frequently
train stats after 184832 examples: {'rewards_train/chosen': '0.63993', 'rewards_train/rejected': '-7.0733', 'rewards_train/margins': '7.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19708', 'examples_per_second': '5.3403', 'grad_norm': '4.375', 'counters/examples': 184832, 'counters/updates': 11552}
skipping logging after 184848 examples to avoid logging too frequently
skipping logging after 184864 examples to avoid logging too frequently
skipping logging after 184880 examples to avoid logging too frequently
train stats after 184896 examples: {'rewards_train/chosen': '-0.17264', 'rewards_train/rejected': '-6.3534', 'rewards_train/margins': '6.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22656', 'examples_per_second': '4.6941', 'grad_norm': '3.9219', 'counters/examples': 184896, 'counters/updates': 11556}
skipping logging after 184912 examples to avoid logging too frequently
skipping logging after 184928 examples to avoid logging too frequently
skipping logging after 184944 examples to avoid logging too frequently
train stats after 184960 examples: {'rewards_train/chosen': '0.3436', 'rewards_train/rejected': '-5.4026', 'rewards_train/margins': '5.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26355', 'examples_per_second': '5.2589', 'grad_norm': '5.2188', 'counters/examples': 184960, 'counters/updates': 11560}
skipping logging after 184976 examples to avoid logging too frequently
skipping logging after 184992 examples to avoid logging too frequently
skipping logging after 185008 examples to avoid logging too frequently
train stats after 185024 examples: {'rewards_train/chosen': '0.10745', 'rewards_train/rejected': '-5.2007', 'rewards_train/margins': '5.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26941', 'examples_per_second': '5.4656', 'grad_norm': '5.0625', 'counters/examples': 185024, 'counters/updates': 11564}
skipping logging after 185040 examples to avoid logging too frequently
skipping logging after 185056 examples to avoid logging too frequently
skipping logging after 185072 examples to avoid logging too frequently
train stats after 185088 examples: {'rewards_train/chosen': '-1.0704', 'rewards_train/rejected': '-6.0509', 'rewards_train/margins': '5.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27216', 'examples_per_second': '4.5205', 'grad_norm': '5.4062', 'counters/examples': 185088, 'counters/updates': 11568}
skipping logging after 185104 examples to avoid logging too frequently
skipping logging after 185120 examples to avoid logging too frequently
skipping logging after 185136 examples to avoid logging too frequently
train stats after 185152 examples: {'rewards_train/chosen': '0.67848', 'rewards_train/rejected': '-5.3523', 'rewards_train/margins': '6.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21796', 'examples_per_second': '4.6288', 'grad_norm': '5.3125', 'counters/examples': 185152, 'counters/updates': 11572}
skipping logging after 185168 examples to avoid logging too frequently
skipping logging after 185184 examples to avoid logging too frequently
skipping logging after 185200 examples to avoid logging too frequently
train stats after 185216 examples: {'rewards_train/chosen': '0.48548', 'rewards_train/rejected': '-5.265', 'rewards_train/margins': '6.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23633', 'examples_per_second': '5.8019', 'grad_norm': '4.1562', 'counters/examples': 185216, 'counters/updates': 11576}
skipping logging after 185232 examples to avoid logging too frequently
skipping logging after 185248 examples to avoid logging too frequently
skipping logging after 185264 examples to avoid logging too frequently
train stats after 185280 examples: {'rewards_train/chosen': '0.40198', 'rewards_train/rejected': '-6.8511', 'rewards_train/margins': '7.3594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22803', 'examples_per_second': '5.6595', 'grad_norm': '4.625', 'counters/examples': 185280, 'counters/updates': 11580}
skipping logging after 185296 examples to avoid logging too frequently
skipping logging after 185312 examples to avoid logging too frequently
skipping logging after 185328 examples to avoid logging too frequently
train stats after 185344 examples: {'rewards_train/chosen': '-0.042704', 'rewards_train/rejected': '-6.4698', 'rewards_train/margins': '6.5391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26019', 'examples_per_second': '5.5939', 'grad_norm': '5.0938', 'counters/examples': 185344, 'counters/updates': 11584}
skipping logging after 185360 examples to avoid logging too frequently
skipping logging after 185376 examples to avoid logging too frequently
skipping logging after 185392 examples to avoid logging too frequently
train stats after 185408 examples: {'rewards_train/chosen': '0.37735', 'rewards_train/rejected': '-5.3787', 'rewards_train/margins': '5.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2041', 'examples_per_second': '5.7101', 'grad_norm': '5.3125', 'counters/examples': 185408, 'counters/updates': 11588}
skipping logging after 185424 examples to avoid logging too frequently
skipping logging after 185440 examples to avoid logging too frequently
skipping logging after 185456 examples to avoid logging too frequently
train stats after 185472 examples: {'rewards_train/chosen': '0.27667', 'rewards_train/rejected': '-6.0297', 'rewards_train/margins': '6.3281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23657', 'examples_per_second': '5.5362', 'grad_norm': '4.25', 'counters/examples': 185472, 'counters/updates': 11592}
skipping logging after 185488 examples to avoid logging too frequently
skipping logging after 185504 examples to avoid logging too frequently
skipping logging after 185520 examples to avoid logging too frequently
train stats after 185536 examples: {'rewards_train/chosen': '0.56069', 'rewards_train/rejected': '-6.3921', 'rewards_train/margins': '7.1875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22998', 'examples_per_second': '5.0808', 'grad_norm': '5', 'counters/examples': 185536, 'counters/updates': 11596}
skipping logging after 185552 examples to avoid logging too frequently
skipping logging after 185568 examples to avoid logging too frequently
skipping logging after 185584 examples to avoid logging too frequently
train stats after 185600 examples: {'rewards_train/chosen': '0.22707', 'rewards_train/rejected': '-5.7052', 'rewards_train/margins': '5.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26074', 'examples_per_second': '4.7516', 'grad_norm': '5.0312', 'counters/examples': 185600, 'counters/updates': 11600}
skipping logging after 185616 examples to avoid logging too frequently
skipping logging after 185632 examples to avoid logging too frequently
skipping logging after 185648 examples to avoid logging too frequently
train stats after 185664 examples: {'rewards_train/chosen': '-0.058818', 'rewards_train/rejected': '-6.7394', 'rewards_train/margins': '6.9297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20209', 'examples_per_second': '5.679', 'grad_norm': '4.4062', 'counters/examples': 185664, 'counters/updates': 11604}
skipping logging after 185680 examples to avoid logging too frequently
skipping logging after 185696 examples to avoid logging too frequently
skipping logging after 185712 examples to avoid logging too frequently
train stats after 185728 examples: {'rewards_train/chosen': '0.25329', 'rewards_train/rejected': '-6.4352', 'rewards_train/margins': '6.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24585', 'examples_per_second': '4.7417', 'grad_norm': '4.4688', 'counters/examples': 185728, 'counters/updates': 11608}
skipping logging after 185744 examples to avoid logging too frequently
skipping logging after 185760 examples to avoid logging too frequently
skipping logging after 185776 examples to avoid logging too frequently
train stats after 185792 examples: {'rewards_train/chosen': '0.57652', 'rewards_train/rejected': '-5.9254', 'rewards_train/margins': '6.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23572', 'examples_per_second': '4.1202', 'grad_norm': '5.9375', 'counters/examples': 185792, 'counters/updates': 11612}
skipping logging after 185808 examples to avoid logging too frequently
skipping logging after 185824 examples to avoid logging too frequently
skipping logging after 185840 examples to avoid logging too frequently
train stats after 185856 examples: {'rewards_train/chosen': '0.47186', 'rewards_train/rejected': '-5.2247', 'rewards_train/margins': '5.6055', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22943', 'examples_per_second': '5.3775', 'grad_norm': '6.2188', 'counters/examples': 185856, 'counters/updates': 11616}
skipping logging after 185872 examples to avoid logging too frequently
skipping logging after 185888 examples to avoid logging too frequently
skipping logging after 185904 examples to avoid logging too frequently
train stats after 185920 examples: {'rewards_train/chosen': '0.21502', 'rewards_train/rejected': '-5.4445', 'rewards_train/margins': '5.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25104', 'examples_per_second': '4.5165', 'grad_norm': '6.2812', 'counters/examples': 185920, 'counters/updates': 11620}
skipping logging after 185936 examples to avoid logging too frequently
skipping logging after 185952 examples to avoid logging too frequently
skipping logging after 185968 examples to avoid logging too frequently
train stats after 185984 examples: {'rewards_train/chosen': '0.62402', 'rewards_train/rejected': '-6.2506', 'rewards_train/margins': '6.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22058', 'examples_per_second': '5.4279', 'grad_norm': '5.2188', 'counters/examples': 185984, 'counters/updates': 11624}
skipping logging after 186000 examples to avoid logging too frequently
skipping logging after 186016 examples to avoid logging too frequently
skipping logging after 186032 examples to avoid logging too frequently
train stats after 186048 examples: {'rewards_train/chosen': '0.23148', 'rewards_train/rejected': '-5.9927', 'rewards_train/margins': '6.4531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24518', 'examples_per_second': '5.9964', 'grad_norm': '5.0312', 'counters/examples': 186048, 'counters/updates': 11628}
skipping logging after 186064 examples to avoid logging too frequently
skipping logging after 186080 examples to avoid logging too frequently
skipping logging after 186096 examples to avoid logging too frequently
train stats after 186112 examples: {'rewards_train/chosen': '0.16446', 'rewards_train/rejected': '-6.3209', 'rewards_train/margins': '6.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22778', 'examples_per_second': '5.0721', 'grad_norm': '5.2812', 'counters/examples': 186112, 'counters/updates': 11632}
skipping logging after 186128 examples to avoid logging too frequently
skipping logging after 186144 examples to avoid logging too frequently
skipping logging after 186160 examples to avoid logging too frequently
train stats after 186176 examples: {'rewards_train/chosen': '0.15145', 'rewards_train/rejected': '-6.2854', 'rewards_train/margins': '6.6641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23236', 'examples_per_second': '4.5565', 'grad_norm': '5.3438', 'counters/examples': 186176, 'counters/updates': 11636}
skipping logging after 186192 examples to avoid logging too frequently
skipping logging after 186208 examples to avoid logging too frequently
skipping logging after 186224 examples to avoid logging too frequently
train stats after 186240 examples: {'rewards_train/chosen': '0.34351', 'rewards_train/rejected': '-6.471', 'rewards_train/margins': '6.7734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26489', 'examples_per_second': '4.3887', 'grad_norm': '5.25', 'counters/examples': 186240, 'counters/updates': 11640}
skipping logging after 186256 examples to avoid logging too frequently
skipping logging after 186272 examples to avoid logging too frequently
skipping logging after 186288 examples to avoid logging too frequently
train stats after 186304 examples: {'rewards_train/chosen': '0.31228', 'rewards_train/rejected': '-6.2363', 'rewards_train/margins': '6.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2204', 'examples_per_second': '5.1819', 'grad_norm': '4.3125', 'counters/examples': 186304, 'counters/updates': 11644}
skipping logging after 186320 examples to avoid logging too frequently
skipping logging after 186336 examples to avoid logging too frequently
skipping logging after 186352 examples to avoid logging too frequently
train stats after 186368 examples: {'rewards_train/chosen': '0.22237', 'rewards_train/rejected': '-6.4772', 'rewards_train/margins': '6.7578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2583', 'examples_per_second': '4.8945', 'grad_norm': '4.8438', 'counters/examples': 186368, 'counters/updates': 11648}
skipping logging after 186384 examples to avoid logging too frequently
skipping logging after 186400 examples to avoid logging too frequently
skipping logging after 186416 examples to avoid logging too frequently
train stats after 186432 examples: {'rewards_train/chosen': '0.36708', 'rewards_train/rejected': '-7.2997', 'rewards_train/margins': '7.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20636', 'examples_per_second': '4.8498', 'grad_norm': '5.2812', 'counters/examples': 186432, 'counters/updates': 11652}
skipping logging after 186448 examples to avoid logging too frequently
skipping logging after 186464 examples to avoid logging too frequently
skipping logging after 186480 examples to avoid logging too frequently
train stats after 186496 examples: {'rewards_train/chosen': '0.43168', 'rewards_train/rejected': '-4.3771', 'rewards_train/margins': '5.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23615', 'examples_per_second': '6.5535', 'grad_norm': '4.8125', 'counters/examples': 186496, 'counters/updates': 11656}
skipping logging after 186512 examples to avoid logging too frequently
skipping logging after 186528 examples to avoid logging too frequently
skipping logging after 186544 examples to avoid logging too frequently
train stats after 186560 examples: {'rewards_train/chosen': '0.26549', 'rewards_train/rejected': '-5.0386', 'rewards_train/margins': '5.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20062', 'examples_per_second': '6.0267', 'grad_norm': '5.0625', 'counters/examples': 186560, 'counters/updates': 11660}
skipping logging after 186576 examples to avoid logging too frequently
skipping logging after 186592 examples to avoid logging too frequently
skipping logging after 186608 examples to avoid logging too frequently
train stats after 186624 examples: {'rewards_train/chosen': '0.30141', 'rewards_train/rejected': '-5.1505', 'rewards_train/margins': '5.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24677', 'examples_per_second': '4.8586', 'grad_norm': '5.1875', 'counters/examples': 186624, 'counters/updates': 11664}
skipping logging after 186640 examples to avoid logging too frequently
skipping logging after 186656 examples to avoid logging too frequently
skipping logging after 186672 examples to avoid logging too frequently
train stats after 186688 examples: {'rewards_train/chosen': '0.19245', 'rewards_train/rejected': '-5.0165', 'rewards_train/margins': '4.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28516', 'examples_per_second': '5.3153', 'grad_norm': '4.875', 'counters/examples': 186688, 'counters/updates': 11668}
skipping logging after 186704 examples to avoid logging too frequently
skipping logging after 186720 examples to avoid logging too frequently
skipping logging after 186736 examples to avoid logging too frequently
train stats after 186752 examples: {'rewards_train/chosen': '0.073486', 'rewards_train/rejected': '-5.2805', 'rewards_train/margins': '5.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23767', 'examples_per_second': '5.0884', 'grad_norm': '5.4062', 'counters/examples': 186752, 'counters/updates': 11672}
skipping logging after 186768 examples to avoid logging too frequently
skipping logging after 186784 examples to avoid logging too frequently
skipping logging after 186800 examples to avoid logging too frequently
train stats after 186816 examples: {'rewards_train/chosen': '0.50416', 'rewards_train/rejected': '-6.3286', 'rewards_train/margins': '6.7109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19775', 'examples_per_second': '5.1165', 'grad_norm': '5.75', 'counters/examples': 186816, 'counters/updates': 11676}
skipping logging after 186832 examples to avoid logging too frequently
skipping logging after 186848 examples to avoid logging too frequently
skipping logging after 186864 examples to avoid logging too frequently
train stats after 186880 examples: {'rewards_train/chosen': '0.0663', 'rewards_train/rejected': '-6.4325', 'rewards_train/margins': '6.5469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27539', 'examples_per_second': '5.2306', 'grad_norm': '5.4062', 'counters/examples': 186880, 'counters/updates': 11680}
skipping logging after 186896 examples to avoid logging too frequently
skipping logging after 186912 examples to avoid logging too frequently
skipping logging after 186928 examples to avoid logging too frequently
train stats after 186944 examples: {'rewards_train/chosen': '0.1992', 'rewards_train/rejected': '-6.0794', 'rewards_train/margins': '6.2383', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22754', 'examples_per_second': '4.6121', 'grad_norm': '4.5312', 'counters/examples': 186944, 'counters/updates': 11684}
skipping logging after 186960 examples to avoid logging too frequently
skipping logging after 186976 examples to avoid logging too frequently
skipping logging after 186992 examples to avoid logging too frequently
train stats after 187008 examples: {'rewards_train/chosen': '0.17526', 'rewards_train/rejected': '-7.0202', 'rewards_train/margins': '7.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24121', 'examples_per_second': '5.6578', 'grad_norm': '4.9062', 'counters/examples': 187008, 'counters/updates': 11688}
skipping logging after 187024 examples to avoid logging too frequently
skipping logging after 187040 examples to avoid logging too frequently
skipping logging after 187056 examples to avoid logging too frequently
train stats after 187072 examples: {'rewards_train/chosen': '0.42471', 'rewards_train/rejected': '-5.9683', 'rewards_train/margins': '6.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19843', 'examples_per_second': '6.6921', 'grad_norm': '5.375', 'counters/examples': 187072, 'counters/updates': 11692}
skipping logging after 187088 examples to avoid logging too frequently
skipping logging after 187104 examples to avoid logging too frequently
skipping logging after 187120 examples to avoid logging too frequently
train stats after 187136 examples: {'rewards_train/chosen': '0.68414', 'rewards_train/rejected': '-5.8011', 'rewards_train/margins': '6.2969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26453', 'examples_per_second': '5.1238', 'grad_norm': '5.0938', 'counters/examples': 187136, 'counters/updates': 11696}
skipping logging after 187152 examples to avoid logging too frequently
skipping logging after 187168 examples to avoid logging too frequently
skipping logging after 187184 examples to avoid logging too frequently
train stats after 187200 examples: {'rewards_train/chosen': '0.55765', 'rewards_train/rejected': '-6.3859', 'rewards_train/margins': '7.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21954', 'examples_per_second': '4.464', 'grad_norm': '5.5312', 'counters/examples': 187200, 'counters/updates': 11700}
skipping logging after 187216 examples to avoid logging too frequently
skipping logging after 187232 examples to avoid logging too frequently
skipping logging after 187248 examples to avoid logging too frequently
train stats after 187264 examples: {'rewards_train/chosen': '0.4528', 'rewards_train/rejected': '-6.49', 'rewards_train/margins': '6.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21655', 'examples_per_second': '4.7335', 'grad_norm': '4.5312', 'counters/examples': 187264, 'counters/updates': 11704}
skipping logging after 187280 examples to avoid logging too frequently
skipping logging after 187296 examples to avoid logging too frequently
skipping logging after 187312 examples to avoid logging too frequently
train stats after 187328 examples: {'rewards_train/chosen': '0.39891', 'rewards_train/rejected': '-5.7393', 'rewards_train/margins': '5.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23627', 'examples_per_second': '4.8468', 'grad_norm': '5', 'counters/examples': 187328, 'counters/updates': 11708}
skipping logging after 187344 examples to avoid logging too frequently
skipping logging after 187360 examples to avoid logging too frequently
skipping logging after 187376 examples to avoid logging too frequently
train stats after 187392 examples: {'rewards_train/chosen': '0.49419', 'rewards_train/rejected': '-6.0616', 'rewards_train/margins': '6.6016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21143', 'examples_per_second': '5.002', 'grad_norm': '5.2812', 'counters/examples': 187392, 'counters/updates': 11712}
skipping logging after 187408 examples to avoid logging too frequently
skipping logging after 187424 examples to avoid logging too frequently
skipping logging after 187440 examples to avoid logging too frequently
train stats after 187456 examples: {'rewards_train/chosen': '0.50237', 'rewards_train/rejected': '-6.5689', 'rewards_train/margins': '7.0312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22778', 'examples_per_second': '5.2022', 'grad_norm': '4.25', 'counters/examples': 187456, 'counters/updates': 11716}
skipping logging after 187472 examples to avoid logging too frequently
skipping logging after 187488 examples to avoid logging too frequently
skipping logging after 187504 examples to avoid logging too frequently
train stats after 187520 examples: {'rewards_train/chosen': '0.24788', 'rewards_train/rejected': '-6.5673', 'rewards_train/margins': '6.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20233', 'examples_per_second': '4.8539', 'grad_norm': '5.8125', 'counters/examples': 187520, 'counters/updates': 11720}
skipping logging after 187536 examples to avoid logging too frequently
skipping logging after 187552 examples to avoid logging too frequently
skipping logging after 187568 examples to avoid logging too frequently
train stats after 187584 examples: {'rewards_train/chosen': '0.18422', 'rewards_train/rejected': '-5.9938', 'rewards_train/margins': '6.0977', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17255', 'examples_per_second': '4.8506', 'grad_norm': '4.3438', 'counters/examples': 187584, 'counters/updates': 11724}
skipping logging after 187600 examples to avoid logging too frequently
skipping logging after 187616 examples to avoid logging too frequently
skipping logging after 187632 examples to avoid logging too frequently
train stats after 187648 examples: {'rewards_train/chosen': '0.55932', 'rewards_train/rejected': '-6.6217', 'rewards_train/margins': '7.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.15131', 'examples_per_second': '5.357', 'grad_norm': '4.3125', 'counters/examples': 187648, 'counters/updates': 11728}
skipping logging after 187664 examples to avoid logging too frequently
skipping logging after 187680 examples to avoid logging too frequently
skipping logging after 187696 examples to avoid logging too frequently
train stats after 187712 examples: {'rewards_train/chosen': '-0.085386', 'rewards_train/rejected': '-5.5202', 'rewards_train/margins': '5.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24036', 'examples_per_second': '4.5062', 'grad_norm': '4.4375', 'counters/examples': 187712, 'counters/updates': 11732}
skipping logging after 187728 examples to avoid logging too frequently
skipping logging after 187744 examples to avoid logging too frequently
skipping logging after 187760 examples to avoid logging too frequently
train stats after 187776 examples: {'rewards_train/chosen': '0.61884', 'rewards_train/rejected': '-7.0225', 'rewards_train/margins': '7.5938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20215', 'examples_per_second': '4.8076', 'grad_norm': '5.2812', 'counters/examples': 187776, 'counters/updates': 11736}
skipping logging after 187792 examples to avoid logging too frequently
skipping logging after 187808 examples to avoid logging too frequently
skipping logging after 187824 examples to avoid logging too frequently
train stats after 187840 examples: {'rewards_train/chosen': '0.49003', 'rewards_train/rejected': '-7.0765', 'rewards_train/margins': '7.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18256', 'examples_per_second': '4.9576', 'grad_norm': '4.3125', 'counters/examples': 187840, 'counters/updates': 11740}
skipping logging after 187856 examples to avoid logging too frequently
skipping logging after 187872 examples to avoid logging too frequently
skipping logging after 187888 examples to avoid logging too frequently
train stats after 187904 examples: {'rewards_train/chosen': '0.063703', 'rewards_train/rejected': '-8.0051', 'rewards_train/margins': '8.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23682', 'examples_per_second': '6.4938', 'grad_norm': '5.125', 'counters/examples': 187904, 'counters/updates': 11744}
skipping logging after 187920 examples to avoid logging too frequently
skipping logging after 187936 examples to avoid logging too frequently
skipping logging after 187952 examples to avoid logging too frequently
train stats after 187968 examples: {'rewards_train/chosen': '0.26127', 'rewards_train/rejected': '-6.2646', 'rewards_train/margins': '6.5469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21399', 'examples_per_second': '5.5634', 'grad_norm': '4.375', 'counters/examples': 187968, 'counters/updates': 11748}
skipping logging after 187984 examples to avoid logging too frequently
skipping logging after 188000 examples to avoid logging too frequently
Running evaluation after 188000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:49,  1.58s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:41,  1.39s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:35,  1.24s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.47s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.68s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.49s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:10<00:34,  1.37s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.53s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.49s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.31s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:41<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]
eval after 188000: {'rewards_eval/chosen': '-5.9079', 'rewards_eval/rejected': '-6.5587', 'rewards_eval/margins': '0.51611', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.45831'}
skipping logging after 188016 examples to avoid logging too frequently
train stats after 188032 examples: {'rewards_train/chosen': '0.37039', 'rewards_train/rejected': '-5.6605', 'rewards_train/margins': '5.7656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23022', 'examples_per_second': '6.0446', 'grad_norm': '7.4062', 'counters/examples': 188032, 'counters/updates': 11752}
skipping logging after 188048 examples to avoid logging too frequently
skipping logging after 188064 examples to avoid logging too frequently
skipping logging after 188080 examples to avoid logging too frequently
train stats after 188096 examples: {'rewards_train/chosen': '0.34011', 'rewards_train/rejected': '-6.002', 'rewards_train/margins': '5.9414', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25824', 'examples_per_second': '4.0807', 'grad_norm': '5.5625', 'counters/examples': 188096, 'counters/updates': 11756}
skipping logging after 188112 examples to avoid logging too frequently
skipping logging after 188128 examples to avoid logging too frequently
skipping logging after 188144 examples to avoid logging too frequently
train stats after 188160 examples: {'rewards_train/chosen': '0.56243', 'rewards_train/rejected': '-5.928', 'rewards_train/margins': '6.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21844', 'examples_per_second': '4.6093', 'grad_norm': '5.5312', 'counters/examples': 188160, 'counters/updates': 11760}
skipping logging after 188176 examples to avoid logging too frequently
skipping logging after 188192 examples to avoid logging too frequently
skipping logging after 188208 examples to avoid logging too frequently
train stats after 188224 examples: {'rewards_train/chosen': '0.37118', 'rewards_train/rejected': '-5.8156', 'rewards_train/margins': '6.2109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28918', 'examples_per_second': '5.4666', 'grad_norm': '5.0312', 'counters/examples': 188224, 'counters/updates': 11764}
skipping logging after 188240 examples to avoid logging too frequently
skipping logging after 188256 examples to avoid logging too frequently
skipping logging after 188272 examples to avoid logging too frequently
train stats after 188288 examples: {'rewards_train/chosen': '0.15516', 'rewards_train/rejected': '-5.2654', 'rewards_train/margins': '5.5508', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28436', 'examples_per_second': '5.2291', 'grad_norm': '4.875', 'counters/examples': 188288, 'counters/updates': 11768}
skipping logging after 188304 examples to avoid logging too frequently
skipping logging after 188320 examples to avoid logging too frequently
skipping logging after 188336 examples to avoid logging too frequently
train stats after 188352 examples: {'rewards_train/chosen': '0.078719', 'rewards_train/rejected': '-4.8827', 'rewards_train/margins': '5.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2572', 'examples_per_second': '5.3469', 'grad_norm': '4.9688', 'counters/examples': 188352, 'counters/updates': 11772}
skipping logging after 188368 examples to avoid logging too frequently
skipping logging after 188384 examples to avoid logging too frequently
skipping logging after 188400 examples to avoid logging too frequently
train stats after 188416 examples: {'rewards_train/chosen': '0.28017', 'rewards_train/rejected': '-4.2294', 'rewards_train/margins': '4.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23926', 'examples_per_second': '5.2668', 'grad_norm': '5.2812', 'counters/examples': 188416, 'counters/updates': 11776}
skipping logging after 188432 examples to avoid logging too frequently
skipping logging after 188448 examples to avoid logging too frequently
skipping logging after 188464 examples to avoid logging too frequently
train stats after 188480 examples: {'rewards_train/chosen': '0.77044', 'rewards_train/rejected': '-4.9642', 'rewards_train/margins': '5.6328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21918', 'examples_per_second': '4.7183', 'grad_norm': '4.375', 'counters/examples': 188480, 'counters/updates': 11780}
skipping logging after 188496 examples to avoid logging too frequently
skipping logging after 188512 examples to avoid logging too frequently
skipping logging after 188528 examples to avoid logging too frequently
train stats after 188544 examples: {'rewards_train/chosen': '0.74158', 'rewards_train/rejected': '-5.1161', 'rewards_train/margins': '5.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22357', 'examples_per_second': '5.1914', 'grad_norm': '5.5312', 'counters/examples': 188544, 'counters/updates': 11784}
skipping logging after 188560 examples to avoid logging too frequently
skipping logging after 188576 examples to avoid logging too frequently
skipping logging after 188592 examples to avoid logging too frequently
train stats after 188608 examples: {'rewards_train/chosen': '0.68976', 'rewards_train/rejected': '-5.3211', 'rewards_train/margins': '5.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20966', 'examples_per_second': '4.4334', 'grad_norm': '4.6562', 'counters/examples': 188608, 'counters/updates': 11788}
skipping logging after 188624 examples to avoid logging too frequently
skipping logging after 188640 examples to avoid logging too frequently
skipping logging after 188656 examples to avoid logging too frequently
train stats after 188672 examples: {'rewards_train/chosen': '0.53306', 'rewards_train/rejected': '-7.4813', 'rewards_train/margins': '8.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22382', 'examples_per_second': '4.8495', 'grad_norm': '5.5625', 'counters/examples': 188672, 'counters/updates': 11792}
skipping logging after 188688 examples to avoid logging too frequently
skipping logging after 188704 examples to avoid logging too frequently
skipping logging after 188720 examples to avoid logging too frequently
train stats after 188736 examples: {'rewards_train/chosen': '0.25537', 'rewards_train/rejected': '-6.4871', 'rewards_train/margins': '7.0547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21912', 'examples_per_second': '4.7782', 'grad_norm': '4.75', 'counters/examples': 188736, 'counters/updates': 11796}
skipping logging after 188752 examples to avoid logging too frequently
skipping logging after 188768 examples to avoid logging too frequently
skipping logging after 188784 examples to avoid logging too frequently
train stats after 188800 examples: {'rewards_train/chosen': '0.31431', 'rewards_train/rejected': '-5.7195', 'rewards_train/margins': '6.0977', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2323', 'examples_per_second': '5.1404', 'grad_norm': '5.1562', 'counters/examples': 188800, 'counters/updates': 11800}
skipping logging after 188816 examples to avoid logging too frequently
skipping logging after 188832 examples to avoid logging too frequently
skipping logging after 188848 examples to avoid logging too frequently
train stats after 188864 examples: {'rewards_train/chosen': '0.19357', 'rewards_train/rejected': '-5.1939', 'rewards_train/margins': '5.4102', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30322', 'examples_per_second': '5.495', 'grad_norm': '5', 'counters/examples': 188864, 'counters/updates': 11804}
skipping logging after 188880 examples to avoid logging too frequently
skipping logging after 188896 examples to avoid logging too frequently
skipping logging after 188912 examples to avoid logging too frequently
train stats after 188928 examples: {'rewards_train/chosen': '0.54349', 'rewards_train/rejected': '-6.8149', 'rewards_train/margins': '7.1016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22925', 'examples_per_second': '4.9899', 'grad_norm': '4.9062', 'counters/examples': 188928, 'counters/updates': 11808}
skipping logging after 188944 examples to avoid logging too frequently
skipping logging after 188960 examples to avoid logging too frequently
skipping logging after 188976 examples to avoid logging too frequently
train stats after 188992 examples: {'rewards_train/chosen': '0.43355', 'rewards_train/rejected': '-5.1858', 'rewards_train/margins': '5.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24359', 'examples_per_second': '4.8816', 'grad_norm': '5', 'counters/examples': 188992, 'counters/updates': 11812}
skipping logging after 189008 examples to avoid logging too frequently
skipping logging after 189024 examples to avoid logging too frequently
skipping logging after 189040 examples to avoid logging too frequently
train stats after 189056 examples: {'rewards_train/chosen': '0.52605', 'rewards_train/rejected': '-6.4724', 'rewards_train/margins': '6.9453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17383', 'examples_per_second': '4.9603', 'grad_norm': '3.875', 'counters/examples': 189056, 'counters/updates': 11816}
skipping logging after 189072 examples to avoid logging too frequently
skipping logging after 189088 examples to avoid logging too frequently
skipping logging after 189104 examples to avoid logging too frequently
train stats after 189120 examples: {'rewards_train/chosen': '0.52543', 'rewards_train/rejected': '-5.2371', 'rewards_train/margins': '5.7266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24847', 'examples_per_second': '4.7178', 'grad_norm': '5.4062', 'counters/examples': 189120, 'counters/updates': 11820}
skipping logging after 189136 examples to avoid logging too frequently
skipping logging after 189152 examples to avoid logging too frequently
skipping logging after 189168 examples to avoid logging too frequently
train stats after 189184 examples: {'rewards_train/chosen': '0.43225', 'rewards_train/rejected': '-7.3424', 'rewards_train/margins': '8.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23682', 'examples_per_second': '6.3031', 'grad_norm': '5.5312', 'counters/examples': 189184, 'counters/updates': 11824}
skipping logging after 189200 examples to avoid logging too frequently
skipping logging after 189216 examples to avoid logging too frequently
skipping logging after 189232 examples to avoid logging too frequently
train stats after 189248 examples: {'rewards_train/chosen': '0.38912', 'rewards_train/rejected': '-5.2647', 'rewards_train/margins': '5.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25024', 'examples_per_second': '4.0938', 'grad_norm': '5.25', 'counters/examples': 189248, 'counters/updates': 11828}
skipping logging after 189264 examples to avoid logging too frequently
skipping logging after 189280 examples to avoid logging too frequently
skipping logging after 189296 examples to avoid logging too frequently
train stats after 189312 examples: {'rewards_train/chosen': '0.10014', 'rewards_train/rejected': '-5.8336', 'rewards_train/margins': '5.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30304', 'examples_per_second': '4.9361', 'grad_norm': '5.4062', 'counters/examples': 189312, 'counters/updates': 11832}
skipping logging after 189328 examples to avoid logging too frequently
skipping logging after 189344 examples to avoid logging too frequently
skipping logging after 189360 examples to avoid logging too frequently
train stats after 189376 examples: {'rewards_train/chosen': '0.19382', 'rewards_train/rejected': '-4.8421', 'rewards_train/margins': '4.9805', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24426', 'examples_per_second': '4.8258', 'grad_norm': '4.75', 'counters/examples': 189376, 'counters/updates': 11836}
skipping logging after 189392 examples to avoid logging too frequently
skipping logging after 189408 examples to avoid logging too frequently
skipping logging after 189424 examples to avoid logging too frequently
train stats after 189440 examples: {'rewards_train/chosen': '0.39274', 'rewards_train/rejected': '-5.1428', 'rewards_train/margins': '5.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20752', 'examples_per_second': '5.8152', 'grad_norm': '4.7812', 'counters/examples': 189440, 'counters/updates': 11840}
skipping logging after 189456 examples to avoid logging too frequently
skipping logging after 189472 examples to avoid logging too frequently
skipping logging after 189488 examples to avoid logging too frequently
train stats after 189504 examples: {'rewards_train/chosen': '0.23261', 'rewards_train/rejected': '-5.766', 'rewards_train/margins': '6.0312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24915', 'examples_per_second': '4.8445', 'grad_norm': '4.8125', 'counters/examples': 189504, 'counters/updates': 11844}
skipping logging after 189520 examples to avoid logging too frequently
skipping logging after 189536 examples to avoid logging too frequently
skipping logging after 189552 examples to avoid logging too frequently
train stats after 189568 examples: {'rewards_train/chosen': '-0.039517', 'rewards_train/rejected': '-7.4566', 'rewards_train/margins': '7.3203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2561', 'examples_per_second': '4.94', 'grad_norm': '5.6875', 'counters/examples': 189568, 'counters/updates': 11848}
skipping logging after 189584 examples to avoid logging too frequently
skipping logging after 189600 examples to avoid logging too frequently
skipping logging after 189616 examples to avoid logging too frequently
train stats after 189632 examples: {'rewards_train/chosen': '0.60905', 'rewards_train/rejected': '-5.0795', 'rewards_train/margins': '5.6875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24902', 'examples_per_second': '4.8753', 'grad_norm': '5.125', 'counters/examples': 189632, 'counters/updates': 11852}
skipping logging after 189648 examples to avoid logging too frequently
skipping logging after 189664 examples to avoid logging too frequently
skipping logging after 189680 examples to avoid logging too frequently
train stats after 189696 examples: {'rewards_train/chosen': '0.30102', 'rewards_train/rejected': '-6.5439', 'rewards_train/margins': '6.7734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24896', 'examples_per_second': '5.2763', 'grad_norm': '4.9062', 'counters/examples': 189696, 'counters/updates': 11856}
skipping logging after 189712 examples to avoid logging too frequently
skipping logging after 189728 examples to avoid logging too frequently
skipping logging after 189744 examples to avoid logging too frequently
train stats after 189760 examples: {'rewards_train/chosen': '0.24382', 'rewards_train/rejected': '-5.2453', 'rewards_train/margins': '5.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23572', 'examples_per_second': '5.2667', 'grad_norm': '4.5312', 'counters/examples': 189760, 'counters/updates': 11860}
skipping logging after 189776 examples to avoid logging too frequently
skipping logging after 189792 examples to avoid logging too frequently
skipping logging after 189808 examples to avoid logging too frequently
train stats after 189824 examples: {'rewards_train/chosen': '0.016908', 'rewards_train/rejected': '-6.3178', 'rewards_train/margins': '6.2109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29681', 'examples_per_second': '4.9689', 'grad_norm': '5.3438', 'counters/examples': 189824, 'counters/updates': 11864}
skipping logging after 189840 examples to avoid logging too frequently
skipping logging after 189856 examples to avoid logging too frequently
skipping logging after 189872 examples to avoid logging too frequently
train stats after 189888 examples: {'rewards_train/chosen': '0.14541', 'rewards_train/rejected': '-5.6253', 'rewards_train/margins': '5.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23138', 'examples_per_second': '5.2112', 'grad_norm': '3.7344', 'counters/examples': 189888, 'counters/updates': 11868}
skipping logging after 189904 examples to avoid logging too frequently
skipping logging after 189920 examples to avoid logging too frequently
skipping logging after 189936 examples to avoid logging too frequently
train stats after 189952 examples: {'rewards_train/chosen': '0.58462', 'rewards_train/rejected': '-5.2697', 'rewards_train/margins': '5.9766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2403', 'examples_per_second': '5.7993', 'grad_norm': '5.5', 'counters/examples': 189952, 'counters/updates': 11872}
skipping logging after 189968 examples to avoid logging too frequently
skipping logging after 189984 examples to avoid logging too frequently
skipping logging after 190000 examples to avoid logging too frequently
train stats after 190016 examples: {'rewards_train/chosen': '0.46243', 'rewards_train/rejected': '-6.3429', 'rewards_train/margins': '6.7734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20746', 'examples_per_second': '5.1122', 'grad_norm': '4.7812', 'counters/examples': 190016, 'counters/updates': 11876}
skipping logging after 190032 examples to avoid logging too frequently
skipping logging after 190048 examples to avoid logging too frequently
skipping logging after 190064 examples to avoid logging too frequently
train stats after 190080 examples: {'rewards_train/chosen': '0.15799', 'rewards_train/rejected': '-5.1434', 'rewards_train/margins': '5.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28284', 'examples_per_second': '4.5348', 'grad_norm': '4.9375', 'counters/examples': 190080, 'counters/updates': 11880}
skipping logging after 190096 examples to avoid logging too frequently
skipping logging after 190112 examples to avoid logging too frequently
skipping logging after 190128 examples to avoid logging too frequently
train stats after 190144 examples: {'rewards_train/chosen': '0.25287', 'rewards_train/rejected': '-4.6902', 'rewards_train/margins': '4.9453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22998', 'examples_per_second': '4.9337', 'grad_norm': '5.3125', 'counters/examples': 190144, 'counters/updates': 11884}
skipping logging after 190160 examples to avoid logging too frequently
skipping logging after 190176 examples to avoid logging too frequently
skipping logging after 190192 examples to avoid logging too frequently
train stats after 190208 examples: {'rewards_train/chosen': '0.15405', 'rewards_train/rejected': '-5.8433', 'rewards_train/margins': '5.8984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2522', 'examples_per_second': '5.4145', 'grad_norm': '4.7812', 'counters/examples': 190208, 'counters/updates': 11888}
skipping logging after 190224 examples to avoid logging too frequently
skipping logging after 190240 examples to avoid logging too frequently
skipping logging after 190256 examples to avoid logging too frequently
train stats after 190272 examples: {'rewards_train/chosen': '0.2744', 'rewards_train/rejected': '-6.7173', 'rewards_train/margins': '6.9766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2533', 'examples_per_second': '5.2293', 'grad_norm': '5.25', 'counters/examples': 190272, 'counters/updates': 11892}
skipping logging after 190288 examples to avoid logging too frequently
skipping logging after 190304 examples to avoid logging too frequently
skipping logging after 190320 examples to avoid logging too frequently
train stats after 190336 examples: {'rewards_train/chosen': '0.29349', 'rewards_train/rejected': '-5.9138', 'rewards_train/margins': '6.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23889', 'examples_per_second': '4.6487', 'grad_norm': '4.25', 'counters/examples': 190336, 'counters/updates': 11896}
skipping logging after 190352 examples to avoid logging too frequently
skipping logging after 190368 examples to avoid logging too frequently
skipping logging after 190384 examples to avoid logging too frequently
train stats after 190400 examples: {'rewards_train/chosen': '0.35205', 'rewards_train/rejected': '-6.6348', 'rewards_train/margins': '7.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24591', 'examples_per_second': '5.4092', 'grad_norm': '3.7656', 'counters/examples': 190400, 'counters/updates': 11900}
skipping logging after 190416 examples to avoid logging too frequently
skipping logging after 190432 examples to avoid logging too frequently
skipping logging after 190448 examples to avoid logging too frequently
train stats after 190464 examples: {'rewards_train/chosen': '0.22932', 'rewards_train/rejected': '-6.6217', 'rewards_train/margins': '7.0742', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23907', 'examples_per_second': '4.5397', 'grad_norm': '5.75', 'counters/examples': 190464, 'counters/updates': 11904}
skipping logging after 190480 examples to avoid logging too frequently
skipping logging after 190496 examples to avoid logging too frequently
skipping logging after 190512 examples to avoid logging too frequently
train stats after 190528 examples: {'rewards_train/chosen': '0.40913', 'rewards_train/rejected': '-4.3315', 'rewards_train/margins': '4.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28485', 'examples_per_second': '3.9452', 'grad_norm': '5.7812', 'counters/examples': 190528, 'counters/updates': 11908}
skipping logging after 190544 examples to avoid logging too frequently
skipping logging after 190560 examples to avoid logging too frequently
skipping logging after 190576 examples to avoid logging too frequently
train stats after 190592 examples: {'rewards_train/chosen': '0.1247', 'rewards_train/rejected': '-5.8104', 'rewards_train/margins': '5.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2157', 'examples_per_second': '5.2738', 'grad_norm': '4.5625', 'counters/examples': 190592, 'counters/updates': 11912}
skipping logging after 190608 examples to avoid logging too frequently
skipping logging after 190624 examples to avoid logging too frequently
skipping logging after 190640 examples to avoid logging too frequently
train stats after 190656 examples: {'rewards_train/chosen': '0.19302', 'rewards_train/rejected': '-5.7682', 'rewards_train/margins': '5.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22308', 'examples_per_second': '6.5033', 'grad_norm': '4.4375', 'counters/examples': 190656, 'counters/updates': 11916}
skipping logging after 190672 examples to avoid logging too frequently
skipping logging after 190688 examples to avoid logging too frequently
skipping logging after 190704 examples to avoid logging too frequently
train stats after 190720 examples: {'rewards_train/chosen': '0.40314', 'rewards_train/rejected': '-6.0262', 'rewards_train/margins': '6.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25964', 'examples_per_second': '5.6888', 'grad_norm': '7.0625', 'counters/examples': 190720, 'counters/updates': 11920}
skipping logging after 190736 examples to avoid logging too frequently
skipping logging after 190752 examples to avoid logging too frequently
skipping logging after 190768 examples to avoid logging too frequently
train stats after 190784 examples: {'rewards_train/chosen': '0.67318', 'rewards_train/rejected': '-5.7793', 'rewards_train/margins': '6.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21417', 'examples_per_second': '6.5004', 'grad_norm': '4.3438', 'counters/examples': 190784, 'counters/updates': 11924}
skipping logging after 190800 examples to avoid logging too frequently
skipping logging after 190816 examples to avoid logging too frequently
skipping logging after 190832 examples to avoid logging too frequently
train stats after 190848 examples: {'rewards_train/chosen': '0.22863', 'rewards_train/rejected': '-4.8942', 'rewards_train/margins': '5.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2312', 'examples_per_second': '5.1922', 'grad_norm': '4.625', 'counters/examples': 190848, 'counters/updates': 11928}
skipping logging after 190864 examples to avoid logging too frequently
skipping logging after 190880 examples to avoid logging too frequently
skipping logging after 190896 examples to avoid logging too frequently
train stats after 190912 examples: {'rewards_train/chosen': '0.4728', 'rewards_train/rejected': '-8.1818', 'rewards_train/margins': '8.8125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24127', 'examples_per_second': '4.1582', 'grad_norm': '4.8125', 'counters/examples': 190912, 'counters/updates': 11932}
skipping logging after 190928 examples to avoid logging too frequently
skipping logging after 190944 examples to avoid logging too frequently
skipping logging after 190960 examples to avoid logging too frequently
train stats after 190976 examples: {'rewards_train/chosen': '0.35529', 'rewards_train/rejected': '-5.5672', 'rewards_train/margins': '6.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27081', 'examples_per_second': '4.4251', 'grad_norm': '5.1562', 'counters/examples': 190976, 'counters/updates': 11936}
skipping logging after 190992 examples to avoid logging too frequently
skipping logging after 191008 examples to avoid logging too frequently
skipping logging after 191024 examples to avoid logging too frequently
train stats after 191040 examples: {'rewards_train/chosen': '0.51038', 'rewards_train/rejected': '-5.2454', 'rewards_train/margins': '5.7734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22443', 'examples_per_second': '6.4119', 'grad_norm': '4.8438', 'counters/examples': 191040, 'counters/updates': 11940}
skipping logging after 191056 examples to avoid logging too frequently
skipping logging after 191072 examples to avoid logging too frequently
skipping logging after 191088 examples to avoid logging too frequently
train stats after 191104 examples: {'rewards_train/chosen': '0.32368', 'rewards_train/rejected': '-5.7975', 'rewards_train/margins': '6.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26282', 'examples_per_second': '6.1078', 'grad_norm': '5.2188', 'counters/examples': 191104, 'counters/updates': 11944}
skipping logging after 191120 examples to avoid logging too frequently
skipping logging after 191136 examples to avoid logging too frequently
skipping logging after 191152 examples to avoid logging too frequently
train stats after 191168 examples: {'rewards_train/chosen': '0.71267', 'rewards_train/rejected': '-5.6559', 'rewards_train/margins': '6.3203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23151', 'examples_per_second': '4.992', 'grad_norm': '5.7188', 'counters/examples': 191168, 'counters/updates': 11948}
skipping logging after 191184 examples to avoid logging too frequently
skipping logging after 191200 examples to avoid logging too frequently
skipping logging after 191216 examples to avoid logging too frequently
train stats after 191232 examples: {'rewards_train/chosen': '0.22131', 'rewards_train/rejected': '-4.8886', 'rewards_train/margins': '5.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24359', 'examples_per_second': '5.5816', 'grad_norm': '4.7188', 'counters/examples': 191232, 'counters/updates': 11952}
skipping logging after 191248 examples to avoid logging too frequently
skipping logging after 191264 examples to avoid logging too frequently
skipping logging after 191280 examples to avoid logging too frequently
train stats after 191296 examples: {'rewards_train/chosen': '0.316', 'rewards_train/rejected': '-4.7768', 'rewards_train/margins': '5.125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24677', 'examples_per_second': '5.4317', 'grad_norm': '5.4688', 'counters/examples': 191296, 'counters/updates': 11956}
skipping logging after 191312 examples to avoid logging too frequently
skipping logging after 191328 examples to avoid logging too frequently
skipping logging after 191344 examples to avoid logging too frequently
train stats after 191360 examples: {'rewards_train/chosen': '0.19014', 'rewards_train/rejected': '-5.9151', 'rewards_train/margins': '6.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22119', 'examples_per_second': '5.2826', 'grad_norm': '4.0938', 'counters/examples': 191360, 'counters/updates': 11960}
skipping logging after 191376 examples to avoid logging too frequently
skipping logging after 191392 examples to avoid logging too frequently
skipping logging after 191408 examples to avoid logging too frequently
train stats after 191424 examples: {'rewards_train/chosen': '0.59243', 'rewards_train/rejected': '-7.0343', 'rewards_train/margins': '7.9375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21429', 'examples_per_second': '5.0916', 'grad_norm': '5.6875', 'counters/examples': 191424, 'counters/updates': 11964}
skipping logging after 191440 examples to avoid logging too frequently
skipping logging after 191456 examples to avoid logging too frequently
skipping logging after 191472 examples to avoid logging too frequently
train stats after 191488 examples: {'rewards_train/chosen': '0.30236', 'rewards_train/rejected': '-6.8121', 'rewards_train/margins': '7.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20557', 'examples_per_second': '4.9555', 'grad_norm': '5.75', 'counters/examples': 191488, 'counters/updates': 11968}
skipping logging after 191504 examples to avoid logging too frequently
skipping logging after 191520 examples to avoid logging too frequently
skipping logging after 191536 examples to avoid logging too frequently
train stats after 191552 examples: {'rewards_train/chosen': '0.24925', 'rewards_train/rejected': '-7.0687', 'rewards_train/margins': '6.8477', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30713', 'examples_per_second': '4.8248', 'grad_norm': '5.5938', 'counters/examples': 191552, 'counters/updates': 11972}
skipping logging after 191568 examples to avoid logging too frequently
skipping logging after 191584 examples to avoid logging too frequently
skipping logging after 191600 examples to avoid logging too frequently
train stats after 191616 examples: {'rewards_train/chosen': '0.65726', 'rewards_train/rejected': '-5.4791', 'rewards_train/margins': '6.1719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21411', 'examples_per_second': '5.3292', 'grad_norm': '4.9688', 'counters/examples': 191616, 'counters/updates': 11976}
skipping logging after 191632 examples to avoid logging too frequently
skipping logging after 191648 examples to avoid logging too frequently
skipping logging after 191664 examples to avoid logging too frequently
train stats after 191680 examples: {'rewards_train/chosen': '0.80036', 'rewards_train/rejected': '-5.4271', 'rewards_train/margins': '6.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20782', 'examples_per_second': '5.1099', 'grad_norm': '5.375', 'counters/examples': 191680, 'counters/updates': 11980}
skipping logging after 191696 examples to avoid logging too frequently
skipping logging after 191712 examples to avoid logging too frequently
skipping logging after 191728 examples to avoid logging too frequently
train stats after 191744 examples: {'rewards_train/chosen': '0.3739', 'rewards_train/rejected': '-5.8751', 'rewards_train/margins': '6.1875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22772', 'examples_per_second': '6.0523', 'grad_norm': '5.8125', 'counters/examples': 191744, 'counters/updates': 11984}
skipping logging after 191760 examples to avoid logging too frequently
skipping logging after 191776 examples to avoid logging too frequently
skipping logging after 191792 examples to avoid logging too frequently
train stats after 191808 examples: {'rewards_train/chosen': '0.2769', 'rewards_train/rejected': '-4.5675', 'rewards_train/margins': '4.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27191', 'examples_per_second': '4.955', 'grad_norm': '5.625', 'counters/examples': 191808, 'counters/updates': 11988}
skipping logging after 191824 examples to avoid logging too frequently
skipping logging after 191840 examples to avoid logging too frequently
skipping logging after 191856 examples to avoid logging too frequently
train stats after 191872 examples: {'rewards_train/chosen': '0.30793', 'rewards_train/rejected': '-7.9509', 'rewards_train/margins': '8.125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21783', 'examples_per_second': '4.5588', 'grad_norm': '5.1562', 'counters/examples': 191872, 'counters/updates': 11992}
skipping logging after 191888 examples to avoid logging too frequently
skipping logging after 191904 examples to avoid logging too frequently
skipping logging after 191920 examples to avoid logging too frequently
train stats after 191936 examples: {'rewards_train/chosen': '0.25827', 'rewards_train/rejected': '-5.4384', 'rewards_train/margins': '5.9141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24213', 'examples_per_second': '5.9201', 'grad_norm': '5.375', 'counters/examples': 191936, 'counters/updates': 11996}
skipping logging after 191952 examples to avoid logging too frequently
skipping logging after 191968 examples to avoid logging too frequently
skipping logging after 191984 examples to avoid logging too frequently
train stats after 192000 examples: {'rewards_train/chosen': '0.074207', 'rewards_train/rejected': '-7.1445', 'rewards_train/margins': '7.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26434', 'examples_per_second': '4.6418', 'grad_norm': '5.625', 'counters/examples': 192000, 'counters/updates': 12000}
Running evaluation after 192000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.26s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.17s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:39,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.65s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.47s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:33,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.51s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:33,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.40s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:30,  1.47s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:21<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:12,  1.44s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.31s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.20s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]
eval after 192000: {'rewards_eval/chosen': '-5.5447', 'rewards_eval/rejected': '-6.1569', 'rewards_eval/margins': '0.45166', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.4569'}
skipping logging after 192016 examples to avoid logging too frequently
skipping logging after 192032 examples to avoid logging too frequently
skipping logging after 192048 examples to avoid logging too frequently
train stats after 192064 examples: {'rewards_train/chosen': '0.26984', 'rewards_train/rejected': '-4.5989', 'rewards_train/margins': '4.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29163', 'examples_per_second': '5.8275', 'grad_norm': '5.25', 'counters/examples': 192064, 'counters/updates': 12004}
skipping logging after 192080 examples to avoid logging too frequently
skipping logging after 192096 examples to avoid logging too frequently
skipping logging after 192112 examples to avoid logging too frequently
train stats after 192128 examples: {'rewards_train/chosen': '0.29506', 'rewards_train/rejected': '-5.4329', 'rewards_train/margins': '5.4531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22015', 'examples_per_second': '5.5602', 'grad_norm': '4.4375', 'counters/examples': 192128, 'counters/updates': 12008}
skipping logging after 192144 examples to avoid logging too frequently
skipping logging after 192160 examples to avoid logging too frequently
skipping logging after 192176 examples to avoid logging too frequently
train stats after 192192 examples: {'rewards_train/chosen': '0.49639', 'rewards_train/rejected': '-8.1295', 'rewards_train/margins': '8.6484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22211', 'examples_per_second': '4.3333', 'grad_norm': '4.875', 'counters/examples': 192192, 'counters/updates': 12012}
skipping logging after 192208 examples to avoid logging too frequently
skipping logging after 192224 examples to avoid logging too frequently
skipping logging after 192240 examples to avoid logging too frequently
train stats after 192256 examples: {'rewards_train/chosen': '0.097472', 'rewards_train/rejected': '-6.0575', 'rewards_train/margins': '6.0117', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2663', 'examples_per_second': '5.1327', 'grad_norm': '4.9688', 'counters/examples': 192256, 'counters/updates': 12016}
skipping logging after 192272 examples to avoid logging too frequently
skipping logging after 192288 examples to avoid logging too frequently
skipping logging after 192304 examples to avoid logging too frequently
train stats after 192320 examples: {'rewards_train/chosen': '0.59173', 'rewards_train/rejected': '-5.3126', 'rewards_train/margins': '6.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23639', 'examples_per_second': '5.5083', 'grad_norm': '4.9062', 'counters/examples': 192320, 'counters/updates': 12020}
skipping logging after 192336 examples to avoid logging too frequently
skipping logging after 192352 examples to avoid logging too frequently
skipping logging after 192368 examples to avoid logging too frequently
train stats after 192384 examples: {'rewards_train/chosen': '0.48309', 'rewards_train/rejected': '-5.4991', 'rewards_train/margins': '5.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23181', 'examples_per_second': '5.5253', 'grad_norm': '4.6562', 'counters/examples': 192384, 'counters/updates': 12024}
skipping logging after 192400 examples to avoid logging too frequently
skipping logging after 192416 examples to avoid logging too frequently
skipping logging after 192432 examples to avoid logging too frequently
train stats after 192448 examples: {'rewards_train/chosen': '0.17318', 'rewards_train/rejected': '-8.3179', 'rewards_train/margins': '8.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25702', 'examples_per_second': '5.5641', 'grad_norm': '4.9688', 'counters/examples': 192448, 'counters/updates': 12028}
skipping logging after 192464 examples to avoid logging too frequently
skipping logging after 192480 examples to avoid logging too frequently
skipping logging after 192496 examples to avoid logging too frequently
train stats after 192512 examples: {'rewards_train/chosen': '0.51414', 'rewards_train/rejected': '-6.2871', 'rewards_train/margins': '6.7891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21362', 'examples_per_second': '5.1813', 'grad_norm': '5.375', 'counters/examples': 192512, 'counters/updates': 12032}
skipping logging after 192528 examples to avoid logging too frequently
skipping logging after 192544 examples to avoid logging too frequently
skipping logging after 192560 examples to avoid logging too frequently
train stats after 192576 examples: {'rewards_train/chosen': '0.51133', 'rewards_train/rejected': '-5.3547', 'rewards_train/margins': '5.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2431', 'examples_per_second': '4.7436', 'grad_norm': '4.9062', 'counters/examples': 192576, 'counters/updates': 12036}
skipping logging after 192592 examples to avoid logging too frequently
skipping logging after 192608 examples to avoid logging too frequently
skipping logging after 192624 examples to avoid logging too frequently
train stats after 192640 examples: {'rewards_train/chosen': '0.2241', 'rewards_train/rejected': '-5.4042', 'rewards_train/margins': '5.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30042', 'examples_per_second': '5.1', 'grad_norm': '5.0938', 'counters/examples': 192640, 'counters/updates': 12040}
skipping logging after 192656 examples to avoid logging too frequently
skipping logging after 192672 examples to avoid logging too frequently
skipping logging after 192688 examples to avoid logging too frequently
train stats after 192704 examples: {'rewards_train/chosen': '0.43235', 'rewards_train/rejected': '-7.8409', 'rewards_train/margins': '8.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27777', 'examples_per_second': '5.2681', 'grad_norm': '5.5', 'counters/examples': 192704, 'counters/updates': 12044}
skipping logging after 192720 examples to avoid logging too frequently
skipping logging after 192736 examples to avoid logging too frequently
skipping logging after 192752 examples to avoid logging too frequently
train stats after 192768 examples: {'rewards_train/chosen': '0.23772', 'rewards_train/rejected': '-4.5504', 'rewards_train/margins': '4.8398', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2605', 'examples_per_second': '5.3279', 'grad_norm': '4.625', 'counters/examples': 192768, 'counters/updates': 12048}
skipping logging after 192784 examples to avoid logging too frequently
skipping logging after 192800 examples to avoid logging too frequently
skipping logging after 192816 examples to avoid logging too frequently
train stats after 192832 examples: {'rewards_train/chosen': '0.27681', 'rewards_train/rejected': '-5.7421', 'rewards_train/margins': '6.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23279', 'examples_per_second': '5.8032', 'grad_norm': '4.875', 'counters/examples': 192832, 'counters/updates': 12052}
skipping logging after 192848 examples to avoid logging too frequently
skipping logging after 192864 examples to avoid logging too frequently
skipping logging after 192880 examples to avoid logging too frequently
train stats after 192896 examples: {'rewards_train/chosen': '0.10096', 'rewards_train/rejected': '-6.6959', 'rewards_train/margins': '6.9375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24365', 'examples_per_second': '4.7801', 'grad_norm': '5.5', 'counters/examples': 192896, 'counters/updates': 12056}
skipping logging after 192912 examples to avoid logging too frequently
skipping logging after 192928 examples to avoid logging too frequently
skipping logging after 192944 examples to avoid logging too frequently
train stats after 192960 examples: {'rewards_train/chosen': '0.62213', 'rewards_train/rejected': '-6.4199', 'rewards_train/margins': '7.0234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21564', 'examples_per_second': '4.0248', 'grad_norm': '4.2188', 'counters/examples': 192960, 'counters/updates': 12060}
skipping logging after 192976 examples to avoid logging too frequently
skipping logging after 192992 examples to avoid logging too frequently
skipping logging after 193008 examples to avoid logging too frequently
train stats after 193024 examples: {'rewards_train/chosen': '0.36123', 'rewards_train/rejected': '-4.6649', 'rewards_train/margins': '5.0117', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22327', 'examples_per_second': '4.2076', 'grad_norm': '5.25', 'counters/examples': 193024, 'counters/updates': 12064}
skipping logging after 193040 examples to avoid logging too frequently
skipping logging after 193056 examples to avoid logging too frequently
skipping logging after 193072 examples to avoid logging too frequently
train stats after 193088 examples: {'rewards_train/chosen': '0.48824', 'rewards_train/rejected': '-5.1049', 'rewards_train/margins': '5.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24469', 'examples_per_second': '5.2882', 'grad_norm': '6.0938', 'counters/examples': 193088, 'counters/updates': 12068}
skipping logging after 193104 examples to avoid logging too frequently
skipping logging after 193120 examples to avoid logging too frequently
skipping logging after 193136 examples to avoid logging too frequently
train stats after 193152 examples: {'rewards_train/chosen': '0.30739', 'rewards_train/rejected': '-5.1623', 'rewards_train/margins': '5.3828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23846', 'examples_per_second': '6.0104', 'grad_norm': '4.6562', 'counters/examples': 193152, 'counters/updates': 12072}
skipping logging after 193168 examples to avoid logging too frequently
skipping logging after 193184 examples to avoid logging too frequently
skipping logging after 193200 examples to avoid logging too frequently
train stats after 193216 examples: {'rewards_train/chosen': '0.24278', 'rewards_train/rejected': '-5.1815', 'rewards_train/margins': '5.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27417', 'examples_per_second': '4.7664', 'grad_norm': '5.5625', 'counters/examples': 193216, 'counters/updates': 12076}
skipping logging after 193232 examples to avoid logging too frequently
skipping logging after 193248 examples to avoid logging too frequently
skipping logging after 193264 examples to avoid logging too frequently
train stats after 193280 examples: {'rewards_train/chosen': '-0.015304', 'rewards_train/rejected': '-5.9419', 'rewards_train/margins': '5.5742', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30591', 'examples_per_second': '6.0884', 'grad_norm': '5.4062', 'counters/examples': 193280, 'counters/updates': 12080}
skipping logging after 193296 examples to avoid logging too frequently
skipping logging after 193312 examples to avoid logging too frequently
skipping logging after 193328 examples to avoid logging too frequently
train stats after 193344 examples: {'rewards_train/chosen': '0.53724', 'rewards_train/rejected': '-5.8284', 'rewards_train/margins': '6.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2392', 'examples_per_second': '5.4807', 'grad_norm': '5.5625', 'counters/examples': 193344, 'counters/updates': 12084}
skipping logging after 193360 examples to avoid logging too frequently
skipping logging after 193376 examples to avoid logging too frequently
skipping logging after 193392 examples to avoid logging too frequently
train stats after 193408 examples: {'rewards_train/chosen': '0.17802', 'rewards_train/rejected': '-5.7999', 'rewards_train/margins': '6.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24243', 'examples_per_second': '5.7853', 'grad_norm': '5.1875', 'counters/examples': 193408, 'counters/updates': 12088}
skipping logging after 193424 examples to avoid logging too frequently
skipping logging after 193440 examples to avoid logging too frequently
skipping logging after 193456 examples to avoid logging too frequently
train stats after 193472 examples: {'rewards_train/chosen': '0.40851', 'rewards_train/rejected': '-5.713', 'rewards_train/margins': '5.4883', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27936', 'examples_per_second': '4.8259', 'grad_norm': '5.0625', 'counters/examples': 193472, 'counters/updates': 12092}
skipping logging after 193488 examples to avoid logging too frequently
skipping logging after 193504 examples to avoid logging too frequently
skipping logging after 193520 examples to avoid logging too frequently
train stats after 193536 examples: {'rewards_train/chosen': '0.53859', 'rewards_train/rejected': '-7.0418', 'rewards_train/margins': '7.9141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21411', 'examples_per_second': '5.9856', 'grad_norm': '5.4062', 'counters/examples': 193536, 'counters/updates': 12096}
skipping logging after 193552 examples to avoid logging too frequently
skipping logging after 193568 examples to avoid logging too frequently
skipping logging after 193584 examples to avoid logging too frequently
train stats after 193600 examples: {'rewards_train/chosen': '0.71445', 'rewards_train/rejected': '-6.2022', 'rewards_train/margins': '6.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19318', 'examples_per_second': '5.1616', 'grad_norm': '4.25', 'counters/examples': 193600, 'counters/updates': 12100}
skipping logging after 193616 examples to avoid logging too frequently
skipping logging after 193632 examples to avoid logging too frequently
skipping logging after 193648 examples to avoid logging too frequently
train stats after 193664 examples: {'rewards_train/chosen': '0.28193', 'rewards_train/rejected': '-7.064', 'rewards_train/margins': '7.4141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19226', 'examples_per_second': '4.7191', 'grad_norm': '4.3125', 'counters/examples': 193664, 'counters/updates': 12104}
skipping logging after 193680 examples to avoid logging too frequently
skipping logging after 193696 examples to avoid logging too frequently
skipping logging after 193712 examples to avoid logging too frequently
train stats after 193728 examples: {'rewards_train/chosen': '0.2515', 'rewards_train/rejected': '-5.024', 'rewards_train/margins': '5.2969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27002', 'examples_per_second': '5.3563', 'grad_norm': '5.0625', 'counters/examples': 193728, 'counters/updates': 12108}
skipping logging after 193744 examples to avoid logging too frequently
skipping logging after 193760 examples to avoid logging too frequently
skipping logging after 193776 examples to avoid logging too frequently
train stats after 193792 examples: {'rewards_train/chosen': '0.44839', 'rewards_train/rejected': '-7.2937', 'rewards_train/margins': '7.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20825', 'examples_per_second': '5.0341', 'grad_norm': '5.7188', 'counters/examples': 193792, 'counters/updates': 12112}
skipping logging after 193808 examples to avoid logging too frequently
skipping logging after 193824 examples to avoid logging too frequently
skipping logging after 193840 examples to avoid logging too frequently
train stats after 193856 examples: {'rewards_train/chosen': '0.093445', 'rewards_train/rejected': '-5.0939', 'rewards_train/margins': '4.8398', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25812', 'examples_per_second': '4.6896', 'grad_norm': '4.6875', 'counters/examples': 193856, 'counters/updates': 12116}
skipping logging after 193872 examples to avoid logging too frequently
skipping logging after 193888 examples to avoid logging too frequently
skipping logging after 193904 examples to avoid logging too frequently
train stats after 193920 examples: {'rewards_train/chosen': '0.61779', 'rewards_train/rejected': '-7.5328', 'rewards_train/margins': '8.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22388', 'examples_per_second': '5.563', 'grad_norm': '5.0938', 'counters/examples': 193920, 'counters/updates': 12120}
skipping logging after 193936 examples to avoid logging too frequently
skipping logging after 193952 examples to avoid logging too frequently
skipping logging after 193968 examples to avoid logging too frequently
train stats after 193984 examples: {'rewards_train/chosen': '0.3195', 'rewards_train/rejected': '-6.2654', 'rewards_train/margins': '7.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26007', 'examples_per_second': '4.38', 'grad_norm': '5.25', 'counters/examples': 193984, 'counters/updates': 12124}
skipping logging after 194000 examples to avoid logging too frequently
skipping logging after 194016 examples to avoid logging too frequently
skipping logging after 194032 examples to avoid logging too frequently
train stats after 194048 examples: {'rewards_train/chosen': '0.2884', 'rewards_train/rejected': '-5.7513', 'rewards_train/margins': '5.9141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2392', 'examples_per_second': '4.5851', 'grad_norm': '5.75', 'counters/examples': 194048, 'counters/updates': 12128}
skipping logging after 194064 examples to avoid logging too frequently
skipping logging after 194080 examples to avoid logging too frequently
skipping logging after 194096 examples to avoid logging too frequently
train stats after 194112 examples: {'rewards_train/chosen': '0.28711', 'rewards_train/rejected': '-6.5437', 'rewards_train/margins': '6.6016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22479', 'examples_per_second': '4.6673', 'grad_norm': '4.4062', 'counters/examples': 194112, 'counters/updates': 12132}
skipping logging after 194128 examples to avoid logging too frequently
skipping logging after 194144 examples to avoid logging too frequently
skipping logging after 194160 examples to avoid logging too frequently
train stats after 194176 examples: {'rewards_train/chosen': '0.12942', 'rewards_train/rejected': '-6.5222', 'rewards_train/margins': '6.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29443', 'examples_per_second': '5.1433', 'grad_norm': '5.4688', 'counters/examples': 194176, 'counters/updates': 12136}
skipping logging after 194192 examples to avoid logging too frequently
skipping logging after 194208 examples to avoid logging too frequently
skipping logging after 194224 examples to avoid logging too frequently
train stats after 194240 examples: {'rewards_train/chosen': '0.55748', 'rewards_train/rejected': '-5.8435', 'rewards_train/margins': '6.4844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18005', 'examples_per_second': '4.901', 'grad_norm': '3.7656', 'counters/examples': 194240, 'counters/updates': 12140}
skipping logging after 194256 examples to avoid logging too frequently
skipping logging after 194272 examples to avoid logging too frequently
skipping logging after 194288 examples to avoid logging too frequently
train stats after 194304 examples: {'rewards_train/chosen': '0.44885', 'rewards_train/rejected': '-4.785', 'rewards_train/margins': '4.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26752', 'examples_per_second': '6.0466', 'grad_norm': '5.5938', 'counters/examples': 194304, 'counters/updates': 12144}
skipping logging after 194320 examples to avoid logging too frequently
skipping logging after 194336 examples to avoid logging too frequently
skipping logging after 194352 examples to avoid logging too frequently
train stats after 194368 examples: {'rewards_train/chosen': '0.45568', 'rewards_train/rejected': '-5.4615', 'rewards_train/margins': '5.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20929', 'examples_per_second': '5.7811', 'grad_norm': '5.5312', 'counters/examples': 194368, 'counters/updates': 12148}
skipping logging after 194384 examples to avoid logging too frequently
skipping logging after 194400 examples to avoid logging too frequently
skipping logging after 194416 examples to avoid logging too frequently
train stats after 194432 examples: {'rewards_train/chosen': '0.33572', 'rewards_train/rejected': '-5.6462', 'rewards_train/margins': '6.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21344', 'examples_per_second': '4.3047', 'grad_norm': '6.4062', 'counters/examples': 194432, 'counters/updates': 12152}
skipping logging after 194448 examples to avoid logging too frequently
skipping logging after 194464 examples to avoid logging too frequently
skipping logging after 194480 examples to avoid logging too frequently
train stats after 194496 examples: {'rewards_train/chosen': '0.52115', 'rewards_train/rejected': '-7.7936', 'rewards_train/margins': '8.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21869', 'examples_per_second': '5.2781', 'grad_norm': '4.8438', 'counters/examples': 194496, 'counters/updates': 12156}
skipping logging after 194512 examples to avoid logging too frequently
skipping logging after 194528 examples to avoid logging too frequently
skipping logging after 194544 examples to avoid logging too frequently
train stats after 194560 examples: {'rewards_train/chosen': '0.49716', 'rewards_train/rejected': '-6.4693', 'rewards_train/margins': '6.7578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22797', 'examples_per_second': '4.8229', 'grad_norm': '5.5938', 'counters/examples': 194560, 'counters/updates': 12160}
skipping logging after 194576 examples to avoid logging too frequently
skipping logging after 194592 examples to avoid logging too frequently
skipping logging after 194608 examples to avoid logging too frequently
train stats after 194624 examples: {'rewards_train/chosen': '0.13632', 'rewards_train/rejected': '-5.5369', 'rewards_train/margins': '5.7109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24493', 'examples_per_second': '5.4094', 'grad_norm': '4.9375', 'counters/examples': 194624, 'counters/updates': 12164}
skipping logging after 194640 examples to avoid logging too frequently
skipping logging after 194656 examples to avoid logging too frequently
skipping logging after 194672 examples to avoid logging too frequently
train stats after 194688 examples: {'rewards_train/chosen': '0.31043', 'rewards_train/rejected': '-4.7175', 'rewards_train/margins': '5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2309', 'examples_per_second': '6.7877', 'grad_norm': '4.9062', 'counters/examples': 194688, 'counters/updates': 12168}
skipping logging after 194704 examples to avoid logging too frequently
skipping logging after 194720 examples to avoid logging too frequently
skipping logging after 194736 examples to avoid logging too frequently
train stats after 194752 examples: {'rewards_train/chosen': '0.55381', 'rewards_train/rejected': '-6.4302', 'rewards_train/margins': '7.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17169', 'examples_per_second': '4.7678', 'grad_norm': '4.5', 'counters/examples': 194752, 'counters/updates': 12172}
skipping logging after 194768 examples to avoid logging too frequently
skipping logging after 194784 examples to avoid logging too frequently
skipping logging after 194800 examples to avoid logging too frequently
train stats after 194816 examples: {'rewards_train/chosen': '0.24456', 'rewards_train/rejected': '-6.0803', 'rewards_train/margins': '5.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22882', 'examples_per_second': '4.9089', 'grad_norm': '4.3438', 'counters/examples': 194816, 'counters/updates': 12176}
skipping logging after 194832 examples to avoid logging too frequently
skipping logging after 194848 examples to avoid logging too frequently
skipping logging after 194864 examples to avoid logging too frequently
train stats after 194880 examples: {'rewards_train/chosen': '0.16142', 'rewards_train/rejected': '-7.9617', 'rewards_train/margins': '8.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26324', 'examples_per_second': '5.7335', 'grad_norm': '4.7812', 'counters/examples': 194880, 'counters/updates': 12180}
skipping logging after 194896 examples to avoid logging too frequently
skipping logging after 194912 examples to avoid logging too frequently
skipping logging after 194928 examples to avoid logging too frequently
train stats after 194944 examples: {'rewards_train/chosen': '0.17057', 'rewards_train/rejected': '-6.8678', 'rewards_train/margins': '7.3594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25641', 'examples_per_second': '5.5727', 'grad_norm': '5.0625', 'counters/examples': 194944, 'counters/updates': 12184}
skipping logging after 194960 examples to avoid logging too frequently
skipping logging after 194976 examples to avoid logging too frequently
skipping logging after 194992 examples to avoid logging too frequently
train stats after 195008 examples: {'rewards_train/chosen': '0.15515', 'rewards_train/rejected': '-5.9097', 'rewards_train/margins': '6.0547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21881', 'examples_per_second': '5.6658', 'grad_norm': '5.0312', 'counters/examples': 195008, 'counters/updates': 12188}
skipping logging after 195024 examples to avoid logging too frequently
skipping logging after 195040 examples to avoid logging too frequently
skipping logging after 195056 examples to avoid logging too frequently
train stats after 195072 examples: {'rewards_train/chosen': '0.48361', 'rewards_train/rejected': '-6.3211', 'rewards_train/margins': '6.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2135', 'examples_per_second': '4.4399', 'grad_norm': '4.75', 'counters/examples': 195072, 'counters/updates': 12192}
skipping logging after 195088 examples to avoid logging too frequently
skipping logging after 195104 examples to avoid logging too frequently
skipping logging after 195120 examples to avoid logging too frequently
train stats after 195136 examples: {'rewards_train/chosen': '0.53538', 'rewards_train/rejected': '-6.102', 'rewards_train/margins': '6.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23853', 'examples_per_second': '4.6746', 'grad_norm': '5.125', 'counters/examples': 195136, 'counters/updates': 12196}
skipping logging after 195152 examples to avoid logging too frequently
skipping logging after 195168 examples to avoid logging too frequently
skipping logging after 195184 examples to avoid logging too frequently
train stats after 195200 examples: {'rewards_train/chosen': '-0.03219', 'rewards_train/rejected': '-6.2941', 'rewards_train/margins': '6.1719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27753', 'examples_per_second': '5.631', 'grad_norm': '4.75', 'counters/examples': 195200, 'counters/updates': 12200}
skipping logging after 195216 examples to avoid logging too frequently
skipping logging after 195232 examples to avoid logging too frequently
skipping logging after 195248 examples to avoid logging too frequently
train stats after 195264 examples: {'rewards_train/chosen': '0.15734', 'rewards_train/rejected': '-5.0938', 'rewards_train/margins': '5.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25189', 'examples_per_second': '5.8678', 'grad_norm': '5.1562', 'counters/examples': 195264, 'counters/updates': 12204}
skipping logging after 195280 examples to avoid logging too frequently
skipping logging after 195296 examples to avoid logging too frequently
skipping logging after 195312 examples to avoid logging too frequently
train stats after 195328 examples: {'rewards_train/chosen': '-0.057562', 'rewards_train/rejected': '-6.3668', 'rewards_train/margins': '6.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2489', 'examples_per_second': '5.8548', 'grad_norm': '5.1562', 'counters/examples': 195328, 'counters/updates': 12208}
skipping logging after 195344 examples to avoid logging too frequently
skipping logging after 195360 examples to avoid logging too frequently
skipping logging after 195376 examples to avoid logging too frequently
train stats after 195392 examples: {'rewards_train/chosen': '0.39654', 'rewards_train/rejected': '-4.7334', 'rewards_train/margins': '5.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21411', 'examples_per_second': '5.7381', 'grad_norm': '5.0312', 'counters/examples': 195392, 'counters/updates': 12212}
skipping logging after 195408 examples to avoid logging too frequently
skipping logging after 195424 examples to avoid logging too frequently
skipping logging after 195440 examples to avoid logging too frequently
train stats after 195456 examples: {'rewards_train/chosen': '0.33112', 'rewards_train/rejected': '-6.5714', 'rewards_train/margins': '6.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17285', 'examples_per_second': '4.3742', 'grad_norm': '4.4062', 'counters/examples': 195456, 'counters/updates': 12216}
skipping logging after 195472 examples to avoid logging too frequently
skipping logging after 195488 examples to avoid logging too frequently
skipping logging after 195504 examples to avoid logging too frequently
train stats after 195520 examples: {'rewards_train/chosen': '0.053187', 'rewards_train/rejected': '-7.6318', 'rewards_train/margins': '7.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25543', 'examples_per_second': '4.8431', 'grad_norm': '5.0938', 'counters/examples': 195520, 'counters/updates': 12220}
skipping logging after 195536 examples to avoid logging too frequently
skipping logging after 195552 examples to avoid logging too frequently
skipping logging after 195568 examples to avoid logging too frequently
train stats after 195584 examples: {'rewards_train/chosen': '0.29685', 'rewards_train/rejected': '-5.92', 'rewards_train/margins': '6.1875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25195', 'examples_per_second': '4.2276', 'grad_norm': '4.8125', 'counters/examples': 195584, 'counters/updates': 12224}
skipping logging after 195600 examples to avoid logging too frequently
skipping logging after 195616 examples to avoid logging too frequently
skipping logging after 195632 examples to avoid logging too frequently
train stats after 195648 examples: {'rewards_train/chosen': '0.37536', 'rewards_train/rejected': '-6.0488', 'rewards_train/margins': '6.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23193', 'examples_per_second': '5.0362', 'grad_norm': '4.7812', 'counters/examples': 195648, 'counters/updates': 12228}
skipping logging after 195664 examples to avoid logging too frequently
skipping logging after 195680 examples to avoid logging too frequently
skipping logging after 195696 examples to avoid logging too frequently
train stats after 195712 examples: {'rewards_train/chosen': '0.66206', 'rewards_train/rejected': '-5.8799', 'rewards_train/margins': '6.125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26843', 'examples_per_second': '4.5576', 'grad_norm': '5.3125', 'counters/examples': 195712, 'counters/updates': 12232}
skipping logging after 195728 examples to avoid logging too frequently
skipping logging after 195744 examples to avoid logging too frequently
skipping logging after 195760 examples to avoid logging too frequently
train stats after 195776 examples: {'rewards_train/chosen': '0.56171', 'rewards_train/rejected': '-6.6069', 'rewards_train/margins': '7.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19696', 'examples_per_second': '4.575', 'grad_norm': '5.0625', 'counters/examples': 195776, 'counters/updates': 12236}
skipping logging after 195792 examples to avoid logging too frequently
skipping logging after 195808 examples to avoid logging too frequently
skipping logging after 195824 examples to avoid logging too frequently
train stats after 195840 examples: {'rewards_train/chosen': '0.33859', 'rewards_train/rejected': '-5.8973', 'rewards_train/margins': '6.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22003', 'examples_per_second': '4.3329', 'grad_norm': '4.8438', 'counters/examples': 195840, 'counters/updates': 12240}
skipping logging after 195856 examples to avoid logging too frequently
skipping logging after 195872 examples to avoid logging too frequently
skipping logging after 195888 examples to avoid logging too frequently
train stats after 195904 examples: {'rewards_train/chosen': '0.30918', 'rewards_train/rejected': '-5.5539', 'rewards_train/margins': '5.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23749', 'examples_per_second': '5.4565', 'grad_norm': '4.3125', 'counters/examples': 195904, 'counters/updates': 12244}
skipping logging after 195920 examples to avoid logging too frequently
skipping logging after 195936 examples to avoid logging too frequently
skipping logging after 195952 examples to avoid logging too frequently
train stats after 195968 examples: {'rewards_train/chosen': '0.46727', 'rewards_train/rejected': '-6.3686', 'rewards_train/margins': '6.8203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25549', 'examples_per_second': '5.1371', 'grad_norm': '4.875', 'counters/examples': 195968, 'counters/updates': 12248}
skipping logging after 195984 examples to avoid logging too frequently
skipping logging after 196000 examples to avoid logging too frequently
Running evaluation after 196000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:50,  1.62s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:42,  1.41s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:36,  1.25s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.48s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.68s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.49s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:10<00:34,  1.37s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.31s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.18s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:41<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]
eval after 196000: {'rewards_eval/chosen': '-5.3665', 'rewards_eval/rejected': '-5.927', 'rewards_eval/margins': '0.40771', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.45786'}
skipping logging after 196016 examples to avoid logging too frequently
train stats after 196032 examples: {'rewards_train/chosen': '0.50203', 'rewards_train/rejected': '-5.251', 'rewards_train/margins': '5.6641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25092', 'examples_per_second': '6.1308', 'grad_norm': '4.25', 'counters/examples': 196032, 'counters/updates': 12252}
skipping logging after 196048 examples to avoid logging too frequently
skipping logging after 196064 examples to avoid logging too frequently
skipping logging after 196080 examples to avoid logging too frequently
train stats after 196096 examples: {'rewards_train/chosen': '0.35235', 'rewards_train/rejected': '-6.7069', 'rewards_train/margins': '7.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21826', 'examples_per_second': '4.3678', 'grad_norm': '5.9062', 'counters/examples': 196096, 'counters/updates': 12256}
skipping logging after 196112 examples to avoid logging too frequently
skipping logging after 196128 examples to avoid logging too frequently
skipping logging after 196144 examples to avoid logging too frequently
train stats after 196160 examples: {'rewards_train/chosen': '-0.088313', 'rewards_train/rejected': '-4.9036', 'rewards_train/margins': '4.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24298', 'examples_per_second': '5.7418', 'grad_norm': '5', 'counters/examples': 196160, 'counters/updates': 12260}
skipping logging after 196176 examples to avoid logging too frequently
skipping logging after 196192 examples to avoid logging too frequently
skipping logging after 196208 examples to avoid logging too frequently
train stats after 196224 examples: {'rewards_train/chosen': '0.50818', 'rewards_train/rejected': '-6.593', 'rewards_train/margins': '7.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21045', 'examples_per_second': '5.0307', 'grad_norm': '4.75', 'counters/examples': 196224, 'counters/updates': 12264}
skipping logging after 196240 examples to avoid logging too frequently
skipping logging after 196256 examples to avoid logging too frequently
skipping logging after 196272 examples to avoid logging too frequently
train stats after 196288 examples: {'rewards_train/chosen': '0.24592', 'rewards_train/rejected': '-5.3481', 'rewards_train/margins': '5.6328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21692', 'examples_per_second': '5.5994', 'grad_norm': '4.4375', 'counters/examples': 196288, 'counters/updates': 12268}
skipping logging after 196304 examples to avoid logging too frequently
skipping logging after 196320 examples to avoid logging too frequently
skipping logging after 196336 examples to avoid logging too frequently
train stats after 196352 examples: {'rewards_train/chosen': '0.42287', 'rewards_train/rejected': '-5.716', 'rewards_train/margins': '5.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22748', 'examples_per_second': '4.0808', 'grad_norm': '4.625', 'counters/examples': 196352, 'counters/updates': 12272}
skipping logging after 196368 examples to avoid logging too frequently
skipping logging after 196384 examples to avoid logging too frequently
skipping logging after 196400 examples to avoid logging too frequently
train stats after 196416 examples: {'rewards_train/chosen': '0.45674', 'rewards_train/rejected': '-7.0884', 'rewards_train/margins': '7.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21497', 'examples_per_second': '4.7919', 'grad_norm': '5.1875', 'counters/examples': 196416, 'counters/updates': 12276}
skipping logging after 196432 examples to avoid logging too frequently
skipping logging after 196448 examples to avoid logging too frequently
skipping logging after 196464 examples to avoid logging too frequently
train stats after 196480 examples: {'rewards_train/chosen': '0.24802', 'rewards_train/rejected': '-6.3252', 'rewards_train/margins': '6.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20496', 'examples_per_second': '4.328', 'grad_norm': '5.0938', 'counters/examples': 196480, 'counters/updates': 12280}
skipping logging after 196496 examples to avoid logging too frequently
skipping logging after 196512 examples to avoid logging too frequently
skipping logging after 196528 examples to avoid logging too frequently
train stats after 196544 examples: {'rewards_train/chosen': '0.50095', 'rewards_train/rejected': '-7.0091', 'rewards_train/margins': '7.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20721', 'examples_per_second': '5.1577', 'grad_norm': '4.7188', 'counters/examples': 196544, 'counters/updates': 12284}
skipping logging after 196560 examples to avoid logging too frequently
skipping logging after 196576 examples to avoid logging too frequently
skipping logging after 196592 examples to avoid logging too frequently
train stats after 196608 examples: {'rewards_train/chosen': '0.0015407', 'rewards_train/rejected': '-7.0631', 'rewards_train/margins': '7.6484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2464', 'examples_per_second': '4.3474', 'grad_norm': '4.9688', 'counters/examples': 196608, 'counters/updates': 12288}
skipping logging after 196624 examples to avoid logging too frequently
skipping logging after 196640 examples to avoid logging too frequently
skipping logging after 196656 examples to avoid logging too frequently
train stats after 196672 examples: {'rewards_train/chosen': '-0.024005', 'rewards_train/rejected': '-4.1785', 'rewards_train/margins': '4.1289', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28601', 'examples_per_second': '5.4823', 'grad_norm': '4.4688', 'counters/examples': 196672, 'counters/updates': 12292}
skipping logging after 196688 examples to avoid logging too frequently
skipping logging after 196704 examples to avoid logging too frequently
skipping logging after 196720 examples to avoid logging too frequently
train stats after 196736 examples: {'rewards_train/chosen': '0.12384', 'rewards_train/rejected': '-5.7714', 'rewards_train/margins': '5.6562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.3056', 'examples_per_second': '5.3992', 'grad_norm': '6.5312', 'counters/examples': 196736, 'counters/updates': 12296}
skipping logging after 196752 examples to avoid logging too frequently
skipping logging after 196768 examples to avoid logging too frequently
skipping logging after 196784 examples to avoid logging too frequently
train stats after 196800 examples: {'rewards_train/chosen': '0.28629', 'rewards_train/rejected': '-6.2002', 'rewards_train/margins': '6.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.3147', 'examples_per_second': '5.0968', 'grad_norm': '5.6875', 'counters/examples': 196800, 'counters/updates': 12300}
skipping logging after 196816 examples to avoid logging too frequently
skipping logging after 196832 examples to avoid logging too frequently
skipping logging after 196848 examples to avoid logging too frequently
train stats after 196864 examples: {'rewards_train/chosen': '0.27367', 'rewards_train/rejected': '-5.8932', 'rewards_train/margins': '6.1172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20978', 'examples_per_second': '4.7651', 'grad_norm': '3.9844', 'counters/examples': 196864, 'counters/updates': 12304}
skipping logging after 196880 examples to avoid logging too frequently
skipping logging after 196896 examples to avoid logging too frequently
skipping logging after 196912 examples to avoid logging too frequently
train stats after 196928 examples: {'rewards_train/chosen': '0.24835', 'rewards_train/rejected': '-6.3707', 'rewards_train/margins': '6.5039', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22925', 'examples_per_second': '4.6095', 'grad_norm': '4.5938', 'counters/examples': 196928, 'counters/updates': 12308}
skipping logging after 196944 examples to avoid logging too frequently
skipping logging after 196960 examples to avoid logging too frequently
skipping logging after 196976 examples to avoid logging too frequently
train stats after 196992 examples: {'rewards_train/chosen': '0.63982', 'rewards_train/rejected': '-5.4103', 'rewards_train/margins': '6.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22418', 'examples_per_second': '5.3195', 'grad_norm': '5.6562', 'counters/examples': 196992, 'counters/updates': 12312}
skipping logging after 197008 examples to avoid logging too frequently
skipping logging after 197024 examples to avoid logging too frequently
skipping logging after 197040 examples to avoid logging too frequently
train stats after 197056 examples: {'rewards_train/chosen': '0.18301', 'rewards_train/rejected': '-5.9445', 'rewards_train/margins': '6.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21558', 'examples_per_second': '5.2209', 'grad_norm': '4', 'counters/examples': 197056, 'counters/updates': 12316}
skipping logging after 197072 examples to avoid logging too frequently
skipping logging after 197088 examples to avoid logging too frequently
skipping logging after 197104 examples to avoid logging too frequently
train stats after 197120 examples: {'rewards_train/chosen': '0.28128', 'rewards_train/rejected': '-6.0193', 'rewards_train/margins': '6.2266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22827', 'examples_per_second': '4.9763', 'grad_norm': '5.0625', 'counters/examples': 197120, 'counters/updates': 12320}
skipping logging after 197136 examples to avoid logging too frequently
skipping logging after 197152 examples to avoid logging too frequently
skipping logging after 197168 examples to avoid logging too frequently
train stats after 197184 examples: {'rewards_train/chosen': '0.43847', 'rewards_train/rejected': '-6.4437', 'rewards_train/margins': '6.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24512', 'examples_per_second': '4.9395', 'grad_norm': '5.3438', 'counters/examples': 197184, 'counters/updates': 12324}
skipping logging after 197200 examples to avoid logging too frequently
skipping logging after 197216 examples to avoid logging too frequently
skipping logging after 197232 examples to avoid logging too frequently
train stats after 197248 examples: {'rewards_train/chosen': '0.42364', 'rewards_train/rejected': '-6.4029', 'rewards_train/margins': '6.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24707', 'examples_per_second': '5.5043', 'grad_norm': '4.5', 'counters/examples': 197248, 'counters/updates': 12328}
skipping logging after 197264 examples to avoid logging too frequently
skipping logging after 197280 examples to avoid logging too frequently
skipping logging after 197296 examples to avoid logging too frequently
train stats after 197312 examples: {'rewards_train/chosen': '0.38241', 'rewards_train/rejected': '-6.6379', 'rewards_train/margins': '7.4219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2395', 'examples_per_second': '6.0298', 'grad_norm': '5.125', 'counters/examples': 197312, 'counters/updates': 12332}
skipping logging after 197328 examples to avoid logging too frequently
skipping logging after 197344 examples to avoid logging too frequently
skipping logging after 197360 examples to avoid logging too frequently
train stats after 197376 examples: {'rewards_train/chosen': '0.21133', 'rewards_train/rejected': '-4.5871', 'rewards_train/margins': '4.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2627', 'examples_per_second': '6.6862', 'grad_norm': '5', 'counters/examples': 197376, 'counters/updates': 12336}
skipping logging after 197392 examples to avoid logging too frequently
skipping logging after 197408 examples to avoid logging too frequently
skipping logging after 197424 examples to avoid logging too frequently
train stats after 197440 examples: {'rewards_train/chosen': '0.69025', 'rewards_train/rejected': '-7.2371', 'rewards_train/margins': '8', 'rewards_train/KL_estimate': '0', 'loss/train': '0.14587', 'examples_per_second': '4.0727', 'grad_norm': '4.125', 'counters/examples': 197440, 'counters/updates': 12340}
skipping logging after 197456 examples to avoid logging too frequently
skipping logging after 197472 examples to avoid logging too frequently
skipping logging after 197488 examples to avoid logging too frequently
train stats after 197504 examples: {'rewards_train/chosen': '0.49915', 'rewards_train/rejected': '-4.8592', 'rewards_train/margins': '5.2539', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21271', 'examples_per_second': '5.2475', 'grad_norm': '5.0312', 'counters/examples': 197504, 'counters/updates': 12344}
skipping logging after 197520 examples to avoid logging too frequently
skipping logging after 197536 examples to avoid logging too frequently
skipping logging after 197552 examples to avoid logging too frequently
train stats after 197568 examples: {'rewards_train/chosen': '0.13988', 'rewards_train/rejected': '-5.8164', 'rewards_train/margins': '6.1172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21771', 'examples_per_second': '4.4641', 'grad_norm': '5.4688', 'counters/examples': 197568, 'counters/updates': 12348}
skipping logging after 197584 examples to avoid logging too frequently
skipping logging after 197600 examples to avoid logging too frequently
skipping logging after 197616 examples to avoid logging too frequently
train stats after 197632 examples: {'rewards_train/chosen': '0.37475', 'rewards_train/rejected': '-5.452', 'rewards_train/margins': '6.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24274', 'examples_per_second': '4.3804', 'grad_norm': '5.2188', 'counters/examples': 197632, 'counters/updates': 12352}
skipping logging after 197648 examples to avoid logging too frequently
skipping logging after 197664 examples to avoid logging too frequently
skipping logging after 197680 examples to avoid logging too frequently
train stats after 197696 examples: {'rewards_train/chosen': '0.32557', 'rewards_train/rejected': '-6.6031', 'rewards_train/margins': '6.8828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25696', 'examples_per_second': '4.3568', 'grad_norm': '5', 'counters/examples': 197696, 'counters/updates': 12356}
skipping logging after 197712 examples to avoid logging too frequently
skipping logging after 197728 examples to avoid logging too frequently
skipping logging after 197744 examples to avoid logging too frequently
train stats after 197760 examples: {'rewards_train/chosen': '0.42067', 'rewards_train/rejected': '-5.5947', 'rewards_train/margins': '5.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22815', 'examples_per_second': '4.6685', 'grad_norm': '4.7812', 'counters/examples': 197760, 'counters/updates': 12360}
skipping logging after 197776 examples to avoid logging too frequently
skipping logging after 197792 examples to avoid logging too frequently
skipping logging after 197808 examples to avoid logging too frequently
train stats after 197824 examples: {'rewards_train/chosen': '0.54076', 'rewards_train/rejected': '-5.199', 'rewards_train/margins': '5.6562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19867', 'examples_per_second': '6.3368', 'grad_norm': '4.875', 'counters/examples': 197824, 'counters/updates': 12364}
skipping logging after 197840 examples to avoid logging too frequently
skipping logging after 197856 examples to avoid logging too frequently
skipping logging after 197872 examples to avoid logging too frequently
train stats after 197888 examples: {'rewards_train/chosen': '0.17095', 'rewards_train/rejected': '-7.3833', 'rewards_train/margins': '7.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24847', 'examples_per_second': '4.3573', 'grad_norm': '4.6875', 'counters/examples': 197888, 'counters/updates': 12368}
skipping logging after 197904 examples to avoid logging too frequently
skipping logging after 197920 examples to avoid logging too frequently
skipping logging after 197936 examples to avoid logging too frequently
train stats after 197952 examples: {'rewards_train/chosen': '0.41104', 'rewards_train/rejected': '-5.0911', 'rewards_train/margins': '5.4844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23883', 'examples_per_second': '5.0723', 'grad_norm': '5.9688', 'counters/examples': 197952, 'counters/updates': 12372}
skipping logging after 197968 examples to avoid logging too frequently
skipping logging after 197984 examples to avoid logging too frequently
skipping logging after 198000 examples to avoid logging too frequently
train stats after 198016 examples: {'rewards_train/chosen': '0.57211', 'rewards_train/rejected': '-5.1663', 'rewards_train/margins': '5.7656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22363', 'examples_per_second': '4.5169', 'grad_norm': '5.0312', 'counters/examples': 198016, 'counters/updates': 12376}
skipping logging after 198032 examples to avoid logging too frequently
skipping logging after 198048 examples to avoid logging too frequently
skipping logging after 198064 examples to avoid logging too frequently
train stats after 198080 examples: {'rewards_train/chosen': '0.044029', 'rewards_train/rejected': '-5.0055', 'rewards_train/margins': '4.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2887', 'examples_per_second': '5.5731', 'grad_norm': '5.9375', 'counters/examples': 198080, 'counters/updates': 12380}
skipping logging after 198096 examples to avoid logging too frequently
skipping logging after 198112 examples to avoid logging too frequently
skipping logging after 198128 examples to avoid logging too frequently
train stats after 198144 examples: {'rewards_train/chosen': '0.73362', 'rewards_train/rejected': '-5.1562', 'rewards_train/margins': '5.7812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17633', 'examples_per_second': '6.6172', 'grad_norm': '5.4062', 'counters/examples': 198144, 'counters/updates': 12384}
skipping logging after 198160 examples to avoid logging too frequently
skipping logging after 198176 examples to avoid logging too frequently
skipping logging after 198192 examples to avoid logging too frequently
train stats after 198208 examples: {'rewards_train/chosen': '0.5526', 'rewards_train/rejected': '-6.348', 'rewards_train/margins': '7.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20935', 'examples_per_second': '4.7492', 'grad_norm': '5.2812', 'counters/examples': 198208, 'counters/updates': 12388}
skipping logging after 198224 examples to avoid logging too frequently
skipping logging after 198240 examples to avoid logging too frequently
skipping logging after 198256 examples to avoid logging too frequently
train stats after 198272 examples: {'rewards_train/chosen': '0.34137', 'rewards_train/rejected': '-5.9258', 'rewards_train/margins': '6.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18127', 'examples_per_second': '4.7105', 'grad_norm': '4.6562', 'counters/examples': 198272, 'counters/updates': 12392}
skipping logging after 198288 examples to avoid logging too frequently
skipping logging after 198304 examples to avoid logging too frequently
skipping logging after 198320 examples to avoid logging too frequently
train stats after 198336 examples: {'rewards_train/chosen': '0.25958', 'rewards_train/rejected': '-4.759', 'rewards_train/margins': '5.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26593', 'examples_per_second': '4.7807', 'grad_norm': '4.8438', 'counters/examples': 198336, 'counters/updates': 12396}
skipping logging after 198352 examples to avoid logging too frequently
skipping logging after 198368 examples to avoid logging too frequently
skipping logging after 198384 examples to avoid logging too frequently
train stats after 198400 examples: {'rewards_train/chosen': '0.51497', 'rewards_train/rejected': '-7.2407', 'rewards_train/margins': '7.7656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17993', 'examples_per_second': '6.3918', 'grad_norm': '4.7812', 'counters/examples': 198400, 'counters/updates': 12400}
skipping logging after 198416 examples to avoid logging too frequently
skipping logging after 198432 examples to avoid logging too frequently
skipping logging after 198448 examples to avoid logging too frequently
train stats after 198464 examples: {'rewards_train/chosen': '-0.25086', 'rewards_train/rejected': '-5.9927', 'rewards_train/margins': '5.6094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26996', 'examples_per_second': '4.5705', 'grad_norm': '4.9688', 'counters/examples': 198464, 'counters/updates': 12404}
skipping logging after 198480 examples to avoid logging too frequently
skipping logging after 198496 examples to avoid logging too frequently
skipping logging after 198512 examples to avoid logging too frequently
train stats after 198528 examples: {'rewards_train/chosen': '0.18992', 'rewards_train/rejected': '-6.4448', 'rewards_train/margins': '6.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25629', 'examples_per_second': '5.5408', 'grad_norm': '5.0312', 'counters/examples': 198528, 'counters/updates': 12408}
skipping logging after 198544 examples to avoid logging too frequently
skipping logging after 198560 examples to avoid logging too frequently
skipping logging after 198576 examples to avoid logging too frequently
train stats after 198592 examples: {'rewards_train/chosen': '0.36911', 'rewards_train/rejected': '-5.9965', 'rewards_train/margins': '6.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26794', 'examples_per_second': '4.7942', 'grad_norm': '6.5', 'counters/examples': 198592, 'counters/updates': 12412}
skipping logging after 198608 examples to avoid logging too frequently
skipping logging after 198624 examples to avoid logging too frequently
skipping logging after 198640 examples to avoid logging too frequently
train stats after 198656 examples: {'rewards_train/chosen': '0.37259', 'rewards_train/rejected': '-7.0147', 'rewards_train/margins': '7.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26392', 'examples_per_second': '6.4062', 'grad_norm': '4.6875', 'counters/examples': 198656, 'counters/updates': 12416}
skipping logging after 198672 examples to avoid logging too frequently
skipping logging after 198688 examples to avoid logging too frequently
skipping logging after 198704 examples to avoid logging too frequently
train stats after 198720 examples: {'rewards_train/chosen': '0.055162', 'rewards_train/rejected': '-7.0444', 'rewards_train/margins': '7.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23438', 'examples_per_second': '5.6938', 'grad_norm': '4.5625', 'counters/examples': 198720, 'counters/updates': 12420}
skipping logging after 198736 examples to avoid logging too frequently
skipping logging after 198752 examples to avoid logging too frequently
skipping logging after 198768 examples to avoid logging too frequently
train stats after 198784 examples: {'rewards_train/chosen': '0.46133', 'rewards_train/rejected': '-5.6992', 'rewards_train/margins': '6.0547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24194', 'examples_per_second': '4.9212', 'grad_norm': '4.4062', 'counters/examples': 198784, 'counters/updates': 12424}
skipping logging after 198800 examples to avoid logging too frequently
skipping logging after 198816 examples to avoid logging too frequently
skipping logging after 198832 examples to avoid logging too frequently
train stats after 198848 examples: {'rewards_train/chosen': '0.42357', 'rewards_train/rejected': '-5.6888', 'rewards_train/margins': '6.4609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2392', 'examples_per_second': '5.3415', 'grad_norm': '5.4062', 'counters/examples': 198848, 'counters/updates': 12428}
skipping logging after 198864 examples to avoid logging too frequently
skipping logging after 198880 examples to avoid logging too frequently
skipping logging after 198896 examples to avoid logging too frequently
train stats after 198912 examples: {'rewards_train/chosen': '0.34823', 'rewards_train/rejected': '-5.5983', 'rewards_train/margins': '5.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21826', 'examples_per_second': '5.8101', 'grad_norm': '5.6562', 'counters/examples': 198912, 'counters/updates': 12432}
skipping logging after 198928 examples to avoid logging too frequently
skipping logging after 198944 examples to avoid logging too frequently
skipping logging after 198960 examples to avoid logging too frequently
train stats after 198976 examples: {'rewards_train/chosen': '0.40129', 'rewards_train/rejected': '-5.834', 'rewards_train/margins': '6.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25226', 'examples_per_second': '5.1512', 'grad_norm': '5.1562', 'counters/examples': 198976, 'counters/updates': 12436}
skipping logging after 198992 examples to avoid logging too frequently
skipping logging after 199008 examples to avoid logging too frequently
skipping logging after 199024 examples to avoid logging too frequently
train stats after 199040 examples: {'rewards_train/chosen': '0.12822', 'rewards_train/rejected': '-6.6661', 'rewards_train/margins': '6.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21057', 'examples_per_second': '4.5703', 'grad_norm': '4.875', 'counters/examples': 199040, 'counters/updates': 12440}
skipping logging after 199056 examples to avoid logging too frequently
skipping logging after 199072 examples to avoid logging too frequently
skipping logging after 199088 examples to avoid logging too frequently
train stats after 199104 examples: {'rewards_train/chosen': '0.11198', 'rewards_train/rejected': '-5.3721', 'rewards_train/margins': '5.7148', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26813', 'examples_per_second': '4.9906', 'grad_norm': '5.1562', 'counters/examples': 199104, 'counters/updates': 12444}
skipping logging after 199120 examples to avoid logging too frequently
skipping logging after 199136 examples to avoid logging too frequently
skipping logging after 199152 examples to avoid logging too frequently
train stats after 199168 examples: {'rewards_train/chosen': '0.10783', 'rewards_train/rejected': '-4.9415', 'rewards_train/margins': '5.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24542', 'examples_per_second': '5.29', 'grad_norm': '4.6875', 'counters/examples': 199168, 'counters/updates': 12448}
skipping logging after 199184 examples to avoid logging too frequently
skipping logging after 199200 examples to avoid logging too frequently
skipping logging after 199216 examples to avoid logging too frequently
train stats after 199232 examples: {'rewards_train/chosen': '0.28192', 'rewards_train/rejected': '-6.3344', 'rewards_train/margins': '6.3086', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26904', 'examples_per_second': '5.6835', 'grad_norm': '5.3125', 'counters/examples': 199232, 'counters/updates': 12452}
skipping logging after 199248 examples to avoid logging too frequently
skipping logging after 199264 examples to avoid logging too frequently
skipping logging after 199280 examples to avoid logging too frequently
train stats after 199296 examples: {'rewards_train/chosen': '0.17457', 'rewards_train/rejected': '-7.2133', 'rewards_train/margins': '7.3281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22046', 'examples_per_second': '4.4233', 'grad_norm': '5.3438', 'counters/examples': 199296, 'counters/updates': 12456}
skipping logging after 199312 examples to avoid logging too frequently
skipping logging after 199328 examples to avoid logging too frequently
skipping logging after 199344 examples to avoid logging too frequently
train stats after 199360 examples: {'rewards_train/chosen': '0.059943', 'rewards_train/rejected': '-5.1281', 'rewards_train/margins': '5.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24854', 'examples_per_second': '5.2401', 'grad_norm': '4.6562', 'counters/examples': 199360, 'counters/updates': 12460}
skipping logging after 199376 examples to avoid logging too frequently
skipping logging after 199392 examples to avoid logging too frequently
skipping logging after 199408 examples to avoid logging too frequently
train stats after 199424 examples: {'rewards_train/chosen': '0.23836', 'rewards_train/rejected': '-5.8999', 'rewards_train/margins': '6.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25726', 'examples_per_second': '5.1524', 'grad_norm': '5.75', 'counters/examples': 199424, 'counters/updates': 12464}
skipping logging after 199440 examples to avoid logging too frequently
skipping logging after 199456 examples to avoid logging too frequently
skipping logging after 199472 examples to avoid logging too frequently
train stats after 199488 examples: {'rewards_train/chosen': '0.54702', 'rewards_train/rejected': '-6.3323', 'rewards_train/margins': '6.9766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19159', 'examples_per_second': '5.1917', 'grad_norm': '6.0312', 'counters/examples': 199488, 'counters/updates': 12468}
skipping logging after 199504 examples to avoid logging too frequently
skipping logging after 199520 examples to avoid logging too frequently
skipping logging after 199536 examples to avoid logging too frequently
train stats after 199552 examples: {'rewards_train/chosen': '0.0028202', 'rewards_train/rejected': '-5.4885', 'rewards_train/margins': '5.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24542', 'examples_per_second': '5.5016', 'grad_norm': '5', 'counters/examples': 199552, 'counters/updates': 12472}
skipping logging after 199568 examples to avoid logging too frequently
skipping logging after 199584 examples to avoid logging too frequently
skipping logging after 199600 examples to avoid logging too frequently
train stats after 199616 examples: {'rewards_train/chosen': '0.24191', 'rewards_train/rejected': '-7.4011', 'rewards_train/margins': '7.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.31396', 'examples_per_second': '5.4055', 'grad_norm': '5.9375', 'counters/examples': 199616, 'counters/updates': 12476}
skipping logging after 199632 examples to avoid logging too frequently
skipping logging after 199648 examples to avoid logging too frequently
skipping logging after 199664 examples to avoid logging too frequently
train stats after 199680 examples: {'rewards_train/chosen': '0.35744', 'rewards_train/rejected': '-6.1406', 'rewards_train/margins': '6.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22687', 'examples_per_second': '4.7194', 'grad_norm': '5.375', 'counters/examples': 199680, 'counters/updates': 12480}
skipping logging after 199696 examples to avoid logging too frequently
skipping logging after 199712 examples to avoid logging too frequently
skipping logging after 199728 examples to avoid logging too frequently
train stats after 199744 examples: {'rewards_train/chosen': '0.32381', 'rewards_train/rejected': '-6.4203', 'rewards_train/margins': '6.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27783', 'examples_per_second': '5.8651', 'grad_norm': '4.5312', 'counters/examples': 199744, 'counters/updates': 12484}
skipping logging after 199760 examples to avoid logging too frequently
skipping logging after 199776 examples to avoid logging too frequently
skipping logging after 199792 examples to avoid logging too frequently
train stats after 199808 examples: {'rewards_train/chosen': '0.74114', 'rewards_train/rejected': '-5.8902', 'rewards_train/margins': '6.6016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20203', 'examples_per_second': '4.5786', 'grad_norm': '5.6562', 'counters/examples': 199808, 'counters/updates': 12488}
skipping logging after 199824 examples to avoid logging too frequently
skipping logging after 199840 examples to avoid logging too frequently
skipping logging after 199856 examples to avoid logging too frequently
train stats after 199872 examples: {'rewards_train/chosen': '0.56357', 'rewards_train/rejected': '-5.0126', 'rewards_train/margins': '5.4609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20746', 'examples_per_second': '5.5885', 'grad_norm': '4.3438', 'counters/examples': 199872, 'counters/updates': 12492}
skipping logging after 199888 examples to avoid logging too frequently
skipping logging after 199904 examples to avoid logging too frequently
skipping logging after 199920 examples to avoid logging too frequently
train stats after 199936 examples: {'rewards_train/chosen': '0.19096', 'rewards_train/rejected': '-5.5987', 'rewards_train/margins': '5.9297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21661', 'examples_per_second': '4.6902', 'grad_norm': '4.9062', 'counters/examples': 199936, 'counters/updates': 12496}
skipping logging after 199952 examples to avoid logging too frequently
skipping logging after 199968 examples to avoid logging too frequently
skipping logging after 199984 examples to avoid logging too frequently
train stats after 200000 examples: {'rewards_train/chosen': '0.3121', 'rewards_train/rejected': '-6.0557', 'rewards_train/margins': '6.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22266', 'examples_per_second': '4.7606', 'grad_norm': '5.4688', 'counters/examples': 200000, 'counters/updates': 12500}
Running evaluation after 200000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.25s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.17s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:39,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.65s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.47s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:33,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.51s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:33,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.40s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:30,  1.47s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.22s/it]Computing eval metrics:  50%|█████     | 16/32 [00:21<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.31s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.18s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]
eval after 200000: {'rewards_eval/chosen': '-5.7176', 'rewards_eval/rejected': '-6.3148', 'rewards_eval/margins': '0.43506', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.45926'}
skipping logging after 200016 examples to avoid logging too frequently
skipping logging after 200032 examples to avoid logging too frequently
skipping logging after 200048 examples to avoid logging too frequently
train stats after 200064 examples: {'rewards_train/chosen': '0.44617', 'rewards_train/rejected': '-5.4599', 'rewards_train/margins': '5.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22357', 'examples_per_second': '4.8447', 'grad_norm': '5', 'counters/examples': 200064, 'counters/updates': 12504}
skipping logging after 200080 examples to avoid logging too frequently
skipping logging after 200096 examples to avoid logging too frequently
skipping logging after 200112 examples to avoid logging too frequently
train stats after 200128 examples: {'rewards_train/chosen': '0.5675', 'rewards_train/rejected': '-6.4294', 'rewards_train/margins': '7.1172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21741', 'examples_per_second': '6.071', 'grad_norm': '4.7188', 'counters/examples': 200128, 'counters/updates': 12508}
skipping logging after 200144 examples to avoid logging too frequently
skipping logging after 200160 examples to avoid logging too frequently
skipping logging after 200176 examples to avoid logging too frequently
train stats after 200192 examples: {'rewards_train/chosen': '0.39291', 'rewards_train/rejected': '-6.1464', 'rewards_train/margins': '6.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22687', 'examples_per_second': '4.8167', 'grad_norm': '5.5938', 'counters/examples': 200192, 'counters/updates': 12512}
skipping logging after 200208 examples to avoid logging too frequently
skipping logging after 200224 examples to avoid logging too frequently
skipping logging after 200240 examples to avoid logging too frequently
train stats after 200256 examples: {'rewards_train/chosen': '0.16813', 'rewards_train/rejected': '-4.2247', 'rewards_train/margins': '4.207', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30487', 'examples_per_second': '6.3526', 'grad_norm': '5.6562', 'counters/examples': 200256, 'counters/updates': 12516}
skipping logging after 200272 examples to avoid logging too frequently
skipping logging after 200288 examples to avoid logging too frequently
skipping logging after 200304 examples to avoid logging too frequently
train stats after 200320 examples: {'rewards_train/chosen': '-0.21002', 'rewards_train/rejected': '-5.1894', 'rewards_train/margins': '4.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27936', 'examples_per_second': '6.2284', 'grad_norm': '5.3125', 'counters/examples': 200320, 'counters/updates': 12520}
skipping logging after 200336 examples to avoid logging too frequently
skipping logging after 200352 examples to avoid logging too frequently
skipping logging after 200368 examples to avoid logging too frequently
train stats after 200384 examples: {'rewards_train/chosen': '0.20198', 'rewards_train/rejected': '-7.116', 'rewards_train/margins': '7.3594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21771', 'examples_per_second': '4.4527', 'grad_norm': '4.9688', 'counters/examples': 200384, 'counters/updates': 12524}
skipping logging after 200400 examples to avoid logging too frequently
skipping logging after 200416 examples to avoid logging too frequently
skipping logging after 200432 examples to avoid logging too frequently
train stats after 200448 examples: {'rewards_train/chosen': '0.24494', 'rewards_train/rejected': '-6.1536', 'rewards_train/margins': '6.6484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26495', 'examples_per_second': '4.3816', 'grad_norm': '4.8125', 'counters/examples': 200448, 'counters/updates': 12528}
skipping logging after 200464 examples to avoid logging too frequently
skipping logging after 200480 examples to avoid logging too frequently
skipping logging after 200496 examples to avoid logging too frequently
train stats after 200512 examples: {'rewards_train/chosen': '0.46863', 'rewards_train/rejected': '-4.3638', 'rewards_train/margins': '4.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26196', 'examples_per_second': '6.0319', 'grad_norm': '4.8438', 'counters/examples': 200512, 'counters/updates': 12532}
skipping logging after 200528 examples to avoid logging too frequently
skipping logging after 200544 examples to avoid logging too frequently
skipping logging after 200560 examples to avoid logging too frequently
train stats after 200576 examples: {'rewards_train/chosen': '0.14595', 'rewards_train/rejected': '-6.1783', 'rewards_train/margins': '6.125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27057', 'examples_per_second': '5.1452', 'grad_norm': '5.7188', 'counters/examples': 200576, 'counters/updates': 12536}
skipping logging after 200592 examples to avoid logging too frequently
skipping logging after 200608 examples to avoid logging too frequently
skipping logging after 200624 examples to avoid logging too frequently
train stats after 200640 examples: {'rewards_train/chosen': '0.050537', 'rewards_train/rejected': '-6.2689', 'rewards_train/margins': '5.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2608', 'examples_per_second': '5.2299', 'grad_norm': '4.9375', 'counters/examples': 200640, 'counters/updates': 12540}
skipping logging after 200656 examples to avoid logging too frequently
skipping logging after 200672 examples to avoid logging too frequently
skipping logging after 200688 examples to avoid logging too frequently
train stats after 200704 examples: {'rewards_train/chosen': '0.27747', 'rewards_train/rejected': '-5.8237', 'rewards_train/margins': '6.1953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29504', 'examples_per_second': '5.1909', 'grad_norm': '5.9375', 'counters/examples': 200704, 'counters/updates': 12544}
skipping logging after 200720 examples to avoid logging too frequently
skipping logging after 200736 examples to avoid logging too frequently
skipping logging after 200752 examples to avoid logging too frequently
train stats after 200768 examples: {'rewards_train/chosen': '0.59629', 'rewards_train/rejected': '-5.3337', 'rewards_train/margins': '5.8906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22015', 'examples_per_second': '4.1416', 'grad_norm': '4.6875', 'counters/examples': 200768, 'counters/updates': 12548}
skipping logging after 200784 examples to avoid logging too frequently
skipping logging after 200800 examples to avoid logging too frequently
skipping logging after 200816 examples to avoid logging too frequently
train stats after 200832 examples: {'rewards_train/chosen': '0.05249', 'rewards_train/rejected': '-4.7778', 'rewards_train/margins': '4.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28772', 'examples_per_second': '5.7266', 'grad_norm': '4.5312', 'counters/examples': 200832, 'counters/updates': 12552}
skipping logging after 200848 examples to avoid logging too frequently
skipping logging after 200864 examples to avoid logging too frequently
skipping logging after 200880 examples to avoid logging too frequently
train stats after 200896 examples: {'rewards_train/chosen': '0.12381', 'rewards_train/rejected': '-6.0995', 'rewards_train/margins': '6.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25671', 'examples_per_second': '5.0563', 'grad_norm': '5.1562', 'counters/examples': 200896, 'counters/updates': 12556}
skipping logging after 200912 examples to avoid logging too frequently
skipping logging after 200928 examples to avoid logging too frequently
skipping logging after 200944 examples to avoid logging too frequently
train stats after 200960 examples: {'rewards_train/chosen': '0.26129', 'rewards_train/rejected': '-5.1676', 'rewards_train/margins': '5.4609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24738', 'examples_per_second': '5.32', 'grad_norm': '5.0938', 'counters/examples': 200960, 'counters/updates': 12560}
skipping logging after 200976 examples to avoid logging too frequently
skipping logging after 200992 examples to avoid logging too frequently
skipping logging after 201008 examples to avoid logging too frequently
train stats after 201024 examples: {'rewards_train/chosen': '0.25447', 'rewards_train/rejected': '-6.0435', 'rewards_train/margins': '6.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22943', 'examples_per_second': '5.3354', 'grad_norm': '4.1562', 'counters/examples': 201024, 'counters/updates': 12564}
skipping logging after 201040 examples to avoid logging too frequently
skipping logging after 201056 examples to avoid logging too frequently
skipping logging after 201072 examples to avoid logging too frequently
train stats after 201088 examples: {'rewards_train/chosen': '0.55125', 'rewards_train/rejected': '-6.7555', 'rewards_train/margins': '7.6562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20557', 'examples_per_second': '5.6144', 'grad_norm': '4.5312', 'counters/examples': 201088, 'counters/updates': 12568}
skipping logging after 201104 examples to avoid logging too frequently
skipping logging after 201120 examples to avoid logging too frequently
skipping logging after 201136 examples to avoid logging too frequently
train stats after 201152 examples: {'rewards_train/chosen': '0.54986', 'rewards_train/rejected': '-5.7134', 'rewards_train/margins': '6.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22009', 'examples_per_second': '5.6122', 'grad_norm': '4.3438', 'counters/examples': 201152, 'counters/updates': 12572}
skipping logging after 201168 examples to avoid logging too frequently
skipping logging after 201184 examples to avoid logging too frequently
skipping logging after 201200 examples to avoid logging too frequently
train stats after 201216 examples: {'rewards_train/chosen': '0.73491', 'rewards_train/rejected': '-6.2773', 'rewards_train/margins': '6.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19818', 'examples_per_second': '4.8118', 'grad_norm': '5.0625', 'counters/examples': 201216, 'counters/updates': 12576}
skipping logging after 201232 examples to avoid logging too frequently
skipping logging after 201248 examples to avoid logging too frequently
skipping logging after 201264 examples to avoid logging too frequently
train stats after 201280 examples: {'rewards_train/chosen': '-0.3058', 'rewards_train/rejected': '-5.6724', 'rewards_train/margins': '5.4141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29871', 'examples_per_second': '5.3778', 'grad_norm': '5.4688', 'counters/examples': 201280, 'counters/updates': 12580}
skipping logging after 201296 examples to avoid logging too frequently
skipping logging after 201312 examples to avoid logging too frequently
skipping logging after 201328 examples to avoid logging too frequently
train stats after 201344 examples: {'rewards_train/chosen': '0.35015', 'rewards_train/rejected': '-6.2638', 'rewards_train/margins': '6.6094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17383', 'examples_per_second': '6.3498', 'grad_norm': '5.0312', 'counters/examples': 201344, 'counters/updates': 12584}
skipping logging after 201360 examples to avoid logging too frequently
skipping logging after 201376 examples to avoid logging too frequently
skipping logging after 201392 examples to avoid logging too frequently
train stats after 201408 examples: {'rewards_train/chosen': '0.34997', 'rewards_train/rejected': '-5.9484', 'rewards_train/margins': '6.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2312', 'examples_per_second': '6.0634', 'grad_norm': '4.625', 'counters/examples': 201408, 'counters/updates': 12588}
skipping logging after 201424 examples to avoid logging too frequently
skipping logging after 201440 examples to avoid logging too frequently
skipping logging after 201456 examples to avoid logging too frequently
train stats after 201472 examples: {'rewards_train/chosen': '0.043774', 'rewards_train/rejected': '-6.8199', 'rewards_train/margins': '7.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26599', 'examples_per_second': '4.8964', 'grad_norm': '4.875', 'counters/examples': 201472, 'counters/updates': 12592}
skipping logging after 201488 examples to avoid logging too frequently
skipping logging after 201504 examples to avoid logging too frequently
skipping logging after 201520 examples to avoid logging too frequently
train stats after 201536 examples: {'rewards_train/chosen': '0.18554', 'rewards_train/rejected': '-5.5179', 'rewards_train/margins': '5.7734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23773', 'examples_per_second': '5.1745', 'grad_norm': '4.2188', 'counters/examples': 201536, 'counters/updates': 12596}
skipping logging after 201552 examples to avoid logging too frequently
skipping logging after 201568 examples to avoid logging too frequently
skipping logging after 201584 examples to avoid logging too frequently
train stats after 201600 examples: {'rewards_train/chosen': '0.099881', 'rewards_train/rejected': '-6.4777', 'rewards_train/margins': '6.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22736', 'examples_per_second': '5.5687', 'grad_norm': '5.7188', 'counters/examples': 201600, 'counters/updates': 12600}
skipping logging after 201616 examples to avoid logging too frequently
skipping logging after 201632 examples to avoid logging too frequently
skipping logging after 201648 examples to avoid logging too frequently
train stats after 201664 examples: {'rewards_train/chosen': '0.70612', 'rewards_train/rejected': '-4.6726', 'rewards_train/margins': '5.3828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20844', 'examples_per_second': '5.0979', 'grad_norm': '5.2188', 'counters/examples': 201664, 'counters/updates': 12604}
skipping logging after 201680 examples to avoid logging too frequently
skipping logging after 201696 examples to avoid logging too frequently
skipping logging after 201712 examples to avoid logging too frequently
train stats after 201728 examples: {'rewards_train/chosen': '0.36957', 'rewards_train/rejected': '-7.2204', 'rewards_train/margins': '7.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22034', 'examples_per_second': '3.9328', 'grad_norm': '4.7188', 'counters/examples': 201728, 'counters/updates': 12608}
skipping logging after 201744 examples to avoid logging too frequently
skipping logging after 201760 examples to avoid logging too frequently
skipping logging after 201776 examples to avoid logging too frequently
train stats after 201792 examples: {'rewards_train/chosen': '0.5623', 'rewards_train/rejected': '-6.6108', 'rewards_train/margins': '7.2969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23376', 'examples_per_second': '4.9752', 'grad_norm': '4.75', 'counters/examples': 201792, 'counters/updates': 12612}
skipping logging after 201808 examples to avoid logging too frequently
skipping logging after 201824 examples to avoid logging too frequently
skipping logging after 201840 examples to avoid logging too frequently
train stats after 201856 examples: {'rewards_train/chosen': '0.46299', 'rewards_train/rejected': '-7.3724', 'rewards_train/margins': '7.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21661', 'examples_per_second': '5.0733', 'grad_norm': '4.4375', 'counters/examples': 201856, 'counters/updates': 12616}
skipping logging after 201872 examples to avoid logging too frequently
skipping logging after 201888 examples to avoid logging too frequently
skipping logging after 201904 examples to avoid logging too frequently
train stats after 201920 examples: {'rewards_train/chosen': '-0.27298', 'rewards_train/rejected': '-7.1598', 'rewards_train/margins': '6.7031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29083', 'examples_per_second': '4.6933', 'grad_norm': '4.75', 'counters/examples': 201920, 'counters/updates': 12620}
skipping logging after 201936 examples to avoid logging too frequently
skipping logging after 201952 examples to avoid logging too frequently
skipping logging after 201968 examples to avoid logging too frequently
train stats after 201984 examples: {'rewards_train/chosen': '0.10956', 'rewards_train/rejected': '-5.8387', 'rewards_train/margins': '5.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27606', 'examples_per_second': '4.8494', 'grad_norm': '5.1562', 'counters/examples': 201984, 'counters/updates': 12624}
skipping logging after 202000 examples to avoid logging too frequently
skipping logging after 202016 examples to avoid logging too frequently
skipping logging after 202032 examples to avoid logging too frequently
train stats after 202048 examples: {'rewards_train/chosen': '0.68321', 'rewards_train/rejected': '-6.1707', 'rewards_train/margins': '6.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17969', 'examples_per_second': '4.3989', 'grad_norm': '5.1562', 'counters/examples': 202048, 'counters/updates': 12628}
skipping logging after 202064 examples to avoid logging too frequently
skipping logging after 202080 examples to avoid logging too frequently
skipping logging after 202096 examples to avoid logging too frequently
train stats after 202112 examples: {'rewards_train/chosen': '0.33347', 'rewards_train/rejected': '-5.9796', 'rewards_train/margins': '6.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20972', 'examples_per_second': '4.9', 'grad_norm': '4.7188', 'counters/examples': 202112, 'counters/updates': 12632}
skipping logging after 202128 examples to avoid logging too frequently
skipping logging after 202144 examples to avoid logging too frequently
skipping logging after 202160 examples to avoid logging too frequently
train stats after 202176 examples: {'rewards_train/chosen': '0.4227', 'rewards_train/rejected': '-6.121', 'rewards_train/margins': '6.2422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25751', 'examples_per_second': '5.4697', 'grad_norm': '5.6562', 'counters/examples': 202176, 'counters/updates': 12636}
skipping logging after 202192 examples to avoid logging too frequently
skipping logging after 202208 examples to avoid logging too frequently
skipping logging after 202224 examples to avoid logging too frequently
train stats after 202240 examples: {'rewards_train/chosen': '0.11909', 'rewards_train/rejected': '-6.373', 'rewards_train/margins': '7.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27307', 'examples_per_second': '5.435', 'grad_norm': '6.25', 'counters/examples': 202240, 'counters/updates': 12640}
skipping logging after 202256 examples to avoid logging too frequently
skipping logging after 202272 examples to avoid logging too frequently
skipping logging after 202288 examples to avoid logging too frequently
train stats after 202304 examples: {'rewards_train/chosen': '0.42233', 'rewards_train/rejected': '-5.8389', 'rewards_train/margins': '6.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20343', 'examples_per_second': '5.0452', 'grad_norm': '4.3125', 'counters/examples': 202304, 'counters/updates': 12644}
skipping logging after 202320 examples to avoid logging too frequently
skipping logging after 202336 examples to avoid logging too frequently
skipping logging after 202352 examples to avoid logging too frequently
train stats after 202368 examples: {'rewards_train/chosen': '0.031198', 'rewards_train/rejected': '-7.7941', 'rewards_train/margins': '7.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25214', 'examples_per_second': '5.3711', 'grad_norm': '4.75', 'counters/examples': 202368, 'counters/updates': 12648}
skipping logging after 202384 examples to avoid logging too frequently
skipping logging after 202400 examples to avoid logging too frequently
skipping logging after 202416 examples to avoid logging too frequently
train stats after 202432 examples: {'rewards_train/chosen': '0.44895', 'rewards_train/rejected': '-6.2094', 'rewards_train/margins': '6.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21887', 'examples_per_second': '5.343', 'grad_norm': '5.625', 'counters/examples': 202432, 'counters/updates': 12652}
skipping logging after 202448 examples to avoid logging too frequently
skipping logging after 202464 examples to avoid logging too frequently
skipping logging after 202480 examples to avoid logging too frequently
train stats after 202496 examples: {'rewards_train/chosen': '0.19508', 'rewards_train/rejected': '-5.8607', 'rewards_train/margins': '5.6328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23981', 'examples_per_second': '5.5545', 'grad_norm': '5.6562', 'counters/examples': 202496, 'counters/updates': 12656}
skipping logging after 202512 examples to avoid logging too frequently
skipping logging after 202528 examples to avoid logging too frequently
skipping logging after 202544 examples to avoid logging too frequently
train stats after 202560 examples: {'rewards_train/chosen': '0.18283', 'rewards_train/rejected': '-5.6135', 'rewards_train/margins': '5.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2345', 'examples_per_second': '6.0175', 'grad_norm': '4.6562', 'counters/examples': 202560, 'counters/updates': 12660}
skipping logging after 202576 examples to avoid logging too frequently
skipping logging after 202592 examples to avoid logging too frequently
skipping logging after 202608 examples to avoid logging too frequently
train stats after 202624 examples: {'rewards_train/chosen': '0.30035', 'rewards_train/rejected': '-5.6406', 'rewards_train/margins': '5.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22699', 'examples_per_second': '6.0478', 'grad_norm': '5.8438', 'counters/examples': 202624, 'counters/updates': 12664}
skipping logging after 202640 examples to avoid logging too frequently
skipping logging after 202656 examples to avoid logging too frequently
skipping logging after 202672 examples to avoid logging too frequently
train stats after 202688 examples: {'rewards_train/chosen': '0.31169', 'rewards_train/rejected': '-6.0781', 'rewards_train/margins': '6.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2265', 'examples_per_second': '5.1641', 'grad_norm': '5.1562', 'counters/examples': 202688, 'counters/updates': 12668}
skipping logging after 202704 examples to avoid logging too frequently
skipping logging after 202720 examples to avoid logging too frequently
skipping logging after 202736 examples to avoid logging too frequently
train stats after 202752 examples: {'rewards_train/chosen': '0.61144', 'rewards_train/rejected': '-6.0214', 'rewards_train/margins': '6.6602', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22827', 'examples_per_second': '4.4915', 'grad_norm': '4.4375', 'counters/examples': 202752, 'counters/updates': 12672}
skipping logging after 202768 examples to avoid logging too frequently
skipping logging after 202784 examples to avoid logging too frequently
skipping logging after 202800 examples to avoid logging too frequently
train stats after 202816 examples: {'rewards_train/chosen': '0.36357', 'rewards_train/rejected': '-7.6159', 'rewards_train/margins': '7.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22626', 'examples_per_second': '4.8207', 'grad_norm': '4.9688', 'counters/examples': 202816, 'counters/updates': 12676}
skipping logging after 202832 examples to avoid logging too frequently
skipping logging after 202848 examples to avoid logging too frequently
skipping logging after 202864 examples to avoid logging too frequently
train stats after 202880 examples: {'rewards_train/chosen': '0.42109', 'rewards_train/rejected': '-6.1011', 'rewards_train/margins': '6.7422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24402', 'examples_per_second': '5.4307', 'grad_norm': '5.1875', 'counters/examples': 202880, 'counters/updates': 12680}
skipping logging after 202896 examples to avoid logging too frequently
skipping logging after 202912 examples to avoid logging too frequently
skipping logging after 202928 examples to avoid logging too frequently
train stats after 202944 examples: {'rewards_train/chosen': '0.5723', 'rewards_train/rejected': '-5.2357', 'rewards_train/margins': '5.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19885', 'examples_per_second': '5.0313', 'grad_norm': '4.9375', 'counters/examples': 202944, 'counters/updates': 12684}
skipping logging after 202960 examples to avoid logging too frequently
skipping logging after 202976 examples to avoid logging too frequently
skipping logging after 202992 examples to avoid logging too frequently
train stats after 203008 examples: {'rewards_train/chosen': '0.59644', 'rewards_train/rejected': '-7.8355', 'rewards_train/margins': '8.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18976', 'examples_per_second': '5.0456', 'grad_norm': '4.875', 'counters/examples': 203008, 'counters/updates': 12688}
skipping logging after 203024 examples to avoid logging too frequently
skipping logging after 203040 examples to avoid logging too frequently
skipping logging after 203056 examples to avoid logging too frequently
train stats after 203072 examples: {'rewards_train/chosen': '0.29217', 'rewards_train/rejected': '-7.8182', 'rewards_train/margins': '8.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27161', 'examples_per_second': '4.1417', 'grad_norm': '5.4062', 'counters/examples': 203072, 'counters/updates': 12692}
skipping logging after 203088 examples to avoid logging too frequently
skipping logging after 203104 examples to avoid logging too frequently
skipping logging after 203120 examples to avoid logging too frequently
train stats after 203136 examples: {'rewards_train/chosen': '0.39703', 'rewards_train/rejected': '-7.4', 'rewards_train/margins': '7.6641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21161', 'examples_per_second': '5.7409', 'grad_norm': '4.7812', 'counters/examples': 203136, 'counters/updates': 12696}
skipping logging after 203152 examples to avoid logging too frequently
skipping logging after 203168 examples to avoid logging too frequently
skipping logging after 203184 examples to avoid logging too frequently
train stats after 203200 examples: {'rewards_train/chosen': '0.34693', 'rewards_train/rejected': '-6.9328', 'rewards_train/margins': '7.3203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22235', 'examples_per_second': '4.7727', 'grad_norm': '4.5625', 'counters/examples': 203200, 'counters/updates': 12700}
skipping logging after 203216 examples to avoid logging too frequently
skipping logging after 203232 examples to avoid logging too frequently
skipping logging after 203248 examples to avoid logging too frequently
train stats after 203264 examples: {'rewards_train/chosen': '0.37028', 'rewards_train/rejected': '-5.5618', 'rewards_train/margins': '5.9453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24951', 'examples_per_second': '5.4165', 'grad_norm': '5.4375', 'counters/examples': 203264, 'counters/updates': 12704}
skipping logging after 203280 examples to avoid logging too frequently
skipping logging after 203296 examples to avoid logging too frequently
skipping logging after 203312 examples to avoid logging too frequently
train stats after 203328 examples: {'rewards_train/chosen': '0.2873', 'rewards_train/rejected': '-4.1133', 'rewards_train/margins': '4.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23828', 'examples_per_second': '6.5255', 'grad_norm': '5.2188', 'counters/examples': 203328, 'counters/updates': 12708}
skipping logging after 203344 examples to avoid logging too frequently
skipping logging after 203360 examples to avoid logging too frequently
skipping logging after 203376 examples to avoid logging too frequently
train stats after 203392 examples: {'rewards_train/chosen': '0.4596', 'rewards_train/rejected': '-5.0672', 'rewards_train/margins': '5.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21631', 'examples_per_second': '6.04', 'grad_norm': '4.75', 'counters/examples': 203392, 'counters/updates': 12712}
skipping logging after 203408 examples to avoid logging too frequently
skipping logging after 203424 examples to avoid logging too frequently
skipping logging after 203440 examples to avoid logging too frequently
train stats after 203456 examples: {'rewards_train/chosen': '0.23581', 'rewards_train/rejected': '-5.4616', 'rewards_train/margins': '5.8984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23987', 'examples_per_second': '5.5294', 'grad_norm': '5.0312', 'counters/examples': 203456, 'counters/updates': 12716}
skipping logging after 203472 examples to avoid logging too frequently
skipping logging after 203488 examples to avoid logging too frequently
skipping logging after 203504 examples to avoid logging too frequently
train stats after 203520 examples: {'rewards_train/chosen': '0.55457', 'rewards_train/rejected': '-6.5338', 'rewards_train/margins': '7.125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21259', 'examples_per_second': '4.1814', 'grad_norm': '4.1875', 'counters/examples': 203520, 'counters/updates': 12720}
skipping logging after 203536 examples to avoid logging too frequently
skipping logging after 203552 examples to avoid logging too frequently
skipping logging after 203568 examples to avoid logging too frequently
train stats after 203584 examples: {'rewards_train/chosen': '0.26145', 'rewards_train/rejected': '-6.0704', 'rewards_train/margins': '6.6875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23962', 'examples_per_second': '5.2209', 'grad_norm': '4.9688', 'counters/examples': 203584, 'counters/updates': 12724}
skipping logging after 203600 examples to avoid logging too frequently
skipping logging after 203616 examples to avoid logging too frequently
skipping logging after 203632 examples to avoid logging too frequently
train stats after 203648 examples: {'rewards_train/chosen': '0.45109', 'rewards_train/rejected': '-7.1403', 'rewards_train/margins': '8.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21753', 'examples_per_second': '4.2673', 'grad_norm': '4.375', 'counters/examples': 203648, 'counters/updates': 12728}
skipping logging after 203664 examples to avoid logging too frequently
skipping logging after 203680 examples to avoid logging too frequently
skipping logging after 203696 examples to avoid logging too frequently
train stats after 203712 examples: {'rewards_train/chosen': '0.25785', 'rewards_train/rejected': '-5.9904', 'rewards_train/margins': '6.3281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22467', 'examples_per_second': '5.5515', 'grad_norm': '5.0312', 'counters/examples': 203712, 'counters/updates': 12732}
skipping logging after 203728 examples to avoid logging too frequently
skipping logging after 203744 examples to avoid logging too frequently
skipping logging after 203760 examples to avoid logging too frequently
train stats after 203776 examples: {'rewards_train/chosen': '0.17471', 'rewards_train/rejected': '-5.387', 'rewards_train/margins': '5.0156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26477', 'examples_per_second': '6.854', 'grad_norm': '5.9375', 'counters/examples': 203776, 'counters/updates': 12736}
skipping logging after 203792 examples to avoid logging too frequently
skipping logging after 203808 examples to avoid logging too frequently
skipping logging after 203824 examples to avoid logging too frequently
train stats after 203840 examples: {'rewards_train/chosen': '0.54948', 'rewards_train/rejected': '-5.9211', 'rewards_train/margins': '5.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23132', 'examples_per_second': '5.0804', 'grad_norm': '5.1562', 'counters/examples': 203840, 'counters/updates': 12740}
skipping logging after 203856 examples to avoid logging too frequently
skipping logging after 203872 examples to avoid logging too frequently
skipping logging after 203888 examples to avoid logging too frequently
train stats after 203904 examples: {'rewards_train/chosen': '0.26171', 'rewards_train/rejected': '-6.515', 'rewards_train/margins': '6.8906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22229', 'examples_per_second': '6.4889', 'grad_norm': '5.5938', 'counters/examples': 203904, 'counters/updates': 12744}
skipping logging after 203920 examples to avoid logging too frequently
skipping logging after 203936 examples to avoid logging too frequently
skipping logging after 203952 examples to avoid logging too frequently
train stats after 203968 examples: {'rewards_train/chosen': '0.30795', 'rewards_train/rejected': '-9.0416', 'rewards_train/margins': '9.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24652', 'examples_per_second': '4.4879', 'grad_norm': '4.625', 'counters/examples': 203968, 'counters/updates': 12748}
skipping logging after 203984 examples to avoid logging too frequently
skipping logging after 204000 examples to avoid logging too frequently
Running evaluation after 204000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:55,  1.78s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:44,  1.48s/it]Computing eval metrics:   9%|▉         | 3/32 [00:04<00:37,  1.29s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:42,  1.50s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.70s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:09<00:39,  1.50s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:10<00:34,  1.38s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:12<00:36,  1.53s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.49s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:31,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.41s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:20<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:21<00:20,  1.22s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:28<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:38<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.20s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:40<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:41<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]
eval after 204000: {'rewards_eval/chosen': '-5.7267', 'rewards_eval/rejected': '-6.2678', 'rewards_eval/margins': '0.3877', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.45865'}
skipping logging after 204016 examples to avoid logging too frequently
train stats after 204032 examples: {'rewards_train/chosen': '0.79485', 'rewards_train/rejected': '-4.6106', 'rewards_train/margins': '5.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21582', 'examples_per_second': '5.3795', 'grad_norm': '4.6875', 'counters/examples': 204032, 'counters/updates': 12752}
skipping logging after 204048 examples to avoid logging too frequently
skipping logging after 204064 examples to avoid logging too frequently
skipping logging after 204080 examples to avoid logging too frequently
train stats after 204096 examples: {'rewards_train/chosen': '0.58587', 'rewards_train/rejected': '-6.0151', 'rewards_train/margins': '6.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23639', 'examples_per_second': '5.3766', 'grad_norm': '5.7812', 'counters/examples': 204096, 'counters/updates': 12756}
skipping logging after 204112 examples to avoid logging too frequently
skipping logging after 204128 examples to avoid logging too frequently
skipping logging after 204144 examples to avoid logging too frequently
train stats after 204160 examples: {'rewards_train/chosen': '0.1869', 'rewards_train/rejected': '-5.9398', 'rewards_train/margins': '6.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29901', 'examples_per_second': '4.3175', 'grad_norm': '4.9375', 'counters/examples': 204160, 'counters/updates': 12760}
skipping logging after 204176 examples to avoid logging too frequently
skipping logging after 204192 examples to avoid logging too frequently
skipping logging after 204208 examples to avoid logging too frequently
train stats after 204224 examples: {'rewards_train/chosen': '0.57973', 'rewards_train/rejected': '-5.1984', 'rewards_train/margins': '5.6016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21722', 'examples_per_second': '6.7133', 'grad_norm': '4.6562', 'counters/examples': 204224, 'counters/updates': 12764}
skipping logging after 204240 examples to avoid logging too frequently
skipping logging after 204256 examples to avoid logging too frequently
skipping logging after 204272 examples to avoid logging too frequently
train stats after 204288 examples: {'rewards_train/chosen': '0.52374', 'rewards_train/rejected': '-6.3555', 'rewards_train/margins': '6.8984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19775', 'examples_per_second': '5.0567', 'grad_norm': '5.1562', 'counters/examples': 204288, 'counters/updates': 12768}
skipping logging after 204304 examples to avoid logging too frequently
skipping logging after 204320 examples to avoid logging too frequently
skipping logging after 204336 examples to avoid logging too frequently
train stats after 204352 examples: {'rewards_train/chosen': '0.58085', 'rewards_train/rejected': '-7.3621', 'rewards_train/margins': '7.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21442', 'examples_per_second': '4.5143', 'grad_norm': '4.9062', 'counters/examples': 204352, 'counters/updates': 12772}
skipping logging after 204368 examples to avoid logging too frequently
skipping logging after 204384 examples to avoid logging too frequently
skipping logging after 204400 examples to avoid logging too frequently
train stats after 204416 examples: {'rewards_train/chosen': '0.42717', 'rewards_train/rejected': '-6.0791', 'rewards_train/margins': '6.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2066', 'examples_per_second': '4.9976', 'grad_norm': '5', 'counters/examples': 204416, 'counters/updates': 12776}
skipping logging after 204432 examples to avoid logging too frequently
skipping logging after 204448 examples to avoid logging too frequently
skipping logging after 204464 examples to avoid logging too frequently
train stats after 204480 examples: {'rewards_train/chosen': '0.63613', 'rewards_train/rejected': '-6.686', 'rewards_train/margins': '7.3203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17084', 'examples_per_second': '5.6831', 'grad_norm': '4.125', 'counters/examples': 204480, 'counters/updates': 12780}
skipping logging after 204496 examples to avoid logging too frequently
skipping logging after 204512 examples to avoid logging too frequently
skipping logging after 204528 examples to avoid logging too frequently
train stats after 204544 examples: {'rewards_train/chosen': '0.24875', 'rewards_train/rejected': '-4.7285', 'rewards_train/margins': '4.9141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.31091', 'examples_per_second': '6.1324', 'grad_norm': '4.9688', 'counters/examples': 204544, 'counters/updates': 12784}
skipping logging after 204560 examples to avoid logging too frequently
skipping logging after 204576 examples to avoid logging too frequently
skipping logging after 204592 examples to avoid logging too frequently
train stats after 204608 examples: {'rewards_train/chosen': '0.10894', 'rewards_train/rejected': '-6.0423', 'rewards_train/margins': '5.9297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24036', 'examples_per_second': '5.88', 'grad_norm': '5.0938', 'counters/examples': 204608, 'counters/updates': 12788}
skipping logging after 204624 examples to avoid logging too frequently
skipping logging after 204640 examples to avoid logging too frequently
skipping logging after 204656 examples to avoid logging too frequently
train stats after 204672 examples: {'rewards_train/chosen': '0.081984', 'rewards_train/rejected': '-6.201', 'rewards_train/margins': '6.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2254', 'examples_per_second': '6.1253', 'grad_norm': '4.7188', 'counters/examples': 204672, 'counters/updates': 12792}
skipping logging after 204688 examples to avoid logging too frequently
skipping logging after 204704 examples to avoid logging too frequently
skipping logging after 204720 examples to avoid logging too frequently
train stats after 204736 examples: {'rewards_train/chosen': '0.091035', 'rewards_train/rejected': '-6.4114', 'rewards_train/margins': '6.6484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24707', 'examples_per_second': '4.459', 'grad_norm': '4.5938', 'counters/examples': 204736, 'counters/updates': 12796}
skipping logging after 204752 examples to avoid logging too frequently
skipping logging after 204768 examples to avoid logging too frequently
skipping logging after 204784 examples to avoid logging too frequently
train stats after 204800 examples: {'rewards_train/chosen': '-0.083935', 'rewards_train/rejected': '-5.4705', 'rewards_train/margins': '5.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24908', 'examples_per_second': '5.6799', 'grad_norm': '5.25', 'counters/examples': 204800, 'counters/updates': 12800}
skipping logging after 204816 examples to avoid logging too frequently
skipping logging after 204832 examples to avoid logging too frequently
skipping logging after 204848 examples to avoid logging too frequently
train stats after 204864 examples: {'rewards_train/chosen': '0.23998', 'rewards_train/rejected': '-6.8754', 'rewards_train/margins': '7.2109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21094', 'examples_per_second': '5.1412', 'grad_norm': '4.7188', 'counters/examples': 204864, 'counters/updates': 12804}
skipping logging after 204880 examples to avoid logging too frequently
skipping logging after 204896 examples to avoid logging too frequently
skipping logging after 204912 examples to avoid logging too frequently
train stats after 204928 examples: {'rewards_train/chosen': '0.23035', 'rewards_train/rejected': '-6.3769', 'rewards_train/margins': '6.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24493', 'examples_per_second': '4.7531', 'grad_norm': '4.4375', 'counters/examples': 204928, 'counters/updates': 12808}
skipping logging after 204944 examples to avoid logging too frequently
skipping logging after 204960 examples to avoid logging too frequently
skipping logging after 204976 examples to avoid logging too frequently
train stats after 204992 examples: {'rewards_train/chosen': '0.55553', 'rewards_train/rejected': '-6.0853', 'rewards_train/margins': '6.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22144', 'examples_per_second': '4.6559', 'grad_norm': '4.25', 'counters/examples': 204992, 'counters/updates': 12812}
skipping logging after 205008 examples to avoid logging too frequently
skipping logging after 205024 examples to avoid logging too frequently
skipping logging after 205040 examples to avoid logging too frequently
train stats after 205056 examples: {'rewards_train/chosen': '0.31234', 'rewards_train/rejected': '-6.5804', 'rewards_train/margins': '6.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26788', 'examples_per_second': '4.9216', 'grad_norm': '6.0312', 'counters/examples': 205056, 'counters/updates': 12816}
skipping logging after 205072 examples to avoid logging too frequently
skipping logging after 205088 examples to avoid logging too frequently
skipping logging after 205104 examples to avoid logging too frequently
train stats after 205120 examples: {'rewards_train/chosen': '0.22577', 'rewards_train/rejected': '-6.5026', 'rewards_train/margins': '6.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23224', 'examples_per_second': '4.7523', 'grad_norm': '5.0938', 'counters/examples': 205120, 'counters/updates': 12820}
skipping logging after 205136 examples to avoid logging too frequently
skipping logging after 205152 examples to avoid logging too frequently
skipping logging after 205168 examples to avoid logging too frequently
train stats after 205184 examples: {'rewards_train/chosen': '0.040726', 'rewards_train/rejected': '-6.2181', 'rewards_train/margins': '6.0234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26038', 'examples_per_second': '4.6597', 'grad_norm': '4.5625', 'counters/examples': 205184, 'counters/updates': 12824}
skipping logging after 205200 examples to avoid logging too frequently
skipping logging after 205216 examples to avoid logging too frequently
skipping logging after 205232 examples to avoid logging too frequently
train stats after 205248 examples: {'rewards_train/chosen': '0.49123', 'rewards_train/rejected': '-5.15', 'rewards_train/margins': '5.7031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21991', 'examples_per_second': '4.716', 'grad_norm': '5.5', 'counters/examples': 205248, 'counters/updates': 12828}
skipping logging after 205264 examples to avoid logging too frequently
skipping logging after 205280 examples to avoid logging too frequently
skipping logging after 205296 examples to avoid logging too frequently
train stats after 205312 examples: {'rewards_train/chosen': '0.30874', 'rewards_train/rejected': '-5.9325', 'rewards_train/margins': '6.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26959', 'examples_per_second': '5.3566', 'grad_norm': '5.9062', 'counters/examples': 205312, 'counters/updates': 12832}
skipping logging after 205328 examples to avoid logging too frequently
skipping logging after 205344 examples to avoid logging too frequently
skipping logging after 205360 examples to avoid logging too frequently
train stats after 205376 examples: {'rewards_train/chosen': '0.2684', 'rewards_train/rejected': '-6.5243', 'rewards_train/margins': '6.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24371', 'examples_per_second': '5.0266', 'grad_norm': '4.3438', 'counters/examples': 205376, 'counters/updates': 12836}
skipping logging after 205392 examples to avoid logging too frequently
skipping logging after 205408 examples to avoid logging too frequently
skipping logging after 205424 examples to avoid logging too frequently
train stats after 205440 examples: {'rewards_train/chosen': '0.35477', 'rewards_train/rejected': '-4.7635', 'rewards_train/margins': '4.8828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23401', 'examples_per_second': '5.904', 'grad_norm': '5.1875', 'counters/examples': 205440, 'counters/updates': 12840}
skipping logging after 205456 examples to avoid logging too frequently
skipping logging after 205472 examples to avoid logging too frequently
skipping logging after 205488 examples to avoid logging too frequently
train stats after 205504 examples: {'rewards_train/chosen': '0.26832', 'rewards_train/rejected': '-4.8954', 'rewards_train/margins': '5.2344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28308', 'examples_per_second': '6.0377', 'grad_norm': '5.9062', 'counters/examples': 205504, 'counters/updates': 12844}
skipping logging after 205520 examples to avoid logging too frequently
skipping logging after 205536 examples to avoid logging too frequently
skipping logging after 205552 examples to avoid logging too frequently
train stats after 205568 examples: {'rewards_train/chosen': '0.49324', 'rewards_train/rejected': '-5.8776', 'rewards_train/margins': '6.2969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19629', 'examples_per_second': '5.3905', 'grad_norm': '5.0938', 'counters/examples': 205568, 'counters/updates': 12848}
skipping logging after 205584 examples to avoid logging too frequently
skipping logging after 205600 examples to avoid logging too frequently
skipping logging after 205616 examples to avoid logging too frequently
train stats after 205632 examples: {'rewards_train/chosen': '0.012671', 'rewards_train/rejected': '-4.8717', 'rewards_train/margins': '4.7539', 'rewards_train/KL_estimate': '0', 'loss/train': '0.3056', 'examples_per_second': '4.516', 'grad_norm': '5.0312', 'counters/examples': 205632, 'counters/updates': 12852}
skipping logging after 205648 examples to avoid logging too frequently
skipping logging after 205664 examples to avoid logging too frequently
skipping logging after 205680 examples to avoid logging too frequently
train stats after 205696 examples: {'rewards_train/chosen': '0.21647', 'rewards_train/rejected': '-5.1709', 'rewards_train/margins': '5.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.255', 'examples_per_second': '5.4793', 'grad_norm': '4.4375', 'counters/examples': 205696, 'counters/updates': 12856}
skipping logging after 205712 examples to avoid logging too frequently
skipping logging after 205728 examples to avoid logging too frequently
skipping logging after 205744 examples to avoid logging too frequently
train stats after 205760 examples: {'rewards_train/chosen': '0.14277', 'rewards_train/rejected': '-4.6553', 'rewards_train/margins': '4.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29205', 'examples_per_second': '5.4551', 'grad_norm': '5.0312', 'counters/examples': 205760, 'counters/updates': 12860}
skipping logging after 205776 examples to avoid logging too frequently
skipping logging after 205792 examples to avoid logging too frequently
skipping logging after 205808 examples to avoid logging too frequently
train stats after 205824 examples: {'rewards_train/chosen': '0.51526', 'rewards_train/rejected': '-5.9305', 'rewards_train/margins': '6.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19025', 'examples_per_second': '5.5337', 'grad_norm': '4.0625', 'counters/examples': 205824, 'counters/updates': 12864}
skipping logging after 205840 examples to avoid logging too frequently
skipping logging after 205856 examples to avoid logging too frequently
skipping logging after 205872 examples to avoid logging too frequently
train stats after 205888 examples: {'rewards_train/chosen': '0.32079', 'rewards_train/rejected': '-4.9768', 'rewards_train/margins': '5.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26434', 'examples_per_second': '6.3563', 'grad_norm': '4.8125', 'counters/examples': 205888, 'counters/updates': 12868}
skipping logging after 205904 examples to avoid logging too frequently
skipping logging after 205920 examples to avoid logging too frequently
skipping logging after 205936 examples to avoid logging too frequently
train stats after 205952 examples: {'rewards_train/chosen': '0.71762', 'rewards_train/rejected': '-4.8473', 'rewards_train/margins': '5.6562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22906', 'examples_per_second': '5.3551', 'grad_norm': '4.75', 'counters/examples': 205952, 'counters/updates': 12872}
skipping logging after 205968 examples to avoid logging too frequently
skipping logging after 205984 examples to avoid logging too frequently
skipping logging after 206000 examples to avoid logging too frequently
train stats after 206016 examples: {'rewards_train/chosen': '0.21065', 'rewards_train/rejected': '-5.8343', 'rewards_train/margins': '5.6484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21637', 'examples_per_second': '4.9511', 'grad_norm': '5', 'counters/examples': 206016, 'counters/updates': 12876}
skipping logging after 206032 examples to avoid logging too frequently
skipping logging after 206048 examples to avoid logging too frequently
skipping logging after 206064 examples to avoid logging too frequently
train stats after 206080 examples: {'rewards_train/chosen': '0.20414', 'rewards_train/rejected': '-7.1246', 'rewards_train/margins': '7.6094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26434', 'examples_per_second': '5.6596', 'grad_norm': '6.25', 'counters/examples': 206080, 'counters/updates': 12880}
skipping logging after 206096 examples to avoid logging too frequently
skipping logging after 206112 examples to avoid logging too frequently
skipping logging after 206128 examples to avoid logging too frequently
train stats after 206144 examples: {'rewards_train/chosen': '0.309', 'rewards_train/rejected': '-5.5647', 'rewards_train/margins': '5.7656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24695', 'examples_per_second': '4.4846', 'grad_norm': '4.9375', 'counters/examples': 206144, 'counters/updates': 12884}
skipping logging after 206160 examples to avoid logging too frequently
skipping logging after 206176 examples to avoid logging too frequently
skipping logging after 206192 examples to avoid logging too frequently
train stats after 206208 examples: {'rewards_train/chosen': '0.46958', 'rewards_train/rejected': '-6.3374', 'rewards_train/margins': '6.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23749', 'examples_per_second': '5.2369', 'grad_norm': '4.875', 'counters/examples': 206208, 'counters/updates': 12888}
skipping logging after 206224 examples to avoid logging too frequently
skipping logging after 206240 examples to avoid logging too frequently
skipping logging after 206256 examples to avoid logging too frequently
train stats after 206272 examples: {'rewards_train/chosen': '0.08287', 'rewards_train/rejected': '-5.7799', 'rewards_train/margins': '5.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28955', 'examples_per_second': '4.5671', 'grad_norm': '5.375', 'counters/examples': 206272, 'counters/updates': 12892}
skipping logging after 206288 examples to avoid logging too frequently
skipping logging after 206304 examples to avoid logging too frequently
skipping logging after 206320 examples to avoid logging too frequently
train stats after 206336 examples: {'rewards_train/chosen': '0.60242', 'rewards_train/rejected': '-6.8789', 'rewards_train/margins': '7.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20483', 'examples_per_second': '5.1373', 'grad_norm': '4.5625', 'counters/examples': 206336, 'counters/updates': 12896}
skipping logging after 206352 examples to avoid logging too frequently
skipping logging after 206368 examples to avoid logging too frequently
skipping logging after 206384 examples to avoid logging too frequently
train stats after 206400 examples: {'rewards_train/chosen': '0.45821', 'rewards_train/rejected': '-5.2948', 'rewards_train/margins': '5.6641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20917', 'examples_per_second': '5.1721', 'grad_norm': '5', 'counters/examples': 206400, 'counters/updates': 12900}
skipping logging after 206416 examples to avoid logging too frequently
skipping logging after 206432 examples to avoid logging too frequently
skipping logging after 206448 examples to avoid logging too frequently
train stats after 206464 examples: {'rewards_train/chosen': '0.28222', 'rewards_train/rejected': '-5.5569', 'rewards_train/margins': '5.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26672', 'examples_per_second': '4.8249', 'grad_norm': '5.3125', 'counters/examples': 206464, 'counters/updates': 12904}
skipping logging after 206480 examples to avoid logging too frequently
skipping logging after 206496 examples to avoid logging too frequently
skipping logging after 206512 examples to avoid logging too frequently
train stats after 206528 examples: {'rewards_train/chosen': '0.37799', 'rewards_train/rejected': '-6.9943', 'rewards_train/margins': '7.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21362', 'examples_per_second': '5.3506', 'grad_norm': '4.5938', 'counters/examples': 206528, 'counters/updates': 12908}
skipping logging after 206544 examples to avoid logging too frequently
skipping logging after 206560 examples to avoid logging too frequently
skipping logging after 206576 examples to avoid logging too frequently
train stats after 206592 examples: {'rewards_train/chosen': '-0.25638', 'rewards_train/rejected': '-6.3608', 'rewards_train/margins': '6.0508', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2063', 'examples_per_second': '4.8504', 'grad_norm': '4.25', 'counters/examples': 206592, 'counters/updates': 12912}
skipping logging after 206608 examples to avoid logging too frequently
skipping logging after 206624 examples to avoid logging too frequently
skipping logging after 206640 examples to avoid logging too frequently
train stats after 206656 examples: {'rewards_train/chosen': '0.3488', 'rewards_train/rejected': '-7.612', 'rewards_train/margins': '7.7109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19983', 'examples_per_second': '4.5945', 'grad_norm': '5.3438', 'counters/examples': 206656, 'counters/updates': 12916}
skipping logging after 206672 examples to avoid logging too frequently
skipping logging after 206688 examples to avoid logging too frequently
skipping logging after 206704 examples to avoid logging too frequently
train stats after 206720 examples: {'rewards_train/chosen': '0.23115', 'rewards_train/rejected': '-6.452', 'rewards_train/margins': '6.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22003', 'examples_per_second': '4.1347', 'grad_norm': '5.0625', 'counters/examples': 206720, 'counters/updates': 12920}
skipping logging after 206736 examples to avoid logging too frequently
skipping logging after 206752 examples to avoid logging too frequently
skipping logging after 206768 examples to avoid logging too frequently
train stats after 206784 examples: {'rewards_train/chosen': '0.18025', 'rewards_train/rejected': '-5.7215', 'rewards_train/margins': '5.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2157', 'examples_per_second': '5.5628', 'grad_norm': '5.125', 'counters/examples': 206784, 'counters/updates': 12924}
skipping logging after 206800 examples to avoid logging too frequently
skipping logging after 206816 examples to avoid logging too frequently
skipping logging after 206832 examples to avoid logging too frequently
train stats after 206848 examples: {'rewards_train/chosen': '0.45532', 'rewards_train/rejected': '-6.0408', 'rewards_train/margins': '6.5391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22473', 'examples_per_second': '3.8321', 'grad_norm': '4.5312', 'counters/examples': 206848, 'counters/updates': 12928}
skipping logging after 206864 examples to avoid logging too frequently
skipping logging after 206880 examples to avoid logging too frequently
skipping logging after 206896 examples to avoid logging too frequently
train stats after 206912 examples: {'rewards_train/chosen': '-0.021687', 'rewards_train/rejected': '-5.57', 'rewards_train/margins': '5.7422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30603', 'examples_per_second': '6.0332', 'grad_norm': '5.6562', 'counters/examples': 206912, 'counters/updates': 12932}
skipping logging after 206928 examples to avoid logging too frequently
skipping logging after 206944 examples to avoid logging too frequently
skipping logging after 206960 examples to avoid logging too frequently
train stats after 206976 examples: {'rewards_train/chosen': '0.22243', 'rewards_train/rejected': '-5.4496', 'rewards_train/margins': '5.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.31079', 'examples_per_second': '5.0212', 'grad_norm': '4.875', 'counters/examples': 206976, 'counters/updates': 12936}
skipping logging after 206992 examples to avoid logging too frequently
skipping logging after 207008 examples to avoid logging too frequently
skipping logging after 207024 examples to avoid logging too frequently
train stats after 207040 examples: {'rewards_train/chosen': '0.48722', 'rewards_train/rejected': '-7.7283', 'rewards_train/margins': '8.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21448', 'examples_per_second': '4.2065', 'grad_norm': '4', 'counters/examples': 207040, 'counters/updates': 12940}
skipping logging after 207056 examples to avoid logging too frequently
skipping logging after 207072 examples to avoid logging too frequently
skipping logging after 207088 examples to avoid logging too frequently
train stats after 207104 examples: {'rewards_train/chosen': '0.34504', 'rewards_train/rejected': '-6.7577', 'rewards_train/margins': '7.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26111', 'examples_per_second': '4.3698', 'grad_norm': '5.5', 'counters/examples': 207104, 'counters/updates': 12944}
skipping logging after 207120 examples to avoid logging too frequently
skipping logging after 207136 examples to avoid logging too frequently
skipping logging after 207152 examples to avoid logging too frequently
train stats after 207168 examples: {'rewards_train/chosen': '0.23777', 'rewards_train/rejected': '-6.8415', 'rewards_train/margins': '7', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25061', 'examples_per_second': '5.7081', 'grad_norm': '5.4062', 'counters/examples': 207168, 'counters/updates': 12948}
skipping logging after 207184 examples to avoid logging too frequently
skipping logging after 207200 examples to avoid logging too frequently
skipping logging after 207216 examples to avoid logging too frequently
train stats after 207232 examples: {'rewards_train/chosen': '0.55609', 'rewards_train/rejected': '-5.4897', 'rewards_train/margins': '6.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2359', 'examples_per_second': '5.1539', 'grad_norm': '5.125', 'counters/examples': 207232, 'counters/updates': 12952}
skipping logging after 207248 examples to avoid logging too frequently
skipping logging after 207264 examples to avoid logging too frequently
skipping logging after 207280 examples to avoid logging too frequently
train stats after 207296 examples: {'rewards_train/chosen': '0.20726', 'rewards_train/rejected': '-6.2785', 'rewards_train/margins': '6.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24341', 'examples_per_second': '4.697', 'grad_norm': '4.4375', 'counters/examples': 207296, 'counters/updates': 12956}
skipping logging after 207312 examples to avoid logging too frequently
skipping logging after 207328 examples to avoid logging too frequently
skipping logging after 207344 examples to avoid logging too frequently
train stats after 207360 examples: {'rewards_train/chosen': '0.52621', 'rewards_train/rejected': '-6.5756', 'rewards_train/margins': '7.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19885', 'examples_per_second': '5.6759', 'grad_norm': '4.4375', 'counters/examples': 207360, 'counters/updates': 12960}
skipping logging after 207376 examples to avoid logging too frequently
skipping logging after 207392 examples to avoid logging too frequently
skipping logging after 207408 examples to avoid logging too frequently
train stats after 207424 examples: {'rewards_train/chosen': '0.1402', 'rewards_train/rejected': '-6.5932', 'rewards_train/margins': '6.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23547', 'examples_per_second': '5.1556', 'grad_norm': '4.4688', 'counters/examples': 207424, 'counters/updates': 12964}
skipping logging after 207440 examples to avoid logging too frequently
skipping logging after 207456 examples to avoid logging too frequently
skipping logging after 207472 examples to avoid logging too frequently
train stats after 207488 examples: {'rewards_train/chosen': '0.27414', 'rewards_train/rejected': '-6.5199', 'rewards_train/margins': '6.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20526', 'examples_per_second': '4.6203', 'grad_norm': '6.125', 'counters/examples': 207488, 'counters/updates': 12968}
skipping logging after 207504 examples to avoid logging too frequently
skipping logging after 207520 examples to avoid logging too frequently
skipping logging after 207536 examples to avoid logging too frequently
train stats after 207552 examples: {'rewards_train/chosen': '0.47418', 'rewards_train/rejected': '-5.3464', 'rewards_train/margins': '5.8906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2597', 'examples_per_second': '5.9035', 'grad_norm': '5.2188', 'counters/examples': 207552, 'counters/updates': 12972}
skipping logging after 207568 examples to avoid logging too frequently
skipping logging after 207584 examples to avoid logging too frequently
skipping logging after 207600 examples to avoid logging too frequently
train stats after 207616 examples: {'rewards_train/chosen': '0.39418', 'rewards_train/rejected': '-5.7814', 'rewards_train/margins': '6.1406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20081', 'examples_per_second': '5.5749', 'grad_norm': '4.25', 'counters/examples': 207616, 'counters/updates': 12976}
skipping logging after 207632 examples to avoid logging too frequently
skipping logging after 207648 examples to avoid logging too frequently
skipping logging after 207664 examples to avoid logging too frequently
train stats after 207680 examples: {'rewards_train/chosen': '0.10598', 'rewards_train/rejected': '-4.9253', 'rewards_train/margins': '4.8633', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28949', 'examples_per_second': '5.2325', 'grad_norm': '5.2812', 'counters/examples': 207680, 'counters/updates': 12980}
skipping logging after 207696 examples to avoid logging too frequently
skipping logging after 207712 examples to avoid logging too frequently
skipping logging after 207728 examples to avoid logging too frequently
train stats after 207744 examples: {'rewards_train/chosen': '0.50628', 'rewards_train/rejected': '-8.0358', 'rewards_train/margins': '8.6562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22229', 'examples_per_second': '4.5224', 'grad_norm': '5.25', 'counters/examples': 207744, 'counters/updates': 12984}
skipping logging after 207760 examples to avoid logging too frequently
skipping logging after 207776 examples to avoid logging too frequently
skipping logging after 207792 examples to avoid logging too frequently
train stats after 207808 examples: {'rewards_train/chosen': '0.52833', 'rewards_train/rejected': '-6.2323', 'rewards_train/margins': '6.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20477', 'examples_per_second': '4.4846', 'grad_norm': '4.875', 'counters/examples': 207808, 'counters/updates': 12988}
skipping logging after 207824 examples to avoid logging too frequently
skipping logging after 207840 examples to avoid logging too frequently
skipping logging after 207856 examples to avoid logging too frequently
train stats after 207872 examples: {'rewards_train/chosen': '0.4195', 'rewards_train/rejected': '-5.8731', 'rewards_train/margins': '6.6289', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23779', 'examples_per_second': '5.1128', 'grad_norm': '5.4062', 'counters/examples': 207872, 'counters/updates': 12992}
skipping logging after 207888 examples to avoid logging too frequently
skipping logging after 207904 examples to avoid logging too frequently
skipping logging after 207920 examples to avoid logging too frequently
train stats after 207936 examples: {'rewards_train/chosen': '0.37777', 'rewards_train/rejected': '-5.0714', 'rewards_train/margins': '5.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26703', 'examples_per_second': '4.6366', 'grad_norm': '4.9375', 'counters/examples': 207936, 'counters/updates': 12996}
skipping logging after 207952 examples to avoid logging too frequently
skipping logging after 207968 examples to avoid logging too frequently
skipping logging after 207984 examples to avoid logging too frequently
train stats after 208000 examples: {'rewards_train/chosen': '0.38615', 'rewards_train/rejected': '-5.2968', 'rewards_train/margins': '5.7031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21161', 'examples_per_second': '5.6807', 'grad_norm': '5.2188', 'counters/examples': 208000, 'counters/updates': 13000}
Running evaluation after 208000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.25s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.17s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:39,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.65s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.47s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:33,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.51s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.40s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:30,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.22s/it]Computing eval metrics:  50%|█████     | 16/32 [00:21<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.42s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.20s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.31s/it]
eval after 208000: {'rewards_eval/chosen': '-5.8067', 'rewards_eval/rejected': '-6.4302', 'rewards_eval/margins': '0.46777', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.45981'}
skipping logging after 208016 examples to avoid logging too frequently
skipping logging after 208032 examples to avoid logging too frequently
skipping logging after 208048 examples to avoid logging too frequently
train stats after 208064 examples: {'rewards_train/chosen': '0.61239', 'rewards_train/rejected': '-6.8887', 'rewards_train/margins': '7.5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1886', 'examples_per_second': '5.4558', 'grad_norm': '4.4688', 'counters/examples': 208064, 'counters/updates': 13004}
skipping logging after 208080 examples to avoid logging too frequently
skipping logging after 208096 examples to avoid logging too frequently
skipping logging after 208112 examples to avoid logging too frequently
train stats after 208128 examples: {'rewards_train/chosen': '0.31493', 'rewards_train/rejected': '-7.0831', 'rewards_train/margins': '7.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23834', 'examples_per_second': '5.1395', 'grad_norm': '5.4062', 'counters/examples': 208128, 'counters/updates': 13008}
skipping logging after 208144 examples to avoid logging too frequently
skipping logging after 208160 examples to avoid logging too frequently
skipping logging after 208176 examples to avoid logging too frequently
train stats after 208192 examples: {'rewards_train/chosen': '0.32742', 'rewards_train/rejected': '-5.9965', 'rewards_train/margins': '6.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21655', 'examples_per_second': '5.3062', 'grad_norm': '5.1562', 'counters/examples': 208192, 'counters/updates': 13012}
skipping logging after 208208 examples to avoid logging too frequently
skipping logging after 208224 examples to avoid logging too frequently
skipping logging after 208240 examples to avoid logging too frequently
train stats after 208256 examples: {'rewards_train/chosen': '0.69276', 'rewards_train/rejected': '-6.3034', 'rewards_train/margins': '6.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17853', 'examples_per_second': '5.0189', 'grad_norm': '4.25', 'counters/examples': 208256, 'counters/updates': 13016}
skipping logging after 208272 examples to avoid logging too frequently
skipping logging after 208288 examples to avoid logging too frequently
skipping logging after 208304 examples to avoid logging too frequently
train stats after 208320 examples: {'rewards_train/chosen': '0.25628', 'rewards_train/rejected': '-6.545', 'rewards_train/margins': '6.9375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22833', 'examples_per_second': '5.349', 'grad_norm': '4.6875', 'counters/examples': 208320, 'counters/updates': 13020}
skipping logging after 208336 examples to avoid logging too frequently
skipping logging after 208352 examples to avoid logging too frequently
skipping logging after 208368 examples to avoid logging too frequently
train stats after 208384 examples: {'rewards_train/chosen': '0.28154', 'rewards_train/rejected': '-5.4813', 'rewards_train/margins': '5.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22681', 'examples_per_second': '5.8896', 'grad_norm': '4.7188', 'counters/examples': 208384, 'counters/updates': 13024}
skipping logging after 208400 examples to avoid logging too frequently
skipping logging after 208416 examples to avoid logging too frequently
skipping logging after 208432 examples to avoid logging too frequently
train stats after 208448 examples: {'rewards_train/chosen': '-0.063757', 'rewards_train/rejected': '-7.2372', 'rewards_train/margins': '7.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24762', 'examples_per_second': '5.8235', 'grad_norm': '4.9688', 'counters/examples': 208448, 'counters/updates': 13028}
skipping logging after 208464 examples to avoid logging too frequently
skipping logging after 208480 examples to avoid logging too frequently
skipping logging after 208496 examples to avoid logging too frequently
train stats after 208512 examples: {'rewards_train/chosen': '0.16976', 'rewards_train/rejected': '-7.8214', 'rewards_train/margins': '8.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24957', 'examples_per_second': '4.611', 'grad_norm': '5.0938', 'counters/examples': 208512, 'counters/updates': 13032}
skipping logging after 208528 examples to avoid logging too frequently
skipping logging after 208544 examples to avoid logging too frequently
skipping logging after 208560 examples to avoid logging too frequently
train stats after 208576 examples: {'rewards_train/chosen': '0.44845', 'rewards_train/rejected': '-6.6403', 'rewards_train/margins': '7.0234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21289', 'examples_per_second': '4.4329', 'grad_norm': '5.25', 'counters/examples': 208576, 'counters/updates': 13036}
skipping logging after 208592 examples to avoid logging too frequently
skipping logging after 208608 examples to avoid logging too frequently
skipping logging after 208624 examples to avoid logging too frequently
train stats after 208640 examples: {'rewards_train/chosen': '0.35856', 'rewards_train/rejected': '-5.8867', 'rewards_train/margins': '6.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1756', 'examples_per_second': '5.0371', 'grad_norm': '4.0625', 'counters/examples': 208640, 'counters/updates': 13040}
skipping logging after 208656 examples to avoid logging too frequently
skipping logging after 208672 examples to avoid logging too frequently
skipping logging after 208688 examples to avoid logging too frequently
train stats after 208704 examples: {'rewards_train/chosen': '0.66604', 'rewards_train/rejected': '-6.2255', 'rewards_train/margins': '6.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.16766', 'examples_per_second': '6.1466', 'grad_norm': '4.2812', 'counters/examples': 208704, 'counters/updates': 13044}
skipping logging after 208720 examples to avoid logging too frequently
skipping logging after 208736 examples to avoid logging too frequently
skipping logging after 208752 examples to avoid logging too frequently
train stats after 208768 examples: {'rewards_train/chosen': '0.4568', 'rewards_train/rejected': '-5.3699', 'rewards_train/margins': '5.8984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2677', 'examples_per_second': '4.4696', 'grad_norm': '5.4375', 'counters/examples': 208768, 'counters/updates': 13048}
skipping logging after 208784 examples to avoid logging too frequently
skipping logging after 208800 examples to avoid logging too frequently
skipping logging after 208816 examples to avoid logging too frequently
train stats after 208832 examples: {'rewards_train/chosen': '-0.028175', 'rewards_train/rejected': '-6.0618', 'rewards_train/margins': '6.1016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2627', 'examples_per_second': '5.8309', 'grad_norm': '5.3438', 'counters/examples': 208832, 'counters/updates': 13052}
skipping logging after 208848 examples to avoid logging too frequently
skipping logging after 208864 examples to avoid logging too frequently
skipping logging after 208880 examples to avoid logging too frequently
train stats after 208896 examples: {'rewards_train/chosen': '0.024481', 'rewards_train/rejected': '-7.2197', 'rewards_train/margins': '7.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24445', 'examples_per_second': '6.6014', 'grad_norm': '4.75', 'counters/examples': 208896, 'counters/updates': 13056}
skipping logging after 208912 examples to avoid logging too frequently
skipping logging after 208928 examples to avoid logging too frequently
skipping logging after 208944 examples to avoid logging too frequently
train stats after 208960 examples: {'rewards_train/chosen': '0.4105', 'rewards_train/rejected': '-5.7769', 'rewards_train/margins': '6.1953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23242', 'examples_per_second': '3.7015', 'grad_norm': '4.5625', 'counters/examples': 208960, 'counters/updates': 13060}
skipping logging after 208976 examples to avoid logging too frequently
skipping logging after 208992 examples to avoid logging too frequently
skipping logging after 209008 examples to avoid logging too frequently
train stats after 209024 examples: {'rewards_train/chosen': '0.3354', 'rewards_train/rejected': '-5.8359', 'rewards_train/margins': '5.5781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25116', 'examples_per_second': '4.7417', 'grad_norm': '4.6562', 'counters/examples': 209024, 'counters/updates': 13064}
skipping logging after 209040 examples to avoid logging too frequently
skipping logging after 209056 examples to avoid logging too frequently
skipping logging after 209072 examples to avoid logging too frequently
train stats after 209088 examples: {'rewards_train/chosen': '0.30099', 'rewards_train/rejected': '-5.4887', 'rewards_train/margins': '5.7891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19916', 'examples_per_second': '4.8646', 'grad_norm': '3.875', 'counters/examples': 209088, 'counters/updates': 13068}
skipping logging after 209104 examples to avoid logging too frequently
skipping logging after 209120 examples to avoid logging too frequently
skipping logging after 209136 examples to avoid logging too frequently
train stats after 209152 examples: {'rewards_train/chosen': '0.68015', 'rewards_train/rejected': '-5.8428', 'rewards_train/margins': '7.125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2348', 'examples_per_second': '4.7799', 'grad_norm': '5.5', 'counters/examples': 209152, 'counters/updates': 13072}
skipping logging after 209168 examples to avoid logging too frequently
skipping logging after 209184 examples to avoid logging too frequently
skipping logging after 209200 examples to avoid logging too frequently
train stats after 209216 examples: {'rewards_train/chosen': '0.51256', 'rewards_train/rejected': '-5.8059', 'rewards_train/margins': '6.3242', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23877', 'examples_per_second': '5.1042', 'grad_norm': '5.7188', 'counters/examples': 209216, 'counters/updates': 13076}
skipping logging after 209232 examples to avoid logging too frequently
skipping logging after 209248 examples to avoid logging too frequently
skipping logging after 209264 examples to avoid logging too frequently
train stats after 209280 examples: {'rewards_train/chosen': '0.42091', 'rewards_train/rejected': '-5.3235', 'rewards_train/margins': '5.6484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26947', 'examples_per_second': '4.8931', 'grad_norm': '5.5938', 'counters/examples': 209280, 'counters/updates': 13080}
skipping logging after 209296 examples to avoid logging too frequently
skipping logging after 209312 examples to avoid logging too frequently
skipping logging after 209328 examples to avoid logging too frequently
train stats after 209344 examples: {'rewards_train/chosen': '0.040569', 'rewards_train/rejected': '-6.0748', 'rewards_train/margins': '6.1172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25867', 'examples_per_second': '4.3651', 'grad_norm': '5.3438', 'counters/examples': 209344, 'counters/updates': 13084}
skipping logging after 209360 examples to avoid logging too frequently
skipping logging after 209376 examples to avoid logging too frequently
skipping logging after 209392 examples to avoid logging too frequently
train stats after 209408 examples: {'rewards_train/chosen': '0.23525', 'rewards_train/rejected': '-5.7045', 'rewards_train/margins': '5.832', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27838', 'examples_per_second': '4.4665', 'grad_norm': '4.7188', 'counters/examples': 209408, 'counters/updates': 13088}
skipping logging after 209424 examples to avoid logging too frequently
skipping logging after 209440 examples to avoid logging too frequently
skipping logging after 209456 examples to avoid logging too frequently
train stats after 209472 examples: {'rewards_train/chosen': '0.59398', 'rewards_train/rejected': '-6.3473', 'rewards_train/margins': '6.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22174', 'examples_per_second': '4.8248', 'grad_norm': '5.5312', 'counters/examples': 209472, 'counters/updates': 13092}
skipping logging after 209488 examples to avoid logging too frequently
skipping logging after 209504 examples to avoid logging too frequently
skipping logging after 209520 examples to avoid logging too frequently
train stats after 209536 examples: {'rewards_train/chosen': '0.58706', 'rewards_train/rejected': '-6.8265', 'rewards_train/margins': '7.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20691', 'examples_per_second': '4.6374', 'grad_norm': '4.2188', 'counters/examples': 209536, 'counters/updates': 13096}
skipping logging after 209552 examples to avoid logging too frequently
skipping logging after 209568 examples to avoid logging too frequently
skipping logging after 209584 examples to avoid logging too frequently
train stats after 209600 examples: {'rewards_train/chosen': '0.21178', 'rewards_train/rejected': '-5.7892', 'rewards_train/margins': '5.7266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24689', 'examples_per_second': '5.614', 'grad_norm': '7.375', 'counters/examples': 209600, 'counters/updates': 13100}
skipping logging after 209616 examples to avoid logging too frequently
skipping logging after 209632 examples to avoid logging too frequently
skipping logging after 209648 examples to avoid logging too frequently
train stats after 209664 examples: {'rewards_train/chosen': '0.043391', 'rewards_train/rejected': '-6.7944', 'rewards_train/margins': '7.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30511', 'examples_per_second': '4.695', 'grad_norm': '5.4375', 'counters/examples': 209664, 'counters/updates': 13104}
skipping logging after 209680 examples to avoid logging too frequently
skipping logging after 209696 examples to avoid logging too frequently
skipping logging after 209712 examples to avoid logging too frequently
train stats after 209728 examples: {'rewards_train/chosen': '0.47113', 'rewards_train/rejected': '-5.3284', 'rewards_train/margins': '5.7539', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22565', 'examples_per_second': '5.6658', 'grad_norm': '4.75', 'counters/examples': 209728, 'counters/updates': 13108}
skipping logging after 209744 examples to avoid logging too frequently
skipping logging after 209760 examples to avoid logging too frequently
skipping logging after 209776 examples to avoid logging too frequently
train stats after 209792 examples: {'rewards_train/chosen': '0.82802', 'rewards_train/rejected': '-5.1366', 'rewards_train/margins': '5.6875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19189', 'examples_per_second': '5.8751', 'grad_norm': '4.2188', 'counters/examples': 209792, 'counters/updates': 13112}
skipping logging after 209808 examples to avoid logging too frequently
skipping logging after 209824 examples to avoid logging too frequently
skipping logging after 209840 examples to avoid logging too frequently
train stats after 209856 examples: {'rewards_train/chosen': '-0.18436', 'rewards_train/rejected': '-5.6492', 'rewards_train/margins': '5.5391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29059', 'examples_per_second': '4.3542', 'grad_norm': '5.9375', 'counters/examples': 209856, 'counters/updates': 13116}
skipping logging after 209872 examples to avoid logging too frequently
skipping logging after 209888 examples to avoid logging too frequently
skipping logging after 209904 examples to avoid logging too frequently
train stats after 209920 examples: {'rewards_train/chosen': '0.33852', 'rewards_train/rejected': '-6.9008', 'rewards_train/margins': '7.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25616', 'examples_per_second': '5.3541', 'grad_norm': '4.7812', 'counters/examples': 209920, 'counters/updates': 13120}
skipping logging after 209936 examples to avoid logging too frequently
skipping logging after 209952 examples to avoid logging too frequently
skipping logging after 209968 examples to avoid logging too frequently
train stats after 209984 examples: {'rewards_train/chosen': '-0.034751', 'rewards_train/rejected': '-7.5995', 'rewards_train/margins': '7.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27667', 'examples_per_second': '5.0631', 'grad_norm': '5.1562', 'counters/examples': 209984, 'counters/updates': 13124}
skipping logging after 210000 examples to avoid logging too frequently
skipping logging after 210016 examples to avoid logging too frequently
skipping logging after 210032 examples to avoid logging too frequently
train stats after 210048 examples: {'rewards_train/chosen': '0.24301', 'rewards_train/rejected': '-7.157', 'rewards_train/margins': '7.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2431', 'examples_per_second': '4.979', 'grad_norm': '4.6875', 'counters/examples': 210048, 'counters/updates': 13128}
skipping logging after 210064 examples to avoid logging too frequently
skipping logging after 210080 examples to avoid logging too frequently
skipping logging after 210096 examples to avoid logging too frequently
train stats after 210112 examples: {'rewards_train/chosen': '0.33207', 'rewards_train/rejected': '-5.3791', 'rewards_train/margins': '5.4961', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23401', 'examples_per_second': '6.7807', 'grad_norm': '6.0312', 'counters/examples': 210112, 'counters/updates': 13132}
skipping logging after 210128 examples to avoid logging too frequently
skipping logging after 210144 examples to avoid logging too frequently
skipping logging after 210160 examples to avoid logging too frequently
train stats after 210176 examples: {'rewards_train/chosen': '0.2935', 'rewards_train/rejected': '-4.8374', 'rewards_train/margins': '4.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23663', 'examples_per_second': '5.2819', 'grad_norm': '4.875', 'counters/examples': 210176, 'counters/updates': 13136}
skipping logging after 210192 examples to avoid logging too frequently
skipping logging after 210208 examples to avoid logging too frequently
skipping logging after 210224 examples to avoid logging too frequently
train stats after 210240 examples: {'rewards_train/chosen': '0.16689', 'rewards_train/rejected': '-4.9133', 'rewards_train/margins': '5.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25244', 'examples_per_second': '5.7755', 'grad_norm': '4.875', 'counters/examples': 210240, 'counters/updates': 13140}
skipping logging after 210256 examples to avoid logging too frequently
skipping logging after 210272 examples to avoid logging too frequently
skipping logging after 210288 examples to avoid logging too frequently
train stats after 210304 examples: {'rewards_train/chosen': '0.083539', 'rewards_train/rejected': '-6.4033', 'rewards_train/margins': '6.4844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25885', 'examples_per_second': '5.7956', 'grad_norm': '4.5938', 'counters/examples': 210304, 'counters/updates': 13144}
skipping logging after 210320 examples to avoid logging too frequently
skipping logging after 210336 examples to avoid logging too frequently
skipping logging after 210352 examples to avoid logging too frequently
train stats after 210368 examples: {'rewards_train/chosen': '0.32536', 'rewards_train/rejected': '-6.1426', 'rewards_train/margins': '6.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2348', 'examples_per_second': '4.9424', 'grad_norm': '4.9375', 'counters/examples': 210368, 'counters/updates': 13148}
skipping logging after 210384 examples to avoid logging too frequently
skipping logging after 210400 examples to avoid logging too frequently
skipping logging after 210416 examples to avoid logging too frequently
train stats after 210432 examples: {'rewards_train/chosen': '0.32609', 'rewards_train/rejected': '-6.0993', 'rewards_train/margins': '6.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19348', 'examples_per_second': '5.927', 'grad_norm': '4.875', 'counters/examples': 210432, 'counters/updates': 13152}
skipping logging after 210448 examples to avoid logging too frequently
skipping logging after 210464 examples to avoid logging too frequently
skipping logging after 210480 examples to avoid logging too frequently
train stats after 210496 examples: {'rewards_train/chosen': '0.12077', 'rewards_train/rejected': '-5.3758', 'rewards_train/margins': '5.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29504', 'examples_per_second': '5.6108', 'grad_norm': '4.875', 'counters/examples': 210496, 'counters/updates': 13156}
skipping logging after 210512 examples to avoid logging too frequently
skipping logging after 210528 examples to avoid logging too frequently
skipping logging after 210544 examples to avoid logging too frequently
train stats after 210560 examples: {'rewards_train/chosen': '0.36025', 'rewards_train/rejected': '-5.3982', 'rewards_train/margins': '5.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30927', 'examples_per_second': '5.2229', 'grad_norm': '5.75', 'counters/examples': 210560, 'counters/updates': 13160}
skipping logging after 210576 examples to avoid logging too frequently
skipping logging after 210592 examples to avoid logging too frequently
skipping logging after 210608 examples to avoid logging too frequently
train stats after 210624 examples: {'rewards_train/chosen': '0.0088239', 'rewards_train/rejected': '-5.9077', 'rewards_train/margins': '5.9805', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28809', 'examples_per_second': '5.3464', 'grad_norm': '5.375', 'counters/examples': 210624, 'counters/updates': 13164}
skipping logging after 210640 examples to avoid logging too frequently
skipping logging after 210656 examples to avoid logging too frequently
skipping logging after 210672 examples to avoid logging too frequently
train stats after 210688 examples: {'rewards_train/chosen': '0.42111', 'rewards_train/rejected': '-6.224', 'rewards_train/margins': '7.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22662', 'examples_per_second': '6.477', 'grad_norm': '4.625', 'counters/examples': 210688, 'counters/updates': 13168}
skipping logging after 210704 examples to avoid logging too frequently
skipping logging after 210720 examples to avoid logging too frequently
skipping logging after 210736 examples to avoid logging too frequently
train stats after 210752 examples: {'rewards_train/chosen': '0.50937', 'rewards_train/rejected': '-4.9991', 'rewards_train/margins': '5.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23926', 'examples_per_second': '4.7723', 'grad_norm': '5.375', 'counters/examples': 210752, 'counters/updates': 13172}
skipping logging after 210768 examples to avoid logging too frequently
skipping logging after 210784 examples to avoid logging too frequently
skipping logging after 210800 examples to avoid logging too frequently
train stats after 210816 examples: {'rewards_train/chosen': '0.28003', 'rewards_train/rejected': '-5.964', 'rewards_train/margins': '6.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22351', 'examples_per_second': '5.2734', 'grad_norm': '5.2812', 'counters/examples': 210816, 'counters/updates': 13176}
skipping logging after 210832 examples to avoid logging too frequently
skipping logging after 210848 examples to avoid logging too frequently
skipping logging after 210864 examples to avoid logging too frequently
train stats after 210880 examples: {'rewards_train/chosen': '0.7627', 'rewards_train/rejected': '-4.3526', 'rewards_train/margins': '5.1172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21497', 'examples_per_second': '6.0553', 'grad_norm': '4.9375', 'counters/examples': 210880, 'counters/updates': 13180}
skipping logging after 210896 examples to avoid logging too frequently
skipping logging after 210912 examples to avoid logging too frequently
skipping logging after 210928 examples to avoid logging too frequently
train stats after 210944 examples: {'rewards_train/chosen': '-0.22572', 'rewards_train/rejected': '-6.7454', 'rewards_train/margins': '6.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29095', 'examples_per_second': '4.7612', 'grad_norm': '5.4688', 'counters/examples': 210944, 'counters/updates': 13184}
skipping logging after 210960 examples to avoid logging too frequently
skipping logging after 210976 examples to avoid logging too frequently
skipping logging after 210992 examples to avoid logging too frequently
train stats after 211008 examples: {'rewards_train/chosen': '0.22496', 'rewards_train/rejected': '-6.351', 'rewards_train/margins': '6.7578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28571', 'examples_per_second': '4.7181', 'grad_norm': '4.625', 'counters/examples': 211008, 'counters/updates': 13188}
skipping logging after 211024 examples to avoid logging too frequently
skipping logging after 211040 examples to avoid logging too frequently
skipping logging after 211056 examples to avoid logging too frequently
train stats after 211072 examples: {'rewards_train/chosen': '0.46953', 'rewards_train/rejected': '-5.4165', 'rewards_train/margins': '5.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2019', 'examples_per_second': '5.2857', 'grad_norm': '4', 'counters/examples': 211072, 'counters/updates': 13192}
skipping logging after 211088 examples to avoid logging too frequently
skipping logging after 211104 examples to avoid logging too frequently
skipping logging after 211120 examples to avoid logging too frequently
train stats after 211136 examples: {'rewards_train/chosen': '-0.037223', 'rewards_train/rejected': '-6.297', 'rewards_train/margins': '6.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21063', 'examples_per_second': '4.7207', 'grad_norm': '5', 'counters/examples': 211136, 'counters/updates': 13196}
skipping logging after 211152 examples to avoid logging too frequently
skipping logging after 211168 examples to avoid logging too frequently
skipping logging after 211184 examples to avoid logging too frequently
train stats after 211200 examples: {'rewards_train/chosen': '0.13275', 'rewards_train/rejected': '-6.3674', 'rewards_train/margins': '6.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2533', 'examples_per_second': '5.6207', 'grad_norm': '5.25', 'counters/examples': 211200, 'counters/updates': 13200}
skipping logging after 211216 examples to avoid logging too frequently
skipping logging after 211232 examples to avoid logging too frequently
skipping logging after 211248 examples to avoid logging too frequently
train stats after 211264 examples: {'rewards_train/chosen': '0.83156', 'rewards_train/rejected': '-7.0407', 'rewards_train/margins': '7.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17114', 'examples_per_second': '4.494', 'grad_norm': '4.0938', 'counters/examples': 211264, 'counters/updates': 13204}
skipping logging after 211280 examples to avoid logging too frequently
skipping logging after 211296 examples to avoid logging too frequently
skipping logging after 211312 examples to avoid logging too frequently
train stats after 211328 examples: {'rewards_train/chosen': '0.53823', 'rewards_train/rejected': '-7.2817', 'rewards_train/margins': '7.8828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24103', 'examples_per_second': '4.8913', 'grad_norm': '4.4062', 'counters/examples': 211328, 'counters/updates': 13208}
skipping logging after 211344 examples to avoid logging too frequently
skipping logging after 211360 examples to avoid logging too frequently
skipping logging after 211376 examples to avoid logging too frequently
train stats after 211392 examples: {'rewards_train/chosen': '0.46015', 'rewards_train/rejected': '-6.0249', 'rewards_train/margins': '6.4609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21918', 'examples_per_second': '5.0973', 'grad_norm': '5.4688', 'counters/examples': 211392, 'counters/updates': 13212}
skipping logging after 211408 examples to avoid logging too frequently
skipping logging after 211424 examples to avoid logging too frequently
skipping logging after 211440 examples to avoid logging too frequently
train stats after 211456 examples: {'rewards_train/chosen': '0.49925', 'rewards_train/rejected': '-6.121', 'rewards_train/margins': '6.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2146', 'examples_per_second': '5.1318', 'grad_norm': '4.875', 'counters/examples': 211456, 'counters/updates': 13216}
skipping logging after 211472 examples to avoid logging too frequently
skipping logging after 211488 examples to avoid logging too frequently
skipping logging after 211504 examples to avoid logging too frequently
train stats after 211520 examples: {'rewards_train/chosen': '0.28609', 'rewards_train/rejected': '-4.7871', 'rewards_train/margins': '5.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2608', 'examples_per_second': '5.1225', 'grad_norm': '5.1875', 'counters/examples': 211520, 'counters/updates': 13220}
skipping logging after 211536 examples to avoid logging too frequently
skipping logging after 211552 examples to avoid logging too frequently
skipping logging after 211568 examples to avoid logging too frequently
train stats after 211584 examples: {'rewards_train/chosen': '0.17212', 'rewards_train/rejected': '-5.5347', 'rewards_train/margins': '5.7891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22015', 'examples_per_second': '6.021', 'grad_norm': '5.4375', 'counters/examples': 211584, 'counters/updates': 13224}
skipping logging after 211600 examples to avoid logging too frequently
skipping logging after 211616 examples to avoid logging too frequently
skipping logging after 211632 examples to avoid logging too frequently
train stats after 211648 examples: {'rewards_train/chosen': '0.44923', 'rewards_train/rejected': '-6.8524', 'rewards_train/margins': '7.2344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23975', 'examples_per_second': '5.1445', 'grad_norm': '5', 'counters/examples': 211648, 'counters/updates': 13228}
skipping logging after 211664 examples to avoid logging too frequently
skipping logging after 211680 examples to avoid logging too frequently
skipping logging after 211696 examples to avoid logging too frequently
train stats after 211712 examples: {'rewards_train/chosen': '0.11789', 'rewards_train/rejected': '-5.8871', 'rewards_train/margins': '6.0312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23651', 'examples_per_second': '4.7076', 'grad_norm': '5.5', 'counters/examples': 211712, 'counters/updates': 13232}
skipping logging after 211728 examples to avoid logging too frequently
skipping logging after 211744 examples to avoid logging too frequently
skipping logging after 211760 examples to avoid logging too frequently
train stats after 211776 examples: {'rewards_train/chosen': '0.5615', 'rewards_train/rejected': '-5.9656', 'rewards_train/margins': '6.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.16119', 'examples_per_second': '5.4036', 'grad_norm': '4.5625', 'counters/examples': 211776, 'counters/updates': 13236}
skipping logging after 211792 examples to avoid logging too frequently
skipping logging after 211808 examples to avoid logging too frequently
skipping logging after 211824 examples to avoid logging too frequently
train stats after 211840 examples: {'rewards_train/chosen': '0.30994', 'rewards_train/rejected': '-5.1172', 'rewards_train/margins': '5.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28687', 'examples_per_second': '5.7606', 'grad_norm': '5.25', 'counters/examples': 211840, 'counters/updates': 13240}
skipping logging after 211856 examples to avoid logging too frequently
skipping logging after 211872 examples to avoid logging too frequently
skipping logging after 211888 examples to avoid logging too frequently
train stats after 211904 examples: {'rewards_train/chosen': '0.26103', 'rewards_train/rejected': '-6.1363', 'rewards_train/margins': '6.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24408', 'examples_per_second': '5.0412', 'grad_norm': '4.9062', 'counters/examples': 211904, 'counters/updates': 13244}
skipping logging after 211920 examples to avoid logging too frequently
skipping logging after 211936 examples to avoid logging too frequently
skipping logging after 211952 examples to avoid logging too frequently
train stats after 211968 examples: {'rewards_train/chosen': '0.30598', 'rewards_train/rejected': '-7.7581', 'rewards_train/margins': '8.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27686', 'examples_per_second': '4.6089', 'grad_norm': '5.2188', 'counters/examples': 211968, 'counters/updates': 13248}
skipping logging after 211984 examples to avoid logging too frequently
skipping logging after 212000 examples to avoid logging too frequently
Running evaluation after 212000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:50,  1.64s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:42,  1.42s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:36,  1.26s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.48s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.69s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.50s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:10<00:34,  1.37s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.53s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.49s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:31,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.41s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:20<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:21<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.28s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:28<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:12,  1.51s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.42s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.20s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:40<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:41<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]
eval after 212000: {'rewards_eval/chosen': '-5.7528', 'rewards_eval/rejected': '-6.4574', 'rewards_eval/margins': '0.53955', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46144'}
skipping logging after 212016 examples to avoid logging too frequently
train stats after 212032 examples: {'rewards_train/chosen': '0.50026', 'rewards_train/rejected': '-6.0746', 'rewards_train/margins': '6.6094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23389', 'examples_per_second': '6.439', 'grad_norm': '6.4062', 'counters/examples': 212032, 'counters/updates': 13252}
skipping logging after 212048 examples to avoid logging too frequently
skipping logging after 212064 examples to avoid logging too frequently
skipping logging after 212080 examples to avoid logging too frequently
train stats after 212096 examples: {'rewards_train/chosen': '0.45265', 'rewards_train/rejected': '-5.5229', 'rewards_train/margins': '6.0156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21814', 'examples_per_second': '6.1477', 'grad_norm': '4.4062', 'counters/examples': 212096, 'counters/updates': 13256}
skipping logging after 212112 examples to avoid logging too frequently
skipping logging after 212128 examples to avoid logging too frequently
skipping logging after 212144 examples to avoid logging too frequently
train stats after 212160 examples: {'rewards_train/chosen': '0.2906', 'rewards_train/rejected': '-6.1727', 'rewards_train/margins': '6.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2157', 'examples_per_second': '5.6114', 'grad_norm': '4.7188', 'counters/examples': 212160, 'counters/updates': 13260}
skipping logging after 212176 examples to avoid logging too frequently
skipping logging after 212192 examples to avoid logging too frequently
skipping logging after 212208 examples to avoid logging too frequently
train stats after 212224 examples: {'rewards_train/chosen': '0.37592', 'rewards_train/rejected': '-5.0453', 'rewards_train/margins': '5.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24261', 'examples_per_second': '5.8161', 'grad_norm': '5.3438', 'counters/examples': 212224, 'counters/updates': 13264}
skipping logging after 212240 examples to avoid logging too frequently
skipping logging after 212256 examples to avoid logging too frequently
skipping logging after 212272 examples to avoid logging too frequently
train stats after 212288 examples: {'rewards_train/chosen': '0.37062', 'rewards_train/rejected': '-7.0394', 'rewards_train/margins': '6.8984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26556', 'examples_per_second': '4.8642', 'grad_norm': '5.3125', 'counters/examples': 212288, 'counters/updates': 13268}
skipping logging after 212304 examples to avoid logging too frequently
skipping logging after 212320 examples to avoid logging too frequently
skipping logging after 212336 examples to avoid logging too frequently
train stats after 212352 examples: {'rewards_train/chosen': '0.25255', 'rewards_train/rejected': '-5.8319', 'rewards_train/margins': '6.0156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2193', 'examples_per_second': '5.6157', 'grad_norm': '4.6875', 'counters/examples': 212352, 'counters/updates': 13272}
skipping logging after 212368 examples to avoid logging too frequently
skipping logging after 212384 examples to avoid logging too frequently
skipping logging after 212400 examples to avoid logging too frequently
train stats after 212416 examples: {'rewards_train/chosen': '-0.22376', 'rewards_train/rejected': '-7.3245', 'rewards_train/margins': '7.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27344', 'examples_per_second': '4.7246', 'grad_norm': '4.6875', 'counters/examples': 212416, 'counters/updates': 13276}
skipping logging after 212432 examples to avoid logging too frequently
skipping logging after 212448 examples to avoid logging too frequently
skipping logging after 212464 examples to avoid logging too frequently
train stats after 212480 examples: {'rewards_train/chosen': '0.070821', 'rewards_train/rejected': '-5.4716', 'rewards_train/margins': '5.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27527', 'examples_per_second': '5.7395', 'grad_norm': '4.8125', 'counters/examples': 212480, 'counters/updates': 13280}
skipping logging after 212496 examples to avoid logging too frequently
skipping logging after 212512 examples to avoid logging too frequently
skipping logging after 212528 examples to avoid logging too frequently
train stats after 212544 examples: {'rewards_train/chosen': '0.51552', 'rewards_train/rejected': '-6.1272', 'rewards_train/margins': '6.8672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22113', 'examples_per_second': '4.8251', 'grad_norm': '5.5312', 'counters/examples': 212544, 'counters/updates': 13284}
skipping logging after 212560 examples to avoid logging too frequently
skipping logging after 212576 examples to avoid logging too frequently
skipping logging after 212592 examples to avoid logging too frequently
train stats after 212608 examples: {'rewards_train/chosen': '0.25883', 'rewards_train/rejected': '-6.7712', 'rewards_train/margins': '6.7109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25018', 'examples_per_second': '6.1964', 'grad_norm': '5.375', 'counters/examples': 212608, 'counters/updates': 13288}
skipping logging after 212624 examples to avoid logging too frequently
skipping logging after 212640 examples to avoid logging too frequently
skipping logging after 212656 examples to avoid logging too frequently
train stats after 212672 examples: {'rewards_train/chosen': '0.62503', 'rewards_train/rejected': '-5.5234', 'rewards_train/margins': '6.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23737', 'examples_per_second': '5.2596', 'grad_norm': '5.3438', 'counters/examples': 212672, 'counters/updates': 13292}
skipping logging after 212688 examples to avoid logging too frequently
skipping logging after 212704 examples to avoid logging too frequently
skipping logging after 212720 examples to avoid logging too frequently
train stats after 212736 examples: {'rewards_train/chosen': '0.53089', 'rewards_train/rejected': '-6.2343', 'rewards_train/margins': '6.9766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21381', 'examples_per_second': '5.5886', 'grad_norm': '5.0625', 'counters/examples': 212736, 'counters/updates': 13296}
skipping logging after 212752 examples to avoid logging too frequently
skipping logging after 212768 examples to avoid logging too frequently
skipping logging after 212784 examples to avoid logging too frequently
train stats after 212800 examples: {'rewards_train/chosen': '0.39567', 'rewards_train/rejected': '-6.3647', 'rewards_train/margins': '6.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1911', 'examples_per_second': '6.307', 'grad_norm': '4.875', 'counters/examples': 212800, 'counters/updates': 13300}
skipping logging after 212816 examples to avoid logging too frequently
skipping logging after 212832 examples to avoid logging too frequently
skipping logging after 212848 examples to avoid logging too frequently
train stats after 212864 examples: {'rewards_train/chosen': '0.30507', 'rewards_train/rejected': '-5.3837', 'rewards_train/margins': '5.7578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21844', 'examples_per_second': '4.3887', 'grad_norm': '4.9688', 'counters/examples': 212864, 'counters/updates': 13304}
skipping logging after 212880 examples to avoid logging too frequently
skipping logging after 212896 examples to avoid logging too frequently
skipping logging after 212912 examples to avoid logging too frequently
train stats after 212928 examples: {'rewards_train/chosen': '0.42335', 'rewards_train/rejected': '-8.1175', 'rewards_train/margins': '8.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20612', 'examples_per_second': '5.0038', 'grad_norm': '4.125', 'counters/examples': 212928, 'counters/updates': 13308}
skipping logging after 212944 examples to avoid logging too frequently
skipping logging after 212960 examples to avoid logging too frequently
skipping logging after 212976 examples to avoid logging too frequently
train stats after 212992 examples: {'rewards_train/chosen': '0.25384', 'rewards_train/rejected': '-6.0153', 'rewards_train/margins': '6.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22229', 'examples_per_second': '5.5624', 'grad_norm': '5.1875', 'counters/examples': 212992, 'counters/updates': 13312}
skipping logging after 213008 examples to avoid logging too frequently
skipping logging after 213024 examples to avoid logging too frequently
skipping logging after 213040 examples to avoid logging too frequently
train stats after 213056 examples: {'rewards_train/chosen': '0.36397', 'rewards_train/rejected': '-7.2225', 'rewards_train/margins': '7.7812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26331', 'examples_per_second': '5.4382', 'grad_norm': '4.9375', 'counters/examples': 213056, 'counters/updates': 13316}
skipping logging after 213072 examples to avoid logging too frequently
skipping logging after 213088 examples to avoid logging too frequently
skipping logging after 213104 examples to avoid logging too frequently
train stats after 213120 examples: {'rewards_train/chosen': '0.26793', 'rewards_train/rejected': '-5.7578', 'rewards_train/margins': '5.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25195', 'examples_per_second': '5.5853', 'grad_norm': '5.0312', 'counters/examples': 213120, 'counters/updates': 13320}
skipping logging after 213136 examples to avoid logging too frequently
skipping logging after 213152 examples to avoid logging too frequently
skipping logging after 213168 examples to avoid logging too frequently
train stats after 213184 examples: {'rewards_train/chosen': '0.27916', 'rewards_train/rejected': '-6.41', 'rewards_train/margins': '6.7109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20721', 'examples_per_second': '4.7087', 'grad_norm': '4.1562', 'counters/examples': 213184, 'counters/updates': 13324}
skipping logging after 213200 examples to avoid logging too frequently
skipping logging after 213216 examples to avoid logging too frequently
skipping logging after 213232 examples to avoid logging too frequently
train stats after 213248 examples: {'rewards_train/chosen': '0.062219', 'rewards_train/rejected': '-6.3464', 'rewards_train/margins': '6.3828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28027', 'examples_per_second': '5.6769', 'grad_norm': '6.5', 'counters/examples': 213248, 'counters/updates': 13328}
skipping logging after 213264 examples to avoid logging too frequently
skipping logging after 213280 examples to avoid logging too frequently
skipping logging after 213296 examples to avoid logging too frequently
train stats after 213312 examples: {'rewards_train/chosen': '0.19368', 'rewards_train/rejected': '-6.2871', 'rewards_train/margins': '6.1836', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26367', 'examples_per_second': '6.2148', 'grad_norm': '4.75', 'counters/examples': 213312, 'counters/updates': 13332}
skipping logging after 213328 examples to avoid logging too frequently
skipping logging after 213344 examples to avoid logging too frequently
skipping logging after 213360 examples to avoid logging too frequently
train stats after 213376 examples: {'rewards_train/chosen': '0.62371', 'rewards_train/rejected': '-5.3917', 'rewards_train/margins': '6.0234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2558', 'examples_per_second': '5.545', 'grad_norm': '5.1562', 'counters/examples': 213376, 'counters/updates': 13336}
skipping logging after 213392 examples to avoid logging too frequently
skipping logging after 213408 examples to avoid logging too frequently
skipping logging after 213424 examples to avoid logging too frequently
train stats after 213440 examples: {'rewards_train/chosen': '0.12713', 'rewards_train/rejected': '-6.0574', 'rewards_train/margins': '6.0859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19324', 'examples_per_second': '4.6461', 'grad_norm': '4.5312', 'counters/examples': 213440, 'counters/updates': 13340}
skipping logging after 213456 examples to avoid logging too frequently
skipping logging after 213472 examples to avoid logging too frequently
skipping logging after 213488 examples to avoid logging too frequently
train stats after 213504 examples: {'rewards_train/chosen': '0.19202', 'rewards_train/rejected': '-6.8426', 'rewards_train/margins': '7.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25476', 'examples_per_second': '4.0672', 'grad_norm': '4.9688', 'counters/examples': 213504, 'counters/updates': 13344}
skipping logging after 213520 examples to avoid logging too frequently
skipping logging after 213536 examples to avoid logging too frequently
skipping logging after 213552 examples to avoid logging too frequently
train stats after 213568 examples: {'rewards_train/chosen': '0.57658', 'rewards_train/rejected': '-5.6142', 'rewards_train/margins': '6.2109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22864', 'examples_per_second': '5.3504', 'grad_norm': '4.625', 'counters/examples': 213568, 'counters/updates': 13348}
skipping logging after 213584 examples to avoid logging too frequently
skipping logging after 213600 examples to avoid logging too frequently
skipping logging after 213616 examples to avoid logging too frequently
train stats after 213632 examples: {'rewards_train/chosen': '0.71245', 'rewards_train/rejected': '-6.8421', 'rewards_train/margins': '7.4219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2052', 'examples_per_second': '4.3847', 'grad_norm': '4.5938', 'counters/examples': 213632, 'counters/updates': 13352}
skipping logging after 213648 examples to avoid logging too frequently
skipping logging after 213664 examples to avoid logging too frequently
skipping logging after 213680 examples to avoid logging too frequently
train stats after 213696 examples: {'rewards_train/chosen': '0.58088', 'rewards_train/rejected': '-5.6761', 'rewards_train/margins': '5.9766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22168', 'examples_per_second': '5.5704', 'grad_norm': '5.5312', 'counters/examples': 213696, 'counters/updates': 13356}
skipping logging after 213712 examples to avoid logging too frequently
skipping logging after 213728 examples to avoid logging too frequently
skipping logging after 213744 examples to avoid logging too frequently
train stats after 213760 examples: {'rewards_train/chosen': '0.12364', 'rewards_train/rejected': '-7.8919', 'rewards_train/margins': '7.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28265', 'examples_per_second': '5.2684', 'grad_norm': '5.5625', 'counters/examples': 213760, 'counters/updates': 13360}
skipping logging after 213776 examples to avoid logging too frequently
skipping logging after 213792 examples to avoid logging too frequently
skipping logging after 213808 examples to avoid logging too frequently
train stats after 213824 examples: {'rewards_train/chosen': '0.35', 'rewards_train/rejected': '-5.966', 'rewards_train/margins': '6.3281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18878', 'examples_per_second': '5.1431', 'grad_norm': '3.75', 'counters/examples': 213824, 'counters/updates': 13364}
skipping logging after 213840 examples to avoid logging too frequently
skipping logging after 213856 examples to avoid logging too frequently
skipping logging after 213872 examples to avoid logging too frequently
train stats after 213888 examples: {'rewards_train/chosen': '0.61301', 'rewards_train/rejected': '-4.7211', 'rewards_train/margins': '5.7578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22205', 'examples_per_second': '6.4911', 'grad_norm': '5.0312', 'counters/examples': 213888, 'counters/updates': 13368}
skipping logging after 213904 examples to avoid logging too frequently
skipping logging after 213920 examples to avoid logging too frequently
skipping logging after 213936 examples to avoid logging too frequently
train stats after 213952 examples: {'rewards_train/chosen': '0.37518', 'rewards_train/rejected': '-5.717', 'rewards_train/margins': '5.8711', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2807', 'examples_per_second': '5.9703', 'grad_norm': '5.9375', 'counters/examples': 213952, 'counters/updates': 13372}
skipping logging after 213968 examples to avoid logging too frequently
skipping logging after 213984 examples to avoid logging too frequently
skipping logging after 214000 examples to avoid logging too frequently
train stats after 214016 examples: {'rewards_train/chosen': '0.74615', 'rewards_train/rejected': '-6.3759', 'rewards_train/margins': '7.1719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20099', 'examples_per_second': '4.3993', 'grad_norm': '5.2812', 'counters/examples': 214016, 'counters/updates': 13376}
skipping logging after 214032 examples to avoid logging too frequently
skipping logging after 214048 examples to avoid logging too frequently
skipping logging after 214064 examples to avoid logging too frequently
train stats after 214080 examples: {'rewards_train/chosen': '0.34613', 'rewards_train/rejected': '-6.215', 'rewards_train/margins': '6.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23181', 'examples_per_second': '5.2035', 'grad_norm': '4.6875', 'counters/examples': 214080, 'counters/updates': 13380}
skipping logging after 214096 examples to avoid logging too frequently
skipping logging after 214112 examples to avoid logging too frequently
skipping logging after 214128 examples to avoid logging too frequently
train stats after 214144 examples: {'rewards_train/chosen': '0.35687', 'rewards_train/rejected': '-6.5048', 'rewards_train/margins': '6.6484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23883', 'examples_per_second': '4.1948', 'grad_norm': '4.9688', 'counters/examples': 214144, 'counters/updates': 13384}
skipping logging after 214160 examples to avoid logging too frequently
skipping logging after 214176 examples to avoid logging too frequently
skipping logging after 214192 examples to avoid logging too frequently
train stats after 214208 examples: {'rewards_train/chosen': '0.32585', 'rewards_train/rejected': '-7.0541', 'rewards_train/margins': '7.3594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24127', 'examples_per_second': '6.4511', 'grad_norm': '6.2812', 'counters/examples': 214208, 'counters/updates': 13388}
skipping logging after 214224 examples to avoid logging too frequently
skipping logging after 214240 examples to avoid logging too frequently
skipping logging after 214256 examples to avoid logging too frequently
train stats after 214272 examples: {'rewards_train/chosen': '0.33053', 'rewards_train/rejected': '-6.4294', 'rewards_train/margins': '6.6562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28156', 'examples_per_second': '5.0882', 'grad_norm': '4.75', 'counters/examples': 214272, 'counters/updates': 13392}
skipping logging after 214288 examples to avoid logging too frequently
skipping logging after 214304 examples to avoid logging too frequently
skipping logging after 214320 examples to avoid logging too frequently
train stats after 214336 examples: {'rewards_train/chosen': '0.4543', 'rewards_train/rejected': '-6.0143', 'rewards_train/margins': '6.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23621', 'examples_per_second': '5.9401', 'grad_norm': '4.4688', 'counters/examples': 214336, 'counters/updates': 13396}
skipping logging after 214352 examples to avoid logging too frequently
skipping logging after 214368 examples to avoid logging too frequently
skipping logging after 214384 examples to avoid logging too frequently
train stats after 214400 examples: {'rewards_train/chosen': '-0.045832', 'rewards_train/rejected': '-6.4052', 'rewards_train/margins': '6.6484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26031', 'examples_per_second': '5.5476', 'grad_norm': '6.125', 'counters/examples': 214400, 'counters/updates': 13400}
skipping logging after 214416 examples to avoid logging too frequently
skipping logging after 214432 examples to avoid logging too frequently
skipping logging after 214448 examples to avoid logging too frequently
train stats after 214464 examples: {'rewards_train/chosen': '0.5985', 'rewards_train/rejected': '-5.9236', 'rewards_train/margins': '6.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26746', 'examples_per_second': '6.1088', 'grad_norm': '5.0625', 'counters/examples': 214464, 'counters/updates': 13404}
skipping logging after 214480 examples to avoid logging too frequently
skipping logging after 214496 examples to avoid logging too frequently
skipping logging after 214512 examples to avoid logging too frequently
train stats after 214528 examples: {'rewards_train/chosen': '0.46083', 'rewards_train/rejected': '-5.4751', 'rewards_train/margins': '5.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23914', 'examples_per_second': '5.6857', 'grad_norm': '4.6562', 'counters/examples': 214528, 'counters/updates': 13408}
skipping logging after 214544 examples to avoid logging too frequently
skipping logging after 214560 examples to avoid logging too frequently
skipping logging after 214576 examples to avoid logging too frequently
train stats after 214592 examples: {'rewards_train/chosen': '0.48268', 'rewards_train/rejected': '-6.7268', 'rewards_train/margins': '7.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21954', 'examples_per_second': '4.713', 'grad_norm': '4.625', 'counters/examples': 214592, 'counters/updates': 13412}
skipping logging after 214608 examples to avoid logging too frequently
skipping logging after 214624 examples to avoid logging too frequently
skipping logging after 214640 examples to avoid logging too frequently
train stats after 214656 examples: {'rewards_train/chosen': '0.79516', 'rewards_train/rejected': '-5.2862', 'rewards_train/margins': '6.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1947', 'examples_per_second': '4.621', 'grad_norm': '5.5312', 'counters/examples': 214656, 'counters/updates': 13416}
skipping logging after 214672 examples to avoid logging too frequently
skipping logging after 214688 examples to avoid logging too frequently
skipping logging after 214704 examples to avoid logging too frequently
train stats after 214720 examples: {'rewards_train/chosen': '-0.1745', 'rewards_train/rejected': '-6.3796', 'rewards_train/margins': '6.1719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26172', 'examples_per_second': '4.3643', 'grad_norm': '4.4688', 'counters/examples': 214720, 'counters/updates': 13420}
skipping logging after 214736 examples to avoid logging too frequently
skipping logging after 214752 examples to avoid logging too frequently
skipping logging after 214768 examples to avoid logging too frequently
train stats after 214784 examples: {'rewards_train/chosen': '0.48421', 'rewards_train/rejected': '-6.3623', 'rewards_train/margins': '6.8984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25098', 'examples_per_second': '3.9524', 'grad_norm': '5.8438', 'counters/examples': 214784, 'counters/updates': 13424}
skipping logging after 214800 examples to avoid logging too frequently
skipping logging after 214816 examples to avoid logging too frequently
skipping logging after 214832 examples to avoid logging too frequently
train stats after 214848 examples: {'rewards_train/chosen': '0.41494', 'rewards_train/rejected': '-6.4732', 'rewards_train/margins': '6.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23492', 'examples_per_second': '5.4022', 'grad_norm': '4.2812', 'counters/examples': 214848, 'counters/updates': 13428}
skipping logging after 214864 examples to avoid logging too frequently
skipping logging after 214880 examples to avoid logging too frequently
skipping logging after 214896 examples to avoid logging too frequently
train stats after 214912 examples: {'rewards_train/chosen': '0.056316', 'rewards_train/rejected': '-5.3472', 'rewards_train/margins': '5.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25531', 'examples_per_second': '5.1427', 'grad_norm': '4.875', 'counters/examples': 214912, 'counters/updates': 13432}
skipping logging after 214928 examples to avoid logging too frequently
skipping logging after 214944 examples to avoid logging too frequently
skipping logging after 214960 examples to avoid logging too frequently
train stats after 214976 examples: {'rewards_train/chosen': '0.25987', 'rewards_train/rejected': '-6.0058', 'rewards_train/margins': '6.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26691', 'examples_per_second': '6.3052', 'grad_norm': '5.0312', 'counters/examples': 214976, 'counters/updates': 13436}
skipping logging after 214992 examples to avoid logging too frequently
skipping logging after 215008 examples to avoid logging too frequently
skipping logging after 215024 examples to avoid logging too frequently
train stats after 215040 examples: {'rewards_train/chosen': '0.42821', 'rewards_train/rejected': '-5.3962', 'rewards_train/margins': '5.7891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23846', 'examples_per_second': '6.6592', 'grad_norm': '4.5938', 'counters/examples': 215040, 'counters/updates': 13440}
skipping logging after 215056 examples to avoid logging too frequently
skipping logging after 215072 examples to avoid logging too frequently
skipping logging after 215088 examples to avoid logging too frequently
train stats after 215104 examples: {'rewards_train/chosen': '0.71306', 'rewards_train/rejected': '-6.1675', 'rewards_train/margins': '6.7031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20148', 'examples_per_second': '5.2262', 'grad_norm': '4.875', 'counters/examples': 215104, 'counters/updates': 13444}
skipping logging after 215120 examples to avoid logging too frequently
skipping logging after 215136 examples to avoid logging too frequently
skipping logging after 215152 examples to avoid logging too frequently
train stats after 215168 examples: {'rewards_train/chosen': '0.37207', 'rewards_train/rejected': '-5.629', 'rewards_train/margins': '6.1406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19769', 'examples_per_second': '5.91', 'grad_norm': '3.8281', 'counters/examples': 215168, 'counters/updates': 13448}
skipping logging after 215184 examples to avoid logging too frequently
skipping logging after 215200 examples to avoid logging too frequently
skipping logging after 215216 examples to avoid logging too frequently
train stats after 215232 examples: {'rewards_train/chosen': '0.34484', 'rewards_train/rejected': '-4.4052', 'rewards_train/margins': '4.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25598', 'examples_per_second': '6.4437', 'grad_norm': '6.75', 'counters/examples': 215232, 'counters/updates': 13452}
skipping logging after 215248 examples to avoid logging too frequently
skipping logging after 215264 examples to avoid logging too frequently
skipping logging after 215280 examples to avoid logging too frequently
train stats after 215296 examples: {'rewards_train/chosen': '0.18309', 'rewards_train/rejected': '-7.3042', 'rewards_train/margins': '7.6328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.3103', 'examples_per_second': '5.1032', 'grad_norm': '5.6875', 'counters/examples': 215296, 'counters/updates': 13456}
skipping logging after 215312 examples to avoid logging too frequently
skipping logging after 215328 examples to avoid logging too frequently
skipping logging after 215344 examples to avoid logging too frequently
train stats after 215360 examples: {'rewards_train/chosen': '0.12949', 'rewards_train/rejected': '-6.3681', 'rewards_train/margins': '6.5938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24445', 'examples_per_second': '5.4135', 'grad_norm': '4.3125', 'counters/examples': 215360, 'counters/updates': 13460}
skipping logging after 215376 examples to avoid logging too frequently
skipping logging after 215392 examples to avoid logging too frequently
skipping logging after 215408 examples to avoid logging too frequently
train stats after 215424 examples: {'rewards_train/chosen': '0.28788', 'rewards_train/rejected': '-5.1521', 'rewards_train/margins': '5.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28894', 'examples_per_second': '6.0689', 'grad_norm': '4.5938', 'counters/examples': 215424, 'counters/updates': 13464}
skipping logging after 215440 examples to avoid logging too frequently
skipping logging after 215456 examples to avoid logging too frequently
skipping logging after 215472 examples to avoid logging too frequently
train stats after 215488 examples: {'rewards_train/chosen': '0.58618', 'rewards_train/rejected': '-6.2709', 'rewards_train/margins': '6.5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1991', 'examples_per_second': '5.3043', 'grad_norm': '5.1875', 'counters/examples': 215488, 'counters/updates': 13468}
skipping logging after 215504 examples to avoid logging too frequently
skipping logging after 215520 examples to avoid logging too frequently
skipping logging after 215536 examples to avoid logging too frequently
train stats after 215552 examples: {'rewards_train/chosen': '0.3491', 'rewards_train/rejected': '-5.8887', 'rewards_train/margins': '6.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24335', 'examples_per_second': '4.5558', 'grad_norm': '5.1562', 'counters/examples': 215552, 'counters/updates': 13472}
skipping logging after 215568 examples to avoid logging too frequently
skipping logging after 215584 examples to avoid logging too frequently
skipping logging after 215600 examples to avoid logging too frequently
train stats after 215616 examples: {'rewards_train/chosen': '0.19901', 'rewards_train/rejected': '-6.9134', 'rewards_train/margins': '6.9453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25018', 'examples_per_second': '5.1698', 'grad_norm': '5.0625', 'counters/examples': 215616, 'counters/updates': 13476}
skipping logging after 215632 examples to avoid logging too frequently
skipping logging after 215648 examples to avoid logging too frequently
skipping logging after 215664 examples to avoid logging too frequently
train stats after 215680 examples: {'rewards_train/chosen': '0.38586', 'rewards_train/rejected': '-6.5508', 'rewards_train/margins': '6.8906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2663', 'examples_per_second': '4.6924', 'grad_norm': '5.3438', 'counters/examples': 215680, 'counters/updates': 13480}
skipping logging after 215696 examples to avoid logging too frequently
skipping logging after 215712 examples to avoid logging too frequently
skipping logging after 215728 examples to avoid logging too frequently
train stats after 215744 examples: {'rewards_train/chosen': '0.54337', 'rewards_train/rejected': '-7.7339', 'rewards_train/margins': '8.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20709', 'examples_per_second': '4.9691', 'grad_norm': '4.1875', 'counters/examples': 215744, 'counters/updates': 13484}
skipping logging after 215760 examples to avoid logging too frequently
skipping logging after 215776 examples to avoid logging too frequently
skipping logging after 215792 examples to avoid logging too frequently
train stats after 215808 examples: {'rewards_train/chosen': '0.12352', 'rewards_train/rejected': '-5.5739', 'rewards_train/margins': '5.6875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20312', 'examples_per_second': '5.8747', 'grad_norm': '4.4375', 'counters/examples': 215808, 'counters/updates': 13488}
skipping logging after 215824 examples to avoid logging too frequently
skipping logging after 215840 examples to avoid logging too frequently
skipping logging after 215856 examples to avoid logging too frequently
train stats after 215872 examples: {'rewards_train/chosen': '0.5689', 'rewards_train/rejected': '-5.9371', 'rewards_train/margins': '6.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21002', 'examples_per_second': '5.7924', 'grad_norm': '4.5312', 'counters/examples': 215872, 'counters/updates': 13492}
skipping logging after 215888 examples to avoid logging too frequently
skipping logging after 215904 examples to avoid logging too frequently
skipping logging after 215920 examples to avoid logging too frequently
train stats after 215936 examples: {'rewards_train/chosen': '0.18894', 'rewards_train/rejected': '-6.1635', 'rewards_train/margins': '6.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23535', 'examples_per_second': '5.9699', 'grad_norm': '5.75', 'counters/examples': 215936, 'counters/updates': 13496}
skipping logging after 215952 examples to avoid logging too frequently
skipping logging after 215968 examples to avoid logging too frequently
skipping logging after 215984 examples to avoid logging too frequently
train stats after 216000 examples: {'rewards_train/chosen': '0.63328', 'rewards_train/rejected': '-7.3478', 'rewards_train/margins': '8.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21582', 'examples_per_second': '5.1621', 'grad_norm': '4.8125', 'counters/examples': 216000, 'counters/updates': 13500}
Running evaluation after 216000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.25s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.17s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:40,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.65s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.47s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:34,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.40s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:30,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.28s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.26s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.31s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.18s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.31s/it]
eval after 216000: {'rewards_eval/chosen': '-5.8607', 'rewards_eval/rejected': '-6.5029', 'rewards_eval/margins': '0.4834', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46045'}
skipping logging after 216016 examples to avoid logging too frequently
skipping logging after 216032 examples to avoid logging too frequently
skipping logging after 216048 examples to avoid logging too frequently
train stats after 216064 examples: {'rewards_train/chosen': '0.49967', 'rewards_train/rejected': '-5.5683', 'rewards_train/margins': '5.6641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27942', 'examples_per_second': '4.2119', 'grad_norm': '5.625', 'counters/examples': 216064, 'counters/updates': 13504}
skipping logging after 216080 examples to avoid logging too frequently
skipping logging after 216096 examples to avoid logging too frequently
skipping logging after 216112 examples to avoid logging too frequently
train stats after 216128 examples: {'rewards_train/chosen': '0.076294', 'rewards_train/rejected': '-5.1497', 'rewards_train/margins': '5.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25879', 'examples_per_second': '6.0106', 'grad_norm': '5.4375', 'counters/examples': 216128, 'counters/updates': 13508}
skipping logging after 216144 examples to avoid logging too frequently
skipping logging after 216160 examples to avoid logging too frequently
skipping logging after 216176 examples to avoid logging too frequently
train stats after 216192 examples: {'rewards_train/chosen': '-0.13042', 'rewards_train/rejected': '-7.5363', 'rewards_train/margins': '7.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27325', 'examples_per_second': '4.6172', 'grad_norm': '4.5', 'counters/examples': 216192, 'counters/updates': 13512}
skipping logging after 216208 examples to avoid logging too frequently
skipping logging after 216224 examples to avoid logging too frequently
skipping logging after 216240 examples to avoid logging too frequently
train stats after 216256 examples: {'rewards_train/chosen': '-0.0049438', 'rewards_train/rejected': '-7.1892', 'rewards_train/margins': '7.9453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.284', 'examples_per_second': '5.3899', 'grad_norm': '5.4688', 'counters/examples': 216256, 'counters/updates': 13516}
skipping logging after 216272 examples to avoid logging too frequently
skipping logging after 216288 examples to avoid logging too frequently
skipping logging after 216304 examples to avoid logging too frequently
train stats after 216320 examples: {'rewards_train/chosen': '0.51658', 'rewards_train/rejected': '-4.8577', 'rewards_train/margins': '5.375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26105', 'examples_per_second': '6.0752', 'grad_norm': '6.5', 'counters/examples': 216320, 'counters/updates': 13520}
skipping logging after 216336 examples to avoid logging too frequently
skipping logging after 216352 examples to avoid logging too frequently
skipping logging after 216368 examples to avoid logging too frequently
train stats after 216384 examples: {'rewards_train/chosen': '0.2614', 'rewards_train/rejected': '-6.02', 'rewards_train/margins': '6.375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26794', 'examples_per_second': '5.0885', 'grad_norm': '4.6562', 'counters/examples': 216384, 'counters/updates': 13524}
skipping logging after 216400 examples to avoid logging too frequently
skipping logging after 216416 examples to avoid logging too frequently
skipping logging after 216432 examples to avoid logging too frequently
train stats after 216448 examples: {'rewards_train/chosen': '0.54023', 'rewards_train/rejected': '-5.3523', 'rewards_train/margins': '5.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2511', 'examples_per_second': '6.2625', 'grad_norm': '4.9375', 'counters/examples': 216448, 'counters/updates': 13528}
skipping logging after 216464 examples to avoid logging too frequently
skipping logging after 216480 examples to avoid logging too frequently
skipping logging after 216496 examples to avoid logging too frequently
train stats after 216512 examples: {'rewards_train/chosen': '0.16638', 'rewards_train/rejected': '-5.1743', 'rewards_train/margins': '5.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27905', 'examples_per_second': '5.042', 'grad_norm': '5.4688', 'counters/examples': 216512, 'counters/updates': 13532}
skipping logging after 216528 examples to avoid logging too frequently
skipping logging after 216544 examples to avoid logging too frequently
skipping logging after 216560 examples to avoid logging too frequently
train stats after 216576 examples: {'rewards_train/chosen': '0.43948', 'rewards_train/rejected': '-4.965', 'rewards_train/margins': '5.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2442', 'examples_per_second': '4.5789', 'grad_norm': '5.125', 'counters/examples': 216576, 'counters/updates': 13536}
skipping logging after 216592 examples to avoid logging too frequently
skipping logging after 216608 examples to avoid logging too frequently
skipping logging after 216624 examples to avoid logging too frequently
train stats after 216640 examples: {'rewards_train/chosen': '0.32502', 'rewards_train/rejected': '-5.8191', 'rewards_train/margins': '6.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23346', 'examples_per_second': '5.4883', 'grad_norm': '4.5312', 'counters/examples': 216640, 'counters/updates': 13540}
skipping logging after 216656 examples to avoid logging too frequently
skipping logging after 216672 examples to avoid logging too frequently
skipping logging after 216688 examples to avoid logging too frequently
train stats after 216704 examples: {'rewards_train/chosen': '0.42977', 'rewards_train/rejected': '-4.2039', 'rewards_train/margins': '4.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23126', 'examples_per_second': '7.313', 'grad_norm': '5.6562', 'counters/examples': 216704, 'counters/updates': 13544}
skipping logging after 216720 examples to avoid logging too frequently
skipping logging after 216736 examples to avoid logging too frequently
skipping logging after 216752 examples to avoid logging too frequently
train stats after 216768 examples: {'rewards_train/chosen': '0.00092285', 'rewards_train/rejected': '-6.4534', 'rewards_train/margins': '6.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2135', 'examples_per_second': '5.5352', 'grad_norm': '4.4375', 'counters/examples': 216768, 'counters/updates': 13548}
skipping logging after 216784 examples to avoid logging too frequently
skipping logging after 216800 examples to avoid logging too frequently
skipping logging after 216816 examples to avoid logging too frequently
train stats after 216832 examples: {'rewards_train/chosen': '0.12939', 'rewards_train/rejected': '-6.3483', 'rewards_train/margins': '6.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24976', 'examples_per_second': '5.3419', 'grad_norm': '4.375', 'counters/examples': 216832, 'counters/updates': 13552}
skipping logging after 216848 examples to avoid logging too frequently
skipping logging after 216864 examples to avoid logging too frequently
skipping logging after 216880 examples to avoid logging too frequently
train stats after 216896 examples: {'rewards_train/chosen': '0.31155', 'rewards_train/rejected': '-6.3007', 'rewards_train/margins': '6.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24017', 'examples_per_second': '4.9865', 'grad_norm': '5.2188', 'counters/examples': 216896, 'counters/updates': 13556}
skipping logging after 216912 examples to avoid logging too frequently
skipping logging after 216928 examples to avoid logging too frequently
skipping logging after 216944 examples to avoid logging too frequently
train stats after 216960 examples: {'rewards_train/chosen': '0.50205', 'rewards_train/rejected': '-7.1692', 'rewards_train/margins': '7.6484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26038', 'examples_per_second': '4.6626', 'grad_norm': '5.4062', 'counters/examples': 216960, 'counters/updates': 13560}
skipping logging after 216976 examples to avoid logging too frequently
skipping logging after 216992 examples to avoid logging too frequently
skipping logging after 217008 examples to avoid logging too frequently
train stats after 217024 examples: {'rewards_train/chosen': '0.48632', 'rewards_train/rejected': '-7.2316', 'rewards_train/margins': '7.7578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21399', 'examples_per_second': '4.9104', 'grad_norm': '4.9375', 'counters/examples': 217024, 'counters/updates': 13564}
skipping logging after 217040 examples to avoid logging too frequently
skipping logging after 217056 examples to avoid logging too frequently
skipping logging after 217072 examples to avoid logging too frequently
train stats after 217088 examples: {'rewards_train/chosen': '0.65978', 'rewards_train/rejected': '-5.9344', 'rewards_train/margins': '6.9297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27496', 'examples_per_second': '4.4148', 'grad_norm': '5.75', 'counters/examples': 217088, 'counters/updates': 13568}
skipping logging after 217104 examples to avoid logging too frequently
skipping logging after 217120 examples to avoid logging too frequently
skipping logging after 217136 examples to avoid logging too frequently
train stats after 217152 examples: {'rewards_train/chosen': '0.46565', 'rewards_train/rejected': '-5.0765', 'rewards_train/margins': '5.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26935', 'examples_per_second': '5.9001', 'grad_norm': '5.5938', 'counters/examples': 217152, 'counters/updates': 13572}
skipping logging after 217168 examples to avoid logging too frequently
skipping logging after 217184 examples to avoid logging too frequently
skipping logging after 217200 examples to avoid logging too frequently
train stats after 217216 examples: {'rewards_train/chosen': '0.41461', 'rewards_train/rejected': '-6.3566', 'rewards_train/margins': '6.7578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20758', 'examples_per_second': '4.4905', 'grad_norm': '5.5312', 'counters/examples': 217216, 'counters/updates': 13576}
skipping logging after 217232 examples to avoid logging too frequently
skipping logging after 217248 examples to avoid logging too frequently
skipping logging after 217264 examples to avoid logging too frequently
train stats after 217280 examples: {'rewards_train/chosen': '0.48249', 'rewards_train/rejected': '-7.6277', 'rewards_train/margins': '8.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19299', 'examples_per_second': '5.7565', 'grad_norm': '4.4062', 'counters/examples': 217280, 'counters/updates': 13580}
skipping logging after 217296 examples to avoid logging too frequently
skipping logging after 217312 examples to avoid logging too frequently
skipping logging after 217328 examples to avoid logging too frequently
train stats after 217344 examples: {'rewards_train/chosen': '0.34702', 'rewards_train/rejected': '-6.7681', 'rewards_train/margins': '7.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24664', 'examples_per_second': '5.4382', 'grad_norm': '4.9375', 'counters/examples': 217344, 'counters/updates': 13584}
skipping logging after 217360 examples to avoid logging too frequently
skipping logging after 217376 examples to avoid logging too frequently
skipping logging after 217392 examples to avoid logging too frequently
train stats after 217408 examples: {'rewards_train/chosen': '0.42722', 'rewards_train/rejected': '-6.2495', 'rewards_train/margins': '6.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23334', 'examples_per_second': '4.4699', 'grad_norm': '4.875', 'counters/examples': 217408, 'counters/updates': 13588}
skipping logging after 217424 examples to avoid logging too frequently
skipping logging after 217440 examples to avoid logging too frequently
skipping logging after 217456 examples to avoid logging too frequently
train stats after 217472 examples: {'rewards_train/chosen': '0.35829', 'rewards_train/rejected': '-5.9881', 'rewards_train/margins': '6.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22162', 'examples_per_second': '5.5749', 'grad_norm': '5.0312', 'counters/examples': 217472, 'counters/updates': 13592}
skipping logging after 217488 examples to avoid logging too frequently
skipping logging after 217504 examples to avoid logging too frequently
skipping logging after 217520 examples to avoid logging too frequently
train stats after 217536 examples: {'rewards_train/chosen': '0.45006', 'rewards_train/rejected': '-6.028', 'rewards_train/margins': '6.7891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20532', 'examples_per_second': '5.0695', 'grad_norm': '4.75', 'counters/examples': 217536, 'counters/updates': 13596}
skipping logging after 217552 examples to avoid logging too frequently
skipping logging after 217568 examples to avoid logging too frequently
skipping logging after 217584 examples to avoid logging too frequently
train stats after 217600 examples: {'rewards_train/chosen': '0.3499', 'rewards_train/rejected': '-6.9818', 'rewards_train/margins': '7.4531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21716', 'examples_per_second': '4.099', 'grad_norm': '5.0312', 'counters/examples': 217600, 'counters/updates': 13600}
skipping logging after 217616 examples to avoid logging too frequently
skipping logging after 217632 examples to avoid logging too frequently
skipping logging after 217648 examples to avoid logging too frequently
train stats after 217664 examples: {'rewards_train/chosen': '0.2436', 'rewards_train/rejected': '-5.5612', 'rewards_train/margins': '6.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29108', 'examples_per_second': '4.8657', 'grad_norm': '5.9688', 'counters/examples': 217664, 'counters/updates': 13604}
skipping logging after 217680 examples to avoid logging too frequently
skipping logging after 217696 examples to avoid logging too frequently
skipping logging after 217712 examples to avoid logging too frequently
train stats after 217728 examples: {'rewards_train/chosen': '0.334', 'rewards_train/rejected': '-6.0306', 'rewards_train/margins': '6.4531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25867', 'examples_per_second': '4.6163', 'grad_norm': '4.4688', 'counters/examples': 217728, 'counters/updates': 13608}
skipping logging after 217744 examples to avoid logging too frequently
skipping logging after 217760 examples to avoid logging too frequently
skipping logging after 217776 examples to avoid logging too frequently
train stats after 217792 examples: {'rewards_train/chosen': '0.41233', 'rewards_train/rejected': '-7.0769', 'rewards_train/margins': '7.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20184', 'examples_per_second': '4.6402', 'grad_norm': '4.625', 'counters/examples': 217792, 'counters/updates': 13612}
skipping logging after 217808 examples to avoid logging too frequently
skipping logging after 217824 examples to avoid logging too frequently
skipping logging after 217840 examples to avoid logging too frequently
train stats after 217856 examples: {'rewards_train/chosen': '0.64613', 'rewards_train/rejected': '-6.3957', 'rewards_train/margins': '6.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23425', 'examples_per_second': '5.9114', 'grad_norm': '5.6562', 'counters/examples': 217856, 'counters/updates': 13616}
skipping logging after 217872 examples to avoid logging too frequently
skipping logging after 217888 examples to avoid logging too frequently
skipping logging after 217904 examples to avoid logging too frequently
train stats after 217920 examples: {'rewards_train/chosen': '0.56861', 'rewards_train/rejected': '-6.2925', 'rewards_train/margins': '6.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21106', 'examples_per_second': '5.6594', 'grad_norm': '4.9375', 'counters/examples': 217920, 'counters/updates': 13620}
skipping logging after 217936 examples to avoid logging too frequently
skipping logging after 217952 examples to avoid logging too frequently
skipping logging after 217968 examples to avoid logging too frequently
train stats after 217984 examples: {'rewards_train/chosen': '0.64842', 'rewards_train/rejected': '-6.9937', 'rewards_train/margins': '7.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21948', 'examples_per_second': '4.6951', 'grad_norm': '4.75', 'counters/examples': 217984, 'counters/updates': 13624}
skipping logging after 218000 examples to avoid logging too frequently
skipping logging after 218016 examples to avoid logging too frequently
skipping logging after 218032 examples to avoid logging too frequently
train stats after 218048 examples: {'rewards_train/chosen': '-0.1478', 'rewards_train/rejected': '-5.5912', 'rewards_train/margins': '5.3203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26422', 'examples_per_second': '5.5775', 'grad_norm': '5.25', 'counters/examples': 218048, 'counters/updates': 13628}
skipping logging after 218064 examples to avoid logging too frequently
skipping logging after 218080 examples to avoid logging too frequently
skipping logging after 218096 examples to avoid logging too frequently
train stats after 218112 examples: {'rewards_train/chosen': '0.43601', 'rewards_train/rejected': '-5.3027', 'rewards_train/margins': '5.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23175', 'examples_per_second': '5.658', 'grad_norm': '5.4062', 'counters/examples': 218112, 'counters/updates': 13632}
skipping logging after 218128 examples to avoid logging too frequently
skipping logging after 218144 examples to avoid logging too frequently
skipping logging after 218160 examples to avoid logging too frequently
train stats after 218176 examples: {'rewards_train/chosen': '0.42291', 'rewards_train/rejected': '-6.6223', 'rewards_train/margins': '7.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24463', 'examples_per_second': '4.9574', 'grad_norm': '5.1562', 'counters/examples': 218176, 'counters/updates': 13636}
skipping logging after 218192 examples to avoid logging too frequently
skipping logging after 218208 examples to avoid logging too frequently
skipping logging after 218224 examples to avoid logging too frequently
train stats after 218240 examples: {'rewards_train/chosen': '0.52562', 'rewards_train/rejected': '-5.6254', 'rewards_train/margins': '6.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2475', 'examples_per_second': '5.0537', 'grad_norm': '5.1562', 'counters/examples': 218240, 'counters/updates': 13640}
skipping logging after 218256 examples to avoid logging too frequently
skipping logging after 218272 examples to avoid logging too frequently
skipping logging after 218288 examples to avoid logging too frequently
train stats after 218304 examples: {'rewards_train/chosen': '-0.098403', 'rewards_train/rejected': '-6.0314', 'rewards_train/margins': '5.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27051', 'examples_per_second': '5.6348', 'grad_norm': '4.6562', 'counters/examples': 218304, 'counters/updates': 13644}
skipping logging after 218320 examples to avoid logging too frequently
skipping logging after 218336 examples to avoid logging too frequently
skipping logging after 218352 examples to avoid logging too frequently
train stats after 218368 examples: {'rewards_train/chosen': '0.35782', 'rewards_train/rejected': '-5.1641', 'rewards_train/margins': '5.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24323', 'examples_per_second': '5.7112', 'grad_norm': '5.3438', 'counters/examples': 218368, 'counters/updates': 13648}
skipping logging after 218384 examples to avoid logging too frequently
skipping logging after 218400 examples to avoid logging too frequently
skipping logging after 218416 examples to avoid logging too frequently
train stats after 218432 examples: {'rewards_train/chosen': '0.53287', 'rewards_train/rejected': '-6.2392', 'rewards_train/margins': '6.6562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21198', 'examples_per_second': '4.3374', 'grad_norm': '5.625', 'counters/examples': 218432, 'counters/updates': 13652}
skipping logging after 218448 examples to avoid logging too frequently
skipping logging after 218464 examples to avoid logging too frequently
skipping logging after 218480 examples to avoid logging too frequently
train stats after 218496 examples: {'rewards_train/chosen': '0.4039', 'rewards_train/rejected': '-5.5414', 'rewards_train/margins': '5.6289', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21143', 'examples_per_second': '5.5096', 'grad_norm': '5.25', 'counters/examples': 218496, 'counters/updates': 13656}
skipping logging after 218512 examples to avoid logging too frequently
skipping logging after 218528 examples to avoid logging too frequently
skipping logging after 218544 examples to avoid logging too frequently
train stats after 218560 examples: {'rewards_train/chosen': '0.53876', 'rewards_train/rejected': '-4.7441', 'rewards_train/margins': '5.4844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21472', 'examples_per_second': '5.1767', 'grad_norm': '5.0938', 'counters/examples': 218560, 'counters/updates': 13660}
skipping logging after 218576 examples to avoid logging too frequently
skipping logging after 218592 examples to avoid logging too frequently
skipping logging after 218608 examples to avoid logging too frequently
train stats after 218624 examples: {'rewards_train/chosen': '0.10112', 'rewards_train/rejected': '-7.403', 'rewards_train/margins': '7.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27887', 'examples_per_second': '4.472', 'grad_norm': '5.0625', 'counters/examples': 218624, 'counters/updates': 13664}
skipping logging after 218640 examples to avoid logging too frequently
skipping logging after 218656 examples to avoid logging too frequently
skipping logging after 218672 examples to avoid logging too frequently
train stats after 218688 examples: {'rewards_train/chosen': '0.80409', 'rewards_train/rejected': '-5.8074', 'rewards_train/margins': '6.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17761', 'examples_per_second': '5.2577', 'grad_norm': '4.5625', 'counters/examples': 218688, 'counters/updates': 13668}
skipping logging after 218704 examples to avoid logging too frequently
skipping logging after 218720 examples to avoid logging too frequently
skipping logging after 218736 examples to avoid logging too frequently
train stats after 218752 examples: {'rewards_train/chosen': '0.14387', 'rewards_train/rejected': '-5.3397', 'rewards_train/margins': '5.5391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25702', 'examples_per_second': '5.4948', 'grad_norm': '5.2188', 'counters/examples': 218752, 'counters/updates': 13672}
skipping logging after 218768 examples to avoid logging too frequently
skipping logging after 218784 examples to avoid logging too frequently
skipping logging after 218800 examples to avoid logging too frequently
train stats after 218816 examples: {'rewards_train/chosen': '0.57093', 'rewards_train/rejected': '-5.22', 'rewards_train/margins': '5.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20776', 'examples_per_second': '5.5782', 'grad_norm': '5.25', 'counters/examples': 218816, 'counters/updates': 13676}
skipping logging after 218832 examples to avoid logging too frequently
skipping logging after 218848 examples to avoid logging too frequently
skipping logging after 218864 examples to avoid logging too frequently
train stats after 218880 examples: {'rewards_train/chosen': '0.14465', 'rewards_train/rejected': '-6.4626', 'rewards_train/margins': '6.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28046', 'examples_per_second': '5.929', 'grad_norm': '5.5625', 'counters/examples': 218880, 'counters/updates': 13680}
skipping logging after 218896 examples to avoid logging too frequently
skipping logging after 218912 examples to avoid logging too frequently
skipping logging after 218928 examples to avoid logging too frequently
train stats after 218944 examples: {'rewards_train/chosen': '0.10703', 'rewards_train/rejected': '-6.1654', 'rewards_train/margins': '6.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23596', 'examples_per_second': '4.8058', 'grad_norm': '4.875', 'counters/examples': 218944, 'counters/updates': 13684}
skipping logging after 218960 examples to avoid logging too frequently
skipping logging after 218976 examples to avoid logging too frequently
skipping logging after 218992 examples to avoid logging too frequently
train stats after 219008 examples: {'rewards_train/chosen': '0.49201', 'rewards_train/rejected': '-5.4345', 'rewards_train/margins': '6', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18237', 'examples_per_second': '5.6002', 'grad_norm': '4.5938', 'counters/examples': 219008, 'counters/updates': 13688}
skipping logging after 219024 examples to avoid logging too frequently
skipping logging after 219040 examples to avoid logging too frequently
skipping logging after 219056 examples to avoid logging too frequently
train stats after 219072 examples: {'rewards_train/chosen': '0.32327', 'rewards_train/rejected': '-4.223', 'rewards_train/margins': '3.9453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25537', 'examples_per_second': '5.5071', 'grad_norm': '5.5', 'counters/examples': 219072, 'counters/updates': 13692}
skipping logging after 219088 examples to avoid logging too frequently
skipping logging after 219104 examples to avoid logging too frequently
skipping logging after 219120 examples to avoid logging too frequently
train stats after 219136 examples: {'rewards_train/chosen': '0.17026', 'rewards_train/rejected': '-7.3958', 'rewards_train/margins': '7.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18549', 'examples_per_second': '5.149', 'grad_norm': '3.8125', 'counters/examples': 219136, 'counters/updates': 13696}
skipping logging after 219152 examples to avoid logging too frequently
skipping logging after 219168 examples to avoid logging too frequently
skipping logging after 219184 examples to avoid logging too frequently
train stats after 219200 examples: {'rewards_train/chosen': '0.53191', 'rewards_train/rejected': '-7.1209', 'rewards_train/margins': '7.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20422', 'examples_per_second': '4.8844', 'grad_norm': '5.1562', 'counters/examples': 219200, 'counters/updates': 13700}
skipping logging after 219216 examples to avoid logging too frequently
skipping logging after 219232 examples to avoid logging too frequently
skipping logging after 219248 examples to avoid logging too frequently
train stats after 219264 examples: {'rewards_train/chosen': '0.20841', 'rewards_train/rejected': '-8.22', 'rewards_train/margins': '7.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23853', 'examples_per_second': '4.939', 'grad_norm': '5.7188', 'counters/examples': 219264, 'counters/updates': 13704}
skipping logging after 219280 examples to avoid logging too frequently
skipping logging after 219296 examples to avoid logging too frequently
skipping logging after 219312 examples to avoid logging too frequently
train stats after 219328 examples: {'rewards_train/chosen': '0.11465', 'rewards_train/rejected': '-5.6761', 'rewards_train/margins': '5.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27661', 'examples_per_second': '5.257', 'grad_norm': '5.625', 'counters/examples': 219328, 'counters/updates': 13708}
skipping logging after 219344 examples to avoid logging too frequently
skipping logging after 219360 examples to avoid logging too frequently
skipping logging after 219376 examples to avoid logging too frequently
train stats after 219392 examples: {'rewards_train/chosen': '0.26344', 'rewards_train/rejected': '-7.309', 'rewards_train/margins': '7.8828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23236', 'examples_per_second': '3.9791', 'grad_norm': '4.375', 'counters/examples': 219392, 'counters/updates': 13712}
skipping logging after 219408 examples to avoid logging too frequently
skipping logging after 219424 examples to avoid logging too frequently
skipping logging after 219440 examples to avoid logging too frequently
train stats after 219456 examples: {'rewards_train/chosen': '0.5865', 'rewards_train/rejected': '-5.7459', 'rewards_train/margins': '6.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19098', 'examples_per_second': '4.8493', 'grad_norm': '5.1562', 'counters/examples': 219456, 'counters/updates': 13716}
skipping logging after 219472 examples to avoid logging too frequently
skipping logging after 219488 examples to avoid logging too frequently
skipping logging after 219504 examples to avoid logging too frequently
train stats after 219520 examples: {'rewards_train/chosen': '0.014286', 'rewards_train/rejected': '-5.5322', 'rewards_train/margins': '5.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26843', 'examples_per_second': '5.1618', 'grad_norm': '5.9375', 'counters/examples': 219520, 'counters/updates': 13720}
skipping logging after 219536 examples to avoid logging too frequently
skipping logging after 219552 examples to avoid logging too frequently
skipping logging after 219568 examples to avoid logging too frequently
train stats after 219584 examples: {'rewards_train/chosen': '0.24001', 'rewards_train/rejected': '-6.0228', 'rewards_train/margins': '6.1719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28424', 'examples_per_second': '4.9602', 'grad_norm': '5.0625', 'counters/examples': 219584, 'counters/updates': 13724}
skipping logging after 219600 examples to avoid logging too frequently
skipping logging after 219616 examples to avoid logging too frequently
skipping logging after 219632 examples to avoid logging too frequently
train stats after 219648 examples: {'rewards_train/chosen': '-0.061322', 'rewards_train/rejected': '-5.0479', 'rewards_train/margins': '5.0156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26678', 'examples_per_second': '4.994', 'grad_norm': '5.5312', 'counters/examples': 219648, 'counters/updates': 13728}
skipping logging after 219664 examples to avoid logging too frequently
skipping logging after 219680 examples to avoid logging too frequently
skipping logging after 219696 examples to avoid logging too frequently
train stats after 219712 examples: {'rewards_train/chosen': '0.39612', 'rewards_train/rejected': '-4.9811', 'rewards_train/margins': '5.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2218', 'examples_per_second': '5.2597', 'grad_norm': '5.4688', 'counters/examples': 219712, 'counters/updates': 13732}
skipping logging after 219728 examples to avoid logging too frequently
skipping logging after 219744 examples to avoid logging too frequently
skipping logging after 219760 examples to avoid logging too frequently
train stats after 219776 examples: {'rewards_train/chosen': '0.41941', 'rewards_train/rejected': '-4.8836', 'rewards_train/margins': '5.3281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24988', 'examples_per_second': '5.7038', 'grad_norm': '4.8438', 'counters/examples': 219776, 'counters/updates': 13736}
skipping logging after 219792 examples to avoid logging too frequently
skipping logging after 219808 examples to avoid logging too frequently
skipping logging after 219824 examples to avoid logging too frequently
train stats after 219840 examples: {'rewards_train/chosen': '0.28431', 'rewards_train/rejected': '-5.969', 'rewards_train/margins': '6.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24927', 'examples_per_second': '4.9735', 'grad_norm': '5.9375', 'counters/examples': 219840, 'counters/updates': 13740}
skipping logging after 219856 examples to avoid logging too frequently
skipping logging after 219872 examples to avoid logging too frequently
skipping logging after 219888 examples to avoid logging too frequently
train stats after 219904 examples: {'rewards_train/chosen': '0.60564', 'rewards_train/rejected': '-5.7192', 'rewards_train/margins': '6.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1955', 'examples_per_second': '5.8187', 'grad_norm': '4.5312', 'counters/examples': 219904, 'counters/updates': 13744}
skipping logging after 219920 examples to avoid logging too frequently
skipping logging after 219936 examples to avoid logging too frequently
skipping logging after 219952 examples to avoid logging too frequently
train stats after 219968 examples: {'rewards_train/chosen': '0.45714', 'rewards_train/rejected': '-6.6494', 'rewards_train/margins': '7.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22314', 'examples_per_second': '5.4326', 'grad_norm': '4.625', 'counters/examples': 219968, 'counters/updates': 13748}
skipping logging after 219984 examples to avoid logging too frequently
skipping logging after 220000 examples to avoid logging too frequently
Running evaluation after 220000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:51,  1.67s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:42,  1.42s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:36,  1.26s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.48s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.69s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.50s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:10<00:34,  1.38s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.53s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.49s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:31,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.39s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:20<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:21<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.28s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:28<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.20s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:40<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:41<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]
eval after 220000: {'rewards_eval/chosen': '-6.1394', 'rewards_eval/rejected': '-6.753', 'rewards_eval/margins': '0.44727', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46008'}
skipping logging after 220016 examples to avoid logging too frequently
train stats after 220032 examples: {'rewards_train/chosen': '0.3343', 'rewards_train/rejected': '-6.6002', 'rewards_train/margins': '6.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23987', 'examples_per_second': '4.5198', 'grad_norm': '5.3125', 'counters/examples': 220032, 'counters/updates': 13752}
skipping logging after 220048 examples to avoid logging too frequently
skipping logging after 220064 examples to avoid logging too frequently
skipping logging after 220080 examples to avoid logging too frequently
train stats after 220096 examples: {'rewards_train/chosen': '0.34161', 'rewards_train/rejected': '-6.8924', 'rewards_train/margins': '7.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20654', 'examples_per_second': '5.2216', 'grad_norm': '4.2812', 'counters/examples': 220096, 'counters/updates': 13756}
skipping logging after 220112 examples to avoid logging too frequently
skipping logging after 220128 examples to avoid logging too frequently
skipping logging after 220144 examples to avoid logging too frequently
train stats after 220160 examples: {'rewards_train/chosen': '0.41132', 'rewards_train/rejected': '-5.8329', 'rewards_train/margins': '6.5781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21667', 'examples_per_second': '5.3184', 'grad_norm': '5.0625', 'counters/examples': 220160, 'counters/updates': 13760}
skipping logging after 220176 examples to avoid logging too frequently
skipping logging after 220192 examples to avoid logging too frequently
skipping logging after 220208 examples to avoid logging too frequently
train stats after 220224 examples: {'rewards_train/chosen': '0.2132', 'rewards_train/rejected': '-5.7444', 'rewards_train/margins': '5.8828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23517', 'examples_per_second': '5.9062', 'grad_norm': '5.5938', 'counters/examples': 220224, 'counters/updates': 13764}
skipping logging after 220240 examples to avoid logging too frequently
skipping logging after 220256 examples to avoid logging too frequently
skipping logging after 220272 examples to avoid logging too frequently
train stats after 220288 examples: {'rewards_train/chosen': '-0.086402', 'rewards_train/rejected': '-6.9549', 'rewards_train/margins': '6.8203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25061', 'examples_per_second': '5.6218', 'grad_norm': '5.1562', 'counters/examples': 220288, 'counters/updates': 13768}
skipping logging after 220304 examples to avoid logging too frequently
skipping logging after 220320 examples to avoid logging too frequently
skipping logging after 220336 examples to avoid logging too frequently
train stats after 220352 examples: {'rewards_train/chosen': '0.17262', 'rewards_train/rejected': '-6.4971', 'rewards_train/margins': '6.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2663', 'examples_per_second': '5.5985', 'grad_norm': '6.1875', 'counters/examples': 220352, 'counters/updates': 13772}
skipping logging after 220368 examples to avoid logging too frequently
skipping logging after 220384 examples to avoid logging too frequently
skipping logging after 220400 examples to avoid logging too frequently
train stats after 220416 examples: {'rewards_train/chosen': '0.13673', 'rewards_train/rejected': '-4.9829', 'rewards_train/margins': '5.0234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28027', 'examples_per_second': '4.8873', 'grad_norm': '5.3438', 'counters/examples': 220416, 'counters/updates': 13776}
skipping logging after 220432 examples to avoid logging too frequently
skipping logging after 220448 examples to avoid logging too frequently
skipping logging after 220464 examples to avoid logging too frequently
train stats after 220480 examples: {'rewards_train/chosen': '0.14495', 'rewards_train/rejected': '-5.8479', 'rewards_train/margins': '6.125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22815', 'examples_per_second': '4.4176', 'grad_norm': '4.9688', 'counters/examples': 220480, 'counters/updates': 13780}
skipping logging after 220496 examples to avoid logging too frequently
skipping logging after 220512 examples to avoid logging too frequently
skipping logging after 220528 examples to avoid logging too frequently
train stats after 220544 examples: {'rewards_train/chosen': '0.41093', 'rewards_train/rejected': '-6.1446', 'rewards_train/margins': '6.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18774', 'examples_per_second': '4.5751', 'grad_norm': '4.125', 'counters/examples': 220544, 'counters/updates': 13784}
skipping logging after 220560 examples to avoid logging too frequently
skipping logging after 220576 examples to avoid logging too frequently
skipping logging after 220592 examples to avoid logging too frequently
train stats after 220608 examples: {'rewards_train/chosen': '0.34536', 'rewards_train/rejected': '-6.8683', 'rewards_train/margins': '7.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23969', 'examples_per_second': '4.6749', 'grad_norm': '4.875', 'counters/examples': 220608, 'counters/updates': 13788}
skipping logging after 220624 examples to avoid logging too frequently
skipping logging after 220640 examples to avoid logging too frequently
skipping logging after 220656 examples to avoid logging too frequently
train stats after 220672 examples: {'rewards_train/chosen': '0.39914', 'rewards_train/rejected': '-6.2689', 'rewards_train/margins': '6.6328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25085', 'examples_per_second': '4.9277', 'grad_norm': '4.9375', 'counters/examples': 220672, 'counters/updates': 13792}
skipping logging after 220688 examples to avoid logging too frequently
skipping logging after 220704 examples to avoid logging too frequently
skipping logging after 220720 examples to avoid logging too frequently
train stats after 220736 examples: {'rewards_train/chosen': '0.35489', 'rewards_train/rejected': '-6.1033', 'rewards_train/margins': '6.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23187', 'examples_per_second': '5.8969', 'grad_norm': '5.3438', 'counters/examples': 220736, 'counters/updates': 13796}
skipping logging after 220752 examples to avoid logging too frequently
skipping logging after 220768 examples to avoid logging too frequently
skipping logging after 220784 examples to avoid logging too frequently
train stats after 220800 examples: {'rewards_train/chosen': '0.40681', 'rewards_train/rejected': '-6.309', 'rewards_train/margins': '6.7031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24915', 'examples_per_second': '5.0811', 'grad_norm': '4.6562', 'counters/examples': 220800, 'counters/updates': 13800}
skipping logging after 220816 examples to avoid logging too frequently
skipping logging after 220832 examples to avoid logging too frequently
skipping logging after 220848 examples to avoid logging too frequently
train stats after 220864 examples: {'rewards_train/chosen': '0.1557', 'rewards_train/rejected': '-4.6245', 'rewards_train/margins': '5.0117', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2749', 'examples_per_second': '5.747', 'grad_norm': '5.1875', 'counters/examples': 220864, 'counters/updates': 13804}
skipping logging after 220880 examples to avoid logging too frequently
skipping logging after 220896 examples to avoid logging too frequently
skipping logging after 220912 examples to avoid logging too frequently
train stats after 220928 examples: {'rewards_train/chosen': '0.077337', 'rewards_train/rejected': '-6.2407', 'rewards_train/margins': '6.5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2392', 'examples_per_second': '5.8028', 'grad_norm': '6.7188', 'counters/examples': 220928, 'counters/updates': 13808}
skipping logging after 220944 examples to avoid logging too frequently
skipping logging after 220960 examples to avoid logging too frequently
skipping logging after 220976 examples to avoid logging too frequently
train stats after 220992 examples: {'rewards_train/chosen': '0.28231', 'rewards_train/rejected': '-5.6368', 'rewards_train/margins': '6.168', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24268', 'examples_per_second': '5.3325', 'grad_norm': '5.1562', 'counters/examples': 220992, 'counters/updates': 13812}
skipping logging after 221008 examples to avoid logging too frequently
skipping logging after 221024 examples to avoid logging too frequently
skipping logging after 221040 examples to avoid logging too frequently
train stats after 221056 examples: {'rewards_train/chosen': '0.61131', 'rewards_train/rejected': '-7.0062', 'rewards_train/margins': '7.3594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22827', 'examples_per_second': '4.4018', 'grad_norm': '4.2812', 'counters/examples': 221056, 'counters/updates': 13816}
skipping logging after 221072 examples to avoid logging too frequently
skipping logging after 221088 examples to avoid logging too frequently
skipping logging after 221104 examples to avoid logging too frequently
train stats after 221120 examples: {'rewards_train/chosen': '0.53202', 'rewards_train/rejected': '-4.7742', 'rewards_train/margins': '5.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26239', 'examples_per_second': '6.1784', 'grad_norm': '4.9375', 'counters/examples': 221120, 'counters/updates': 13820}
skipping logging after 221136 examples to avoid logging too frequently
skipping logging after 221152 examples to avoid logging too frequently
skipping logging after 221168 examples to avoid logging too frequently
train stats after 221184 examples: {'rewards_train/chosen': '0.40382', 'rewards_train/rejected': '-6.8717', 'rewards_train/margins': '7.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26202', 'examples_per_second': '5.3414', 'grad_norm': '5.7188', 'counters/examples': 221184, 'counters/updates': 13824}
skipping logging after 221200 examples to avoid logging too frequently
skipping logging after 221216 examples to avoid logging too frequently
skipping logging after 221232 examples to avoid logging too frequently
train stats after 221248 examples: {'rewards_train/chosen': '0.36254', 'rewards_train/rejected': '-4.9634', 'rewards_train/margins': '5.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24811', 'examples_per_second': '6.332', 'grad_norm': '5.375', 'counters/examples': 221248, 'counters/updates': 13828}
skipping logging after 221264 examples to avoid logging too frequently
skipping logging after 221280 examples to avoid logging too frequently
skipping logging after 221296 examples to avoid logging too frequently
train stats after 221312 examples: {'rewards_train/chosen': '0.28676', 'rewards_train/rejected': '-6.1479', 'rewards_train/margins': '6.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26758', 'examples_per_second': '4.9501', 'grad_norm': '5.125', 'counters/examples': 221312, 'counters/updates': 13832}
skipping logging after 221328 examples to avoid logging too frequently
skipping logging after 221344 examples to avoid logging too frequently
skipping logging after 221360 examples to avoid logging too frequently
train stats after 221376 examples: {'rewards_train/chosen': '0.29772', 'rewards_train/rejected': '-5.6766', 'rewards_train/margins': '5.8555', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26746', 'examples_per_second': '5.0474', 'grad_norm': '5.625', 'counters/examples': 221376, 'counters/updates': 13836}
skipping logging after 221392 examples to avoid logging too frequently
skipping logging after 221408 examples to avoid logging too frequently
skipping logging after 221424 examples to avoid logging too frequently
train stats after 221440 examples: {'rewards_train/chosen': '0.18029', 'rewards_train/rejected': '-6.5237', 'rewards_train/margins': '6.6094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26666', 'examples_per_second': '4.8739', 'grad_norm': '4.5938', 'counters/examples': 221440, 'counters/updates': 13840}
skipping logging after 221456 examples to avoid logging too frequently
skipping logging after 221472 examples to avoid logging too frequently
skipping logging after 221488 examples to avoid logging too frequently
train stats after 221504 examples: {'rewards_train/chosen': '0.19541', 'rewards_train/rejected': '-6.9542', 'rewards_train/margins': '7.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23193', 'examples_per_second': '6.1306', 'grad_norm': '4.625', 'counters/examples': 221504, 'counters/updates': 13844}
skipping logging after 221520 examples to avoid logging too frequently
skipping logging after 221536 examples to avoid logging too frequently
skipping logging after 221552 examples to avoid logging too frequently
train stats after 221568 examples: {'rewards_train/chosen': '0.30738', 'rewards_train/rejected': '-7.29', 'rewards_train/margins': '7.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22272', 'examples_per_second': '4.6787', 'grad_norm': '4.5312', 'counters/examples': 221568, 'counters/updates': 13848}
skipping logging after 221584 examples to avoid logging too frequently
skipping logging after 221600 examples to avoid logging too frequently
skipping logging after 221616 examples to avoid logging too frequently
train stats after 221632 examples: {'rewards_train/chosen': '0.7522', 'rewards_train/rejected': '-4.6631', 'rewards_train/margins': '5.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20575', 'examples_per_second': '4.5674', 'grad_norm': '5.0312', 'counters/examples': 221632, 'counters/updates': 13852}
skipping logging after 221648 examples to avoid logging too frequently
skipping logging after 221664 examples to avoid logging too frequently
skipping logging after 221680 examples to avoid logging too frequently
train stats after 221696 examples: {'rewards_train/chosen': '0.48205', 'rewards_train/rejected': '-8.0573', 'rewards_train/margins': '8.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20221', 'examples_per_second': '4.7087', 'grad_norm': '5.4375', 'counters/examples': 221696, 'counters/updates': 13856}
skipping logging after 221712 examples to avoid logging too frequently
skipping logging after 221728 examples to avoid logging too frequently
skipping logging after 221744 examples to avoid logging too frequently
train stats after 221760 examples: {'rewards_train/chosen': '-0.052385', 'rewards_train/rejected': '-7.8746', 'rewards_train/margins': '7.7266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21558', 'examples_per_second': '4.3423', 'grad_norm': '3.7969', 'counters/examples': 221760, 'counters/updates': 13860}
skipping logging after 221776 examples to avoid logging too frequently
skipping logging after 221792 examples to avoid logging too frequently
skipping logging after 221808 examples to avoid logging too frequently
train stats after 221824 examples: {'rewards_train/chosen': '0.020665', 'rewards_train/rejected': '-7.1269', 'rewards_train/margins': '7.6016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23627', 'examples_per_second': '5.0377', 'grad_norm': '4.4688', 'counters/examples': 221824, 'counters/updates': 13864}
skipping logging after 221840 examples to avoid logging too frequently
skipping logging after 221856 examples to avoid logging too frequently
skipping logging after 221872 examples to avoid logging too frequently
train stats after 221888 examples: {'rewards_train/chosen': '0.42957', 'rewards_train/rejected': '-6.4251', 'rewards_train/margins': '6.8984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21637', 'examples_per_second': '5.3597', 'grad_norm': '4.7812', 'counters/examples': 221888, 'counters/updates': 13868}
skipping logging after 221904 examples to avoid logging too frequently
skipping logging after 221920 examples to avoid logging too frequently
skipping logging after 221936 examples to avoid logging too frequently
train stats after 221952 examples: {'rewards_train/chosen': '0.46168', 'rewards_train/rejected': '-5.4341', 'rewards_train/margins': '5.9141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22571', 'examples_per_second': '5.8522', 'grad_norm': '4.875', 'counters/examples': 221952, 'counters/updates': 13872}
skipping logging after 221968 examples to avoid logging too frequently
skipping logging after 221984 examples to avoid logging too frequently
skipping logging after 222000 examples to avoid logging too frequently
train stats after 222016 examples: {'rewards_train/chosen': '0.10501', 'rewards_train/rejected': '-6.2736', 'rewards_train/margins': '6.4805', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2605', 'examples_per_second': '5.4448', 'grad_norm': '5.0312', 'counters/examples': 222016, 'counters/updates': 13876}
skipping logging after 222032 examples to avoid logging too frequently
skipping logging after 222048 examples to avoid logging too frequently
skipping logging after 222064 examples to avoid logging too frequently
train stats after 222080 examples: {'rewards_train/chosen': '0.12786', 'rewards_train/rejected': '-6.5423', 'rewards_train/margins': '6.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22308', 'examples_per_second': '4.5223', 'grad_norm': '5', 'counters/examples': 222080, 'counters/updates': 13880}
skipping logging after 222096 examples to avoid logging too frequently
skipping logging after 222112 examples to avoid logging too frequently
skipping logging after 222128 examples to avoid logging too frequently
train stats after 222144 examples: {'rewards_train/chosen': '0.30839', 'rewards_train/rejected': '-6.4347', 'rewards_train/margins': '6.7266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22168', 'examples_per_second': '4.7857', 'grad_norm': '5.0312', 'counters/examples': 222144, 'counters/updates': 13884}
skipping logging after 222160 examples to avoid logging too frequently
skipping logging after 222176 examples to avoid logging too frequently
skipping logging after 222192 examples to avoid logging too frequently
train stats after 222208 examples: {'rewards_train/chosen': '0.28884', 'rewards_train/rejected': '-6.0269', 'rewards_train/margins': '6.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26373', 'examples_per_second': '5.9199', 'grad_norm': '4.8438', 'counters/examples': 222208, 'counters/updates': 13888}
skipping logging after 222224 examples to avoid logging too frequently
skipping logging after 222240 examples to avoid logging too frequently
skipping logging after 222256 examples to avoid logging too frequently
train stats after 222272 examples: {'rewards_train/chosen': '0.025327', 'rewards_train/rejected': '-5.411', 'rewards_train/margins': '5.4102', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22003', 'examples_per_second': '5.9092', 'grad_norm': '4.9375', 'counters/examples': 222272, 'counters/updates': 13892}
skipping logging after 222288 examples to avoid logging too frequently
skipping logging after 222304 examples to avoid logging too frequently
skipping logging after 222320 examples to avoid logging too frequently
train stats after 222336 examples: {'rewards_train/chosen': '0.42198', 'rewards_train/rejected': '-5.499', 'rewards_train/margins': '5.9297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21863', 'examples_per_second': '4.5192', 'grad_norm': '6.1875', 'counters/examples': 222336, 'counters/updates': 13896}
skipping logging after 222352 examples to avoid logging too frequently
skipping logging after 222368 examples to avoid logging too frequently
skipping logging after 222384 examples to avoid logging too frequently
train stats after 222400 examples: {'rewards_train/chosen': '-0.20034', 'rewards_train/rejected': '-7.1866', 'rewards_train/margins': '7', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25269', 'examples_per_second': '4.4576', 'grad_norm': '5.2188', 'counters/examples': 222400, 'counters/updates': 13900}
skipping logging after 222416 examples to avoid logging too frequently
skipping logging after 222432 examples to avoid logging too frequently
skipping logging after 222448 examples to avoid logging too frequently
train stats after 222464 examples: {'rewards_train/chosen': '0.34193', 'rewards_train/rejected': '-6.0317', 'rewards_train/margins': '6.5391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25043', 'examples_per_second': '4.8622', 'grad_norm': '6.2188', 'counters/examples': 222464, 'counters/updates': 13904}
skipping logging after 222480 examples to avoid logging too frequently
skipping logging after 222496 examples to avoid logging too frequently
skipping logging after 222512 examples to avoid logging too frequently
train stats after 222528 examples: {'rewards_train/chosen': '0.53662', 'rewards_train/rejected': '-7.0888', 'rewards_train/margins': '7.5938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24377', 'examples_per_second': '4.0087', 'grad_norm': '5.1562', 'counters/examples': 222528, 'counters/updates': 13908}
skipping logging after 222544 examples to avoid logging too frequently
skipping logging after 222560 examples to avoid logging too frequently
skipping logging after 222576 examples to avoid logging too frequently
train stats after 222592 examples: {'rewards_train/chosen': '0.39915', 'rewards_train/rejected': '-7.2715', 'rewards_train/margins': '7.2422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21942', 'examples_per_second': '3.9696', 'grad_norm': '3.9688', 'counters/examples': 222592, 'counters/updates': 13912}
skipping logging after 222608 examples to avoid logging too frequently
skipping logging after 222624 examples to avoid logging too frequently
skipping logging after 222640 examples to avoid logging too frequently
train stats after 222656 examples: {'rewards_train/chosen': '0.40121', 'rewards_train/rejected': '-6.9986', 'rewards_train/margins': '7.375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21521', 'examples_per_second': '5.0022', 'grad_norm': '4.5625', 'counters/examples': 222656, 'counters/updates': 13916}
skipping logging after 222672 examples to avoid logging too frequently
skipping logging after 222688 examples to avoid logging too frequently
skipping logging after 222704 examples to avoid logging too frequently
train stats after 222720 examples: {'rewards_train/chosen': '0.015932', 'rewards_train/rejected': '-6.0414', 'rewards_train/margins': '5.8945', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27679', 'examples_per_second': '4.8717', 'grad_norm': '5.0625', 'counters/examples': 222720, 'counters/updates': 13920}
skipping logging after 222736 examples to avoid logging too frequently
skipping logging after 222752 examples to avoid logging too frequently
skipping logging after 222768 examples to avoid logging too frequently
train stats after 222784 examples: {'rewards_train/chosen': '0.23887', 'rewards_train/rejected': '-5.9982', 'rewards_train/margins': '6.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26965', 'examples_per_second': '4.826', 'grad_norm': '5.0938', 'counters/examples': 222784, 'counters/updates': 13924}
skipping logging after 222800 examples to avoid logging too frequently
skipping logging after 222816 examples to avoid logging too frequently
skipping logging after 222832 examples to avoid logging too frequently
train stats after 222848 examples: {'rewards_train/chosen': '0.28673', 'rewards_train/rejected': '-5.7126', 'rewards_train/margins': '5.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2453', 'examples_per_second': '4.8139', 'grad_norm': '4.8125', 'counters/examples': 222848, 'counters/updates': 13928}
skipping logging after 222864 examples to avoid logging too frequently
skipping logging after 222880 examples to avoid logging too frequently
skipping logging after 222896 examples to avoid logging too frequently
train stats after 222912 examples: {'rewards_train/chosen': '0.19659', 'rewards_train/rejected': '-6.0319', 'rewards_train/margins': '6.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29407', 'examples_per_second': '4.9455', 'grad_norm': '5.6562', 'counters/examples': 222912, 'counters/updates': 13932}
skipping logging after 222928 examples to avoid logging too frequently
skipping logging after 222944 examples to avoid logging too frequently
skipping logging after 222960 examples to avoid logging too frequently
train stats after 222976 examples: {'rewards_train/chosen': '0.25541', 'rewards_train/rejected': '-4.9986', 'rewards_train/margins': '5.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29895', 'examples_per_second': '5.5607', 'grad_norm': '5.6562', 'counters/examples': 222976, 'counters/updates': 13936}
skipping logging after 222992 examples to avoid logging too frequently
skipping logging after 223008 examples to avoid logging too frequently
skipping logging after 223024 examples to avoid logging too frequently
train stats after 223040 examples: {'rewards_train/chosen': '0.32596', 'rewards_train/rejected': '-5.8577', 'rewards_train/margins': '6.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23486', 'examples_per_second': '5.8177', 'grad_norm': '4.5', 'counters/examples': 223040, 'counters/updates': 13940}
skipping logging after 223056 examples to avoid logging too frequently
skipping logging after 223072 examples to avoid logging too frequently
skipping logging after 223088 examples to avoid logging too frequently
train stats after 223104 examples: {'rewards_train/chosen': '0.37204', 'rewards_train/rejected': '-5.4933', 'rewards_train/margins': '5.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25922', 'examples_per_second': '4.5844', 'grad_norm': '4.7188', 'counters/examples': 223104, 'counters/updates': 13944}
skipping logging after 223120 examples to avoid logging too frequently
skipping logging after 223136 examples to avoid logging too frequently
skipping logging after 223152 examples to avoid logging too frequently
train stats after 223168 examples: {'rewards_train/chosen': '0.69347', 'rewards_train/rejected': '-5.8489', 'rewards_train/margins': '6.4141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23444', 'examples_per_second': '5.4718', 'grad_norm': '4.8125', 'counters/examples': 223168, 'counters/updates': 13948}
skipping logging after 223184 examples to avoid logging too frequently
skipping logging after 223200 examples to avoid logging too frequently
skipping logging after 223216 examples to avoid logging too frequently
train stats after 223232 examples: {'rewards_train/chosen': '0.20048', 'rewards_train/rejected': '-6.4848', 'rewards_train/margins': '6.7422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23224', 'examples_per_second': '4.3203', 'grad_norm': '4.8438', 'counters/examples': 223232, 'counters/updates': 13952}
skipping logging after 223248 examples to avoid logging too frequently
skipping logging after 223264 examples to avoid logging too frequently
skipping logging after 223280 examples to avoid logging too frequently
train stats after 223296 examples: {'rewards_train/chosen': '0.23472', 'rewards_train/rejected': '-7.0154', 'rewards_train/margins': '7.1719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24512', 'examples_per_second': '5.2468', 'grad_norm': '5.0938', 'counters/examples': 223296, 'counters/updates': 13956}
skipping logging after 223312 examples to avoid logging too frequently
skipping logging after 223328 examples to avoid logging too frequently
skipping logging after 223344 examples to avoid logging too frequently
train stats after 223360 examples: {'rewards_train/chosen': '0.52527', 'rewards_train/rejected': '-4.8104', 'rewards_train/margins': '5.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21063', 'examples_per_second': '5.5812', 'grad_norm': '5.0625', 'counters/examples': 223360, 'counters/updates': 13960}
skipping logging after 223376 examples to avoid logging too frequently
skipping logging after 223392 examples to avoid logging too frequently
skipping logging after 223408 examples to avoid logging too frequently
train stats after 223424 examples: {'rewards_train/chosen': '0.50283', 'rewards_train/rejected': '-6.8635', 'rewards_train/margins': '7.2422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18646', 'examples_per_second': '4.8487', 'grad_norm': '4.8438', 'counters/examples': 223424, 'counters/updates': 13964}
skipping logging after 223440 examples to avoid logging too frequently
skipping logging after 223456 examples to avoid logging too frequently
skipping logging after 223472 examples to avoid logging too frequently
train stats after 223488 examples: {'rewards_train/chosen': '0.34722', 'rewards_train/rejected': '-6.6852', 'rewards_train/margins': '7.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21155', 'examples_per_second': '5.192', 'grad_norm': '4.9375', 'counters/examples': 223488, 'counters/updates': 13968}
skipping logging after 223504 examples to avoid logging too frequently
skipping logging after 223520 examples to avoid logging too frequently
skipping logging after 223536 examples to avoid logging too frequently
train stats after 223552 examples: {'rewards_train/chosen': '0.043255', 'rewards_train/rejected': '-7.2252', 'rewards_train/margins': '7.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22504', 'examples_per_second': '5.9507', 'grad_norm': '4.75', 'counters/examples': 223552, 'counters/updates': 13972}
skipping logging after 223568 examples to avoid logging too frequently
skipping logging after 223584 examples to avoid logging too frequently
skipping logging after 223600 examples to avoid logging too frequently
train stats after 223616 examples: {'rewards_train/chosen': '-0.12669', 'rewards_train/rejected': '-7.1959', 'rewards_train/margins': '6.7422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28271', 'examples_per_second': '5.1138', 'grad_norm': '5', 'counters/examples': 223616, 'counters/updates': 13976}
skipping logging after 223632 examples to avoid logging too frequently
skipping logging after 223648 examples to avoid logging too frequently
skipping logging after 223664 examples to avoid logging too frequently
train stats after 223680 examples: {'rewards_train/chosen': '0.28793', 'rewards_train/rejected': '-6.339', 'rewards_train/margins': '6.6602', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29791', 'examples_per_second': '4.7625', 'grad_norm': '4.75', 'counters/examples': 223680, 'counters/updates': 13980}
skipping logging after 223696 examples to avoid logging too frequently
skipping logging after 223712 examples to avoid logging too frequently
skipping logging after 223728 examples to avoid logging too frequently
train stats after 223744 examples: {'rewards_train/chosen': '0.41107', 'rewards_train/rejected': '-5.423', 'rewards_train/margins': '5.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24579', 'examples_per_second': '5.8912', 'grad_norm': '5.375', 'counters/examples': 223744, 'counters/updates': 13984}
skipping logging after 223760 examples to avoid logging too frequently
skipping logging after 223776 examples to avoid logging too frequently
skipping logging after 223792 examples to avoid logging too frequently
train stats after 223808 examples: {'rewards_train/chosen': '0.42584', 'rewards_train/rejected': '-6.2067', 'rewards_train/margins': '6.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20142', 'examples_per_second': '4.78', 'grad_norm': '4.4062', 'counters/examples': 223808, 'counters/updates': 13988}
skipping logging after 223824 examples to avoid logging too frequently
skipping logging after 223840 examples to avoid logging too frequently
skipping logging after 223856 examples to avoid logging too frequently
train stats after 223872 examples: {'rewards_train/chosen': '0.59822', 'rewards_train/rejected': '-5.2019', 'rewards_train/margins': '5.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18701', 'examples_per_second': '5.4912', 'grad_norm': '4.9375', 'counters/examples': 223872, 'counters/updates': 13992}
skipping logging after 223888 examples to avoid logging too frequently
skipping logging after 223904 examples to avoid logging too frequently
skipping logging after 223920 examples to avoid logging too frequently
train stats after 223936 examples: {'rewards_train/chosen': '0.44569', 'rewards_train/rejected': '-7.9635', 'rewards_train/margins': '8.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20776', 'examples_per_second': '5.0949', 'grad_norm': '4.75', 'counters/examples': 223936, 'counters/updates': 13996}
skipping logging after 223952 examples to avoid logging too frequently
skipping logging after 223968 examples to avoid logging too frequently
skipping logging after 223984 examples to avoid logging too frequently
train stats after 224000 examples: {'rewards_train/chosen': '0.44263', 'rewards_train/rejected': '-5.3102', 'rewards_train/margins': '5.8203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25513', 'examples_per_second': '6.1143', 'grad_norm': '4.875', 'counters/examples': 224000, 'counters/updates': 14000}
Running evaluation after 224000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.24s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.25s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.16s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:39,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.65s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.47s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:34,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.51s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.40s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:30,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:21<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]
eval after 224000: {'rewards_eval/chosen': '-5.9787', 'rewards_eval/rejected': '-6.583', 'rewards_eval/margins': '0.42529', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.45801'}
skipping logging after 224016 examples to avoid logging too frequently
skipping logging after 224032 examples to avoid logging too frequently
skipping logging after 224048 examples to avoid logging too frequently
train stats after 224064 examples: {'rewards_train/chosen': '0.60472', 'rewards_train/rejected': '-5.3625', 'rewards_train/margins': '6', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30627', 'examples_per_second': '5.0013', 'grad_norm': '6.9375', 'counters/examples': 224064, 'counters/updates': 14004}
skipping logging after 224080 examples to avoid logging too frequently
skipping logging after 224096 examples to avoid logging too frequently
skipping logging after 224112 examples to avoid logging too frequently
train stats after 224128 examples: {'rewards_train/chosen': '0.69059', 'rewards_train/rejected': '-6.7496', 'rewards_train/margins': '7.5469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.16882', 'examples_per_second': '5.6102', 'grad_norm': '3.7188', 'counters/examples': 224128, 'counters/updates': 14008}
skipping logging after 224144 examples to avoid logging too frequently
skipping logging after 224160 examples to avoid logging too frequently
skipping logging after 224176 examples to avoid logging too frequently
train stats after 224192 examples: {'rewards_train/chosen': '0.48918', 'rewards_train/rejected': '-6.3137', 'rewards_train/margins': '6.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26086', 'examples_per_second': '6.7422', 'grad_norm': '5.5625', 'counters/examples': 224192, 'counters/updates': 14012}
skipping logging after 224208 examples to avoid logging too frequently
skipping logging after 224224 examples to avoid logging too frequently
skipping logging after 224240 examples to avoid logging too frequently
train stats after 224256 examples: {'rewards_train/chosen': '0.19001', 'rewards_train/rejected': '-6.2619', 'rewards_train/margins': '6.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24329', 'examples_per_second': '4.9242', 'grad_norm': '4.5625', 'counters/examples': 224256, 'counters/updates': 14016}
skipping logging after 224272 examples to avoid logging too frequently
skipping logging after 224288 examples to avoid logging too frequently
skipping logging after 224304 examples to avoid logging too frequently
train stats after 224320 examples: {'rewards_train/chosen': '0.45996', 'rewards_train/rejected': '-5.844', 'rewards_train/margins': '6.3828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23895', 'examples_per_second': '5.5927', 'grad_norm': '4.8125', 'counters/examples': 224320, 'counters/updates': 14020}
skipping logging after 224336 examples to avoid logging too frequently
skipping logging after 224352 examples to avoid logging too frequently
skipping logging after 224368 examples to avoid logging too frequently
train stats after 224384 examples: {'rewards_train/chosen': '0.45718', 'rewards_train/rejected': '-6.4156', 'rewards_train/margins': '6.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19934', 'examples_per_second': '4.93', 'grad_norm': '4.7188', 'counters/examples': 224384, 'counters/updates': 14024}
skipping logging after 224400 examples to avoid logging too frequently
skipping logging after 224416 examples to avoid logging too frequently
skipping logging after 224432 examples to avoid logging too frequently
train stats after 224448 examples: {'rewards_train/chosen': '0.083549', 'rewards_train/rejected': '-8.1597', 'rewards_train/margins': '8.1953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18604', 'examples_per_second': '5.4702', 'grad_norm': '3.9062', 'counters/examples': 224448, 'counters/updates': 14028}
skipping logging after 224464 examples to avoid logging too frequently
skipping logging after 224480 examples to avoid logging too frequently
skipping logging after 224496 examples to avoid logging too frequently
train stats after 224512 examples: {'rewards_train/chosen': '0.65815', 'rewards_train/rejected': '-5.9053', 'rewards_train/margins': '6.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22699', 'examples_per_second': '4.5625', 'grad_norm': '5.1875', 'counters/examples': 224512, 'counters/updates': 14032}
skipping logging after 224528 examples to avoid logging too frequently
skipping logging after 224544 examples to avoid logging too frequently
skipping logging after 224560 examples to avoid logging too frequently
train stats after 224576 examples: {'rewards_train/chosen': '0.34748', 'rewards_train/rejected': '-6.9173', 'rewards_train/margins': '7.1875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25458', 'examples_per_second': '5.4731', 'grad_norm': '5.9375', 'counters/examples': 224576, 'counters/updates': 14036}
skipping logging after 224592 examples to avoid logging too frequently
skipping logging after 224608 examples to avoid logging too frequently
skipping logging after 224624 examples to avoid logging too frequently
train stats after 224640 examples: {'rewards_train/chosen': '0.33068', 'rewards_train/rejected': '-6.4753', 'rewards_train/margins': '6.7812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24261', 'examples_per_second': '4.4937', 'grad_norm': '5.625', 'counters/examples': 224640, 'counters/updates': 14040}
skipping logging after 224656 examples to avoid logging too frequently
skipping logging after 224672 examples to avoid logging too frequently
skipping logging after 224688 examples to avoid logging too frequently
train stats after 224704 examples: {'rewards_train/chosen': '0.45934', 'rewards_train/rejected': '-5.4796', 'rewards_train/margins': '5.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24457', 'examples_per_second': '5.0071', 'grad_norm': '5.0938', 'counters/examples': 224704, 'counters/updates': 14044}
skipping logging after 224720 examples to avoid logging too frequently
skipping logging after 224736 examples to avoid logging too frequently
skipping logging after 224752 examples to avoid logging too frequently
train stats after 224768 examples: {'rewards_train/chosen': '0.28913', 'rewards_train/rejected': '-4.5391', 'rewards_train/margins': '4.9141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2417', 'examples_per_second': '5.7707', 'grad_norm': '6.25', 'counters/examples': 224768, 'counters/updates': 14048}
skipping logging after 224784 examples to avoid logging too frequently
skipping logging after 224800 examples to avoid logging too frequently
skipping logging after 224816 examples to avoid logging too frequently
train stats after 224832 examples: {'rewards_train/chosen': '0.18547', 'rewards_train/rejected': '-6.745', 'rewards_train/margins': '6.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20422', 'examples_per_second': '5.0708', 'grad_norm': '6', 'counters/examples': 224832, 'counters/updates': 14052}
skipping logging after 224848 examples to avoid logging too frequently
skipping logging after 224864 examples to avoid logging too frequently
skipping logging after 224880 examples to avoid logging too frequently
train stats after 224896 examples: {'rewards_train/chosen': '0.49353', 'rewards_train/rejected': '-6.8921', 'rewards_train/margins': '7.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21027', 'examples_per_second': '5.8669', 'grad_norm': '4.8125', 'counters/examples': 224896, 'counters/updates': 14056}
skipping logging after 224912 examples to avoid logging too frequently
skipping logging after 224928 examples to avoid logging too frequently
skipping logging after 224944 examples to avoid logging too frequently
train stats after 224960 examples: {'rewards_train/chosen': '0.28021', 'rewards_train/rejected': '-5.3878', 'rewards_train/margins': '5.668', 'rewards_train/KL_estimate': '0', 'loss/train': '0.297', 'examples_per_second': '6.1674', 'grad_norm': '5.1562', 'counters/examples': 224960, 'counters/updates': 14060}
skipping logging after 224976 examples to avoid logging too frequently
skipping logging after 224992 examples to avoid logging too frequently
skipping logging after 225008 examples to avoid logging too frequently
train stats after 225024 examples: {'rewards_train/chosen': '0.30904', 'rewards_train/rejected': '-6.0833', 'rewards_train/margins': '6.4609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26318', 'examples_per_second': '4.4247', 'grad_norm': '5.9062', 'counters/examples': 225024, 'counters/updates': 14064}
skipping logging after 225040 examples to avoid logging too frequently
skipping logging after 225056 examples to avoid logging too frequently
skipping logging after 225072 examples to avoid logging too frequently
train stats after 225088 examples: {'rewards_train/chosen': '0.55905', 'rewards_train/rejected': '-7.0579', 'rewards_train/margins': '7.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18683', 'examples_per_second': '4.286', 'grad_norm': '6.0312', 'counters/examples': 225088, 'counters/updates': 14068}
skipping logging after 225104 examples to avoid logging too frequently
skipping logging after 225120 examples to avoid logging too frequently
skipping logging after 225136 examples to avoid logging too frequently
train stats after 225152 examples: {'rewards_train/chosen': '0.40442', 'rewards_train/rejected': '-5.6598', 'rewards_train/margins': '5.9961', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2442', 'examples_per_second': '6.545', 'grad_norm': '4.5', 'counters/examples': 225152, 'counters/updates': 14072}
skipping logging after 225168 examples to avoid logging too frequently
skipping logging after 225184 examples to avoid logging too frequently
skipping logging after 225200 examples to avoid logging too frequently
train stats after 225216 examples: {'rewards_train/chosen': '0.36092', 'rewards_train/rejected': '-6.945', 'rewards_train/margins': '7.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20612', 'examples_per_second': '4.8864', 'grad_norm': '5.5', 'counters/examples': 225216, 'counters/updates': 14076}
skipping logging after 225232 examples to avoid logging too frequently
skipping logging after 225248 examples to avoid logging too frequently
skipping logging after 225264 examples to avoid logging too frequently
train stats after 225280 examples: {'rewards_train/chosen': '-0.052653', 'rewards_train/rejected': '-6.3256', 'rewards_train/margins': '6.6836', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26111', 'examples_per_second': '5.6568', 'grad_norm': '5.7812', 'counters/examples': 225280, 'counters/updates': 14080}
skipping logging after 225296 examples to avoid logging too frequently
skipping logging after 225312 examples to avoid logging too frequently
skipping logging after 225328 examples to avoid logging too frequently
train stats after 225344 examples: {'rewards_train/chosen': '0.16115', 'rewards_train/rejected': '-7.0072', 'rewards_train/margins': '7.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.224', 'examples_per_second': '5.5795', 'grad_norm': '4.7812', 'counters/examples': 225344, 'counters/updates': 14084}
skipping logging after 225360 examples to avoid logging too frequently
skipping logging after 225376 examples to avoid logging too frequently
skipping logging after 225392 examples to avoid logging too frequently
train stats after 225408 examples: {'rewards_train/chosen': '0.4572', 'rewards_train/rejected': '-7.6638', 'rewards_train/margins': '7.9453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23145', 'examples_per_second': '4.3647', 'grad_norm': '4.9375', 'counters/examples': 225408, 'counters/updates': 14088}
skipping logging after 225424 examples to avoid logging too frequently
skipping logging after 225440 examples to avoid logging too frequently
skipping logging after 225456 examples to avoid logging too frequently
train stats after 225472 examples: {'rewards_train/chosen': '0.45546', 'rewards_train/rejected': '-6.4864', 'rewards_train/margins': '6.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21991', 'examples_per_second': '4.6639', 'grad_norm': '5.0938', 'counters/examples': 225472, 'counters/updates': 14092}
skipping logging after 225488 examples to avoid logging too frequently
skipping logging after 225504 examples to avoid logging too frequently
skipping logging after 225520 examples to avoid logging too frequently
train stats after 225536 examples: {'rewards_train/chosen': '0.39647', 'rewards_train/rejected': '-6.0459', 'rewards_train/margins': '6.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19989', 'examples_per_second': '4.8785', 'grad_norm': '4.9062', 'counters/examples': 225536, 'counters/updates': 14096}
skipping logging after 225552 examples to avoid logging too frequently
skipping logging after 225568 examples to avoid logging too frequently
skipping logging after 225584 examples to avoid logging too frequently
train stats after 225600 examples: {'rewards_train/chosen': '0.39468', 'rewards_train/rejected': '-7.0019', 'rewards_train/margins': '7.375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23242', 'examples_per_second': '5.1458', 'grad_norm': '5.3125', 'counters/examples': 225600, 'counters/updates': 14100}
skipping logging after 225616 examples to avoid logging too frequently
skipping logging after 225632 examples to avoid logging too frequently
skipping logging after 225648 examples to avoid logging too frequently
train stats after 225664 examples: {'rewards_train/chosen': '0.24368', 'rewards_train/rejected': '-4.9821', 'rewards_train/margins': '5.1758', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27582', 'examples_per_second': '4.0976', 'grad_norm': '5.8438', 'counters/examples': 225664, 'counters/updates': 14104}
skipping logging after 225680 examples to avoid logging too frequently
skipping logging after 225696 examples to avoid logging too frequently
skipping logging after 225712 examples to avoid logging too frequently
train stats after 225728 examples: {'rewards_train/chosen': '-0.033576', 'rewards_train/rejected': '-5.9723', 'rewards_train/margins': '5.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30731', 'examples_per_second': '5.2785', 'grad_norm': '4.8125', 'counters/examples': 225728, 'counters/updates': 14108}
skipping logging after 225744 examples to avoid logging too frequently
skipping logging after 225760 examples to avoid logging too frequently
skipping logging after 225776 examples to avoid logging too frequently
train stats after 225792 examples: {'rewards_train/chosen': '0.34309', 'rewards_train/rejected': '-5.7953', 'rewards_train/margins': '6.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26849', 'examples_per_second': '4.5092', 'grad_norm': '5', 'counters/examples': 225792, 'counters/updates': 14112}
skipping logging after 225808 examples to avoid logging too frequently
skipping logging after 225824 examples to avoid logging too frequently
skipping logging after 225840 examples to avoid logging too frequently
train stats after 225856 examples: {'rewards_train/chosen': '0.29363', 'rewards_train/rejected': '-7.0268', 'rewards_train/margins': '7.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23309', 'examples_per_second': '5.0376', 'grad_norm': '5.4688', 'counters/examples': 225856, 'counters/updates': 14116}
skipping logging after 225872 examples to avoid logging too frequently
skipping logging after 225888 examples to avoid logging too frequently
skipping logging after 225904 examples to avoid logging too frequently
train stats after 225920 examples: {'rewards_train/chosen': '0.26567', 'rewards_train/rejected': '-6.3316', 'rewards_train/margins': '7.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26477', 'examples_per_second': '5.164', 'grad_norm': '4.7812', 'counters/examples': 225920, 'counters/updates': 14120}
skipping logging after 225936 examples to avoid logging too frequently
skipping logging after 225952 examples to avoid logging too frequently
skipping logging after 225968 examples to avoid logging too frequently
train stats after 225984 examples: {'rewards_train/chosen': '0.87507', 'rewards_train/rejected': '-6.2966', 'rewards_train/margins': '7.1016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20264', 'examples_per_second': '5.3033', 'grad_norm': '4.4375', 'counters/examples': 225984, 'counters/updates': 14124}
skipping logging after 226000 examples to avoid logging too frequently
skipping logging after 226016 examples to avoid logging too frequently
skipping logging after 226032 examples to avoid logging too frequently
train stats after 226048 examples: {'rewards_train/chosen': '0.31042', 'rewards_train/rejected': '-6.4299', 'rewards_train/margins': '6.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21851', 'examples_per_second': '4.5672', 'grad_norm': '4.7812', 'counters/examples': 226048, 'counters/updates': 14128}
skipping logging after 226064 examples to avoid logging too frequently
skipping logging after 226080 examples to avoid logging too frequently
skipping logging after 226096 examples to avoid logging too frequently
train stats after 226112 examples: {'rewards_train/chosen': '0.37214', 'rewards_train/rejected': '-6.1672', 'rewards_train/margins': '6.4531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21375', 'examples_per_second': '5.5116', 'grad_norm': '4.5625', 'counters/examples': 226112, 'counters/updates': 14132}
skipping logging after 226128 examples to avoid logging too frequently
skipping logging after 226144 examples to avoid logging too frequently
skipping logging after 226160 examples to avoid logging too frequently
train stats after 226176 examples: {'rewards_train/chosen': '0.22554', 'rewards_train/rejected': '-6.8704', 'rewards_train/margins': '7.2422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25952', 'examples_per_second': '4.7736', 'grad_norm': '5.4375', 'counters/examples': 226176, 'counters/updates': 14136}
skipping logging after 226192 examples to avoid logging too frequently
skipping logging after 226208 examples to avoid logging too frequently
skipping logging after 226224 examples to avoid logging too frequently
train stats after 226240 examples: {'rewards_train/chosen': '0.335', 'rewards_train/rejected': '-6.5042', 'rewards_train/margins': '6.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.31488', 'examples_per_second': '4.9811', 'grad_norm': '6.1875', 'counters/examples': 226240, 'counters/updates': 14140}
skipping logging after 226256 examples to avoid logging too frequently
skipping logging after 226272 examples to avoid logging too frequently
skipping logging after 226288 examples to avoid logging too frequently
train stats after 226304 examples: {'rewards_train/chosen': '0.55612', 'rewards_train/rejected': '-5.2645', 'rewards_train/margins': '5.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24719', 'examples_per_second': '5.3947', 'grad_norm': '4.9375', 'counters/examples': 226304, 'counters/updates': 14144}
skipping logging after 226320 examples to avoid logging too frequently
skipping logging after 226336 examples to avoid logging too frequently
skipping logging after 226352 examples to avoid logging too frequently
train stats after 226368 examples: {'rewards_train/chosen': '0.6042', 'rewards_train/rejected': '-7.8943', 'rewards_train/margins': '7.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21338', 'examples_per_second': '4.2356', 'grad_norm': '5.1875', 'counters/examples': 226368, 'counters/updates': 14148}
skipping logging after 226384 examples to avoid logging too frequently
skipping logging after 226400 examples to avoid logging too frequently
skipping logging after 226416 examples to avoid logging too frequently
train stats after 226432 examples: {'rewards_train/chosen': '0.44211', 'rewards_train/rejected': '-5.3788', 'rewards_train/margins': '5.5664', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24854', 'examples_per_second': '5.9414', 'grad_norm': '4.5938', 'counters/examples': 226432, 'counters/updates': 14152}
skipping logging after 226448 examples to avoid logging too frequently
skipping logging after 226464 examples to avoid logging too frequently
skipping logging after 226480 examples to avoid logging too frequently
train stats after 226496 examples: {'rewards_train/chosen': '0.39309', 'rewards_train/rejected': '-6.415', 'rewards_train/margins': '7.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28094', 'examples_per_second': '5.3397', 'grad_norm': '5.2812', 'counters/examples': 226496, 'counters/updates': 14156}
skipping logging after 226512 examples to avoid logging too frequently
skipping logging after 226528 examples to avoid logging too frequently
skipping logging after 226544 examples to avoid logging too frequently
train stats after 226560 examples: {'rewards_train/chosen': '0.45567', 'rewards_train/rejected': '-6.0768', 'rewards_train/margins': '6.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26099', 'examples_per_second': '5.4814', 'grad_norm': '5.5625', 'counters/examples': 226560, 'counters/updates': 14160}
skipping logging after 226576 examples to avoid logging too frequently
skipping logging after 226592 examples to avoid logging too frequently
skipping logging after 226608 examples to avoid logging too frequently
train stats after 226624 examples: {'rewards_train/chosen': '0.48824', 'rewards_train/rejected': '-6.1787', 'rewards_train/margins': '6.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19275', 'examples_per_second': '5.5425', 'grad_norm': '4.5625', 'counters/examples': 226624, 'counters/updates': 14164}
skipping logging after 226640 examples to avoid logging too frequently
skipping logging after 226656 examples to avoid logging too frequently
skipping logging after 226672 examples to avoid logging too frequently
train stats after 226688 examples: {'rewards_train/chosen': '0.36967', 'rewards_train/rejected': '-5.7477', 'rewards_train/margins': '5.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20154', 'examples_per_second': '5.1911', 'grad_norm': '4.9375', 'counters/examples': 226688, 'counters/updates': 14168}
skipping logging after 226704 examples to avoid logging too frequently
skipping logging after 226720 examples to avoid logging too frequently
skipping logging after 226736 examples to avoid logging too frequently
train stats after 226752 examples: {'rewards_train/chosen': '0.14265', 'rewards_train/rejected': '-7.321', 'rewards_train/margins': '7.3281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26447', 'examples_per_second': '4.7692', 'grad_norm': '5.9062', 'counters/examples': 226752, 'counters/updates': 14172}
skipping logging after 226768 examples to avoid logging too frequently
skipping logging after 226784 examples to avoid logging too frequently
skipping logging after 226800 examples to avoid logging too frequently
train stats after 226816 examples: {'rewards_train/chosen': '-0.0097971', 'rewards_train/rejected': '-5.7114', 'rewards_train/margins': '5.7266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25812', 'examples_per_second': '5.8836', 'grad_norm': '5', 'counters/examples': 226816, 'counters/updates': 14176}
skipping logging after 226832 examples to avoid logging too frequently
skipping logging after 226848 examples to avoid logging too frequently
skipping logging after 226864 examples to avoid logging too frequently
train stats after 226880 examples: {'rewards_train/chosen': '0.42995', 'rewards_train/rejected': '-5.8267', 'rewards_train/margins': '6.2344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25153', 'examples_per_second': '4.5607', 'grad_norm': '5.5312', 'counters/examples': 226880, 'counters/updates': 14180}
skipping logging after 226896 examples to avoid logging too frequently
skipping logging after 226912 examples to avoid logging too frequently
skipping logging after 226928 examples to avoid logging too frequently
train stats after 226944 examples: {'rewards_train/chosen': '0.55055', 'rewards_train/rejected': '-7.7591', 'rewards_train/margins': '8.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.15833', 'examples_per_second': '4.2152', 'grad_norm': '4.5312', 'counters/examples': 226944, 'counters/updates': 14184}
skipping logging after 226960 examples to avoid logging too frequently
skipping logging after 226976 examples to avoid logging too frequently
skipping logging after 226992 examples to avoid logging too frequently
train stats after 227008 examples: {'rewards_train/chosen': '0.34141', 'rewards_train/rejected': '-6.5642', 'rewards_train/margins': '7.0547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.216', 'examples_per_second': '5.1906', 'grad_norm': '4.5', 'counters/examples': 227008, 'counters/updates': 14188}
skipping logging after 227024 examples to avoid logging too frequently
skipping logging after 227040 examples to avoid logging too frequently
skipping logging after 227056 examples to avoid logging too frequently
train stats after 227072 examples: {'rewards_train/chosen': '0.44039', 'rewards_train/rejected': '-5.454', 'rewards_train/margins': '6.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25171', 'examples_per_second': '5.8532', 'grad_norm': '5.5', 'counters/examples': 227072, 'counters/updates': 14192}
skipping logging after 227088 examples to avoid logging too frequently
skipping logging after 227104 examples to avoid logging too frequently
skipping logging after 227120 examples to avoid logging too frequently
train stats after 227136 examples: {'rewards_train/chosen': '0.52877', 'rewards_train/rejected': '-6.3708', 'rewards_train/margins': '6.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20325', 'examples_per_second': '5.5404', 'grad_norm': '5.4375', 'counters/examples': 227136, 'counters/updates': 14196}
skipping logging after 227152 examples to avoid logging too frequently
skipping logging after 227168 examples to avoid logging too frequently
skipping logging after 227184 examples to avoid logging too frequently
train stats after 227200 examples: {'rewards_train/chosen': '0.15029', 'rewards_train/rejected': '-5.5756', 'rewards_train/margins': '5.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21259', 'examples_per_second': '5.5231', 'grad_norm': '4.5625', 'counters/examples': 227200, 'counters/updates': 14200}
skipping logging after 227216 examples to avoid logging too frequently
skipping logging after 227232 examples to avoid logging too frequently
skipping logging after 227248 examples to avoid logging too frequently
train stats after 227264 examples: {'rewards_train/chosen': '0.37706', 'rewards_train/rejected': '-6.8438', 'rewards_train/margins': '7.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21326', 'examples_per_second': '6.6385', 'grad_norm': '6.1875', 'counters/examples': 227264, 'counters/updates': 14204}
skipping logging after 227280 examples to avoid logging too frequently
skipping logging after 227296 examples to avoid logging too frequently
skipping logging after 227312 examples to avoid logging too frequently
train stats after 227328 examples: {'rewards_train/chosen': '0.49938', 'rewards_train/rejected': '-6.4617', 'rewards_train/margins': '6.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20465', 'examples_per_second': '4.8078', 'grad_norm': '4.8125', 'counters/examples': 227328, 'counters/updates': 14208}
skipping logging after 227344 examples to avoid logging too frequently
skipping logging after 227360 examples to avoid logging too frequently
skipping logging after 227376 examples to avoid logging too frequently
train stats after 227392 examples: {'rewards_train/chosen': '0.52188', 'rewards_train/rejected': '-6.3237', 'rewards_train/margins': '6.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19067', 'examples_per_second': '5.9534', 'grad_norm': '4.5312', 'counters/examples': 227392, 'counters/updates': 14212}
skipping logging after 227408 examples to avoid logging too frequently
skipping logging after 227424 examples to avoid logging too frequently
skipping logging after 227440 examples to avoid logging too frequently
train stats after 227456 examples: {'rewards_train/chosen': '0.22286', 'rewards_train/rejected': '-6.6588', 'rewards_train/margins': '6.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21918', 'examples_per_second': '5.9967', 'grad_norm': '4.25', 'counters/examples': 227456, 'counters/updates': 14216}
skipping logging after 227472 examples to avoid logging too frequently
skipping logging after 227488 examples to avoid logging too frequently
skipping logging after 227504 examples to avoid logging too frequently
train stats after 227520 examples: {'rewards_train/chosen': '0.074478', 'rewards_train/rejected': '-7.6566', 'rewards_train/margins': '7.9297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25232', 'examples_per_second': '4.6113', 'grad_norm': '5.4062', 'counters/examples': 227520, 'counters/updates': 14220}
skipping logging after 227536 examples to avoid logging too frequently
skipping logging after 227552 examples to avoid logging too frequently
skipping logging after 227568 examples to avoid logging too frequently
train stats after 227584 examples: {'rewards_train/chosen': '0.33058', 'rewards_train/rejected': '-7.3948', 'rewards_train/margins': '7.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23547', 'examples_per_second': '5.6109', 'grad_norm': '4.7812', 'counters/examples': 227584, 'counters/updates': 14224}
skipping logging after 227600 examples to avoid logging too frequently
skipping logging after 227616 examples to avoid logging too frequently
skipping logging after 227632 examples to avoid logging too frequently
train stats after 227648 examples: {'rewards_train/chosen': '0.45219', 'rewards_train/rejected': '-5.6621', 'rewards_train/margins': '6.1016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24634', 'examples_per_second': '4.8668', 'grad_norm': '4.625', 'counters/examples': 227648, 'counters/updates': 14228}
skipping logging after 227664 examples to avoid logging too frequently
skipping logging after 227680 examples to avoid logging too frequently
skipping logging after 227696 examples to avoid logging too frequently
train stats after 227712 examples: {'rewards_train/chosen': '0.56285', 'rewards_train/rejected': '-6.431', 'rewards_train/margins': '6.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21021', 'examples_per_second': '5.6455', 'grad_norm': '4.6875', 'counters/examples': 227712, 'counters/updates': 14232}
skipping logging after 227728 examples to avoid logging too frequently
skipping logging after 227744 examples to avoid logging too frequently
skipping logging after 227760 examples to avoid logging too frequently
train stats after 227776 examples: {'rewards_train/chosen': '0.49859', 'rewards_train/rejected': '-6.9111', 'rewards_train/margins': '7.375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26147', 'examples_per_second': '4.9607', 'grad_norm': '5.4688', 'counters/examples': 227776, 'counters/updates': 14236}
skipping logging after 227792 examples to avoid logging too frequently
skipping logging after 227808 examples to avoid logging too frequently
skipping logging after 227824 examples to avoid logging too frequently
train stats after 227840 examples: {'rewards_train/chosen': '0.27402', 'rewards_train/rejected': '-6.1779', 'rewards_train/margins': '6.2344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24353', 'examples_per_second': '4.8185', 'grad_norm': '4.6562', 'counters/examples': 227840, 'counters/updates': 14240}
skipping logging after 227856 examples to avoid logging too frequently
skipping logging after 227872 examples to avoid logging too frequently
skipping logging after 227888 examples to avoid logging too frequently
train stats after 227904 examples: {'rewards_train/chosen': '0.14613', 'rewards_train/rejected': '-7.6043', 'rewards_train/margins': '7.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21619', 'examples_per_second': '5.1835', 'grad_norm': '5.3125', 'counters/examples': 227904, 'counters/updates': 14244}
skipping logging after 227920 examples to avoid logging too frequently
skipping logging after 227936 examples to avoid logging too frequently
skipping logging after 227952 examples to avoid logging too frequently
train stats after 227968 examples: {'rewards_train/chosen': '-0.14189', 'rewards_train/rejected': '-7.2145', 'rewards_train/margins': '6.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25586', 'examples_per_second': '5.7326', 'grad_norm': '4.6562', 'counters/examples': 227968, 'counters/updates': 14248}
skipping logging after 227984 examples to avoid logging too frequently
skipping logging after 228000 examples to avoid logging too frequently
Running evaluation after 228000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:48,  1.57s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:41,  1.39s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:35,  1.24s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.47s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.68s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.49s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:10<00:34,  1.37s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.49s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:31,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.22s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.17s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:12,  1.44s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:11,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.35s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.31s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.18s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.31s/it]
eval after 228000: {'rewards_eval/chosen': '-5.6585', 'rewards_eval/rejected': '-6.2295', 'rewards_eval/margins': '0.41602', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.45831'}
skipping logging after 228016 examples to avoid logging too frequently
train stats after 228032 examples: {'rewards_train/chosen': '0.48184', 'rewards_train/rejected': '-5.4613', 'rewards_train/margins': '5.9453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.237', 'examples_per_second': '5.6114', 'grad_norm': '4.625', 'counters/examples': 228032, 'counters/updates': 14252}
skipping logging after 228048 examples to avoid logging too frequently
skipping logging after 228064 examples to avoid logging too frequently
skipping logging after 228080 examples to avoid logging too frequently
train stats after 228096 examples: {'rewards_train/chosen': '0.24786', 'rewards_train/rejected': '-5.6136', 'rewards_train/margins': '5.5781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26453', 'examples_per_second': '5.8845', 'grad_norm': '5.25', 'counters/examples': 228096, 'counters/updates': 14256}
skipping logging after 228112 examples to avoid logging too frequently
skipping logging after 228128 examples to avoid logging too frequently
skipping logging after 228144 examples to avoid logging too frequently
train stats after 228160 examples: {'rewards_train/chosen': '0.32007', 'rewards_train/rejected': '-7.2457', 'rewards_train/margins': '7.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2771', 'examples_per_second': '5.3182', 'grad_norm': '4.9688', 'counters/examples': 228160, 'counters/updates': 14260}
skipping logging after 228176 examples to avoid logging too frequently
skipping logging after 228192 examples to avoid logging too frequently
skipping logging after 228208 examples to avoid logging too frequently
train stats after 228224 examples: {'rewards_train/chosen': '0.44948', 'rewards_train/rejected': '-5.5778', 'rewards_train/margins': '6.0859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23053', 'examples_per_second': '5.8798', 'grad_norm': '4.7812', 'counters/examples': 228224, 'counters/updates': 14264}
skipping logging after 228240 examples to avoid logging too frequently
skipping logging after 228256 examples to avoid logging too frequently
skipping logging after 228272 examples to avoid logging too frequently
train stats after 228288 examples: {'rewards_train/chosen': '0.19998', 'rewards_train/rejected': '-6.0006', 'rewards_train/margins': '6.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22235', 'examples_per_second': '5.3671', 'grad_norm': '4.9062', 'counters/examples': 228288, 'counters/updates': 14268}
skipping logging after 228304 examples to avoid logging too frequently
skipping logging after 228320 examples to avoid logging too frequently
skipping logging after 228336 examples to avoid logging too frequently
train stats after 228352 examples: {'rewards_train/chosen': '0.31237', 'rewards_train/rejected': '-6.4419', 'rewards_train/margins': '6.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19153', 'examples_per_second': '4.447', 'grad_norm': '4.0938', 'counters/examples': 228352, 'counters/updates': 14272}
skipping logging after 228368 examples to avoid logging too frequently
skipping logging after 228384 examples to avoid logging too frequently
skipping logging after 228400 examples to avoid logging too frequently
train stats after 228416 examples: {'rewards_train/chosen': '-0.064189', 'rewards_train/rejected': '-5.5076', 'rewards_train/margins': '5.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28302', 'examples_per_second': '4.5004', 'grad_norm': '6.4688', 'counters/examples': 228416, 'counters/updates': 14276}
skipping logging after 228432 examples to avoid logging too frequently
skipping logging after 228448 examples to avoid logging too frequently
skipping logging after 228464 examples to avoid logging too frequently
train stats after 228480 examples: {'rewards_train/chosen': '0.54013', 'rewards_train/rejected': '-4.9689', 'rewards_train/margins': '5.7656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22296', 'examples_per_second': '5.2485', 'grad_norm': '4.1562', 'counters/examples': 228480, 'counters/updates': 14280}
skipping logging after 228496 examples to avoid logging too frequently
skipping logging after 228512 examples to avoid logging too frequently
skipping logging after 228528 examples to avoid logging too frequently
train stats after 228544 examples: {'rewards_train/chosen': '0.44146', 'rewards_train/rejected': '-6.279', 'rewards_train/margins': '6.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20514', 'examples_per_second': '5.5513', 'grad_norm': '4.375', 'counters/examples': 228544, 'counters/updates': 14284}
skipping logging after 228560 examples to avoid logging too frequently
skipping logging after 228576 examples to avoid logging too frequently
skipping logging after 228592 examples to avoid logging too frequently
train stats after 228608 examples: {'rewards_train/chosen': '0.546', 'rewards_train/rejected': '-5.098', 'rewards_train/margins': '5.4219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24548', 'examples_per_second': '5.8772', 'grad_norm': '6.4688', 'counters/examples': 228608, 'counters/updates': 14288}
skipping logging after 228624 examples to avoid logging too frequently
skipping logging after 228640 examples to avoid logging too frequently
skipping logging after 228656 examples to avoid logging too frequently
train stats after 228672 examples: {'rewards_train/chosen': '0.45629', 'rewards_train/rejected': '-5.9766', 'rewards_train/margins': '6.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.224', 'examples_per_second': '5.3358', 'grad_norm': '4.6562', 'counters/examples': 228672, 'counters/updates': 14292}
skipping logging after 228688 examples to avoid logging too frequently
skipping logging after 228704 examples to avoid logging too frequently
skipping logging after 228720 examples to avoid logging too frequently
train stats after 228736 examples: {'rewards_train/chosen': '0.52535', 'rewards_train/rejected': '-7.1683', 'rewards_train/margins': '7.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2251', 'examples_per_second': '5.034', 'grad_norm': '5.125', 'counters/examples': 228736, 'counters/updates': 14296}
skipping logging after 228752 examples to avoid logging too frequently
skipping logging after 228768 examples to avoid logging too frequently
skipping logging after 228784 examples to avoid logging too frequently
train stats after 228800 examples: {'rewards_train/chosen': '0.32383', 'rewards_train/rejected': '-4.6841', 'rewards_train/margins': '4.918', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29504', 'examples_per_second': '6.628', 'grad_norm': '5.625', 'counters/examples': 228800, 'counters/updates': 14300}
skipping logging after 228816 examples to avoid logging too frequently
skipping logging after 228832 examples to avoid logging too frequently
skipping logging after 228848 examples to avoid logging too frequently
train stats after 228864 examples: {'rewards_train/chosen': '0.62582', 'rewards_train/rejected': '-5.7316', 'rewards_train/margins': '6.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22687', 'examples_per_second': '5.3815', 'grad_norm': '4.9688', 'counters/examples': 228864, 'counters/updates': 14304}
skipping logging after 228880 examples to avoid logging too frequently
skipping logging after 228896 examples to avoid logging too frequently
skipping logging after 228912 examples to avoid logging too frequently
train stats after 228928 examples: {'rewards_train/chosen': '0.62666', 'rewards_train/rejected': '-5.7625', 'rewards_train/margins': '6.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19836', 'examples_per_second': '5.6032', 'grad_norm': '5.2188', 'counters/examples': 228928, 'counters/updates': 14308}
skipping logging after 228944 examples to avoid logging too frequently
skipping logging after 228960 examples to avoid logging too frequently
skipping logging after 228976 examples to avoid logging too frequently
train stats after 228992 examples: {'rewards_train/chosen': '0.23449', 'rewards_train/rejected': '-4.9821', 'rewards_train/margins': '5.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23114', 'examples_per_second': '5.7494', 'grad_norm': '5.3438', 'counters/examples': 228992, 'counters/updates': 14312}
skipping logging after 229008 examples to avoid logging too frequently
skipping logging after 229024 examples to avoid logging too frequently
skipping logging after 229040 examples to avoid logging too frequently
train stats after 229056 examples: {'rewards_train/chosen': '0.41428', 'rewards_train/rejected': '-6.8368', 'rewards_train/margins': '6.7461', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23682', 'examples_per_second': '4.4185', 'grad_norm': '4.9062', 'counters/examples': 229056, 'counters/updates': 14316}
skipping logging after 229072 examples to avoid logging too frequently
skipping logging after 229088 examples to avoid logging too frequently
skipping logging after 229104 examples to avoid logging too frequently
train stats after 229120 examples: {'rewards_train/chosen': '0.3861', 'rewards_train/rejected': '-5.3504', 'rewards_train/margins': '5.7812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27252', 'examples_per_second': '5.2286', 'grad_norm': '5.5938', 'counters/examples': 229120, 'counters/updates': 14320}
skipping logging after 229136 examples to avoid logging too frequently
skipping logging after 229152 examples to avoid logging too frequently
skipping logging after 229168 examples to avoid logging too frequently
train stats after 229184 examples: {'rewards_train/chosen': '0.6555', 'rewards_train/rejected': '-4.5932', 'rewards_train/margins': '5.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24066', 'examples_per_second': '5.1248', 'grad_norm': '4.5938', 'counters/examples': 229184, 'counters/updates': 14324}
skipping logging after 229200 examples to avoid logging too frequently
skipping logging after 229216 examples to avoid logging too frequently
skipping logging after 229232 examples to avoid logging too frequently
train stats after 229248 examples: {'rewards_train/chosen': '0.22157', 'rewards_train/rejected': '-6.545', 'rewards_train/margins': '6.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18719', 'examples_per_second': '5.5538', 'grad_norm': '4.9375', 'counters/examples': 229248, 'counters/updates': 14328}
skipping logging after 229264 examples to avoid logging too frequently
skipping logging after 229280 examples to avoid logging too frequently
skipping logging after 229296 examples to avoid logging too frequently
train stats after 229312 examples: {'rewards_train/chosen': '0.30394', 'rewards_train/rejected': '-7.1258', 'rewards_train/margins': '7.3672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1936', 'examples_per_second': '4.7088', 'grad_norm': '5.0625', 'counters/examples': 229312, 'counters/updates': 14332}
skipping logging after 229328 examples to avoid logging too frequently
skipping logging after 229344 examples to avoid logging too frequently
skipping logging after 229360 examples to avoid logging too frequently
train stats after 229376 examples: {'rewards_train/chosen': '0.18833', 'rewards_train/rejected': '-7.7382', 'rewards_train/margins': '7.8906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27203', 'examples_per_second': '4.3755', 'grad_norm': '5.2188', 'counters/examples': 229376, 'counters/updates': 14336}
skipping logging after 229392 examples to avoid logging too frequently
skipping logging after 229408 examples to avoid logging too frequently
skipping logging after 229424 examples to avoid logging too frequently
train stats after 229440 examples: {'rewards_train/chosen': '0.3704', 'rewards_train/rejected': '-6.4362', 'rewards_train/margins': '6.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26526', 'examples_per_second': '4.8069', 'grad_norm': '5.3125', 'counters/examples': 229440, 'counters/updates': 14340}
skipping logging after 229456 examples to avoid logging too frequently
skipping logging after 229472 examples to avoid logging too frequently
skipping logging after 229488 examples to avoid logging too frequently
train stats after 229504 examples: {'rewards_train/chosen': '0.57409', 'rewards_train/rejected': '-6.7533', 'rewards_train/margins': '7.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18793', 'examples_per_second': '4.6095', 'grad_norm': '5.1875', 'counters/examples': 229504, 'counters/updates': 14344}
skipping logging after 229520 examples to avoid logging too frequently
skipping logging after 229536 examples to avoid logging too frequently
skipping logging after 229552 examples to avoid logging too frequently
train stats after 229568 examples: {'rewards_train/chosen': '0.34752', 'rewards_train/rejected': '-6.6184', 'rewards_train/margins': '6.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25073', 'examples_per_second': '5.0229', 'grad_norm': '6.375', 'counters/examples': 229568, 'counters/updates': 14348}
skipping logging after 229584 examples to avoid logging too frequently
skipping logging after 229600 examples to avoid logging too frequently
skipping logging after 229616 examples to avoid logging too frequently
train stats after 229632 examples: {'rewards_train/chosen': '0.42389', 'rewards_train/rejected': '-5.8412', 'rewards_train/margins': '6.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26196', 'examples_per_second': '5.2027', 'grad_norm': '5.2188', 'counters/examples': 229632, 'counters/updates': 14352}
skipping logging after 229648 examples to avoid logging too frequently
skipping logging after 229664 examples to avoid logging too frequently
skipping logging after 229680 examples to avoid logging too frequently
train stats after 229696 examples: {'rewards_train/chosen': '-0.40715', 'rewards_train/rejected': '-5.1861', 'rewards_train/margins': '4.9258', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27679', 'examples_per_second': '5.1813', 'grad_norm': '4.6875', 'counters/examples': 229696, 'counters/updates': 14356}
skipping logging after 229712 examples to avoid logging too frequently
skipping logging after 229728 examples to avoid logging too frequently
skipping logging after 229744 examples to avoid logging too frequently
train stats after 229760 examples: {'rewards_train/chosen': '0.1904', 'rewards_train/rejected': '-6.2772', 'rewards_train/margins': '6.5781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2804', 'examples_per_second': '4.9443', 'grad_norm': '6', 'counters/examples': 229760, 'counters/updates': 14360}
skipping logging after 229776 examples to avoid logging too frequently
skipping logging after 229792 examples to avoid logging too frequently
skipping logging after 229808 examples to avoid logging too frequently
train stats after 229824 examples: {'rewards_train/chosen': '0.52216', 'rewards_train/rejected': '-5.8608', 'rewards_train/margins': '6.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21106', 'examples_per_second': '4.518', 'grad_norm': '5.2812', 'counters/examples': 229824, 'counters/updates': 14364}
skipping logging after 229840 examples to avoid logging too frequently
skipping logging after 229856 examples to avoid logging too frequently
skipping logging after 229872 examples to avoid logging too frequently
train stats after 229888 examples: {'rewards_train/chosen': '0.31657', 'rewards_train/rejected': '-5.0345', 'rewards_train/margins': '5.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26599', 'examples_per_second': '6.146', 'grad_norm': '5.3125', 'counters/examples': 229888, 'counters/updates': 14368}
skipping logging after 229904 examples to avoid logging too frequently
skipping logging after 229920 examples to avoid logging too frequently
skipping logging after 229936 examples to avoid logging too frequently
train stats after 229952 examples: {'rewards_train/chosen': '0.26269', 'rewards_train/rejected': '-5.1399', 'rewards_train/margins': '5.2422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26874', 'examples_per_second': '4.0887', 'grad_norm': '4.8125', 'counters/examples': 229952, 'counters/updates': 14372}
skipping logging after 229968 examples to avoid logging too frequently
skipping logging after 229984 examples to avoid logging too frequently
skipping logging after 230000 examples to avoid logging too frequently
train stats after 230016 examples: {'rewards_train/chosen': '0.37331', 'rewards_train/rejected': '-6.0635', 'rewards_train/margins': '6.7109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22754', 'examples_per_second': '4.8713', 'grad_norm': '4.5', 'counters/examples': 230016, 'counters/updates': 14376}
skipping logging after 230032 examples to avoid logging too frequently
skipping logging after 230048 examples to avoid logging too frequently
skipping logging after 230064 examples to avoid logging too frequently
train stats after 230080 examples: {'rewards_train/chosen': '0.14759', 'rewards_train/rejected': '-6.9971', 'rewards_train/margins': '7.1406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22742', 'examples_per_second': '6.4135', 'grad_norm': '4.7812', 'counters/examples': 230080, 'counters/updates': 14380}
skipping logging after 230096 examples to avoid logging too frequently
skipping logging after 230112 examples to avoid logging too frequently
skipping logging after 230128 examples to avoid logging too frequently
train stats after 230144 examples: {'rewards_train/chosen': '0.27904', 'rewards_train/rejected': '-6.6775', 'rewards_train/margins': '6.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27362', 'examples_per_second': '4.4697', 'grad_norm': '5.125', 'counters/examples': 230144, 'counters/updates': 14384}
skipping logging after 230160 examples to avoid logging too frequently
skipping logging after 230176 examples to avoid logging too frequently
skipping logging after 230192 examples to avoid logging too frequently
train stats after 230208 examples: {'rewards_train/chosen': '0.5048', 'rewards_train/rejected': '-7.6351', 'rewards_train/margins': '7.8945', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21692', 'examples_per_second': '5.6154', 'grad_norm': '5.0938', 'counters/examples': 230208, 'counters/updates': 14388}
skipping logging after 230224 examples to avoid logging too frequently
skipping logging after 230240 examples to avoid logging too frequently
skipping logging after 230256 examples to avoid logging too frequently
train stats after 230272 examples: {'rewards_train/chosen': '0.21749', 'rewards_train/rejected': '-5.5364', 'rewards_train/margins': '5.7891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27686', 'examples_per_second': '6.3137', 'grad_norm': '6.2188', 'counters/examples': 230272, 'counters/updates': 14392}
skipping logging after 230288 examples to avoid logging too frequently
skipping logging after 230304 examples to avoid logging too frequently
skipping logging after 230320 examples to avoid logging too frequently
train stats after 230336 examples: {'rewards_train/chosen': '-0.033871', 'rewards_train/rejected': '-6.4428', 'rewards_train/margins': '6.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29181', 'examples_per_second': '4.3855', 'grad_norm': '6.1562', 'counters/examples': 230336, 'counters/updates': 14396}
skipping logging after 230352 examples to avoid logging too frequently
skipping logging after 230368 examples to avoid logging too frequently
skipping logging after 230384 examples to avoid logging too frequently
train stats after 230400 examples: {'rewards_train/chosen': '0.91486', 'rewards_train/rejected': '-6.5628', 'rewards_train/margins': '7.3594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19696', 'examples_per_second': '4.9292', 'grad_norm': '4.9375', 'counters/examples': 230400, 'counters/updates': 14400}
skipping logging after 230416 examples to avoid logging too frequently
skipping logging after 230432 examples to avoid logging too frequently
skipping logging after 230448 examples to avoid logging too frequently
train stats after 230464 examples: {'rewards_train/chosen': '0.42175', 'rewards_train/rejected': '-6.5043', 'rewards_train/margins': '6.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1925', 'examples_per_second': '4.2632', 'grad_norm': '5.1875', 'counters/examples': 230464, 'counters/updates': 14404}
skipping logging after 230480 examples to avoid logging too frequently
skipping logging after 230496 examples to avoid logging too frequently
skipping logging after 230512 examples to avoid logging too frequently
train stats after 230528 examples: {'rewards_train/chosen': '0.52885', 'rewards_train/rejected': '-6.6116', 'rewards_train/margins': '7.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19098', 'examples_per_second': '4.7602', 'grad_norm': '4.0312', 'counters/examples': 230528, 'counters/updates': 14408}
skipping logging after 230544 examples to avoid logging too frequently
skipping logging after 230560 examples to avoid logging too frequently
skipping logging after 230576 examples to avoid logging too frequently
train stats after 230592 examples: {'rewards_train/chosen': '0.31101', 'rewards_train/rejected': '-7.1589', 'rewards_train/margins': '7.3594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22644', 'examples_per_second': '5.3501', 'grad_norm': '4.9375', 'counters/examples': 230592, 'counters/updates': 14412}
skipping logging after 230608 examples to avoid logging too frequently
skipping logging after 230624 examples to avoid logging too frequently
skipping logging after 230640 examples to avoid logging too frequently
train stats after 230656 examples: {'rewards_train/chosen': '0.2545', 'rewards_train/rejected': '-6.7091', 'rewards_train/margins': '7.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23743', 'examples_per_second': '4.0405', 'grad_norm': '4.7812', 'counters/examples': 230656, 'counters/updates': 14416}
skipping logging after 230672 examples to avoid logging too frequently
skipping logging after 230688 examples to avoid logging too frequently
skipping logging after 230704 examples to avoid logging too frequently
train stats after 230720 examples: {'rewards_train/chosen': '0.018722', 'rewards_train/rejected': '-5.7654', 'rewards_train/margins': '5.7656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27283', 'examples_per_second': '4.9453', 'grad_norm': '5.625', 'counters/examples': 230720, 'counters/updates': 14420}
skipping logging after 230736 examples to avoid logging too frequently
skipping logging after 230752 examples to avoid logging too frequently
skipping logging after 230768 examples to avoid logging too frequently
train stats after 230784 examples: {'rewards_train/chosen': '0.16066', 'rewards_train/rejected': '-7.0818', 'rewards_train/margins': '7.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2196', 'examples_per_second': '5.6711', 'grad_norm': '4.625', 'counters/examples': 230784, 'counters/updates': 14424}
skipping logging after 230800 examples to avoid logging too frequently
skipping logging after 230816 examples to avoid logging too frequently
skipping logging after 230832 examples to avoid logging too frequently
train stats after 230848 examples: {'rewards_train/chosen': '0.51794', 'rewards_train/rejected': '-7.8167', 'rewards_train/margins': '8.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.16852', 'examples_per_second': '4.8811', 'grad_norm': '4.0312', 'counters/examples': 230848, 'counters/updates': 14428}
skipping logging after 230864 examples to avoid logging too frequently
skipping logging after 230880 examples to avoid logging too frequently
skipping logging after 230896 examples to avoid logging too frequently
train stats after 230912 examples: {'rewards_train/chosen': '0.23644', 'rewards_train/rejected': '-5.0618', 'rewards_train/margins': '6.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26971', 'examples_per_second': '5.4092', 'grad_norm': '5.0625', 'counters/examples': 230912, 'counters/updates': 14432}
skipping logging after 230928 examples to avoid logging too frequently
skipping logging after 230944 examples to avoid logging too frequently
skipping logging after 230960 examples to avoid logging too frequently
train stats after 230976 examples: {'rewards_train/chosen': '0.55858', 'rewards_train/rejected': '-5.4028', 'rewards_train/margins': '5.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2135', 'examples_per_second': '5.7001', 'grad_norm': '5.0312', 'counters/examples': 230976, 'counters/updates': 14436}
skipping logging after 230992 examples to avoid logging too frequently
skipping logging after 231008 examples to avoid logging too frequently
skipping logging after 231024 examples to avoid logging too frequently
train stats after 231040 examples: {'rewards_train/chosen': '0.50476', 'rewards_train/rejected': '-10.324', 'rewards_train/margins': '10.922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1886', 'examples_per_second': '5.3604', 'grad_norm': '5.6562', 'counters/examples': 231040, 'counters/updates': 14440}
skipping logging after 231056 examples to avoid logging too frequently
skipping logging after 231072 examples to avoid logging too frequently
skipping logging after 231088 examples to avoid logging too frequently
train stats after 231104 examples: {'rewards_train/chosen': '0.28391', 'rewards_train/rejected': '-6.5662', 'rewards_train/margins': '6.9766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22375', 'examples_per_second': '4.7551', 'grad_norm': '5.4688', 'counters/examples': 231104, 'counters/updates': 14444}
skipping logging after 231120 examples to avoid logging too frequently
skipping logging after 231136 examples to avoid logging too frequently
skipping logging after 231152 examples to avoid logging too frequently
train stats after 231168 examples: {'rewards_train/chosen': '0.32593', 'rewards_train/rejected': '-7.0228', 'rewards_train/margins': '7.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23883', 'examples_per_second': '6.5453', 'grad_norm': '5.0938', 'counters/examples': 231168, 'counters/updates': 14448}
skipping logging after 231184 examples to avoid logging too frequently
skipping logging after 231200 examples to avoid logging too frequently
skipping logging after 231216 examples to avoid logging too frequently
train stats after 231232 examples: {'rewards_train/chosen': '0.30608', 'rewards_train/rejected': '-7.4211', 'rewards_train/margins': '8.0312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23828', 'examples_per_second': '4.4505', 'grad_norm': '5.8125', 'counters/examples': 231232, 'counters/updates': 14452}
skipping logging after 231248 examples to avoid logging too frequently
skipping logging after 231264 examples to avoid logging too frequently
skipping logging after 231280 examples to avoid logging too frequently
train stats after 231296 examples: {'rewards_train/chosen': '0.55182', 'rewards_train/rejected': '-5.2944', 'rewards_train/margins': '5.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21027', 'examples_per_second': '4.9279', 'grad_norm': '4.875', 'counters/examples': 231296, 'counters/updates': 14456}
skipping logging after 231312 examples to avoid logging too frequently
skipping logging after 231328 examples to avoid logging too frequently
skipping logging after 231344 examples to avoid logging too frequently
train stats after 231360 examples: {'rewards_train/chosen': '0.37046', 'rewards_train/rejected': '-7.595', 'rewards_train/margins': '7.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24817', 'examples_per_second': '4.8773', 'grad_norm': '5.625', 'counters/examples': 231360, 'counters/updates': 14460}
skipping logging after 231376 examples to avoid logging too frequently
skipping logging after 231392 examples to avoid logging too frequently
skipping logging after 231408 examples to avoid logging too frequently
train stats after 231424 examples: {'rewards_train/chosen': '-0.028143', 'rewards_train/rejected': '-7.1951', 'rewards_train/margins': '7.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25677', 'examples_per_second': '5.8035', 'grad_norm': '4.0938', 'counters/examples': 231424, 'counters/updates': 14464}
skipping logging after 231440 examples to avoid logging too frequently
skipping logging after 231456 examples to avoid logging too frequently
skipping logging after 231472 examples to avoid logging too frequently
train stats after 231488 examples: {'rewards_train/chosen': '0.15166', 'rewards_train/rejected': '-5.5477', 'rewards_train/margins': '5.7031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23022', 'examples_per_second': '4.7407', 'grad_norm': '5.3125', 'counters/examples': 231488, 'counters/updates': 14468}
skipping logging after 231504 examples to avoid logging too frequently
skipping logging after 231520 examples to avoid logging too frequently
skipping logging after 231536 examples to avoid logging too frequently
train stats after 231552 examples: {'rewards_train/chosen': '0.43975', 'rewards_train/rejected': '-6.7478', 'rewards_train/margins': '7.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23254', 'examples_per_second': '4.7972', 'grad_norm': '4.625', 'counters/examples': 231552, 'counters/updates': 14472}
skipping logging after 231568 examples to avoid logging too frequently
skipping logging after 231584 examples to avoid logging too frequently
skipping logging after 231600 examples to avoid logging too frequently
train stats after 231616 examples: {'rewards_train/chosen': '0.50723', 'rewards_train/rejected': '-6.109', 'rewards_train/margins': '7.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25061', 'examples_per_second': '5.3388', 'grad_norm': '5.4062', 'counters/examples': 231616, 'counters/updates': 14476}
skipping logging after 231632 examples to avoid logging too frequently
skipping logging after 231648 examples to avoid logging too frequently
skipping logging after 231664 examples to avoid logging too frequently
train stats after 231680 examples: {'rewards_train/chosen': '0.33176', 'rewards_train/rejected': '-5.7217', 'rewards_train/margins': '6.3477', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25183', 'examples_per_second': '6.3514', 'grad_norm': '4.875', 'counters/examples': 231680, 'counters/updates': 14480}
skipping logging after 231696 examples to avoid logging too frequently
skipping logging after 231712 examples to avoid logging too frequently
skipping logging after 231728 examples to avoid logging too frequently
train stats after 231744 examples: {'rewards_train/chosen': '0.34325', 'rewards_train/rejected': '-6.784', 'rewards_train/margins': '7.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23193', 'examples_per_second': '5.9725', 'grad_norm': '6.9688', 'counters/examples': 231744, 'counters/updates': 14484}
skipping logging after 231760 examples to avoid logging too frequently
skipping logging after 231776 examples to avoid logging too frequently
skipping logging after 231792 examples to avoid logging too frequently
train stats after 231808 examples: {'rewards_train/chosen': '0.21959', 'rewards_train/rejected': '-5.6145', 'rewards_train/margins': '5.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25031', 'examples_per_second': '5.1225', 'grad_norm': '4.6562', 'counters/examples': 231808, 'counters/updates': 14488}
skipping logging after 231824 examples to avoid logging too frequently
skipping logging after 231840 examples to avoid logging too frequently
skipping logging after 231856 examples to avoid logging too frequently
train stats after 231872 examples: {'rewards_train/chosen': '0.34888', 'rewards_train/rejected': '-6.9464', 'rewards_train/margins': '7.4609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25433', 'examples_per_second': '4.9262', 'grad_norm': '5.1875', 'counters/examples': 231872, 'counters/updates': 14492}
skipping logging after 231888 examples to avoid logging too frequently
skipping logging after 231904 examples to avoid logging too frequently
skipping logging after 231920 examples to avoid logging too frequently
train stats after 231936 examples: {'rewards_train/chosen': '0.47841', 'rewards_train/rejected': '-6.2833', 'rewards_train/margins': '6.7812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2149', 'examples_per_second': '5.4735', 'grad_norm': '5.1875', 'counters/examples': 231936, 'counters/updates': 14496}
skipping logging after 231952 examples to avoid logging too frequently
skipping logging after 231968 examples to avoid logging too frequently
skipping logging after 231984 examples to avoid logging too frequently
train stats after 232000 examples: {'rewards_train/chosen': '0.35965', 'rewards_train/rejected': '-5.6213', 'rewards_train/margins': '6.0898', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21863', 'examples_per_second': '6.2225', 'grad_norm': '5.375', 'counters/examples': 232000, 'counters/updates': 14500}
Running evaluation after 232000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.25s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.17s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:39,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.65s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.47s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:33,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.40s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:21<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]
eval after 232000: {'rewards_eval/chosen': '-6.0598', 'rewards_eval/rejected': '-6.6425', 'rewards_eval/margins': '0.39258', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.45876'}
skipping logging after 232016 examples to avoid logging too frequently
skipping logging after 232032 examples to avoid logging too frequently
skipping logging after 232048 examples to avoid logging too frequently
train stats after 232064 examples: {'rewards_train/chosen': '0.19247', 'rewards_train/rejected': '-6.7651', 'rewards_train/margins': '7.0547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21112', 'examples_per_second': '5.9676', 'grad_norm': '4.6562', 'counters/examples': 232064, 'counters/updates': 14504}
skipping logging after 232080 examples to avoid logging too frequently
skipping logging after 232096 examples to avoid logging too frequently
skipping logging after 232112 examples to avoid logging too frequently
train stats after 232128 examples: {'rewards_train/chosen': '0.51202', 'rewards_train/rejected': '-6.91', 'rewards_train/margins': '7.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20404', 'examples_per_second': '5.3342', 'grad_norm': '4.5312', 'counters/examples': 232128, 'counters/updates': 14508}
skipping logging after 232144 examples to avoid logging too frequently
skipping logging after 232160 examples to avoid logging too frequently
skipping logging after 232176 examples to avoid logging too frequently
train stats after 232192 examples: {'rewards_train/chosen': '0.14579', 'rewards_train/rejected': '-6.0415', 'rewards_train/margins': '6.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28119', 'examples_per_second': '5.8282', 'grad_norm': '5.5312', 'counters/examples': 232192, 'counters/updates': 14512}
skipping logging after 232208 examples to avoid logging too frequently
skipping logging after 232224 examples to avoid logging too frequently
skipping logging after 232240 examples to avoid logging too frequently
train stats after 232256 examples: {'rewards_train/chosen': '0.20573', 'rewards_train/rejected': '-6.1089', 'rewards_train/margins': '6.4609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19519', 'examples_per_second': '4.8821', 'grad_norm': '4.6875', 'counters/examples': 232256, 'counters/updates': 14516}
skipping logging after 232272 examples to avoid logging too frequently
skipping logging after 232288 examples to avoid logging too frequently
skipping logging after 232304 examples to avoid logging too frequently
train stats after 232320 examples: {'rewards_train/chosen': '0.30048', 'rewards_train/rejected': '-5.6387', 'rewards_train/margins': '6.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23657', 'examples_per_second': '4.5692', 'grad_norm': '4.5312', 'counters/examples': 232320, 'counters/updates': 14520}
skipping logging after 232336 examples to avoid logging too frequently
skipping logging after 232352 examples to avoid logging too frequently
skipping logging after 232368 examples to avoid logging too frequently
train stats after 232384 examples: {'rewards_train/chosen': '0.31718', 'rewards_train/rejected': '-5.8314', 'rewards_train/margins': '6.0117', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24634', 'examples_per_second': '6.0197', 'grad_norm': '5', 'counters/examples': 232384, 'counters/updates': 14524}
skipping logging after 232400 examples to avoid logging too frequently
skipping logging after 232416 examples to avoid logging too frequently
skipping logging after 232432 examples to avoid logging too frequently
train stats after 232448 examples: {'rewards_train/chosen': '0.08352', 'rewards_train/rejected': '-6.5945', 'rewards_train/margins': '6.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2099', 'examples_per_second': '5.0423', 'grad_norm': '5.1562', 'counters/examples': 232448, 'counters/updates': 14528}
skipping logging after 232464 examples to avoid logging too frequently
skipping logging after 232480 examples to avoid logging too frequently
skipping logging after 232496 examples to avoid logging too frequently
train stats after 232512 examples: {'rewards_train/chosen': '0.39632', 'rewards_train/rejected': '-4.9887', 'rewards_train/margins': '5.6875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28748', 'examples_per_second': '5.1233', 'grad_norm': '5.7188', 'counters/examples': 232512, 'counters/updates': 14532}
skipping logging after 232528 examples to avoid logging too frequently
skipping logging after 232544 examples to avoid logging too frequently
skipping logging after 232560 examples to avoid logging too frequently
train stats after 232576 examples: {'rewards_train/chosen': '0.32601', 'rewards_train/rejected': '-4.6385', 'rewards_train/margins': '5.043', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25641', 'examples_per_second': '5.4315', 'grad_norm': '4.4688', 'counters/examples': 232576, 'counters/updates': 14536}
skipping logging after 232592 examples to avoid logging too frequently
skipping logging after 232608 examples to avoid logging too frequently
skipping logging after 232624 examples to avoid logging too frequently
train stats after 232640 examples: {'rewards_train/chosen': '0.54595', 'rewards_train/rejected': '-6.1923', 'rewards_train/margins': '6.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21503', 'examples_per_second': '5.6466', 'grad_norm': '4.7188', 'counters/examples': 232640, 'counters/updates': 14540}
skipping logging after 232656 examples to avoid logging too frequently
skipping logging after 232672 examples to avoid logging too frequently
skipping logging after 232688 examples to avoid logging too frequently
train stats after 232704 examples: {'rewards_train/chosen': '0.19313', 'rewards_train/rejected': '-6.1787', 'rewards_train/margins': '6.3672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23102', 'examples_per_second': '5.1424', 'grad_norm': '4.375', 'counters/examples': 232704, 'counters/updates': 14544}
skipping logging after 232720 examples to avoid logging too frequently
skipping logging after 232736 examples to avoid logging too frequently
skipping logging after 232752 examples to avoid logging too frequently
train stats after 232768 examples: {'rewards_train/chosen': '0.32865', 'rewards_train/rejected': '-5.8268', 'rewards_train/margins': '6.2344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25195', 'examples_per_second': '4.908', 'grad_norm': '4.5938', 'counters/examples': 232768, 'counters/updates': 14548}
skipping logging after 232784 examples to avoid logging too frequently
skipping logging after 232800 examples to avoid logging too frequently
skipping logging after 232816 examples to avoid logging too frequently
train stats after 232832 examples: {'rewards_train/chosen': '0.37417', 'rewards_train/rejected': '-5.7642', 'rewards_train/margins': '6.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21515', 'examples_per_second': '4.589', 'grad_norm': '5.6562', 'counters/examples': 232832, 'counters/updates': 14552}
skipping logging after 232848 examples to avoid logging too frequently
skipping logging after 232864 examples to avoid logging too frequently
skipping logging after 232880 examples to avoid logging too frequently
train stats after 232896 examples: {'rewards_train/chosen': '0.66239', 'rewards_train/rejected': '-6.9405', 'rewards_train/margins': '7.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19983', 'examples_per_second': '5.1866', 'grad_norm': '5.375', 'counters/examples': 232896, 'counters/updates': 14556}
skipping logging after 232912 examples to avoid logging too frequently
skipping logging after 232928 examples to avoid logging too frequently
skipping logging after 232944 examples to avoid logging too frequently
train stats after 232960 examples: {'rewards_train/chosen': '0.33027', 'rewards_train/rejected': '-5.5163', 'rewards_train/margins': '5.7617', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26892', 'examples_per_second': '6.2189', 'grad_norm': '5.9688', 'counters/examples': 232960, 'counters/updates': 14560}
skipping logging after 232976 examples to avoid logging too frequently
skipping logging after 232992 examples to avoid logging too frequently
skipping logging after 233008 examples to avoid logging too frequently
train stats after 233024 examples: {'rewards_train/chosen': '0.56289', 'rewards_train/rejected': '-5.8519', 'rewards_train/margins': '6.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23187', 'examples_per_second': '4.9257', 'grad_norm': '5.4062', 'counters/examples': 233024, 'counters/updates': 14564}
skipping logging after 233040 examples to avoid logging too frequently
skipping logging after 233056 examples to avoid logging too frequently
skipping logging after 233072 examples to avoid logging too frequently
train stats after 233088 examples: {'rewards_train/chosen': '0.12528', 'rewards_train/rejected': '-7.002', 'rewards_train/margins': '7.0859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2832', 'examples_per_second': '5.7174', 'grad_norm': '5.0312', 'counters/examples': 233088, 'counters/updates': 14568}
skipping logging after 233104 examples to avoid logging too frequently
skipping logging after 233120 examples to avoid logging too frequently
skipping logging after 233136 examples to avoid logging too frequently
train stats after 233152 examples: {'rewards_train/chosen': '0.2419', 'rewards_train/rejected': '-5.9837', 'rewards_train/margins': '6.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23987', 'examples_per_second': '6.1219', 'grad_norm': '4.5625', 'counters/examples': 233152, 'counters/updates': 14572}
skipping logging after 233168 examples to avoid logging too frequently
skipping logging after 233184 examples to avoid logging too frequently
skipping logging after 233200 examples to avoid logging too frequently
train stats after 233216 examples: {'rewards_train/chosen': '0.61072', 'rewards_train/rejected': '-5.446', 'rewards_train/margins': '6.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22284', 'examples_per_second': '4.5848', 'grad_norm': '4.6875', 'counters/examples': 233216, 'counters/updates': 14576}
skipping logging after 233232 examples to avoid logging too frequently
skipping logging after 233248 examples to avoid logging too frequently
skipping logging after 233264 examples to avoid logging too frequently
train stats after 233280 examples: {'rewards_train/chosen': '0.30695', 'rewards_train/rejected': '-6.1921', 'rewards_train/margins': '6.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26367', 'examples_per_second': '4.8933', 'grad_norm': '4.7812', 'counters/examples': 233280, 'counters/updates': 14580}
skipping logging after 233296 examples to avoid logging too frequently
skipping logging after 233312 examples to avoid logging too frequently
skipping logging after 233328 examples to avoid logging too frequently
train stats after 233344 examples: {'rewards_train/chosen': '0.34254', 'rewards_train/rejected': '-4.4234', 'rewards_train/margins': '4.7305', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25616', 'examples_per_second': '4.6823', 'grad_norm': '5.9688', 'counters/examples': 233344, 'counters/updates': 14584}
skipping logging after 233360 examples to avoid logging too frequently
skipping logging after 233376 examples to avoid logging too frequently
skipping logging after 233392 examples to avoid logging too frequently
train stats after 233408 examples: {'rewards_train/chosen': '0.60856', 'rewards_train/rejected': '-6.5837', 'rewards_train/margins': '7.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21375', 'examples_per_second': '6.1533', 'grad_norm': '4.5', 'counters/examples': 233408, 'counters/updates': 14588}
skipping logging after 233424 examples to avoid logging too frequently
skipping logging after 233440 examples to avoid logging too frequently
skipping logging after 233456 examples to avoid logging too frequently
train stats after 233472 examples: {'rewards_train/chosen': '0.05731', 'rewards_train/rejected': '-8.3827', 'rewards_train/margins': '8.3672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25189', 'examples_per_second': '4.6237', 'grad_norm': '5.625', 'counters/examples': 233472, 'counters/updates': 14592}
skipping logging after 233488 examples to avoid logging too frequently
skipping logging after 233504 examples to avoid logging too frequently
skipping logging after 233520 examples to avoid logging too frequently
train stats after 233536 examples: {'rewards_train/chosen': '0.41636', 'rewards_train/rejected': '-5.3671', 'rewards_train/margins': '5.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22852', 'examples_per_second': '4.4322', 'grad_norm': '5.8125', 'counters/examples': 233536, 'counters/updates': 14596}
skipping logging after 233552 examples to avoid logging too frequently
skipping logging after 233568 examples to avoid logging too frequently
skipping logging after 233584 examples to avoid logging too frequently
train stats after 233600 examples: {'rewards_train/chosen': '0.83312', 'rewards_train/rejected': '-7.5838', 'rewards_train/margins': '8.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20654', 'examples_per_second': '4.1492', 'grad_norm': '4.4062', 'counters/examples': 233600, 'counters/updates': 14600}
skipping logging after 233616 examples to avoid logging too frequently
skipping logging after 233632 examples to avoid logging too frequently
skipping logging after 233648 examples to avoid logging too frequently
train stats after 233664 examples: {'rewards_train/chosen': '0.51697', 'rewards_train/rejected': '-6.1012', 'rewards_train/margins': '6.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20654', 'examples_per_second': '4.9583', 'grad_norm': '4.25', 'counters/examples': 233664, 'counters/updates': 14604}
skipping logging after 233680 examples to avoid logging too frequently
skipping logging after 233696 examples to avoid logging too frequently
skipping logging after 233712 examples to avoid logging too frequently
train stats after 233728 examples: {'rewards_train/chosen': '0.60945', 'rewards_train/rejected': '-6.4078', 'rewards_train/margins': '7.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18738', 'examples_per_second': '4.3605', 'grad_norm': '4.875', 'counters/examples': 233728, 'counters/updates': 14608}
skipping logging after 233744 examples to avoid logging too frequently
skipping logging after 233760 examples to avoid logging too frequently
skipping logging after 233776 examples to avoid logging too frequently
train stats after 233792 examples: {'rewards_train/chosen': '0.49014', 'rewards_train/rejected': '-6.7433', 'rewards_train/margins': '7.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1969', 'examples_per_second': '4.2363', 'grad_norm': '4.4062', 'counters/examples': 233792, 'counters/updates': 14612}
skipping logging after 233808 examples to avoid logging too frequently
skipping logging after 233824 examples to avoid logging too frequently
skipping logging after 233840 examples to avoid logging too frequently
train stats after 233856 examples: {'rewards_train/chosen': '0.39308', 'rewards_train/rejected': '-6.8328', 'rewards_train/margins': '7.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23627', 'examples_per_second': '5.1048', 'grad_norm': '5.4062', 'counters/examples': 233856, 'counters/updates': 14616}
skipping logging after 233872 examples to avoid logging too frequently
skipping logging after 233888 examples to avoid logging too frequently
skipping logging after 233904 examples to avoid logging too frequently
train stats after 233920 examples: {'rewards_train/chosen': '0.15478', 'rewards_train/rejected': '-6.3688', 'rewards_train/margins': '6.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21503', 'examples_per_second': '5.2631', 'grad_norm': '6.8438', 'counters/examples': 233920, 'counters/updates': 14620}
skipping logging after 233936 examples to avoid logging too frequently
skipping logging after 233952 examples to avoid logging too frequently
skipping logging after 233968 examples to avoid logging too frequently
train stats after 233984 examples: {'rewards_train/chosen': '0.41434', 'rewards_train/rejected': '-7.1514', 'rewards_train/margins': '7.9141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20898', 'examples_per_second': '5.7456', 'grad_norm': '5.1875', 'counters/examples': 233984, 'counters/updates': 14624}
skipping logging after 234000 examples to avoid logging too frequently
skipping logging after 234016 examples to avoid logging too frequently
skipping logging after 234032 examples to avoid logging too frequently
train stats after 234048 examples: {'rewards_train/chosen': '0.43317', 'rewards_train/rejected': '-4.8525', 'rewards_train/margins': '5.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23633', 'examples_per_second': '4.8169', 'grad_norm': '4.6562', 'counters/examples': 234048, 'counters/updates': 14628}
skipping logging after 234064 examples to avoid logging too frequently
skipping logging after 234080 examples to avoid logging too frequently
skipping logging after 234096 examples to avoid logging too frequently
train stats after 234112 examples: {'rewards_train/chosen': '0.26127', 'rewards_train/rejected': '-6.7125', 'rewards_train/margins': '7.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22308', 'examples_per_second': '5.4398', 'grad_norm': '3.9062', 'counters/examples': 234112, 'counters/updates': 14632}
skipping logging after 234128 examples to avoid logging too frequently
skipping logging after 234144 examples to avoid logging too frequently
skipping logging after 234160 examples to avoid logging too frequently
train stats after 234176 examples: {'rewards_train/chosen': '-0.27462', 'rewards_train/rejected': '-7.113', 'rewards_train/margins': '7.0234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27271', 'examples_per_second': '4.6634', 'grad_norm': '5.75', 'counters/examples': 234176, 'counters/updates': 14636}
skipping logging after 234192 examples to avoid logging too frequently
skipping logging after 234208 examples to avoid logging too frequently
skipping logging after 234224 examples to avoid logging too frequently
train stats after 234240 examples: {'rewards_train/chosen': '0.22181', 'rewards_train/rejected': '-6.1877', 'rewards_train/margins': '6.5938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26263', 'examples_per_second': '5.6348', 'grad_norm': '5.8125', 'counters/examples': 234240, 'counters/updates': 14640}
skipping logging after 234256 examples to avoid logging too frequently
skipping logging after 234272 examples to avoid logging too frequently
skipping logging after 234288 examples to avoid logging too frequently
train stats after 234304 examples: {'rewards_train/chosen': '0.66727', 'rewards_train/rejected': '-6.8992', 'rewards_train/margins': '7.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.16486', 'examples_per_second': '5.1133', 'grad_norm': '4.625', 'counters/examples': 234304, 'counters/updates': 14644}
skipping logging after 234320 examples to avoid logging too frequently
skipping logging after 234336 examples to avoid logging too frequently
skipping logging after 234352 examples to avoid logging too frequently
train stats after 234368 examples: {'rewards_train/chosen': '0.30299', 'rewards_train/rejected': '-6.6956', 'rewards_train/margins': '7.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23376', 'examples_per_second': '4.9115', 'grad_norm': '5.3438', 'counters/examples': 234368, 'counters/updates': 14648}
skipping logging after 234384 examples to avoid logging too frequently
skipping logging after 234400 examples to avoid logging too frequently
skipping logging after 234416 examples to avoid logging too frequently
train stats after 234432 examples: {'rewards_train/chosen': '-0.00011771', 'rewards_train/rejected': '-8.4413', 'rewards_train/margins': '8.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2121', 'examples_per_second': '5.8906', 'grad_norm': '4.75', 'counters/examples': 234432, 'counters/updates': 14652}
skipping logging after 234448 examples to avoid logging too frequently
skipping logging after 234464 examples to avoid logging too frequently
skipping logging after 234480 examples to avoid logging too frequently
train stats after 234496 examples: {'rewards_train/chosen': '0.29134', 'rewards_train/rejected': '-6.2349', 'rewards_train/margins': '6.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23181', 'examples_per_second': '5.2994', 'grad_norm': '4.625', 'counters/examples': 234496, 'counters/updates': 14656}
skipping logging after 234512 examples to avoid logging too frequently
skipping logging after 234528 examples to avoid logging too frequently
skipping logging after 234544 examples to avoid logging too frequently
train stats after 234560 examples: {'rewards_train/chosen': '0.44069', 'rewards_train/rejected': '-6.7421', 'rewards_train/margins': '7.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18958', 'examples_per_second': '5.5557', 'grad_norm': '5.5', 'counters/examples': 234560, 'counters/updates': 14660}
skipping logging after 234576 examples to avoid logging too frequently
skipping logging after 234592 examples to avoid logging too frequently
skipping logging after 234608 examples to avoid logging too frequently
train stats after 234624 examples: {'rewards_train/chosen': '-0.095112', 'rewards_train/rejected': '-6.5137', 'rewards_train/margins': '5.9297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30627', 'examples_per_second': '5.5538', 'grad_norm': '4.8125', 'counters/examples': 234624, 'counters/updates': 14664}
skipping logging after 234640 examples to avoid logging too frequently
skipping logging after 234656 examples to avoid logging too frequently
skipping logging after 234672 examples to avoid logging too frequently
train stats after 234688 examples: {'rewards_train/chosen': '0.43279', 'rewards_train/rejected': '-7.564', 'rewards_train/margins': '7.8672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22638', 'examples_per_second': '5.6277', 'grad_norm': '5.3438', 'counters/examples': 234688, 'counters/updates': 14668}
skipping logging after 234704 examples to avoid logging too frequently
skipping logging after 234720 examples to avoid logging too frequently
skipping logging after 234736 examples to avoid logging too frequently
train stats after 234752 examples: {'rewards_train/chosen': '0.28848', 'rewards_train/rejected': '-7.1147', 'rewards_train/margins': '7.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21289', 'examples_per_second': '4.6457', 'grad_norm': '5.1562', 'counters/examples': 234752, 'counters/updates': 14672}
skipping logging after 234768 examples to avoid logging too frequently
skipping logging after 234784 examples to avoid logging too frequently
skipping logging after 234800 examples to avoid logging too frequently
train stats after 234816 examples: {'rewards_train/chosen': '0.29633', 'rewards_train/rejected': '-5.889', 'rewards_train/margins': '5.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26556', 'examples_per_second': '5.3013', 'grad_norm': '5.3438', 'counters/examples': 234816, 'counters/updates': 14676}
skipping logging after 234832 examples to avoid logging too frequently
skipping logging after 234848 examples to avoid logging too frequently
skipping logging after 234864 examples to avoid logging too frequently
train stats after 234880 examples: {'rewards_train/chosen': '0.42306', 'rewards_train/rejected': '-6.4019', 'rewards_train/margins': '7.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26642', 'examples_per_second': '5.5256', 'grad_norm': '5', 'counters/examples': 234880, 'counters/updates': 14680}
skipping logging after 234896 examples to avoid logging too frequently
skipping logging after 234912 examples to avoid logging too frequently
skipping logging after 234928 examples to avoid logging too frequently
train stats after 234944 examples: {'rewards_train/chosen': '0.076922', 'rewards_train/rejected': '-5.6169', 'rewards_train/margins': '6.0156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2868', 'examples_per_second': '5.2657', 'grad_norm': '5.625', 'counters/examples': 234944, 'counters/updates': 14684}
skipping logging after 234960 examples to avoid logging too frequently
skipping logging after 234976 examples to avoid logging too frequently
skipping logging after 234992 examples to avoid logging too frequently
train stats after 235008 examples: {'rewards_train/chosen': '0.40044', 'rewards_train/rejected': '-5.9941', 'rewards_train/margins': '6.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27118', 'examples_per_second': '5.8179', 'grad_norm': '5.4688', 'counters/examples': 235008, 'counters/updates': 14688}
skipping logging after 235024 examples to avoid logging too frequently
skipping logging after 235040 examples to avoid logging too frequently
skipping logging after 235056 examples to avoid logging too frequently
train stats after 235072 examples: {'rewards_train/chosen': '0.33804', 'rewards_train/rejected': '-6.0664', 'rewards_train/margins': '6.3828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22632', 'examples_per_second': '5.2867', 'grad_norm': '4.4375', 'counters/examples': 235072, 'counters/updates': 14692}
skipping logging after 235088 examples to avoid logging too frequently
skipping logging after 235104 examples to avoid logging too frequently
skipping logging after 235120 examples to avoid logging too frequently
train stats after 235136 examples: {'rewards_train/chosen': '0.43997', 'rewards_train/rejected': '-5.7845', 'rewards_train/margins': '6.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27423', 'examples_per_second': '6.1569', 'grad_norm': '5.2188', 'counters/examples': 235136, 'counters/updates': 14696}
skipping logging after 235152 examples to avoid logging too frequently
skipping logging after 235168 examples to avoid logging too frequently
skipping logging after 235184 examples to avoid logging too frequently
train stats after 235200 examples: {'rewards_train/chosen': '0.2627', 'rewards_train/rejected': '-6.4517', 'rewards_train/margins': '6.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27374', 'examples_per_second': '4.9611', 'grad_norm': '5.5312', 'counters/examples': 235200, 'counters/updates': 14700}
skipping logging after 235216 examples to avoid logging too frequently
skipping logging after 235232 examples to avoid logging too frequently
skipping logging after 235248 examples to avoid logging too frequently
train stats after 235264 examples: {'rewards_train/chosen': '0.25812', 'rewards_train/rejected': '-5.6324', 'rewards_train/margins': '5.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26465', 'examples_per_second': '5.3287', 'grad_norm': '4.375', 'counters/examples': 235264, 'counters/updates': 14704}
skipping logging after 235280 examples to avoid logging too frequently
skipping logging after 235296 examples to avoid logging too frequently
skipping logging after 235312 examples to avoid logging too frequently
train stats after 235328 examples: {'rewards_train/chosen': '0.41166', 'rewards_train/rejected': '-6.4895', 'rewards_train/margins': '6.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23761', 'examples_per_second': '5.3495', 'grad_norm': '4.5', 'counters/examples': 235328, 'counters/updates': 14708}
skipping logging after 235344 examples to avoid logging too frequently
skipping logging after 235360 examples to avoid logging too frequently
skipping logging after 235376 examples to avoid logging too frequently
train stats after 235392 examples: {'rewards_train/chosen': '0.57748', 'rewards_train/rejected': '-5.0711', 'rewards_train/margins': '5.7266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2099', 'examples_per_second': '5.1065', 'grad_norm': '4.375', 'counters/examples': 235392, 'counters/updates': 14712}
skipping logging after 235408 examples to avoid logging too frequently
skipping logging after 235424 examples to avoid logging too frequently
skipping logging after 235440 examples to avoid logging too frequently
train stats after 235456 examples: {'rewards_train/chosen': '0.23706', 'rewards_train/rejected': '-5.8595', 'rewards_train/margins': '6.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2132', 'examples_per_second': '5.194', 'grad_norm': '5.0625', 'counters/examples': 235456, 'counters/updates': 14716}
skipping logging after 235472 examples to avoid logging too frequently
skipping logging after 235488 examples to avoid logging too frequently
skipping logging after 235504 examples to avoid logging too frequently
train stats after 235520 examples: {'rewards_train/chosen': '0.39777', 'rewards_train/rejected': '-5.437', 'rewards_train/margins': '5.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25415', 'examples_per_second': '4.7835', 'grad_norm': '5.0312', 'counters/examples': 235520, 'counters/updates': 14720}
skipping logging after 235536 examples to avoid logging too frequently
skipping logging after 235552 examples to avoid logging too frequently
skipping logging after 235568 examples to avoid logging too frequently
train stats after 235584 examples: {'rewards_train/chosen': '0.26645', 'rewards_train/rejected': '-5.5137', 'rewards_train/margins': '5.8477', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28827', 'examples_per_second': '5.6131', 'grad_norm': '6.0312', 'counters/examples': 235584, 'counters/updates': 14724}
skipping logging after 235600 examples to avoid logging too frequently
skipping logging after 235616 examples to avoid logging too frequently
skipping logging after 235632 examples to avoid logging too frequently
train stats after 235648 examples: {'rewards_train/chosen': '0.59525', 'rewards_train/rejected': '-6.2342', 'rewards_train/margins': '7.1406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18951', 'examples_per_second': '4.7696', 'grad_norm': '4', 'counters/examples': 235648, 'counters/updates': 14728}
skipping logging after 235664 examples to avoid logging too frequently
skipping logging after 235680 examples to avoid logging too frequently
skipping logging after 235696 examples to avoid logging too frequently
train stats after 235712 examples: {'rewards_train/chosen': '-0.107', 'rewards_train/rejected': '-6.395', 'rewards_train/margins': '6.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27625', 'examples_per_second': '5.0518', 'grad_norm': '5.375', 'counters/examples': 235712, 'counters/updates': 14732}
skipping logging after 235728 examples to avoid logging too frequently
skipping logging after 235744 examples to avoid logging too frequently
skipping logging after 235760 examples to avoid logging too frequently
train stats after 235776 examples: {'rewards_train/chosen': '0.50992', 'rewards_train/rejected': '-6.1813', 'rewards_train/margins': '6.0273', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27216', 'examples_per_second': '5.0672', 'grad_norm': '4.9688', 'counters/examples': 235776, 'counters/updates': 14736}
skipping logging after 235792 examples to avoid logging too frequently
skipping logging after 235808 examples to avoid logging too frequently
skipping logging after 235824 examples to avoid logging too frequently
train stats after 235840 examples: {'rewards_train/chosen': '0.40846', 'rewards_train/rejected': '-6.2363', 'rewards_train/margins': '6.5781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21753', 'examples_per_second': '5.3238', 'grad_norm': '4.8438', 'counters/examples': 235840, 'counters/updates': 14740}
skipping logging after 235856 examples to avoid logging too frequently
skipping logging after 235872 examples to avoid logging too frequently
skipping logging after 235888 examples to avoid logging too frequently
train stats after 235904 examples: {'rewards_train/chosen': '0.50869', 'rewards_train/rejected': '-6.2933', 'rewards_train/margins': '6.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22992', 'examples_per_second': '5.2029', 'grad_norm': '4.9688', 'counters/examples': 235904, 'counters/updates': 14744}
skipping logging after 235920 examples to avoid logging too frequently
skipping logging after 235936 examples to avoid logging too frequently
skipping logging after 235952 examples to avoid logging too frequently
train stats after 235968 examples: {'rewards_train/chosen': '0.0064826', 'rewards_train/rejected': '-7.6868', 'rewards_train/margins': '7.6875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30414', 'examples_per_second': '5.357', 'grad_norm': '5.25', 'counters/examples': 235968, 'counters/updates': 14748}
skipping logging after 235984 examples to avoid logging too frequently
skipping logging after 236000 examples to avoid logging too frequently
Running evaluation after 236000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:48,  1.58s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:41,  1.39s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:35,  1.24s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.47s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.68s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.49s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:10<00:34,  1.37s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:30,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.17s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.44s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.31s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.18s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.12s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.31s/it]
eval after 236000: {'rewards_eval/chosen': '-5.8208', 'rewards_eval/rejected': '-6.456', 'rewards_eval/margins': '0.46436', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.4591'}
skipping logging after 236016 examples to avoid logging too frequently
train stats after 236032 examples: {'rewards_train/chosen': '0.43596', 'rewards_train/rejected': '-6.1018', 'rewards_train/margins': '6.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20935', 'examples_per_second': '4.942', 'grad_norm': '5.8125', 'counters/examples': 236032, 'counters/updates': 14752}
skipping logging after 236048 examples to avoid logging too frequently
skipping logging after 236064 examples to avoid logging too frequently
skipping logging after 236080 examples to avoid logging too frequently
train stats after 236096 examples: {'rewards_train/chosen': '0.052405', 'rewards_train/rejected': '-5.0009', 'rewards_train/margins': '4.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25623', 'examples_per_second': '5.7847', 'grad_norm': '5.1875', 'counters/examples': 236096, 'counters/updates': 14756}
skipping logging after 236112 examples to avoid logging too frequently
skipping logging after 236128 examples to avoid logging too frequently
skipping logging after 236144 examples to avoid logging too frequently
train stats after 236160 examples: {'rewards_train/chosen': '0.59686', 'rewards_train/rejected': '-5.1472', 'rewards_train/margins': '5.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20416', 'examples_per_second': '6.2653', 'grad_norm': '4.875', 'counters/examples': 236160, 'counters/updates': 14760}
skipping logging after 236176 examples to avoid logging too frequently
skipping logging after 236192 examples to avoid logging too frequently
skipping logging after 236208 examples to avoid logging too frequently
train stats after 236224 examples: {'rewards_train/chosen': '0.10542', 'rewards_train/rejected': '-6.6767', 'rewards_train/margins': '7.0312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28363', 'examples_per_second': '5.0285', 'grad_norm': '5.9062', 'counters/examples': 236224, 'counters/updates': 14764}
skipping logging after 236240 examples to avoid logging too frequently
skipping logging after 236256 examples to avoid logging too frequently
skipping logging after 236272 examples to avoid logging too frequently
train stats after 236288 examples: {'rewards_train/chosen': '0.55711', 'rewards_train/rejected': '-6.0654', 'rewards_train/margins': '6.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2041', 'examples_per_second': '5.2332', 'grad_norm': '4.6562', 'counters/examples': 236288, 'counters/updates': 14768}
skipping logging after 236304 examples to avoid logging too frequently
skipping logging after 236320 examples to avoid logging too frequently
skipping logging after 236336 examples to avoid logging too frequently
train stats after 236352 examples: {'rewards_train/chosen': '0.27255', 'rewards_train/rejected': '-5.959', 'rewards_train/margins': '5.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21851', 'examples_per_second': '6.2086', 'grad_norm': '4.4375', 'counters/examples': 236352, 'counters/updates': 14772}
skipping logging after 236368 examples to avoid logging too frequently
skipping logging after 236384 examples to avoid logging too frequently
skipping logging after 236400 examples to avoid logging too frequently
train stats after 236416 examples: {'rewards_train/chosen': '0.41254', 'rewards_train/rejected': '-6.0293', 'rewards_train/margins': '6.5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22375', 'examples_per_second': '3.9374', 'grad_norm': '4.7188', 'counters/examples': 236416, 'counters/updates': 14776}
skipping logging after 236432 examples to avoid logging too frequently
skipping logging after 236448 examples to avoid logging too frequently
skipping logging after 236464 examples to avoid logging too frequently
train stats after 236480 examples: {'rewards_train/chosen': '0.38122', 'rewards_train/rejected': '-7.3074', 'rewards_train/margins': '7.7031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20795', 'examples_per_second': '6.4435', 'grad_norm': '4.6562', 'counters/examples': 236480, 'counters/updates': 14780}
skipping logging after 236496 examples to avoid logging too frequently
skipping logging after 236512 examples to avoid logging too frequently
skipping logging after 236528 examples to avoid logging too frequently
train stats after 236544 examples: {'rewards_train/chosen': '0.20427', 'rewards_train/rejected': '-5.2456', 'rewards_train/margins': '5.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25604', 'examples_per_second': '4.3806', 'grad_norm': '7.0312', 'counters/examples': 236544, 'counters/updates': 14784}
skipping logging after 236560 examples to avoid logging too frequently
skipping logging after 236576 examples to avoid logging too frequently
skipping logging after 236592 examples to avoid logging too frequently
train stats after 236608 examples: {'rewards_train/chosen': '0.2005', 'rewards_train/rejected': '-6.2386', 'rewards_train/margins': '6.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24335', 'examples_per_second': '5.0158', 'grad_norm': '4.8125', 'counters/examples': 236608, 'counters/updates': 14788}
skipping logging after 236624 examples to avoid logging too frequently
skipping logging after 236640 examples to avoid logging too frequently
skipping logging after 236656 examples to avoid logging too frequently
train stats after 236672 examples: {'rewards_train/chosen': '0.20493', 'rewards_train/rejected': '-5.35', 'rewards_train/margins': '5.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23779', 'examples_per_second': '5.7966', 'grad_norm': '5.0938', 'counters/examples': 236672, 'counters/updates': 14792}
skipping logging after 236688 examples to avoid logging too frequently
skipping logging after 236704 examples to avoid logging too frequently
skipping logging after 236720 examples to avoid logging too frequently
train stats after 236736 examples: {'rewards_train/chosen': '0.36717', 'rewards_train/rejected': '-6.3085', 'rewards_train/margins': '6.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23413', 'examples_per_second': '4.4927', 'grad_norm': '4.2812', 'counters/examples': 236736, 'counters/updates': 14796}
skipping logging after 236752 examples to avoid logging too frequently
skipping logging after 236768 examples to avoid logging too frequently
skipping logging after 236784 examples to avoid logging too frequently
train stats after 236800 examples: {'rewards_train/chosen': '0.46375', 'rewards_train/rejected': '-6.308', 'rewards_train/margins': '6.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22894', 'examples_per_second': '5.6289', 'grad_norm': '4.5938', 'counters/examples': 236800, 'counters/updates': 14800}
skipping logging after 236816 examples to avoid logging too frequently
skipping logging after 236832 examples to avoid logging too frequently
skipping logging after 236848 examples to avoid logging too frequently
train stats after 236864 examples: {'rewards_train/chosen': '0.48634', 'rewards_train/rejected': '-5.1626', 'rewards_train/margins': '5.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23853', 'examples_per_second': '5.9669', 'grad_norm': '5.625', 'counters/examples': 236864, 'counters/updates': 14804}
skipping logging after 236880 examples to avoid logging too frequently
skipping logging after 236896 examples to avoid logging too frequently
skipping logging after 236912 examples to avoid logging too frequently
train stats after 236928 examples: {'rewards_train/chosen': '0.20109', 'rewards_train/rejected': '-4.657', 'rewards_train/margins': '4.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.302', 'examples_per_second': '5.3947', 'grad_norm': '6.5625', 'counters/examples': 236928, 'counters/updates': 14808}
skipping logging after 236944 examples to avoid logging too frequently
skipping logging after 236960 examples to avoid logging too frequently
skipping logging after 236976 examples to avoid logging too frequently
train stats after 236992 examples: {'rewards_train/chosen': '0.3061', 'rewards_train/rejected': '-5.7666', 'rewards_train/margins': '5.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25916', 'examples_per_second': '4.7126', 'grad_norm': '5.0938', 'counters/examples': 236992, 'counters/updates': 14812}
skipping logging after 237008 examples to avoid logging too frequently
skipping logging after 237024 examples to avoid logging too frequently
skipping logging after 237040 examples to avoid logging too frequently
train stats after 237056 examples: {'rewards_train/chosen': '0.20829', 'rewards_train/rejected': '-5.5869', 'rewards_train/margins': '5.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28406', 'examples_per_second': '5.6398', 'grad_norm': '4.25', 'counters/examples': 237056, 'counters/updates': 14816}
skipping logging after 237072 examples to avoid logging too frequently
skipping logging after 237088 examples to avoid logging too frequently
skipping logging after 237104 examples to avoid logging too frequently
train stats after 237120 examples: {'rewards_train/chosen': '0.36844', 'rewards_train/rejected': '-6.0668', 'rewards_train/margins': '6.1953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23828', 'examples_per_second': '4.3205', 'grad_norm': '5.25', 'counters/examples': 237120, 'counters/updates': 14820}
skipping logging after 237136 examples to avoid logging too frequently
skipping logging after 237152 examples to avoid logging too frequently
skipping logging after 237168 examples to avoid logging too frequently
train stats after 237184 examples: {'rewards_train/chosen': '0.34866', 'rewards_train/rejected': '-6.3373', 'rewards_train/margins': '6.6562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23322', 'examples_per_second': '5.7199', 'grad_norm': '5.1875', 'counters/examples': 237184, 'counters/updates': 14824}
skipping logging after 237200 examples to avoid logging too frequently
skipping logging after 237216 examples to avoid logging too frequently
skipping logging after 237232 examples to avoid logging too frequently
train stats after 237248 examples: {'rewards_train/chosen': '0.25444', 'rewards_train/rejected': '-6.4149', 'rewards_train/margins': '6.7266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22961', 'examples_per_second': '5.1402', 'grad_norm': '4.4062', 'counters/examples': 237248, 'counters/updates': 14828}
skipping logging after 237264 examples to avoid logging too frequently
skipping logging after 237280 examples to avoid logging too frequently
skipping logging after 237296 examples to avoid logging too frequently
train stats after 237312 examples: {'rewards_train/chosen': '0.60583', 'rewards_train/rejected': '-7.0917', 'rewards_train/margins': '7.5391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25537', 'examples_per_second': '4.692', 'grad_norm': '5.4062', 'counters/examples': 237312, 'counters/updates': 14832}
skipping logging after 237328 examples to avoid logging too frequently
skipping logging after 237344 examples to avoid logging too frequently
skipping logging after 237360 examples to avoid logging too frequently
train stats after 237376 examples: {'rewards_train/chosen': '-0.0013445', 'rewards_train/rejected': '-5.8675', 'rewards_train/margins': '5.7539', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2738', 'examples_per_second': '4.9003', 'grad_norm': '5.0625', 'counters/examples': 237376, 'counters/updates': 14836}
skipping logging after 237392 examples to avoid logging too frequently
skipping logging after 237408 examples to avoid logging too frequently
skipping logging after 237424 examples to avoid logging too frequently
train stats after 237440 examples: {'rewards_train/chosen': '0.17532', 'rewards_train/rejected': '-6.3683', 'rewards_train/margins': '6.4219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2569', 'examples_per_second': '4.9509', 'grad_norm': '5.6562', 'counters/examples': 237440, 'counters/updates': 14840}
skipping logging after 237456 examples to avoid logging too frequently
skipping logging after 237472 examples to avoid logging too frequently
skipping logging after 237488 examples to avoid logging too frequently
train stats after 237504 examples: {'rewards_train/chosen': '0.34894', 'rewards_train/rejected': '-6.3275', 'rewards_train/margins': '6.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27423', 'examples_per_second': '5.0342', 'grad_norm': '5.2812', 'counters/examples': 237504, 'counters/updates': 14844}
skipping logging after 237520 examples to avoid logging too frequently
skipping logging after 237536 examples to avoid logging too frequently
skipping logging after 237552 examples to avoid logging too frequently
train stats after 237568 examples: {'rewards_train/chosen': '0.30199', 'rewards_train/rejected': '-5.1623', 'rewards_train/margins': '5.4219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26233', 'examples_per_second': '3.8131', 'grad_norm': '4.6562', 'counters/examples': 237568, 'counters/updates': 14848}
skipping logging after 237584 examples to avoid logging too frequently
skipping logging after 237600 examples to avoid logging too frequently
skipping logging after 237616 examples to avoid logging too frequently
train stats after 237632 examples: {'rewards_train/chosen': '0.57833', 'rewards_train/rejected': '-6.2408', 'rewards_train/margins': '6.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21979', 'examples_per_second': '4.9178', 'grad_norm': '5.0625', 'counters/examples': 237632, 'counters/updates': 14852}
skipping logging after 237648 examples to avoid logging too frequently
skipping logging after 237664 examples to avoid logging too frequently
skipping logging after 237680 examples to avoid logging too frequently
train stats after 237696 examples: {'rewards_train/chosen': '0.11108', 'rewards_train/rejected': '-6.1575', 'rewards_train/margins': '6.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.31708', 'examples_per_second': '4.9696', 'grad_norm': '6.1875', 'counters/examples': 237696, 'counters/updates': 14856}
skipping logging after 237712 examples to avoid logging too frequently
skipping logging after 237728 examples to avoid logging too frequently
skipping logging after 237744 examples to avoid logging too frequently
train stats after 237760 examples: {'rewards_train/chosen': '0.16641', 'rewards_train/rejected': '-7.5909', 'rewards_train/margins': '8.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24237', 'examples_per_second': '4.4189', 'grad_norm': '5', 'counters/examples': 237760, 'counters/updates': 14860}
skipping logging after 237776 examples to avoid logging too frequently
skipping logging after 237792 examples to avoid logging too frequently
skipping logging after 237808 examples to avoid logging too frequently
train stats after 237824 examples: {'rewards_train/chosen': '0.34057', 'rewards_train/rejected': '-5.9014', 'rewards_train/margins': '6.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23334', 'examples_per_second': '4.7484', 'grad_norm': '4.6875', 'counters/examples': 237824, 'counters/updates': 14864}
skipping logging after 237840 examples to avoid logging too frequently
skipping logging after 237856 examples to avoid logging too frequently
skipping logging after 237872 examples to avoid logging too frequently
train stats after 237888 examples: {'rewards_train/chosen': '0.42254', 'rewards_train/rejected': '-6.3796', 'rewards_train/margins': '6.8828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24622', 'examples_per_second': '4.7857', 'grad_norm': '5', 'counters/examples': 237888, 'counters/updates': 14868}
skipping logging after 237904 examples to avoid logging too frequently
skipping logging after 237920 examples to avoid logging too frequently
skipping logging after 237936 examples to avoid logging too frequently
train stats after 237952 examples: {'rewards_train/chosen': '0.43108', 'rewards_train/rejected': '-7.7705', 'rewards_train/margins': '8.2969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19543', 'examples_per_second': '5.3199', 'grad_norm': '5.375', 'counters/examples': 237952, 'counters/updates': 14872}
skipping logging after 237968 examples to avoid logging too frequently
skipping logging after 237984 examples to avoid logging too frequently
skipping logging after 238000 examples to avoid logging too frequently
train stats after 238016 examples: {'rewards_train/chosen': '0.11264', 'rewards_train/rejected': '-6.0611', 'rewards_train/margins': '6.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22534', 'examples_per_second': '4.9943', 'grad_norm': '4.6875', 'counters/examples': 238016, 'counters/updates': 14876}
skipping logging after 238032 examples to avoid logging too frequently
skipping logging after 238048 examples to avoid logging too frequently
skipping logging after 238064 examples to avoid logging too frequently
train stats after 238080 examples: {'rewards_train/chosen': '0.27395', 'rewards_train/rejected': '-6.2', 'rewards_train/margins': '6.5195', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25916', 'examples_per_second': '6.2517', 'grad_norm': '5.3125', 'counters/examples': 238080, 'counters/updates': 14880}
skipping logging after 238096 examples to avoid logging too frequently
skipping logging after 238112 examples to avoid logging too frequently
skipping logging after 238128 examples to avoid logging too frequently
train stats after 238144 examples: {'rewards_train/chosen': '0.33213', 'rewards_train/rejected': '-7.6941', 'rewards_train/margins': '8.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27466', 'examples_per_second': '5.9632', 'grad_norm': '5.8438', 'counters/examples': 238144, 'counters/updates': 14884}
skipping logging after 238160 examples to avoid logging too frequently
skipping logging after 238176 examples to avoid logging too frequently
skipping logging after 238192 examples to avoid logging too frequently
train stats after 238208 examples: {'rewards_train/chosen': '0.14446', 'rewards_train/rejected': '-6.5425', 'rewards_train/margins': '6.6641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22693', 'examples_per_second': '5.5416', 'grad_norm': '4.2188', 'counters/examples': 238208, 'counters/updates': 14888}
skipping logging after 238224 examples to avoid logging too frequently
skipping logging after 238240 examples to avoid logging too frequently
skipping logging after 238256 examples to avoid logging too frequently
train stats after 238272 examples: {'rewards_train/chosen': '0.15575', 'rewards_train/rejected': '-6.3923', 'rewards_train/margins': '6.3203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23053', 'examples_per_second': '6.5559', 'grad_norm': '4.5625', 'counters/examples': 238272, 'counters/updates': 14892}
skipping logging after 238288 examples to avoid logging too frequently
skipping logging after 238304 examples to avoid logging too frequently
skipping logging after 238320 examples to avoid logging too frequently
train stats after 238336 examples: {'rewards_train/chosen': '0.37219', 'rewards_train/rejected': '-6.8211', 'rewards_train/margins': '7.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23126', 'examples_per_second': '4.7324', 'grad_norm': '4.5', 'counters/examples': 238336, 'counters/updates': 14896}
skipping logging after 238352 examples to avoid logging too frequently
skipping logging after 238368 examples to avoid logging too frequently
skipping logging after 238384 examples to avoid logging too frequently
train stats after 238400 examples: {'rewards_train/chosen': '-0.078857', 'rewards_train/rejected': '-6.2545', 'rewards_train/margins': '6.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24042', 'examples_per_second': '4.5572', 'grad_norm': '4.1875', 'counters/examples': 238400, 'counters/updates': 14900}
skipping logging after 238416 examples to avoid logging too frequently
skipping logging after 238432 examples to avoid logging too frequently
skipping logging after 238448 examples to avoid logging too frequently
train stats after 238464 examples: {'rewards_train/chosen': '0.55079', 'rewards_train/rejected': '-5.5542', 'rewards_train/margins': '6.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25488', 'examples_per_second': '4.1607', 'grad_norm': '6.5938', 'counters/examples': 238464, 'counters/updates': 14904}
skipping logging after 238480 examples to avoid logging too frequently
skipping logging after 238496 examples to avoid logging too frequently
skipping logging after 238512 examples to avoid logging too frequently
train stats after 238528 examples: {'rewards_train/chosen': '0.41297', 'rewards_train/rejected': '-5.8123', 'rewards_train/margins': '6.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19403', 'examples_per_second': '5.2818', 'grad_norm': '5.5', 'counters/examples': 238528, 'counters/updates': 14908}
skipping logging after 238544 examples to avoid logging too frequently
skipping logging after 238560 examples to avoid logging too frequently
skipping logging after 238576 examples to avoid logging too frequently
train stats after 238592 examples: {'rewards_train/chosen': '0.40901', 'rewards_train/rejected': '-6.1821', 'rewards_train/margins': '6.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26257', 'examples_per_second': '5.3659', 'grad_norm': '5.3125', 'counters/examples': 238592, 'counters/updates': 14912}
skipping logging after 238608 examples to avoid logging too frequently
skipping logging after 238624 examples to avoid logging too frequently
skipping logging after 238640 examples to avoid logging too frequently
train stats after 238656 examples: {'rewards_train/chosen': '0.48166', 'rewards_train/rejected': '-5.6679', 'rewards_train/margins': '6.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21637', 'examples_per_second': '4.9579', 'grad_norm': '4.3125', 'counters/examples': 238656, 'counters/updates': 14916}
skipping logging after 238672 examples to avoid logging too frequently
skipping logging after 238688 examples to avoid logging too frequently
skipping logging after 238704 examples to avoid logging too frequently
train stats after 238720 examples: {'rewards_train/chosen': '0.64154', 'rewards_train/rejected': '-6.3918', 'rewards_train/margins': '6.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19757', 'examples_per_second': '5.9974', 'grad_norm': '4.3438', 'counters/examples': 238720, 'counters/updates': 14920}
skipping logging after 238736 examples to avoid logging too frequently
skipping logging after 238752 examples to avoid logging too frequently
skipping logging after 238768 examples to avoid logging too frequently
train stats after 238784 examples: {'rewards_train/chosen': '0.49775', 'rewards_train/rejected': '-5.0496', 'rewards_train/margins': '5.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24695', 'examples_per_second': '5.1636', 'grad_norm': '5.75', 'counters/examples': 238784, 'counters/updates': 14924}
skipping logging after 238800 examples to avoid logging too frequently
skipping logging after 238816 examples to avoid logging too frequently
skipping logging after 238832 examples to avoid logging too frequently
train stats after 238848 examples: {'rewards_train/chosen': '0.37783', 'rewards_train/rejected': '-6.6105', 'rewards_train/margins': '6.6562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21741', 'examples_per_second': '5.5484', 'grad_norm': '5.1562', 'counters/examples': 238848, 'counters/updates': 14928}
skipping logging after 238864 examples to avoid logging too frequently
skipping logging after 238880 examples to avoid logging too frequently
skipping logging after 238896 examples to avoid logging too frequently
train stats after 238912 examples: {'rewards_train/chosen': '0.40649', 'rewards_train/rejected': '-6.3157', 'rewards_train/margins': '6.5391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23102', 'examples_per_second': '5.399', 'grad_norm': '4.5938', 'counters/examples': 238912, 'counters/updates': 14932}
skipping logging after 238928 examples to avoid logging too frequently
skipping logging after 238944 examples to avoid logging too frequently
skipping logging after 238960 examples to avoid logging too frequently
train stats after 238976 examples: {'rewards_train/chosen': '0.37671', 'rewards_train/rejected': '-7.1176', 'rewards_train/margins': '7.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20239', 'examples_per_second': '4.9693', 'grad_norm': '5.3438', 'counters/examples': 238976, 'counters/updates': 14936}
skipping logging after 238992 examples to avoid logging too frequently
skipping logging after 239008 examples to avoid logging too frequently
skipping logging after 239024 examples to avoid logging too frequently
train stats after 239040 examples: {'rewards_train/chosen': '0.15776', 'rewards_train/rejected': '-6.3615', 'rewards_train/margins': '6.6211', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20337', 'examples_per_second': '5.8596', 'grad_norm': '4.6562', 'counters/examples': 239040, 'counters/updates': 14940}
skipping logging after 239056 examples to avoid logging too frequently
skipping logging after 239072 examples to avoid logging too frequently
skipping logging after 239088 examples to avoid logging too frequently
train stats after 239104 examples: {'rewards_train/chosen': '0.19889', 'rewards_train/rejected': '-6.1587', 'rewards_train/margins': '6.3203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22955', 'examples_per_second': '5.4437', 'grad_norm': '5.2812', 'counters/examples': 239104, 'counters/updates': 14944}
skipping logging after 239120 examples to avoid logging too frequently
skipping logging after 239136 examples to avoid logging too frequently
skipping logging after 239152 examples to avoid logging too frequently
train stats after 239168 examples: {'rewards_train/chosen': '-0.1576', 'rewards_train/rejected': '-6.0491', 'rewards_train/margins': '5.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22723', 'examples_per_second': '5.6379', 'grad_norm': '5.375', 'counters/examples': 239168, 'counters/updates': 14948}
skipping logging after 239184 examples to avoid logging too frequently
skipping logging after 239200 examples to avoid logging too frequently
skipping logging after 239216 examples to avoid logging too frequently
train stats after 239232 examples: {'rewards_train/chosen': '0.33123', 'rewards_train/rejected': '-6.1726', 'rewards_train/margins': '6.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27466', 'examples_per_second': '4.757', 'grad_norm': '5.375', 'counters/examples': 239232, 'counters/updates': 14952}
skipping logging after 239248 examples to avoid logging too frequently
skipping logging after 239264 examples to avoid logging too frequently
skipping logging after 239280 examples to avoid logging too frequently
train stats after 239296 examples: {'rewards_train/chosen': '0.21068', 'rewards_train/rejected': '-6.7913', 'rewards_train/margins': '6.3672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23523', 'examples_per_second': '5.3667', 'grad_norm': '4.2188', 'counters/examples': 239296, 'counters/updates': 14956}
skipping logging after 239312 examples to avoid logging too frequently
skipping logging after 239328 examples to avoid logging too frequently
skipping logging after 239344 examples to avoid logging too frequently
train stats after 239360 examples: {'rewards_train/chosen': '0.43483', 'rewards_train/rejected': '-5.7626', 'rewards_train/margins': '6.3672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22955', 'examples_per_second': '4.5833', 'grad_norm': '5.3125', 'counters/examples': 239360, 'counters/updates': 14960}
skipping logging after 239376 examples to avoid logging too frequently
skipping logging after 239392 examples to avoid logging too frequently
skipping logging after 239408 examples to avoid logging too frequently
train stats after 239424 examples: {'rewards_train/chosen': '0.5047', 'rewards_train/rejected': '-5.5234', 'rewards_train/margins': '6.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24194', 'examples_per_second': '4.8958', 'grad_norm': '5.2812', 'counters/examples': 239424, 'counters/updates': 14964}
skipping logging after 239440 examples to avoid logging too frequently
skipping logging after 239456 examples to avoid logging too frequently
skipping logging after 239472 examples to avoid logging too frequently
train stats after 239488 examples: {'rewards_train/chosen': '0.3917', 'rewards_train/rejected': '-6.1091', 'rewards_train/margins': '6.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23059', 'examples_per_second': '4.2473', 'grad_norm': '5.5625', 'counters/examples': 239488, 'counters/updates': 14968}
skipping logging after 239504 examples to avoid logging too frequently
skipping logging after 239520 examples to avoid logging too frequently
skipping logging after 239536 examples to avoid logging too frequently
train stats after 239552 examples: {'rewards_train/chosen': '0.69855', 'rewards_train/rejected': '-5.4642', 'rewards_train/margins': '6.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17078', 'examples_per_second': '5.7786', 'grad_norm': '4.3125', 'counters/examples': 239552, 'counters/updates': 14972}
skipping logging after 239568 examples to avoid logging too frequently
skipping logging after 239584 examples to avoid logging too frequently
skipping logging after 239600 examples to avoid logging too frequently
train stats after 239616 examples: {'rewards_train/chosen': '0.057904', 'rewards_train/rejected': '-8.2024', 'rewards_train/margins': '8.1172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24286', 'examples_per_second': '5.7662', 'grad_norm': '5.1562', 'counters/examples': 239616, 'counters/updates': 14976}
skipping logging after 239632 examples to avoid logging too frequently
skipping logging after 239648 examples to avoid logging too frequently
skipping logging after 239664 examples to avoid logging too frequently
train stats after 239680 examples: {'rewards_train/chosen': '-0.085846', 'rewards_train/rejected': '-8.0631', 'rewards_train/margins': '7.9297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23877', 'examples_per_second': '4.6382', 'grad_norm': '4.5', 'counters/examples': 239680, 'counters/updates': 14980}
skipping logging after 239696 examples to avoid logging too frequently
skipping logging after 239712 examples to avoid logging too frequently
skipping logging after 239728 examples to avoid logging too frequently
train stats after 239744 examples: {'rewards_train/chosen': '0.28618', 'rewards_train/rejected': '-5.4556', 'rewards_train/margins': '5.8906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29517', 'examples_per_second': '5.5824', 'grad_norm': '6.25', 'counters/examples': 239744, 'counters/updates': 14984}
skipping logging after 239760 examples to avoid logging too frequently
skipping logging after 239776 examples to avoid logging too frequently
skipping logging after 239792 examples to avoid logging too frequently
train stats after 239808 examples: {'rewards_train/chosen': '0.31034', 'rewards_train/rejected': '-6.1541', 'rewards_train/margins': '6.3828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20721', 'examples_per_second': '5.1895', 'grad_norm': '4.0312', 'counters/examples': 239808, 'counters/updates': 14988}
skipping logging after 239824 examples to avoid logging too frequently
skipping logging after 239840 examples to avoid logging too frequently
skipping logging after 239856 examples to avoid logging too frequently
train stats after 239872 examples: {'rewards_train/chosen': '0.39488', 'rewards_train/rejected': '-6.8568', 'rewards_train/margins': '7.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20044', 'examples_per_second': '4.8662', 'grad_norm': '4.6875', 'counters/examples': 239872, 'counters/updates': 14992}
skipping logging after 239888 examples to avoid logging too frequently
skipping logging after 239904 examples to avoid logging too frequently
skipping logging after 239920 examples to avoid logging too frequently
train stats after 239936 examples: {'rewards_train/chosen': '0.1576', 'rewards_train/rejected': '-6.146', 'rewards_train/margins': '6.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20856', 'examples_per_second': '4.5817', 'grad_norm': '5.0938', 'counters/examples': 239936, 'counters/updates': 14996}
skipping logging after 239952 examples to avoid logging too frequently
skipping logging after 239968 examples to avoid logging too frequently
skipping logging after 239984 examples to avoid logging too frequently
train stats after 240000 examples: {'rewards_train/chosen': '0.0021776', 'rewards_train/rejected': '-6.1396', 'rewards_train/margins': '6.3086', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23285', 'examples_per_second': '5.2408', 'grad_norm': '5.2812', 'counters/examples': 240000, 'counters/updates': 15000}
Running evaluation after 240000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.26s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.17s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:39,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.65s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.47s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:33,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.51s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:33,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.40s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:30,  1.47s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:21<00:20,  1.28s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]
eval after 240000: {'rewards_eval/chosen': '-6.1949', 'rewards_eval/rejected': '-6.8979', 'rewards_eval/margins': '0.52344', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.45793'}
skipping logging after 240016 examples to avoid logging too frequently
skipping logging after 240032 examples to avoid logging too frequently
skipping logging after 240048 examples to avoid logging too frequently
train stats after 240064 examples: {'rewards_train/chosen': '0.59389', 'rewards_train/rejected': '-6.186', 'rewards_train/margins': '6.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20874', 'examples_per_second': '5.3751', 'grad_norm': '5.2188', 'counters/examples': 240064, 'counters/updates': 15004}
skipping logging after 240080 examples to avoid logging too frequently
skipping logging after 240096 examples to avoid logging too frequently
skipping logging after 240112 examples to avoid logging too frequently
train stats after 240128 examples: {'rewards_train/chosen': '-0.11549', 'rewards_train/rejected': '-7.8843', 'rewards_train/margins': '7.9297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25909', 'examples_per_second': '4.3988', 'grad_norm': '5.6875', 'counters/examples': 240128, 'counters/updates': 15008}
skipping logging after 240144 examples to avoid logging too frequently
skipping logging after 240160 examples to avoid logging too frequently
skipping logging after 240176 examples to avoid logging too frequently
train stats after 240192 examples: {'rewards_train/chosen': '0.47463', 'rewards_train/rejected': '-8.0547', 'rewards_train/margins': '8.5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22913', 'examples_per_second': '5.465', 'grad_norm': '5.4688', 'counters/examples': 240192, 'counters/updates': 15012}
skipping logging after 240208 examples to avoid logging too frequently
skipping logging after 240224 examples to avoid logging too frequently
skipping logging after 240240 examples to avoid logging too frequently
train stats after 240256 examples: {'rewards_train/chosen': '0.63885', 'rewards_train/rejected': '-6.552', 'rewards_train/margins': '6.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20471', 'examples_per_second': '5.4833', 'grad_norm': '4.6562', 'counters/examples': 240256, 'counters/updates': 15016}
skipping logging after 240272 examples to avoid logging too frequently
skipping logging after 240288 examples to avoid logging too frequently
skipping logging after 240304 examples to avoid logging too frequently
train stats after 240320 examples: {'rewards_train/chosen': '0.30886', 'rewards_train/rejected': '-6.1324', 'rewards_train/margins': '6.4219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22717', 'examples_per_second': '4.5742', 'grad_norm': '5.4375', 'counters/examples': 240320, 'counters/updates': 15020}
skipping logging after 240336 examples to avoid logging too frequently
skipping logging after 240352 examples to avoid logging too frequently
skipping logging after 240368 examples to avoid logging too frequently
train stats after 240384 examples: {'rewards_train/chosen': '0.36328', 'rewards_train/rejected': '-5.4804', 'rewards_train/margins': '6.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23981', 'examples_per_second': '5.2582', 'grad_norm': '5.0625', 'counters/examples': 240384, 'counters/updates': 15024}
skipping logging after 240400 examples to avoid logging too frequently
skipping logging after 240416 examples to avoid logging too frequently
skipping logging after 240432 examples to avoid logging too frequently
train stats after 240448 examples: {'rewards_train/chosen': '0.2096', 'rewards_train/rejected': '-5.7246', 'rewards_train/margins': '5.9375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28479', 'examples_per_second': '5.0386', 'grad_norm': '5', 'counters/examples': 240448, 'counters/updates': 15028}
skipping logging after 240464 examples to avoid logging too frequently
skipping logging after 240480 examples to avoid logging too frequently
skipping logging after 240496 examples to avoid logging too frequently
train stats after 240512 examples: {'rewards_train/chosen': '-0.074879', 'rewards_train/rejected': '-5.7766', 'rewards_train/margins': '5.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23932', 'examples_per_second': '5.4482', 'grad_norm': '4.2812', 'counters/examples': 240512, 'counters/updates': 15032}
skipping logging after 240528 examples to avoid logging too frequently
skipping logging after 240544 examples to avoid logging too frequently
skipping logging after 240560 examples to avoid logging too frequently
train stats after 240576 examples: {'rewards_train/chosen': '0.43901', 'rewards_train/rejected': '-6.4851', 'rewards_train/margins': '7.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25397', 'examples_per_second': '6.2411', 'grad_norm': '4.5', 'counters/examples': 240576, 'counters/updates': 15036}
skipping logging after 240592 examples to avoid logging too frequently
skipping logging after 240608 examples to avoid logging too frequently
skipping logging after 240624 examples to avoid logging too frequently
train stats after 240640 examples: {'rewards_train/chosen': '0.35403', 'rewards_train/rejected': '-5.799', 'rewards_train/margins': '6.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25031', 'examples_per_second': '5.1446', 'grad_norm': '4.9062', 'counters/examples': 240640, 'counters/updates': 15040}
skipping logging after 240656 examples to avoid logging too frequently
skipping logging after 240672 examples to avoid logging too frequently
skipping logging after 240688 examples to avoid logging too frequently
train stats after 240704 examples: {'rewards_train/chosen': '0.18575', 'rewards_train/rejected': '-6.4811', 'rewards_train/margins': '6.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27643', 'examples_per_second': '4.6912', 'grad_norm': '4.4375', 'counters/examples': 240704, 'counters/updates': 15044}
skipping logging after 240720 examples to avoid logging too frequently
skipping logging after 240736 examples to avoid logging too frequently
skipping logging after 240752 examples to avoid logging too frequently
train stats after 240768 examples: {'rewards_train/chosen': '0.3623', 'rewards_train/rejected': '-6.8592', 'rewards_train/margins': '7.7578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19031', 'examples_per_second': '5.6545', 'grad_norm': '4.1875', 'counters/examples': 240768, 'counters/updates': 15048}
skipping logging after 240784 examples to avoid logging too frequently
skipping logging after 240800 examples to avoid logging too frequently
skipping logging after 240816 examples to avoid logging too frequently
train stats after 240832 examples: {'rewards_train/chosen': '0.24511', 'rewards_train/rejected': '-6.3277', 'rewards_train/margins': '6.3281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25', 'examples_per_second': '4.2572', 'grad_norm': '4.5625', 'counters/examples': 240832, 'counters/updates': 15052}
skipping logging after 240848 examples to avoid logging too frequently
skipping logging after 240864 examples to avoid logging too frequently
skipping logging after 240880 examples to avoid logging too frequently
train stats after 240896 examples: {'rewards_train/chosen': '-0.19575', 'rewards_train/rejected': '-6.8045', 'rewards_train/margins': '6.6094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24097', 'examples_per_second': '4.1262', 'grad_norm': '4.75', 'counters/examples': 240896, 'counters/updates': 15056}
skipping logging after 240912 examples to avoid logging too frequently
skipping logging after 240928 examples to avoid logging too frequently
skipping logging after 240944 examples to avoid logging too frequently
train stats after 240960 examples: {'rewards_train/chosen': '0.62793', 'rewards_train/rejected': '-5.8528', 'rewards_train/margins': '6.8672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17389', 'examples_per_second': '4.4918', 'grad_norm': '4.375', 'counters/examples': 240960, 'counters/updates': 15060}
skipping logging after 240976 examples to avoid logging too frequently
skipping logging after 240992 examples to avoid logging too frequently
skipping logging after 241008 examples to avoid logging too frequently
train stats after 241024 examples: {'rewards_train/chosen': '0.26451', 'rewards_train/rejected': '-6.1525', 'rewards_train/margins': '6.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24603', 'examples_per_second': '4.0014', 'grad_norm': '5.8438', 'counters/examples': 241024, 'counters/updates': 15064}
skipping logging after 241040 examples to avoid logging too frequently
skipping logging after 241056 examples to avoid logging too frequently
skipping logging after 241072 examples to avoid logging too frequently
train stats after 241088 examples: {'rewards_train/chosen': '0.4284', 'rewards_train/rejected': '-5.7167', 'rewards_train/margins': '6.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23035', 'examples_per_second': '5.5098', 'grad_norm': '4.7812', 'counters/examples': 241088, 'counters/updates': 15068}
skipping logging after 241104 examples to avoid logging too frequently
skipping logging after 241120 examples to avoid logging too frequently
skipping logging after 241136 examples to avoid logging too frequently
train stats after 241152 examples: {'rewards_train/chosen': '0.40672', 'rewards_train/rejected': '-6.3996', 'rewards_train/margins': '6.4219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27063', 'examples_per_second': '4.3229', 'grad_norm': '5.1562', 'counters/examples': 241152, 'counters/updates': 15072}
skipping logging after 241168 examples to avoid logging too frequently
skipping logging after 241184 examples to avoid logging too frequently
skipping logging after 241200 examples to avoid logging too frequently
train stats after 241216 examples: {'rewards_train/chosen': '0.42288', 'rewards_train/rejected': '-5.8393', 'rewards_train/margins': '6.1953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24225', 'examples_per_second': '5.3407', 'grad_norm': '5.7188', 'counters/examples': 241216, 'counters/updates': 15076}
skipping logging after 241232 examples to avoid logging too frequently
skipping logging after 241248 examples to avoid logging too frequently
skipping logging after 241264 examples to avoid logging too frequently
train stats after 241280 examples: {'rewards_train/chosen': '-0.025305', 'rewards_train/rejected': '-6.3348', 'rewards_train/margins': '6.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.31018', 'examples_per_second': '5.7687', 'grad_norm': '5.7188', 'counters/examples': 241280, 'counters/updates': 15080}
skipping logging after 241296 examples to avoid logging too frequently
skipping logging after 241312 examples to avoid logging too frequently
skipping logging after 241328 examples to avoid logging too frequently
train stats after 241344 examples: {'rewards_train/chosen': '0.73356', 'rewards_train/rejected': '-4.97', 'rewards_train/margins': '5.7109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20587', 'examples_per_second': '5.5112', 'grad_norm': '4.5312', 'counters/examples': 241344, 'counters/updates': 15084}
skipping logging after 241360 examples to avoid logging too frequently
skipping logging after 241376 examples to avoid logging too frequently
skipping logging after 241392 examples to avoid logging too frequently
train stats after 241408 examples: {'rewards_train/chosen': '-0.08327', 'rewards_train/rejected': '-6.3045', 'rewards_train/margins': '6.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23535', 'examples_per_second': '5.0456', 'grad_norm': '4.9375', 'counters/examples': 241408, 'counters/updates': 15088}
skipping logging after 241424 examples to avoid logging too frequently
skipping logging after 241440 examples to avoid logging too frequently
skipping logging after 241456 examples to avoid logging too frequently
train stats after 241472 examples: {'rewards_train/chosen': '0.36907', 'rewards_train/rejected': '-4.9498', 'rewards_train/margins': '5.3828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2373', 'examples_per_second': '5.4033', 'grad_norm': '4.7812', 'counters/examples': 241472, 'counters/updates': 15092}
skipping logging after 241488 examples to avoid logging too frequently
skipping logging after 241504 examples to avoid logging too frequently
skipping logging after 241520 examples to avoid logging too frequently
train stats after 241536 examples: {'rewards_train/chosen': '0.43306', 'rewards_train/rejected': '-6.4253', 'rewards_train/margins': '6.9297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20923', 'examples_per_second': '5.5399', 'grad_norm': '4.6875', 'counters/examples': 241536, 'counters/updates': 15096}
skipping logging after 241552 examples to avoid logging too frequently
skipping logging after 241568 examples to avoid logging too frequently
skipping logging after 241584 examples to avoid logging too frequently
train stats after 241600 examples: {'rewards_train/chosen': '0.46392', 'rewards_train/rejected': '-6.4', 'rewards_train/margins': '6.8125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25415', 'examples_per_second': '4.6675', 'grad_norm': '5.3438', 'counters/examples': 241600, 'counters/updates': 15100}
skipping logging after 241616 examples to avoid logging too frequently
skipping logging after 241632 examples to avoid logging too frequently
skipping logging after 241648 examples to avoid logging too frequently
train stats after 241664 examples: {'rewards_train/chosen': '0.15021', 'rewards_train/rejected': '-5.9147', 'rewards_train/margins': '6.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2226', 'examples_per_second': '5.3126', 'grad_norm': '5.3125', 'counters/examples': 241664, 'counters/updates': 15104}
skipping logging after 241680 examples to avoid logging too frequently
skipping logging after 241696 examples to avoid logging too frequently
skipping logging after 241712 examples to avoid logging too frequently
train stats after 241728 examples: {'rewards_train/chosen': '0.478', 'rewards_train/rejected': '-7.5973', 'rewards_train/margins': '8.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21143', 'examples_per_second': '4.8553', 'grad_norm': '4.7812', 'counters/examples': 241728, 'counters/updates': 15108}
skipping logging after 241744 examples to avoid logging too frequently
skipping logging after 241760 examples to avoid logging too frequently
skipping logging after 241776 examples to avoid logging too frequently
train stats after 241792 examples: {'rewards_train/chosen': '0.46503', 'rewards_train/rejected': '-6.2992', 'rewards_train/margins': '6.6562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2345', 'examples_per_second': '5.2563', 'grad_norm': '5.5625', 'counters/examples': 241792, 'counters/updates': 15112}
skipping logging after 241808 examples to avoid logging too frequently
skipping logging after 241824 examples to avoid logging too frequently
skipping logging after 241840 examples to avoid logging too frequently
train stats after 241856 examples: {'rewards_train/chosen': '0.38445', 'rewards_train/rejected': '-6.3042', 'rewards_train/margins': '6.7266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21729', 'examples_per_second': '5.1799', 'grad_norm': '4.6562', 'counters/examples': 241856, 'counters/updates': 15116}
skipping logging after 241872 examples to avoid logging too frequently
skipping logging after 241888 examples to avoid logging too frequently
skipping logging after 241904 examples to avoid logging too frequently
train stats after 241920 examples: {'rewards_train/chosen': '0.43407', 'rewards_train/rejected': '-6.2678', 'rewards_train/margins': '7.0156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25879', 'examples_per_second': '5.7127', 'grad_norm': '5.9688', 'counters/examples': 241920, 'counters/updates': 15120}
skipping logging after 241936 examples to avoid logging too frequently
skipping logging after 241952 examples to avoid logging too frequently
skipping logging after 241968 examples to avoid logging too frequently
train stats after 241984 examples: {'rewards_train/chosen': '0.03202', 'rewards_train/rejected': '-5.7852', 'rewards_train/margins': '5.5117', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28778', 'examples_per_second': '4.9499', 'grad_norm': '5.125', 'counters/examples': 241984, 'counters/updates': 15124}
skipping logging after 242000 examples to avoid logging too frequently
skipping logging after 242016 examples to avoid logging too frequently
skipping logging after 242032 examples to avoid logging too frequently
train stats after 242048 examples: {'rewards_train/chosen': '0.52964', 'rewards_train/rejected': '-7.0404', 'rewards_train/margins': '7.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.16638', 'examples_per_second': '5.3826', 'grad_norm': '4.875', 'counters/examples': 242048, 'counters/updates': 15128}
skipping logging after 242064 examples to avoid logging too frequently
skipping logging after 242080 examples to avoid logging too frequently
skipping logging after 242096 examples to avoid logging too frequently
train stats after 242112 examples: {'rewards_train/chosen': '0.1811', 'rewards_train/rejected': '-6.5304', 'rewards_train/margins': '6.9922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24072', 'examples_per_second': '5.7004', 'grad_norm': '4.625', 'counters/examples': 242112, 'counters/updates': 15132}
skipping logging after 242128 examples to avoid logging too frequently
skipping logging after 242144 examples to avoid logging too frequently
skipping logging after 242160 examples to avoid logging too frequently
train stats after 242176 examples: {'rewards_train/chosen': '0.44824', 'rewards_train/rejected': '-6.945', 'rewards_train/margins': '7.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2287', 'examples_per_second': '4.2849', 'grad_norm': '5.1875', 'counters/examples': 242176, 'counters/updates': 15136}
skipping logging after 242192 examples to avoid logging too frequently
skipping logging after 242208 examples to avoid logging too frequently
skipping logging after 242224 examples to avoid logging too frequently
train stats after 242240 examples: {'rewards_train/chosen': '0.17594', 'rewards_train/rejected': '-4.9758', 'rewards_train/margins': '5.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24213', 'examples_per_second': '4.9208', 'grad_norm': '4.5938', 'counters/examples': 242240, 'counters/updates': 15140}
skipping logging after 242256 examples to avoid logging too frequently
skipping logging after 242272 examples to avoid logging too frequently
skipping logging after 242288 examples to avoid logging too frequently
train stats after 242304 examples: {'rewards_train/chosen': '0.096911', 'rewards_train/rejected': '-6.5961', 'rewards_train/margins': '6.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22693', 'examples_per_second': '5.0112', 'grad_norm': '4.625', 'counters/examples': 242304, 'counters/updates': 15144}
skipping logging after 242320 examples to avoid logging too frequently
skipping logging after 242336 examples to avoid logging too frequently
skipping logging after 242352 examples to avoid logging too frequently
train stats after 242368 examples: {'rewards_train/chosen': '0.24778', 'rewards_train/rejected': '-7.0435', 'rewards_train/margins': '7.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25098', 'examples_per_second': '5.9513', 'grad_norm': '5.0938', 'counters/examples': 242368, 'counters/updates': 15148}
skipping logging after 242384 examples to avoid logging too frequently
skipping logging after 242400 examples to avoid logging too frequently
skipping logging after 242416 examples to avoid logging too frequently
train stats after 242432 examples: {'rewards_train/chosen': '0.55421', 'rewards_train/rejected': '-6.8894', 'rewards_train/margins': '7.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20526', 'examples_per_second': '4.7218', 'grad_norm': '4.625', 'counters/examples': 242432, 'counters/updates': 15152}
skipping logging after 242448 examples to avoid logging too frequently
skipping logging after 242464 examples to avoid logging too frequently
skipping logging after 242480 examples to avoid logging too frequently
train stats after 242496 examples: {'rewards_train/chosen': '0.77292', 'rewards_train/rejected': '-7.7275', 'rewards_train/margins': '8.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19269', 'examples_per_second': '4.8249', 'grad_norm': '4.7812', 'counters/examples': 242496, 'counters/updates': 15156}
skipping logging after 242512 examples to avoid logging too frequently
skipping logging after 242528 examples to avoid logging too frequently
skipping logging after 242544 examples to avoid logging too frequently
train stats after 242560 examples: {'rewards_train/chosen': '0.30395', 'rewards_train/rejected': '-7.1622', 'rewards_train/margins': '7.6094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2478', 'examples_per_second': '5.8308', 'grad_norm': '5.1562', 'counters/examples': 242560, 'counters/updates': 15160}
skipping logging after 242576 examples to avoid logging too frequently
skipping logging after 242592 examples to avoid logging too frequently
skipping logging after 242608 examples to avoid logging too frequently
train stats after 242624 examples: {'rewards_train/chosen': '0.3305', 'rewards_train/rejected': '-6.4176', 'rewards_train/margins': '6.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24255', 'examples_per_second': '6.3772', 'grad_norm': '5.125', 'counters/examples': 242624, 'counters/updates': 15164}
skipping logging after 242640 examples to avoid logging too frequently
skipping logging after 242656 examples to avoid logging too frequently
skipping logging after 242672 examples to avoid logging too frequently
train stats after 242688 examples: {'rewards_train/chosen': '0.3663', 'rewards_train/rejected': '-6.1378', 'rewards_train/margins': '6.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23853', 'examples_per_second': '4.5002', 'grad_norm': '5.7188', 'counters/examples': 242688, 'counters/updates': 15168}
skipping logging after 242704 examples to avoid logging too frequently
skipping logging after 242720 examples to avoid logging too frequently
skipping logging after 242736 examples to avoid logging too frequently
train stats after 242752 examples: {'rewards_train/chosen': '0.18507', 'rewards_train/rejected': '-6.5459', 'rewards_train/margins': '6.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25287', 'examples_per_second': '4.3786', 'grad_norm': '4.4688', 'counters/examples': 242752, 'counters/updates': 15172}
skipping logging after 242768 examples to avoid logging too frequently
skipping logging after 242784 examples to avoid logging too frequently
skipping logging after 242800 examples to avoid logging too frequently
train stats after 242816 examples: {'rewards_train/chosen': '0.51724', 'rewards_train/rejected': '-6.4465', 'rewards_train/margins': '6.9453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2157', 'examples_per_second': '5.2962', 'grad_norm': '5.3125', 'counters/examples': 242816, 'counters/updates': 15176}
skipping logging after 242832 examples to avoid logging too frequently
skipping logging after 242848 examples to avoid logging too frequently
skipping logging after 242864 examples to avoid logging too frequently
train stats after 242880 examples: {'rewards_train/chosen': '0.10358', 'rewards_train/rejected': '-6.1815', 'rewards_train/margins': '6.1602', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25031', 'examples_per_second': '4.5022', 'grad_norm': '5.125', 'counters/examples': 242880, 'counters/updates': 15180}
skipping logging after 242896 examples to avoid logging too frequently
skipping logging after 242912 examples to avoid logging too frequently
skipping logging after 242928 examples to avoid logging too frequently
train stats after 242944 examples: {'rewards_train/chosen': '0.39477', 'rewards_train/rejected': '-6.3923', 'rewards_train/margins': '6.7109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17926', 'examples_per_second': '4.9314', 'grad_norm': '4.5625', 'counters/examples': 242944, 'counters/updates': 15184}
skipping logging after 242960 examples to avoid logging too frequently
skipping logging after 242976 examples to avoid logging too frequently
skipping logging after 242992 examples to avoid logging too frequently
train stats after 243008 examples: {'rewards_train/chosen': '0.15095', 'rewards_train/rejected': '-6.3432', 'rewards_train/margins': '6.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21875', 'examples_per_second': '4.5932', 'grad_norm': '4.4688', 'counters/examples': 243008, 'counters/updates': 15188}
skipping logging after 243024 examples to avoid logging too frequently
skipping logging after 243040 examples to avoid logging too frequently
skipping logging after 243056 examples to avoid logging too frequently
train stats after 243072 examples: {'rewards_train/chosen': '0.3733', 'rewards_train/rejected': '-5.8889', 'rewards_train/margins': '6.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24225', 'examples_per_second': '4.9724', 'grad_norm': '4.4062', 'counters/examples': 243072, 'counters/updates': 15192}
skipping logging after 243088 examples to avoid logging too frequently
skipping logging after 243104 examples to avoid logging too frequently
skipping logging after 243120 examples to avoid logging too frequently
train stats after 243136 examples: {'rewards_train/chosen': '0.45385', 'rewards_train/rejected': '-7.3428', 'rewards_train/margins': '7.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22937', 'examples_per_second': '5.0413', 'grad_norm': '4.625', 'counters/examples': 243136, 'counters/updates': 15196}
skipping logging after 243152 examples to avoid logging too frequently
skipping logging after 243168 examples to avoid logging too frequently
skipping logging after 243184 examples to avoid logging too frequently
train stats after 243200 examples: {'rewards_train/chosen': '0.34882', 'rewards_train/rejected': '-5.1127', 'rewards_train/margins': '5.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23181', 'examples_per_second': '5.1838', 'grad_norm': '5.4062', 'counters/examples': 243200, 'counters/updates': 15200}
skipping logging after 243216 examples to avoid logging too frequently
skipping logging after 243232 examples to avoid logging too frequently
skipping logging after 243248 examples to avoid logging too frequently
train stats after 243264 examples: {'rewards_train/chosen': '0.40286', 'rewards_train/rejected': '-6.0881', 'rewards_train/margins': '6.1523', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23645', 'examples_per_second': '4.6222', 'grad_norm': '4.8125', 'counters/examples': 243264, 'counters/updates': 15204}
skipping logging after 243280 examples to avoid logging too frequently
skipping logging after 243296 examples to avoid logging too frequently
skipping logging after 243312 examples to avoid logging too frequently
train stats after 243328 examples: {'rewards_train/chosen': '0.64196', 'rewards_train/rejected': '-6.6645', 'rewards_train/margins': '7.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21814', 'examples_per_second': '4.789', 'grad_norm': '5.0312', 'counters/examples': 243328, 'counters/updates': 15208}
skipping logging after 243344 examples to avoid logging too frequently
skipping logging after 243360 examples to avoid logging too frequently
skipping logging after 243376 examples to avoid logging too frequently
train stats after 243392 examples: {'rewards_train/chosen': '0.26149', 'rewards_train/rejected': '-5.7536', 'rewards_train/margins': '6.0156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23907', 'examples_per_second': '5.8005', 'grad_norm': '4.2812', 'counters/examples': 243392, 'counters/updates': 15212}
skipping logging after 243408 examples to avoid logging too frequently
skipping logging after 243424 examples to avoid logging too frequently
skipping logging after 243440 examples to avoid logging too frequently
train stats after 243456 examples: {'rewards_train/chosen': '-0.029272', 'rewards_train/rejected': '-6.8204', 'rewards_train/margins': '6.7578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2146', 'examples_per_second': '5.7823', 'grad_norm': '4.625', 'counters/examples': 243456, 'counters/updates': 15216}
skipping logging after 243472 examples to avoid logging too frequently
skipping logging after 243488 examples to avoid logging too frequently
skipping logging after 243504 examples to avoid logging too frequently
train stats after 243520 examples: {'rewards_train/chosen': '0.23169', 'rewards_train/rejected': '-6.9417', 'rewards_train/margins': '7.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22559', 'examples_per_second': '4.9832', 'grad_norm': '4.9062', 'counters/examples': 243520, 'counters/updates': 15220}
skipping logging after 243536 examples to avoid logging too frequently
skipping logging after 243552 examples to avoid logging too frequently
skipping logging after 243568 examples to avoid logging too frequently
train stats after 243584 examples: {'rewards_train/chosen': '0.50852', 'rewards_train/rejected': '-6.9591', 'rewards_train/margins': '6.8203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2489', 'examples_per_second': '4.5181', 'grad_norm': '4.875', 'counters/examples': 243584, 'counters/updates': 15224}
skipping logging after 243600 examples to avoid logging too frequently
skipping logging after 243616 examples to avoid logging too frequently
skipping logging after 243632 examples to avoid logging too frequently
train stats after 243648 examples: {'rewards_train/chosen': '0.65117', 'rewards_train/rejected': '-6.62', 'rewards_train/margins': '7.3203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19073', 'examples_per_second': '5.2044', 'grad_norm': '4.125', 'counters/examples': 243648, 'counters/updates': 15228}
skipping logging after 243664 examples to avoid logging too frequently
skipping logging after 243680 examples to avoid logging too frequently
skipping logging after 243696 examples to avoid logging too frequently
train stats after 243712 examples: {'rewards_train/chosen': '0.46695', 'rewards_train/rejected': '-6.1328', 'rewards_train/margins': '6.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19531', 'examples_per_second': '4.4398', 'grad_norm': '4.5625', 'counters/examples': 243712, 'counters/updates': 15232}
skipping logging after 243728 examples to avoid logging too frequently
skipping logging after 243744 examples to avoid logging too frequently
skipping logging after 243760 examples to avoid logging too frequently
train stats after 243776 examples: {'rewards_train/chosen': '0.1886', 'rewards_train/rejected': '-4.9734', 'rewards_train/margins': '4.9023', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30078', 'examples_per_second': '4.7422', 'grad_norm': '6.0938', 'counters/examples': 243776, 'counters/updates': 15236}
skipping logging after 243792 examples to avoid logging too frequently
skipping logging after 243808 examples to avoid logging too frequently
skipping logging after 243824 examples to avoid logging too frequently
train stats after 243840 examples: {'rewards_train/chosen': '0.26633', 'rewards_train/rejected': '-5.1693', 'rewards_train/margins': '5.4219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2868', 'examples_per_second': '6.5944', 'grad_norm': '5.5625', 'counters/examples': 243840, 'counters/updates': 15240}
skipping logging after 243856 examples to avoid logging too frequently
skipping logging after 243872 examples to avoid logging too frequently
skipping logging after 243888 examples to avoid logging too frequently
train stats after 243904 examples: {'rewards_train/chosen': '0.16313', 'rewards_train/rejected': '-6.1235', 'rewards_train/margins': '5.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26978', 'examples_per_second': '5.2341', 'grad_norm': '9.25', 'counters/examples': 243904, 'counters/updates': 15244}
skipping logging after 243920 examples to avoid logging too frequently
skipping logging after 243936 examples to avoid logging too frequently
skipping logging after 243952 examples to avoid logging too frequently
train stats after 243968 examples: {'rewards_train/chosen': '0.49937', 'rewards_train/rejected': '-4.5858', 'rewards_train/margins': '5.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21857', 'examples_per_second': '5.5951', 'grad_norm': '5.6875', 'counters/examples': 243968, 'counters/updates': 15248}
skipping logging after 243984 examples to avoid logging too frequently
skipping logging after 244000 examples to avoid logging too frequently
Running evaluation after 244000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:46,  1.51s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:40,  1.36s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:35,  1.22s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.47s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.68s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.49s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:34,  1.37s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.53s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.49s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:31,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.41s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.39s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.28s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.51s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.42s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.20s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:41<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]
eval after 244000: {'rewards_eval/chosen': '-6.1425', 'rewards_eval/rejected': '-6.7658', 'rewards_eval/margins': '0.45117', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.45754'}
skipping logging after 244016 examples to avoid logging too frequently
train stats after 244032 examples: {'rewards_train/chosen': '0.49483', 'rewards_train/rejected': '-7.2703', 'rewards_train/margins': '7.7656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22156', 'examples_per_second': '5.0406', 'grad_norm': '4.625', 'counters/examples': 244032, 'counters/updates': 15252}
skipping logging after 244048 examples to avoid logging too frequently
skipping logging after 244064 examples to avoid logging too frequently
skipping logging after 244080 examples to avoid logging too frequently
train stats after 244096 examples: {'rewards_train/chosen': '0.21267', 'rewards_train/rejected': '-6.6943', 'rewards_train/margins': '6.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24469', 'examples_per_second': '5.6837', 'grad_norm': '5.875', 'counters/examples': 244096, 'counters/updates': 15256}
skipping logging after 244112 examples to avoid logging too frequently
skipping logging after 244128 examples to avoid logging too frequently
skipping logging after 244144 examples to avoid logging too frequently
train stats after 244160 examples: {'rewards_train/chosen': '0.051027', 'rewards_train/rejected': '-5.5276', 'rewards_train/margins': '5.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28357', 'examples_per_second': '5.2102', 'grad_norm': '5.9062', 'counters/examples': 244160, 'counters/updates': 15260}
skipping logging after 244176 examples to avoid logging too frequently
skipping logging after 244192 examples to avoid logging too frequently
skipping logging after 244208 examples to avoid logging too frequently
train stats after 244224 examples: {'rewards_train/chosen': '0.50844', 'rewards_train/rejected': '-7.4002', 'rewards_train/margins': '7.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18457', 'examples_per_second': '5.068', 'grad_norm': '4.0312', 'counters/examples': 244224, 'counters/updates': 15264}
skipping logging after 244240 examples to avoid logging too frequently
skipping logging after 244256 examples to avoid logging too frequently
skipping logging after 244272 examples to avoid logging too frequently
train stats after 244288 examples: {'rewards_train/chosen': '0.19217', 'rewards_train/rejected': '-5.2304', 'rewards_train/margins': '5.2344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26086', 'examples_per_second': '5.0431', 'grad_norm': '6.2812', 'counters/examples': 244288, 'counters/updates': 15268}
skipping logging after 244304 examples to avoid logging too frequently
skipping logging after 244320 examples to avoid logging too frequently
skipping logging after 244336 examples to avoid logging too frequently
train stats after 244352 examples: {'rewards_train/chosen': '0.58331', 'rewards_train/rejected': '-5.253', 'rewards_train/margins': '5.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2218', 'examples_per_second': '5.397', 'grad_norm': '4.6562', 'counters/examples': 244352, 'counters/updates': 15272}
skipping logging after 244368 examples to avoid logging too frequently
skipping logging after 244384 examples to avoid logging too frequently
skipping logging after 244400 examples to avoid logging too frequently
train stats after 244416 examples: {'rewards_train/chosen': '0.80969', 'rewards_train/rejected': '-6.637', 'rewards_train/margins': '7.5469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17224', 'examples_per_second': '5.2589', 'grad_norm': '6.1562', 'counters/examples': 244416, 'counters/updates': 15276}
skipping logging after 244432 examples to avoid logging too frequently
skipping logging after 244448 examples to avoid logging too frequently
skipping logging after 244464 examples to avoid logging too frequently
train stats after 244480 examples: {'rewards_train/chosen': '0.25192', 'rewards_train/rejected': '-6.4896', 'rewards_train/margins': '6.2969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24915', 'examples_per_second': '5.8977', 'grad_norm': '5.125', 'counters/examples': 244480, 'counters/updates': 15280}
skipping logging after 244496 examples to avoid logging too frequently
skipping logging after 244512 examples to avoid logging too frequently
skipping logging after 244528 examples to avoid logging too frequently
train stats after 244544 examples: {'rewards_train/chosen': '0.23603', 'rewards_train/rejected': '-5.9412', 'rewards_train/margins': '6.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22955', 'examples_per_second': '5.0467', 'grad_norm': '5.5625', 'counters/examples': 244544, 'counters/updates': 15284}
skipping logging after 244560 examples to avoid logging too frequently
skipping logging after 244576 examples to avoid logging too frequently
skipping logging after 244592 examples to avoid logging too frequently
train stats after 244608 examples: {'rewards_train/chosen': '0.26048', 'rewards_train/rejected': '-6.0613', 'rewards_train/margins': '6.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25507', 'examples_per_second': '5.5135', 'grad_norm': '5.75', 'counters/examples': 244608, 'counters/updates': 15288}
skipping logging after 244624 examples to avoid logging too frequently
skipping logging after 244640 examples to avoid logging too frequently
skipping logging after 244656 examples to avoid logging too frequently
train stats after 244672 examples: {'rewards_train/chosen': '0.33902', 'rewards_train/rejected': '-5.4749', 'rewards_train/margins': '6.1016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25671', 'examples_per_second': '5.0749', 'grad_norm': '5', 'counters/examples': 244672, 'counters/updates': 15292}
skipping logging after 244688 examples to avoid logging too frequently
skipping logging after 244704 examples to avoid logging too frequently
skipping logging after 244720 examples to avoid logging too frequently
train stats after 244736 examples: {'rewards_train/chosen': '0.40463', 'rewards_train/rejected': '-5.6769', 'rewards_train/margins': '6.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24707', 'examples_per_second': '5.9442', 'grad_norm': '5.0938', 'counters/examples': 244736, 'counters/updates': 15296}
skipping logging after 244752 examples to avoid logging too frequently
skipping logging after 244768 examples to avoid logging too frequently
skipping logging after 244784 examples to avoid logging too frequently
train stats after 244800 examples: {'rewards_train/chosen': '0.056303', 'rewards_train/rejected': '-7.2377', 'rewards_train/margins': '7.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25848', 'examples_per_second': '5.1827', 'grad_norm': '6', 'counters/examples': 244800, 'counters/updates': 15300}
skipping logging after 244816 examples to avoid logging too frequently
skipping logging after 244832 examples to avoid logging too frequently
skipping logging after 244848 examples to avoid logging too frequently
train stats after 244864 examples: {'rewards_train/chosen': '0.52381', 'rewards_train/rejected': '-7.8906', 'rewards_train/margins': '8.4531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20056', 'examples_per_second': '4.6839', 'grad_norm': '4.0625', 'counters/examples': 244864, 'counters/updates': 15304}
skipping logging after 244880 examples to avoid logging too frequently
skipping logging after 244896 examples to avoid logging too frequently
skipping logging after 244912 examples to avoid logging too frequently
train stats after 244928 examples: {'rewards_train/chosen': '0.44971', 'rewards_train/rejected': '-6.1809', 'rewards_train/margins': '6.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21387', 'examples_per_second': '4.7461', 'grad_norm': '4.5312', 'counters/examples': 244928, 'counters/updates': 15308}
skipping logging after 244944 examples to avoid logging too frequently
skipping logging after 244960 examples to avoid logging too frequently
skipping logging after 244976 examples to avoid logging too frequently
train stats after 244992 examples: {'rewards_train/chosen': '-0.047932', 'rewards_train/rejected': '-5.9022', 'rewards_train/margins': '5.7422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25128', 'examples_per_second': '6.5644', 'grad_norm': '4.6562', 'counters/examples': 244992, 'counters/updates': 15312}
skipping logging after 245008 examples to avoid logging too frequently
skipping logging after 245024 examples to avoid logging too frequently
skipping logging after 245040 examples to avoid logging too frequently
train stats after 245056 examples: {'rewards_train/chosen': '-0.22295', 'rewards_train/rejected': '-5.2677', 'rewards_train/margins': '5.0742', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29352', 'examples_per_second': '5.3156', 'grad_norm': '5.6562', 'counters/examples': 245056, 'counters/updates': 15316}
skipping logging after 245072 examples to avoid logging too frequently
skipping logging after 245088 examples to avoid logging too frequently
skipping logging after 245104 examples to avoid logging too frequently
train stats after 245120 examples: {'rewards_train/chosen': '0.35564', 'rewards_train/rejected': '-6.869', 'rewards_train/margins': '7.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23389', 'examples_per_second': '4.8826', 'grad_norm': '5.625', 'counters/examples': 245120, 'counters/updates': 15320}
skipping logging after 245136 examples to avoid logging too frequently
skipping logging after 245152 examples to avoid logging too frequently
skipping logging after 245168 examples to avoid logging too frequently
train stats after 245184 examples: {'rewards_train/chosen': '0.48269', 'rewards_train/rejected': '-7.0449', 'rewards_train/margins': '7.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23792', 'examples_per_second': '5.0328', 'grad_norm': '5.8125', 'counters/examples': 245184, 'counters/updates': 15324}
skipping logging after 245200 examples to avoid logging too frequently
skipping logging after 245216 examples to avoid logging too frequently
skipping logging after 245232 examples to avoid logging too frequently
train stats after 245248 examples: {'rewards_train/chosen': '0.059566', 'rewards_train/rejected': '-6.9704', 'rewards_train/margins': '6.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24133', 'examples_per_second': '4.3334', 'grad_norm': '4.9062', 'counters/examples': 245248, 'counters/updates': 15328}
skipping logging after 245264 examples to avoid logging too frequently
skipping logging after 245280 examples to avoid logging too frequently
skipping logging after 245296 examples to avoid logging too frequently
train stats after 245312 examples: {'rewards_train/chosen': '0.4506', 'rewards_train/rejected': '-6.8581', 'rewards_train/margins': '7.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21698', 'examples_per_second': '4.8002', 'grad_norm': '5.2812', 'counters/examples': 245312, 'counters/updates': 15332}
skipping logging after 245328 examples to avoid logging too frequently
skipping logging after 245344 examples to avoid logging too frequently
skipping logging after 245360 examples to avoid logging too frequently
train stats after 245376 examples: {'rewards_train/chosen': '0.25362', 'rewards_train/rejected': '-6.9606', 'rewards_train/margins': '7.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2049', 'examples_per_second': '5.7864', 'grad_norm': '5.6875', 'counters/examples': 245376, 'counters/updates': 15336}
skipping logging after 245392 examples to avoid logging too frequently
skipping logging after 245408 examples to avoid logging too frequently
skipping logging after 245424 examples to avoid logging too frequently
train stats after 245440 examples: {'rewards_train/chosen': '0.17353', 'rewards_train/rejected': '-6.1617', 'rewards_train/margins': '6.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28259', 'examples_per_second': '5.4885', 'grad_norm': '6.3438', 'counters/examples': 245440, 'counters/updates': 15340}
skipping logging after 245456 examples to avoid logging too frequently
skipping logging after 245472 examples to avoid logging too frequently
skipping logging after 245488 examples to avoid logging too frequently
train stats after 245504 examples: {'rewards_train/chosen': '-0.65606', 'rewards_train/rejected': '-5.8166', 'rewards_train/margins': '5.3203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2655', 'examples_per_second': '5.1287', 'grad_norm': '4.6562', 'counters/examples': 245504, 'counters/updates': 15344}
skipping logging after 245520 examples to avoid logging too frequently
skipping logging after 245536 examples to avoid logging too frequently
skipping logging after 245552 examples to avoid logging too frequently
train stats after 245568 examples: {'rewards_train/chosen': '0.29535', 'rewards_train/rejected': '-7.4844', 'rewards_train/margins': '7.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24005', 'examples_per_second': '5.2639', 'grad_norm': '5.75', 'counters/examples': 245568, 'counters/updates': 15348}
skipping logging after 245584 examples to avoid logging too frequently
skipping logging after 245600 examples to avoid logging too frequently
skipping logging after 245616 examples to avoid logging too frequently
train stats after 245632 examples: {'rewards_train/chosen': '-0.67458', 'rewards_train/rejected': '-6.269', 'rewards_train/margins': '5.7539', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25745', 'examples_per_second': '5.7586', 'grad_norm': '4.25', 'counters/examples': 245632, 'counters/updates': 15352}
skipping logging after 245648 examples to avoid logging too frequently
skipping logging after 245664 examples to avoid logging too frequently
skipping logging after 245680 examples to avoid logging too frequently
train stats after 245696 examples: {'rewards_train/chosen': '-0.098991', 'rewards_train/rejected': '-5.3448', 'rewards_train/margins': '5.168', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25159', 'examples_per_second': '6.2857', 'grad_norm': '4.8438', 'counters/examples': 245696, 'counters/updates': 15356}
skipping logging after 245712 examples to avoid logging too frequently
skipping logging after 245728 examples to avoid logging too frequently
skipping logging after 245744 examples to avoid logging too frequently
train stats after 245760 examples: {'rewards_train/chosen': '0.09529', 'rewards_train/rejected': '-6.4301', 'rewards_train/margins': '6.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30164', 'examples_per_second': '5.6123', 'grad_norm': '5.6562', 'counters/examples': 245760, 'counters/updates': 15360}
skipping logging after 245776 examples to avoid logging too frequently
skipping logging after 245792 examples to avoid logging too frequently
skipping logging after 245808 examples to avoid logging too frequently
train stats after 245824 examples: {'rewards_train/chosen': '0.49112', 'rewards_train/rejected': '-5.0281', 'rewards_train/margins': '5.6914', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21033', 'examples_per_second': '5.7799', 'grad_norm': '4.5625', 'counters/examples': 245824, 'counters/updates': 15364}
skipping logging after 245840 examples to avoid logging too frequently
skipping logging after 245856 examples to avoid logging too frequently
skipping logging after 245872 examples to avoid logging too frequently
train stats after 245888 examples: {'rewards_train/chosen': '0.44044', 'rewards_train/rejected': '-7.049', 'rewards_train/margins': '7.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24847', 'examples_per_second': '4.9785', 'grad_norm': '5.0312', 'counters/examples': 245888, 'counters/updates': 15368}
skipping logging after 245904 examples to avoid logging too frequently
skipping logging after 245920 examples to avoid logging too frequently
skipping logging after 245936 examples to avoid logging too frequently
train stats after 245952 examples: {'rewards_train/chosen': '0.13493', 'rewards_train/rejected': '-5.2899', 'rewards_train/margins': '5.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2478', 'examples_per_second': '5.6815', 'grad_norm': '5.2188', 'counters/examples': 245952, 'counters/updates': 15372}
skipping logging after 245968 examples to avoid logging too frequently
skipping logging after 245984 examples to avoid logging too frequently
skipping logging after 246000 examples to avoid logging too frequently
train stats after 246016 examples: {'rewards_train/chosen': '0.21155', 'rewards_train/rejected': '-5.185', 'rewards_train/margins': '5.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23322', 'examples_per_second': '5.3302', 'grad_norm': '4.75', 'counters/examples': 246016, 'counters/updates': 15376}
skipping logging after 246032 examples to avoid logging too frequently
skipping logging after 246048 examples to avoid logging too frequently
skipping logging after 246064 examples to avoid logging too frequently
train stats after 246080 examples: {'rewards_train/chosen': '0.28069', 'rewards_train/rejected': '-7.8768', 'rewards_train/margins': '8.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24994', 'examples_per_second': '4.9861', 'grad_norm': '6.6875', 'counters/examples': 246080, 'counters/updates': 15380}
skipping logging after 246096 examples to avoid logging too frequently
skipping logging after 246112 examples to avoid logging too frequently
skipping logging after 246128 examples to avoid logging too frequently
train stats after 246144 examples: {'rewards_train/chosen': '0.54541', 'rewards_train/rejected': '-5.6338', 'rewards_train/margins': '6.5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25317', 'examples_per_second': '3.713', 'grad_norm': '4.7812', 'counters/examples': 246144, 'counters/updates': 15384}
skipping logging after 246160 examples to avoid logging too frequently
skipping logging after 246176 examples to avoid logging too frequently
skipping logging after 246192 examples to avoid logging too frequently
train stats after 246208 examples: {'rewards_train/chosen': '0.1883', 'rewards_train/rejected': '-5.8605', 'rewards_train/margins': '6.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27533', 'examples_per_second': '4.6583', 'grad_norm': '5.4375', 'counters/examples': 246208, 'counters/updates': 15388}
skipping logging after 246224 examples to avoid logging too frequently
skipping logging after 246240 examples to avoid logging too frequently
skipping logging after 246256 examples to avoid logging too frequently
train stats after 246272 examples: {'rewards_train/chosen': '0.030879', 'rewards_train/rejected': '-4.9841', 'rewards_train/margins': '5.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28705', 'examples_per_second': '5.6956', 'grad_norm': '4.7188', 'counters/examples': 246272, 'counters/updates': 15392}
skipping logging after 246288 examples to avoid logging too frequently
skipping logging after 246304 examples to avoid logging too frequently
skipping logging after 246320 examples to avoid logging too frequently
train stats after 246336 examples: {'rewards_train/chosen': '0.044366', 'rewards_train/rejected': '-7.2578', 'rewards_train/margins': '7.3828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22552', 'examples_per_second': '5.1145', 'grad_norm': '4.5', 'counters/examples': 246336, 'counters/updates': 15396}
skipping logging after 246352 examples to avoid logging too frequently
skipping logging after 246368 examples to avoid logging too frequently
skipping logging after 246384 examples to avoid logging too frequently
train stats after 246400 examples: {'rewards_train/chosen': '0.52629', 'rewards_train/rejected': '-5.2863', 'rewards_train/margins': '5.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2016', 'examples_per_second': '4.7827', 'grad_norm': '5.0625', 'counters/examples': 246400, 'counters/updates': 15400}
skipping logging after 246416 examples to avoid logging too frequently
skipping logging after 246432 examples to avoid logging too frequently
skipping logging after 246448 examples to avoid logging too frequently
train stats after 246464 examples: {'rewards_train/chosen': '0.30496', 'rewards_train/rejected': '-5.7179', 'rewards_train/margins': '5.8555', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23834', 'examples_per_second': '6.4415', 'grad_norm': '6', 'counters/examples': 246464, 'counters/updates': 15404}
skipping logging after 246480 examples to avoid logging too frequently
skipping logging after 246496 examples to avoid logging too frequently
skipping logging after 246512 examples to avoid logging too frequently
train stats after 246528 examples: {'rewards_train/chosen': '0.53581', 'rewards_train/rejected': '-4.8242', 'rewards_train/margins': '5.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24188', 'examples_per_second': '4.8858', 'grad_norm': '5', 'counters/examples': 246528, 'counters/updates': 15408}
skipping logging after 246544 examples to avoid logging too frequently
skipping logging after 246560 examples to avoid logging too frequently
skipping logging after 246576 examples to avoid logging too frequently
train stats after 246592 examples: {'rewards_train/chosen': '0.23434', 'rewards_train/rejected': '-6.5767', 'rewards_train/margins': '6.7656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21136', 'examples_per_second': '5.685', 'grad_norm': '5.0938', 'counters/examples': 246592, 'counters/updates': 15412}
skipping logging after 246608 examples to avoid logging too frequently
skipping logging after 246624 examples to avoid logging too frequently
skipping logging after 246640 examples to avoid logging too frequently
train stats after 246656 examples: {'rewards_train/chosen': '-0.25965', 'rewards_train/rejected': '-6.7821', 'rewards_train/margins': '6.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27191', 'examples_per_second': '5.6319', 'grad_norm': '6', 'counters/examples': 246656, 'counters/updates': 15416}
skipping logging after 246672 examples to avoid logging too frequently
skipping logging after 246688 examples to avoid logging too frequently
skipping logging after 246704 examples to avoid logging too frequently
train stats after 246720 examples: {'rewards_train/chosen': '0.016891', 'rewards_train/rejected': '-6.7595', 'rewards_train/margins': '7.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25702', 'examples_per_second': '4.7153', 'grad_norm': '4.875', 'counters/examples': 246720, 'counters/updates': 15420}
skipping logging after 246736 examples to avoid logging too frequently
skipping logging after 246752 examples to avoid logging too frequently
skipping logging after 246768 examples to avoid logging too frequently
train stats after 246784 examples: {'rewards_train/chosen': '0.36044', 'rewards_train/rejected': '-5.7846', 'rewards_train/margins': '6.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22241', 'examples_per_second': '5.1757', 'grad_norm': '6.2188', 'counters/examples': 246784, 'counters/updates': 15424}
skipping logging after 246800 examples to avoid logging too frequently
skipping logging after 246816 examples to avoid logging too frequently
skipping logging after 246832 examples to avoid logging too frequently
train stats after 246848 examples: {'rewards_train/chosen': '0.43141', 'rewards_train/rejected': '-5.6575', 'rewards_train/margins': '6.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26361', 'examples_per_second': '4.8119', 'grad_norm': '5.0312', 'counters/examples': 246848, 'counters/updates': 15428}
skipping logging after 246864 examples to avoid logging too frequently
skipping logging after 246880 examples to avoid logging too frequently
skipping logging after 246896 examples to avoid logging too frequently
train stats after 246912 examples: {'rewards_train/chosen': '0.19873', 'rewards_train/rejected': '-6.1044', 'rewards_train/margins': '5.7852', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22766', 'examples_per_second': '5.8483', 'grad_norm': '5.3438', 'counters/examples': 246912, 'counters/updates': 15432}
skipping logging after 246928 examples to avoid logging too frequently
skipping logging after 246944 examples to avoid logging too frequently
skipping logging after 246960 examples to avoid logging too frequently
train stats after 246976 examples: {'rewards_train/chosen': '0.18688', 'rewards_train/rejected': '-6.3225', 'rewards_train/margins': '6.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26367', 'examples_per_second': '6.0387', 'grad_norm': '5.3125', 'counters/examples': 246976, 'counters/updates': 15436}
skipping logging after 246992 examples to avoid logging too frequently
skipping logging after 247008 examples to avoid logging too frequently
skipping logging after 247024 examples to avoid logging too frequently
train stats after 247040 examples: {'rewards_train/chosen': '0.4278', 'rewards_train/rejected': '-6.7016', 'rewards_train/margins': '7.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26514', 'examples_per_second': '5.953', 'grad_norm': '5.4688', 'counters/examples': 247040, 'counters/updates': 15440}
skipping logging after 247056 examples to avoid logging too frequently
skipping logging after 247072 examples to avoid logging too frequently
skipping logging after 247088 examples to avoid logging too frequently
train stats after 247104 examples: {'rewards_train/chosen': '0.52268', 'rewards_train/rejected': '-6.6538', 'rewards_train/margins': '7.0156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22778', 'examples_per_second': '4.6211', 'grad_norm': '6.3438', 'counters/examples': 247104, 'counters/updates': 15444}
skipping logging after 247120 examples to avoid logging too frequently
skipping logging after 247136 examples to avoid logging too frequently
skipping logging after 247152 examples to avoid logging too frequently
train stats after 247168 examples: {'rewards_train/chosen': '0.26626', 'rewards_train/rejected': '-5.7546', 'rewards_train/margins': '5.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20215', 'examples_per_second': '6.3623', 'grad_norm': '4.7188', 'counters/examples': 247168, 'counters/updates': 15448}
skipping logging after 247184 examples to avoid logging too frequently
skipping logging after 247200 examples to avoid logging too frequently
skipping logging after 247216 examples to avoid logging too frequently
train stats after 247232 examples: {'rewards_train/chosen': '0.1892', 'rewards_train/rejected': '-4.04', 'rewards_train/margins': '4.082', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25842', 'examples_per_second': '4.8487', 'grad_norm': '4.9062', 'counters/examples': 247232, 'counters/updates': 15452}
skipping logging after 247248 examples to avoid logging too frequently
skipping logging after 247264 examples to avoid logging too frequently
skipping logging after 247280 examples to avoid logging too frequently
train stats after 247296 examples: {'rewards_train/chosen': '0.40071', 'rewards_train/rejected': '-4.9967', 'rewards_train/margins': '5.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24792', 'examples_per_second': '5.4868', 'grad_norm': '4.9062', 'counters/examples': 247296, 'counters/updates': 15456}
skipping logging after 247312 examples to avoid logging too frequently
skipping logging after 247328 examples to avoid logging too frequently
skipping logging after 247344 examples to avoid logging too frequently
train stats after 247360 examples: {'rewards_train/chosen': '0.22632', 'rewards_train/rejected': '-6.7853', 'rewards_train/margins': '7.125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28784', 'examples_per_second': '4.6682', 'grad_norm': '6.125', 'counters/examples': 247360, 'counters/updates': 15460}
skipping logging after 247376 examples to avoid logging too frequently
skipping logging after 247392 examples to avoid logging too frequently
skipping logging after 247408 examples to avoid logging too frequently
train stats after 247424 examples: {'rewards_train/chosen': '0.73877', 'rewards_train/rejected': '-6.1442', 'rewards_train/margins': '6.9453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19458', 'examples_per_second': '3.6072', 'grad_norm': '3.875', 'counters/examples': 247424, 'counters/updates': 15464}
skipping logging after 247440 examples to avoid logging too frequently
skipping logging after 247456 examples to avoid logging too frequently
skipping logging after 247472 examples to avoid logging too frequently
train stats after 247488 examples: {'rewards_train/chosen': '0.2727', 'rewards_train/rejected': '-6.3296', 'rewards_train/margins': '6.7578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26343', 'examples_per_second': '4.3494', 'grad_norm': '4.9688', 'counters/examples': 247488, 'counters/updates': 15468}
skipping logging after 247504 examples to avoid logging too frequently
skipping logging after 247520 examples to avoid logging too frequently
skipping logging after 247536 examples to avoid logging too frequently
train stats after 247552 examples: {'rewards_train/chosen': '0.1505', 'rewards_train/rejected': '-5.5352', 'rewards_train/margins': '5.7422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26178', 'examples_per_second': '5.2552', 'grad_norm': '5.6875', 'counters/examples': 247552, 'counters/updates': 15472}
skipping logging after 247568 examples to avoid logging too frequently
skipping logging after 247584 examples to avoid logging too frequently
skipping logging after 247600 examples to avoid logging too frequently
train stats after 247616 examples: {'rewards_train/chosen': '0.33646', 'rewards_train/rejected': '-7.3522', 'rewards_train/margins': '7.6094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19397', 'examples_per_second': '4.8481', 'grad_norm': '3.7344', 'counters/examples': 247616, 'counters/updates': 15476}
skipping logging after 247632 examples to avoid logging too frequently
skipping logging after 247648 examples to avoid logging too frequently
skipping logging after 247664 examples to avoid logging too frequently
train stats after 247680 examples: {'rewards_train/chosen': '0.21571', 'rewards_train/rejected': '-5.5207', 'rewards_train/margins': '5.6484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25134', 'examples_per_second': '6.417', 'grad_norm': '4.3438', 'counters/examples': 247680, 'counters/updates': 15480}
skipping logging after 247696 examples to avoid logging too frequently
skipping logging after 247712 examples to avoid logging too frequently
skipping logging after 247728 examples to avoid logging too frequently
train stats after 247744 examples: {'rewards_train/chosen': '0.16859', 'rewards_train/rejected': '-6.3852', 'rewards_train/margins': '6.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2464', 'examples_per_second': '5.169', 'grad_norm': '5.0938', 'counters/examples': 247744, 'counters/updates': 15484}
skipping logging after 247760 examples to avoid logging too frequently
skipping logging after 247776 examples to avoid logging too frequently
skipping logging after 247792 examples to avoid logging too frequently
train stats after 247808 examples: {'rewards_train/chosen': '0.46171', 'rewards_train/rejected': '-5.7525', 'rewards_train/margins': '6.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2489', 'examples_per_second': '5.2353', 'grad_norm': '5.2812', 'counters/examples': 247808, 'counters/updates': 15488}
skipping logging after 247824 examples to avoid logging too frequently
skipping logging after 247840 examples to avoid logging too frequently
skipping logging after 247856 examples to avoid logging too frequently
train stats after 247872 examples: {'rewards_train/chosen': '0.60932', 'rewards_train/rejected': '-5.4264', 'rewards_train/margins': '5.6641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23163', 'examples_per_second': '4.4499', 'grad_norm': '4.8125', 'counters/examples': 247872, 'counters/updates': 15492}
skipping logging after 247888 examples to avoid logging too frequently
skipping logging after 247904 examples to avoid logging too frequently
skipping logging after 247920 examples to avoid logging too frequently
train stats after 247936 examples: {'rewards_train/chosen': '0.21729', 'rewards_train/rejected': '-5.7446', 'rewards_train/margins': '6.0547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27838', 'examples_per_second': '5.8292', 'grad_norm': '4.4688', 'counters/examples': 247936, 'counters/updates': 15496}
skipping logging after 247952 examples to avoid logging too frequently
skipping logging after 247968 examples to avoid logging too frequently
skipping logging after 247984 examples to avoid logging too frequently
train stats after 248000 examples: {'rewards_train/chosen': '0.2397', 'rewards_train/rejected': '-6.0319', 'rewards_train/margins': '6.1523', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23242', 'examples_per_second': '4.7478', 'grad_norm': '5.0938', 'counters/examples': 248000, 'counters/updates': 15500}
Running evaluation after 248000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.26s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.17s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:40,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.65s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.47s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:34,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.51s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.39s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:21<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.42s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.18s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.31s/it]
eval after 248000: {'rewards_eval/chosen': '-5.5183', 'rewards_eval/rejected': '-6.0358', 'rewards_eval/margins': '0.39111', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.45816'}
skipping logging after 248016 examples to avoid logging too frequently
skipping logging after 248032 examples to avoid logging too frequently
skipping logging after 248048 examples to avoid logging too frequently
train stats after 248064 examples: {'rewards_train/chosen': '0.047642', 'rewards_train/rejected': '-5.5704', 'rewards_train/margins': '5.0352', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2276', 'examples_per_second': '5.369', 'grad_norm': '5.3438', 'counters/examples': 248064, 'counters/updates': 15504}
skipping logging after 248080 examples to avoid logging too frequently
skipping logging after 248096 examples to avoid logging too frequently
skipping logging after 248112 examples to avoid logging too frequently
train stats after 248128 examples: {'rewards_train/chosen': '0.40936', 'rewards_train/rejected': '-6.917', 'rewards_train/margins': '7.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21118', 'examples_per_second': '5.353', 'grad_norm': '5.4375', 'counters/examples': 248128, 'counters/updates': 15508}
skipping logging after 248144 examples to avoid logging too frequently
skipping logging after 248160 examples to avoid logging too frequently
skipping logging after 248176 examples to avoid logging too frequently
train stats after 248192 examples: {'rewards_train/chosen': '0.15903', 'rewards_train/rejected': '-7.0135', 'rewards_train/margins': '7.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23578', 'examples_per_second': '4.5326', 'grad_norm': '4.5625', 'counters/examples': 248192, 'counters/updates': 15512}
skipping logging after 248208 examples to avoid logging too frequently
skipping logging after 248224 examples to avoid logging too frequently
skipping logging after 248240 examples to avoid logging too frequently
train stats after 248256 examples: {'rewards_train/chosen': '0.31492', 'rewards_train/rejected': '-6.0818', 'rewards_train/margins': '6.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18829', 'examples_per_second': '5.8241', 'grad_norm': '4.3438', 'counters/examples': 248256, 'counters/updates': 15516}
skipping logging after 248272 examples to avoid logging too frequently
skipping logging after 248288 examples to avoid logging too frequently
skipping logging after 248304 examples to avoid logging too frequently
train stats after 248320 examples: {'rewards_train/chosen': '0.29512', 'rewards_train/rejected': '-7.1792', 'rewards_train/margins': '7.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22876', 'examples_per_second': '5.9151', 'grad_norm': '5.7188', 'counters/examples': 248320, 'counters/updates': 15520}
skipping logging after 248336 examples to avoid logging too frequently
skipping logging after 248352 examples to avoid logging too frequently
skipping logging after 248368 examples to avoid logging too frequently
train stats after 248384 examples: {'rewards_train/chosen': '0.306', 'rewards_train/rejected': '-5.1755', 'rewards_train/margins': '5.9141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27118', 'examples_per_second': '5.7966', 'grad_norm': '5.75', 'counters/examples': 248384, 'counters/updates': 15524}
skipping logging after 248400 examples to avoid logging too frequently
skipping logging after 248416 examples to avoid logging too frequently
skipping logging after 248432 examples to avoid logging too frequently
train stats after 248448 examples: {'rewards_train/chosen': '0.18777', 'rewards_train/rejected': '-5.5732', 'rewards_train/margins': '5.3398', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26465', 'examples_per_second': '5.4108', 'grad_norm': '5.0312', 'counters/examples': 248448, 'counters/updates': 15528}
skipping logging after 248464 examples to avoid logging too frequently
skipping logging after 248480 examples to avoid logging too frequently
skipping logging after 248496 examples to avoid logging too frequently
train stats after 248512 examples: {'rewards_train/chosen': '0.26768', 'rewards_train/rejected': '-6.7612', 'rewards_train/margins': '7.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26215', 'examples_per_second': '5.3272', 'grad_norm': '5.1875', 'counters/examples': 248512, 'counters/updates': 15532}
skipping logging after 248528 examples to avoid logging too frequently
skipping logging after 248544 examples to avoid logging too frequently
skipping logging after 248560 examples to avoid logging too frequently
train stats after 248576 examples: {'rewards_train/chosen': '0.29667', 'rewards_train/rejected': '-5.8083', 'rewards_train/margins': '6.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.3042', 'examples_per_second': '5.2725', 'grad_norm': '5.4375', 'counters/examples': 248576, 'counters/updates': 15536}
skipping logging after 248592 examples to avoid logging too frequently
skipping logging after 248608 examples to avoid logging too frequently
skipping logging after 248624 examples to avoid logging too frequently
train stats after 248640 examples: {'rewards_train/chosen': '0.27165', 'rewards_train/rejected': '-5.5755', 'rewards_train/margins': '5.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2384', 'examples_per_second': '4.7327', 'grad_norm': '4.6562', 'counters/examples': 248640, 'counters/updates': 15540}
skipping logging after 248656 examples to avoid logging too frequently
skipping logging after 248672 examples to avoid logging too frequently
skipping logging after 248688 examples to avoid logging too frequently
train stats after 248704 examples: {'rewards_train/chosen': '0.37318', 'rewards_train/rejected': '-6.1109', 'rewards_train/margins': '6.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2243', 'examples_per_second': '4.5575', 'grad_norm': '4.5625', 'counters/examples': 248704, 'counters/updates': 15544}
skipping logging after 248720 examples to avoid logging too frequently
skipping logging after 248736 examples to avoid logging too frequently
skipping logging after 248752 examples to avoid logging too frequently
train stats after 248768 examples: {'rewards_train/chosen': '0.46886', 'rewards_train/rejected': '-6.8584', 'rewards_train/margins': '7.3203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26672', 'examples_per_second': '4.3768', 'grad_norm': '5.7812', 'counters/examples': 248768, 'counters/updates': 15548}
skipping logging after 248784 examples to avoid logging too frequently
skipping logging after 248800 examples to avoid logging too frequently
skipping logging after 248816 examples to avoid logging too frequently
train stats after 248832 examples: {'rewards_train/chosen': '0.41511', 'rewards_train/rejected': '-5.1617', 'rewards_train/margins': '5.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21857', 'examples_per_second': '5.5152', 'grad_norm': '4.8125', 'counters/examples': 248832, 'counters/updates': 15552}
skipping logging after 248848 examples to avoid logging too frequently
skipping logging after 248864 examples to avoid logging too frequently
skipping logging after 248880 examples to avoid logging too frequently
train stats after 248896 examples: {'rewards_train/chosen': '0.42964', 'rewards_train/rejected': '-6.103', 'rewards_train/margins': '6.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27863', 'examples_per_second': '4.6846', 'grad_norm': '5.4688', 'counters/examples': 248896, 'counters/updates': 15556}
skipping logging after 248912 examples to avoid logging too frequently
skipping logging after 248928 examples to avoid logging too frequently
skipping logging after 248944 examples to avoid logging too frequently
train stats after 248960 examples: {'rewards_train/chosen': '0.39248', 'rewards_train/rejected': '-5.4422', 'rewards_train/margins': '5.7383', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24878', 'examples_per_second': '5.4587', 'grad_norm': '4.9688', 'counters/examples': 248960, 'counters/updates': 15560}
skipping logging after 248976 examples to avoid logging too frequently
skipping logging after 248992 examples to avoid logging too frequently
skipping logging after 249008 examples to avoid logging too frequently
train stats after 249024 examples: {'rewards_train/chosen': '0.41014', 'rewards_train/rejected': '-5.8556', 'rewards_train/margins': '6.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23547', 'examples_per_second': '5.1966', 'grad_norm': '4.8125', 'counters/examples': 249024, 'counters/updates': 15564}
skipping logging after 249040 examples to avoid logging too frequently
skipping logging after 249056 examples to avoid logging too frequently
skipping logging after 249072 examples to avoid logging too frequently
train stats after 249088 examples: {'rewards_train/chosen': '0.39915', 'rewards_train/rejected': '-6.2349', 'rewards_train/margins': '6.8945', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22784', 'examples_per_second': '5.1331', 'grad_norm': '5.2188', 'counters/examples': 249088, 'counters/updates': 15568}
skipping logging after 249104 examples to avoid logging too frequently
skipping logging after 249120 examples to avoid logging too frequently
skipping logging after 249136 examples to avoid logging too frequently
train stats after 249152 examples: {'rewards_train/chosen': '0.24859', 'rewards_train/rejected': '-6.3714', 'rewards_train/margins': '6.6016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23004', 'examples_per_second': '5.4183', 'grad_norm': '5.3125', 'counters/examples': 249152, 'counters/updates': 15572}
skipping logging after 249168 examples to avoid logging too frequently
skipping logging after 249184 examples to avoid logging too frequently
skipping logging after 249200 examples to avoid logging too frequently
train stats after 249216 examples: {'rewards_train/chosen': '0.27158', 'rewards_train/rejected': '-6.3278', 'rewards_train/margins': '6.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27423', 'examples_per_second': '4.9314', 'grad_norm': '5.8438', 'counters/examples': 249216, 'counters/updates': 15576}
skipping logging after 249232 examples to avoid logging too frequently
skipping logging after 249248 examples to avoid logging too frequently
skipping logging after 249264 examples to avoid logging too frequently
train stats after 249280 examples: {'rewards_train/chosen': '0.39155', 'rewards_train/rejected': '-6.21', 'rewards_train/margins': '6.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24109', 'examples_per_second': '5.787', 'grad_norm': '5.1562', 'counters/examples': 249280, 'counters/updates': 15580}
skipping logging after 249296 examples to avoid logging too frequently
skipping logging after 249312 examples to avoid logging too frequently
skipping logging after 249328 examples to avoid logging too frequently
train stats after 249344 examples: {'rewards_train/chosen': '0.33569', 'rewards_train/rejected': '-6.1826', 'rewards_train/margins': '6.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22247', 'examples_per_second': '4.3003', 'grad_norm': '4.75', 'counters/examples': 249344, 'counters/updates': 15584}
skipping logging after 249360 examples to avoid logging too frequently
skipping logging after 249376 examples to avoid logging too frequently
skipping logging after 249392 examples to avoid logging too frequently
train stats after 249408 examples: {'rewards_train/chosen': '0.36415', 'rewards_train/rejected': '-6.0857', 'rewards_train/margins': '6.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2229', 'examples_per_second': '4.9634', 'grad_norm': '5', 'counters/examples': 249408, 'counters/updates': 15588}
skipping logging after 249424 examples to avoid logging too frequently
skipping logging after 249440 examples to avoid logging too frequently
skipping logging after 249456 examples to avoid logging too frequently
train stats after 249472 examples: {'rewards_train/chosen': '0.44875', 'rewards_train/rejected': '-6.0166', 'rewards_train/margins': '6.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24554', 'examples_per_second': '4.9833', 'grad_norm': '4.7812', 'counters/examples': 249472, 'counters/updates': 15592}
skipping logging after 249488 examples to avoid logging too frequently
skipping logging after 249504 examples to avoid logging too frequently
skipping logging after 249520 examples to avoid logging too frequently
train stats after 249536 examples: {'rewards_train/chosen': '0.66914', 'rewards_train/rejected': '-6.0016', 'rewards_train/margins': '6.4961', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2171', 'examples_per_second': '6.2838', 'grad_norm': '4.9375', 'counters/examples': 249536, 'counters/updates': 15596}
skipping logging after 249552 examples to avoid logging too frequently
skipping logging after 249568 examples to avoid logging too frequently
skipping logging after 249584 examples to avoid logging too frequently
train stats after 249600 examples: {'rewards_train/chosen': '0.27235', 'rewards_train/rejected': '-5.8204', 'rewards_train/margins': '6.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21698', 'examples_per_second': '5.0166', 'grad_norm': '5.3125', 'counters/examples': 249600, 'counters/updates': 15600}
skipping logging after 249616 examples to avoid logging too frequently
skipping logging after 249632 examples to avoid logging too frequently
skipping logging after 249648 examples to avoid logging too frequently
train stats after 249664 examples: {'rewards_train/chosen': '0.44556', 'rewards_train/rejected': '-7.1138', 'rewards_train/margins': '7.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22919', 'examples_per_second': '4.2709', 'grad_norm': '5.875', 'counters/examples': 249664, 'counters/updates': 15604}
skipping logging after 249680 examples to avoid logging too frequently
skipping logging after 249696 examples to avoid logging too frequently
skipping logging after 249712 examples to avoid logging too frequently
train stats after 249728 examples: {'rewards_train/chosen': '0.34079', 'rewards_train/rejected': '-6.8292', 'rewards_train/margins': '7.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20605', 'examples_per_second': '4.9843', 'grad_norm': '5.6875', 'counters/examples': 249728, 'counters/updates': 15608}
skipping logging after 249744 examples to avoid logging too frequently
skipping logging after 249760 examples to avoid logging too frequently
skipping logging after 249776 examples to avoid logging too frequently
train stats after 249792 examples: {'rewards_train/chosen': '0.38524', 'rewards_train/rejected': '-7.2895', 'rewards_train/margins': '8.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19257', 'examples_per_second': '4.9529', 'grad_norm': '6.5', 'counters/examples': 249792, 'counters/updates': 15612}
skipping logging after 249808 examples to avoid logging too frequently
skipping logging after 249824 examples to avoid logging too frequently
skipping logging after 249840 examples to avoid logging too frequently
train stats after 249856 examples: {'rewards_train/chosen': '0.33668', 'rewards_train/rejected': '-6.5966', 'rewards_train/margins': '7.0312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23358', 'examples_per_second': '5.2946', 'grad_norm': '4.8438', 'counters/examples': 249856, 'counters/updates': 15616}
skipping logging after 249872 examples to avoid logging too frequently
skipping logging after 249888 examples to avoid logging too frequently
skipping logging after 249904 examples to avoid logging too frequently
train stats after 249920 examples: {'rewards_train/chosen': '0.4812', 'rewards_train/rejected': '-4.6814', 'rewards_train/margins': '5.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23322', 'examples_per_second': '5.3001', 'grad_norm': '5.0625', 'counters/examples': 249920, 'counters/updates': 15620}
skipping logging after 249936 examples to avoid logging too frequently
skipping logging after 249952 examples to avoid logging too frequently
skipping logging after 249968 examples to avoid logging too frequently
train stats after 249984 examples: {'rewards_train/chosen': '0.65568', 'rewards_train/rejected': '-6.6805', 'rewards_train/margins': '7.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20605', 'examples_per_second': '4.5582', 'grad_norm': '6.1875', 'counters/examples': 249984, 'counters/updates': 15624}
skipping logging after 250000 examples to avoid logging too frequently
skipping logging after 250016 examples to avoid logging too frequently
skipping logging after 250032 examples to avoid logging too frequently
train stats after 250048 examples: {'rewards_train/chosen': '0.47578', 'rewards_train/rejected': '-6.407', 'rewards_train/margins': '7.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23999', 'examples_per_second': '4.776', 'grad_norm': '5.5312', 'counters/examples': 250048, 'counters/updates': 15628}
skipping logging after 250064 examples to avoid logging too frequently
skipping logging after 250080 examples to avoid logging too frequently
skipping logging after 250096 examples to avoid logging too frequently
train stats after 250112 examples: {'rewards_train/chosen': '0.03864', 'rewards_train/rejected': '-5.576', 'rewards_train/margins': '5.2148', 'rewards_train/KL_estimate': '0', 'loss/train': '0.31152', 'examples_per_second': '5.7372', 'grad_norm': '6.25', 'counters/examples': 250112, 'counters/updates': 15632}
skipping logging after 250128 examples to avoid logging too frequently
skipping logging after 250144 examples to avoid logging too frequently
skipping logging after 250160 examples to avoid logging too frequently
train stats after 250176 examples: {'rewards_train/chosen': '0.47409', 'rewards_train/rejected': '-6.3477', 'rewards_train/margins': '7.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23193', 'examples_per_second': '5.4928', 'grad_norm': '4.75', 'counters/examples': 250176, 'counters/updates': 15636}
skipping logging after 250192 examples to avoid logging too frequently
skipping logging after 250208 examples to avoid logging too frequently
skipping logging after 250224 examples to avoid logging too frequently
train stats after 250240 examples: {'rewards_train/chosen': '0.072012', 'rewards_train/rejected': '-5.5393', 'rewards_train/margins': '5.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28485', 'examples_per_second': '7.4304', 'grad_norm': '4.25', 'counters/examples': 250240, 'counters/updates': 15640}
skipping logging after 250256 examples to avoid logging too frequently
skipping logging after 250272 examples to avoid logging too frequently
skipping logging after 250288 examples to avoid logging too frequently
train stats after 250304 examples: {'rewards_train/chosen': '0.16352', 'rewards_train/rejected': '-5.6668', 'rewards_train/margins': '6', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25903', 'examples_per_second': '6.2354', 'grad_norm': '5.5938', 'counters/examples': 250304, 'counters/updates': 15644}
skipping logging after 250320 examples to avoid logging too frequently
skipping logging after 250336 examples to avoid logging too frequently
skipping logging after 250352 examples to avoid logging too frequently
train stats after 250368 examples: {'rewards_train/chosen': '0.29624', 'rewards_train/rejected': '-7.1536', 'rewards_train/margins': '7.375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20728', 'examples_per_second': '5.5994', 'grad_norm': '5.0312', 'counters/examples': 250368, 'counters/updates': 15648}
skipping logging after 250384 examples to avoid logging too frequently
skipping logging after 250400 examples to avoid logging too frequently
skipping logging after 250416 examples to avoid logging too frequently
train stats after 250432 examples: {'rewards_train/chosen': '0.33321', 'rewards_train/rejected': '-6.7772', 'rewards_train/margins': '6.7773', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27338', 'examples_per_second': '5.6029', 'grad_norm': '5.0938', 'counters/examples': 250432, 'counters/updates': 15652}
skipping logging after 250448 examples to avoid logging too frequently
skipping logging after 250464 examples to avoid logging too frequently
skipping logging after 250480 examples to avoid logging too frequently
train stats after 250496 examples: {'rewards_train/chosen': '0.085648', 'rewards_train/rejected': '-6.8674', 'rewards_train/margins': '7.0234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24023', 'examples_per_second': '3.9093', 'grad_norm': '5.0625', 'counters/examples': 250496, 'counters/updates': 15656}
skipping logging after 250512 examples to avoid logging too frequently
skipping logging after 250528 examples to avoid logging too frequently
skipping logging after 250544 examples to avoid logging too frequently
train stats after 250560 examples: {'rewards_train/chosen': '0.22103', 'rewards_train/rejected': '-7.6538', 'rewards_train/margins': '8.0859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26129', 'examples_per_second': '5.2394', 'grad_norm': '5.75', 'counters/examples': 250560, 'counters/updates': 15660}
skipping logging after 250576 examples to avoid logging too frequently
skipping logging after 250592 examples to avoid logging too frequently
skipping logging after 250608 examples to avoid logging too frequently
train stats after 250624 examples: {'rewards_train/chosen': '0.26677', 'rewards_train/rejected': '-6.3315', 'rewards_train/margins': '6.6484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26282', 'examples_per_second': '5.8607', 'grad_norm': '5.3438', 'counters/examples': 250624, 'counters/updates': 15664}
skipping logging after 250640 examples to avoid logging too frequently
skipping logging after 250656 examples to avoid logging too frequently
skipping logging after 250672 examples to avoid logging too frequently
train stats after 250688 examples: {'rewards_train/chosen': '0.36929', 'rewards_train/rejected': '-5.8967', 'rewards_train/margins': '6.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2038', 'examples_per_second': '5.3011', 'grad_norm': '4.25', 'counters/examples': 250688, 'counters/updates': 15668}
skipping logging after 250704 examples to avoid logging too frequently
skipping logging after 250720 examples to avoid logging too frequently
skipping logging after 250736 examples to avoid logging too frequently
train stats after 250752 examples: {'rewards_train/chosen': '0.26915', 'rewards_train/rejected': '-8.6603', 'rewards_train/margins': '8.2422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27277', 'examples_per_second': '4.4783', 'grad_norm': '5.2188', 'counters/examples': 250752, 'counters/updates': 15672}
skipping logging after 250768 examples to avoid logging too frequently
skipping logging after 250784 examples to avoid logging too frequently
skipping logging after 250800 examples to avoid logging too frequently
train stats after 250816 examples: {'rewards_train/chosen': '0.24842', 'rewards_train/rejected': '-4.9608', 'rewards_train/margins': '5.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24048', 'examples_per_second': '5.0262', 'grad_norm': '5.875', 'counters/examples': 250816, 'counters/updates': 15676}
skipping logging after 250832 examples to avoid logging too frequently
skipping logging after 250848 examples to avoid logging too frequently
skipping logging after 250864 examples to avoid logging too frequently
train stats after 250880 examples: {'rewards_train/chosen': '0.56279', 'rewards_train/rejected': '-6.8351', 'rewards_train/margins': '7.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21558', 'examples_per_second': '5.2047', 'grad_norm': '4.875', 'counters/examples': 250880, 'counters/updates': 15680}
skipping logging after 250896 examples to avoid logging too frequently
skipping logging after 250912 examples to avoid logging too frequently
skipping logging after 250928 examples to avoid logging too frequently
train stats after 250944 examples: {'rewards_train/chosen': '0.13772', 'rewards_train/rejected': '-6.6351', 'rewards_train/margins': '6.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23389', 'examples_per_second': '5.4694', 'grad_norm': '5.7188', 'counters/examples': 250944, 'counters/updates': 15684}
skipping logging after 250960 examples to avoid logging too frequently
skipping logging after 250976 examples to avoid logging too frequently
skipping logging after 250992 examples to avoid logging too frequently
train stats after 251008 examples: {'rewards_train/chosen': '0.11671', 'rewards_train/rejected': '-6.0159', 'rewards_train/margins': '6.0859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27173', 'examples_per_second': '5.4244', 'grad_norm': '5.4688', 'counters/examples': 251008, 'counters/updates': 15688}
skipping logging after 251024 examples to avoid logging too frequently
skipping logging after 251040 examples to avoid logging too frequently
skipping logging after 251056 examples to avoid logging too frequently
train stats after 251072 examples: {'rewards_train/chosen': '0.21757', 'rewards_train/rejected': '-5.6542', 'rewards_train/margins': '5.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19757', 'examples_per_second': '4.3692', 'grad_norm': '4.7812', 'counters/examples': 251072, 'counters/updates': 15692}
skipping logging after 251088 examples to avoid logging too frequently
skipping logging after 251104 examples to avoid logging too frequently
skipping logging after 251120 examples to avoid logging too frequently
train stats after 251136 examples: {'rewards_train/chosen': '0.21869', 'rewards_train/rejected': '-7.1098', 'rewards_train/margins': '7.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23792', 'examples_per_second': '5.2507', 'grad_norm': '5.75', 'counters/examples': 251136, 'counters/updates': 15696}
skipping logging after 251152 examples to avoid logging too frequently
skipping logging after 251168 examples to avoid logging too frequently
skipping logging after 251184 examples to avoid logging too frequently
train stats after 251200 examples: {'rewards_train/chosen': '0.36252', 'rewards_train/rejected': '-5.8991', 'rewards_train/margins': '6.2266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25409', 'examples_per_second': '6.4073', 'grad_norm': '5.1562', 'counters/examples': 251200, 'counters/updates': 15700}
skipping logging after 251216 examples to avoid logging too frequently
skipping logging after 251232 examples to avoid logging too frequently
skipping logging after 251248 examples to avoid logging too frequently
train stats after 251264 examples: {'rewards_train/chosen': '0.45702', 'rewards_train/rejected': '-6.8605', 'rewards_train/margins': '7.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25049', 'examples_per_second': '5.2475', 'grad_norm': '5.1875', 'counters/examples': 251264, 'counters/updates': 15704}
skipping logging after 251280 examples to avoid logging too frequently
skipping logging after 251296 examples to avoid logging too frequently
skipping logging after 251312 examples to avoid logging too frequently
train stats after 251328 examples: {'rewards_train/chosen': '0.41958', 'rewards_train/rejected': '-5.3699', 'rewards_train/margins': '6.1016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26361', 'examples_per_second': '4.6723', 'grad_norm': '5.4375', 'counters/examples': 251328, 'counters/updates': 15708}
skipping logging after 251344 examples to avoid logging too frequently
skipping logging after 251360 examples to avoid logging too frequently
skipping logging after 251376 examples to avoid logging too frequently
train stats after 251392 examples: {'rewards_train/chosen': '0.42514', 'rewards_train/rejected': '-7.2991', 'rewards_train/margins': '7.5391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26324', 'examples_per_second': '4.6958', 'grad_norm': '5.4062', 'counters/examples': 251392, 'counters/updates': 15712}
skipping logging after 251408 examples to avoid logging too frequently
skipping logging after 251424 examples to avoid logging too frequently
skipping logging after 251440 examples to avoid logging too frequently
train stats after 251456 examples: {'rewards_train/chosen': '0.26061', 'rewards_train/rejected': '-6.4344', 'rewards_train/margins': '6.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24316', 'examples_per_second': '4.0797', 'grad_norm': '6', 'counters/examples': 251456, 'counters/updates': 15716}
skipping logging after 251472 examples to avoid logging too frequently
skipping logging after 251488 examples to avoid logging too frequently
skipping logging after 251504 examples to avoid logging too frequently
train stats after 251520 examples: {'rewards_train/chosen': '0.20072', 'rewards_train/rejected': '-6.8367', 'rewards_train/margins': '7.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24457', 'examples_per_second': '6.0803', 'grad_norm': '4.5938', 'counters/examples': 251520, 'counters/updates': 15720}
skipping logging after 251536 examples to avoid logging too frequently
skipping logging after 251552 examples to avoid logging too frequently
skipping logging after 251568 examples to avoid logging too frequently
train stats after 251584 examples: {'rewards_train/chosen': '-0.10728', 'rewards_train/rejected': '-7.2029', 'rewards_train/margins': '7.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2605', 'examples_per_second': '4.776', 'grad_norm': '5.7812', 'counters/examples': 251584, 'counters/updates': 15724}
skipping logging after 251600 examples to avoid logging too frequently
skipping logging after 251616 examples to avoid logging too frequently
skipping logging after 251632 examples to avoid logging too frequently
train stats after 251648 examples: {'rewards_train/chosen': '0.37241', 'rewards_train/rejected': '-6.2302', 'rewards_train/margins': '6.7656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22638', 'examples_per_second': '4.313', 'grad_norm': '4.5938', 'counters/examples': 251648, 'counters/updates': 15728}
skipping logging after 251664 examples to avoid logging too frequently
skipping logging after 251680 examples to avoid logging too frequently
skipping logging after 251696 examples to avoid logging too frequently
train stats after 251712 examples: {'rewards_train/chosen': '0.1401', 'rewards_train/rejected': '-5.8907', 'rewards_train/margins': '6.3828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24725', 'examples_per_second': '6.1573', 'grad_norm': '4.875', 'counters/examples': 251712, 'counters/updates': 15732}
skipping logging after 251728 examples to avoid logging too frequently
skipping logging after 251744 examples to avoid logging too frequently
skipping logging after 251760 examples to avoid logging too frequently
train stats after 251776 examples: {'rewards_train/chosen': '-0.089978', 'rewards_train/rejected': '-5.8363', 'rewards_train/margins': '5.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25244', 'examples_per_second': '5.5508', 'grad_norm': '4.875', 'counters/examples': 251776, 'counters/updates': 15736}
skipping logging after 251792 examples to avoid logging too frequently
skipping logging after 251808 examples to avoid logging too frequently
skipping logging after 251824 examples to avoid logging too frequently
train stats after 251840 examples: {'rewards_train/chosen': '-0.0068427', 'rewards_train/rejected': '-6.8019', 'rewards_train/margins': '6.8203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2475', 'examples_per_second': '5.5597', 'grad_norm': '5.0312', 'counters/examples': 251840, 'counters/updates': 15740}
skipping logging after 251856 examples to avoid logging too frequently
skipping logging after 251872 examples to avoid logging too frequently
skipping logging after 251888 examples to avoid logging too frequently
train stats after 251904 examples: {'rewards_train/chosen': '0.32509', 'rewards_train/rejected': '-6.5171', 'rewards_train/margins': '6.5469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22363', 'examples_per_second': '5.3673', 'grad_norm': '4.9688', 'counters/examples': 251904, 'counters/updates': 15744}
skipping logging after 251920 examples to avoid logging too frequently
skipping logging after 251936 examples to avoid logging too frequently
skipping logging after 251952 examples to avoid logging too frequently
train stats after 251968 examples: {'rewards_train/chosen': '0.40659', 'rewards_train/rejected': '-4.6304', 'rewards_train/margins': '5.0039', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22339', 'examples_per_second': '4.949', 'grad_norm': '5.2188', 'counters/examples': 251968, 'counters/updates': 15748}
skipping logging after 251984 examples to avoid logging too frequently
skipping logging after 252000 examples to avoid logging too frequently
Running evaluation after 252000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:51,  1.67s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:42,  1.43s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:36,  1.26s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.49s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.69s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:09<00:38,  1.50s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:10<00:34,  1.38s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.53s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.49s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:31,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.41s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.39s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:20<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:21<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.28s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:28<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.31s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.20s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:40<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:41<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]
eval after 252000: {'rewards_eval/chosen': '-5.8215', 'rewards_eval/rejected': '-6.3651', 'rewards_eval/margins': '0.38086', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.45852'}
skipping logging after 252016 examples to avoid logging too frequently
train stats after 252032 examples: {'rewards_train/chosen': '0.10912', 'rewards_train/rejected': '-7.1734', 'rewards_train/margins': '7.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26428', 'examples_per_second': '5.1239', 'grad_norm': '4.875', 'counters/examples': 252032, 'counters/updates': 15752}
skipping logging after 252048 examples to avoid logging too frequently
skipping logging after 252064 examples to avoid logging too frequently
skipping logging after 252080 examples to avoid logging too frequently
train stats after 252096 examples: {'rewards_train/chosen': '0.3436', 'rewards_train/rejected': '-5.617', 'rewards_train/margins': '5.9258', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22839', 'examples_per_second': '4.5357', 'grad_norm': '4.5312', 'counters/examples': 252096, 'counters/updates': 15756}
skipping logging after 252112 examples to avoid logging too frequently
skipping logging after 252128 examples to avoid logging too frequently
skipping logging after 252144 examples to avoid logging too frequently
train stats after 252160 examples: {'rewards_train/chosen': '0.56925', 'rewards_train/rejected': '-5.5012', 'rewards_train/margins': '6.0156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18695', 'examples_per_second': '5.1514', 'grad_norm': '4.4375', 'counters/examples': 252160, 'counters/updates': 15760}
skipping logging after 252176 examples to avoid logging too frequently
skipping logging after 252192 examples to avoid logging too frequently
skipping logging after 252208 examples to avoid logging too frequently
train stats after 252224 examples: {'rewards_train/chosen': '0.20156', 'rewards_train/rejected': '-5.3738', 'rewards_train/margins': '5.5938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26385', 'examples_per_second': '5.4213', 'grad_norm': '5.2188', 'counters/examples': 252224, 'counters/updates': 15764}
skipping logging after 252240 examples to avoid logging too frequently
skipping logging after 252256 examples to avoid logging too frequently
skipping logging after 252272 examples to avoid logging too frequently
train stats after 252288 examples: {'rewards_train/chosen': '0.086498', 'rewards_train/rejected': '-6.6094', 'rewards_train/margins': '6.6484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27063', 'examples_per_second': '5.6908', 'grad_norm': '5.5312', 'counters/examples': 252288, 'counters/updates': 15768}
skipping logging after 252304 examples to avoid logging too frequently
skipping logging after 252320 examples to avoid logging too frequently
skipping logging after 252336 examples to avoid logging too frequently
train stats after 252352 examples: {'rewards_train/chosen': '0.61618', 'rewards_train/rejected': '-6.7407', 'rewards_train/margins': '7.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20758', 'examples_per_second': '4.7102', 'grad_norm': '6.3125', 'counters/examples': 252352, 'counters/updates': 15772}
skipping logging after 252368 examples to avoid logging too frequently
skipping logging after 252384 examples to avoid logging too frequently
skipping logging after 252400 examples to avoid logging too frequently
train stats after 252416 examples: {'rewards_train/chosen': '0.26631', 'rewards_train/rejected': '-6.1514', 'rewards_train/margins': '6.4609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23187', 'examples_per_second': '5.3557', 'grad_norm': '5.875', 'counters/examples': 252416, 'counters/updates': 15776}
skipping logging after 252432 examples to avoid logging too frequently
skipping logging after 252448 examples to avoid logging too frequently
skipping logging after 252464 examples to avoid logging too frequently
train stats after 252480 examples: {'rewards_train/chosen': '0.36589', 'rewards_train/rejected': '-6.0148', 'rewards_train/margins': '6.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24603', 'examples_per_second': '5.0189', 'grad_norm': '4.3438', 'counters/examples': 252480, 'counters/updates': 15780}
skipping logging after 252496 examples to avoid logging too frequently
skipping logging after 252512 examples to avoid logging too frequently
skipping logging after 252528 examples to avoid logging too frequently
train stats after 252544 examples: {'rewards_train/chosen': '0.41096', 'rewards_train/rejected': '-6.4427', 'rewards_train/margins': '7.2422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26495', 'examples_per_second': '4.0701', 'grad_norm': '4.6562', 'counters/examples': 252544, 'counters/updates': 15784}
skipping logging after 252560 examples to avoid logging too frequently
skipping logging after 252576 examples to avoid logging too frequently
skipping logging after 252592 examples to avoid logging too frequently
train stats after 252608 examples: {'rewards_train/chosen': '0.56274', 'rewards_train/rejected': '-5.4359', 'rewards_train/margins': '6.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20813', 'examples_per_second': '4.6175', 'grad_norm': '4.9062', 'counters/examples': 252608, 'counters/updates': 15788}
skipping logging after 252624 examples to avoid logging too frequently
skipping logging after 252640 examples to avoid logging too frequently
skipping logging after 252656 examples to avoid logging too frequently
train stats after 252672 examples: {'rewards_train/chosen': '0.39871', 'rewards_train/rejected': '-5.8885', 'rewards_train/margins': '6.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22394', 'examples_per_second': '5.1139', 'grad_norm': '6.9688', 'counters/examples': 252672, 'counters/updates': 15792}
skipping logging after 252688 examples to avoid logging too frequently
skipping logging after 252704 examples to avoid logging too frequently
skipping logging after 252720 examples to avoid logging too frequently
train stats after 252736 examples: {'rewards_train/chosen': '0.37922', 'rewards_train/rejected': '-5.1315', 'rewards_train/margins': '5.5898', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26868', 'examples_per_second': '6.3914', 'grad_norm': '6.4062', 'counters/examples': 252736, 'counters/updates': 15796}
skipping logging after 252752 examples to avoid logging too frequently
skipping logging after 252768 examples to avoid logging too frequently
skipping logging after 252784 examples to avoid logging too frequently
train stats after 252800 examples: {'rewards_train/chosen': '0.54839', 'rewards_train/rejected': '-6.3198', 'rewards_train/margins': '6.9375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25989', 'examples_per_second': '5.1638', 'grad_norm': '5', 'counters/examples': 252800, 'counters/updates': 15800}
skipping logging after 252816 examples to avoid logging too frequently
skipping logging after 252832 examples to avoid logging too frequently
skipping logging after 252848 examples to avoid logging too frequently
train stats after 252864 examples: {'rewards_train/chosen': '0.46607', 'rewards_train/rejected': '-6.2238', 'rewards_train/margins': '6.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20471', 'examples_per_second': '6.1121', 'grad_norm': '4.625', 'counters/examples': 252864, 'counters/updates': 15804}
skipping logging after 252880 examples to avoid logging too frequently
skipping logging after 252896 examples to avoid logging too frequently
skipping logging after 252912 examples to avoid logging too frequently
train stats after 252928 examples: {'rewards_train/chosen': '0.40202', 'rewards_train/rejected': '-6.0568', 'rewards_train/margins': '6.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19348', 'examples_per_second': '4.7886', 'grad_norm': '4.4688', 'counters/examples': 252928, 'counters/updates': 15808}
skipping logging after 252944 examples to avoid logging too frequently
skipping logging after 252960 examples to avoid logging too frequently
skipping logging after 252976 examples to avoid logging too frequently
train stats after 252992 examples: {'rewards_train/chosen': '-0.50476', 'rewards_train/rejected': '-5.9751', 'rewards_train/margins': '5.4219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2674', 'examples_per_second': '4.825', 'grad_norm': '5.6562', 'counters/examples': 252992, 'counters/updates': 15812}
skipping logging after 253008 examples to avoid logging too frequently
skipping logging after 253024 examples to avoid logging too frequently
skipping logging after 253040 examples to avoid logging too frequently
train stats after 253056 examples: {'rewards_train/chosen': '0.32904', 'rewards_train/rejected': '-5.7596', 'rewards_train/margins': '6.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27368', 'examples_per_second': '5.0453', 'grad_norm': '5.4375', 'counters/examples': 253056, 'counters/updates': 15816}
skipping logging after 253072 examples to avoid logging too frequently
skipping logging after 253088 examples to avoid logging too frequently
skipping logging after 253104 examples to avoid logging too frequently
train stats after 253120 examples: {'rewards_train/chosen': '0.39995', 'rewards_train/rejected': '-6.5119', 'rewards_train/margins': '6.8984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19678', 'examples_per_second': '4.8114', 'grad_norm': '4.5625', 'counters/examples': 253120, 'counters/updates': 15820}
skipping logging after 253136 examples to avoid logging too frequently
skipping logging after 253152 examples to avoid logging too frequently
skipping logging after 253168 examples to avoid logging too frequently
train stats after 253184 examples: {'rewards_train/chosen': '0.33604', 'rewards_train/rejected': '-5.671', 'rewards_train/margins': '5.7734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21216', 'examples_per_second': '5.6729', 'grad_norm': '4.375', 'counters/examples': 253184, 'counters/updates': 15824}
skipping logging after 253200 examples to avoid logging too frequently
skipping logging after 253216 examples to avoid logging too frequently
skipping logging after 253232 examples to avoid logging too frequently
train stats after 253248 examples: {'rewards_train/chosen': '0.36702', 'rewards_train/rejected': '-5.2394', 'rewards_train/margins': '5.8828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25531', 'examples_per_second': '4.9061', 'grad_norm': '5.4688', 'counters/examples': 253248, 'counters/updates': 15828}
skipping logging after 253264 examples to avoid logging too frequently
skipping logging after 253280 examples to avoid logging too frequently
skipping logging after 253296 examples to avoid logging too frequently
train stats after 253312 examples: {'rewards_train/chosen': '0.26951', 'rewards_train/rejected': '-6.6701', 'rewards_train/margins': '7.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25934', 'examples_per_second': '5.0542', 'grad_norm': '4.875', 'counters/examples': 253312, 'counters/updates': 15832}
skipping logging after 253328 examples to avoid logging too frequently
skipping logging after 253344 examples to avoid logging too frequently
skipping logging after 253360 examples to avoid logging too frequently
train stats after 253376 examples: {'rewards_train/chosen': '0.46144', 'rewards_train/rejected': '-6.2567', 'rewards_train/margins': '6.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24738', 'examples_per_second': '5.5902', 'grad_norm': '5.375', 'counters/examples': 253376, 'counters/updates': 15836}
skipping logging after 253392 examples to avoid logging too frequently
skipping logging after 253408 examples to avoid logging too frequently
skipping logging after 253424 examples to avoid logging too frequently
train stats after 253440 examples: {'rewards_train/chosen': '0.18372', 'rewards_train/rejected': '-5.9393', 'rewards_train/margins': '5.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21753', 'examples_per_second': '4.8265', 'grad_norm': '4.9062', 'counters/examples': 253440, 'counters/updates': 15840}
skipping logging after 253456 examples to avoid logging too frequently
skipping logging after 253472 examples to avoid logging too frequently
skipping logging after 253488 examples to avoid logging too frequently
train stats after 253504 examples: {'rewards_train/chosen': '0.54382', 'rewards_train/rejected': '-5.2019', 'rewards_train/margins': '5.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25598', 'examples_per_second': '4.8225', 'grad_norm': '4.625', 'counters/examples': 253504, 'counters/updates': 15844}
skipping logging after 253520 examples to avoid logging too frequently
skipping logging after 253536 examples to avoid logging too frequently
skipping logging after 253552 examples to avoid logging too frequently
train stats after 253568 examples: {'rewards_train/chosen': '0.15802', 'rewards_train/rejected': '-6.054', 'rewards_train/margins': '6.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23108', 'examples_per_second': '4.1321', 'grad_norm': '5.1875', 'counters/examples': 253568, 'counters/updates': 15848}
skipping logging after 253584 examples to avoid logging too frequently
skipping logging after 253600 examples to avoid logging too frequently
skipping logging after 253616 examples to avoid logging too frequently
train stats after 253632 examples: {'rewards_train/chosen': '0.37646', 'rewards_train/rejected': '-7.1791', 'rewards_train/margins': '7.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20673', 'examples_per_second': '4.6762', 'grad_norm': '4.5', 'counters/examples': 253632, 'counters/updates': 15852}
skipping logging after 253648 examples to avoid logging too frequently
skipping logging after 253664 examples to avoid logging too frequently
skipping logging after 253680 examples to avoid logging too frequently
train stats after 253696 examples: {'rewards_train/chosen': '0.23002', 'rewards_train/rejected': '-5.7663', 'rewards_train/margins': '5.8633', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21265', 'examples_per_second': '4.7561', 'grad_norm': '5', 'counters/examples': 253696, 'counters/updates': 15856}
skipping logging after 253712 examples to avoid logging too frequently
skipping logging after 253728 examples to avoid logging too frequently
skipping logging after 253744 examples to avoid logging too frequently
train stats after 253760 examples: {'rewards_train/chosen': '0.12501', 'rewards_train/rejected': '-5.5345', 'rewards_train/margins': '5.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27124', 'examples_per_second': '5.2438', 'grad_norm': '5.5312', 'counters/examples': 253760, 'counters/updates': 15860}
skipping logging after 253776 examples to avoid logging too frequently
skipping logging after 253792 examples to avoid logging too frequently
skipping logging after 253808 examples to avoid logging too frequently
train stats after 253824 examples: {'rewards_train/chosen': '0.50616', 'rewards_train/rejected': '-6.0723', 'rewards_train/margins': '6.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23126', 'examples_per_second': '4.9659', 'grad_norm': '5.3438', 'counters/examples': 253824, 'counters/updates': 15864}
skipping logging after 253840 examples to avoid logging too frequently
skipping logging after 253856 examples to avoid logging too frequently
skipping logging after 253872 examples to avoid logging too frequently
train stats after 253888 examples: {'rewards_train/chosen': '0.34121', 'rewards_train/rejected': '-6.8776', 'rewards_train/margins': '6.9375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20422', 'examples_per_second': '4.9117', 'grad_norm': '3.9062', 'counters/examples': 253888, 'counters/updates': 15868}
skipping logging after 253904 examples to avoid logging too frequently
skipping logging after 253920 examples to avoid logging too frequently
skipping logging after 253936 examples to avoid logging too frequently
train stats after 253952 examples: {'rewards_train/chosen': '-0.17282', 'rewards_train/rejected': '-6.3824', 'rewards_train/margins': '6.3828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23993', 'examples_per_second': '6.6033', 'grad_norm': '4.4375', 'counters/examples': 253952, 'counters/updates': 15872}
skipping logging after 253968 examples to avoid logging too frequently
skipping logging after 253984 examples to avoid logging too frequently
skipping logging after 254000 examples to avoid logging too frequently
train stats after 254016 examples: {'rewards_train/chosen': '0.077522', 'rewards_train/rejected': '-6.6498', 'rewards_train/margins': '6.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25232', 'examples_per_second': '4.8614', 'grad_norm': '4.9375', 'counters/examples': 254016, 'counters/updates': 15876}
skipping logging after 254032 examples to avoid logging too frequently
skipping logging after 254048 examples to avoid logging too frequently
skipping logging after 254064 examples to avoid logging too frequently
train stats after 254080 examples: {'rewards_train/chosen': '0.24596', 'rewards_train/rejected': '-5.7539', 'rewards_train/margins': '5.4883', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28143', 'examples_per_second': '4.9092', 'grad_norm': '5.75', 'counters/examples': 254080, 'counters/updates': 15880}
skipping logging after 254096 examples to avoid logging too frequently
skipping logging after 254112 examples to avoid logging too frequently
skipping logging after 254128 examples to avoid logging too frequently
train stats after 254144 examples: {'rewards_train/chosen': '0.067078', 'rewards_train/rejected': '-5.2904', 'rewards_train/margins': '5.3672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26019', 'examples_per_second': '4.942', 'grad_norm': '4.4688', 'counters/examples': 254144, 'counters/updates': 15884}
skipping logging after 254160 examples to avoid logging too frequently
skipping logging after 254176 examples to avoid logging too frequently
skipping logging after 254192 examples to avoid logging too frequently
train stats after 254208 examples: {'rewards_train/chosen': '0.3131', 'rewards_train/rejected': '-5.0902', 'rewards_train/margins': '5.5469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24414', 'examples_per_second': '4.5589', 'grad_norm': '4.7188', 'counters/examples': 254208, 'counters/updates': 15888}
skipping logging after 254224 examples to avoid logging too frequently
skipping logging after 254240 examples to avoid logging too frequently
skipping logging after 254256 examples to avoid logging too frequently
train stats after 254272 examples: {'rewards_train/chosen': '0.28313', 'rewards_train/rejected': '-6.8734', 'rewards_train/margins': '7.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25922', 'examples_per_second': '4.6603', 'grad_norm': '6.2812', 'counters/examples': 254272, 'counters/updates': 15892}
skipping logging after 254288 examples to avoid logging too frequently
skipping logging after 254304 examples to avoid logging too frequently
skipping logging after 254320 examples to avoid logging too frequently
train stats after 254336 examples: {'rewards_train/chosen': '0.33627', 'rewards_train/rejected': '-5.5501', 'rewards_train/margins': '5.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2937', 'examples_per_second': '5.22', 'grad_norm': '5.1562', 'counters/examples': 254336, 'counters/updates': 15896}
skipping logging after 254352 examples to avoid logging too frequently
skipping logging after 254368 examples to avoid logging too frequently
skipping logging after 254384 examples to avoid logging too frequently
train stats after 254400 examples: {'rewards_train/chosen': '0.41697', 'rewards_train/rejected': '-6.2081', 'rewards_train/margins': '6.582', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25586', 'examples_per_second': '4.2995', 'grad_norm': '5.6562', 'counters/examples': 254400, 'counters/updates': 15900}
skipping logging after 254416 examples to avoid logging too frequently
skipping logging after 254432 examples to avoid logging too frequently
skipping logging after 254448 examples to avoid logging too frequently
train stats after 254464 examples: {'rewards_train/chosen': '0.22645', 'rewards_train/rejected': '-5.3845', 'rewards_train/margins': '5.4141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22656', 'examples_per_second': '4.5573', 'grad_norm': '4.7188', 'counters/examples': 254464, 'counters/updates': 15904}
skipping logging after 254480 examples to avoid logging too frequently
skipping logging after 254496 examples to avoid logging too frequently
skipping logging after 254512 examples to avoid logging too frequently
train stats after 254528 examples: {'rewards_train/chosen': '0.3951', 'rewards_train/rejected': '-6.0583', 'rewards_train/margins': '6.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18683', 'examples_per_second': '5.5419', 'grad_norm': '4.5312', 'counters/examples': 254528, 'counters/updates': 15908}
skipping logging after 254544 examples to avoid logging too frequently
skipping logging after 254560 examples to avoid logging too frequently
skipping logging after 254576 examples to avoid logging too frequently
train stats after 254592 examples: {'rewards_train/chosen': '-0.024503', 'rewards_train/rejected': '-6.3776', 'rewards_train/margins': '7.0859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28345', 'examples_per_second': '5.147', 'grad_norm': '7.1562', 'counters/examples': 254592, 'counters/updates': 15912}
skipping logging after 254608 examples to avoid logging too frequently
skipping logging after 254624 examples to avoid logging too frequently
skipping logging after 254640 examples to avoid logging too frequently
train stats after 254656 examples: {'rewards_train/chosen': '0.43857', 'rewards_train/rejected': '-5.0829', 'rewards_train/margins': '5.6016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19446', 'examples_per_second': '5.0212', 'grad_norm': '4.5938', 'counters/examples': 254656, 'counters/updates': 15916}
skipping logging after 254672 examples to avoid logging too frequently
skipping logging after 254688 examples to avoid logging too frequently
skipping logging after 254704 examples to avoid logging too frequently
train stats after 254720 examples: {'rewards_train/chosen': '0.54312', 'rewards_train/rejected': '-6.2323', 'rewards_train/margins': '6.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19537', 'examples_per_second': '5.1724', 'grad_norm': '5.4688', 'counters/examples': 254720, 'counters/updates': 15920}
skipping logging after 254736 examples to avoid logging too frequently
skipping logging after 254752 examples to avoid logging too frequently
skipping logging after 254768 examples to avoid logging too frequently
train stats after 254784 examples: {'rewards_train/chosen': '-0.35716', 'rewards_train/rejected': '-6.5039', 'rewards_train/margins': '6.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.31885', 'examples_per_second': '4.8939', 'grad_norm': '6.375', 'counters/examples': 254784, 'counters/updates': 15924}
skipping logging after 254800 examples to avoid logging too frequently
skipping logging after 254816 examples to avoid logging too frequently
skipping logging after 254832 examples to avoid logging too frequently
train stats after 254848 examples: {'rewards_train/chosen': '-0.0045277', 'rewards_train/rejected': '-4.9786', 'rewards_train/margins': '4.9297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25867', 'examples_per_second': '6.6682', 'grad_norm': '5.0938', 'counters/examples': 254848, 'counters/updates': 15928}
skipping logging after 254864 examples to avoid logging too frequently
skipping logging after 254880 examples to avoid logging too frequently
skipping logging after 254896 examples to avoid logging too frequently
train stats after 254912 examples: {'rewards_train/chosen': '0.083029', 'rewards_train/rejected': '-5.8202', 'rewards_train/margins': '6.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2702', 'examples_per_second': '5.4684', 'grad_norm': '5.125', 'counters/examples': 254912, 'counters/updates': 15932}
skipping logging after 254928 examples to avoid logging too frequently
skipping logging after 254944 examples to avoid logging too frequently
skipping logging after 254960 examples to avoid logging too frequently
train stats after 254976 examples: {'rewards_train/chosen': '0.62049', 'rewards_train/rejected': '-6.9116', 'rewards_train/margins': '7.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19928', 'examples_per_second': '4.9491', 'grad_norm': '4.1875', 'counters/examples': 254976, 'counters/updates': 15936}
skipping logging after 254992 examples to avoid logging too frequently
skipping logging after 255008 examples to avoid logging too frequently
skipping logging after 255024 examples to avoid logging too frequently
train stats after 255040 examples: {'rewards_train/chosen': '0.25827', 'rewards_train/rejected': '-6.4819', 'rewards_train/margins': '6.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26587', 'examples_per_second': '6.3276', 'grad_norm': '4.875', 'counters/examples': 255040, 'counters/updates': 15940}
skipping logging after 255056 examples to avoid logging too frequently
skipping logging after 255072 examples to avoid logging too frequently
skipping logging after 255088 examples to avoid logging too frequently
train stats after 255104 examples: {'rewards_train/chosen': '0.49337', 'rewards_train/rejected': '-5.0066', 'rewards_train/margins': '5.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23486', 'examples_per_second': '5.2408', 'grad_norm': '5.4062', 'counters/examples': 255104, 'counters/updates': 15944}
skipping logging after 255120 examples to avoid logging too frequently
skipping logging after 255136 examples to avoid logging too frequently
skipping logging after 255152 examples to avoid logging too frequently
train stats after 255168 examples: {'rewards_train/chosen': '0.1816', 'rewards_train/rejected': '-6.3119', 'rewards_train/margins': '6.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21082', 'examples_per_second': '5.2971', 'grad_norm': '4.6875', 'counters/examples': 255168, 'counters/updates': 15948}
skipping logging after 255184 examples to avoid logging too frequently
skipping logging after 255200 examples to avoid logging too frequently
skipping logging after 255216 examples to avoid logging too frequently
train stats after 255232 examples: {'rewards_train/chosen': '0.52878', 'rewards_train/rejected': '-5.9329', 'rewards_train/margins': '6.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.16125', 'examples_per_second': '5.5037', 'grad_norm': '5.5938', 'counters/examples': 255232, 'counters/updates': 15952}
skipping logging after 255248 examples to avoid logging too frequently
skipping logging after 255264 examples to avoid logging too frequently
skipping logging after 255280 examples to avoid logging too frequently
train stats after 255296 examples: {'rewards_train/chosen': '0.3641', 'rewards_train/rejected': '-5.1784', 'rewards_train/margins': '5.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26678', 'examples_per_second': '4.6787', 'grad_norm': '6.4062', 'counters/examples': 255296, 'counters/updates': 15956}
skipping logging after 255312 examples to avoid logging too frequently
skipping logging after 255328 examples to avoid logging too frequently
skipping logging after 255344 examples to avoid logging too frequently
train stats after 255360 examples: {'rewards_train/chosen': '0.26966', 'rewards_train/rejected': '-6.0096', 'rewards_train/margins': '6.1406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26587', 'examples_per_second': '4.9366', 'grad_norm': '4.8125', 'counters/examples': 255360, 'counters/updates': 15960}
skipping logging after 255376 examples to avoid logging too frequently
skipping logging after 255392 examples to avoid logging too frequently
skipping logging after 255408 examples to avoid logging too frequently
train stats after 255424 examples: {'rewards_train/chosen': '0.3894', 'rewards_train/rejected': '-6.8262', 'rewards_train/margins': '7.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27197', 'examples_per_second': '6.0338', 'grad_norm': '5.3125', 'counters/examples': 255424, 'counters/updates': 15964}
skipping logging after 255440 examples to avoid logging too frequently
skipping logging after 255456 examples to avoid logging too frequently
skipping logging after 255472 examples to avoid logging too frequently
train stats after 255488 examples: {'rewards_train/chosen': '0.33409', 'rewards_train/rejected': '-5.5731', 'rewards_train/margins': '6.2227', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19275', 'examples_per_second': '4.9907', 'grad_norm': '4.0312', 'counters/examples': 255488, 'counters/updates': 15968}
skipping logging after 255504 examples to avoid logging too frequently
skipping logging after 255520 examples to avoid logging too frequently
skipping logging after 255536 examples to avoid logging too frequently
train stats after 255552 examples: {'rewards_train/chosen': '0.29629', 'rewards_train/rejected': '-6.4392', 'rewards_train/margins': '6.4141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24615', 'examples_per_second': '4.5502', 'grad_norm': '5.125', 'counters/examples': 255552, 'counters/updates': 15972}
skipping logging after 255568 examples to avoid logging too frequently
skipping logging after 255584 examples to avoid logging too frequently
skipping logging after 255600 examples to avoid logging too frequently
train stats after 255616 examples: {'rewards_train/chosen': '0.12222', 'rewards_train/rejected': '-6.1708', 'rewards_train/margins': '6.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26929', 'examples_per_second': '4.4723', 'grad_norm': '5.4375', 'counters/examples': 255616, 'counters/updates': 15976}
skipping logging after 255632 examples to avoid logging too frequently
skipping logging after 255648 examples to avoid logging too frequently
skipping logging after 255664 examples to avoid logging too frequently
train stats after 255680 examples: {'rewards_train/chosen': '0.2646', 'rewards_train/rejected': '-5.6762', 'rewards_train/margins': '6.1875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24445', 'examples_per_second': '6.3198', 'grad_norm': '5.0938', 'counters/examples': 255680, 'counters/updates': 15980}
skipping logging after 255696 examples to avoid logging too frequently
skipping logging after 255712 examples to avoid logging too frequently
skipping logging after 255728 examples to avoid logging too frequently
train stats after 255744 examples: {'rewards_train/chosen': '0.39234', 'rewards_train/rejected': '-5.7632', 'rewards_train/margins': '6.3594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22009', 'examples_per_second': '5.6642', 'grad_norm': '4.8125', 'counters/examples': 255744, 'counters/updates': 15984}
skipping logging after 255760 examples to avoid logging too frequently
skipping logging after 255776 examples to avoid logging too frequently
skipping logging after 255792 examples to avoid logging too frequently
train stats after 255808 examples: {'rewards_train/chosen': '0.54889', 'rewards_train/rejected': '-6.1218', 'rewards_train/margins': '6.8125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17346', 'examples_per_second': '4.9754', 'grad_norm': '5.1562', 'counters/examples': 255808, 'counters/updates': 15988}
skipping logging after 255824 examples to avoid logging too frequently
skipping logging after 255840 examples to avoid logging too frequently
skipping logging after 255856 examples to avoid logging too frequently
train stats after 255872 examples: {'rewards_train/chosen': '0.64777', 'rewards_train/rejected': '-7.4155', 'rewards_train/margins': '7.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19128', 'examples_per_second': '4.2434', 'grad_norm': '3.8438', 'counters/examples': 255872, 'counters/updates': 15992}
skipping logging after 255888 examples to avoid logging too frequently
skipping logging after 255904 examples to avoid logging too frequently
skipping logging after 255920 examples to avoid logging too frequently
train stats after 255936 examples: {'rewards_train/chosen': '0.060617', 'rewards_train/rejected': '-5.3857', 'rewards_train/margins': '5.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21661', 'examples_per_second': '6.1751', 'grad_norm': '4.75', 'counters/examples': 255936, 'counters/updates': 15996}
skipping logging after 255952 examples to avoid logging too frequently
skipping logging after 255968 examples to avoid logging too frequently
skipping logging after 255984 examples to avoid logging too frequently
train stats after 256000 examples: {'rewards_train/chosen': '0.47841', 'rewards_train/rejected': '-6.829', 'rewards_train/margins': '7.1953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18341', 'examples_per_second': '4.8237', 'grad_norm': '4.0312', 'counters/examples': 256000, 'counters/updates': 16000}
Running evaluation after 256000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.25s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.16s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:39,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.65s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.47s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:34,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.40s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.39s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.28s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.51s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.31s/it]
eval after 256000: {'rewards_eval/chosen': '-5.8683', 'rewards_eval/rejected': '-6.5144', 'rewards_eval/margins': '0.48926', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.45717'}
skipping logging after 256016 examples to avoid logging too frequently
skipping logging after 256032 examples to avoid logging too frequently
skipping logging after 256048 examples to avoid logging too frequently
train stats after 256064 examples: {'rewards_train/chosen': '0.21357', 'rewards_train/rejected': '-4.2671', 'rewards_train/margins': '4.6133', 'rewards_train/KL_estimate': '0', 'loss/train': '0.3017', 'examples_per_second': '5.6267', 'grad_norm': '6.2812', 'counters/examples': 256064, 'counters/updates': 16004}
skipping logging after 256080 examples to avoid logging too frequently
skipping logging after 256096 examples to avoid logging too frequently
skipping logging after 256112 examples to avoid logging too frequently
train stats after 256128 examples: {'rewards_train/chosen': '0.43085', 'rewards_train/rejected': '-5.8793', 'rewards_train/margins': '6.4219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23822', 'examples_per_second': '5.1994', 'grad_norm': '5.2812', 'counters/examples': 256128, 'counters/updates': 16008}
skipping logging after 256144 examples to avoid logging too frequently
skipping logging after 256160 examples to avoid logging too frequently
skipping logging after 256176 examples to avoid logging too frequently
train stats after 256192 examples: {'rewards_train/chosen': '-0.26563', 'rewards_train/rejected': '-5.5378', 'rewards_train/margins': '5.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23279', 'examples_per_second': '5.6181', 'grad_norm': '5.125', 'counters/examples': 256192, 'counters/updates': 16012}
skipping logging after 256208 examples to avoid logging too frequently
skipping logging after 256224 examples to avoid logging too frequently
skipping logging after 256240 examples to avoid logging too frequently
train stats after 256256 examples: {'rewards_train/chosen': '0.17302', 'rewards_train/rejected': '-5.1939', 'rewards_train/margins': '5.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29193', 'examples_per_second': '5.0589', 'grad_norm': '4.875', 'counters/examples': 256256, 'counters/updates': 16016}
skipping logging after 256272 examples to avoid logging too frequently
skipping logging after 256288 examples to avoid logging too frequently
skipping logging after 256304 examples to avoid logging too frequently
train stats after 256320 examples: {'rewards_train/chosen': '0.035113', 'rewards_train/rejected': '-5.0704', 'rewards_train/margins': '5.1055', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27301', 'examples_per_second': '4.8578', 'grad_norm': '6.0312', 'counters/examples': 256320, 'counters/updates': 16020}
skipping logging after 256336 examples to avoid logging too frequently
skipping logging after 256352 examples to avoid logging too frequently
skipping logging after 256368 examples to avoid logging too frequently
train stats after 256384 examples: {'rewards_train/chosen': '0.29861', 'rewards_train/rejected': '-6.4843', 'rewards_train/margins': '6.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27118', 'examples_per_second': '4.7614', 'grad_norm': '6.625', 'counters/examples': 256384, 'counters/updates': 16024}
skipping logging after 256400 examples to avoid logging too frequently
skipping logging after 256416 examples to avoid logging too frequently
skipping logging after 256432 examples to avoid logging too frequently
train stats after 256448 examples: {'rewards_train/chosen': '0.48196', 'rewards_train/rejected': '-6.0085', 'rewards_train/margins': '6.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20898', 'examples_per_second': '5.897', 'grad_norm': '4.7812', 'counters/examples': 256448, 'counters/updates': 16028}
skipping logging after 256464 examples to avoid logging too frequently
skipping logging after 256480 examples to avoid logging too frequently
skipping logging after 256496 examples to avoid logging too frequently
train stats after 256512 examples: {'rewards_train/chosen': '0.38422', 'rewards_train/rejected': '-6.0423', 'rewards_train/margins': '6.5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23468', 'examples_per_second': '4.9577', 'grad_norm': '5', 'counters/examples': 256512, 'counters/updates': 16032}
skipping logging after 256528 examples to avoid logging too frequently
skipping logging after 256544 examples to avoid logging too frequently
skipping logging after 256560 examples to avoid logging too frequently
train stats after 256576 examples: {'rewards_train/chosen': '0.27256', 'rewards_train/rejected': '-4.8024', 'rewards_train/margins': '4.6758', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2879', 'examples_per_second': '5.6166', 'grad_norm': '4.9375', 'counters/examples': 256576, 'counters/updates': 16036}
skipping logging after 256592 examples to avoid logging too frequently
skipping logging after 256608 examples to avoid logging too frequently
skipping logging after 256624 examples to avoid logging too frequently
train stats after 256640 examples: {'rewards_train/chosen': '0.34845', 'rewards_train/rejected': '-5.7629', 'rewards_train/margins': '6.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27856', 'examples_per_second': '4.4963', 'grad_norm': '4.5938', 'counters/examples': 256640, 'counters/updates': 16040}
skipping logging after 256656 examples to avoid logging too frequently
skipping logging after 256672 examples to avoid logging too frequently
skipping logging after 256688 examples to avoid logging too frequently
train stats after 256704 examples: {'rewards_train/chosen': '0.53123', 'rewards_train/rejected': '-6.4352', 'rewards_train/margins': '7.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23395', 'examples_per_second': '5.5144', 'grad_norm': '4.5625', 'counters/examples': 256704, 'counters/updates': 16044}
skipping logging after 256720 examples to avoid logging too frequently
skipping logging after 256736 examples to avoid logging too frequently
skipping logging after 256752 examples to avoid logging too frequently
train stats after 256768 examples: {'rewards_train/chosen': '0.19402', 'rewards_train/rejected': '-5.0854', 'rewards_train/margins': '5.1953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27423', 'examples_per_second': '5.8988', 'grad_norm': '4.9688', 'counters/examples': 256768, 'counters/updates': 16048}
skipping logging after 256784 examples to avoid logging too frequently
skipping logging after 256800 examples to avoid logging too frequently
skipping logging after 256816 examples to avoid logging too frequently
train stats after 256832 examples: {'rewards_train/chosen': '-0.055516', 'rewards_train/rejected': '-5.2949', 'rewards_train/margins': '5.1289', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24341', 'examples_per_second': '6.3056', 'grad_norm': '5.2812', 'counters/examples': 256832, 'counters/updates': 16052}
skipping logging after 256848 examples to avoid logging too frequently
skipping logging after 256864 examples to avoid logging too frequently
skipping logging after 256880 examples to avoid logging too frequently
train stats after 256896 examples: {'rewards_train/chosen': '0.33727', 'rewards_train/rejected': '-6.2993', 'rewards_train/margins': '6.5781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19489', 'examples_per_second': '6.342', 'grad_norm': '5.125', 'counters/examples': 256896, 'counters/updates': 16056}
skipping logging after 256912 examples to avoid logging too frequently
skipping logging after 256928 examples to avoid logging too frequently
skipping logging after 256944 examples to avoid logging too frequently
train stats after 256960 examples: {'rewards_train/chosen': '-0.025439', 'rewards_train/rejected': '-5.6552', 'rewards_train/margins': '5.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25336', 'examples_per_second': '5.3513', 'grad_norm': '5.8125', 'counters/examples': 256960, 'counters/updates': 16060}
skipping logging after 256976 examples to avoid logging too frequently
skipping logging after 256992 examples to avoid logging too frequently
skipping logging after 257008 examples to avoid logging too frequently
train stats after 257024 examples: {'rewards_train/chosen': '0.1384', 'rewards_train/rejected': '-7.0994', 'rewards_train/margins': '7.2344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26593', 'examples_per_second': '5.5522', 'grad_norm': '5.4062', 'counters/examples': 257024, 'counters/updates': 16064}
skipping logging after 257040 examples to avoid logging too frequently
skipping logging after 257056 examples to avoid logging too frequently
skipping logging after 257072 examples to avoid logging too frequently
train stats after 257088 examples: {'rewards_train/chosen': '0.12612', 'rewards_train/rejected': '-5.8828', 'rewards_train/margins': '6.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25458', 'examples_per_second': '4.8942', 'grad_norm': '5.0625', 'counters/examples': 257088, 'counters/updates': 16068}
skipping logging after 257104 examples to avoid logging too frequently
skipping logging after 257120 examples to avoid logging too frequently
skipping logging after 257136 examples to avoid logging too frequently
train stats after 257152 examples: {'rewards_train/chosen': '0.0019551', 'rewards_train/rejected': '-5.6091', 'rewards_train/margins': '5.6328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26257', 'examples_per_second': '4.7054', 'grad_norm': '5.4375', 'counters/examples': 257152, 'counters/updates': 16072}
skipping logging after 257168 examples to avoid logging too frequently
skipping logging after 257184 examples to avoid logging too frequently
skipping logging after 257200 examples to avoid logging too frequently
train stats after 257216 examples: {'rewards_train/chosen': '0.51088', 'rewards_train/rejected': '-6.803', 'rewards_train/margins': '7.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2132', 'examples_per_second': '5.5464', 'grad_norm': '5.0938', 'counters/examples': 257216, 'counters/updates': 16076}
skipping logging after 257232 examples to avoid logging too frequently
skipping logging after 257248 examples to avoid logging too frequently
skipping logging after 257264 examples to avoid logging too frequently
train stats after 257280 examples: {'rewards_train/chosen': '0.37479', 'rewards_train/rejected': '-7.5325', 'rewards_train/margins': '7.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23792', 'examples_per_second': '4.3143', 'grad_norm': '4.4062', 'counters/examples': 257280, 'counters/updates': 16080}
skipping logging after 257296 examples to avoid logging too frequently
skipping logging after 257312 examples to avoid logging too frequently
skipping logging after 257328 examples to avoid logging too frequently
train stats after 257344 examples: {'rewards_train/chosen': '0.2595', 'rewards_train/rejected': '-5.034', 'rewards_train/margins': '5.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25519', 'examples_per_second': '6.1746', 'grad_norm': '4.875', 'counters/examples': 257344, 'counters/updates': 16084}
skipping logging after 257360 examples to avoid logging too frequently
skipping logging after 257376 examples to avoid logging too frequently
skipping logging after 257392 examples to avoid logging too frequently
train stats after 257408 examples: {'rewards_train/chosen': '0.1262', 'rewards_train/rejected': '-6.0924', 'rewards_train/margins': '6.0859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24792', 'examples_per_second': '6.3652', 'grad_norm': '4.5312', 'counters/examples': 257408, 'counters/updates': 16088}
skipping logging after 257424 examples to avoid logging too frequently
skipping logging after 257440 examples to avoid logging too frequently
skipping logging after 257456 examples to avoid logging too frequently
train stats after 257472 examples: {'rewards_train/chosen': '0.70786', 'rewards_train/rejected': '-4.9688', 'rewards_train/margins': '5.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18304', 'examples_per_second': '4.2467', 'grad_norm': '5.0625', 'counters/examples': 257472, 'counters/updates': 16092}
skipping logging after 257488 examples to avoid logging too frequently
skipping logging after 257504 examples to avoid logging too frequently
skipping logging after 257520 examples to avoid logging too frequently
train stats after 257536 examples: {'rewards_train/chosen': '0.34862', 'rewards_train/rejected': '-5.8805', 'rewards_train/margins': '6.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24725', 'examples_per_second': '5.3256', 'grad_norm': '5.5938', 'counters/examples': 257536, 'counters/updates': 16096}
skipping logging after 257552 examples to avoid logging too frequently
skipping logging after 257568 examples to avoid logging too frequently
skipping logging after 257584 examples to avoid logging too frequently
train stats after 257600 examples: {'rewards_train/chosen': '0.13477', 'rewards_train/rejected': '-6.78', 'rewards_train/margins': '7.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26166', 'examples_per_second': '6.226', 'grad_norm': '5.2812', 'counters/examples': 257600, 'counters/updates': 16100}
skipping logging after 257616 examples to avoid logging too frequently
skipping logging after 257632 examples to avoid logging too frequently
skipping logging after 257648 examples to avoid logging too frequently
train stats after 257664 examples: {'rewards_train/chosen': '0.57733', 'rewards_train/rejected': '-4.4484', 'rewards_train/margins': '4.9102', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25128', 'examples_per_second': '5.5655', 'grad_norm': '6.4062', 'counters/examples': 257664, 'counters/updates': 16104}
skipping logging after 257680 examples to avoid logging too frequently
skipping logging after 257696 examples to avoid logging too frequently
skipping logging after 257712 examples to avoid logging too frequently
train stats after 257728 examples: {'rewards_train/chosen': '0.08679', 'rewards_train/rejected': '-5.8647', 'rewards_train/margins': '6.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23865', 'examples_per_second': '4.4747', 'grad_norm': '4.5', 'counters/examples': 257728, 'counters/updates': 16108}
skipping logging after 257744 examples to avoid logging too frequently
skipping logging after 257760 examples to avoid logging too frequently
skipping logging after 257776 examples to avoid logging too frequently
train stats after 257792 examples: {'rewards_train/chosen': '0.50434', 'rewards_train/rejected': '-6.5391', 'rewards_train/margins': '6.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22375', 'examples_per_second': '5.0368', 'grad_norm': '5.0938', 'counters/examples': 257792, 'counters/updates': 16112}
skipping logging after 257808 examples to avoid logging too frequently
skipping logging after 257824 examples to avoid logging too frequently
skipping logging after 257840 examples to avoid logging too frequently
train stats after 257856 examples: {'rewards_train/chosen': '0.33197', 'rewards_train/rejected': '-5.5234', 'rewards_train/margins': '6.0547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28387', 'examples_per_second': '5.9238', 'grad_norm': '5.3125', 'counters/examples': 257856, 'counters/updates': 16116}
skipping logging after 257872 examples to avoid logging too frequently
skipping logging after 257888 examples to avoid logging too frequently
skipping logging after 257904 examples to avoid logging too frequently
train stats after 257920 examples: {'rewards_train/chosen': '0.044035', 'rewards_train/rejected': '-5.1633', 'rewards_train/margins': '5.4609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27936', 'examples_per_second': '4.4258', 'grad_norm': '6.2188', 'counters/examples': 257920, 'counters/updates': 16120}
skipping logging after 257936 examples to avoid logging too frequently
skipping logging after 257952 examples to avoid logging too frequently
skipping logging after 257968 examples to avoid logging too frequently
train stats after 257984 examples: {'rewards_train/chosen': '0.56804', 'rewards_train/rejected': '-6.69', 'rewards_train/margins': '7.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19958', 'examples_per_second': '5.0589', 'grad_norm': '4.8125', 'counters/examples': 257984, 'counters/updates': 16124}
skipping logging after 258000 examples to avoid logging too frequently
skipping logging after 258016 examples to avoid logging too frequently
skipping logging after 258032 examples to avoid logging too frequently
train stats after 258048 examples: {'rewards_train/chosen': '0.29298', 'rewards_train/rejected': '-5.7292', 'rewards_train/margins': '6.0234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25122', 'examples_per_second': '6.3406', 'grad_norm': '5.75', 'counters/examples': 258048, 'counters/updates': 16128}
skipping logging after 258064 examples to avoid logging too frequently
skipping logging after 258080 examples to avoid logging too frequently
skipping logging after 258096 examples to avoid logging too frequently
train stats after 258112 examples: {'rewards_train/chosen': '-0.020514', 'rewards_train/rejected': '-7.2152', 'rewards_train/margins': '7.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22821', 'examples_per_second': '5.3631', 'grad_norm': '4.7188', 'counters/examples': 258112, 'counters/updates': 16132}
skipping logging after 258128 examples to avoid logging too frequently
skipping logging after 258144 examples to avoid logging too frequently
skipping logging after 258160 examples to avoid logging too frequently
train stats after 258176 examples: {'rewards_train/chosen': '0.47804', 'rewards_train/rejected': '-6.7993', 'rewards_train/margins': '7.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26312', 'examples_per_second': '4.6097', 'grad_norm': '5.5312', 'counters/examples': 258176, 'counters/updates': 16136}
skipping logging after 258192 examples to avoid logging too frequently
skipping logging after 258208 examples to avoid logging too frequently
skipping logging after 258224 examples to avoid logging too frequently
train stats after 258240 examples: {'rewards_train/chosen': '-0.20513', 'rewards_train/rejected': '-7.3246', 'rewards_train/margins': '7.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20612', 'examples_per_second': '4.7737', 'grad_norm': '5.125', 'counters/examples': 258240, 'counters/updates': 16140}
skipping logging after 258256 examples to avoid logging too frequently
skipping logging after 258272 examples to avoid logging too frequently
skipping logging after 258288 examples to avoid logging too frequently
train stats after 258304 examples: {'rewards_train/chosen': '0.29744', 'rewards_train/rejected': '-6.5391', 'rewards_train/margins': '6.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27338', 'examples_per_second': '5.2348', 'grad_norm': '7.625', 'counters/examples': 258304, 'counters/updates': 16144}
skipping logging after 258320 examples to avoid logging too frequently
skipping logging after 258336 examples to avoid logging too frequently
skipping logging after 258352 examples to avoid logging too frequently
train stats after 258368 examples: {'rewards_train/chosen': '0.4109', 'rewards_train/rejected': '-6.0773', 'rewards_train/margins': '6.1016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2157', 'examples_per_second': '5.6188', 'grad_norm': '5.5938', 'counters/examples': 258368, 'counters/updates': 16148}
skipping logging after 258384 examples to avoid logging too frequently
skipping logging after 258400 examples to avoid logging too frequently
skipping logging after 258416 examples to avoid logging too frequently
train stats after 258432 examples: {'rewards_train/chosen': '0.23149', 'rewards_train/rejected': '-6.3137', 'rewards_train/margins': '6.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25262', 'examples_per_second': '5.3205', 'grad_norm': '5.3125', 'counters/examples': 258432, 'counters/updates': 16152}
skipping logging after 258448 examples to avoid logging too frequently
skipping logging after 258464 examples to avoid logging too frequently
skipping logging after 258480 examples to avoid logging too frequently
train stats after 258496 examples: {'rewards_train/chosen': '0.47472', 'rewards_train/rejected': '-6.6237', 'rewards_train/margins': '7.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24524', 'examples_per_second': '5.1552', 'grad_norm': '6.0312', 'counters/examples': 258496, 'counters/updates': 16156}
skipping logging after 258512 examples to avoid logging too frequently
skipping logging after 258528 examples to avoid logging too frequently
skipping logging after 258544 examples to avoid logging too frequently
train stats after 258560 examples: {'rewards_train/chosen': '0.46582', 'rewards_train/rejected': '-6.6946', 'rewards_train/margins': '7.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23853', 'examples_per_second': '5.4002', 'grad_norm': '5.0625', 'counters/examples': 258560, 'counters/updates': 16160}
skipping logging after 258576 examples to avoid logging too frequently
skipping logging after 258592 examples to avoid logging too frequently
skipping logging after 258608 examples to avoid logging too frequently
train stats after 258624 examples: {'rewards_train/chosen': '0.033055', 'rewards_train/rejected': '-5.7616', 'rewards_train/margins': '5.8555', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27222', 'examples_per_second': '5.3844', 'grad_norm': '5.0938', 'counters/examples': 258624, 'counters/updates': 16164}
skipping logging after 258640 examples to avoid logging too frequently
skipping logging after 258656 examples to avoid logging too frequently
skipping logging after 258672 examples to avoid logging too frequently
train stats after 258688 examples: {'rewards_train/chosen': '0.16733', 'rewards_train/rejected': '-6.774', 'rewards_train/margins': '6.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22003', 'examples_per_second': '4.8816', 'grad_norm': '5.0312', 'counters/examples': 258688, 'counters/updates': 16168}
skipping logging after 258704 examples to avoid logging too frequently
skipping logging after 258720 examples to avoid logging too frequently
skipping logging after 258736 examples to avoid logging too frequently
train stats after 258752 examples: {'rewards_train/chosen': '-0.68712', 'rewards_train/rejected': '-5.3111', 'rewards_train/margins': '4.6758', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26288', 'examples_per_second': '4.9077', 'grad_norm': '4.625', 'counters/examples': 258752, 'counters/updates': 16172}
skipping logging after 258768 examples to avoid logging too frequently
skipping logging after 258784 examples to avoid logging too frequently
skipping logging after 258800 examples to avoid logging too frequently
train stats after 258816 examples: {'rewards_train/chosen': '0.095806', 'rewards_train/rejected': '-6.1165', 'rewards_train/margins': '6.1406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19763', 'examples_per_second': '6.3185', 'grad_norm': '4.375', 'counters/examples': 258816, 'counters/updates': 16176}
skipping logging after 258832 examples to avoid logging too frequently
skipping logging after 258848 examples to avoid logging too frequently
skipping logging after 258864 examples to avoid logging too frequently
train stats after 258880 examples: {'rewards_train/chosen': '0.33958', 'rewards_train/rejected': '-7.683', 'rewards_train/margins': '7.9297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23737', 'examples_per_second': '5.522', 'grad_norm': '4.9688', 'counters/examples': 258880, 'counters/updates': 16180}
skipping logging after 258896 examples to avoid logging too frequently
skipping logging after 258912 examples to avoid logging too frequently
skipping logging after 258928 examples to avoid logging too frequently
train stats after 258944 examples: {'rewards_train/chosen': '0.16169', 'rewards_train/rejected': '-7.3896', 'rewards_train/margins': '7.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22369', 'examples_per_second': '6.4043', 'grad_norm': '4.75', 'counters/examples': 258944, 'counters/updates': 16184}
skipping logging after 258960 examples to avoid logging too frequently
skipping logging after 258976 examples to avoid logging too frequently
skipping logging after 258992 examples to avoid logging too frequently
train stats after 259008 examples: {'rewards_train/chosen': '-0.019816', 'rewards_train/rejected': '-7.7109', 'rewards_train/margins': '7.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28717', 'examples_per_second': '5.0215', 'grad_norm': '4.9062', 'counters/examples': 259008, 'counters/updates': 16188}
skipping logging after 259024 examples to avoid logging too frequently
skipping logging after 259040 examples to avoid logging too frequently
skipping logging after 259056 examples to avoid logging too frequently
train stats after 259072 examples: {'rewards_train/chosen': '-0.072978', 'rewards_train/rejected': '-6.108', 'rewards_train/margins': '6.0273', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27057', 'examples_per_second': '3.9497', 'grad_norm': '4.6562', 'counters/examples': 259072, 'counters/updates': 16192}
skipping logging after 259088 examples to avoid logging too frequently
skipping logging after 259104 examples to avoid logging too frequently
skipping logging after 259120 examples to avoid logging too frequently
train stats after 259136 examples: {'rewards_train/chosen': '0.086373', 'rewards_train/rejected': '-6.1133', 'rewards_train/margins': '6.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26624', 'examples_per_second': '4.7001', 'grad_norm': '4.8438', 'counters/examples': 259136, 'counters/updates': 16196}
skipping logging after 259152 examples to avoid logging too frequently
skipping logging after 259168 examples to avoid logging too frequently
skipping logging after 259184 examples to avoid logging too frequently
train stats after 259200 examples: {'rewards_train/chosen': '0.3952', 'rewards_train/rejected': '-7.3399', 'rewards_train/margins': '7.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29846', 'examples_per_second': '5.1451', 'grad_norm': '5.5', 'counters/examples': 259200, 'counters/updates': 16200}
skipping logging after 259216 examples to avoid logging too frequently
skipping logging after 259232 examples to avoid logging too frequently
skipping logging after 259248 examples to avoid logging too frequently
train stats after 259264 examples: {'rewards_train/chosen': '0.4428', 'rewards_train/rejected': '-5.1037', 'rewards_train/margins': '5.8008', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25433', 'examples_per_second': '5.0184', 'grad_norm': '5.6562', 'counters/examples': 259264, 'counters/updates': 16204}
skipping logging after 259280 examples to avoid logging too frequently
skipping logging after 259296 examples to avoid logging too frequently
skipping logging after 259312 examples to avoid logging too frequently
train stats after 259328 examples: {'rewards_train/chosen': '0.22713', 'rewards_train/rejected': '-6.4245', 'rewards_train/margins': '6.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18024', 'examples_per_second': '5.569', 'grad_norm': '4.3438', 'counters/examples': 259328, 'counters/updates': 16208}
skipping logging after 259344 examples to avoid logging too frequently
skipping logging after 259360 examples to avoid logging too frequently
skipping logging after 259376 examples to avoid logging too frequently
train stats after 259392 examples: {'rewards_train/chosen': '0.64917', 'rewards_train/rejected': '-6.2854', 'rewards_train/margins': '6.9375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21399', 'examples_per_second': '5.4793', 'grad_norm': '4.6562', 'counters/examples': 259392, 'counters/updates': 16212}
skipping logging after 259408 examples to avoid logging too frequently
skipping logging after 259424 examples to avoid logging too frequently
skipping logging after 259440 examples to avoid logging too frequently
train stats after 259456 examples: {'rewards_train/chosen': '0.042147', 'rewards_train/rejected': '-5.457', 'rewards_train/margins': '5.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26074', 'examples_per_second': '5.7944', 'grad_norm': '5.1875', 'counters/examples': 259456, 'counters/updates': 16216}
skipping logging after 259472 examples to avoid logging too frequently
skipping logging after 259488 examples to avoid logging too frequently
skipping logging after 259504 examples to avoid logging too frequently
train stats after 259520 examples: {'rewards_train/chosen': '0.5859', 'rewards_train/rejected': '-6.1415', 'rewards_train/margins': '6.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20673', 'examples_per_second': '5.0807', 'grad_norm': '4.5', 'counters/examples': 259520, 'counters/updates': 16220}
skipping logging after 259536 examples to avoid logging too frequently
skipping logging after 259552 examples to avoid logging too frequently
skipping logging after 259568 examples to avoid logging too frequently
train stats after 259584 examples: {'rewards_train/chosen': '0.50899', 'rewards_train/rejected': '-6.4718', 'rewards_train/margins': '6.9766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20386', 'examples_per_second': '4.9064', 'grad_norm': '5.8125', 'counters/examples': 259584, 'counters/updates': 16224}
skipping logging after 259600 examples to avoid logging too frequently
skipping logging after 259616 examples to avoid logging too frequently
skipping logging after 259632 examples to avoid logging too frequently
train stats after 259648 examples: {'rewards_train/chosen': '0.50452', 'rewards_train/rejected': '-5.6657', 'rewards_train/margins': '6.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20453', 'examples_per_second': '4.9809', 'grad_norm': '4.875', 'counters/examples': 259648, 'counters/updates': 16228}
skipping logging after 259664 examples to avoid logging too frequently
skipping logging after 259680 examples to avoid logging too frequently
skipping logging after 259696 examples to avoid logging too frequently
train stats after 259712 examples: {'rewards_train/chosen': '0.31846', 'rewards_train/rejected': '-6.2622', 'rewards_train/margins': '6.2344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24078', 'examples_per_second': '4.9699', 'grad_norm': '5.5', 'counters/examples': 259712, 'counters/updates': 16232}
skipping logging after 259728 examples to avoid logging too frequently
skipping logging after 259744 examples to avoid logging too frequently
skipping logging after 259760 examples to avoid logging too frequently
train stats after 259776 examples: {'rewards_train/chosen': '0.3613', 'rewards_train/rejected': '-6.5277', 'rewards_train/margins': '7.0156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22565', 'examples_per_second': '5.2811', 'grad_norm': '5.5625', 'counters/examples': 259776, 'counters/updates': 16236}
skipping logging after 259792 examples to avoid logging too frequently
skipping logging after 259808 examples to avoid logging too frequently
skipping logging after 259824 examples to avoid logging too frequently
train stats after 259840 examples: {'rewards_train/chosen': '0.16388', 'rewards_train/rejected': '-7.3577', 'rewards_train/margins': '7.3594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22913', 'examples_per_second': '4.8832', 'grad_norm': '4.9375', 'counters/examples': 259840, 'counters/updates': 16240}
skipping logging after 259856 examples to avoid logging too frequently
skipping logging after 259872 examples to avoid logging too frequently
skipping logging after 259888 examples to avoid logging too frequently
train stats after 259904 examples: {'rewards_train/chosen': '0.20941', 'rewards_train/rejected': '-7.3556', 'rewards_train/margins': '7.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24951', 'examples_per_second': '4.6967', 'grad_norm': '5.5312', 'counters/examples': 259904, 'counters/updates': 16244}
skipping logging after 259920 examples to avoid logging too frequently
skipping logging after 259936 examples to avoid logging too frequently
skipping logging after 259952 examples to avoid logging too frequently
train stats after 259968 examples: {'rewards_train/chosen': '0.39773', 'rewards_train/rejected': '-6.4876', 'rewards_train/margins': '6.8906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25555', 'examples_per_second': '5.1085', 'grad_norm': '5.4062', 'counters/examples': 259968, 'counters/updates': 16248}
skipping logging after 259984 examples to avoid logging too frequently
skipping logging after 260000 examples to avoid logging too frequently
Running evaluation after 260000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:57,  1.84s/it]Computing eval metrics:   6%|▋         | 2/32 [00:03<00:45,  1.50s/it]Computing eval metrics:   9%|▉         | 3/32 [00:04<00:37,  1.30s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:06<00:42,  1.51s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:08<00:46,  1.71s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:09<00:39,  1.51s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:10<00:34,  1.39s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:12<00:36,  1.54s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.50s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:31,  1.42s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:31,  1.49s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.41s/it]Computing eval metrics:  41%|████      | 13/32 [00:19<00:26,  1.39s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:20<00:24,  1.35s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:21<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.28s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.26s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:25<00:17,  1.25s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:27<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:28<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:12,  1.51s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:09,  1.37s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.42s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:38<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:39<00:03,  1.20s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:40<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:41<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.33s/it]
eval after 260000: {'rewards_eval/chosen': '-6.005', 'rewards_eval/rejected': '-6.6211', 'rewards_eval/margins': '0.44971', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.45629'}
skipping logging after 260016 examples to avoid logging too frequently
train stats after 260032 examples: {'rewards_train/chosen': '0.31179', 'rewards_train/rejected': '-5.8674', 'rewards_train/margins': '5.9258', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28809', 'examples_per_second': '4.1412', 'grad_norm': '5.3438', 'counters/examples': 260032, 'counters/updates': 16252}
skipping logging after 260048 examples to avoid logging too frequently
skipping logging after 260064 examples to avoid logging too frequently
skipping logging after 260080 examples to avoid logging too frequently
train stats after 260096 examples: {'rewards_train/chosen': '0.29073', 'rewards_train/rejected': '-5.911', 'rewards_train/margins': '6.1875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27356', 'examples_per_second': '5.6897', 'grad_norm': '5.375', 'counters/examples': 260096, 'counters/updates': 16256}
skipping logging after 260112 examples to avoid logging too frequently
skipping logging after 260128 examples to avoid logging too frequently
skipping logging after 260144 examples to avoid logging too frequently
train stats after 260160 examples: {'rewards_train/chosen': '0.37856', 'rewards_train/rejected': '-6.5957', 'rewards_train/margins': '6.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22949', 'examples_per_second': '4.299', 'grad_norm': '4.9062', 'counters/examples': 260160, 'counters/updates': 16260}
skipping logging after 260176 examples to avoid logging too frequently
skipping logging after 260192 examples to avoid logging too frequently
skipping logging after 260208 examples to avoid logging too frequently
train stats after 260224 examples: {'rewards_train/chosen': '0.11864', 'rewards_train/rejected': '-5.8713', 'rewards_train/margins': '5.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28131', 'examples_per_second': '5.9006', 'grad_norm': '5.5938', 'counters/examples': 260224, 'counters/updates': 16264}
skipping logging after 260240 examples to avoid logging too frequently
skipping logging after 260256 examples to avoid logging too frequently
skipping logging after 260272 examples to avoid logging too frequently
train stats after 260288 examples: {'rewards_train/chosen': '0.53295', 'rewards_train/rejected': '-6.2125', 'rewards_train/margins': '6.1953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2489', 'examples_per_second': '5.0139', 'grad_norm': '4.8125', 'counters/examples': 260288, 'counters/updates': 16268}
skipping logging after 260304 examples to avoid logging too frequently
skipping logging after 260320 examples to avoid logging too frequently
skipping logging after 260336 examples to avoid logging too frequently
train stats after 260352 examples: {'rewards_train/chosen': '0.35536', 'rewards_train/rejected': '-6.6071', 'rewards_train/margins': '6.7422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22406', 'examples_per_second': '4.9891', 'grad_norm': '4.8125', 'counters/examples': 260352, 'counters/updates': 16272}
skipping logging after 260368 examples to avoid logging too frequently
skipping logging after 260384 examples to avoid logging too frequently
skipping logging after 260400 examples to avoid logging too frequently
train stats after 260416 examples: {'rewards_train/chosen': '0.16318', 'rewards_train/rejected': '-5.2566', 'rewards_train/margins': '5.4531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24103', 'examples_per_second': '4.8148', 'grad_norm': '5.3438', 'counters/examples': 260416, 'counters/updates': 16276}
skipping logging after 260432 examples to avoid logging too frequently
skipping logging after 260448 examples to avoid logging too frequently
skipping logging after 260464 examples to avoid logging too frequently
train stats after 260480 examples: {'rewards_train/chosen': '0.68335', 'rewards_train/rejected': '-5.0076', 'rewards_train/margins': '5.7031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23596', 'examples_per_second': '5.1301', 'grad_norm': '5.5625', 'counters/examples': 260480, 'counters/updates': 16280}
skipping logging after 260496 examples to avoid logging too frequently
skipping logging after 260512 examples to avoid logging too frequently
skipping logging after 260528 examples to avoid logging too frequently
train stats after 260544 examples: {'rewards_train/chosen': '0.62124', 'rewards_train/rejected': '-5.3289', 'rewards_train/margins': '6.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21094', 'examples_per_second': '4.5932', 'grad_norm': '5.2812', 'counters/examples': 260544, 'counters/updates': 16284}
skipping logging after 260560 examples to avoid logging too frequently
skipping logging after 260576 examples to avoid logging too frequently
skipping logging after 260592 examples to avoid logging too frequently
train stats after 260608 examples: {'rewards_train/chosen': '0.40871', 'rewards_train/rejected': '-6.8752', 'rewards_train/margins': '7.3281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22437', 'examples_per_second': '4.686', 'grad_norm': '5.2188', 'counters/examples': 260608, 'counters/updates': 16288}
skipping logging after 260624 examples to avoid logging too frequently
skipping logging after 260640 examples to avoid logging too frequently
skipping logging after 260656 examples to avoid logging too frequently
train stats after 260672 examples: {'rewards_train/chosen': '0.1799', 'rewards_train/rejected': '-5.3158', 'rewards_train/margins': '5.5391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2464', 'examples_per_second': '4.2542', 'grad_norm': '5.2188', 'counters/examples': 260672, 'counters/updates': 16292}
skipping logging after 260688 examples to avoid logging too frequently
skipping logging after 260704 examples to avoid logging too frequently
skipping logging after 260720 examples to avoid logging too frequently
train stats after 260736 examples: {'rewards_train/chosen': '0.25385', 'rewards_train/rejected': '-6.3029', 'rewards_train/margins': '6.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2171', 'examples_per_second': '5.6364', 'grad_norm': '5.4375', 'counters/examples': 260736, 'counters/updates': 16296}
skipping logging after 260752 examples to avoid logging too frequently
skipping logging after 260768 examples to avoid logging too frequently
skipping logging after 260784 examples to avoid logging too frequently
train stats after 260800 examples: {'rewards_train/chosen': '0.086528', 'rewards_train/rejected': '-5.9228', 'rewards_train/margins': '6.1875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23145', 'examples_per_second': '5.177', 'grad_norm': '4.75', 'counters/examples': 260800, 'counters/updates': 16300}
skipping logging after 260816 examples to avoid logging too frequently
skipping logging after 260832 examples to avoid logging too frequently
skipping logging after 260848 examples to avoid logging too frequently
train stats after 260864 examples: {'rewards_train/chosen': '0.17925', 'rewards_train/rejected': '-6.6019', 'rewards_train/margins': '6.7656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22357', 'examples_per_second': '5.4761', 'grad_norm': '4.3438', 'counters/examples': 260864, 'counters/updates': 16304}
skipping logging after 260880 examples to avoid logging too frequently
skipping logging after 260896 examples to avoid logging too frequently
skipping logging after 260912 examples to avoid logging too frequently
train stats after 260928 examples: {'rewards_train/chosen': '0.26025', 'rewards_train/rejected': '-7.1699', 'rewards_train/margins': '7.3594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21527', 'examples_per_second': '5.3495', 'grad_norm': '5.125', 'counters/examples': 260928, 'counters/updates': 16308}
skipping logging after 260944 examples to avoid logging too frequently
skipping logging after 260960 examples to avoid logging too frequently
skipping logging after 260976 examples to avoid logging too frequently
train stats after 260992 examples: {'rewards_train/chosen': '0.38244', 'rewards_train/rejected': '-6.4473', 'rewards_train/margins': '6.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20648', 'examples_per_second': '5.4403', 'grad_norm': '4.5312', 'counters/examples': 260992, 'counters/updates': 16312}
skipping logging after 261008 examples to avoid logging too frequently
skipping logging after 261024 examples to avoid logging too frequently
skipping logging after 261040 examples to avoid logging too frequently
train stats after 261056 examples: {'rewards_train/chosen': '-0.079636', 'rewards_train/rejected': '-7.3801', 'rewards_train/margins': '7.2969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25287', 'examples_per_second': '5.4107', 'grad_norm': '5.25', 'counters/examples': 261056, 'counters/updates': 16316}
skipping logging after 261072 examples to avoid logging too frequently
skipping logging after 261088 examples to avoid logging too frequently
skipping logging after 261104 examples to avoid logging too frequently
train stats after 261120 examples: {'rewards_train/chosen': '0.17413', 'rewards_train/rejected': '-7.6776', 'rewards_train/margins': '7.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23535', 'examples_per_second': '4.8936', 'grad_norm': '4.9375', 'counters/examples': 261120, 'counters/updates': 16320}
skipping logging after 261136 examples to avoid logging too frequently
skipping logging after 261152 examples to avoid logging too frequently
skipping logging after 261168 examples to avoid logging too frequently
train stats after 261184 examples: {'rewards_train/chosen': '0.37941', 'rewards_train/rejected': '-6.0593', 'rewards_train/margins': '6.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21777', 'examples_per_second': '5.9345', 'grad_norm': '4.9062', 'counters/examples': 261184, 'counters/updates': 16324}
skipping logging after 261200 examples to avoid logging too frequently
skipping logging after 261216 examples to avoid logging too frequently
skipping logging after 261232 examples to avoid logging too frequently
train stats after 261248 examples: {'rewards_train/chosen': '-0.01346', 'rewards_train/rejected': '-6.0511', 'rewards_train/margins': '6.125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2486', 'examples_per_second': '4.1563', 'grad_norm': '4.875', 'counters/examples': 261248, 'counters/updates': 16328}
skipping logging after 261264 examples to avoid logging too frequently
skipping logging after 261280 examples to avoid logging too frequently
skipping logging after 261296 examples to avoid logging too frequently
train stats after 261312 examples: {'rewards_train/chosen': '0.33447', 'rewards_train/rejected': '-5.2349', 'rewards_train/margins': '5.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21747', 'examples_per_second': '4.5203', 'grad_norm': '5.375', 'counters/examples': 261312, 'counters/updates': 16332}
skipping logging after 261328 examples to avoid logging too frequently
skipping logging after 261344 examples to avoid logging too frequently
skipping logging after 261360 examples to avoid logging too frequently
train stats after 261376 examples: {'rewards_train/chosen': '0.41739', 'rewards_train/rejected': '-6.9827', 'rewards_train/margins': '7.2266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1839', 'examples_per_second': '4.3659', 'grad_norm': '4.6562', 'counters/examples': 261376, 'counters/updates': 16336}
skipping logging after 261392 examples to avoid logging too frequently
skipping logging after 261408 examples to avoid logging too frequently
skipping logging after 261424 examples to avoid logging too frequently
train stats after 261440 examples: {'rewards_train/chosen': '0.18149', 'rewards_train/rejected': '-7.1848', 'rewards_train/margins': '7.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2403', 'examples_per_second': '5.2731', 'grad_norm': '5.0625', 'counters/examples': 261440, 'counters/updates': 16340}
skipping logging after 261456 examples to avoid logging too frequently
skipping logging after 261472 examples to avoid logging too frequently
skipping logging after 261488 examples to avoid logging too frequently
train stats after 261504 examples: {'rewards_train/chosen': '0.2105', 'rewards_train/rejected': '-5.8788', 'rewards_train/margins': '6.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24597', 'examples_per_second': '5.2023', 'grad_norm': '5.4375', 'counters/examples': 261504, 'counters/updates': 16344}
skipping logging after 261520 examples to avoid logging too frequently
skipping logging after 261536 examples to avoid logging too frequently
skipping logging after 261552 examples to avoid logging too frequently
train stats after 261568 examples: {'rewards_train/chosen': '0.050766', 'rewards_train/rejected': '-5.514', 'rewards_train/margins': '5.6641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2876', 'examples_per_second': '5.0404', 'grad_norm': '6.5', 'counters/examples': 261568, 'counters/updates': 16348}
skipping logging after 261584 examples to avoid logging too frequently
skipping logging after 261600 examples to avoid logging too frequently
skipping logging after 261616 examples to avoid logging too frequently
train stats after 261632 examples: {'rewards_train/chosen': '0.43153', 'rewards_train/rejected': '-5.3497', 'rewards_train/margins': '5.8672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23718', 'examples_per_second': '4.3545', 'grad_norm': '5.4375', 'counters/examples': 261632, 'counters/updates': 16352}
skipping logging after 261648 examples to avoid logging too frequently
skipping logging after 261664 examples to avoid logging too frequently
skipping logging after 261680 examples to avoid logging too frequently
train stats after 261696 examples: {'rewards_train/chosen': '0.41441', 'rewards_train/rejected': '-5.8463', 'rewards_train/margins': '6.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24274', 'examples_per_second': '7.5422', 'grad_norm': '4.5', 'counters/examples': 261696, 'counters/updates': 16356}
skipping logging after 261712 examples to avoid logging too frequently
skipping logging after 261728 examples to avoid logging too frequently
skipping logging after 261744 examples to avoid logging too frequently
train stats after 261760 examples: {'rewards_train/chosen': '0.12194', 'rewards_train/rejected': '-7.4924', 'rewards_train/margins': '7.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21759', 'examples_per_second': '5.1539', 'grad_norm': '5.9062', 'counters/examples': 261760, 'counters/updates': 16360}
skipping logging after 261776 examples to avoid logging too frequently
skipping logging after 261792 examples to avoid logging too frequently
skipping logging after 261808 examples to avoid logging too frequently
train stats after 261824 examples: {'rewards_train/chosen': '0.44229', 'rewards_train/rejected': '-6.0246', 'rewards_train/margins': '6.5938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20404', 'examples_per_second': '4.4915', 'grad_norm': '5.5938', 'counters/examples': 261824, 'counters/updates': 16364}
skipping logging after 261840 examples to avoid logging too frequently
skipping logging after 261856 examples to avoid logging too frequently
skipping logging after 261872 examples to avoid logging too frequently
train stats after 261888 examples: {'rewards_train/chosen': '0.35383', 'rewards_train/rejected': '-5.5891', 'rewards_train/margins': '5.8672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18848', 'examples_per_second': '5.7703', 'grad_norm': '4.6875', 'counters/examples': 261888, 'counters/updates': 16368}
skipping logging after 261904 examples to avoid logging too frequently
skipping logging after 261920 examples to avoid logging too frequently
skipping logging after 261936 examples to avoid logging too frequently
train stats after 261952 examples: {'rewards_train/chosen': '0.28669', 'rewards_train/rejected': '-6.1875', 'rewards_train/margins': '6.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21851', 'examples_per_second': '4.5007', 'grad_norm': '4.5312', 'counters/examples': 261952, 'counters/updates': 16372}
skipping logging after 261968 examples to avoid logging too frequently
skipping logging after 261984 examples to avoid logging too frequently
skipping logging after 262000 examples to avoid logging too frequently
train stats after 262016 examples: {'rewards_train/chosen': '0.29337', 'rewards_train/rejected': '-6.0718', 'rewards_train/margins': '6.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24945', 'examples_per_second': '4.2262', 'grad_norm': '5.8125', 'counters/examples': 262016, 'counters/updates': 16376}
skipping logging after 262032 examples to avoid logging too frequently
skipping logging after 262048 examples to avoid logging too frequently
skipping logging after 262064 examples to avoid logging too frequently
train stats after 262080 examples: {'rewards_train/chosen': '0.46357', 'rewards_train/rejected': '-6.6127', 'rewards_train/margins': '7.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18225', 'examples_per_second': '6.005', 'grad_norm': '4.4375', 'counters/examples': 262080, 'counters/updates': 16380}
skipping logging after 262096 examples to avoid logging too frequently
skipping logging after 262112 examples to avoid logging too frequently
skipping logging after 262128 examples to avoid logging too frequently
train stats after 262144 examples: {'rewards_train/chosen': '0.38416', 'rewards_train/rejected': '-5.9097', 'rewards_train/margins': '6.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24133', 'examples_per_second': '5.169', 'grad_norm': '5.3438', 'counters/examples': 262144, 'counters/updates': 16384}
skipping logging after 262160 examples to avoid logging too frequently
skipping logging after 262176 examples to avoid logging too frequently
skipping logging after 262192 examples to avoid logging too frequently
train stats after 262208 examples: {'rewards_train/chosen': '-0.33563', 'rewards_train/rejected': '-5.2667', 'rewards_train/margins': '4.7656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2616', 'examples_per_second': '5.63', 'grad_norm': '5.2188', 'counters/examples': 262208, 'counters/updates': 16388}
skipping logging after 262224 examples to avoid logging too frequently
skipping logging after 262240 examples to avoid logging too frequently
skipping logging after 262256 examples to avoid logging too frequently
train stats after 262272 examples: {'rewards_train/chosen': '0.11879', 'rewards_train/rejected': '-6.6095', 'rewards_train/margins': '6.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25598', 'examples_per_second': '5.6624', 'grad_norm': '6.0625', 'counters/examples': 262272, 'counters/updates': 16392}
skipping logging after 262288 examples to avoid logging too frequently
skipping logging after 262304 examples to avoid logging too frequently
skipping logging after 262320 examples to avoid logging too frequently
train stats after 262336 examples: {'rewards_train/chosen': '0.031474', 'rewards_train/rejected': '-4.6846', 'rewards_train/margins': '4.8008', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27753', 'examples_per_second': '5.487', 'grad_norm': '5.2812', 'counters/examples': 262336, 'counters/updates': 16396}
skipping logging after 262352 examples to avoid logging too frequently
skipping logging after 262368 examples to avoid logging too frequently
skipping logging after 262384 examples to avoid logging too frequently
train stats after 262400 examples: {'rewards_train/chosen': '-0.13905', 'rewards_train/rejected': '-6.757', 'rewards_train/margins': '6.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24738', 'examples_per_second': '4.4849', 'grad_norm': '4.7812', 'counters/examples': 262400, 'counters/updates': 16400}
skipping logging after 262416 examples to avoid logging too frequently
skipping logging after 262432 examples to avoid logging too frequently
skipping logging after 262448 examples to avoid logging too frequently
train stats after 262464 examples: {'rewards_train/chosen': '-0.018302', 'rewards_train/rejected': '-7.1953', 'rewards_train/margins': '7.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2887', 'examples_per_second': '4.987', 'grad_norm': '5.75', 'counters/examples': 262464, 'counters/updates': 16404}
skipping logging after 262480 examples to avoid logging too frequently
skipping logging after 262496 examples to avoid logging too frequently
skipping logging after 262512 examples to avoid logging too frequently
train stats after 262528 examples: {'rewards_train/chosen': '0.36495', 'rewards_train/rejected': '-6.1055', 'rewards_train/margins': '6.3828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2287', 'examples_per_second': '4.1821', 'grad_norm': '6.9062', 'counters/examples': 262528, 'counters/updates': 16408}
skipping logging after 262544 examples to avoid logging too frequently
skipping logging after 262560 examples to avoid logging too frequently
skipping logging after 262576 examples to avoid logging too frequently
train stats after 262592 examples: {'rewards_train/chosen': '0.30312', 'rewards_train/rejected': '-7.1133', 'rewards_train/margins': '7.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25354', 'examples_per_second': '5.767', 'grad_norm': '5.0938', 'counters/examples': 262592, 'counters/updates': 16412}
skipping logging after 262608 examples to avoid logging too frequently
skipping logging after 262624 examples to avoid logging too frequently
skipping logging after 262640 examples to avoid logging too frequently
train stats after 262656 examples: {'rewards_train/chosen': '0.30221', 'rewards_train/rejected': '-5.1737', 'rewards_train/margins': '5.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25409', 'examples_per_second': '5.1027', 'grad_norm': '5.1875', 'counters/examples': 262656, 'counters/updates': 16416}
skipping logging after 262672 examples to avoid logging too frequently
skipping logging after 262688 examples to avoid logging too frequently
skipping logging after 262704 examples to avoid logging too frequently
train stats after 262720 examples: {'rewards_train/chosen': '0.50225', 'rewards_train/rejected': '-6.1823', 'rewards_train/margins': '6.7422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2276', 'examples_per_second': '4.8036', 'grad_norm': '4.5', 'counters/examples': 262720, 'counters/updates': 16420}
skipping logging after 262736 examples to avoid logging too frequently
skipping logging after 262752 examples to avoid logging too frequently
skipping logging after 262768 examples to avoid logging too frequently
train stats after 262784 examples: {'rewards_train/chosen': '0.48274', 'rewards_train/rejected': '-6.8694', 'rewards_train/margins': '7.6562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23438', 'examples_per_second': '5.4562', 'grad_norm': '4.9375', 'counters/examples': 262784, 'counters/updates': 16424}
skipping logging after 262800 examples to avoid logging too frequently
skipping logging after 262816 examples to avoid logging too frequently
skipping logging after 262832 examples to avoid logging too frequently
train stats after 262848 examples: {'rewards_train/chosen': '0.47236', 'rewards_train/rejected': '-5.6911', 'rewards_train/margins': '6.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23535', 'examples_per_second': '5.0168', 'grad_norm': '4.5312', 'counters/examples': 262848, 'counters/updates': 16428}
skipping logging after 262864 examples to avoid logging too frequently
skipping logging after 262880 examples to avoid logging too frequently
skipping logging after 262896 examples to avoid logging too frequently
train stats after 262912 examples: {'rewards_train/chosen': '0.52', 'rewards_train/rejected': '-6.9439', 'rewards_train/margins': '7.2969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1911', 'examples_per_second': '4.8962', 'grad_norm': '5.0938', 'counters/examples': 262912, 'counters/updates': 16432}
skipping logging after 262928 examples to avoid logging too frequently
skipping logging after 262944 examples to avoid logging too frequently
skipping logging after 262960 examples to avoid logging too frequently
train stats after 262976 examples: {'rewards_train/chosen': '0.22152', 'rewards_train/rejected': '-6.2608', 'rewards_train/margins': '6.1719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22296', 'examples_per_second': '5.191', 'grad_norm': '5', 'counters/examples': 262976, 'counters/updates': 16436}
skipping logging after 262992 examples to avoid logging too frequently
skipping logging after 263008 examples to avoid logging too frequently
skipping logging after 263024 examples to avoid logging too frequently
train stats after 263040 examples: {'rewards_train/chosen': '0.34325', 'rewards_train/rejected': '-5.3679', 'rewards_train/margins': '5.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18707', 'examples_per_second': '4.1787', 'grad_norm': '4.6875', 'counters/examples': 263040, 'counters/updates': 16440}
skipping logging after 263056 examples to avoid logging too frequently
skipping logging after 263072 examples to avoid logging too frequently
skipping logging after 263088 examples to avoid logging too frequently
train stats after 263104 examples: {'rewards_train/chosen': '0.36188', 'rewards_train/rejected': '-5.9512', 'rewards_train/margins': '6.3594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20001', 'examples_per_second': '5.9732', 'grad_norm': '4.5938', 'counters/examples': 263104, 'counters/updates': 16444}
skipping logging after 263120 examples to avoid logging too frequently
skipping logging after 263136 examples to avoid logging too frequently
skipping logging after 263152 examples to avoid logging too frequently
train stats after 263168 examples: {'rewards_train/chosen': '0.18813', 'rewards_train/rejected': '-5.1126', 'rewards_train/margins': '5.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26453', 'examples_per_second': '6.7237', 'grad_norm': '4.875', 'counters/examples': 263168, 'counters/updates': 16448}
skipping logging after 263184 examples to avoid logging too frequently
skipping logging after 263200 examples to avoid logging too frequently
skipping logging after 263216 examples to avoid logging too frequently
train stats after 263232 examples: {'rewards_train/chosen': '0.88922', 'rewards_train/rejected': '-8.2344', 'rewards_train/margins': '9.5938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17151', 'examples_per_second': '4.9065', 'grad_norm': '4.6875', 'counters/examples': 263232, 'counters/updates': 16452}
skipping logging after 263248 examples to avoid logging too frequently
skipping logging after 263264 examples to avoid logging too frequently
skipping logging after 263280 examples to avoid logging too frequently
train stats after 263296 examples: {'rewards_train/chosen': '0.14376', 'rewards_train/rejected': '-6.818', 'rewards_train/margins': '6.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24445', 'examples_per_second': '5.9975', 'grad_norm': '4.8125', 'counters/examples': 263296, 'counters/updates': 16456}
skipping logging after 263312 examples to avoid logging too frequently
skipping logging after 263328 examples to avoid logging too frequently
skipping logging after 263344 examples to avoid logging too frequently
train stats after 263360 examples: {'rewards_train/chosen': '0.48367', 'rewards_train/rejected': '-6.3055', 'rewards_train/margins': '6.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23956', 'examples_per_second': '4.6839', 'grad_norm': '5.5', 'counters/examples': 263360, 'counters/updates': 16460}
skipping logging after 263376 examples to avoid logging too frequently
skipping logging after 263392 examples to avoid logging too frequently
skipping logging after 263408 examples to avoid logging too frequently
train stats after 263424 examples: {'rewards_train/chosen': '0.45628', 'rewards_train/rejected': '-7.6243', 'rewards_train/margins': '8.0312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20264', 'examples_per_second': '4.7296', 'grad_norm': '4.7812', 'counters/examples': 263424, 'counters/updates': 16464}
skipping logging after 263440 examples to avoid logging too frequently
skipping logging after 263456 examples to avoid logging too frequently
skipping logging after 263472 examples to avoid logging too frequently
train stats after 263488 examples: {'rewards_train/chosen': '-0.078589', 'rewards_train/rejected': '-6.5186', 'rewards_train/margins': '6.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24542', 'examples_per_second': '5.348', 'grad_norm': '4.4688', 'counters/examples': 263488, 'counters/updates': 16468}
skipping logging after 263504 examples to avoid logging too frequently
skipping logging after 263520 examples to avoid logging too frequently
skipping logging after 263536 examples to avoid logging too frequently
train stats after 263552 examples: {'rewards_train/chosen': '-0.11087', 'rewards_train/rejected': '-5.421', 'rewards_train/margins': '5.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24371', 'examples_per_second': '5.8563', 'grad_norm': '4.9688', 'counters/examples': 263552, 'counters/updates': 16472}
skipping logging after 263568 examples to avoid logging too frequently
skipping logging after 263584 examples to avoid logging too frequently
skipping logging after 263600 examples to avoid logging too frequently
train stats after 263616 examples: {'rewards_train/chosen': '0.14455', 'rewards_train/rejected': '-6.3655', 'rewards_train/margins': '6.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26666', 'examples_per_second': '5.3408', 'grad_norm': '5.2812', 'counters/examples': 263616, 'counters/updates': 16476}
skipping logging after 263632 examples to avoid logging too frequently
skipping logging after 263648 examples to avoid logging too frequently
skipping logging after 263664 examples to avoid logging too frequently
train stats after 263680 examples: {'rewards_train/chosen': '0.55643', 'rewards_train/rejected': '-6.9985', 'rewards_train/margins': '7.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.15253', 'examples_per_second': '5.5529', 'grad_norm': '4.25', 'counters/examples': 263680, 'counters/updates': 16480}
skipping logging after 263696 examples to avoid logging too frequently
skipping logging after 263712 examples to avoid logging too frequently
skipping logging after 263728 examples to avoid logging too frequently
train stats after 263744 examples: {'rewards_train/chosen': '0.55805', 'rewards_train/rejected': '-5.1421', 'rewards_train/margins': '5.5938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20282', 'examples_per_second': '5.239', 'grad_norm': '5.4375', 'counters/examples': 263744, 'counters/updates': 16484}
skipping logging after 263760 examples to avoid logging too frequently
skipping logging after 263776 examples to avoid logging too frequently
skipping logging after 263792 examples to avoid logging too frequently
train stats after 263808 examples: {'rewards_train/chosen': '-0.17936', 'rewards_train/rejected': '-6.6679', 'rewards_train/margins': '6.5391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26385', 'examples_per_second': '5.0758', 'grad_norm': '6.5625', 'counters/examples': 263808, 'counters/updates': 16488}
skipping logging after 263824 examples to avoid logging too frequently
skipping logging after 263840 examples to avoid logging too frequently
skipping logging after 263856 examples to avoid logging too frequently
train stats after 263872 examples: {'rewards_train/chosen': '0.24809', 'rewards_train/rejected': '-6.893', 'rewards_train/margins': '7.2109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25671', 'examples_per_second': '5.5332', 'grad_norm': '5.4062', 'counters/examples': 263872, 'counters/updates': 16492}
skipping logging after 263888 examples to avoid logging too frequently
skipping logging after 263904 examples to avoid logging too frequently
skipping logging after 263920 examples to avoid logging too frequently
train stats after 263936 examples: {'rewards_train/chosen': '0.21596', 'rewards_train/rejected': '-6.0385', 'rewards_train/margins': '6.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1886', 'examples_per_second': '5.024', 'grad_norm': '4.8125', 'counters/examples': 263936, 'counters/updates': 16496}
skipping logging after 263952 examples to avoid logging too frequently
skipping logging after 263968 examples to avoid logging too frequently
skipping logging after 263984 examples to avoid logging too frequently
train stats after 264000 examples: {'rewards_train/chosen': '0.17009', 'rewards_train/rejected': '-6.2982', 'rewards_train/margins': '6.5781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29559', 'examples_per_second': '5.729', 'grad_norm': '6.125', 'counters/examples': 264000, 'counters/updates': 16500}
Running evaluation after 264000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.26s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.26s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.17s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:40,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.65s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.47s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:33,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.51s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.40s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:30,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:21<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.51s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.20s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.31s/it]
eval after 264000: {'rewards_eval/chosen': '-5.4838', 'rewards_eval/rejected': '-6.0207', 'rewards_eval/margins': '0.38477', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.45815'}
skipping logging after 264016 examples to avoid logging too frequently
skipping logging after 264032 examples to avoid logging too frequently
skipping logging after 264048 examples to avoid logging too frequently
train stats after 264064 examples: {'rewards_train/chosen': '0.28461', 'rewards_train/rejected': '-5.6095', 'rewards_train/margins': '6.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30225', 'examples_per_second': '4.8738', 'grad_norm': '5.5312', 'counters/examples': 264064, 'counters/updates': 16504}
skipping logging after 264080 examples to avoid logging too frequently
skipping logging after 264096 examples to avoid logging too frequently
skipping logging after 264112 examples to avoid logging too frequently
train stats after 264128 examples: {'rewards_train/chosen': '0.38513', 'rewards_train/rejected': '-5.7856', 'rewards_train/margins': '5.7852', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26294', 'examples_per_second': '4.4745', 'grad_norm': '5.5312', 'counters/examples': 264128, 'counters/updates': 16508}
skipping logging after 264144 examples to avoid logging too frequently
skipping logging after 264160 examples to avoid logging too frequently
skipping logging after 264176 examples to avoid logging too frequently
train stats after 264192 examples: {'rewards_train/chosen': '0.42885', 'rewards_train/rejected': '-6.963', 'rewards_train/margins': '7.0312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24329', 'examples_per_second': '4.7821', 'grad_norm': '4.7812', 'counters/examples': 264192, 'counters/updates': 16512}
skipping logging after 264208 examples to avoid logging too frequently
skipping logging after 264224 examples to avoid logging too frequently
skipping logging after 264240 examples to avoid logging too frequently
train stats after 264256 examples: {'rewards_train/chosen': '0.22366', 'rewards_train/rejected': '-5.7254', 'rewards_train/margins': '6', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2511', 'examples_per_second': '4.8303', 'grad_norm': '5.0625', 'counters/examples': 264256, 'counters/updates': 16516}
skipping logging after 264272 examples to avoid logging too frequently
skipping logging after 264288 examples to avoid logging too frequently
skipping logging after 264304 examples to avoid logging too frequently
train stats after 264320 examples: {'rewards_train/chosen': '0.41614', 'rewards_train/rejected': '-4.1437', 'rewards_train/margins': '4.4883', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2262', 'examples_per_second': '4.7207', 'grad_norm': '5.7188', 'counters/examples': 264320, 'counters/updates': 16520}
skipping logging after 264336 examples to avoid logging too frequently
skipping logging after 264352 examples to avoid logging too frequently
skipping logging after 264368 examples to avoid logging too frequently
train stats after 264384 examples: {'rewards_train/chosen': '0.3623', 'rewards_train/rejected': '-7.9661', 'rewards_train/margins': '8.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24298', 'examples_per_second': '5.1509', 'grad_norm': '5.5625', 'counters/examples': 264384, 'counters/updates': 16524}
skipping logging after 264400 examples to avoid logging too frequently
skipping logging after 264416 examples to avoid logging too frequently
skipping logging after 264432 examples to avoid logging too frequently
train stats after 264448 examples: {'rewards_train/chosen': '-0.16044', 'rewards_train/rejected': '-6.3841', 'rewards_train/margins': '5.1777', 'rewards_train/KL_estimate': '0', 'loss/train': '0.32672', 'examples_per_second': '4.8141', 'grad_norm': '4.9688', 'counters/examples': 264448, 'counters/updates': 16528}
skipping logging after 264464 examples to avoid logging too frequently
skipping logging after 264480 examples to avoid logging too frequently
skipping logging after 264496 examples to avoid logging too frequently
train stats after 264512 examples: {'rewards_train/chosen': '0.61935', 'rewards_train/rejected': '-6.0112', 'rewards_train/margins': '7.0156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22955', 'examples_per_second': '5.2093', 'grad_norm': '5.3438', 'counters/examples': 264512, 'counters/updates': 16532}
skipping logging after 264528 examples to avoid logging too frequently
skipping logging after 264544 examples to avoid logging too frequently
skipping logging after 264560 examples to avoid logging too frequently
train stats after 264576 examples: {'rewards_train/chosen': '0.28112', 'rewards_train/rejected': '-5.3004', 'rewards_train/margins': '5.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22748', 'examples_per_second': '5.3308', 'grad_norm': '4.7812', 'counters/examples': 264576, 'counters/updates': 16536}
skipping logging after 264592 examples to avoid logging too frequently
skipping logging after 264608 examples to avoid logging too frequently
skipping logging after 264624 examples to avoid logging too frequently
train stats after 264640 examples: {'rewards_train/chosen': '0.27774', 'rewards_train/rejected': '-6.4343', 'rewards_train/margins': '6.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24213', 'examples_per_second': '5.5057', 'grad_norm': '5.75', 'counters/examples': 264640, 'counters/updates': 16540}
skipping logging after 264656 examples to avoid logging too frequently
skipping logging after 264672 examples to avoid logging too frequently
skipping logging after 264688 examples to avoid logging too frequently
train stats after 264704 examples: {'rewards_train/chosen': '0.15888', 'rewards_train/rejected': '-5.6039', 'rewards_train/margins': '5.7266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27582', 'examples_per_second': '5.4217', 'grad_norm': '5.25', 'counters/examples': 264704, 'counters/updates': 16544}
skipping logging after 264720 examples to avoid logging too frequently
skipping logging after 264736 examples to avoid logging too frequently
skipping logging after 264752 examples to avoid logging too frequently
train stats after 264768 examples: {'rewards_train/chosen': '0.17579', 'rewards_train/rejected': '-5.3822', 'rewards_train/margins': '5.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28607', 'examples_per_second': '5.1413', 'grad_norm': '6.2188', 'counters/examples': 264768, 'counters/updates': 16548}
skipping logging after 264784 examples to avoid logging too frequently
skipping logging after 264800 examples to avoid logging too frequently
skipping logging after 264816 examples to avoid logging too frequently
train stats after 264832 examples: {'rewards_train/chosen': '0.59251', 'rewards_train/rejected': '-5.2428', 'rewards_train/margins': '5.5508', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19073', 'examples_per_second': '5.2477', 'grad_norm': '7.5312', 'counters/examples': 264832, 'counters/updates': 16552}
skipping logging after 264848 examples to avoid logging too frequently
skipping logging after 264864 examples to avoid logging too frequently
skipping logging after 264880 examples to avoid logging too frequently
train stats after 264896 examples: {'rewards_train/chosen': '-0.11323', 'rewards_train/rejected': '-5.8234', 'rewards_train/margins': '5.7422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26892', 'examples_per_second': '5.5822', 'grad_norm': '6.2812', 'counters/examples': 264896, 'counters/updates': 16556}
skipping logging after 264912 examples to avoid logging too frequently
skipping logging after 264928 examples to avoid logging too frequently
skipping logging after 264944 examples to avoid logging too frequently
train stats after 264960 examples: {'rewards_train/chosen': '0.4282', 'rewards_train/rejected': '-6.0334', 'rewards_train/margins': '6.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19806', 'examples_per_second': '4.5884', 'grad_norm': '4.5938', 'counters/examples': 264960, 'counters/updates': 16560}
skipping logging after 264976 examples to avoid logging too frequently
skipping logging after 264992 examples to avoid logging too frequently
skipping logging after 265008 examples to avoid logging too frequently
train stats after 265024 examples: {'rewards_train/chosen': '0.19413', 'rewards_train/rejected': '-7.0727', 'rewards_train/margins': '7.2773', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24701', 'examples_per_second': '4.7588', 'grad_norm': '4.4688', 'counters/examples': 265024, 'counters/updates': 16564}
skipping logging after 265040 examples to avoid logging too frequently
skipping logging after 265056 examples to avoid logging too frequently
skipping logging after 265072 examples to avoid logging too frequently
train stats after 265088 examples: {'rewards_train/chosen': '0.34789', 'rewards_train/rejected': '-6.665', 'rewards_train/margins': '7', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23694', 'examples_per_second': '4.8503', 'grad_norm': '5.1562', 'counters/examples': 265088, 'counters/updates': 16568}
skipping logging after 265104 examples to avoid logging too frequently
skipping logging after 265120 examples to avoid logging too frequently
skipping logging after 265136 examples to avoid logging too frequently
train stats after 265152 examples: {'rewards_train/chosen': '0.46976', 'rewards_train/rejected': '-6.1352', 'rewards_train/margins': '6.4141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23047', 'examples_per_second': '4.6746', 'grad_norm': '5', 'counters/examples': 265152, 'counters/updates': 16572}
skipping logging after 265168 examples to avoid logging too frequently
skipping logging after 265184 examples to avoid logging too frequently
skipping logging after 265200 examples to avoid logging too frequently
train stats after 265216 examples: {'rewards_train/chosen': '0.27091', 'rewards_train/rejected': '-6.1013', 'rewards_train/margins': '6.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23322', 'examples_per_second': '3.7088', 'grad_norm': '4.875', 'counters/examples': 265216, 'counters/updates': 16576}
skipping logging after 265232 examples to avoid logging too frequently
skipping logging after 265248 examples to avoid logging too frequently
skipping logging after 265264 examples to avoid logging too frequently
train stats after 265280 examples: {'rewards_train/chosen': '0.30821', 'rewards_train/rejected': '-5.6728', 'rewards_train/margins': '6.1953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26886', 'examples_per_second': '5.1614', 'grad_norm': '4.8125', 'counters/examples': 265280, 'counters/updates': 16580}
skipping logging after 265296 examples to avoid logging too frequently
skipping logging after 265312 examples to avoid logging too frequently
skipping logging after 265328 examples to avoid logging too frequently
train stats after 265344 examples: {'rewards_train/chosen': '0.43922', 'rewards_train/rejected': '-4.5314', 'rewards_train/margins': '4.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25494', 'examples_per_second': '5.7375', 'grad_norm': '4.9375', 'counters/examples': 265344, 'counters/updates': 16584}
skipping logging after 265360 examples to avoid logging too frequently
skipping logging after 265376 examples to avoid logging too frequently
skipping logging after 265392 examples to avoid logging too frequently
train stats after 265408 examples: {'rewards_train/chosen': '0.045383', 'rewards_train/rejected': '-6.0703', 'rewards_train/margins': '6.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22003', 'examples_per_second': '6.312', 'grad_norm': '5.375', 'counters/examples': 265408, 'counters/updates': 16588}
skipping logging after 265424 examples to avoid logging too frequently
skipping logging after 265440 examples to avoid logging too frequently
skipping logging after 265456 examples to avoid logging too frequently
train stats after 265472 examples: {'rewards_train/chosen': '0.35354', 'rewards_train/rejected': '-6.6579', 'rewards_train/margins': '6.9336', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25354', 'examples_per_second': '4.7701', 'grad_norm': '5.5', 'counters/examples': 265472, 'counters/updates': 16592}
skipping logging after 265488 examples to avoid logging too frequently
skipping logging after 265504 examples to avoid logging too frequently
skipping logging after 265520 examples to avoid logging too frequently
train stats after 265536 examples: {'rewards_train/chosen': '0.5327', 'rewards_train/rejected': '-5.7786', 'rewards_train/margins': '6.2422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20453', 'examples_per_second': '5.0749', 'grad_norm': '5.2188', 'counters/examples': 265536, 'counters/updates': 16596}
skipping logging after 265552 examples to avoid logging too frequently
skipping logging after 265568 examples to avoid logging too frequently
skipping logging after 265584 examples to avoid logging too frequently
train stats after 265600 examples: {'rewards_train/chosen': '0.40304', 'rewards_train/rejected': '-5.4004', 'rewards_train/margins': '5.7031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20435', 'examples_per_second': '6.1304', 'grad_norm': '5.0938', 'counters/examples': 265600, 'counters/updates': 16600}
skipping logging after 265616 examples to avoid logging too frequently
skipping logging after 265632 examples to avoid logging too frequently
skipping logging after 265648 examples to avoid logging too frequently
train stats after 265664 examples: {'rewards_train/chosen': '0.27322', 'rewards_train/rejected': '-5.8223', 'rewards_train/margins': '6.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24091', 'examples_per_second': '5.0048', 'grad_norm': '5.6562', 'counters/examples': 265664, 'counters/updates': 16604}
skipping logging after 265680 examples to avoid logging too frequently
skipping logging after 265696 examples to avoid logging too frequently
skipping logging after 265712 examples to avoid logging too frequently
train stats after 265728 examples: {'rewards_train/chosen': '0.0044038', 'rewards_train/rejected': '-7.7348', 'rewards_train/margins': '8.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19', 'examples_per_second': '4.4953', 'grad_norm': '4.9062', 'counters/examples': 265728, 'counters/updates': 16608}
skipping logging after 265744 examples to avoid logging too frequently
skipping logging after 265760 examples to avoid logging too frequently
skipping logging after 265776 examples to avoid logging too frequently
train stats after 265792 examples: {'rewards_train/chosen': '0.33094', 'rewards_train/rejected': '-6.3826', 'rewards_train/margins': '6.7812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23438', 'examples_per_second': '6.3937', 'grad_norm': '5.8438', 'counters/examples': 265792, 'counters/updates': 16612}
skipping logging after 265808 examples to avoid logging too frequently
skipping logging after 265824 examples to avoid logging too frequently
skipping logging after 265840 examples to avoid logging too frequently
train stats after 265856 examples: {'rewards_train/chosen': '-0.078216', 'rewards_train/rejected': '-5.2974', 'rewards_train/margins': '5.1406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25244', 'examples_per_second': '5.1055', 'grad_norm': '5.25', 'counters/examples': 265856, 'counters/updates': 16616}
skipping logging after 265872 examples to avoid logging too frequently
skipping logging after 265888 examples to avoid logging too frequently
skipping logging after 265904 examples to avoid logging too frequently
train stats after 265920 examples: {'rewards_train/chosen': '0.41162', 'rewards_train/rejected': '-5.6311', 'rewards_train/margins': '6.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24969', 'examples_per_second': '4.8455', 'grad_norm': '5', 'counters/examples': 265920, 'counters/updates': 16620}
skipping logging after 265936 examples to avoid logging too frequently
skipping logging after 265952 examples to avoid logging too frequently
skipping logging after 265968 examples to avoid logging too frequently
train stats after 265984 examples: {'rewards_train/chosen': '0.32887', 'rewards_train/rejected': '-6.5366', 'rewards_train/margins': '6.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1524', 'examples_per_second': '4.3049', 'grad_norm': '3.8125', 'counters/examples': 265984, 'counters/updates': 16624}
skipping logging after 266000 examples to avoid logging too frequently
skipping logging after 266016 examples to avoid logging too frequently
skipping logging after 266032 examples to avoid logging too frequently
train stats after 266048 examples: {'rewards_train/chosen': '0.41539', 'rewards_train/rejected': '-6.4219', 'rewards_train/margins': '6.8125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21027', 'examples_per_second': '5.3239', 'grad_norm': '5.5625', 'counters/examples': 266048, 'counters/updates': 16628}
skipping logging after 266064 examples to avoid logging too frequently
skipping logging after 266080 examples to avoid logging too frequently
skipping logging after 266096 examples to avoid logging too frequently
train stats after 266112 examples: {'rewards_train/chosen': '-0.075227', 'rewards_train/rejected': '-6.5859', 'rewards_train/margins': '6.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23737', 'examples_per_second': '4.314', 'grad_norm': '4.9375', 'counters/examples': 266112, 'counters/updates': 16632}
skipping logging after 266128 examples to avoid logging too frequently
skipping logging after 266144 examples to avoid logging too frequently
skipping logging after 266160 examples to avoid logging too frequently
train stats after 266176 examples: {'rewards_train/chosen': '0.0023872', 'rewards_train/rejected': '-6.0363', 'rewards_train/margins': '5.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24597', 'examples_per_second': '5.5075', 'grad_norm': '5.8125', 'counters/examples': 266176, 'counters/updates': 16636}
skipping logging after 266192 examples to avoid logging too frequently
skipping logging after 266208 examples to avoid logging too frequently
skipping logging after 266224 examples to avoid logging too frequently
train stats after 266240 examples: {'rewards_train/chosen': '0.4977', 'rewards_train/rejected': '-6.6056', 'rewards_train/margins': '7.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23151', 'examples_per_second': '5.1603', 'grad_norm': '5.7812', 'counters/examples': 266240, 'counters/updates': 16640}
skipping logging after 266256 examples to avoid logging too frequently
skipping logging after 266272 examples to avoid logging too frequently
skipping logging after 266288 examples to avoid logging too frequently
train stats after 266304 examples: {'rewards_train/chosen': '0.56026', 'rewards_train/rejected': '-7.2584', 'rewards_train/margins': '7.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23926', 'examples_per_second': '5.2808', 'grad_norm': '5.4375', 'counters/examples': 266304, 'counters/updates': 16644}
skipping logging after 266320 examples to avoid logging too frequently
skipping logging after 266336 examples to avoid logging too frequently
skipping logging after 266352 examples to avoid logging too frequently
train stats after 266368 examples: {'rewards_train/chosen': '0.0074657', 'rewards_train/rejected': '-5.776', 'rewards_train/margins': '5.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27576', 'examples_per_second': '5.0013', 'grad_norm': '5.1875', 'counters/examples': 266368, 'counters/updates': 16648}
skipping logging after 266384 examples to avoid logging too frequently
skipping logging after 266400 examples to avoid logging too frequently
skipping logging after 266416 examples to avoid logging too frequently
train stats after 266432 examples: {'rewards_train/chosen': '0.42881', 'rewards_train/rejected': '-6.3995', 'rewards_train/margins': '6.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19702', 'examples_per_second': '5.3757', 'grad_norm': '5.2188', 'counters/examples': 266432, 'counters/updates': 16652}
skipping logging after 266448 examples to avoid logging too frequently
skipping logging after 266464 examples to avoid logging too frequently
skipping logging after 266480 examples to avoid logging too frequently
train stats after 266496 examples: {'rewards_train/chosen': '0.41065', 'rewards_train/rejected': '-7.4214', 'rewards_train/margins': '8.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19629', 'examples_per_second': '4.1953', 'grad_norm': '4.5938', 'counters/examples': 266496, 'counters/updates': 16656}
skipping logging after 266512 examples to avoid logging too frequently
skipping logging after 266528 examples to avoid logging too frequently
skipping logging after 266544 examples to avoid logging too frequently
train stats after 266560 examples: {'rewards_train/chosen': '0.33013', 'rewards_train/rejected': '-5.5039', 'rewards_train/margins': '5.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22931', 'examples_per_second': '5.9489', 'grad_norm': '4.3125', 'counters/examples': 266560, 'counters/updates': 16660}
skipping logging after 266576 examples to avoid logging too frequently
skipping logging after 266592 examples to avoid logging too frequently
skipping logging after 266608 examples to avoid logging too frequently
train stats after 266624 examples: {'rewards_train/chosen': '0.50715', 'rewards_train/rejected': '-5.7455', 'rewards_train/margins': '6.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21796', 'examples_per_second': '5.8648', 'grad_norm': '5.3125', 'counters/examples': 266624, 'counters/updates': 16664}
skipping logging after 266640 examples to avoid logging too frequently
skipping logging after 266656 examples to avoid logging too frequently
skipping logging after 266672 examples to avoid logging too frequently
train stats after 266688 examples: {'rewards_train/chosen': '-0.080583', 'rewards_train/rejected': '-5.9688', 'rewards_train/margins': '6.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28912', 'examples_per_second': '4.5548', 'grad_norm': '5.9062', 'counters/examples': 266688, 'counters/updates': 16668}
skipping logging after 266704 examples to avoid logging too frequently
skipping logging after 266720 examples to avoid logging too frequently
skipping logging after 266736 examples to avoid logging too frequently
train stats after 266752 examples: {'rewards_train/chosen': '-0.21872', 'rewards_train/rejected': '-7.766', 'rewards_train/margins': '7.6094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28912', 'examples_per_second': '4.8952', 'grad_norm': '5.0938', 'counters/examples': 266752, 'counters/updates': 16672}
skipping logging after 266768 examples to avoid logging too frequently
skipping logging after 266784 examples to avoid logging too frequently
skipping logging after 266800 examples to avoid logging too frequently
train stats after 266816 examples: {'rewards_train/chosen': '0.40161', 'rewards_train/rejected': '-6.2346', 'rewards_train/margins': '6.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20673', 'examples_per_second': '4.1571', 'grad_norm': '4.25', 'counters/examples': 266816, 'counters/updates': 16676}
skipping logging after 266832 examples to avoid logging too frequently
skipping logging after 266848 examples to avoid logging too frequently
skipping logging after 266864 examples to avoid logging too frequently
train stats after 266880 examples: {'rewards_train/chosen': '0.46783', 'rewards_train/rejected': '-5.7112', 'rewards_train/margins': '6.0273', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23169', 'examples_per_second': '5.9685', 'grad_norm': '4.5', 'counters/examples': 266880, 'counters/updates': 16680}
skipping logging after 266896 examples to avoid logging too frequently
skipping logging after 266912 examples to avoid logging too frequently
skipping logging after 266928 examples to avoid logging too frequently
train stats after 266944 examples: {'rewards_train/chosen': '0.58896', 'rewards_train/rejected': '-6.4289', 'rewards_train/margins': '7.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22992', 'examples_per_second': '4.3236', 'grad_norm': '4.8438', 'counters/examples': 266944, 'counters/updates': 16684}
skipping logging after 266960 examples to avoid logging too frequently
skipping logging after 266976 examples to avoid logging too frequently
skipping logging after 266992 examples to avoid logging too frequently
train stats after 267008 examples: {'rewards_train/chosen': '0.054695', 'rewards_train/rejected': '-6.4173', 'rewards_train/margins': '6.6562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25726', 'examples_per_second': '4.5951', 'grad_norm': '4.75', 'counters/examples': 267008, 'counters/updates': 16688}
skipping logging after 267024 examples to avoid logging too frequently
skipping logging after 267040 examples to avoid logging too frequently
skipping logging after 267056 examples to avoid logging too frequently
train stats after 267072 examples: {'rewards_train/chosen': '0.19849', 'rewards_train/rejected': '-7.1825', 'rewards_train/margins': '7.5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23553', 'examples_per_second': '5.4876', 'grad_norm': '4.5312', 'counters/examples': 267072, 'counters/updates': 16692}
skipping logging after 267088 examples to avoid logging too frequently
skipping logging after 267104 examples to avoid logging too frequently
skipping logging after 267120 examples to avoid logging too frequently
train stats after 267136 examples: {'rewards_train/chosen': '0.27533', 'rewards_train/rejected': '-5.9766', 'rewards_train/margins': '6.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21686', 'examples_per_second': '5.4425', 'grad_norm': '4.875', 'counters/examples': 267136, 'counters/updates': 16696}
skipping logging after 267152 examples to avoid logging too frequently
skipping logging after 267168 examples to avoid logging too frequently
skipping logging after 267184 examples to avoid logging too frequently
train stats after 267200 examples: {'rewards_train/chosen': '0.12084', 'rewards_train/rejected': '-6.4676', 'rewards_train/margins': '6.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18488', 'examples_per_second': '4.8179', 'grad_norm': '5.4688', 'counters/examples': 267200, 'counters/updates': 16700}
skipping logging after 267216 examples to avoid logging too frequently
skipping logging after 267232 examples to avoid logging too frequently
skipping logging after 267248 examples to avoid logging too frequently
train stats after 267264 examples: {'rewards_train/chosen': '0.31902', 'rewards_train/rejected': '-6.7241', 'rewards_train/margins': '7.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23468', 'examples_per_second': '4.8877', 'grad_norm': '5.6562', 'counters/examples': 267264, 'counters/updates': 16704}
skipping logging after 267280 examples to avoid logging too frequently
skipping logging after 267296 examples to avoid logging too frequently
skipping logging after 267312 examples to avoid logging too frequently
train stats after 267328 examples: {'rewards_train/chosen': '0.12991', 'rewards_train/rejected': '-4.6939', 'rewards_train/margins': '4.6133', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27118', 'examples_per_second': '5.2979', 'grad_norm': '5.4375', 'counters/examples': 267328, 'counters/updates': 16708}
skipping logging after 267344 examples to avoid logging too frequently
skipping logging after 267360 examples to avoid logging too frequently
skipping logging after 267376 examples to avoid logging too frequently
train stats after 267392 examples: {'rewards_train/chosen': '0.50014', 'rewards_train/rejected': '-4.866', 'rewards_train/margins': '5.5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21826', 'examples_per_second': '6.2827', 'grad_norm': '4.2188', 'counters/examples': 267392, 'counters/updates': 16712}
skipping logging after 267408 examples to avoid logging too frequently
skipping logging after 267424 examples to avoid logging too frequently
skipping logging after 267440 examples to avoid logging too frequently
train stats after 267456 examples: {'rewards_train/chosen': '0.13355', 'rewards_train/rejected': '-6.0342', 'rewards_train/margins': '6.1953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2973', 'examples_per_second': '5.057', 'grad_norm': '5.5938', 'counters/examples': 267456, 'counters/updates': 16716}
skipping logging after 267472 examples to avoid logging too frequently
skipping logging after 267488 examples to avoid logging too frequently
skipping logging after 267504 examples to avoid logging too frequently
train stats after 267520 examples: {'rewards_train/chosen': '0.38216', 'rewards_train/rejected': '-5.9375', 'rewards_train/margins': '6.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2749', 'examples_per_second': '5.4824', 'grad_norm': '6.0625', 'counters/examples': 267520, 'counters/updates': 16720}
skipping logging after 267536 examples to avoid logging too frequently
skipping logging after 267552 examples to avoid logging too frequently
skipping logging after 267568 examples to avoid logging too frequently
train stats after 267584 examples: {'rewards_train/chosen': '0.53821', 'rewards_train/rejected': '-5.7378', 'rewards_train/margins': '6.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2301', 'examples_per_second': '5.4987', 'grad_norm': '6.5938', 'counters/examples': 267584, 'counters/updates': 16724}
skipping logging after 267600 examples to avoid logging too frequently
skipping logging after 267616 examples to avoid logging too frequently
skipping logging after 267632 examples to avoid logging too frequently
train stats after 267648 examples: {'rewards_train/chosen': '0.40405', 'rewards_train/rejected': '-6.8958', 'rewards_train/margins': '7.3594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21509', 'examples_per_second': '5.4275', 'grad_norm': '4.875', 'counters/examples': 267648, 'counters/updates': 16728}
skipping logging after 267664 examples to avoid logging too frequently
skipping logging after 267680 examples to avoid logging too frequently
skipping logging after 267696 examples to avoid logging too frequently
train stats after 267712 examples: {'rewards_train/chosen': '0.020118', 'rewards_train/rejected': '-6.0761', 'rewards_train/margins': '6.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20453', 'examples_per_second': '5.2683', 'grad_norm': '5.3438', 'counters/examples': 267712, 'counters/updates': 16732}
skipping logging after 267728 examples to avoid logging too frequently
skipping logging after 267744 examples to avoid logging too frequently
skipping logging after 267760 examples to avoid logging too frequently
train stats after 267776 examples: {'rewards_train/chosen': '0.23931', 'rewards_train/rejected': '-7.0751', 'rewards_train/margins': '7.2969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25751', 'examples_per_second': '4.6525', 'grad_norm': '5.9688', 'counters/examples': 267776, 'counters/updates': 16736}
skipping logging after 267792 examples to avoid logging too frequently
skipping logging after 267808 examples to avoid logging too frequently
skipping logging after 267824 examples to avoid logging too frequently
train stats after 267840 examples: {'rewards_train/chosen': '0.38062', 'rewards_train/rejected': '-6.1551', 'rewards_train/margins': '6.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22424', 'examples_per_second': '5.2041', 'grad_norm': '5.1875', 'counters/examples': 267840, 'counters/updates': 16740}
skipping logging after 267856 examples to avoid logging too frequently
skipping logging after 267872 examples to avoid logging too frequently
skipping logging after 267888 examples to avoid logging too frequently
train stats after 267904 examples: {'rewards_train/chosen': '0.35243', 'rewards_train/rejected': '-5.4071', 'rewards_train/margins': '5.6445', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22949', 'examples_per_second': '5.3379', 'grad_norm': '5.7812', 'counters/examples': 267904, 'counters/updates': 16744}
skipping logging after 267920 examples to avoid logging too frequently
skipping logging after 267936 examples to avoid logging too frequently
skipping logging after 267952 examples to avoid logging too frequently
train stats after 267968 examples: {'rewards_train/chosen': '0.52481', 'rewards_train/rejected': '-6.7886', 'rewards_train/margins': '7.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23907', 'examples_per_second': '4.0963', 'grad_norm': '4.75', 'counters/examples': 267968, 'counters/updates': 16748}
skipping logging after 267984 examples to avoid logging too frequently
skipping logging after 268000 examples to avoid logging too frequently
Running evaluation after 268000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:51,  1.65s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:42,  1.42s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:36,  1.25s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.48s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.69s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.49s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:10<00:34,  1.37s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:20<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:28<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:12,  1.44s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.20s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:41<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]
eval after 268000: {'rewards_eval/chosen': '-6.0502', 'rewards_eval/rejected': '-6.5225', 'rewards_eval/margins': '0.31348', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.45937'}
skipping logging after 268016 examples to avoid logging too frequently
train stats after 268032 examples: {'rewards_train/chosen': '0.19219', 'rewards_train/rejected': '-6.7484', 'rewards_train/margins': '7.2109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27649', 'examples_per_second': '6.7248', 'grad_norm': '5.6875', 'counters/examples': 268032, 'counters/updates': 16752}
skipping logging after 268048 examples to avoid logging too frequently
skipping logging after 268064 examples to avoid logging too frequently
skipping logging after 268080 examples to avoid logging too frequently
train stats after 268096 examples: {'rewards_train/chosen': '0.19942', 'rewards_train/rejected': '-6.62', 'rewards_train/margins': '6.8906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21637', 'examples_per_second': '6.2121', 'grad_norm': '5.8125', 'counters/examples': 268096, 'counters/updates': 16756}
skipping logging after 268112 examples to avoid logging too frequently
skipping logging after 268128 examples to avoid logging too frequently
skipping logging after 268144 examples to avoid logging too frequently
train stats after 268160 examples: {'rewards_train/chosen': '0.43295', 'rewards_train/rejected': '-4.8902', 'rewards_train/margins': '5.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23511', 'examples_per_second': '5.4728', 'grad_norm': '5.3438', 'counters/examples': 268160, 'counters/updates': 16760}
skipping logging after 268176 examples to avoid logging too frequently
skipping logging after 268192 examples to avoid logging too frequently
skipping logging after 268208 examples to avoid logging too frequently
train stats after 268224 examples: {'rewards_train/chosen': '-0.18153', 'rewards_train/rejected': '-6.7296', 'rewards_train/margins': '6.7656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.31146', 'examples_per_second': '5.4982', 'grad_norm': '6.0312', 'counters/examples': 268224, 'counters/updates': 16764}
skipping logging after 268240 examples to avoid logging too frequently
skipping logging after 268256 examples to avoid logging too frequently
skipping logging after 268272 examples to avoid logging too frequently
train stats after 268288 examples: {'rewards_train/chosen': '0.5859', 'rewards_train/rejected': '-6.6937', 'rewards_train/margins': '7.0859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.16302', 'examples_per_second': '5.0117', 'grad_norm': '4.0938', 'counters/examples': 268288, 'counters/updates': 16768}
skipping logging after 268304 examples to avoid logging too frequently
skipping logging after 268320 examples to avoid logging too frequently
skipping logging after 268336 examples to avoid logging too frequently
train stats after 268352 examples: {'rewards_train/chosen': '0.49128', 'rewards_train/rejected': '-4.6586', 'rewards_train/margins': '5.1953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22241', 'examples_per_second': '5.9904', 'grad_norm': '4.9375', 'counters/examples': 268352, 'counters/updates': 16772}
skipping logging after 268368 examples to avoid logging too frequently
skipping logging after 268384 examples to avoid logging too frequently
skipping logging after 268400 examples to avoid logging too frequently
train stats after 268416 examples: {'rewards_train/chosen': '0.43721', 'rewards_train/rejected': '-4.3773', 'rewards_train/margins': '5.2422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27069', 'examples_per_second': '4.8451', 'grad_norm': '5.125', 'counters/examples': 268416, 'counters/updates': 16776}
skipping logging after 268432 examples to avoid logging too frequently
skipping logging after 268448 examples to avoid logging too frequently
skipping logging after 268464 examples to avoid logging too frequently
train stats after 268480 examples: {'rewards_train/chosen': '0.31949', 'rewards_train/rejected': '-6.5586', 'rewards_train/margins': '6.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26605', 'examples_per_second': '5.1813', 'grad_norm': '5.5938', 'counters/examples': 268480, 'counters/updates': 16780}
skipping logging after 268496 examples to avoid logging too frequently
skipping logging after 268512 examples to avoid logging too frequently
skipping logging after 268528 examples to avoid logging too frequently
train stats after 268544 examples: {'rewards_train/chosen': '0.48599', 'rewards_train/rejected': '-6.0958', 'rewards_train/margins': '6.375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23401', 'examples_per_second': '6.6457', 'grad_norm': '4.6562', 'counters/examples': 268544, 'counters/updates': 16784}
skipping logging after 268560 examples to avoid logging too frequently
skipping logging after 268576 examples to avoid logging too frequently
skipping logging after 268592 examples to avoid logging too frequently
train stats after 268608 examples: {'rewards_train/chosen': '-0.043618', 'rewards_train/rejected': '-6.3602', 'rewards_train/margins': '6.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25671', 'examples_per_second': '5.9761', 'grad_norm': '4.8438', 'counters/examples': 268608, 'counters/updates': 16788}
skipping logging after 268624 examples to avoid logging too frequently
skipping logging after 268640 examples to avoid logging too frequently
skipping logging after 268656 examples to avoid logging too frequently
train stats after 268672 examples: {'rewards_train/chosen': '0.46975', 'rewards_train/rejected': '-6.5231', 'rewards_train/margins': '6.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2196', 'examples_per_second': '5.2467', 'grad_norm': '5.1562', 'counters/examples': 268672, 'counters/updates': 16792}
skipping logging after 268688 examples to avoid logging too frequently
skipping logging after 268704 examples to avoid logging too frequently
skipping logging after 268720 examples to avoid logging too frequently
train stats after 268736 examples: {'rewards_train/chosen': '0.2298', 'rewards_train/rejected': '-6.2357', 'rewards_train/margins': '6.5508', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23987', 'examples_per_second': '5.8781', 'grad_norm': '4.4062', 'counters/examples': 268736, 'counters/updates': 16796}
skipping logging after 268752 examples to avoid logging too frequently
skipping logging after 268768 examples to avoid logging too frequently
skipping logging after 268784 examples to avoid logging too frequently
train stats after 268800 examples: {'rewards_train/chosen': '0.50748', 'rewards_train/rejected': '-6.9465', 'rewards_train/margins': '7.6328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23505', 'examples_per_second': '5.9946', 'grad_norm': '4.75', 'counters/examples': 268800, 'counters/updates': 16800}
skipping logging after 268816 examples to avoid logging too frequently
skipping logging after 268832 examples to avoid logging too frequently
skipping logging after 268848 examples to avoid logging too frequently
train stats after 268864 examples: {'rewards_train/chosen': '-0.078654', 'rewards_train/rejected': '-7.263', 'rewards_train/margins': '6.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30804', 'examples_per_second': '4.9839', 'grad_norm': '5.5312', 'counters/examples': 268864, 'counters/updates': 16804}
skipping logging after 268880 examples to avoid logging too frequently
skipping logging after 268896 examples to avoid logging too frequently
skipping logging after 268912 examples to avoid logging too frequently
train stats after 268928 examples: {'rewards_train/chosen': '0.38358', 'rewards_train/rejected': '-7.4514', 'rewards_train/margins': '7.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27301', 'examples_per_second': '5.0274', 'grad_norm': '6.2188', 'counters/examples': 268928, 'counters/updates': 16808}
skipping logging after 268944 examples to avoid logging too frequently
skipping logging after 268960 examples to avoid logging too frequently
skipping logging after 268976 examples to avoid logging too frequently
train stats after 268992 examples: {'rewards_train/chosen': '0.40285', 'rewards_train/rejected': '-7.0635', 'rewards_train/margins': '7.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22217', 'examples_per_second': '4.376', 'grad_norm': '5.4688', 'counters/examples': 268992, 'counters/updates': 16812}
skipping logging after 269008 examples to avoid logging too frequently
skipping logging after 269024 examples to avoid logging too frequently
skipping logging after 269040 examples to avoid logging too frequently
train stats after 269056 examples: {'rewards_train/chosen': '0.26178', 'rewards_train/rejected': '-6.1186', 'rewards_train/margins': '6.3672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21906', 'examples_per_second': '4.6393', 'grad_norm': '5.4375', 'counters/examples': 269056, 'counters/updates': 16816}
skipping logging after 269072 examples to avoid logging too frequently
skipping logging after 269088 examples to avoid logging too frequently
skipping logging after 269104 examples to avoid logging too frequently
train stats after 269120 examples: {'rewards_train/chosen': '0.57085', 'rewards_train/rejected': '-7.4753', 'rewards_train/margins': '8.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23248', 'examples_per_second': '4.9809', 'grad_norm': '5.25', 'counters/examples': 269120, 'counters/updates': 16820}
skipping logging after 269136 examples to avoid logging too frequently
skipping logging after 269152 examples to avoid logging too frequently
skipping logging after 269168 examples to avoid logging too frequently
train stats after 269184 examples: {'rewards_train/chosen': '0.0033285', 'rewards_train/rejected': '-6.1411', 'rewards_train/margins': '6.3828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24768', 'examples_per_second': '5.0657', 'grad_norm': '4.9062', 'counters/examples': 269184, 'counters/updates': 16824}
skipping logging after 269200 examples to avoid logging too frequently
skipping logging after 269216 examples to avoid logging too frequently
skipping logging after 269232 examples to avoid logging too frequently
train stats after 269248 examples: {'rewards_train/chosen': '0.44118', 'rewards_train/rejected': '-5.8496', 'rewards_train/margins': '6.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2525', 'examples_per_second': '4.4851', 'grad_norm': '5.7188', 'counters/examples': 269248, 'counters/updates': 16828}
skipping logging after 269264 examples to avoid logging too frequently
skipping logging after 269280 examples to avoid logging too frequently
skipping logging after 269296 examples to avoid logging too frequently
train stats after 269312 examples: {'rewards_train/chosen': '0.40175', 'rewards_train/rejected': '-6.5019', 'rewards_train/margins': '6.7422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2254', 'examples_per_second': '4.4695', 'grad_norm': '4.7812', 'counters/examples': 269312, 'counters/updates': 16832}
skipping logging after 269328 examples to avoid logging too frequently
skipping logging after 269344 examples to avoid logging too frequently
skipping logging after 269360 examples to avoid logging too frequently
train stats after 269376 examples: {'rewards_train/chosen': '0.25401', 'rewards_train/rejected': '-5.1221', 'rewards_train/margins': '5.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26379', 'examples_per_second': '6.715', 'grad_norm': '5.6875', 'counters/examples': 269376, 'counters/updates': 16836}
skipping logging after 269392 examples to avoid logging too frequently
skipping logging after 269408 examples to avoid logging too frequently
skipping logging after 269424 examples to avoid logging too frequently
train stats after 269440 examples: {'rewards_train/chosen': '0.23532', 'rewards_train/rejected': '-6.3125', 'rewards_train/margins': '6.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29352', 'examples_per_second': '5.4443', 'grad_norm': '5.3438', 'counters/examples': 269440, 'counters/updates': 16840}
skipping logging after 269456 examples to avoid logging too frequently
skipping logging after 269472 examples to avoid logging too frequently
skipping logging after 269488 examples to avoid logging too frequently
train stats after 269504 examples: {'rewards_train/chosen': '0.45466', 'rewards_train/rejected': '-5.4741', 'rewards_train/margins': '6.1172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23883', 'examples_per_second': '4.8824', 'grad_norm': '5.4062', 'counters/examples': 269504, 'counters/updates': 16844}
skipping logging after 269520 examples to avoid logging too frequently
skipping logging after 269536 examples to avoid logging too frequently
skipping logging after 269552 examples to avoid logging too frequently
train stats after 269568 examples: {'rewards_train/chosen': '0.4845', 'rewards_train/rejected': '-6.3005', 'rewards_train/margins': '7.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24036', 'examples_per_second': '5.1218', 'grad_norm': '5.4688', 'counters/examples': 269568, 'counters/updates': 16848}
skipping logging after 269584 examples to avoid logging too frequently
skipping logging after 269600 examples to avoid logging too frequently
skipping logging after 269616 examples to avoid logging too frequently
train stats after 269632 examples: {'rewards_train/chosen': '0.10667', 'rewards_train/rejected': '-5.4783', 'rewards_train/margins': '5.6367', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23895', 'examples_per_second': '5.7519', 'grad_norm': '5.4688', 'counters/examples': 269632, 'counters/updates': 16852}
skipping logging after 269648 examples to avoid logging too frequently
skipping logging after 269664 examples to avoid logging too frequently
skipping logging after 269680 examples to avoid logging too frequently
train stats after 269696 examples: {'rewards_train/chosen': '0.36832', 'rewards_train/rejected': '-6.5336', 'rewards_train/margins': '7.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25677', 'examples_per_second': '4.6223', 'grad_norm': '5.375', 'counters/examples': 269696, 'counters/updates': 16856}
skipping logging after 269712 examples to avoid logging too frequently
skipping logging after 269728 examples to avoid logging too frequently
skipping logging after 269744 examples to avoid logging too frequently
train stats after 269760 examples: {'rewards_train/chosen': '0.35927', 'rewards_train/rejected': '-5.8689', 'rewards_train/margins': '6.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23724', 'examples_per_second': '4.3906', 'grad_norm': '5.625', 'counters/examples': 269760, 'counters/updates': 16860}
skipping logging after 269776 examples to avoid logging too frequently
skipping logging after 269792 examples to avoid logging too frequently
skipping logging after 269808 examples to avoid logging too frequently
train stats after 269824 examples: {'rewards_train/chosen': '0.057739', 'rewards_train/rejected': '-6.0374', 'rewards_train/margins': '6.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21747', 'examples_per_second': '4.0999', 'grad_norm': '4.75', 'counters/examples': 269824, 'counters/updates': 16864}
skipping logging after 269840 examples to avoid logging too frequently
skipping logging after 269856 examples to avoid logging too frequently
skipping logging after 269872 examples to avoid logging too frequently
train stats after 269888 examples: {'rewards_train/chosen': '0.35819', 'rewards_train/rejected': '-7.2066', 'rewards_train/margins': '7.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23962', 'examples_per_second': '4.5748', 'grad_norm': '4.7812', 'counters/examples': 269888, 'counters/updates': 16868}
skipping logging after 269904 examples to avoid logging too frequently
skipping logging after 269920 examples to avoid logging too frequently
skipping logging after 269936 examples to avoid logging too frequently
train stats after 269952 examples: {'rewards_train/chosen': '0.36792', 'rewards_train/rejected': '-6.5227', 'rewards_train/margins': '7.0312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23462', 'examples_per_second': '4.8135', 'grad_norm': '4.4375', 'counters/examples': 269952, 'counters/updates': 16872}
skipping logging after 269968 examples to avoid logging too frequently
skipping logging after 269984 examples to avoid logging too frequently
skipping logging after 270000 examples to avoid logging too frequently
train stats after 270016 examples: {'rewards_train/chosen': '0.47953', 'rewards_train/rejected': '-6.3239', 'rewards_train/margins': '6.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19733', 'examples_per_second': '5.1817', 'grad_norm': '4.7812', 'counters/examples': 270016, 'counters/updates': 16876}
skipping logging after 270032 examples to avoid logging too frequently
skipping logging after 270048 examples to avoid logging too frequently
skipping logging after 270064 examples to avoid logging too frequently
train stats after 270080 examples: {'rewards_train/chosen': '0.37408', 'rewards_train/rejected': '-5.2566', 'rewards_train/margins': '5.7031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23132', 'examples_per_second': '5.0584', 'grad_norm': '4.6562', 'counters/examples': 270080, 'counters/updates': 16880}
skipping logging after 270096 examples to avoid logging too frequently
skipping logging after 270112 examples to avoid logging too frequently
skipping logging after 270128 examples to avoid logging too frequently
train stats after 270144 examples: {'rewards_train/chosen': '-0.25842', 'rewards_train/rejected': '-6.5043', 'rewards_train/margins': '6.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25323', 'examples_per_second': '5.5408', 'grad_norm': '5.4062', 'counters/examples': 270144, 'counters/updates': 16884}
skipping logging after 270160 examples to avoid logging too frequently
skipping logging after 270176 examples to avoid logging too frequently
skipping logging after 270192 examples to avoid logging too frequently
train stats after 270208 examples: {'rewards_train/chosen': '0.46926', 'rewards_train/rejected': '-5.7327', 'rewards_train/margins': '6.8828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27179', 'examples_per_second': '6.3257', 'grad_norm': '4.8438', 'counters/examples': 270208, 'counters/updates': 16888}
skipping logging after 270224 examples to avoid logging too frequently
skipping logging after 270240 examples to avoid logging too frequently
skipping logging after 270256 examples to avoid logging too frequently
train stats after 270272 examples: {'rewards_train/chosen': '0.42921', 'rewards_train/rejected': '-5.9656', 'rewards_train/margins': '6.2344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23987', 'examples_per_second': '5.6864', 'grad_norm': '5.0938', 'counters/examples': 270272, 'counters/updates': 16892}
skipping logging after 270288 examples to avoid logging too frequently
skipping logging after 270304 examples to avoid logging too frequently
skipping logging after 270320 examples to avoid logging too frequently
train stats after 270336 examples: {'rewards_train/chosen': '0.3467', 'rewards_train/rejected': '-6.3239', 'rewards_train/margins': '6.043', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2041', 'examples_per_second': '5.2492', 'grad_norm': '5.1875', 'counters/examples': 270336, 'counters/updates': 16896}
skipping logging after 270352 examples to avoid logging too frequently
skipping logging after 270368 examples to avoid logging too frequently
skipping logging after 270384 examples to avoid logging too frequently
train stats after 270400 examples: {'rewards_train/chosen': '0.20734', 'rewards_train/rejected': '-5.7436', 'rewards_train/margins': '5.5898', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26514', 'examples_per_second': '5.6905', 'grad_norm': '6.125', 'counters/examples': 270400, 'counters/updates': 16900}
skipping logging after 270416 examples to avoid logging too frequently
skipping logging after 270432 examples to avoid logging too frequently
skipping logging after 270448 examples to avoid logging too frequently
train stats after 270464 examples: {'rewards_train/chosen': '0.31675', 'rewards_train/rejected': '-6.5387', 'rewards_train/margins': '7.0195', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28741', 'examples_per_second': '5.5749', 'grad_norm': '5.2812', 'counters/examples': 270464, 'counters/updates': 16904}
skipping logging after 270480 examples to avoid logging too frequently
skipping logging after 270496 examples to avoid logging too frequently
skipping logging after 270512 examples to avoid logging too frequently
train stats after 270528 examples: {'rewards_train/chosen': '0.3078', 'rewards_train/rejected': '-4.5767', 'rewards_train/margins': '4.8164', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30304', 'examples_per_second': '5.2188', 'grad_norm': '5.5312', 'counters/examples': 270528, 'counters/updates': 16908}
skipping logging after 270544 examples to avoid logging too frequently
skipping logging after 270560 examples to avoid logging too frequently
skipping logging after 270576 examples to avoid logging too frequently
train stats after 270592 examples: {'rewards_train/chosen': '0.23067', 'rewards_train/rejected': '-5.5804', 'rewards_train/margins': '5.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28314', 'examples_per_second': '5.0291', 'grad_norm': '4.6875', 'counters/examples': 270592, 'counters/updates': 16912}
skipping logging after 270608 examples to avoid logging too frequently
skipping logging after 270624 examples to avoid logging too frequently
skipping logging after 270640 examples to avoid logging too frequently
train stats after 270656 examples: {'rewards_train/chosen': '-0.041567', 'rewards_train/rejected': '-6.848', 'rewards_train/margins': '6.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28467', 'examples_per_second': '5.5276', 'grad_norm': '5.9375', 'counters/examples': 270656, 'counters/updates': 16916}
skipping logging after 270672 examples to avoid logging too frequently
skipping logging after 270688 examples to avoid logging too frequently
skipping logging after 270704 examples to avoid logging too frequently
train stats after 270720 examples: {'rewards_train/chosen': '0.0036961', 'rewards_train/rejected': '-5.3891', 'rewards_train/margins': '5.2617', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24811', 'examples_per_second': '4.508', 'grad_norm': '4.5', 'counters/examples': 270720, 'counters/updates': 16920}
skipping logging after 270736 examples to avoid logging too frequently
skipping logging after 270752 examples to avoid logging too frequently
skipping logging after 270768 examples to avoid logging too frequently
train stats after 270784 examples: {'rewards_train/chosen': '0.25826', 'rewards_train/rejected': '-5.1523', 'rewards_train/margins': '5.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23633', 'examples_per_second': '6.486', 'grad_norm': '5.1562', 'counters/examples': 270784, 'counters/updates': 16924}
skipping logging after 270800 examples to avoid logging too frequently
skipping logging after 270816 examples to avoid logging too frequently
skipping logging after 270832 examples to avoid logging too frequently
train stats after 270848 examples: {'rewards_train/chosen': '0.21645', 'rewards_train/rejected': '-6.3718', 'rewards_train/margins': '6.5781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25647', 'examples_per_second': '5.7115', 'grad_norm': '5.0625', 'counters/examples': 270848, 'counters/updates': 16928}
skipping logging after 270864 examples to avoid logging too frequently
skipping logging after 270880 examples to avoid logging too frequently
skipping logging after 270896 examples to avoid logging too frequently
train stats after 270912 examples: {'rewards_train/chosen': '0.2555', 'rewards_train/rejected': '-6.3135', 'rewards_train/margins': '6.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21051', 'examples_per_second': '4.7307', 'grad_norm': '4.8125', 'counters/examples': 270912, 'counters/updates': 16932}
skipping logging after 270928 examples to avoid logging too frequently
skipping logging after 270944 examples to avoid logging too frequently
skipping logging after 270960 examples to avoid logging too frequently
train stats after 270976 examples: {'rewards_train/chosen': '0.27815', 'rewards_train/rejected': '-5.6378', 'rewards_train/margins': '5.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26257', 'examples_per_second': '5.1731', 'grad_norm': '4.875', 'counters/examples': 270976, 'counters/updates': 16936}
skipping logging after 270992 examples to avoid logging too frequently
skipping logging after 271008 examples to avoid logging too frequently
skipping logging after 271024 examples to avoid logging too frequently
train stats after 271040 examples: {'rewards_train/chosen': '0.2283', 'rewards_train/rejected': '-4.8955', 'rewards_train/margins': '5.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2771', 'examples_per_second': '5.5804', 'grad_norm': '5.1562', 'counters/examples': 271040, 'counters/updates': 16940}
skipping logging after 271056 examples to avoid logging too frequently
skipping logging after 271072 examples to avoid logging too frequently
skipping logging after 271088 examples to avoid logging too frequently
train stats after 271104 examples: {'rewards_train/chosen': '0.13265', 'rewards_train/rejected': '-6.5963', 'rewards_train/margins': '6.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25067', 'examples_per_second': '4.6763', 'grad_norm': '4.5625', 'counters/examples': 271104, 'counters/updates': 16944}
skipping logging after 271120 examples to avoid logging too frequently
skipping logging after 271136 examples to avoid logging too frequently
skipping logging after 271152 examples to avoid logging too frequently
train stats after 271168 examples: {'rewards_train/chosen': '0.2019', 'rewards_train/rejected': '-6.2006', 'rewards_train/margins': '6.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.245', 'examples_per_second': '5.3022', 'grad_norm': '4.9688', 'counters/examples': 271168, 'counters/updates': 16948}
skipping logging after 271184 examples to avoid logging too frequently
skipping logging after 271200 examples to avoid logging too frequently
skipping logging after 271216 examples to avoid logging too frequently
train stats after 271232 examples: {'rewards_train/chosen': '0.43097', 'rewards_train/rejected': '-6.0675', 'rewards_train/margins': '6.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24109', 'examples_per_second': '5.0127', 'grad_norm': '5.3438', 'counters/examples': 271232, 'counters/updates': 16952}
skipping logging after 271248 examples to avoid logging too frequently
skipping logging after 271264 examples to avoid logging too frequently
skipping logging after 271280 examples to avoid logging too frequently
train stats after 271296 examples: {'rewards_train/chosen': '-0.22874', 'rewards_train/rejected': '-7.3243', 'rewards_train/margins': '7.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27313', 'examples_per_second': '6.6017', 'grad_norm': '5.375', 'counters/examples': 271296, 'counters/updates': 16956}
skipping logging after 271312 examples to avoid logging too frequently
skipping logging after 271328 examples to avoid logging too frequently
skipping logging after 271344 examples to avoid logging too frequently
train stats after 271360 examples: {'rewards_train/chosen': '0.19142', 'rewards_train/rejected': '-4.9215', 'rewards_train/margins': '4.6602', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27295', 'examples_per_second': '4.9335', 'grad_norm': '5.0625', 'counters/examples': 271360, 'counters/updates': 16960}
skipping logging after 271376 examples to avoid logging too frequently
skipping logging after 271392 examples to avoid logging too frequently
skipping logging after 271408 examples to avoid logging too frequently
train stats after 271424 examples: {'rewards_train/chosen': '0.4128', 'rewards_train/rejected': '-4.9675', 'rewards_train/margins': '5.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22491', 'examples_per_second': '5.5546', 'grad_norm': '5.5938', 'counters/examples': 271424, 'counters/updates': 16964}
skipping logging after 271440 examples to avoid logging too frequently
skipping logging after 271456 examples to avoid logging too frequently
skipping logging after 271472 examples to avoid logging too frequently
train stats after 271488 examples: {'rewards_train/chosen': '0.37664', 'rewards_train/rejected': '-7.2414', 'rewards_train/margins': '7.3281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29224', 'examples_per_second': '5.724', 'grad_norm': '5.25', 'counters/examples': 271488, 'counters/updates': 16968}
skipping logging after 271504 examples to avoid logging too frequently
skipping logging after 271520 examples to avoid logging too frequently
skipping logging after 271536 examples to avoid logging too frequently
train stats after 271552 examples: {'rewards_train/chosen': '0.097957', 'rewards_train/rejected': '-6.3198', 'rewards_train/margins': '6.4062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22101', 'examples_per_second': '5.5274', 'grad_norm': '4.2812', 'counters/examples': 271552, 'counters/updates': 16972}
skipping logging after 271568 examples to avoid logging too frequently
skipping logging after 271584 examples to avoid logging too frequently
skipping logging after 271600 examples to avoid logging too frequently
train stats after 271616 examples: {'rewards_train/chosen': '0.50351', 'rewards_train/rejected': '-5.9307', 'rewards_train/margins': '6.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21484', 'examples_per_second': '4.4797', 'grad_norm': '5.1562', 'counters/examples': 271616, 'counters/updates': 16976}
skipping logging after 271632 examples to avoid logging too frequently
skipping logging after 271648 examples to avoid logging too frequently
skipping logging after 271664 examples to avoid logging too frequently
train stats after 271680 examples: {'rewards_train/chosen': '0.13715', 'rewards_train/rejected': '-6.1316', 'rewards_train/margins': '6.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29816', 'examples_per_second': '5.7383', 'grad_norm': '4.75', 'counters/examples': 271680, 'counters/updates': 16980}
skipping logging after 271696 examples to avoid logging too frequently
skipping logging after 271712 examples to avoid logging too frequently
skipping logging after 271728 examples to avoid logging too frequently
train stats after 271744 examples: {'rewards_train/chosen': '0.3655', 'rewards_train/rejected': '-5.3679', 'rewards_train/margins': '5.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24152', 'examples_per_second': '4.7364', 'grad_norm': '4.9375', 'counters/examples': 271744, 'counters/updates': 16984}
skipping logging after 271760 examples to avoid logging too frequently
skipping logging after 271776 examples to avoid logging too frequently
skipping logging after 271792 examples to avoid logging too frequently
train stats after 271808 examples: {'rewards_train/chosen': '0.38409', 'rewards_train/rejected': '-6.52', 'rewards_train/margins': '6.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2356', 'examples_per_second': '4.3535', 'grad_norm': '5.625', 'counters/examples': 271808, 'counters/updates': 16988}
skipping logging after 271824 examples to avoid logging too frequently
skipping logging after 271840 examples to avoid logging too frequently
skipping logging after 271856 examples to avoid logging too frequently
train stats after 271872 examples: {'rewards_train/chosen': '0.39674', 'rewards_train/rejected': '-5.3343', 'rewards_train/margins': '6', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2547', 'examples_per_second': '5.2543', 'grad_norm': '4.875', 'counters/examples': 271872, 'counters/updates': 16992}
skipping logging after 271888 examples to avoid logging too frequently
skipping logging after 271904 examples to avoid logging too frequently
skipping logging after 271920 examples to avoid logging too frequently
train stats after 271936 examples: {'rewards_train/chosen': '-0.081935', 'rewards_train/rejected': '-5.9743', 'rewards_train/margins': '5.8984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23737', 'examples_per_second': '6.8985', 'grad_norm': '4.7188', 'counters/examples': 271936, 'counters/updates': 16996}
skipping logging after 271952 examples to avoid logging too frequently
skipping logging after 271968 examples to avoid logging too frequently
skipping logging after 271984 examples to avoid logging too frequently
train stats after 272000 examples: {'rewards_train/chosen': '0.28957', 'rewards_train/rejected': '-5.4042', 'rewards_train/margins': '5.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24023', 'examples_per_second': '5.6384', 'grad_norm': '4.9062', 'counters/examples': 272000, 'counters/updates': 17000}
Running evaluation after 272000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.26s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.17s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:40,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.66s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.48s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:34,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.41s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.28s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.16s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.51s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.37s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.42s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.20s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.31s/it]
eval after 272000: {'rewards_eval/chosen': '-6.0705', 'rewards_eval/rejected': '-6.606', 'rewards_eval/margins': '0.37402', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46088'}
skipping logging after 272016 examples to avoid logging too frequently
skipping logging after 272032 examples to avoid logging too frequently
skipping logging after 272048 examples to avoid logging too frequently
train stats after 272064 examples: {'rewards_train/chosen': '0.63673', 'rewards_train/rejected': '-7.7327', 'rewards_train/margins': '8.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19843', 'examples_per_second': '6.1302', 'grad_norm': '4.9688', 'counters/examples': 272064, 'counters/updates': 17004}
skipping logging after 272080 examples to avoid logging too frequently
skipping logging after 272096 examples to avoid logging too frequently
skipping logging after 272112 examples to avoid logging too frequently
train stats after 272128 examples: {'rewards_train/chosen': '0.25238', 'rewards_train/rejected': '-8.0842', 'rewards_train/margins': '8.3281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22668', 'examples_per_second': '5.3535', 'grad_norm': '4.4062', 'counters/examples': 272128, 'counters/updates': 17008}
skipping logging after 272144 examples to avoid logging too frequently
skipping logging after 272160 examples to avoid logging too frequently
skipping logging after 272176 examples to avoid logging too frequently
train stats after 272192 examples: {'rewards_train/chosen': '0.18516', 'rewards_train/rejected': '-5.9211', 'rewards_train/margins': '6.3281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27832', 'examples_per_second': '5.3344', 'grad_norm': '5.8438', 'counters/examples': 272192, 'counters/updates': 17012}
skipping logging after 272208 examples to avoid logging too frequently
skipping logging after 272224 examples to avoid logging too frequently
skipping logging after 272240 examples to avoid logging too frequently
train stats after 272256 examples: {'rewards_train/chosen': '0.30099', 'rewards_train/rejected': '-6.3148', 'rewards_train/margins': '6.5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21643', 'examples_per_second': '4.8004', 'grad_norm': '4.5938', 'counters/examples': 272256, 'counters/updates': 17016}
skipping logging after 272272 examples to avoid logging too frequently
skipping logging after 272288 examples to avoid logging too frequently
skipping logging after 272304 examples to avoid logging too frequently
train stats after 272320 examples: {'rewards_train/chosen': '0.2427', 'rewards_train/rejected': '-5.7272', 'rewards_train/margins': '5.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29193', 'examples_per_second': '4.3977', 'grad_norm': '6.625', 'counters/examples': 272320, 'counters/updates': 17020}
skipping logging after 272336 examples to avoid logging too frequently
skipping logging after 272352 examples to avoid logging too frequently
skipping logging after 272368 examples to avoid logging too frequently
train stats after 272384 examples: {'rewards_train/chosen': '0.48637', 'rewards_train/rejected': '-6.6594', 'rewards_train/margins': '7.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21747', 'examples_per_second': '4.8533', 'grad_norm': '4.9688', 'counters/examples': 272384, 'counters/updates': 17024}
skipping logging after 272400 examples to avoid logging too frequently
skipping logging after 272416 examples to avoid logging too frequently
skipping logging after 272432 examples to avoid logging too frequently
train stats after 272448 examples: {'rewards_train/chosen': '0.36678', 'rewards_train/rejected': '-4.85', 'rewards_train/margins': '5.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.32141', 'examples_per_second': '5.0277', 'grad_norm': '6.5312', 'counters/examples': 272448, 'counters/updates': 17028}
skipping logging after 272464 examples to avoid logging too frequently
skipping logging after 272480 examples to avoid logging too frequently
skipping logging after 272496 examples to avoid logging too frequently
train stats after 272512 examples: {'rewards_train/chosen': '0.49808', 'rewards_train/rejected': '-4.9965', 'rewards_train/margins': '5.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21173', 'examples_per_second': '5.1388', 'grad_norm': '5.1875', 'counters/examples': 272512, 'counters/updates': 17032}
skipping logging after 272528 examples to avoid logging too frequently
skipping logging after 272544 examples to avoid logging too frequently
skipping logging after 272560 examples to avoid logging too frequently
train stats after 272576 examples: {'rewards_train/chosen': '-0.12796', 'rewards_train/rejected': '-5.8585', 'rewards_train/margins': '5.4336', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22711', 'examples_per_second': '5.336', 'grad_norm': '6.5938', 'counters/examples': 272576, 'counters/updates': 17036}
skipping logging after 272592 examples to avoid logging too frequently
skipping logging after 272608 examples to avoid logging too frequently
skipping logging after 272624 examples to avoid logging too frequently
train stats after 272640 examples: {'rewards_train/chosen': '0.058736', 'rewards_train/rejected': '-5.1771', 'rewards_train/margins': '5.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28027', 'examples_per_second': '4.0103', 'grad_norm': '5.7812', 'counters/examples': 272640, 'counters/updates': 17040}
skipping logging after 272656 examples to avoid logging too frequently
skipping logging after 272672 examples to avoid logging too frequently
skipping logging after 272688 examples to avoid logging too frequently
train stats after 272704 examples: {'rewards_train/chosen': '0.24693', 'rewards_train/rejected': '-6.9768', 'rewards_train/margins': '7.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2345', 'examples_per_second': '4.912', 'grad_norm': '4.9688', 'counters/examples': 272704, 'counters/updates': 17044}
skipping logging after 272720 examples to avoid logging too frequently
skipping logging after 272736 examples to avoid logging too frequently
skipping logging after 272752 examples to avoid logging too frequently
train stats after 272768 examples: {'rewards_train/chosen': '0.36336', 'rewards_train/rejected': '-5.3334', 'rewards_train/margins': '5.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23407', 'examples_per_second': '5.9655', 'grad_norm': '5.25', 'counters/examples': 272768, 'counters/updates': 17048}
skipping logging after 272784 examples to avoid logging too frequently
skipping logging after 272800 examples to avoid logging too frequently
skipping logging after 272816 examples to avoid logging too frequently
train stats after 272832 examples: {'rewards_train/chosen': '0.455', 'rewards_train/rejected': '-5.8677', 'rewards_train/margins': '6.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22162', 'examples_per_second': '5.067', 'grad_norm': '4.4375', 'counters/examples': 272832, 'counters/updates': 17052}
skipping logging after 272848 examples to avoid logging too frequently
skipping logging after 272864 examples to avoid logging too frequently
skipping logging after 272880 examples to avoid logging too frequently
train stats after 272896 examples: {'rewards_train/chosen': '0.33795', 'rewards_train/rejected': '-6.5028', 'rewards_train/margins': '6.8906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2511', 'examples_per_second': '5.1819', 'grad_norm': '5.2188', 'counters/examples': 272896, 'counters/updates': 17056}
skipping logging after 272912 examples to avoid logging too frequently
skipping logging after 272928 examples to avoid logging too frequently
skipping logging after 272944 examples to avoid logging too frequently
train stats after 272960 examples: {'rewards_train/chosen': '0.55409', 'rewards_train/rejected': '-5.1432', 'rewards_train/margins': '5.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24908', 'examples_per_second': '4.8892', 'grad_norm': '5.4375', 'counters/examples': 272960, 'counters/updates': 17060}
skipping logging after 272976 examples to avoid logging too frequently
skipping logging after 272992 examples to avoid logging too frequently
skipping logging after 273008 examples to avoid logging too frequently
train stats after 273024 examples: {'rewards_train/chosen': '0.35892', 'rewards_train/rejected': '-6.9724', 'rewards_train/margins': '7.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27649', 'examples_per_second': '5.0127', 'grad_norm': '5.8438', 'counters/examples': 273024, 'counters/updates': 17064}
skipping logging after 273040 examples to avoid logging too frequently
skipping logging after 273056 examples to avoid logging too frequently
skipping logging after 273072 examples to avoid logging too frequently
train stats after 273088 examples: {'rewards_train/chosen': '0.42396', 'rewards_train/rejected': '-6.8017', 'rewards_train/margins': '6.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21307', 'examples_per_second': '5.4882', 'grad_norm': '4.4375', 'counters/examples': 273088, 'counters/updates': 17068}
skipping logging after 273104 examples to avoid logging too frequently
skipping logging after 273120 examples to avoid logging too frequently
skipping logging after 273136 examples to avoid logging too frequently
train stats after 273152 examples: {'rewards_train/chosen': '0.16102', 'rewards_train/rejected': '-5.7051', 'rewards_train/margins': '5.6875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19525', 'examples_per_second': '6.1622', 'grad_norm': '4.75', 'counters/examples': 273152, 'counters/updates': 17072}
skipping logging after 273168 examples to avoid logging too frequently
skipping logging after 273184 examples to avoid logging too frequently
skipping logging after 273200 examples to avoid logging too frequently
train stats after 273216 examples: {'rewards_train/chosen': '0.48061', 'rewards_train/rejected': '-6.1023', 'rewards_train/margins': '6.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21265', 'examples_per_second': '5.5694', 'grad_norm': '4.625', 'counters/examples': 273216, 'counters/updates': 17076}
skipping logging after 273232 examples to avoid logging too frequently
skipping logging after 273248 examples to avoid logging too frequently
skipping logging after 273264 examples to avoid logging too frequently
train stats after 273280 examples: {'rewards_train/chosen': '0.74086', 'rewards_train/rejected': '-7.9071', 'rewards_train/margins': '8.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24445', 'examples_per_second': '4.761', 'grad_norm': '5.4375', 'counters/examples': 273280, 'counters/updates': 17080}
skipping logging after 273296 examples to avoid logging too frequently
skipping logging after 273312 examples to avoid logging too frequently
skipping logging after 273328 examples to avoid logging too frequently
train stats after 273344 examples: {'rewards_train/chosen': '0.15613', 'rewards_train/rejected': '-5.2749', 'rewards_train/margins': '5.2969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2655', 'examples_per_second': '4.6662', 'grad_norm': '4.5938', 'counters/examples': 273344, 'counters/updates': 17084}
skipping logging after 273360 examples to avoid logging too frequently
skipping logging after 273376 examples to avoid logging too frequently
skipping logging after 273392 examples to avoid logging too frequently
train stats after 273408 examples: {'rewards_train/chosen': '0.40357', 'rewards_train/rejected': '-5.3518', 'rewards_train/margins': '5.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2337', 'examples_per_second': '5.2871', 'grad_norm': '5.375', 'counters/examples': 273408, 'counters/updates': 17088}
skipping logging after 273424 examples to avoid logging too frequently
skipping logging after 273440 examples to avoid logging too frequently
skipping logging after 273456 examples to avoid logging too frequently
train stats after 273472 examples: {'rewards_train/chosen': '0.38317', 'rewards_train/rejected': '-7.2457', 'rewards_train/margins': '7.6328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1806', 'examples_per_second': '5.3273', 'grad_norm': '5.2188', 'counters/examples': 273472, 'counters/updates': 17092}
skipping logging after 273488 examples to avoid logging too frequently
skipping logging after 273504 examples to avoid logging too frequently
skipping logging after 273520 examples to avoid logging too frequently
train stats after 273536 examples: {'rewards_train/chosen': '0.26703', 'rewards_train/rejected': '-5.6129', 'rewards_train/margins': '5.7031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26105', 'examples_per_second': '5.1127', 'grad_norm': '5.6562', 'counters/examples': 273536, 'counters/updates': 17096}
skipping logging after 273552 examples to avoid logging too frequently
skipping logging after 273568 examples to avoid logging too frequently
skipping logging after 273584 examples to avoid logging too frequently
train stats after 273600 examples: {'rewards_train/chosen': '0.12996', 'rewards_train/rejected': '-5.9937', 'rewards_train/margins': '6.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28278', 'examples_per_second': '5.2258', 'grad_norm': '5.5312', 'counters/examples': 273600, 'counters/updates': 17100}
skipping logging after 273616 examples to avoid logging too frequently
skipping logging after 273632 examples to avoid logging too frequently
skipping logging after 273648 examples to avoid logging too frequently
train stats after 273664 examples: {'rewards_train/chosen': '0.30297', 'rewards_train/rejected': '-6.0751', 'rewards_train/margins': '6.1445', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25', 'examples_per_second': '4.5891', 'grad_norm': '5.4688', 'counters/examples': 273664, 'counters/updates': 17104}
skipping logging after 273680 examples to avoid logging too frequently
skipping logging after 273696 examples to avoid logging too frequently
skipping logging after 273712 examples to avoid logging too frequently
train stats after 273728 examples: {'rewards_train/chosen': '0.24294', 'rewards_train/rejected': '-6.5569', 'rewards_train/margins': '6.5117', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2334', 'examples_per_second': '4.982', 'grad_norm': '4.1562', 'counters/examples': 273728, 'counters/updates': 17108}
skipping logging after 273744 examples to avoid logging too frequently
skipping logging after 273760 examples to avoid logging too frequently
skipping logging after 273776 examples to avoid logging too frequently
train stats after 273792 examples: {'rewards_train/chosen': '0.36643', 'rewards_train/rejected': '-6.3573', 'rewards_train/margins': '6.7109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21692', 'examples_per_second': '4.1206', 'grad_norm': '5.8438', 'counters/examples': 273792, 'counters/updates': 17112}
skipping logging after 273808 examples to avoid logging too frequently
skipping logging after 273824 examples to avoid logging too frequently
skipping logging after 273840 examples to avoid logging too frequently
train stats after 273856 examples: {'rewards_train/chosen': '0.47858', 'rewards_train/rejected': '-6.5121', 'rewards_train/margins': '6.8906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24597', 'examples_per_second': '4.6211', 'grad_norm': '5.375', 'counters/examples': 273856, 'counters/updates': 17116}
skipping logging after 273872 examples to avoid logging too frequently
skipping logging after 273888 examples to avoid logging too frequently
skipping logging after 273904 examples to avoid logging too frequently
train stats after 273920 examples: {'rewards_train/chosen': '0.34318', 'rewards_train/rejected': '-6.5809', 'rewards_train/margins': '6.8828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2171', 'examples_per_second': '5.0475', 'grad_norm': '4.7188', 'counters/examples': 273920, 'counters/updates': 17120}
skipping logging after 273936 examples to avoid logging too frequently
skipping logging after 273952 examples to avoid logging too frequently
skipping logging after 273968 examples to avoid logging too frequently
train stats after 273984 examples: {'rewards_train/chosen': '0.25005', 'rewards_train/rejected': '-5.4523', 'rewards_train/margins': '5.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24554', 'examples_per_second': '5.9605', 'grad_norm': '4.4688', 'counters/examples': 273984, 'counters/updates': 17124}
skipping logging after 274000 examples to avoid logging too frequently
skipping logging after 274016 examples to avoid logging too frequently
skipping logging after 274032 examples to avoid logging too frequently
train stats after 274048 examples: {'rewards_train/chosen': '0.20463', 'rewards_train/rejected': '-5.708', 'rewards_train/margins': '5.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2843', 'examples_per_second': '5.1136', 'grad_norm': '6.1875', 'counters/examples': 274048, 'counters/updates': 17128}
skipping logging after 274064 examples to avoid logging too frequently
skipping logging after 274080 examples to avoid logging too frequently
skipping logging after 274096 examples to avoid logging too frequently
train stats after 274112 examples: {'rewards_train/chosen': '0.028479', 'rewards_train/rejected': '-6.0354', 'rewards_train/margins': '6.0156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25781', 'examples_per_second': '4.334', 'grad_norm': '4.5312', 'counters/examples': 274112, 'counters/updates': 17132}
skipping logging after 274128 examples to avoid logging too frequently
skipping logging after 274144 examples to avoid logging too frequently
skipping logging after 274160 examples to avoid logging too frequently
train stats after 274176 examples: {'rewards_train/chosen': '0.65278', 'rewards_train/rejected': '-6.2689', 'rewards_train/margins': '6.7812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24353', 'examples_per_second': '4.6075', 'grad_norm': '5.3438', 'counters/examples': 274176, 'counters/updates': 17136}
skipping logging after 274192 examples to avoid logging too frequently
skipping logging after 274208 examples to avoid logging too frequently
skipping logging after 274224 examples to avoid logging too frequently
train stats after 274240 examples: {'rewards_train/chosen': '0.25312', 'rewards_train/rejected': '-6.3156', 'rewards_train/margins': '6.5938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20294', 'examples_per_second': '5.6806', 'grad_norm': '4.9375', 'counters/examples': 274240, 'counters/updates': 17140}
skipping logging after 274256 examples to avoid logging too frequently
skipping logging after 274272 examples to avoid logging too frequently
skipping logging after 274288 examples to avoid logging too frequently
train stats after 274304 examples: {'rewards_train/chosen': '0.16066', 'rewards_train/rejected': '-5.7362', 'rewards_train/margins': '5.6484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23712', 'examples_per_second': '5.1278', 'grad_norm': '4.875', 'counters/examples': 274304, 'counters/updates': 17144}
skipping logging after 274320 examples to avoid logging too frequently
skipping logging after 274336 examples to avoid logging too frequently
skipping logging after 274352 examples to avoid logging too frequently
train stats after 274368 examples: {'rewards_train/chosen': '0.46874', 'rewards_train/rejected': '-6.7874', 'rewards_train/margins': '7.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26672', 'examples_per_second': '4.9284', 'grad_norm': '5.3125', 'counters/examples': 274368, 'counters/updates': 17148}
skipping logging after 274384 examples to avoid logging too frequently
skipping logging after 274400 examples to avoid logging too frequently
skipping logging after 274416 examples to avoid logging too frequently
train stats after 274432 examples: {'rewards_train/chosen': '0.49728', 'rewards_train/rejected': '-6.0404', 'rewards_train/margins': '6.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22296', 'examples_per_second': '4.3744', 'grad_norm': '4.7188', 'counters/examples': 274432, 'counters/updates': 17152}
skipping logging after 274448 examples to avoid logging too frequently
skipping logging after 274464 examples to avoid logging too frequently
skipping logging after 274480 examples to avoid logging too frequently
train stats after 274496 examples: {'rewards_train/chosen': '0.62223', 'rewards_train/rejected': '-7.0258', 'rewards_train/margins': '7.6328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.16656', 'examples_per_second': '5.2899', 'grad_norm': '4.4375', 'counters/examples': 274496, 'counters/updates': 17156}
skipping logging after 274512 examples to avoid logging too frequently
skipping logging after 274528 examples to avoid logging too frequently
skipping logging after 274544 examples to avoid logging too frequently
train stats after 274560 examples: {'rewards_train/chosen': '0.34485', 'rewards_train/rejected': '-6.3494', 'rewards_train/margins': '6.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22687', 'examples_per_second': '5.0757', 'grad_norm': '5.5938', 'counters/examples': 274560, 'counters/updates': 17160}
skipping logging after 274576 examples to avoid logging too frequently
skipping logging after 274592 examples to avoid logging too frequently
skipping logging after 274608 examples to avoid logging too frequently
train stats after 274624 examples: {'rewards_train/chosen': '0.42387', 'rewards_train/rejected': '-5.319', 'rewards_train/margins': '5.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21729', 'examples_per_second': '5.5179', 'grad_norm': '4.9375', 'counters/examples': 274624, 'counters/updates': 17164}
skipping logging after 274640 examples to avoid logging too frequently
skipping logging after 274656 examples to avoid logging too frequently
skipping logging after 274672 examples to avoid logging too frequently
train stats after 274688 examples: {'rewards_train/chosen': '0.10204', 'rewards_train/rejected': '-5.6217', 'rewards_train/margins': '5.6328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20911', 'examples_per_second': '4.9777', 'grad_norm': '4.7188', 'counters/examples': 274688, 'counters/updates': 17168}
skipping logging after 274704 examples to avoid logging too frequently
skipping logging after 274720 examples to avoid logging too frequently
skipping logging after 274736 examples to avoid logging too frequently
train stats after 274752 examples: {'rewards_train/chosen': '0.2068', 'rewards_train/rejected': '-6.6103', 'rewards_train/margins': '6.7578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26611', 'examples_per_second': '4.9455', 'grad_norm': '4.9062', 'counters/examples': 274752, 'counters/updates': 17172}
skipping logging after 274768 examples to avoid logging too frequently
skipping logging after 274784 examples to avoid logging too frequently
skipping logging after 274800 examples to avoid logging too frequently
train stats after 274816 examples: {'rewards_train/chosen': '0.24251', 'rewards_train/rejected': '-6.0614', 'rewards_train/margins': '6.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25214', 'examples_per_second': '4.8539', 'grad_norm': '5.0312', 'counters/examples': 274816, 'counters/updates': 17176}
skipping logging after 274832 examples to avoid logging too frequently
skipping logging after 274848 examples to avoid logging too frequently
skipping logging after 274864 examples to avoid logging too frequently
train stats after 274880 examples: {'rewards_train/chosen': '0.16667', 'rewards_train/rejected': '-6.8711', 'rewards_train/margins': '7.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23816', 'examples_per_second': '5.5988', 'grad_norm': '4.125', 'counters/examples': 274880, 'counters/updates': 17180}
skipping logging after 274896 examples to avoid logging too frequently
skipping logging after 274912 examples to avoid logging too frequently
skipping logging after 274928 examples to avoid logging too frequently
train stats after 274944 examples: {'rewards_train/chosen': '0.059863', 'rewards_train/rejected': '-6.062', 'rewards_train/margins': '6.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22552', 'examples_per_second': '4.9287', 'grad_norm': '4.4062', 'counters/examples': 274944, 'counters/updates': 17184}
skipping logging after 274960 examples to avoid logging too frequently
skipping logging after 274976 examples to avoid logging too frequently
skipping logging after 274992 examples to avoid logging too frequently
train stats after 275008 examples: {'rewards_train/chosen': '0.41978', 'rewards_train/rejected': '-5.777', 'rewards_train/margins': '6.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23425', 'examples_per_second': '4.5664', 'grad_norm': '5', 'counters/examples': 275008, 'counters/updates': 17188}
skipping logging after 275024 examples to avoid logging too frequently
skipping logging after 275040 examples to avoid logging too frequently
skipping logging after 275056 examples to avoid logging too frequently
train stats after 275072 examples: {'rewards_train/chosen': '0.25125', 'rewards_train/rejected': '-6.2671', 'rewards_train/margins': '6.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23102', 'examples_per_second': '5.6867', 'grad_norm': '4.4688', 'counters/examples': 275072, 'counters/updates': 17192}
skipping logging after 275088 examples to avoid logging too frequently
skipping logging after 275104 examples to avoid logging too frequently
skipping logging after 275120 examples to avoid logging too frequently
train stats after 275136 examples: {'rewards_train/chosen': '0.34878', 'rewards_train/rejected': '-6.3466', 'rewards_train/margins': '6.6875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23492', 'examples_per_second': '5.2028', 'grad_norm': '4.5', 'counters/examples': 275136, 'counters/updates': 17196}
skipping logging after 275152 examples to avoid logging too frequently
skipping logging after 275168 examples to avoid logging too frequently
skipping logging after 275184 examples to avoid logging too frequently
train stats after 275200 examples: {'rewards_train/chosen': '-0.033495', 'rewards_train/rejected': '-6.6098', 'rewards_train/margins': '6.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.33252', 'examples_per_second': '5.5504', 'grad_norm': '5.6875', 'counters/examples': 275200, 'counters/updates': 17200}
skipping logging after 275216 examples to avoid logging too frequently
skipping logging after 275232 examples to avoid logging too frequently
skipping logging after 275248 examples to avoid logging too frequently
train stats after 275264 examples: {'rewards_train/chosen': '0.36267', 'rewards_train/rejected': '-6.2886', 'rewards_train/margins': '6.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24573', 'examples_per_second': '5.6872', 'grad_norm': '4.375', 'counters/examples': 275264, 'counters/updates': 17204}
skipping logging after 275280 examples to avoid logging too frequently
skipping logging after 275296 examples to avoid logging too frequently
skipping logging after 275312 examples to avoid logging too frequently
train stats after 275328 examples: {'rewards_train/chosen': '0.40519', 'rewards_train/rejected': '-6.1011', 'rewards_train/margins': '6.5', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21625', 'examples_per_second': '4.5594', 'grad_norm': '5.0625', 'counters/examples': 275328, 'counters/updates': 17208}
skipping logging after 275344 examples to avoid logging too frequently
skipping logging after 275360 examples to avoid logging too frequently
skipping logging after 275376 examples to avoid logging too frequently
train stats after 275392 examples: {'rewards_train/chosen': '0.59294', 'rewards_train/rejected': '-6.8593', 'rewards_train/margins': '7.3281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25055', 'examples_per_second': '5.3097', 'grad_norm': '5.0625', 'counters/examples': 275392, 'counters/updates': 17212}
skipping logging after 275408 examples to avoid logging too frequently
skipping logging after 275424 examples to avoid logging too frequently
skipping logging after 275440 examples to avoid logging too frequently
train stats after 275456 examples: {'rewards_train/chosen': '0.54996', 'rewards_train/rejected': '-6.9189', 'rewards_train/margins': '7.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23633', 'examples_per_second': '4.4281', 'grad_norm': '5.25', 'counters/examples': 275456, 'counters/updates': 17216}
skipping logging after 275472 examples to avoid logging too frequently
skipping logging after 275488 examples to avoid logging too frequently
skipping logging after 275504 examples to avoid logging too frequently
train stats after 275520 examples: {'rewards_train/chosen': '0.10749', 'rewards_train/rejected': '-5.2124', 'rewards_train/margins': '4.8672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25421', 'examples_per_second': '4.7911', 'grad_norm': '4.875', 'counters/examples': 275520, 'counters/updates': 17220}
skipping logging after 275536 examples to avoid logging too frequently
skipping logging after 275552 examples to avoid logging too frequently
skipping logging after 275568 examples to avoid logging too frequently
train stats after 275584 examples: {'rewards_train/chosen': '0.5355', 'rewards_train/rejected': '-5.1287', 'rewards_train/margins': '6.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26208', 'examples_per_second': '5.79', 'grad_norm': '4.9375', 'counters/examples': 275584, 'counters/updates': 17224}
skipping logging after 275600 examples to avoid logging too frequently
skipping logging after 275616 examples to avoid logging too frequently
skipping logging after 275632 examples to avoid logging too frequently
train stats after 275648 examples: {'rewards_train/chosen': '0.013335', 'rewards_train/rejected': '-6.558', 'rewards_train/margins': '6.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1781', 'examples_per_second': '5.9995', 'grad_norm': '5.125', 'counters/examples': 275648, 'counters/updates': 17228}
skipping logging after 275664 examples to avoid logging too frequently
skipping logging after 275680 examples to avoid logging too frequently
skipping logging after 275696 examples to avoid logging too frequently
train stats after 275712 examples: {'rewards_train/chosen': '0.6091', 'rewards_train/rejected': '-7.6695', 'rewards_train/margins': '8.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19745', 'examples_per_second': '5.0354', 'grad_norm': '4.875', 'counters/examples': 275712, 'counters/updates': 17232}
skipping logging after 275728 examples to avoid logging too frequently
skipping logging after 275744 examples to avoid logging too frequently
skipping logging after 275760 examples to avoid logging too frequently
train stats after 275776 examples: {'rewards_train/chosen': '0.27748', 'rewards_train/rejected': '-6.1406', 'rewards_train/margins': '6.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22784', 'examples_per_second': '6.0139', 'grad_norm': '5.875', 'counters/examples': 275776, 'counters/updates': 17236}
skipping logging after 275792 examples to avoid logging too frequently
skipping logging after 275808 examples to avoid logging too frequently
skipping logging after 275824 examples to avoid logging too frequently
train stats after 275840 examples: {'rewards_train/chosen': '0.39133', 'rewards_train/rejected': '-7.7298', 'rewards_train/margins': '8.2422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23718', 'examples_per_second': '4.088', 'grad_norm': '5.0625', 'counters/examples': 275840, 'counters/updates': 17240}
skipping logging after 275856 examples to avoid logging too frequently
skipping logging after 275872 examples to avoid logging too frequently
skipping logging after 275888 examples to avoid logging too frequently
train stats after 275904 examples: {'rewards_train/chosen': '0.3514', 'rewards_train/rejected': '-4.4552', 'rewards_train/margins': '4.6602', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26971', 'examples_per_second': '5.3933', 'grad_norm': '5.6562', 'counters/examples': 275904, 'counters/updates': 17244}
skipping logging after 275920 examples to avoid logging too frequently
skipping logging after 275936 examples to avoid logging too frequently
skipping logging after 275952 examples to avoid logging too frequently
train stats after 275968 examples: {'rewards_train/chosen': '0.45314', 'rewards_train/rejected': '-4.9867', 'rewards_train/margins': '5.668', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2959', 'examples_per_second': '4.4855', 'grad_norm': '5.5', 'counters/examples': 275968, 'counters/updates': 17248}
skipping logging after 275984 examples to avoid logging too frequently
skipping logging after 276000 examples to avoid logging too frequently
Running evaluation after 276000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:51,  1.65s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:42,  1.42s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:36,  1.25s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.48s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.69s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.49s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:10<00:34,  1.38s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.53s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.49s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:31,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.39s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:20<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:28<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:40<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:41<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]
eval after 276000: {'rewards_eval/chosen': '-5.9963', 'rewards_eval/rejected': '-6.4869', 'rewards_eval/margins': '0.33887', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.46033'}
skipping logging after 276016 examples to avoid logging too frequently
train stats after 276032 examples: {'rewards_train/chosen': '0.51451', 'rewards_train/rejected': '-5.9362', 'rewards_train/margins': '6.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22339', 'examples_per_second': '5.5373', 'grad_norm': '4.5', 'counters/examples': 276032, 'counters/updates': 17252}
skipping logging after 276048 examples to avoid logging too frequently
skipping logging after 276064 examples to avoid logging too frequently
skipping logging after 276080 examples to avoid logging too frequently
train stats after 276096 examples: {'rewards_train/chosen': '0.49019', 'rewards_train/rejected': '-5.4136', 'rewards_train/margins': '5.9453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23022', 'examples_per_second': '4.7193', 'grad_norm': '5.3438', 'counters/examples': 276096, 'counters/updates': 17256}
skipping logging after 276112 examples to avoid logging too frequently
skipping logging after 276128 examples to avoid logging too frequently
skipping logging after 276144 examples to avoid logging too frequently
train stats after 276160 examples: {'rewards_train/chosen': '0.26667', 'rewards_train/rejected': '-7.2556', 'rewards_train/margins': '7.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23108', 'examples_per_second': '6.3604', 'grad_norm': '4.75', 'counters/examples': 276160, 'counters/updates': 17260}
skipping logging after 276176 examples to avoid logging too frequently
skipping logging after 276192 examples to avoid logging too frequently
skipping logging after 276208 examples to avoid logging too frequently
train stats after 276224 examples: {'rewards_train/chosen': '0.31696', 'rewards_train/rejected': '-5.8645', 'rewards_train/margins': '6.4531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22217', 'examples_per_second': '5.961', 'grad_norm': '5.7188', 'counters/examples': 276224, 'counters/updates': 17264}
skipping logging after 276240 examples to avoid logging too frequently
skipping logging after 276256 examples to avoid logging too frequently
skipping logging after 276272 examples to avoid logging too frequently
train stats after 276288 examples: {'rewards_train/chosen': '0.16874', 'rewards_train/rejected': '-7.1863', 'rewards_train/margins': '6.7891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27307', 'examples_per_second': '5.7166', 'grad_norm': '5.625', 'counters/examples': 276288, 'counters/updates': 17268}
skipping logging after 276304 examples to avoid logging too frequently
skipping logging after 276320 examples to avoid logging too frequently
skipping logging after 276336 examples to avoid logging too frequently
train stats after 276352 examples: {'rewards_train/chosen': '0.36529', 'rewards_train/rejected': '-6.5611', 'rewards_train/margins': '7.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2644', 'examples_per_second': '4.9946', 'grad_norm': '5.4062', 'counters/examples': 276352, 'counters/updates': 17272}
skipping logging after 276368 examples to avoid logging too frequently
skipping logging after 276384 examples to avoid logging too frequently
skipping logging after 276400 examples to avoid logging too frequently
train stats after 276416 examples: {'rewards_train/chosen': '0.48052', 'rewards_train/rejected': '-5.6115', 'rewards_train/margins': '5.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22125', 'examples_per_second': '5.2006', 'grad_norm': '5.4062', 'counters/examples': 276416, 'counters/updates': 17276}
skipping logging after 276432 examples to avoid logging too frequently
skipping logging after 276448 examples to avoid logging too frequently
skipping logging after 276464 examples to avoid logging too frequently
train stats after 276480 examples: {'rewards_train/chosen': '0.29478', 'rewards_train/rejected': '-5.9397', 'rewards_train/margins': '6.0156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25836', 'examples_per_second': '6.1171', 'grad_norm': '7.2812', 'counters/examples': 276480, 'counters/updates': 17280}
skipping logging after 276496 examples to avoid logging too frequently
skipping logging after 276512 examples to avoid logging too frequently
skipping logging after 276528 examples to avoid logging too frequently
train stats after 276544 examples: {'rewards_train/chosen': '-0.051644', 'rewards_train/rejected': '-6.271', 'rewards_train/margins': '6.1953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2865', 'examples_per_second': '5.1519', 'grad_norm': '5.2812', 'counters/examples': 276544, 'counters/updates': 17284}
skipping logging after 276560 examples to avoid logging too frequently
skipping logging after 276576 examples to avoid logging too frequently
skipping logging after 276592 examples to avoid logging too frequently
train stats after 276608 examples: {'rewards_train/chosen': '0.26906', 'rewards_train/rejected': '-7.0124', 'rewards_train/margins': '7.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21619', 'examples_per_second': '5.2161', 'grad_norm': '4.9688', 'counters/examples': 276608, 'counters/updates': 17288}
skipping logging after 276624 examples to avoid logging too frequently
skipping logging after 276640 examples to avoid logging too frequently
skipping logging after 276656 examples to avoid logging too frequently
train stats after 276672 examples: {'rewards_train/chosen': '0.25375', 'rewards_train/rejected': '-5.1936', 'rewards_train/margins': '5.4844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2345', 'examples_per_second': '5.0344', 'grad_norm': '5.25', 'counters/examples': 276672, 'counters/updates': 17292}
skipping logging after 276688 examples to avoid logging too frequently
skipping logging after 276704 examples to avoid logging too frequently
skipping logging after 276720 examples to avoid logging too frequently
train stats after 276736 examples: {'rewards_train/chosen': '0.23004', 'rewards_train/rejected': '-5.4836', 'rewards_train/margins': '5.8203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26312', 'examples_per_second': '4.8384', 'grad_norm': '4.7812', 'counters/examples': 276736, 'counters/updates': 17296}
skipping logging after 276752 examples to avoid logging too frequently
skipping logging after 276768 examples to avoid logging too frequently
skipping logging after 276784 examples to avoid logging too frequently
train stats after 276800 examples: {'rewards_train/chosen': '0.31599', 'rewards_train/rejected': '-6.6616', 'rewards_train/margins': '7.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25616', 'examples_per_second': '4.2109', 'grad_norm': '5.0938', 'counters/examples': 276800, 'counters/updates': 17300}
skipping logging after 276816 examples to avoid logging too frequently
skipping logging after 276832 examples to avoid logging too frequently
skipping logging after 276848 examples to avoid logging too frequently
train stats after 276864 examples: {'rewards_train/chosen': '0.51102', 'rewards_train/rejected': '-7.2174', 'rewards_train/margins': '7.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23608', 'examples_per_second': '4.9985', 'grad_norm': '4.8438', 'counters/examples': 276864, 'counters/updates': 17304}
skipping logging after 276880 examples to avoid logging too frequently
skipping logging after 276896 examples to avoid logging too frequently
skipping logging after 276912 examples to avoid logging too frequently
train stats after 276928 examples: {'rewards_train/chosen': '0.28825', 'rewards_train/rejected': '-6.1276', 'rewards_train/margins': '6.3203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24744', 'examples_per_second': '6.1463', 'grad_norm': '4.75', 'counters/examples': 276928, 'counters/updates': 17308}
skipping logging after 276944 examples to avoid logging too frequently
skipping logging after 276960 examples to avoid logging too frequently
skipping logging after 276976 examples to avoid logging too frequently
train stats after 276992 examples: {'rewards_train/chosen': '0.53568', 'rewards_train/rejected': '-5.9973', 'rewards_train/margins': '6.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23584', 'examples_per_second': '3.9243', 'grad_norm': '4.2812', 'counters/examples': 276992, 'counters/updates': 17312}
skipping logging after 277008 examples to avoid logging too frequently
skipping logging after 277024 examples to avoid logging too frequently
skipping logging after 277040 examples to avoid logging too frequently
train stats after 277056 examples: {'rewards_train/chosen': '0.40912', 'rewards_train/rejected': '-6.212', 'rewards_train/margins': '6.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18457', 'examples_per_second': '5.0843', 'grad_norm': '4.4062', 'counters/examples': 277056, 'counters/updates': 17316}
skipping logging after 277072 examples to avoid logging too frequently
skipping logging after 277088 examples to avoid logging too frequently
skipping logging after 277104 examples to avoid logging too frequently
train stats after 277120 examples: {'rewards_train/chosen': '0.34989', 'rewards_train/rejected': '-5.3887', 'rewards_train/margins': '5.7227', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24677', 'examples_per_second': '5.3758', 'grad_norm': '5.625', 'counters/examples': 277120, 'counters/updates': 17320}
skipping logging after 277136 examples to avoid logging too frequently
skipping logging after 277152 examples to avoid logging too frequently
skipping logging after 277168 examples to avoid logging too frequently
train stats after 277184 examples: {'rewards_train/chosen': '0.17536', 'rewards_train/rejected': '-6.2688', 'rewards_train/margins': '6.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24255', 'examples_per_second': '5.5864', 'grad_norm': '4.7188', 'counters/examples': 277184, 'counters/updates': 17324}
skipping logging after 277200 examples to avoid logging too frequently
skipping logging after 277216 examples to avoid logging too frequently
skipping logging after 277232 examples to avoid logging too frequently
train stats after 277248 examples: {'rewards_train/chosen': '0.66088', 'rewards_train/rejected': '-7.1387', 'rewards_train/margins': '7.4531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21442', 'examples_per_second': '5.1069', 'grad_norm': '4.6875', 'counters/examples': 277248, 'counters/updates': 17328}
skipping logging after 277264 examples to avoid logging too frequently
skipping logging after 277280 examples to avoid logging too frequently
skipping logging after 277296 examples to avoid logging too frequently
train stats after 277312 examples: {'rewards_train/chosen': '0.43727', 'rewards_train/rejected': '-5.7076', 'rewards_train/margins': '5.9102', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21094', 'examples_per_second': '5.7801', 'grad_norm': '4.875', 'counters/examples': 277312, 'counters/updates': 17332}
skipping logging after 277328 examples to avoid logging too frequently
skipping logging after 277344 examples to avoid logging too frequently
skipping logging after 277360 examples to avoid logging too frequently
train stats after 277376 examples: {'rewards_train/chosen': '0.48416', 'rewards_train/rejected': '-6.5611', 'rewards_train/margins': '6.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29199', 'examples_per_second': '4.9524', 'grad_norm': '6.5312', 'counters/examples': 277376, 'counters/updates': 17336}
skipping logging after 277392 examples to avoid logging too frequently
skipping logging after 277408 examples to avoid logging too frequently
skipping logging after 277424 examples to avoid logging too frequently
train stats after 277440 examples: {'rewards_train/chosen': '0.14609', 'rewards_train/rejected': '-4.3972', 'rewards_train/margins': '4.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26886', 'examples_per_second': '4.9532', 'grad_norm': '5.2188', 'counters/examples': 277440, 'counters/updates': 17340}
skipping logging after 277456 examples to avoid logging too frequently
skipping logging after 277472 examples to avoid logging too frequently
skipping logging after 277488 examples to avoid logging too frequently
train stats after 277504 examples: {'rewards_train/chosen': '0.015878', 'rewards_train/rejected': '-5.4655', 'rewards_train/margins': '5.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26044', 'examples_per_second': '4.91', 'grad_norm': '5', 'counters/examples': 277504, 'counters/updates': 17344}
skipping logging after 277520 examples to avoid logging too frequently
skipping logging after 277536 examples to avoid logging too frequently
skipping logging after 277552 examples to avoid logging too frequently
train stats after 277568 examples: {'rewards_train/chosen': '0.41376', 'rewards_train/rejected': '-7.2725', 'rewards_train/margins': '7.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23926', 'examples_per_second': '5.2197', 'grad_norm': '4.9062', 'counters/examples': 277568, 'counters/updates': 17348}
skipping logging after 277584 examples to avoid logging too frequently
skipping logging after 277600 examples to avoid logging too frequently
skipping logging after 277616 examples to avoid logging too frequently
train stats after 277632 examples: {'rewards_train/chosen': '0.37185', 'rewards_train/rejected': '-6.9367', 'rewards_train/margins': '7.3203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23279', 'examples_per_second': '5.5889', 'grad_norm': '4.2188', 'counters/examples': 277632, 'counters/updates': 17352}
skipping logging after 277648 examples to avoid logging too frequently
skipping logging after 277664 examples to avoid logging too frequently
skipping logging after 277680 examples to avoid logging too frequently
train stats after 277696 examples: {'rewards_train/chosen': '0.15403', 'rewards_train/rejected': '-5.1283', 'rewards_train/margins': '5.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25677', 'examples_per_second': '5.1552', 'grad_norm': '5.625', 'counters/examples': 277696, 'counters/updates': 17356}
skipping logging after 277712 examples to avoid logging too frequently
skipping logging after 277728 examples to avoid logging too frequently
skipping logging after 277744 examples to avoid logging too frequently
train stats after 277760 examples: {'rewards_train/chosen': '0.054189', 'rewards_train/rejected': '-6.6339', 'rewards_train/margins': '6.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21832', 'examples_per_second': '5.0815', 'grad_norm': '4', 'counters/examples': 277760, 'counters/updates': 17360}
skipping logging after 277776 examples to avoid logging too frequently
skipping logging after 277792 examples to avoid logging too frequently
skipping logging after 277808 examples to avoid logging too frequently
train stats after 277824 examples: {'rewards_train/chosen': '0.014801', 'rewards_train/rejected': '-6.7198', 'rewards_train/margins': '6.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22406', 'examples_per_second': '5.4223', 'grad_norm': '4.3125', 'counters/examples': 277824, 'counters/updates': 17364}
skipping logging after 277840 examples to avoid logging too frequently
skipping logging after 277856 examples to avoid logging too frequently
skipping logging after 277872 examples to avoid logging too frequently
train stats after 277888 examples: {'rewards_train/chosen': '0.25481', 'rewards_train/rejected': '-6.5965', 'rewards_train/margins': '6.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2146', 'examples_per_second': '4.9118', 'grad_norm': '5.3438', 'counters/examples': 277888, 'counters/updates': 17368}
skipping logging after 277904 examples to avoid logging too frequently
skipping logging after 277920 examples to avoid logging too frequently
skipping logging after 277936 examples to avoid logging too frequently
train stats after 277952 examples: {'rewards_train/chosen': '0.25341', 'rewards_train/rejected': '-6.5312', 'rewards_train/margins': '6.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25299', 'examples_per_second': '4.8356', 'grad_norm': '4.7188', 'counters/examples': 277952, 'counters/updates': 17372}
skipping logging after 277968 examples to avoid logging too frequently
skipping logging after 277984 examples to avoid logging too frequently
skipping logging after 278000 examples to avoid logging too frequently
train stats after 278016 examples: {'rewards_train/chosen': '0.56803', 'rewards_train/rejected': '-6.0547', 'rewards_train/margins': '6.7109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21118', 'examples_per_second': '4.3229', 'grad_norm': '5.6562', 'counters/examples': 278016, 'counters/updates': 17376}
skipping logging after 278032 examples to avoid logging too frequently
skipping logging after 278048 examples to avoid logging too frequently
skipping logging after 278064 examples to avoid logging too frequently
train stats after 278080 examples: {'rewards_train/chosen': '0.22253', 'rewards_train/rejected': '-6.8076', 'rewards_train/margins': '7.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27228', 'examples_per_second': '5.1872', 'grad_norm': '5.9375', 'counters/examples': 278080, 'counters/updates': 17380}
skipping logging after 278096 examples to avoid logging too frequently
skipping logging after 278112 examples to avoid logging too frequently
skipping logging after 278128 examples to avoid logging too frequently
train stats after 278144 examples: {'rewards_train/chosen': '0.186', 'rewards_train/rejected': '-6.258', 'rewards_train/margins': '6.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23865', 'examples_per_second': '4.3077', 'grad_norm': '4.7188', 'counters/examples': 278144, 'counters/updates': 17384}
skipping logging after 278160 examples to avoid logging too frequently
skipping logging after 278176 examples to avoid logging too frequently
skipping logging after 278192 examples to avoid logging too frequently
train stats after 278208 examples: {'rewards_train/chosen': '-0.023148', 'rewards_train/rejected': '-7.1518', 'rewards_train/margins': '7.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29065', 'examples_per_second': '5.5258', 'grad_norm': '6.5', 'counters/examples': 278208, 'counters/updates': 17388}
skipping logging after 278224 examples to avoid logging too frequently
skipping logging after 278240 examples to avoid logging too frequently
skipping logging after 278256 examples to avoid logging too frequently
train stats after 278272 examples: {'rewards_train/chosen': '0.23467', 'rewards_train/rejected': '-6.2508', 'rewards_train/margins': '6.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19727', 'examples_per_second': '5.2347', 'grad_norm': '5.875', 'counters/examples': 278272, 'counters/updates': 17392}
skipping logging after 278288 examples to avoid logging too frequently
skipping logging after 278304 examples to avoid logging too frequently
skipping logging after 278320 examples to avoid logging too frequently
train stats after 278336 examples: {'rewards_train/chosen': '0.26345', 'rewards_train/rejected': '-5.4148', 'rewards_train/margins': '5.4492', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25812', 'examples_per_second': '4.94', 'grad_norm': '5.6875', 'counters/examples': 278336, 'counters/updates': 17396}
skipping logging after 278352 examples to avoid logging too frequently
skipping logging after 278368 examples to avoid logging too frequently
skipping logging after 278384 examples to avoid logging too frequently
train stats after 278400 examples: {'rewards_train/chosen': '0.48873', 'rewards_train/rejected': '-6.5213', 'rewards_train/margins': '6.8906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26044', 'examples_per_second': '5.1994', 'grad_norm': '5.1875', 'counters/examples': 278400, 'counters/updates': 17400}
skipping logging after 278416 examples to avoid logging too frequently
skipping logging after 278432 examples to avoid logging too frequently
skipping logging after 278448 examples to avoid logging too frequently
train stats after 278464 examples: {'rewards_train/chosen': '0.46663', 'rewards_train/rejected': '-5.7672', 'rewards_train/margins': '6.2266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21924', 'examples_per_second': '5.2079', 'grad_norm': '4.875', 'counters/examples': 278464, 'counters/updates': 17404}
skipping logging after 278480 examples to avoid logging too frequently
skipping logging after 278496 examples to avoid logging too frequently
skipping logging after 278512 examples to avoid logging too frequently
train stats after 278528 examples: {'rewards_train/chosen': '0.41443', 'rewards_train/rejected': '-4.9884', 'rewards_train/margins': '5.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25665', 'examples_per_second': '5.8593', 'grad_norm': '5.1562', 'counters/examples': 278528, 'counters/updates': 17408}
skipping logging after 278544 examples to avoid logging too frequently
skipping logging after 278560 examples to avoid logging too frequently
skipping logging after 278576 examples to avoid logging too frequently
train stats after 278592 examples: {'rewards_train/chosen': '0.31396', 'rewards_train/rejected': '-5.9951', 'rewards_train/margins': '6.5938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22699', 'examples_per_second': '4.2675', 'grad_norm': '5.2188', 'counters/examples': 278592, 'counters/updates': 17412}
skipping logging after 278608 examples to avoid logging too frequently
skipping logging after 278624 examples to avoid logging too frequently
skipping logging after 278640 examples to avoid logging too frequently
train stats after 278656 examples: {'rewards_train/chosen': '0.25229', 'rewards_train/rejected': '-6.1081', 'rewards_train/margins': '6.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27185', 'examples_per_second': '5.6343', 'grad_norm': '5.5', 'counters/examples': 278656, 'counters/updates': 17416}
skipping logging after 278672 examples to avoid logging too frequently
skipping logging after 278688 examples to avoid logging too frequently
skipping logging after 278704 examples to avoid logging too frequently
train stats after 278720 examples: {'rewards_train/chosen': '0.25663', 'rewards_train/rejected': '-6.0465', 'rewards_train/margins': '6.0586', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25006', 'examples_per_second': '5.1663', 'grad_norm': '4.1875', 'counters/examples': 278720, 'counters/updates': 17420}
skipping logging after 278736 examples to avoid logging too frequently
skipping logging after 278752 examples to avoid logging too frequently
skipping logging after 278768 examples to avoid logging too frequently
train stats after 278784 examples: {'rewards_train/chosen': '0.3268', 'rewards_train/rejected': '-5.9439', 'rewards_train/margins': '6.0664', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22833', 'examples_per_second': '4.8069', 'grad_norm': '4.6875', 'counters/examples': 278784, 'counters/updates': 17424}
skipping logging after 278800 examples to avoid logging too frequently
skipping logging after 278816 examples to avoid logging too frequently
skipping logging after 278832 examples to avoid logging too frequently
train stats after 278848 examples: {'rewards_train/chosen': '0.064023', 'rewards_train/rejected': '-6.7072', 'rewards_train/margins': '6.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21277', 'examples_per_second': '5.2225', 'grad_norm': '5.1875', 'counters/examples': 278848, 'counters/updates': 17428}
skipping logging after 278864 examples to avoid logging too frequently
skipping logging after 278880 examples to avoid logging too frequently
skipping logging after 278896 examples to avoid logging too frequently
train stats after 278912 examples: {'rewards_train/chosen': '0.20291', 'rewards_train/rejected': '-6.5066', 'rewards_train/margins': '6.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30054', 'examples_per_second': '5.4343', 'grad_norm': '5.9375', 'counters/examples': 278912, 'counters/updates': 17432}
skipping logging after 278928 examples to avoid logging too frequently
skipping logging after 278944 examples to avoid logging too frequently
skipping logging after 278960 examples to avoid logging too frequently
train stats after 278976 examples: {'rewards_train/chosen': '0.84739', 'rewards_train/rejected': '-5.489', 'rewards_train/margins': '6.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20123', 'examples_per_second': '5.4794', 'grad_norm': '4.5938', 'counters/examples': 278976, 'counters/updates': 17436}
skipping logging after 278992 examples to avoid logging too frequently
skipping logging after 279008 examples to avoid logging too frequently
skipping logging after 279024 examples to avoid logging too frequently
train stats after 279040 examples: {'rewards_train/chosen': '0.33456', 'rewards_train/rejected': '-6.2993', 'rewards_train/margins': '6.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21942', 'examples_per_second': '4.9718', 'grad_norm': '4.5625', 'counters/examples': 279040, 'counters/updates': 17440}
skipping logging after 279056 examples to avoid logging too frequently
skipping logging after 279072 examples to avoid logging too frequently
skipping logging after 279088 examples to avoid logging too frequently
train stats after 279104 examples: {'rewards_train/chosen': '0.46293', 'rewards_train/rejected': '-6.8965', 'rewards_train/margins': '7.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25787', 'examples_per_second': '4.7385', 'grad_norm': '6.4375', 'counters/examples': 279104, 'counters/updates': 17444}
skipping logging after 279120 examples to avoid logging too frequently
skipping logging after 279136 examples to avoid logging too frequently
skipping logging after 279152 examples to avoid logging too frequently
train stats after 279168 examples: {'rewards_train/chosen': '0.13216', 'rewards_train/rejected': '-5.7718', 'rewards_train/margins': '6.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.32086', 'examples_per_second': '4.7938', 'grad_norm': '5.1562', 'counters/examples': 279168, 'counters/updates': 17448}
skipping logging after 279184 examples to avoid logging too frequently
skipping logging after 279200 examples to avoid logging too frequently
skipping logging after 279216 examples to avoid logging too frequently
train stats after 279232 examples: {'rewards_train/chosen': '0.084436', 'rewards_train/rejected': '-6.4965', 'rewards_train/margins': '6.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2132', 'examples_per_second': '4.9891', 'grad_norm': '5.3125', 'counters/examples': 279232, 'counters/updates': 17452}
skipping logging after 279248 examples to avoid logging too frequently
skipping logging after 279264 examples to avoid logging too frequently
skipping logging after 279280 examples to avoid logging too frequently
train stats after 279296 examples: {'rewards_train/chosen': '0.50314', 'rewards_train/rejected': '-7.0637', 'rewards_train/margins': '7.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23059', 'examples_per_second': '5.2945', 'grad_norm': '4.4688', 'counters/examples': 279296, 'counters/updates': 17456}
skipping logging after 279312 examples to avoid logging too frequently
skipping logging after 279328 examples to avoid logging too frequently
skipping logging after 279344 examples to avoid logging too frequently
train stats after 279360 examples: {'rewards_train/chosen': '0.2247', 'rewards_train/rejected': '-6.0731', 'rewards_train/margins': '6.0898', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22913', 'examples_per_second': '4.6314', 'grad_norm': '4.4062', 'counters/examples': 279360, 'counters/updates': 17460}
skipping logging after 279376 examples to avoid logging too frequently
skipping logging after 279392 examples to avoid logging too frequently
skipping logging after 279408 examples to avoid logging too frequently
train stats after 279424 examples: {'rewards_train/chosen': '0.4375', 'rewards_train/rejected': '-6.2867', 'rewards_train/margins': '6.4375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23401', 'examples_per_second': '5.3415', 'grad_norm': '5.6875', 'counters/examples': 279424, 'counters/updates': 17464}
skipping logging after 279440 examples to avoid logging too frequently
skipping logging after 279456 examples to avoid logging too frequently
skipping logging after 279472 examples to avoid logging too frequently
train stats after 279488 examples: {'rewards_train/chosen': '0.51658', 'rewards_train/rejected': '-5.8613', 'rewards_train/margins': '6.2266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20996', 'examples_per_second': '5.4728', 'grad_norm': '4.6875', 'counters/examples': 279488, 'counters/updates': 17468}
skipping logging after 279504 examples to avoid logging too frequently
skipping logging after 279520 examples to avoid logging too frequently
skipping logging after 279536 examples to avoid logging too frequently
train stats after 279552 examples: {'rewards_train/chosen': '0.46683', 'rewards_train/rejected': '-6.4056', 'rewards_train/margins': '6.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18896', 'examples_per_second': '4.5738', 'grad_norm': '4.4688', 'counters/examples': 279552, 'counters/updates': 17472}
skipping logging after 279568 examples to avoid logging too frequently
skipping logging after 279584 examples to avoid logging too frequently
skipping logging after 279600 examples to avoid logging too frequently
train stats after 279616 examples: {'rewards_train/chosen': '0.42226', 'rewards_train/rejected': '-7.9443', 'rewards_train/margins': '8.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22345', 'examples_per_second': '4.8615', 'grad_norm': '5.125', 'counters/examples': 279616, 'counters/updates': 17476}
skipping logging after 279632 examples to avoid logging too frequently
skipping logging after 279648 examples to avoid logging too frequently
skipping logging after 279664 examples to avoid logging too frequently
train stats after 279680 examples: {'rewards_train/chosen': '0.24455', 'rewards_train/rejected': '-6.4787', 'rewards_train/margins': '6.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20984', 'examples_per_second': '5.49', 'grad_norm': '3.7812', 'counters/examples': 279680, 'counters/updates': 17480}
skipping logging after 279696 examples to avoid logging too frequently
skipping logging after 279712 examples to avoid logging too frequently
skipping logging after 279728 examples to avoid logging too frequently
train stats after 279744 examples: {'rewards_train/chosen': '0.2725', 'rewards_train/rejected': '-5.8271', 'rewards_train/margins': '6.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24524', 'examples_per_second': '4.5116', 'grad_norm': '5.2188', 'counters/examples': 279744, 'counters/updates': 17484}
skipping logging after 279760 examples to avoid logging too frequently
skipping logging after 279776 examples to avoid logging too frequently
skipping logging after 279792 examples to avoid logging too frequently
train stats after 279808 examples: {'rewards_train/chosen': '0.45008', 'rewards_train/rejected': '-7.8415', 'rewards_train/margins': '8.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23303', 'examples_per_second': '4.1538', 'grad_norm': '6.0312', 'counters/examples': 279808, 'counters/updates': 17488}
skipping logging after 279824 examples to avoid logging too frequently
skipping logging after 279840 examples to avoid logging too frequently
skipping logging after 279856 examples to avoid logging too frequently
train stats after 279872 examples: {'rewards_train/chosen': '0.55065', 'rewards_train/rejected': '-7.6138', 'rewards_train/margins': '8.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25146', 'examples_per_second': '5.9622', 'grad_norm': '5.5938', 'counters/examples': 279872, 'counters/updates': 17492}
skipping logging after 279888 examples to avoid logging too frequently
skipping logging after 279904 examples to avoid logging too frequently
skipping logging after 279920 examples to avoid logging too frequently
train stats after 279936 examples: {'rewards_train/chosen': '0.39449', 'rewards_train/rejected': '-6.9795', 'rewards_train/margins': '7.3281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22308', 'examples_per_second': '6.27', 'grad_norm': '5.6875', 'counters/examples': 279936, 'counters/updates': 17496}
skipping logging after 279952 examples to avoid logging too frequently
skipping logging after 279968 examples to avoid logging too frequently
skipping logging after 279984 examples to avoid logging too frequently
train stats after 280000 examples: {'rewards_train/chosen': '-0.098389', 'rewards_train/rejected': '-5.8456', 'rewards_train/margins': '5.957', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2655', 'examples_per_second': '5.4171', 'grad_norm': '4.4688', 'counters/examples': 280000, 'counters/updates': 17500}
Running evaluation after 280000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.24s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.25s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.16s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:39,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.65s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.47s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:33,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.51s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:33,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.40s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:21<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.42s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.18s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it]
eval after 280000: {'rewards_eval/chosen': '-6.1035', 'rewards_eval/rejected': '-6.7331', 'rewards_eval/margins': '0.48682', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.45776'}
skipping logging after 280016 examples to avoid logging too frequently
skipping logging after 280032 examples to avoid logging too frequently
skipping logging after 280048 examples to avoid logging too frequently
train stats after 280064 examples: {'rewards_train/chosen': '0.4216', 'rewards_train/rejected': '-7.003', 'rewards_train/margins': '7.7227', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24329', 'examples_per_second': '4.7473', 'grad_norm': '5.4062', 'counters/examples': 280064, 'counters/updates': 17504}
skipping logging after 280080 examples to avoid logging too frequently
skipping logging after 280096 examples to avoid logging too frequently
skipping logging after 280112 examples to avoid logging too frequently
train stats after 280128 examples: {'rewards_train/chosen': '0.53989', 'rewards_train/rejected': '-6.8294', 'rewards_train/margins': '7.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23041', 'examples_per_second': '5.0146', 'grad_norm': '4.9375', 'counters/examples': 280128, 'counters/updates': 17508}
skipping logging after 280144 examples to avoid logging too frequently
skipping logging after 280160 examples to avoid logging too frequently
skipping logging after 280176 examples to avoid logging too frequently
train stats after 280192 examples: {'rewards_train/chosen': '0.34814', 'rewards_train/rejected': '-5.5444', 'rewards_train/margins': '6.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25214', 'examples_per_second': '3.807', 'grad_norm': '4.4062', 'counters/examples': 280192, 'counters/updates': 17512}
skipping logging after 280208 examples to avoid logging too frequently
skipping logging after 280224 examples to avoid logging too frequently
skipping logging after 280240 examples to avoid logging too frequently
train stats after 280256 examples: {'rewards_train/chosen': '0.23173', 'rewards_train/rejected': '-6.3484', 'rewards_train/margins': '6.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2572', 'examples_per_second': '4.7613', 'grad_norm': '5.3438', 'counters/examples': 280256, 'counters/updates': 17516}
skipping logging after 280272 examples to avoid logging too frequently
skipping logging after 280288 examples to avoid logging too frequently
skipping logging after 280304 examples to avoid logging too frequently
train stats after 280320 examples: {'rewards_train/chosen': '0.57348', 'rewards_train/rejected': '-6.7036', 'rewards_train/margins': '7.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1983', 'examples_per_second': '5.749', 'grad_norm': '4.0625', 'counters/examples': 280320, 'counters/updates': 17520}
skipping logging after 280336 examples to avoid logging too frequently
skipping logging after 280352 examples to avoid logging too frequently
skipping logging after 280368 examples to avoid logging too frequently
train stats after 280384 examples: {'rewards_train/chosen': '0.1724', 'rewards_train/rejected': '-5.3432', 'rewards_train/margins': '5.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21167', 'examples_per_second': '5.6554', 'grad_norm': '4.8438', 'counters/examples': 280384, 'counters/updates': 17524}
skipping logging after 280400 examples to avoid logging too frequently
skipping logging after 280416 examples to avoid logging too frequently
skipping logging after 280432 examples to avoid logging too frequently
train stats after 280448 examples: {'rewards_train/chosen': '0.62345', 'rewards_train/rejected': '-6.7522', 'rewards_train/margins': '7.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.16675', 'examples_per_second': '4.2522', 'grad_norm': '4.8125', 'counters/examples': 280448, 'counters/updates': 17528}
skipping logging after 280464 examples to avoid logging too frequently
skipping logging after 280480 examples to avoid logging too frequently
skipping logging after 280496 examples to avoid logging too frequently
train stats after 280512 examples: {'rewards_train/chosen': '-0.10101', 'rewards_train/rejected': '-8.6064', 'rewards_train/margins': '9.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2536', 'examples_per_second': '5.2953', 'grad_norm': '6.0938', 'counters/examples': 280512, 'counters/updates': 17532}
skipping logging after 280528 examples to avoid logging too frequently
skipping logging after 280544 examples to avoid logging too frequently
skipping logging after 280560 examples to avoid logging too frequently
train stats after 280576 examples: {'rewards_train/chosen': '0.31409', 'rewards_train/rejected': '-7.3544', 'rewards_train/margins': '7.6094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22845', 'examples_per_second': '5.6074', 'grad_norm': '5.375', 'counters/examples': 280576, 'counters/updates': 17536}
skipping logging after 280592 examples to avoid logging too frequently
skipping logging after 280608 examples to avoid logging too frequently
skipping logging after 280624 examples to avoid logging too frequently
train stats after 280640 examples: {'rewards_train/chosen': '0.18333', 'rewards_train/rejected': '-5.2776', 'rewards_train/margins': '5.7266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2215', 'examples_per_second': '6.2474', 'grad_norm': '4.1562', 'counters/examples': 280640, 'counters/updates': 17540}
skipping logging after 280656 examples to avoid logging too frequently
skipping logging after 280672 examples to avoid logging too frequently
skipping logging after 280688 examples to avoid logging too frequently
train stats after 280704 examples: {'rewards_train/chosen': '0.052927', 'rewards_train/rejected': '-5.5737', 'rewards_train/margins': '6', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22968', 'examples_per_second': '5.8524', 'grad_norm': '4.625', 'counters/examples': 280704, 'counters/updates': 17544}
skipping logging after 280720 examples to avoid logging too frequently
skipping logging after 280736 examples to avoid logging too frequently
skipping logging after 280752 examples to avoid logging too frequently
train stats after 280768 examples: {'rewards_train/chosen': '0.50537', 'rewards_train/rejected': '-6.193', 'rewards_train/margins': '6.6328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20667', 'examples_per_second': '5.7233', 'grad_norm': '4.75', 'counters/examples': 280768, 'counters/updates': 17548}
skipping logging after 280784 examples to avoid logging too frequently
skipping logging after 280800 examples to avoid logging too frequently
skipping logging after 280816 examples to avoid logging too frequently
train stats after 280832 examples: {'rewards_train/chosen': '0.47747', 'rewards_train/rejected': '-5.4286', 'rewards_train/margins': '5.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25012', 'examples_per_second': '6.1045', 'grad_norm': '6.2188', 'counters/examples': 280832, 'counters/updates': 17552}
skipping logging after 280848 examples to avoid logging too frequently
skipping logging after 280864 examples to avoid logging too frequently
skipping logging after 280880 examples to avoid logging too frequently
train stats after 280896 examples: {'rewards_train/chosen': '0.4238', 'rewards_train/rejected': '-6.9368', 'rewards_train/margins': '7.0234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20276', 'examples_per_second': '6.0796', 'grad_norm': '3.6094', 'counters/examples': 280896, 'counters/updates': 17556}
skipping logging after 280912 examples to avoid logging too frequently
skipping logging after 280928 examples to avoid logging too frequently
skipping logging after 280944 examples to avoid logging too frequently
train stats after 280960 examples: {'rewards_train/chosen': '0.25692', 'rewards_train/rejected': '-7.2826', 'rewards_train/margins': '7.7109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23816', 'examples_per_second': '5.7908', 'grad_norm': '4.5938', 'counters/examples': 280960, 'counters/updates': 17560}
skipping logging after 280976 examples to avoid logging too frequently
skipping logging after 280992 examples to avoid logging too frequently
skipping logging after 281008 examples to avoid logging too frequently
train stats after 281024 examples: {'rewards_train/chosen': '0.49829', 'rewards_train/rejected': '-5.9761', 'rewards_train/margins': '6.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20312', 'examples_per_second': '4.7403', 'grad_norm': '4.6562', 'counters/examples': 281024, 'counters/updates': 17564}
skipping logging after 281040 examples to avoid logging too frequently
skipping logging after 281056 examples to avoid logging too frequently
skipping logging after 281072 examples to avoid logging too frequently
train stats after 281088 examples: {'rewards_train/chosen': '0.37633', 'rewards_train/rejected': '-5.2982', 'rewards_train/margins': '5.6836', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25696', 'examples_per_second': '5.2769', 'grad_norm': '6.375', 'counters/examples': 281088, 'counters/updates': 17568}
skipping logging after 281104 examples to avoid logging too frequently
skipping logging after 281120 examples to avoid logging too frequently
skipping logging after 281136 examples to avoid logging too frequently
train stats after 281152 examples: {'rewards_train/chosen': '0.32249', 'rewards_train/rejected': '-6.8009', 'rewards_train/margins': '7.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24396', 'examples_per_second': '4.7059', 'grad_norm': '5.3125', 'counters/examples': 281152, 'counters/updates': 17572}
skipping logging after 281168 examples to avoid logging too frequently
skipping logging after 281184 examples to avoid logging too frequently
skipping logging after 281200 examples to avoid logging too frequently
train stats after 281216 examples: {'rewards_train/chosen': '0.096502', 'rewards_train/rejected': '-6.118', 'rewards_train/margins': '6.2422', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21399', 'examples_per_second': '4.7454', 'grad_norm': '6.625', 'counters/examples': 281216, 'counters/updates': 17576}
skipping logging after 281232 examples to avoid logging too frequently
skipping logging after 281248 examples to avoid logging too frequently
skipping logging after 281264 examples to avoid logging too frequently
train stats after 281280 examples: {'rewards_train/chosen': '0.31902', 'rewards_train/rejected': '-6.7636', 'rewards_train/margins': '7.1875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2793', 'examples_per_second': '5.0548', 'grad_norm': '5.9375', 'counters/examples': 281280, 'counters/updates': 17580}
skipping logging after 281296 examples to avoid logging too frequently
skipping logging after 281312 examples to avoid logging too frequently
skipping logging after 281328 examples to avoid logging too frequently
train stats after 281344 examples: {'rewards_train/chosen': '0.28451', 'rewards_train/rejected': '-5.9375', 'rewards_train/margins': '6.2969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21136', 'examples_per_second': '4.8542', 'grad_norm': '4.9375', 'counters/examples': 281344, 'counters/updates': 17584}
skipping logging after 281360 examples to avoid logging too frequently
skipping logging after 281376 examples to avoid logging too frequently
skipping logging after 281392 examples to avoid logging too frequently
train stats after 281408 examples: {'rewards_train/chosen': '-0.13988', 'rewards_train/rejected': '-7.5224', 'rewards_train/margins': '7.1406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28217', 'examples_per_second': '5.5062', 'grad_norm': '6.5938', 'counters/examples': 281408, 'counters/updates': 17588}
skipping logging after 281424 examples to avoid logging too frequently
skipping logging after 281440 examples to avoid logging too frequently
skipping logging after 281456 examples to avoid logging too frequently
train stats after 281472 examples: {'rewards_train/chosen': '0.39272', 'rewards_train/rejected': '-7.4352', 'rewards_train/margins': '8.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2746', 'examples_per_second': '4.1395', 'grad_norm': '5.25', 'counters/examples': 281472, 'counters/updates': 17592}
skipping logging after 281488 examples to avoid logging too frequently
skipping logging after 281504 examples to avoid logging too frequently
skipping logging after 281520 examples to avoid logging too frequently
train stats after 281536 examples: {'rewards_train/chosen': '0.66521', 'rewards_train/rejected': '-5.9624', 'rewards_train/margins': '6.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21997', 'examples_per_second': '5.9318', 'grad_norm': '5.1875', 'counters/examples': 281536, 'counters/updates': 17596}
skipping logging after 281552 examples to avoid logging too frequently
skipping logging after 281568 examples to avoid logging too frequently
skipping logging after 281584 examples to avoid logging too frequently
train stats after 281600 examples: {'rewards_train/chosen': '0.36815', 'rewards_train/rejected': '-8.9394', 'rewards_train/margins': '9.1719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26886', 'examples_per_second': '4.9751', 'grad_norm': '5.5938', 'counters/examples': 281600, 'counters/updates': 17600}
skipping logging after 281616 examples to avoid logging too frequently
skipping logging after 281632 examples to avoid logging too frequently
skipping logging after 281648 examples to avoid logging too frequently
train stats after 281664 examples: {'rewards_train/chosen': '0.37391', 'rewards_train/rejected': '-7.0802', 'rewards_train/margins': '7.4844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25714', 'examples_per_second': '5.2293', 'grad_norm': '4.1562', 'counters/examples': 281664, 'counters/updates': 17604}
skipping logging after 281680 examples to avoid logging too frequently
skipping logging after 281696 examples to avoid logging too frequently
skipping logging after 281712 examples to avoid logging too frequently
train stats after 281728 examples: {'rewards_train/chosen': '-0.091194', 'rewards_train/rejected': '-6.6266', 'rewards_train/margins': '6.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27399', 'examples_per_second': '6.1773', 'grad_norm': '5.1875', 'counters/examples': 281728, 'counters/updates': 17608}
skipping logging after 281744 examples to avoid logging too frequently
skipping logging after 281760 examples to avoid logging too frequently
skipping logging after 281776 examples to avoid logging too frequently
train stats after 281792 examples: {'rewards_train/chosen': '0.22709', 'rewards_train/rejected': '-5.4229', 'rewards_train/margins': '4.9648', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30139', 'examples_per_second': '4.945', 'grad_norm': '5.0625', 'counters/examples': 281792, 'counters/updates': 17612}
skipping logging after 281808 examples to avoid logging too frequently
skipping logging after 281824 examples to avoid logging too frequently
skipping logging after 281840 examples to avoid logging too frequently
train stats after 281856 examples: {'rewards_train/chosen': '0.3344', 'rewards_train/rejected': '-4.6508', 'rewards_train/margins': '4.8672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27966', 'examples_per_second': '5.6045', 'grad_norm': '5.3438', 'counters/examples': 281856, 'counters/updates': 17616}
skipping logging after 281872 examples to avoid logging too frequently
skipping logging after 281888 examples to avoid logging too frequently
skipping logging after 281904 examples to avoid logging too frequently
train stats after 281920 examples: {'rewards_train/chosen': '0.047729', 'rewards_train/rejected': '-6.6122', 'rewards_train/margins': '6.1445', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20703', 'examples_per_second': '4.5814', 'grad_norm': '5.0312', 'counters/examples': 281920, 'counters/updates': 17620}
skipping logging after 281936 examples to avoid logging too frequently
skipping logging after 281952 examples to avoid logging too frequently
skipping logging after 281968 examples to avoid logging too frequently
train stats after 281984 examples: {'rewards_train/chosen': '-0.075213', 'rewards_train/rejected': '-4.6589', 'rewards_train/margins': '4.7891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25531', 'examples_per_second': '5.7658', 'grad_norm': '5.1875', 'counters/examples': 281984, 'counters/updates': 17624}
skipping logging after 282000 examples to avoid logging too frequently
skipping logging after 282016 examples to avoid logging too frequently
skipping logging after 282032 examples to avoid logging too frequently
train stats after 282048 examples: {'rewards_train/chosen': '0.022278', 'rewards_train/rejected': '-6.0223', 'rewards_train/margins': '6.0234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26611', 'examples_per_second': '5.2585', 'grad_norm': '5.4375', 'counters/examples': 282048, 'counters/updates': 17628}
skipping logging after 282064 examples to avoid logging too frequently
skipping logging after 282080 examples to avoid logging too frequently
skipping logging after 282096 examples to avoid logging too frequently
train stats after 282112 examples: {'rewards_train/chosen': '0.34473', 'rewards_train/rejected': '-5.8177', 'rewards_train/margins': '6.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21558', 'examples_per_second': '4.4671', 'grad_norm': '5.5', 'counters/examples': 282112, 'counters/updates': 17632}
skipping logging after 282128 examples to avoid logging too frequently
skipping logging after 282144 examples to avoid logging too frequently
skipping logging after 282160 examples to avoid logging too frequently
train stats after 282176 examples: {'rewards_train/chosen': '0.42284', 'rewards_train/rejected': '-6.0285', 'rewards_train/margins': '6.6875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22504', 'examples_per_second': '5.617', 'grad_norm': '5.0312', 'counters/examples': 282176, 'counters/updates': 17636}
skipping logging after 282192 examples to avoid logging too frequently
skipping logging after 282208 examples to avoid logging too frequently
skipping logging after 282224 examples to avoid logging too frequently
train stats after 282240 examples: {'rewards_train/chosen': '0.52158', 'rewards_train/rejected': '-6.1769', 'rewards_train/margins': '6.75', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2337', 'examples_per_second': '4.217', 'grad_norm': '5.6562', 'counters/examples': 282240, 'counters/updates': 17640}
skipping logging after 282256 examples to avoid logging too frequently
skipping logging after 282272 examples to avoid logging too frequently
skipping logging after 282288 examples to avoid logging too frequently
train stats after 282304 examples: {'rewards_train/chosen': '-0.73485', 'rewards_train/rejected': '-7.216', 'rewards_train/margins': '6.2266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24866', 'examples_per_second': '5.9911', 'grad_norm': '4.5938', 'counters/examples': 282304, 'counters/updates': 17644}
skipping logging after 282320 examples to avoid logging too frequently
skipping logging after 282336 examples to avoid logging too frequently
skipping logging after 282352 examples to avoid logging too frequently
train stats after 282368 examples: {'rewards_train/chosen': '0.53385', 'rewards_train/rejected': '-5.1435', 'rewards_train/margins': '5.6641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20001', 'examples_per_second': '6.0609', 'grad_norm': '4.75', 'counters/examples': 282368, 'counters/updates': 17648}
skipping logging after 282384 examples to avoid logging too frequently
skipping logging after 282400 examples to avoid logging too frequently
skipping logging after 282416 examples to avoid logging too frequently
train stats after 282432 examples: {'rewards_train/chosen': '0.27582', 'rewards_train/rejected': '-5.9732', 'rewards_train/margins': '6.1406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27423', 'examples_per_second': '5.7453', 'grad_norm': '4.9375', 'counters/examples': 282432, 'counters/updates': 17652}
skipping logging after 282448 examples to avoid logging too frequently
skipping logging after 282464 examples to avoid logging too frequently
skipping logging after 282480 examples to avoid logging too frequently
train stats after 282496 examples: {'rewards_train/chosen': '0.49938', 'rewards_train/rejected': '-6.9795', 'rewards_train/margins': '7.4609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22864', 'examples_per_second': '4.7371', 'grad_norm': '4.9375', 'counters/examples': 282496, 'counters/updates': 17656}
skipping logging after 282512 examples to avoid logging too frequently
skipping logging after 282528 examples to avoid logging too frequently
skipping logging after 282544 examples to avoid logging too frequently
train stats after 282560 examples: {'rewards_train/chosen': '0.35899', 'rewards_train/rejected': '-7.4763', 'rewards_train/margins': '7.875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19989', 'examples_per_second': '4.7673', 'grad_norm': '4.625', 'counters/examples': 282560, 'counters/updates': 17660}
skipping logging after 282576 examples to avoid logging too frequently
skipping logging after 282592 examples to avoid logging too frequently
skipping logging after 282608 examples to avoid logging too frequently
train stats after 282624 examples: {'rewards_train/chosen': '0.34901', 'rewards_train/rejected': '-7.2915', 'rewards_train/margins': '7.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23358', 'examples_per_second': '5.1171', 'grad_norm': '5.625', 'counters/examples': 282624, 'counters/updates': 17664}
skipping logging after 282640 examples to avoid logging too frequently
skipping logging after 282656 examples to avoid logging too frequently
skipping logging after 282672 examples to avoid logging too frequently
train stats after 282688 examples: {'rewards_train/chosen': '0.086071', 'rewards_train/rejected': '-7.2084', 'rewards_train/margins': '7.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26617', 'examples_per_second': '5.0917', 'grad_norm': '5.25', 'counters/examples': 282688, 'counters/updates': 17668}
skipping logging after 282704 examples to avoid logging too frequently
skipping logging after 282720 examples to avoid logging too frequently
skipping logging after 282736 examples to avoid logging too frequently
train stats after 282752 examples: {'rewards_train/chosen': '0.10289', 'rewards_train/rejected': '-5.9387', 'rewards_train/margins': '6.0234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.245', 'examples_per_second': '6.7478', 'grad_norm': '4.1875', 'counters/examples': 282752, 'counters/updates': 17672}
skipping logging after 282768 examples to avoid logging too frequently
skipping logging after 282784 examples to avoid logging too frequently
skipping logging after 282800 examples to avoid logging too frequently
train stats after 282816 examples: {'rewards_train/chosen': '0.48675', 'rewards_train/rejected': '-5.2904', 'rewards_train/margins': '5.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22754', 'examples_per_second': '6.2427', 'grad_norm': '5.0938', 'counters/examples': 282816, 'counters/updates': 17676}
skipping logging after 282832 examples to avoid logging too frequently
skipping logging after 282848 examples to avoid logging too frequently
skipping logging after 282864 examples to avoid logging too frequently
train stats after 282880 examples: {'rewards_train/chosen': '0.2864', 'rewards_train/rejected': '-5.5709', 'rewards_train/margins': '5.8906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.1839', 'examples_per_second': '5.2871', 'grad_norm': '4.2812', 'counters/examples': 282880, 'counters/updates': 17680}
skipping logging after 282896 examples to avoid logging too frequently
skipping logging after 282912 examples to avoid logging too frequently
skipping logging after 282928 examples to avoid logging too frequently
train stats after 282944 examples: {'rewards_train/chosen': '0.37886', 'rewards_train/rejected': '-6.9814', 'rewards_train/margins': '7.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2439', 'examples_per_second': '5.0115', 'grad_norm': '4.5312', 'counters/examples': 282944, 'counters/updates': 17684}
skipping logging after 282960 examples to avoid logging too frequently
skipping logging after 282976 examples to avoid logging too frequently
skipping logging after 282992 examples to avoid logging too frequently
train stats after 283008 examples: {'rewards_train/chosen': '0.018768', 'rewards_train/rejected': '-5.9575', 'rewards_train/margins': '5.7793', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29608', 'examples_per_second': '4.6351', 'grad_norm': '5.1875', 'counters/examples': 283008, 'counters/updates': 17688}
skipping logging after 283024 examples to avoid logging too frequently
skipping logging after 283040 examples to avoid logging too frequently
skipping logging after 283056 examples to avoid logging too frequently
train stats after 283072 examples: {'rewards_train/chosen': '0.012728', 'rewards_train/rejected': '-6.1978', 'rewards_train/margins': '5.9414', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25842', 'examples_per_second': '5.8283', 'grad_norm': '5.4062', 'counters/examples': 283072, 'counters/updates': 17692}
skipping logging after 283088 examples to avoid logging too frequently
skipping logging after 283104 examples to avoid logging too frequently
skipping logging after 283120 examples to avoid logging too frequently
train stats after 283136 examples: {'rewards_train/chosen': '0.54048', 'rewards_train/rejected': '-6.6943', 'rewards_train/margins': '7.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19916', 'examples_per_second': '5.0297', 'grad_norm': '4.5938', 'counters/examples': 283136, 'counters/updates': 17696}
skipping logging after 283152 examples to avoid logging too frequently
skipping logging after 283168 examples to avoid logging too frequently
skipping logging after 283184 examples to avoid logging too frequently
train stats after 283200 examples: {'rewards_train/chosen': '0.26347', 'rewards_train/rejected': '-6.7893', 'rewards_train/margins': '6.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24994', 'examples_per_second': '5.3112', 'grad_norm': '5.3438', 'counters/examples': 283200, 'counters/updates': 17700}
skipping logging after 283216 examples to avoid logging too frequently
skipping logging after 283232 examples to avoid logging too frequently
skipping logging after 283248 examples to avoid logging too frequently
train stats after 283264 examples: {'rewards_train/chosen': '0.48588', 'rewards_train/rejected': '-5.7617', 'rewards_train/margins': '6.6016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23322', 'examples_per_second': '6.0821', 'grad_norm': '5.2188', 'counters/examples': 283264, 'counters/updates': 17704}
skipping logging after 283280 examples to avoid logging too frequently
skipping logging after 283296 examples to avoid logging too frequently
skipping logging after 283312 examples to avoid logging too frequently
train stats after 283328 examples: {'rewards_train/chosen': '0.059359', 'rewards_train/rejected': '-5.8806', 'rewards_train/margins': '6.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24426', 'examples_per_second': '4.8245', 'grad_norm': '5.875', 'counters/examples': 283328, 'counters/updates': 17708}
skipping logging after 283344 examples to avoid logging too frequently
skipping logging after 283360 examples to avoid logging too frequently
skipping logging after 283376 examples to avoid logging too frequently
train stats after 283392 examples: {'rewards_train/chosen': '0.44153', 'rewards_train/rejected': '-7.5842', 'rewards_train/margins': '8.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20496', 'examples_per_second': '6.0244', 'grad_norm': '4.9688', 'counters/examples': 283392, 'counters/updates': 17712}
skipping logging after 283408 examples to avoid logging too frequently
skipping logging after 283424 examples to avoid logging too frequently
skipping logging after 283440 examples to avoid logging too frequently
train stats after 283456 examples: {'rewards_train/chosen': '0.11929', 'rewards_train/rejected': '-6.6308', 'rewards_train/margins': '6.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23029', 'examples_per_second': '5.3207', 'grad_norm': '4.6875', 'counters/examples': 283456, 'counters/updates': 17716}
skipping logging after 283472 examples to avoid logging too frequently
skipping logging after 283488 examples to avoid logging too frequently
skipping logging after 283504 examples to avoid logging too frequently
train stats after 283520 examples: {'rewards_train/chosen': '0.20098', 'rewards_train/rejected': '-7.0252', 'rewards_train/margins': '7.3047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23932', 'examples_per_second': '4.8625', 'grad_norm': '4.8438', 'counters/examples': 283520, 'counters/updates': 17720}
skipping logging after 283536 examples to avoid logging too frequently
skipping logging after 283552 examples to avoid logging too frequently
skipping logging after 283568 examples to avoid logging too frequently
train stats after 283584 examples: {'rewards_train/chosen': '0.3256', 'rewards_train/rejected': '-7.0762', 'rewards_train/margins': '7.4141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21222', 'examples_per_second': '5.8996', 'grad_norm': '6.9688', 'counters/examples': 283584, 'counters/updates': 17724}
skipping logging after 283600 examples to avoid logging too frequently
skipping logging after 283616 examples to avoid logging too frequently
skipping logging after 283632 examples to avoid logging too frequently
train stats after 283648 examples: {'rewards_train/chosen': '0.10094', 'rewards_train/rejected': '-8.48', 'rewards_train/margins': '8.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26465', 'examples_per_second': '4.9607', 'grad_norm': '6.0625', 'counters/examples': 283648, 'counters/updates': 17728}
skipping logging after 283664 examples to avoid logging too frequently
skipping logging after 283680 examples to avoid logging too frequently
skipping logging after 283696 examples to avoid logging too frequently
train stats after 283712 examples: {'rewards_train/chosen': '0.21328', 'rewards_train/rejected': '-6.1205', 'rewards_train/margins': '6.3672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25336', 'examples_per_second': '5.5697', 'grad_norm': '4.7188', 'counters/examples': 283712, 'counters/updates': 17732}
skipping logging after 283728 examples to avoid logging too frequently
skipping logging after 283744 examples to avoid logging too frequently
skipping logging after 283760 examples to avoid logging too frequently
train stats after 283776 examples: {'rewards_train/chosen': '0.26905', 'rewards_train/rejected': '-6.0475', 'rewards_train/margins': '6.2344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29407', 'examples_per_second': '4.8748', 'grad_norm': '5.4688', 'counters/examples': 283776, 'counters/updates': 17736}
skipping logging after 283792 examples to avoid logging too frequently
skipping logging after 283808 examples to avoid logging too frequently
skipping logging after 283824 examples to avoid logging too frequently
train stats after 283840 examples: {'rewards_train/chosen': '0.68111', 'rewards_train/rejected': '-6.3428', 'rewards_train/margins': '6.7656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20514', 'examples_per_second': '5.1754', 'grad_norm': '6.1562', 'counters/examples': 283840, 'counters/updates': 17740}
skipping logging after 283856 examples to avoid logging too frequently
skipping logging after 283872 examples to avoid logging too frequently
skipping logging after 283888 examples to avoid logging too frequently
train stats after 283904 examples: {'rewards_train/chosen': '0.40288', 'rewards_train/rejected': '-7.2849', 'rewards_train/margins': '7.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21869', 'examples_per_second': '5.6276', 'grad_norm': '5.1875', 'counters/examples': 283904, 'counters/updates': 17744}
skipping logging after 283920 examples to avoid logging too frequently
skipping logging after 283936 examples to avoid logging too frequently
skipping logging after 283952 examples to avoid logging too frequently
train stats after 283968 examples: {'rewards_train/chosen': '0.28817', 'rewards_train/rejected': '-6.0347', 'rewards_train/margins': '6.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21753', 'examples_per_second': '5.1608', 'grad_norm': '4.4062', 'counters/examples': 283968, 'counters/updates': 17748}
skipping logging after 283984 examples to avoid logging too frequently
skipping logging after 284000 examples to avoid logging too frequently
Running evaluation after 284000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:52,  1.70s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:43,  1.44s/it]Computing eval metrics:   9%|▉         | 3/32 [00:04<00:36,  1.26s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.49s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.69s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:09<00:38,  1.50s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:10<00:34,  1.38s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.53s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.49s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:31,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.41s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:20<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:21<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:28<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:12,  1.44s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:33<00:11,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:34<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.31s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:40<00:02,  1.18s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:41<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.12s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it]
eval after 284000: {'rewards_eval/chosen': '-6.186', 'rewards_eval/rejected': '-6.838', 'rewards_eval/margins': '0.47266', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.45702'}
skipping logging after 284016 examples to avoid logging too frequently
train stats after 284032 examples: {'rewards_train/chosen': '0.3371', 'rewards_train/rejected': '-7.9757', 'rewards_train/margins': '8.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25629', 'examples_per_second': '5.8817', 'grad_norm': '5.6562', 'counters/examples': 284032, 'counters/updates': 17752}
skipping logging after 284048 examples to avoid logging too frequently
skipping logging after 284064 examples to avoid logging too frequently
skipping logging after 284080 examples to avoid logging too frequently
train stats after 284096 examples: {'rewards_train/chosen': '0.33038', 'rewards_train/rejected': '-6.5352', 'rewards_train/margins': '6.7344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25458', 'examples_per_second': '4.6818', 'grad_norm': '5.4062', 'counters/examples': 284096, 'counters/updates': 17756}
skipping logging after 284112 examples to avoid logging too frequently
skipping logging after 284128 examples to avoid logging too frequently
skipping logging after 284144 examples to avoid logging too frequently
train stats after 284160 examples: {'rewards_train/chosen': '-0.071958', 'rewards_train/rejected': '-5.8782', 'rewards_train/margins': '5.6914', 'rewards_train/KL_estimate': '0', 'loss/train': '0.31262', 'examples_per_second': '5.5859', 'grad_norm': '6.25', 'counters/examples': 284160, 'counters/updates': 17760}
skipping logging after 284176 examples to avoid logging too frequently
skipping logging after 284192 examples to avoid logging too frequently
skipping logging after 284208 examples to avoid logging too frequently
train stats after 284224 examples: {'rewards_train/chosen': '0.21529', 'rewards_train/rejected': '-7.5358', 'rewards_train/margins': '8.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.3031', 'examples_per_second': '4.7147', 'grad_norm': '5.625', 'counters/examples': 284224, 'counters/updates': 17764}
skipping logging after 284240 examples to avoid logging too frequently
skipping logging after 284256 examples to avoid logging too frequently
skipping logging after 284272 examples to avoid logging too frequently
train stats after 284288 examples: {'rewards_train/chosen': '0.45678', 'rewards_train/rejected': '-4.7996', 'rewards_train/margins': '5.0898', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23431', 'examples_per_second': '4.9931', 'grad_norm': '5.2812', 'counters/examples': 284288, 'counters/updates': 17768}
skipping logging after 284304 examples to avoid logging too frequently
skipping logging after 284320 examples to avoid logging too frequently
skipping logging after 284336 examples to avoid logging too frequently
train stats after 284352 examples: {'rewards_train/chosen': '0.54628', 'rewards_train/rejected': '-6.6269', 'rewards_train/margins': '7.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23108', 'examples_per_second': '4.0603', 'grad_norm': '4.4375', 'counters/examples': 284352, 'counters/updates': 17772}
skipping logging after 284368 examples to avoid logging too frequently
skipping logging after 284384 examples to avoid logging too frequently
skipping logging after 284400 examples to avoid logging too frequently
train stats after 284416 examples: {'rewards_train/chosen': '0.30526', 'rewards_train/rejected': '-5.8011', 'rewards_train/margins': '6.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27258', 'examples_per_second': '5.7547', 'grad_norm': '5.7188', 'counters/examples': 284416, 'counters/updates': 17776}
skipping logging after 284432 examples to avoid logging too frequently
skipping logging after 284448 examples to avoid logging too frequently
skipping logging after 284464 examples to avoid logging too frequently
train stats after 284480 examples: {'rewards_train/chosen': '-0.0065746', 'rewards_train/rejected': '-4.972', 'rewards_train/margins': '4.8594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26929', 'examples_per_second': '6.0149', 'grad_norm': '5.0625', 'counters/examples': 284480, 'counters/updates': 17780}
skipping logging after 284496 examples to avoid logging too frequently
skipping logging after 284512 examples to avoid logging too frequently
skipping logging after 284528 examples to avoid logging too frequently
train stats after 284544 examples: {'rewards_train/chosen': '0.22899', 'rewards_train/rejected': '-5.114', 'rewards_train/margins': '5.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25067', 'examples_per_second': '4.861', 'grad_norm': '5.125', 'counters/examples': 284544, 'counters/updates': 17784}
skipping logging after 284560 examples to avoid logging too frequently
skipping logging after 284576 examples to avoid logging too frequently
skipping logging after 284592 examples to avoid logging too frequently
train stats after 284608 examples: {'rewards_train/chosen': '0.23908', 'rewards_train/rejected': '-6.3676', 'rewards_train/margins': '6.7266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22528', 'examples_per_second': '5.4206', 'grad_norm': '4.7188', 'counters/examples': 284608, 'counters/updates': 17788}
skipping logging after 284624 examples to avoid logging too frequently
skipping logging after 284640 examples to avoid logging too frequently
skipping logging after 284656 examples to avoid logging too frequently
train stats after 284672 examples: {'rewards_train/chosen': '0.55405', 'rewards_train/rejected': '-7.0714', 'rewards_train/margins': '7.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20605', 'examples_per_second': '4.8537', 'grad_norm': '4.2188', 'counters/examples': 284672, 'counters/updates': 17792}
skipping logging after 284688 examples to avoid logging too frequently
skipping logging after 284704 examples to avoid logging too frequently
skipping logging after 284720 examples to avoid logging too frequently
train stats after 284736 examples: {'rewards_train/chosen': '0.23959', 'rewards_train/rejected': '-6.6232', 'rewards_train/margins': '7.5547', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24927', 'examples_per_second': '5.0361', 'grad_norm': '4.75', 'counters/examples': 284736, 'counters/updates': 17796}
skipping logging after 284752 examples to avoid logging too frequently
skipping logging after 284768 examples to avoid logging too frequently
skipping logging after 284784 examples to avoid logging too frequently
train stats after 284800 examples: {'rewards_train/chosen': '0.095929', 'rewards_train/rejected': '-6.329', 'rewards_train/margins': '6.6484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28308', 'examples_per_second': '5.3813', 'grad_norm': '5.2812', 'counters/examples': 284800, 'counters/updates': 17800}
skipping logging after 284816 examples to avoid logging too frequently
skipping logging after 284832 examples to avoid logging too frequently
skipping logging after 284848 examples to avoid logging too frequently
train stats after 284864 examples: {'rewards_train/chosen': '0.63769', 'rewards_train/rejected': '-5.3504', 'rewards_train/margins': '6.0312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21423', 'examples_per_second': '5.0499', 'grad_norm': '4.4375', 'counters/examples': 284864, 'counters/updates': 17804}
skipping logging after 284880 examples to avoid logging too frequently
skipping logging after 284896 examples to avoid logging too frequently
skipping logging after 284912 examples to avoid logging too frequently
train stats after 284928 examples: {'rewards_train/chosen': '0.33647', 'rewards_train/rejected': '-6.7826', 'rewards_train/margins': '6.9453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22473', 'examples_per_second': '4.8766', 'grad_norm': '4.625', 'counters/examples': 284928, 'counters/updates': 17808}
skipping logging after 284944 examples to avoid logging too frequently
skipping logging after 284960 examples to avoid logging too frequently
skipping logging after 284976 examples to avoid logging too frequently
train stats after 284992 examples: {'rewards_train/chosen': '0.22707', 'rewards_train/rejected': '-5.4153', 'rewards_train/margins': '5.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25409', 'examples_per_second': '4.8786', 'grad_norm': '5.4062', 'counters/examples': 284992, 'counters/updates': 17812}
skipping logging after 285008 examples to avoid logging too frequently
skipping logging after 285024 examples to avoid logging too frequently
skipping logging after 285040 examples to avoid logging too frequently
train stats after 285056 examples: {'rewards_train/chosen': '0.16728', 'rewards_train/rejected': '-4.8705', 'rewards_train/margins': '4.8672', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30231', 'examples_per_second': '5.1877', 'grad_norm': '5.375', 'counters/examples': 285056, 'counters/updates': 17816}
skipping logging after 285072 examples to avoid logging too frequently
skipping logging after 285088 examples to avoid logging too frequently
skipping logging after 285104 examples to avoid logging too frequently
train stats after 285120 examples: {'rewards_train/chosen': '0.42042', 'rewards_train/rejected': '-4.9078', 'rewards_train/margins': '5.3281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25922', 'examples_per_second': '5.1834', 'grad_norm': '5.3438', 'counters/examples': 285120, 'counters/updates': 17820}
skipping logging after 285136 examples to avoid logging too frequently
skipping logging after 285152 examples to avoid logging too frequently
skipping logging after 285168 examples to avoid logging too frequently
train stats after 285184 examples: {'rewards_train/chosen': '0.30089', 'rewards_train/rejected': '-5.8368', 'rewards_train/margins': '6.2344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22125', 'examples_per_second': '4.6842', 'grad_norm': '4.5312', 'counters/examples': 285184, 'counters/updates': 17824}
skipping logging after 285200 examples to avoid logging too frequently
skipping logging after 285216 examples to avoid logging too frequently
skipping logging after 285232 examples to avoid logging too frequently
train stats after 285248 examples: {'rewards_train/chosen': '0.45041', 'rewards_train/rejected': '-5.5765', 'rewards_train/margins': '6.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24127', 'examples_per_second': '5.5791', 'grad_norm': '4.5312', 'counters/examples': 285248, 'counters/updates': 17828}
skipping logging after 285264 examples to avoid logging too frequently
skipping logging after 285280 examples to avoid logging too frequently
skipping logging after 285296 examples to avoid logging too frequently
train stats after 285312 examples: {'rewards_train/chosen': '0.24445', 'rewards_train/rejected': '-5.6284', 'rewards_train/margins': '5.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24939', 'examples_per_second': '4.2519', 'grad_norm': '6', 'counters/examples': 285312, 'counters/updates': 17832}
skipping logging after 285328 examples to avoid logging too frequently
skipping logging after 285344 examples to avoid logging too frequently
skipping logging after 285360 examples to avoid logging too frequently
train stats after 285376 examples: {'rewards_train/chosen': '0.17581', 'rewards_train/rejected': '-6.0031', 'rewards_train/margins': '6.1172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28192', 'examples_per_second': '4.9006', 'grad_norm': '4.9688', 'counters/examples': 285376, 'counters/updates': 17836}
skipping logging after 285392 examples to avoid logging too frequently
skipping logging after 285408 examples to avoid logging too frequently
skipping logging after 285424 examples to avoid logging too frequently
train stats after 285440 examples: {'rewards_train/chosen': '0.26135', 'rewards_train/rejected': '-6.8223', 'rewards_train/margins': '7.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22717', 'examples_per_second': '4.7261', 'grad_norm': '5.5', 'counters/examples': 285440, 'counters/updates': 17840}
skipping logging after 285456 examples to avoid logging too frequently
skipping logging after 285472 examples to avoid logging too frequently
skipping logging after 285488 examples to avoid logging too frequently
train stats after 285504 examples: {'rewards_train/chosen': '0.24086', 'rewards_train/rejected': '-5.3312', 'rewards_train/margins': '5.5859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2005', 'examples_per_second': '6.5119', 'grad_norm': '4.2812', 'counters/examples': 285504, 'counters/updates': 17844}
skipping logging after 285520 examples to avoid logging too frequently
skipping logging after 285536 examples to avoid logging too frequently
skipping logging after 285552 examples to avoid logging too frequently
train stats after 285568 examples: {'rewards_train/chosen': '0.028389', 'rewards_train/rejected': '-6.9345', 'rewards_train/margins': '6.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24762', 'examples_per_second': '5.3121', 'grad_norm': '4.8438', 'counters/examples': 285568, 'counters/updates': 17848}
skipping logging after 285584 examples to avoid logging too frequently
skipping logging after 285600 examples to avoid logging too frequently
skipping logging after 285616 examples to avoid logging too frequently
train stats after 285632 examples: {'rewards_train/chosen': '0.28342', 'rewards_train/rejected': '-5.8857', 'rewards_train/margins': '5.9883', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22778', 'examples_per_second': '5.4982', 'grad_norm': '5.0938', 'counters/examples': 285632, 'counters/updates': 17852}
skipping logging after 285648 examples to avoid logging too frequently
skipping logging after 285664 examples to avoid logging too frequently
skipping logging after 285680 examples to avoid logging too frequently
train stats after 285696 examples: {'rewards_train/chosen': '0.55876', 'rewards_train/rejected': '-6.0503', 'rewards_train/margins': '6.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19824', 'examples_per_second': '4.1959', 'grad_norm': '5.125', 'counters/examples': 285696, 'counters/updates': 17856}
skipping logging after 285712 examples to avoid logging too frequently
skipping logging after 285728 examples to avoid logging too frequently
skipping logging after 285744 examples to avoid logging too frequently
train stats after 285760 examples: {'rewards_train/chosen': '0.22958', 'rewards_train/rejected': '-6.8216', 'rewards_train/margins': '6.9609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25836', 'examples_per_second': '5.7508', 'grad_norm': '4.5312', 'counters/examples': 285760, 'counters/updates': 17860}
skipping logging after 285776 examples to avoid logging too frequently
skipping logging after 285792 examples to avoid logging too frequently
skipping logging after 285808 examples to avoid logging too frequently
train stats after 285824 examples: {'rewards_train/chosen': '-0.05878', 'rewards_train/rejected': '-6.3954', 'rewards_train/margins': '6.8281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22766', 'examples_per_second': '6.8706', 'grad_norm': '4.9062', 'counters/examples': 285824, 'counters/updates': 17864}
skipping logging after 285840 examples to avoid logging too frequently
skipping logging after 285856 examples to avoid logging too frequently
skipping logging after 285872 examples to avoid logging too frequently
train stats after 285888 examples: {'rewards_train/chosen': '0.40447', 'rewards_train/rejected': '-6.2209', 'rewards_train/margins': '6.8125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22729', 'examples_per_second': '5.548', 'grad_norm': '4.625', 'counters/examples': 285888, 'counters/updates': 17868}
skipping logging after 285904 examples to avoid logging too frequently
skipping logging after 285920 examples to avoid logging too frequently
skipping logging after 285936 examples to avoid logging too frequently
train stats after 285952 examples: {'rewards_train/chosen': '0.1875', 'rewards_train/rejected': '-6.9109', 'rewards_train/margins': '7.2812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2583', 'examples_per_second': '6.3266', 'grad_norm': '5.2188', 'counters/examples': 285952, 'counters/updates': 17872}
skipping logging after 285968 examples to avoid logging too frequently
skipping logging after 285984 examples to avoid logging too frequently
skipping logging after 286000 examples to avoid logging too frequently
train stats after 286016 examples: {'rewards_train/chosen': '0.49629', 'rewards_train/rejected': '-6.5031', 'rewards_train/margins': '7.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21234', 'examples_per_second': '5.1235', 'grad_norm': '7.2188', 'counters/examples': 286016, 'counters/updates': 17876}
skipping logging after 286032 examples to avoid logging too frequently
skipping logging after 286048 examples to avoid logging too frequently
skipping logging after 286064 examples to avoid logging too frequently
train stats after 286080 examples: {'rewards_train/chosen': '0.058675', 'rewards_train/rejected': '-4.8839', 'rewards_train/margins': '4.7656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26111', 'examples_per_second': '5.3071', 'grad_norm': '5.5', 'counters/examples': 286080, 'counters/updates': 17880}
skipping logging after 286096 examples to avoid logging too frequently
skipping logging after 286112 examples to avoid logging too frequently
skipping logging after 286128 examples to avoid logging too frequently
train stats after 286144 examples: {'rewards_train/chosen': '0.13085', 'rewards_train/rejected': '-6.3785', 'rewards_train/margins': '6.5391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26587', 'examples_per_second': '4.4906', 'grad_norm': '5.625', 'counters/examples': 286144, 'counters/updates': 17884}
skipping logging after 286160 examples to avoid logging too frequently
skipping logging after 286176 examples to avoid logging too frequently
skipping logging after 286192 examples to avoid logging too frequently
train stats after 286208 examples: {'rewards_train/chosen': '0.43299', 'rewards_train/rejected': '-6.6757', 'rewards_train/margins': '7.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17267', 'examples_per_second': '4.9682', 'grad_norm': '5.4062', 'counters/examples': 286208, 'counters/updates': 17888}
skipping logging after 286224 examples to avoid logging too frequently
skipping logging after 286240 examples to avoid logging too frequently
skipping logging after 286256 examples to avoid logging too frequently
train stats after 286272 examples: {'rewards_train/chosen': '0.15338', 'rewards_train/rejected': '-5.7875', 'rewards_train/margins': '6.0078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25726', 'examples_per_second': '5.3772', 'grad_norm': '5.125', 'counters/examples': 286272, 'counters/updates': 17892}
skipping logging after 286288 examples to avoid logging too frequently
skipping logging after 286304 examples to avoid logging too frequently
skipping logging after 286320 examples to avoid logging too frequently
train stats after 286336 examples: {'rewards_train/chosen': '0.2306', 'rewards_train/rejected': '-6.8103', 'rewards_train/margins': '7.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26294', 'examples_per_second': '4.9214', 'grad_norm': '5.2188', 'counters/examples': 286336, 'counters/updates': 17896}
skipping logging after 286352 examples to avoid logging too frequently
skipping logging after 286368 examples to avoid logging too frequently
skipping logging after 286384 examples to avoid logging too frequently
train stats after 286400 examples: {'rewards_train/chosen': '0.15194', 'rewards_train/rejected': '-5.9887', 'rewards_train/margins': '6.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23615', 'examples_per_second': '5.7412', 'grad_norm': '4.5', 'counters/examples': 286400, 'counters/updates': 17900}
skipping logging after 286416 examples to avoid logging too frequently
skipping logging after 286432 examples to avoid logging too frequently
skipping logging after 286448 examples to avoid logging too frequently
train stats after 286464 examples: {'rewards_train/chosen': '0.093945', 'rewards_train/rejected': '-5.4024', 'rewards_train/margins': '5.3984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28369', 'examples_per_second': '5.5612', 'grad_norm': '6.1562', 'counters/examples': 286464, 'counters/updates': 17904}
skipping logging after 286480 examples to avoid logging too frequently
skipping logging after 286496 examples to avoid logging too frequently
skipping logging after 286512 examples to avoid logging too frequently
train stats after 286528 examples: {'rewards_train/chosen': '0.13513', 'rewards_train/rejected': '-6.171', 'rewards_train/margins': '6.375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23944', 'examples_per_second': '5.4569', 'grad_norm': '5.2188', 'counters/examples': 286528, 'counters/updates': 17908}
skipping logging after 286544 examples to avoid logging too frequently
skipping logging after 286560 examples to avoid logging too frequently
skipping logging after 286576 examples to avoid logging too frequently
train stats after 286592 examples: {'rewards_train/chosen': '0.35809', 'rewards_train/rejected': '-5.5418', 'rewards_train/margins': '5.9375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25726', 'examples_per_second': '5.9825', 'grad_norm': '6.125', 'counters/examples': 286592, 'counters/updates': 17912}
skipping logging after 286608 examples to avoid logging too frequently
skipping logging after 286624 examples to avoid logging too frequently
skipping logging after 286640 examples to avoid logging too frequently
train stats after 286656 examples: {'rewards_train/chosen': '0.38816', 'rewards_train/rejected': '-5.196', 'rewards_train/margins': '5.5938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27338', 'examples_per_second': '5.7793', 'grad_norm': '5.75', 'counters/examples': 286656, 'counters/updates': 17916}
skipping logging after 286672 examples to avoid logging too frequently
skipping logging after 286688 examples to avoid logging too frequently
skipping logging after 286704 examples to avoid logging too frequently
train stats after 286720 examples: {'rewards_train/chosen': '0.36057', 'rewards_train/rejected': '-6.6708', 'rewards_train/margins': '8.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29175', 'examples_per_second': '5.043', 'grad_norm': '5.0625', 'counters/examples': 286720, 'counters/updates': 17920}
skipping logging after 286736 examples to avoid logging too frequently
skipping logging after 286752 examples to avoid logging too frequently
skipping logging after 286768 examples to avoid logging too frequently
train stats after 286784 examples: {'rewards_train/chosen': '0.49512', 'rewards_train/rejected': '-5.3979', 'rewards_train/margins': '5.8633', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23248', 'examples_per_second': '4.1909', 'grad_norm': '5.8438', 'counters/examples': 286784, 'counters/updates': 17924}
skipping logging after 286800 examples to avoid logging too frequently
skipping logging after 286816 examples to avoid logging too frequently
skipping logging after 286832 examples to avoid logging too frequently
train stats after 286848 examples: {'rewards_train/chosen': '0.56915', 'rewards_train/rejected': '-4.8996', 'rewards_train/margins': '5.5781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24939', 'examples_per_second': '4.5064', 'grad_norm': '6.5312', 'counters/examples': 286848, 'counters/updates': 17928}
skipping logging after 286864 examples to avoid logging too frequently
skipping logging after 286880 examples to avoid logging too frequently
skipping logging after 286896 examples to avoid logging too frequently
train stats after 286912 examples: {'rewards_train/chosen': '0.28059', 'rewards_train/rejected': '-6.1367', 'rewards_train/margins': '6.2734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23529', 'examples_per_second': '4.4956', 'grad_norm': '5.5312', 'counters/examples': 286912, 'counters/updates': 17932}
skipping logging after 286928 examples to avoid logging too frequently
skipping logging after 286944 examples to avoid logging too frequently
skipping logging after 286960 examples to avoid logging too frequently
train stats after 286976 examples: {'rewards_train/chosen': '0.13278', 'rewards_train/rejected': '-6.0439', 'rewards_train/margins': '6.2109', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20996', 'examples_per_second': '5.1142', 'grad_norm': '4.4062', 'counters/examples': 286976, 'counters/updates': 17936}
skipping logging after 286992 examples to avoid logging too frequently
skipping logging after 287008 examples to avoid logging too frequently
skipping logging after 287024 examples to avoid logging too frequently
train stats after 287040 examples: {'rewards_train/chosen': '0.33903', 'rewards_train/rejected': '-6.7065', 'rewards_train/margins': '7.1016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23676', 'examples_per_second': '5.6274', 'grad_norm': '4.6875', 'counters/examples': 287040, 'counters/updates': 17940}
skipping logging after 287056 examples to avoid logging too frequently
skipping logging after 287072 examples to avoid logging too frequently
skipping logging after 287088 examples to avoid logging too frequently
train stats after 287104 examples: {'rewards_train/chosen': '0.18441', 'rewards_train/rejected': '-6.1491', 'rewards_train/margins': '6.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20953', 'examples_per_second': '5.7571', 'grad_norm': '4.6875', 'counters/examples': 287104, 'counters/updates': 17944}
skipping logging after 287120 examples to avoid logging too frequently
skipping logging after 287136 examples to avoid logging too frequently
skipping logging after 287152 examples to avoid logging too frequently
train stats after 287168 examples: {'rewards_train/chosen': '0.34229', 'rewards_train/rejected': '-6.4426', 'rewards_train/margins': '6.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25043', 'examples_per_second': '6.2977', 'grad_norm': '6.25', 'counters/examples': 287168, 'counters/updates': 17948}
skipping logging after 287184 examples to avoid logging too frequently
skipping logging after 287200 examples to avoid logging too frequently
skipping logging after 287216 examples to avoid logging too frequently
train stats after 287232 examples: {'rewards_train/chosen': '0.3718', 'rewards_train/rejected': '-5.1603', 'rewards_train/margins': '5.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20898', 'examples_per_second': '4.841', 'grad_norm': '5.5', 'counters/examples': 287232, 'counters/updates': 17952}
skipping logging after 287248 examples to avoid logging too frequently
skipping logging after 287264 examples to avoid logging too frequently
skipping logging after 287280 examples to avoid logging too frequently
train stats after 287296 examples: {'rewards_train/chosen': '0.12218', 'rewards_train/rejected': '-7.0939', 'rewards_train/margins': '7.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2323', 'examples_per_second': '4.1324', 'grad_norm': '5.0625', 'counters/examples': 287296, 'counters/updates': 17956}
skipping logging after 287312 examples to avoid logging too frequently
skipping logging after 287328 examples to avoid logging too frequently
skipping logging after 287344 examples to avoid logging too frequently
train stats after 287360 examples: {'rewards_train/chosen': '0.2241', 'rewards_train/rejected': '-5.8675', 'rewards_train/margins': '6.25', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23535', 'examples_per_second': '5.5829', 'grad_norm': '5.125', 'counters/examples': 287360, 'counters/updates': 17960}
skipping logging after 287376 examples to avoid logging too frequently
skipping logging after 287392 examples to avoid logging too frequently
skipping logging after 287408 examples to avoid logging too frequently
train stats after 287424 examples: {'rewards_train/chosen': '0.14116', 'rewards_train/rejected': '-6.2433', 'rewards_train/margins': '6.4844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26044', 'examples_per_second': '4.2895', 'grad_norm': '6.1875', 'counters/examples': 287424, 'counters/updates': 17964}
skipping logging after 287440 examples to avoid logging too frequently
skipping logging after 287456 examples to avoid logging too frequently
skipping logging after 287472 examples to avoid logging too frequently
train stats after 287488 examples: {'rewards_train/chosen': '0.43833', 'rewards_train/rejected': '-6.6024', 'rewards_train/margins': '6.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23108', 'examples_per_second': '5.1186', 'grad_norm': '4.8438', 'counters/examples': 287488, 'counters/updates': 17968}
skipping logging after 287504 examples to avoid logging too frequently
skipping logging after 287520 examples to avoid logging too frequently
skipping logging after 287536 examples to avoid logging too frequently
train stats after 287552 examples: {'rewards_train/chosen': '-0.13608', 'rewards_train/rejected': '-6.0231', 'rewards_train/margins': '5.8984', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25922', 'examples_per_second': '6.2098', 'grad_norm': '5.125', 'counters/examples': 287552, 'counters/updates': 17972}
skipping logging after 287568 examples to avoid logging too frequently
skipping logging after 287584 examples to avoid logging too frequently
skipping logging after 287600 examples to avoid logging too frequently
train stats after 287616 examples: {'rewards_train/chosen': '0.40257', 'rewards_train/rejected': '-5.5652', 'rewards_train/margins': '5.9844', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24408', 'examples_per_second': '5.1308', 'grad_norm': '6.3438', 'counters/examples': 287616, 'counters/updates': 17976}
skipping logging after 287632 examples to avoid logging too frequently
skipping logging after 287648 examples to avoid logging too frequently
skipping logging after 287664 examples to avoid logging too frequently
train stats after 287680 examples: {'rewards_train/chosen': '0.49429', 'rewards_train/rejected': '-5.9986', 'rewards_train/margins': '6.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21246', 'examples_per_second': '4.7158', 'grad_norm': '4.125', 'counters/examples': 287680, 'counters/updates': 17980}
skipping logging after 287696 examples to avoid logging too frequently
skipping logging after 287712 examples to avoid logging too frequently
skipping logging after 287728 examples to avoid logging too frequently
train stats after 287744 examples: {'rewards_train/chosen': '0.34021', 'rewards_train/rejected': '-6.048', 'rewards_train/margins': '6.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2533', 'examples_per_second': '4.7764', 'grad_norm': '7.3125', 'counters/examples': 287744, 'counters/updates': 17984}
skipping logging after 287760 examples to avoid logging too frequently
skipping logging after 287776 examples to avoid logging too frequently
skipping logging after 287792 examples to avoid logging too frequently
train stats after 287808 examples: {'rewards_train/chosen': '0.46967', 'rewards_train/rejected': '-5.955', 'rewards_train/margins': '6.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22198', 'examples_per_second': '5.5827', 'grad_norm': '4.8438', 'counters/examples': 287808, 'counters/updates': 17988}
skipping logging after 287824 examples to avoid logging too frequently
skipping logging after 287840 examples to avoid logging too frequently
skipping logging after 287856 examples to avoid logging too frequently
train stats after 287872 examples: {'rewards_train/chosen': '0.67816', 'rewards_train/rejected': '-6.8139', 'rewards_train/margins': '7.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18524', 'examples_per_second': '5.0711', 'grad_norm': '4.125', 'counters/examples': 287872, 'counters/updates': 17992}
skipping logging after 287888 examples to avoid logging too frequently
skipping logging after 287904 examples to avoid logging too frequently
skipping logging after 287920 examples to avoid logging too frequently
train stats after 287936 examples: {'rewards_train/chosen': '0.44356', 'rewards_train/rejected': '-5.4857', 'rewards_train/margins': '5.9688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21985', 'examples_per_second': '5.4127', 'grad_norm': '5.3125', 'counters/examples': 287936, 'counters/updates': 17996}
skipping logging after 287952 examples to avoid logging too frequently
skipping logging after 287968 examples to avoid logging too frequently
skipping logging after 287984 examples to avoid logging too frequently
train stats after 288000 examples: {'rewards_train/chosen': '0.51417', 'rewards_train/rejected': '-6.8969', 'rewards_train/margins': '7.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20618', 'examples_per_second': '4.2385', 'grad_norm': '4.8125', 'counters/examples': 288000, 'counters/updates': 18000}
Running evaluation after 288000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:38,  1.25s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:37,  1.25s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:33,  1.16s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:39,  1.43s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:44,  1.65s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.47s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:09<00:33,  1.36s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.51s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:12<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:15<00:31,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.23s/it]Computing eval metrics:  50%|█████     | 16/32 [00:21<00:20,  1.28s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:28<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:30<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.32s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.19s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.13s/it]Computing eval metrics: 100%|██████████| 32/32 [00:41<00:00,  1.31s/it]
eval after 288000: {'rewards_eval/chosen': '-6.05', 'rewards_eval/rejected': '-6.7027', 'rewards_eval/margins': '0.5083', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.45688'}
skipping logging after 288016 examples to avoid logging too frequently
skipping logging after 288032 examples to avoid logging too frequently
skipping logging after 288048 examples to avoid logging too frequently
train stats after 288064 examples: {'rewards_train/chosen': '-0.021676', 'rewards_train/rejected': '-5.7571', 'rewards_train/margins': '5.5391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26129', 'examples_per_second': '5.5291', 'grad_norm': '4.9688', 'counters/examples': 288064, 'counters/updates': 18004}
skipping logging after 288080 examples to avoid logging too frequently
skipping logging after 288096 examples to avoid logging too frequently
skipping logging after 288112 examples to avoid logging too frequently
train stats after 288128 examples: {'rewards_train/chosen': '0.51823', 'rewards_train/rejected': '-6.4319', 'rewards_train/margins': '7.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17255', 'examples_per_second': '5.2964', 'grad_norm': '5.0312', 'counters/examples': 288128, 'counters/updates': 18008}
skipping logging after 288144 examples to avoid logging too frequently
skipping logging after 288160 examples to avoid logging too frequently
skipping logging after 288176 examples to avoid logging too frequently
train stats after 288192 examples: {'rewards_train/chosen': '-0.419', 'rewards_train/rejected': '-6.0877', 'rewards_train/margins': '5.5469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.32489', 'examples_per_second': '5.6614', 'grad_norm': '6.125', 'counters/examples': 288192, 'counters/updates': 18012}
skipping logging after 288208 examples to avoid logging too frequently
skipping logging after 288224 examples to avoid logging too frequently
skipping logging after 288240 examples to avoid logging too frequently
train stats after 288256 examples: {'rewards_train/chosen': '0.58719', 'rewards_train/rejected': '-6.8958', 'rewards_train/margins': '7.1016', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20093', 'examples_per_second': '4.9344', 'grad_norm': '5.25', 'counters/examples': 288256, 'counters/updates': 18016}
skipping logging after 288272 examples to avoid logging too frequently
skipping logging after 288288 examples to avoid logging too frequently
skipping logging after 288304 examples to avoid logging too frequently
train stats after 288320 examples: {'rewards_train/chosen': '0.25923', 'rewards_train/rejected': '-5.8081', 'rewards_train/margins': '6.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25385', 'examples_per_second': '4.3655', 'grad_norm': '5.4375', 'counters/examples': 288320, 'counters/updates': 18020}
skipping logging after 288336 examples to avoid logging too frequently
skipping logging after 288352 examples to avoid logging too frequently
skipping logging after 288368 examples to avoid logging too frequently
train stats after 288384 examples: {'rewards_train/chosen': '-0.20865', 'rewards_train/rejected': '-5.9442', 'rewards_train/margins': '5.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27875', 'examples_per_second': '6.8021', 'grad_norm': '4.5938', 'counters/examples': 288384, 'counters/updates': 18024}
skipping logging after 288400 examples to avoid logging too frequently
skipping logging after 288416 examples to avoid logging too frequently
skipping logging after 288432 examples to avoid logging too frequently
train stats after 288448 examples: {'rewards_train/chosen': '0.2873', 'rewards_train/rejected': '-6.4733', 'rewards_train/margins': '6.6719', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25287', 'examples_per_second': '4.2837', 'grad_norm': '5.9062', 'counters/examples': 288448, 'counters/updates': 18028}
skipping logging after 288464 examples to avoid logging too frequently
skipping logging after 288480 examples to avoid logging too frequently
skipping logging after 288496 examples to avoid logging too frequently
train stats after 288512 examples: {'rewards_train/chosen': '0.38591', 'rewards_train/rejected': '-6.4397', 'rewards_train/margins': '7.0938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22949', 'examples_per_second': '5.2053', 'grad_norm': '4.7188', 'counters/examples': 288512, 'counters/updates': 18032}
skipping logging after 288528 examples to avoid logging too frequently
skipping logging after 288544 examples to avoid logging too frequently
skipping logging after 288560 examples to avoid logging too frequently
train stats after 288576 examples: {'rewards_train/chosen': '-0.05579', 'rewards_train/rejected': '-5.7031', 'rewards_train/margins': '6.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26129', 'examples_per_second': '5.7433', 'grad_norm': '5.375', 'counters/examples': 288576, 'counters/updates': 18036}
skipping logging after 288592 examples to avoid logging too frequently
skipping logging after 288608 examples to avoid logging too frequently
skipping logging after 288624 examples to avoid logging too frequently
train stats after 288640 examples: {'rewards_train/chosen': '0.3454', 'rewards_train/rejected': '-5.0632', 'rewards_train/margins': '5.3281', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22607', 'examples_per_second': '5.7409', 'grad_norm': '5.1562', 'counters/examples': 288640, 'counters/updates': 18040}
skipping logging after 288656 examples to avoid logging too frequently
skipping logging after 288672 examples to avoid logging too frequently
skipping logging after 288688 examples to avoid logging too frequently
train stats after 288704 examples: {'rewards_train/chosen': '0.25014', 'rewards_train/rejected': '-6.7673', 'rewards_train/margins': '6.5781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28833', 'examples_per_second': '4.7377', 'grad_norm': '5.5625', 'counters/examples': 288704, 'counters/updates': 18044}
skipping logging after 288720 examples to avoid logging too frequently
skipping logging after 288736 examples to avoid logging too frequently
skipping logging after 288752 examples to avoid logging too frequently
train stats after 288768 examples: {'rewards_train/chosen': '0.079565', 'rewards_train/rejected': '-4.9516', 'rewards_train/margins': '5.0859', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2431', 'examples_per_second': '5.2696', 'grad_norm': '5.2188', 'counters/examples': 288768, 'counters/updates': 18048}
skipping logging after 288784 examples to avoid logging too frequently
skipping logging after 288800 examples to avoid logging too frequently
skipping logging after 288816 examples to avoid logging too frequently
train stats after 288832 examples: {'rewards_train/chosen': '0.38272', 'rewards_train/rejected': '-5.9087', 'rewards_train/margins': '6.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24414', 'examples_per_second': '4.7015', 'grad_norm': '4.3438', 'counters/examples': 288832, 'counters/updates': 18052}
skipping logging after 288848 examples to avoid logging too frequently
skipping logging after 288864 examples to avoid logging too frequently
skipping logging after 288880 examples to avoid logging too frequently
train stats after 288896 examples: {'rewards_train/chosen': '0.32963', 'rewards_train/rejected': '-4.7212', 'rewards_train/margins': '5.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25323', 'examples_per_second': '5.3477', 'grad_norm': '5.875', 'counters/examples': 288896, 'counters/updates': 18056}
skipping logging after 288912 examples to avoid logging too frequently
skipping logging after 288928 examples to avoid logging too frequently
skipping logging after 288944 examples to avoid logging too frequently
train stats after 288960 examples: {'rewards_train/chosen': '0.6082', 'rewards_train/rejected': '-6.1365', 'rewards_train/margins': '7.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20813', 'examples_per_second': '5.5487', 'grad_norm': '5.6562', 'counters/examples': 288960, 'counters/updates': 18060}
skipping logging after 288976 examples to avoid logging too frequently
skipping logging after 288992 examples to avoid logging too frequently
skipping logging after 289008 examples to avoid logging too frequently
train stats after 289024 examples: {'rewards_train/chosen': '0.1703', 'rewards_train/rejected': '-8.6455', 'rewards_train/margins': '9.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23163', 'examples_per_second': '4.5581', 'grad_norm': '5.6562', 'counters/examples': 289024, 'counters/updates': 18064}
skipping logging after 289040 examples to avoid logging too frequently
skipping logging after 289056 examples to avoid logging too frequently
skipping logging after 289072 examples to avoid logging too frequently
train stats after 289088 examples: {'rewards_train/chosen': '-0.039278', 'rewards_train/rejected': '-7.1353', 'rewards_train/margins': '7.2031', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27643', 'examples_per_second': '5.4181', 'grad_norm': '5.125', 'counters/examples': 289088, 'counters/updates': 18068}
skipping logging after 289104 examples to avoid logging too frequently
skipping logging after 289120 examples to avoid logging too frequently
skipping logging after 289136 examples to avoid logging too frequently
train stats after 289152 examples: {'rewards_train/chosen': '0.63879', 'rewards_train/rejected': '-7.1758', 'rewards_train/margins': '7.9219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19781', 'examples_per_second': '5.7627', 'grad_norm': '5', 'counters/examples': 289152, 'counters/updates': 18072}
skipping logging after 289168 examples to avoid logging too frequently
skipping logging after 289184 examples to avoid logging too frequently
skipping logging after 289200 examples to avoid logging too frequently
train stats after 289216 examples: {'rewards_train/chosen': '0.38217', 'rewards_train/rejected': '-5.592', 'rewards_train/margins': '6.0117', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25116', 'examples_per_second': '5.2722', 'grad_norm': '5.6875', 'counters/examples': 289216, 'counters/updates': 18076}
skipping logging after 289232 examples to avoid logging too frequently
skipping logging after 289248 examples to avoid logging too frequently
skipping logging after 289264 examples to avoid logging too frequently
train stats after 289280 examples: {'rewards_train/chosen': '0.33973', 'rewards_train/rejected': '-6.0352', 'rewards_train/margins': '6.2578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23035', 'examples_per_second': '4.9287', 'grad_norm': '4.25', 'counters/examples': 289280, 'counters/updates': 18080}
skipping logging after 289296 examples to avoid logging too frequently
skipping logging after 289312 examples to avoid logging too frequently
skipping logging after 289328 examples to avoid logging too frequently
train stats after 289344 examples: {'rewards_train/chosen': '0.39767', 'rewards_train/rejected': '-6.1924', 'rewards_train/margins': '6.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25946', 'examples_per_second': '4.6149', 'grad_norm': '5', 'counters/examples': 289344, 'counters/updates': 18084}
skipping logging after 289360 examples to avoid logging too frequently
skipping logging after 289376 examples to avoid logging too frequently
skipping logging after 289392 examples to avoid logging too frequently
train stats after 289408 examples: {'rewards_train/chosen': '0.38499', 'rewards_train/rejected': '-4.9225', 'rewards_train/margins': '5.3945', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23224', 'examples_per_second': '5.9184', 'grad_norm': '4.4688', 'counters/examples': 289408, 'counters/updates': 18088}
skipping logging after 289424 examples to avoid logging too frequently
skipping logging after 289440 examples to avoid logging too frequently
skipping logging after 289456 examples to avoid logging too frequently
train stats after 289472 examples: {'rewards_train/chosen': '0.0057031', 'rewards_train/rejected': '-6.1305', 'rewards_train/margins': '6.3125', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22278', 'examples_per_second': '4.9375', 'grad_norm': '4.7188', 'counters/examples': 289472, 'counters/updates': 18092}
skipping logging after 289488 examples to avoid logging too frequently
skipping logging after 289504 examples to avoid logging too frequently
skipping logging after 289520 examples to avoid logging too frequently
train stats after 289536 examples: {'rewards_train/chosen': '0.17206', 'rewards_train/rejected': '-6.2831', 'rewards_train/margins': '6.3906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24652', 'examples_per_second': '7.0626', 'grad_norm': '4.75', 'counters/examples': 289536, 'counters/updates': 18096}
skipping logging after 289552 examples to avoid logging too frequently
skipping logging after 289568 examples to avoid logging too frequently
skipping logging after 289584 examples to avoid logging too frequently
train stats after 289600 examples: {'rewards_train/chosen': '-0.14838', 'rewards_train/rejected': '-8.1279', 'rewards_train/margins': '7.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26825', 'examples_per_second': '4.5307', 'grad_norm': '5.75', 'counters/examples': 289600, 'counters/updates': 18100}
skipping logging after 289616 examples to avoid logging too frequently
skipping logging after 289632 examples to avoid logging too frequently
skipping logging after 289648 examples to avoid logging too frequently
train stats after 289664 examples: {'rewards_train/chosen': '0.21931', 'rewards_train/rejected': '-5.5795', 'rewards_train/margins': '5.8516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23639', 'examples_per_second': '5.8397', 'grad_norm': '4.6875', 'counters/examples': 289664, 'counters/updates': 18104}
skipping logging after 289680 examples to avoid logging too frequently
skipping logging after 289696 examples to avoid logging too frequently
skipping logging after 289712 examples to avoid logging too frequently
train stats after 289728 examples: {'rewards_train/chosen': '0.53045', 'rewards_train/rejected': '-6.1681', 'rewards_train/margins': '6.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2392', 'examples_per_second': '5.1313', 'grad_norm': '4.9375', 'counters/examples': 289728, 'counters/updates': 18108}
skipping logging after 289744 examples to avoid logging too frequently
skipping logging after 289760 examples to avoid logging too frequently
skipping logging after 289776 examples to avoid logging too frequently
train stats after 289792 examples: {'rewards_train/chosen': '-0.22637', 'rewards_train/rejected': '-5.5766', 'rewards_train/margins': '5.1445', 'rewards_train/KL_estimate': '0', 'loss/train': '0.3158', 'examples_per_second': '5.6957', 'grad_norm': '6', 'counters/examples': 289792, 'counters/updates': 18112}
skipping logging after 289808 examples to avoid logging too frequently
skipping logging after 289824 examples to avoid logging too frequently
skipping logging after 289840 examples to avoid logging too frequently
train stats after 289856 examples: {'rewards_train/chosen': '0.23649', 'rewards_train/rejected': '-5.7151', 'rewards_train/margins': '5.8711', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25305', 'examples_per_second': '5.7257', 'grad_norm': '5.0625', 'counters/examples': 289856, 'counters/updates': 18116}
skipping logging after 289872 examples to avoid logging too frequently
skipping logging after 289888 examples to avoid logging too frequently
skipping logging after 289904 examples to avoid logging too frequently
train stats after 289920 examples: {'rewards_train/chosen': '0.5674', 'rewards_train/rejected': '-5.2543', 'rewards_train/margins': '5.7891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23126', 'examples_per_second': '5.33', 'grad_norm': '5.8438', 'counters/examples': 289920, 'counters/updates': 18120}
skipping logging after 289936 examples to avoid logging too frequently
skipping logging after 289952 examples to avoid logging too frequently
skipping logging after 289968 examples to avoid logging too frequently
train stats after 289984 examples: {'rewards_train/chosen': '-0.010711', 'rewards_train/rejected': '-5.2756', 'rewards_train/margins': '5.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23773', 'examples_per_second': '5.0465', 'grad_norm': '4.6875', 'counters/examples': 289984, 'counters/updates': 18124}
skipping logging after 290000 examples to avoid logging too frequently
skipping logging after 290016 examples to avoid logging too frequently
skipping logging after 290032 examples to avoid logging too frequently
train stats after 290048 examples: {'rewards_train/chosen': '0.4683', 'rewards_train/rejected': '-7.5786', 'rewards_train/margins': '8.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24054', 'examples_per_second': '5.1419', 'grad_norm': '5.375', 'counters/examples': 290048, 'counters/updates': 18128}
skipping logging after 290064 examples to avoid logging too frequently
skipping logging after 290080 examples to avoid logging too frequently
skipping logging after 290096 examples to avoid logging too frequently
train stats after 290112 examples: {'rewards_train/chosen': '-0.086005', 'rewards_train/rejected': '-4.1221', 'rewards_train/margins': '4.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.3006', 'examples_per_second': '6.6381', 'grad_norm': '5.7812', 'counters/examples': 290112, 'counters/updates': 18132}
skipping logging after 290128 examples to avoid logging too frequently
skipping logging after 290144 examples to avoid logging too frequently
skipping logging after 290160 examples to avoid logging too frequently
train stats after 290176 examples: {'rewards_train/chosen': '0.29289', 'rewards_train/rejected': '-5.9658', 'rewards_train/margins': '6.3516', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24249', 'examples_per_second': '5.0491', 'grad_norm': '5.6875', 'counters/examples': 290176, 'counters/updates': 18136}
skipping logging after 290192 examples to avoid logging too frequently
skipping logging after 290208 examples to avoid logging too frequently
skipping logging after 290224 examples to avoid logging too frequently
train stats after 290240 examples: {'rewards_train/chosen': '0.14616', 'rewards_train/rejected': '-6.2179', 'rewards_train/margins': '6.3359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25366', 'examples_per_second': '4.494', 'grad_norm': '5.6875', 'counters/examples': 290240, 'counters/updates': 18140}
skipping logging after 290256 examples to avoid logging too frequently
skipping logging after 290272 examples to avoid logging too frequently
skipping logging after 290288 examples to avoid logging too frequently
train stats after 290304 examples: {'rewards_train/chosen': '0.21216', 'rewards_train/rejected': '-5.9401', 'rewards_train/margins': '6.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19641', 'examples_per_second': '5.8662', 'grad_norm': '4.2812', 'counters/examples': 290304, 'counters/updates': 18144}
skipping logging after 290320 examples to avoid logging too frequently
skipping logging after 290336 examples to avoid logging too frequently
skipping logging after 290352 examples to avoid logging too frequently
train stats after 290368 examples: {'rewards_train/chosen': '0.30653', 'rewards_train/rejected': '-6.7615', 'rewards_train/margins': '6.8047', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24786', 'examples_per_second': '4.8793', 'grad_norm': '4.875', 'counters/examples': 290368, 'counters/updates': 18148}
skipping logging after 290384 examples to avoid logging too frequently
skipping logging after 290400 examples to avoid logging too frequently
skipping logging after 290416 examples to avoid logging too frequently
train stats after 290432 examples: {'rewards_train/chosen': '-0.072294', 'rewards_train/rejected': '-6.1661', 'rewards_train/margins': '6.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.29834', 'examples_per_second': '4.5881', 'grad_norm': '5', 'counters/examples': 290432, 'counters/updates': 18152}
skipping logging after 290448 examples to avoid logging too frequently
skipping logging after 290464 examples to avoid logging too frequently
skipping logging after 290480 examples to avoid logging too frequently
train stats after 290496 examples: {'rewards_train/chosen': '-0.029342', 'rewards_train/rejected': '-5.3643', 'rewards_train/margins': '5.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28119', 'examples_per_second': '6.0422', 'grad_norm': '5.5', 'counters/examples': 290496, 'counters/updates': 18156}
skipping logging after 290512 examples to avoid logging too frequently
skipping logging after 290528 examples to avoid logging too frequently
skipping logging after 290544 examples to avoid logging too frequently
train stats after 290560 examples: {'rewards_train/chosen': '0.14954', 'rewards_train/rejected': '-5.1507', 'rewards_train/margins': '5.6094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2934', 'examples_per_second': '5.6681', 'grad_norm': '5.9062', 'counters/examples': 290560, 'counters/updates': 18160}
skipping logging after 290576 examples to avoid logging too frequently
skipping logging after 290592 examples to avoid logging too frequently
skipping logging after 290608 examples to avoid logging too frequently
train stats after 290624 examples: {'rewards_train/chosen': '0.38219', 'rewards_train/rejected': '-6.9814', 'rewards_train/margins': '7.5391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21771', 'examples_per_second': '4.1831', 'grad_norm': '4.3438', 'counters/examples': 290624, 'counters/updates': 18164}
skipping logging after 290640 examples to avoid logging too frequently
skipping logging after 290656 examples to avoid logging too frequently
skipping logging after 290672 examples to avoid logging too frequently
train stats after 290688 examples: {'rewards_train/chosen': '0.3745', 'rewards_train/rejected': '-5.1119', 'rewards_train/margins': '5.6797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24231', 'examples_per_second': '5.9652', 'grad_norm': '4.8125', 'counters/examples': 290688, 'counters/updates': 18168}
skipping logging after 290704 examples to avoid logging too frequently
skipping logging after 290720 examples to avoid logging too frequently
skipping logging after 290736 examples to avoid logging too frequently
train stats after 290752 examples: {'rewards_train/chosen': '0.47514', 'rewards_train/rejected': '-6.6925', 'rewards_train/margins': '7.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19855', 'examples_per_second': '5.5891', 'grad_norm': '4.9688', 'counters/examples': 290752, 'counters/updates': 18172}
skipping logging after 290768 examples to avoid logging too frequently
skipping logging after 290784 examples to avoid logging too frequently
skipping logging after 290800 examples to avoid logging too frequently
train stats after 290816 examples: {'rewards_train/chosen': '0.50163', 'rewards_train/rejected': '-6.8918', 'rewards_train/margins': '7.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23132', 'examples_per_second': '5.2422', 'grad_norm': '4.9688', 'counters/examples': 290816, 'counters/updates': 18176}
skipping logging after 290832 examples to avoid logging too frequently
skipping logging after 290848 examples to avoid logging too frequently
skipping logging after 290864 examples to avoid logging too frequently
train stats after 290880 examples: {'rewards_train/chosen': '0.49908', 'rewards_train/rejected': '-5.6409', 'rewards_train/margins': '5.8945', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25507', 'examples_per_second': '5.6105', 'grad_norm': '5.9375', 'counters/examples': 290880, 'counters/updates': 18180}
skipping logging after 290896 examples to avoid logging too frequently
skipping logging after 290912 examples to avoid logging too frequently
skipping logging after 290928 examples to avoid logging too frequently
train stats after 290944 examples: {'rewards_train/chosen': '0.1558', 'rewards_train/rejected': '-6.2997', 'rewards_train/margins': '6.5234', 'rewards_train/KL_estimate': '0', 'loss/train': '0.255', 'examples_per_second': '4.1037', 'grad_norm': '5.4688', 'counters/examples': 290944, 'counters/updates': 18184}
skipping logging after 290960 examples to avoid logging too frequently
skipping logging after 290976 examples to avoid logging too frequently
skipping logging after 290992 examples to avoid logging too frequently
train stats after 291008 examples: {'rewards_train/chosen': '0.19527', 'rewards_train/rejected': '-6.2728', 'rewards_train/margins': '6.6484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27362', 'examples_per_second': '5.4843', 'grad_norm': '5.6562', 'counters/examples': 291008, 'counters/updates': 18188}
skipping logging after 291024 examples to avoid logging too frequently
skipping logging after 291040 examples to avoid logging too frequently
skipping logging after 291056 examples to avoid logging too frequently
train stats after 291072 examples: {'rewards_train/chosen': '-0.026035', 'rewards_train/rejected': '-5.9658', 'rewards_train/margins': '5.9531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25189', 'examples_per_second': '5.8546', 'grad_norm': '5.4062', 'counters/examples': 291072, 'counters/updates': 18192}
skipping logging after 291088 examples to avoid logging too frequently
skipping logging after 291104 examples to avoid logging too frequently
skipping logging after 291120 examples to avoid logging too frequently
train stats after 291136 examples: {'rewards_train/chosen': '0.17917', 'rewards_train/rejected': '-4.7376', 'rewards_train/margins': '5.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2533', 'examples_per_second': '4.8624', 'grad_norm': '4.9062', 'counters/examples': 291136, 'counters/updates': 18196}
skipping logging after 291152 examples to avoid logging too frequently
skipping logging after 291168 examples to avoid logging too frequently
skipping logging after 291184 examples to avoid logging too frequently
train stats after 291200 examples: {'rewards_train/chosen': '0.046556', 'rewards_train/rejected': '-4.88', 'rewards_train/margins': '5.0586', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26837', 'examples_per_second': '5.0159', 'grad_norm': '6.0625', 'counters/examples': 291200, 'counters/updates': 18200}
skipping logging after 291216 examples to avoid logging too frequently
skipping logging after 291232 examples to avoid logging too frequently
skipping logging after 291248 examples to avoid logging too frequently
train stats after 291264 examples: {'rewards_train/chosen': '0.44749', 'rewards_train/rejected': '-6.9423', 'rewards_train/margins': '7.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24176', 'examples_per_second': '4.8331', 'grad_norm': '5.1875', 'counters/examples': 291264, 'counters/updates': 18204}
skipping logging after 291280 examples to avoid logging too frequently
skipping logging after 291296 examples to avoid logging too frequently
skipping logging after 291312 examples to avoid logging too frequently
train stats after 291328 examples: {'rewards_train/chosen': '-0.10859', 'rewards_train/rejected': '-5.3635', 'rewards_train/margins': '5.2832', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2373', 'examples_per_second': '4.3547', 'grad_norm': '4.5938', 'counters/examples': 291328, 'counters/updates': 18208}
skipping logging after 291344 examples to avoid logging too frequently
skipping logging after 291360 examples to avoid logging too frequently
skipping logging after 291376 examples to avoid logging too frequently
train stats after 291392 examples: {'rewards_train/chosen': '0.29202', 'rewards_train/rejected': '-5.7143', 'rewards_train/margins': '5.8906', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25787', 'examples_per_second': '4.917', 'grad_norm': '5.1562', 'counters/examples': 291392, 'counters/updates': 18212}
skipping logging after 291408 examples to avoid logging too frequently
skipping logging after 291424 examples to avoid logging too frequently
skipping logging after 291440 examples to avoid logging too frequently
train stats after 291456 examples: {'rewards_train/chosen': '0.49162', 'rewards_train/rejected': '-6.3026', 'rewards_train/margins': '6.8359', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20422', 'examples_per_second': '4.6391', 'grad_norm': '4.5312', 'counters/examples': 291456, 'counters/updates': 18216}
skipping logging after 291472 examples to avoid logging too frequently
skipping logging after 291488 examples to avoid logging too frequently
skipping logging after 291504 examples to avoid logging too frequently
train stats after 291520 examples: {'rewards_train/chosen': '0.59624', 'rewards_train/rejected': '-6.7479', 'rewards_train/margins': '7.2656', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20953', 'examples_per_second': '4.4885', 'grad_norm': '5.1875', 'counters/examples': 291520, 'counters/updates': 18220}
skipping logging after 291536 examples to avoid logging too frequently
skipping logging after 291552 examples to avoid logging too frequently
skipping logging after 291568 examples to avoid logging too frequently
train stats after 291584 examples: {'rewards_train/chosen': '0.087386', 'rewards_train/rejected': '-6.9743', 'rewards_train/margins': '6.7578', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24683', 'examples_per_second': '5.7427', 'grad_norm': '5.0312', 'counters/examples': 291584, 'counters/updates': 18224}
skipping logging after 291600 examples to avoid logging too frequently
skipping logging after 291616 examples to avoid logging too frequently
skipping logging after 291632 examples to avoid logging too frequently
train stats after 291648 examples: {'rewards_train/chosen': '0.51587', 'rewards_train/rejected': '-7.6693', 'rewards_train/margins': '8.1328', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24548', 'examples_per_second': '4.4347', 'grad_norm': '5.2812', 'counters/examples': 291648, 'counters/updates': 18228}
skipping logging after 291664 examples to avoid logging too frequently
skipping logging after 291680 examples to avoid logging too frequently
skipping logging after 291696 examples to avoid logging too frequently
train stats after 291712 examples: {'rewards_train/chosen': '0.28739', 'rewards_train/rejected': '-6.9413', 'rewards_train/margins': '7.3594', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21503', 'examples_per_second': '6.0742', 'grad_norm': '4.5', 'counters/examples': 291712, 'counters/updates': 18232}
skipping logging after 291728 examples to avoid logging too frequently
skipping logging after 291744 examples to avoid logging too frequently
skipping logging after 291760 examples to avoid logging too frequently
train stats after 291776 examples: {'rewards_train/chosen': '0.33861', 'rewards_train/rejected': '-5.7911', 'rewards_train/margins': '6.0703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23462', 'examples_per_second': '4.5691', 'grad_norm': '5.5', 'counters/examples': 291776, 'counters/updates': 18236}
skipping logging after 291792 examples to avoid logging too frequently
skipping logging after 291808 examples to avoid logging too frequently
skipping logging after 291824 examples to avoid logging too frequently
train stats after 291840 examples: {'rewards_train/chosen': '0.4384', 'rewards_train/rejected': '-6.5434', 'rewards_train/margins': '7.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23248', 'examples_per_second': '4.7919', 'grad_norm': '4', 'counters/examples': 291840, 'counters/updates': 18240}
skipping logging after 291856 examples to avoid logging too frequently
skipping logging after 291872 examples to avoid logging too frequently
skipping logging after 291888 examples to avoid logging too frequently
train stats after 291904 examples: {'rewards_train/chosen': '0.39075', 'rewards_train/rejected': '-5.0937', 'rewards_train/margins': '5.5156', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26068', 'examples_per_second': '5.6383', 'grad_norm': '5.5938', 'counters/examples': 291904, 'counters/updates': 18244}
skipping logging after 291920 examples to avoid logging too frequently
skipping logging after 291936 examples to avoid logging too frequently
skipping logging after 291952 examples to avoid logging too frequently
train stats after 291968 examples: {'rewards_train/chosen': '0.68991', 'rewards_train/rejected': '-5.694', 'rewards_train/margins': '6.3828', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21735', 'examples_per_second': '4.5732', 'grad_norm': '5', 'counters/examples': 291968, 'counters/updates': 18248}
skipping logging after 291984 examples to avoid logging too frequently
skipping logging after 292000 examples to avoid logging too frequently
Running evaluation after 292000 train examples
Computing eval metrics:   0%|          | 0/32 [00:00<?, ?it/s]Computing eval metrics:   3%|▎         | 1/32 [00:01<00:49,  1.59s/it]Computing eval metrics:   6%|▋         | 2/32 [00:02<00:41,  1.39s/it]Computing eval metrics:   9%|▉         | 3/32 [00:03<00:36,  1.24s/it]Computing eval metrics:  12%|█▎        | 4/32 [00:05<00:41,  1.47s/it]Computing eval metrics:  16%|█▌        | 5/32 [00:07<00:45,  1.68s/it]Computing eval metrics:  19%|█▉        | 6/32 [00:08<00:38,  1.49s/it]Computing eval metrics:  22%|██▏       | 7/32 [00:10<00:34,  1.37s/it]Computing eval metrics:  25%|██▌       | 8/32 [00:11<00:36,  1.52s/it]Computing eval metrics:  28%|██▊       | 9/32 [00:13<00:34,  1.48s/it]Computing eval metrics:  31%|███▏      | 10/32 [00:14<00:30,  1.41s/it]Computing eval metrics:  34%|███▍      | 11/32 [00:16<00:30,  1.48s/it]Computing eval metrics:  38%|███▊      | 12/32 [00:17<00:28,  1.40s/it]Computing eval metrics:  41%|████      | 13/32 [00:18<00:26,  1.38s/it]Computing eval metrics:  44%|████▍     | 14/32 [00:19<00:24,  1.34s/it]Computing eval metrics:  47%|████▋     | 15/32 [00:20<00:20,  1.22s/it]Computing eval metrics:  50%|█████     | 16/32 [00:22<00:20,  1.27s/it]Computing eval metrics:  53%|█████▎    | 17/32 [00:23<00:18,  1.25s/it]Computing eval metrics:  56%|█████▋    | 18/32 [00:24<00:17,  1.24s/it]Computing eval metrics:  59%|█████▉    | 19/32 [00:25<00:14,  1.14s/it]Computing eval metrics:  62%|██████▎   | 20/32 [00:26<00:13,  1.15s/it]Computing eval metrics:  66%|██████▌   | 21/32 [00:27<00:12,  1.15s/it]Computing eval metrics:  69%|██████▉   | 22/32 [00:29<00:11,  1.18s/it]Computing eval metrics:  72%|███████▏  | 23/32 [00:31<00:13,  1.45s/it]Computing eval metrics:  75%|███████▌  | 24/32 [00:32<00:12,  1.50s/it]Computing eval metrics:  78%|███████▊  | 25/32 [00:33<00:09,  1.36s/it]Computing eval metrics:  81%|████████▏ | 26/32 [00:35<00:08,  1.41s/it]Computing eval metrics:  84%|████████▍ | 27/32 [00:36<00:06,  1.31s/it]Computing eval metrics:  88%|████████▊ | 28/32 [00:37<00:05,  1.31s/it]Computing eval metrics:  91%|█████████ | 29/32 [00:38<00:03,  1.19s/it]Computing eval metrics:  94%|█████████▍| 30/32 [00:39<00:02,  1.18s/it]Computing eval metrics:  97%|█████████▋| 31/32 [00:40<00:01,  1.16s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.12s/it]Computing eval metrics: 100%|██████████| 32/32 [00:42<00:00,  1.31s/it]
eval after 292000: {'rewards_eval/chosen': '-6.7529', 'rewards_eval/rejected': '-7.4179', 'rewards_eval/margins': '0.46875', 'rewards_eval/KL_estimate': '0', 'loss/eval': '0.45577'}
skipping logging after 292016 examples to avoid logging too frequently
train stats after 292032 examples: {'rewards_train/chosen': '0.15565', 'rewards_train/rejected': '-7.0132', 'rewards_train/margins': '7.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24225', 'examples_per_second': '5.9616', 'grad_norm': '5.5', 'counters/examples': 292032, 'counters/updates': 18252}
skipping logging after 292048 examples to avoid logging too frequently
skipping logging after 292064 examples to avoid logging too frequently
skipping logging after 292080 examples to avoid logging too frequently
train stats after 292096 examples: {'rewards_train/chosen': '0.11817', 'rewards_train/rejected': '-7.9744', 'rewards_train/margins': '7.7891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26086', 'examples_per_second': '5.2467', 'grad_norm': '6.25', 'counters/examples': 292096, 'counters/updates': 18256}
skipping logging after 292112 examples to avoid logging too frequently
skipping logging after 292128 examples to avoid logging too frequently
skipping logging after 292144 examples to avoid logging too frequently
train stats after 292160 examples: {'rewards_train/chosen': '0.14583', 'rewards_train/rejected': '-5.6129', 'rewards_train/margins': '5.3438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.32562', 'examples_per_second': '6.0016', 'grad_norm': '5.4375', 'counters/examples': 292160, 'counters/updates': 18260}
skipping logging after 292176 examples to avoid logging too frequently
skipping logging after 292192 examples to avoid logging too frequently
skipping logging after 292208 examples to avoid logging too frequently
train stats after 292224 examples: {'rewards_train/chosen': '0.66653', 'rewards_train/rejected': '-5.5345', 'rewards_train/margins': '6.2188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20386', 'examples_per_second': '6.2472', 'grad_norm': '5.0625', 'counters/examples': 292224, 'counters/updates': 18264}
skipping logging after 292240 examples to avoid logging too frequently
skipping logging after 292256 examples to avoid logging too frequently
skipping logging after 292272 examples to avoid logging too frequently
train stats after 292288 examples: {'rewards_train/chosen': '0.23399', 'rewards_train/rejected': '-6.6747', 'rewards_train/margins': '6.8438', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2345', 'examples_per_second': '7.2882', 'grad_norm': '5.625', 'counters/examples': 292288, 'counters/updates': 18268}
skipping logging after 292304 examples to avoid logging too frequently
skipping logging after 292320 examples to avoid logging too frequently
skipping logging after 292336 examples to avoid logging too frequently
train stats after 292352 examples: {'rewards_train/chosen': '0.32289', 'rewards_train/rejected': '-7.7037', 'rewards_train/margins': '8.2266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.17712', 'examples_per_second': '5.5674', 'grad_norm': '4.5', 'counters/examples': 292352, 'counters/updates': 18272}
skipping logging after 292368 examples to avoid logging too frequently
skipping logging after 292384 examples to avoid logging too frequently
skipping logging after 292400 examples to avoid logging too frequently
train stats after 292416 examples: {'rewards_train/chosen': '0.069121', 'rewards_train/rejected': '-6.2873', 'rewards_train/margins': '6.4531', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28754', 'examples_per_second': '5.9181', 'grad_norm': '7.0312', 'counters/examples': 292416, 'counters/updates': 18276}
skipping logging after 292432 examples to avoid logging too frequently
skipping logging after 292448 examples to avoid logging too frequently
skipping logging after 292464 examples to avoid logging too frequently
train stats after 292480 examples: {'rewards_train/chosen': '0.28057', 'rewards_train/rejected': '-6.0879', 'rewards_train/margins': '6.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2149', 'examples_per_second': '5.0858', 'grad_norm': '4.6562', 'counters/examples': 292480, 'counters/updates': 18280}
skipping logging after 292496 examples to avoid logging too frequently
skipping logging after 292512 examples to avoid logging too frequently
skipping logging after 292528 examples to avoid logging too frequently
train stats after 292544 examples: {'rewards_train/chosen': '0.23682', 'rewards_train/rejected': '-6.1182', 'rewards_train/margins': '6.6875', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23248', 'examples_per_second': '4.3159', 'grad_norm': '5.25', 'counters/examples': 292544, 'counters/updates': 18284}
skipping logging after 292560 examples to avoid logging too frequently
skipping logging after 292576 examples to avoid logging too frequently
skipping logging after 292592 examples to avoid logging too frequently
train stats after 292608 examples: {'rewards_train/chosen': '0.43103', 'rewards_train/rejected': '-7.4296', 'rewards_train/margins': '7.7812', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23096', 'examples_per_second': '5.146', 'grad_norm': '4.3438', 'counters/examples': 292608, 'counters/updates': 18288}
skipping logging after 292624 examples to avoid logging too frequently
skipping logging after 292640 examples to avoid logging too frequently
skipping logging after 292656 examples to avoid logging too frequently
train stats after 292672 examples: {'rewards_train/chosen': '0.4708', 'rewards_train/rejected': '-6.7642', 'rewards_train/margins': '7.1172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25891', 'examples_per_second': '4.5506', 'grad_norm': '5.6562', 'counters/examples': 292672, 'counters/updates': 18292}
skipping logging after 292688 examples to avoid logging too frequently
skipping logging after 292704 examples to avoid logging too frequently
skipping logging after 292720 examples to avoid logging too frequently
train stats after 292736 examples: {'rewards_train/chosen': '-0.0060938', 'rewards_train/rejected': '-6.598', 'rewards_train/margins': '6.6641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20844', 'examples_per_second': '4.9109', 'grad_norm': '4.4062', 'counters/examples': 292736, 'counters/updates': 18296}
skipping logging after 292752 examples to avoid logging too frequently
skipping logging after 292768 examples to avoid logging too frequently
skipping logging after 292784 examples to avoid logging too frequently
train stats after 292800 examples: {'rewards_train/chosen': '0.2514', 'rewards_train/rejected': '-6.3774', 'rewards_train/margins': '6.6406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2511', 'examples_per_second': '4.4588', 'grad_norm': '4.3125', 'counters/examples': 292800, 'counters/updates': 18300}
skipping logging after 292816 examples to avoid logging too frequently
skipping logging after 292832 examples to avoid logging too frequently
skipping logging after 292848 examples to avoid logging too frequently
train stats after 292864 examples: {'rewards_train/chosen': '0.19255', 'rewards_train/rejected': '-6.4929', 'rewards_train/margins': '6.7266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25562', 'examples_per_second': '5.8334', 'grad_norm': '4.8125', 'counters/examples': 292864, 'counters/updates': 18304}
skipping logging after 292880 examples to avoid logging too frequently
skipping logging after 292896 examples to avoid logging too frequently
skipping logging after 292912 examples to avoid logging too frequently
train stats after 292928 examples: {'rewards_train/chosen': '0.49889', 'rewards_train/rejected': '-5.7559', 'rewards_train/margins': '6.4141', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23639', 'examples_per_second': '4.9659', 'grad_norm': '5.5938', 'counters/examples': 292928, 'counters/updates': 18308}
skipping logging after 292944 examples to avoid logging too frequently
skipping logging after 292960 examples to avoid logging too frequently
skipping logging after 292976 examples to avoid logging too frequently
train stats after 292992 examples: {'rewards_train/chosen': '0.55246', 'rewards_train/rejected': '-7.1819', 'rewards_train/margins': '7.5703', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21344', 'examples_per_second': '5.1128', 'grad_norm': '4.5', 'counters/examples': 292992, 'counters/updates': 18312}
skipping logging after 293008 examples to avoid logging too frequently
skipping logging after 293024 examples to avoid logging too frequently
skipping logging after 293040 examples to avoid logging too frequently
train stats after 293056 examples: {'rewards_train/chosen': '0.086421', 'rewards_train/rejected': '-6.419', 'rewards_train/margins': '6.625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26129', 'examples_per_second': '4.9843', 'grad_norm': '5.3438', 'counters/examples': 293056, 'counters/updates': 18316}
skipping logging after 293072 examples to avoid logging too frequently
skipping logging after 293088 examples to avoid logging too frequently
skipping logging after 293104 examples to avoid logging too frequently
train stats after 293120 examples: {'rewards_train/chosen': '0.076217', 'rewards_train/rejected': '-6.4211', 'rewards_train/margins': '6.4922', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27838', 'examples_per_second': '5.3651', 'grad_norm': '5.2812', 'counters/examples': 293120, 'counters/updates': 18320}
skipping logging after 293136 examples to avoid logging too frequently
skipping logging after 293152 examples to avoid logging too frequently
skipping logging after 293168 examples to avoid logging too frequently
train stats after 293184 examples: {'rewards_train/chosen': '0.16629', 'rewards_train/rejected': '-6.7067', 'rewards_train/margins': '6.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24689', 'examples_per_second': '4.7956', 'grad_norm': '6.5625', 'counters/examples': 293184, 'counters/updates': 18324}
skipping logging after 293200 examples to avoid logging too frequently
skipping logging after 293216 examples to avoid logging too frequently
skipping logging after 293232 examples to avoid logging too frequently
train stats after 293248 examples: {'rewards_train/chosen': '0.089124', 'rewards_train/rejected': '-6.8299', 'rewards_train/margins': '6.7969', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25153', 'examples_per_second': '5.3273', 'grad_norm': '4.5938', 'counters/examples': 293248, 'counters/updates': 18328}
skipping logging after 293264 examples to avoid logging too frequently
skipping logging after 293280 examples to avoid logging too frequently
skipping logging after 293296 examples to avoid logging too frequently
train stats after 293312 examples: {'rewards_train/chosen': '0.21673', 'rewards_train/rejected': '-6.5518', 'rewards_train/margins': '7.0469', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23352', 'examples_per_second': '5.2605', 'grad_norm': '5.1562', 'counters/examples': 293312, 'counters/updates': 18332}
skipping logging after 293328 examples to avoid logging too frequently
skipping logging after 293344 examples to avoid logging too frequently
skipping logging after 293360 examples to avoid logging too frequently
train stats after 293376 examples: {'rewards_train/chosen': '0.27469', 'rewards_train/rejected': '-6.0327', 'rewards_train/margins': '7.375', 'rewards_train/KL_estimate': '0', 'loss/train': '0.23987', 'examples_per_second': '6.3826', 'grad_norm': '6.9688', 'counters/examples': 293376, 'counters/updates': 18336}
skipping logging after 293392 examples to avoid logging too frequently
skipping logging after 293408 examples to avoid logging too frequently
skipping logging after 293424 examples to avoid logging too frequently
train stats after 293440 examples: {'rewards_train/chosen': '0.031903', 'rewards_train/rejected': '-6.2782', 'rewards_train/margins': '6.1641', 'rewards_train/KL_estimate': '0', 'loss/train': '0.30768', 'examples_per_second': '4.2975', 'grad_norm': '6.6875', 'counters/examples': 293440, 'counters/updates': 18340}
skipping logging after 293456 examples to avoid logging too frequently
skipping logging after 293472 examples to avoid logging too frequently
skipping logging after 293488 examples to avoid logging too frequently
train stats after 293504 examples: {'rewards_train/chosen': '0.3355', 'rewards_train/rejected': '-6.411', 'rewards_train/margins': '6.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25336', 'examples_per_second': '3.9597', 'grad_norm': '6.0312', 'counters/examples': 293504, 'counters/updates': 18344}
skipping logging after 293520 examples to avoid logging too frequently
skipping logging after 293536 examples to avoid logging too frequently
skipping logging after 293552 examples to avoid logging too frequently
train stats after 293568 examples: {'rewards_train/chosen': '0.46262', 'rewards_train/rejected': '-5.3868', 'rewards_train/margins': '5.5938', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22235', 'examples_per_second': '4.7322', 'grad_norm': '6.0625', 'counters/examples': 293568, 'counters/updates': 18348}
skipping logging after 293584 examples to avoid logging too frequently
skipping logging after 293600 examples to avoid logging too frequently
skipping logging after 293616 examples to avoid logging too frequently
train stats after 293632 examples: {'rewards_train/chosen': '0.17327', 'rewards_train/rejected': '-5.0128', 'rewards_train/margins': '5.1094', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25201', 'examples_per_second': '7.0039', 'grad_norm': '5.7188', 'counters/examples': 293632, 'counters/updates': 18352}
skipping logging after 293648 examples to avoid logging too frequently
skipping logging after 293664 examples to avoid logging too frequently
skipping logging after 293680 examples to avoid logging too frequently
train stats after 293696 examples: {'rewards_train/chosen': '-0.01392', 'rewards_train/rejected': '-7.9664', 'rewards_train/margins': '7.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.33936', 'examples_per_second': '4.9232', 'grad_norm': '5.0625', 'counters/examples': 293696, 'counters/updates': 18356}
skipping logging after 293712 examples to avoid logging too frequently
skipping logging after 293728 examples to avoid logging too frequently
skipping logging after 293744 examples to avoid logging too frequently
train stats after 293760 examples: {'rewards_train/chosen': '0.29623', 'rewards_train/rejected': '-6.2287', 'rewards_train/margins': '6.4453', 'rewards_train/KL_estimate': '0', 'loss/train': '0.28198', 'examples_per_second': '5.4152', 'grad_norm': '5', 'counters/examples': 293760, 'counters/updates': 18360}
skipping logging after 293776 examples to avoid logging too frequently
skipping logging after 293792 examples to avoid logging too frequently
skipping logging after 293808 examples to avoid logging too frequently
train stats after 293824 examples: {'rewards_train/chosen': '0.69234', 'rewards_train/rejected': '-5.6283', 'rewards_train/margins': '6.2891', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21173', 'examples_per_second': '5.712', 'grad_norm': '4.375', 'counters/examples': 293824, 'counters/updates': 18364}
skipping logging after 293840 examples to avoid logging too frequently
skipping logging after 293856 examples to avoid logging too frequently
skipping logging after 293872 examples to avoid logging too frequently
train stats after 293888 examples: {'rewards_train/chosen': '0.39849', 'rewards_train/rejected': '-5.7203', 'rewards_train/margins': '6.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22443', 'examples_per_second': '5.4208', 'grad_norm': '5.0938', 'counters/examples': 293888, 'counters/updates': 18368}
skipping logging after 293904 examples to avoid logging too frequently
skipping logging after 293920 examples to avoid logging too frequently
skipping logging after 293936 examples to avoid logging too frequently
train stats after 293952 examples: {'rewards_train/chosen': '0.10923', 'rewards_train/rejected': '-6.1597', 'rewards_train/margins': '6.4219', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24908', 'examples_per_second': '4.5684', 'grad_norm': '5.9375', 'counters/examples': 293952, 'counters/updates': 18372}
skipping logging after 293968 examples to avoid logging too frequently
skipping logging after 293984 examples to avoid logging too frequently
skipping logging after 294000 examples to avoid logging too frequently
train stats after 294016 examples: {'rewards_train/chosen': '0.33898', 'rewards_train/rejected': '-7.4685', 'rewards_train/margins': '7.4688', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20087', 'examples_per_second': '4.0321', 'grad_norm': '4.9688', 'counters/examples': 294016, 'counters/updates': 18376}
skipping logging after 294032 examples to avoid logging too frequently
skipping logging after 294048 examples to avoid logging too frequently
skipping logging after 294064 examples to avoid logging too frequently
train stats after 294080 examples: {'rewards_train/chosen': '0.013307', 'rewards_train/rejected': '-7.2787', 'rewards_train/margins': '7.2344', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24677', 'examples_per_second': '4.8057', 'grad_norm': '5.1562', 'counters/examples': 294080, 'counters/updates': 18380}
skipping logging after 294096 examples to avoid logging too frequently
skipping logging after 294112 examples to avoid logging too frequently
skipping logging after 294128 examples to avoid logging too frequently
train stats after 294144 examples: {'rewards_train/chosen': '0.052091', 'rewards_train/rejected': '-5.9065', 'rewards_train/margins': '5.8203', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22766', 'examples_per_second': '5.6886', 'grad_norm': '5.5938', 'counters/examples': 294144, 'counters/updates': 18384}
skipping logging after 294160 examples to avoid logging too frequently
skipping logging after 294176 examples to avoid logging too frequently
skipping logging after 294192 examples to avoid logging too frequently
train stats after 294208 examples: {'rewards_train/chosen': '0.34836', 'rewards_train/rejected': '-7.6241', 'rewards_train/margins': '8.1484', 'rewards_train/KL_estimate': '0', 'loss/train': '0.19299', 'examples_per_second': '4.9904', 'grad_norm': '4.5312', 'counters/examples': 294208, 'counters/updates': 18388}
skipping logging after 294224 examples to avoid logging too frequently
skipping logging after 294240 examples to avoid logging too frequently
skipping logging after 294256 examples to avoid logging too frequently
train stats after 294272 examples: {'rewards_train/chosen': '-0.026035', 'rewards_train/rejected': '-6.7858', 'rewards_train/margins': '6.9414', 'rewards_train/KL_estimate': '0', 'loss/train': '0.33234', 'examples_per_second': '5.3434', 'grad_norm': '6.8438', 'counters/examples': 294272, 'counters/updates': 18392}
skipping logging after 294288 examples to avoid logging too frequently
skipping logging after 294304 examples to avoid logging too frequently
skipping logging after 294320 examples to avoid logging too frequently
train stats after 294336 examples: {'rewards_train/chosen': '0.29593', 'rewards_train/rejected': '-5.4279', 'rewards_train/margins': '5.7188', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22357', 'examples_per_second': '4.7301', 'grad_norm': '4.875', 'counters/examples': 294336, 'counters/updates': 18396}
skipping logging after 294352 examples to avoid logging too frequently
skipping logging after 294368 examples to avoid logging too frequently
skipping logging after 294384 examples to avoid logging too frequently
train stats after 294400 examples: {'rewards_train/chosen': '-0.00098581', 'rewards_train/rejected': '-7.5629', 'rewards_train/margins': '7.4766', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26581', 'examples_per_second': '4.278', 'grad_norm': '4.1875', 'counters/examples': 294400, 'counters/updates': 18400}
skipping logging after 294416 examples to avoid logging too frequently
skipping logging after 294432 examples to avoid logging too frequently
skipping logging after 294448 examples to avoid logging too frequently
train stats after 294464 examples: {'rewards_train/chosen': '0.37998', 'rewards_train/rejected': '-5.3146', 'rewards_train/margins': '5.6172', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25122', 'examples_per_second': '5.7735', 'grad_norm': '5', 'counters/examples': 294464, 'counters/updates': 18404}
skipping logging after 294480 examples to avoid logging too frequently
skipping logging after 294496 examples to avoid logging too frequently
skipping logging after 294512 examples to avoid logging too frequently
train stats after 294528 examples: {'rewards_train/chosen': '-0.14404', 'rewards_train/rejected': '-5.2659', 'rewards_train/margins': '5.0781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25635', 'examples_per_second': '4.9904', 'grad_norm': '6.75', 'counters/examples': 294528, 'counters/updates': 18408}
skipping logging after 294544 examples to avoid logging too frequently
skipping logging after 294560 examples to avoid logging too frequently
skipping logging after 294576 examples to avoid logging too frequently
train stats after 294592 examples: {'rewards_train/chosen': '-0.26786', 'rewards_train/rejected': '-5.3787', 'rewards_train/margins': '5.1797', 'rewards_train/KL_estimate': '0', 'loss/train': '0.27527', 'examples_per_second': '5.5829', 'grad_norm': '4.9688', 'counters/examples': 294592, 'counters/updates': 18412}
skipping logging after 294608 examples to avoid logging too frequently
skipping logging after 294624 examples to avoid logging too frequently
skipping logging after 294640 examples to avoid logging too frequently
train stats after 294656 examples: {'rewards_train/chosen': '0.029905', 'rewards_train/rejected': '-7.7329', 'rewards_train/margins': '7.5078', 'rewards_train/KL_estimate': '0', 'loss/train': '0.20349', 'examples_per_second': '4.9204', 'grad_norm': '3.8281', 'counters/examples': 294656, 'counters/updates': 18416}
skipping logging after 294672 examples to avoid logging too frequently
skipping logging after 294688 examples to avoid logging too frequently
skipping logging after 294704 examples to avoid logging too frequently
train stats after 294720 examples: {'rewards_train/chosen': '0.42433', 'rewards_train/rejected': '-6.3123', 'rewards_train/margins': '6.7734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21924', 'examples_per_second': '5.5151', 'grad_norm': '5.2188', 'counters/examples': 294720, 'counters/updates': 18420}
skipping logging after 294736 examples to avoid logging too frequently
skipping logging after 294752 examples to avoid logging too frequently
skipping logging after 294768 examples to avoid logging too frequently
train stats after 294784 examples: {'rewards_train/chosen': '-0.089781', 'rewards_train/rejected': '-6.3306', 'rewards_train/margins': '6.2266', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25958', 'examples_per_second': '5.9808', 'grad_norm': '4.875', 'counters/examples': 294784, 'counters/updates': 18424}
skipping logging after 294800 examples to avoid logging too frequently
skipping logging after 294816 examples to avoid logging too frequently
skipping logging after 294832 examples to avoid logging too frequently
train stats after 294848 examples: {'rewards_train/chosen': '0.10995', 'rewards_train/rejected': '-6.005', 'rewards_train/margins': '6.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.25262', 'examples_per_second': '5.0883', 'grad_norm': '4.0312', 'counters/examples': 294848, 'counters/updates': 18428}
skipping logging after 294864 examples to avoid logging too frequently
skipping logging after 294880 examples to avoid logging too frequently
skipping logging after 294896 examples to avoid logging too frequently
train stats after 294912 examples: {'rewards_train/chosen': '0.26244', 'rewards_train/rejected': '-5.6802', 'rewards_train/margins': '5.5625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.31787', 'examples_per_second': '4.8878', 'grad_norm': '5.875', 'counters/examples': 294912, 'counters/updates': 18432}
skipping logging after 294928 examples to avoid logging too frequently
skipping logging after 294944 examples to avoid logging too frequently
skipping logging after 294960 examples to avoid logging too frequently
train stats after 294976 examples: {'rewards_train/chosen': '0.5273', 'rewards_train/rejected': '-5.3932', 'rewards_train/margins': '6.0625', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26477', 'examples_per_second': '4.424', 'grad_norm': '5.1562', 'counters/examples': 294976, 'counters/updates': 18436}
skipping logging after 294992 examples to avoid logging too frequently
skipping logging after 295008 examples to avoid logging too frequently
skipping logging after 295024 examples to avoid logging too frequently
train stats after 295040 examples: {'rewards_train/chosen': '-0.27934', 'rewards_train/rejected': '-6.8151', 'rewards_train/margins': '6.9062', 'rewards_train/KL_estimate': '0', 'loss/train': '0.33429', 'examples_per_second': '5.0866', 'grad_norm': '7.125', 'counters/examples': 295040, 'counters/updates': 18440}
skipping logging after 295056 examples to avoid logging too frequently
skipping logging after 295072 examples to avoid logging too frequently
skipping logging after 295088 examples to avoid logging too frequently
train stats after 295104 examples: {'rewards_train/chosen': '0.45192', 'rewards_train/rejected': '-4.9859', 'rewards_train/margins': '5.5781', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22815', 'examples_per_second': '5.3694', 'grad_norm': '4.375', 'counters/examples': 295104, 'counters/updates': 18444}
skipping logging after 295120 examples to avoid logging too frequently
skipping logging after 295136 examples to avoid logging too frequently
skipping logging after 295152 examples to avoid logging too frequently
train stats after 295168 examples: {'rewards_train/chosen': '0.641', 'rewards_train/rejected': '-5.9876', 'rewards_train/margins': '6.4609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18829', 'examples_per_second': '5.1239', 'grad_norm': '4.0625', 'counters/examples': 295168, 'counters/updates': 18448}
skipping logging after 295184 examples to avoid logging too frequently
skipping logging after 295200 examples to avoid logging too frequently
skipping logging after 295216 examples to avoid logging too frequently
train stats after 295232 examples: {'rewards_train/chosen': '0.2079', 'rewards_train/rejected': '-6.5396', 'rewards_train/margins': '6.6953', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22522', 'examples_per_second': '5.743', 'grad_norm': '5.3438', 'counters/examples': 295232, 'counters/updates': 18452}
skipping logging after 295248 examples to avoid logging too frequently
skipping logging after 295264 examples to avoid logging too frequently
skipping logging after 295280 examples to avoid logging too frequently
train stats after 295296 examples: {'rewards_train/chosen': '0.2619', 'rewards_train/rejected': '-5.7679', 'rewards_train/margins': '6.1406', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26636', 'examples_per_second': '5.0915', 'grad_norm': '5.5', 'counters/examples': 295296, 'counters/updates': 18456}
skipping logging after 295312 examples to avoid logging too frequently
skipping logging after 295328 examples to avoid logging too frequently
skipping logging after 295344 examples to avoid logging too frequently
train stats after 295360 examples: {'rewards_train/chosen': '-0.06866', 'rewards_train/rejected': '-6.4228', 'rewards_train/margins': '6.4297', 'rewards_train/KL_estimate': '0', 'loss/train': '0.26288', 'examples_per_second': '5.6152', 'grad_norm': '5.5312', 'counters/examples': 295360, 'counters/updates': 18460}
skipping logging after 295376 examples to avoid logging too frequently
skipping logging after 295392 examples to avoid logging too frequently
skipping logging after 295408 examples to avoid logging too frequently
train stats after 295424 examples: {'rewards_train/chosen': '0.35487', 'rewards_train/rejected': '-5.7241', 'rewards_train/margins': '6.0391', 'rewards_train/KL_estimate': '0', 'loss/train': '0.18481', 'examples_per_second': '4.4598', 'grad_norm': '4.6562', 'counters/examples': 295424, 'counters/updates': 18464}
skipping logging after 295440 examples to avoid logging too frequently
skipping logging after 295456 examples to avoid logging too frequently
skipping logging after 295472 examples to avoid logging too frequently
train stats after 295488 examples: {'rewards_train/chosen': '0.28291', 'rewards_train/rejected': '-6.4325', 'rewards_train/margins': '6.7734', 'rewards_train/KL_estimate': '0', 'loss/train': '0.22852', 'examples_per_second': '5.6767', 'grad_norm': '5.0938', 'counters/examples': 295488, 'counters/updates': 18468}
skipping logging after 295504 examples to avoid logging too frequently
skipping logging after 295520 examples to avoid logging too frequently
skipping logging after 295536 examples to avoid logging too frequently
train stats after 295552 examples: {'rewards_train/chosen': '0.29172', 'rewards_train/rejected': '-7.048', 'rewards_train/margins': '7.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24872', 'examples_per_second': '4.7101', 'grad_norm': '5.0312', 'counters/examples': 295552, 'counters/updates': 18472}
skipping logging after 295568 examples to avoid logging too frequently
skipping logging after 295584 examples to avoid logging too frequently
skipping logging after 295600 examples to avoid logging too frequently
train stats after 295616 examples: {'rewards_train/chosen': '0.50119', 'rewards_train/rejected': '-5.9909', 'rewards_train/margins': '6.1562', 'rewards_train/KL_estimate': '0', 'loss/train': '0.2207', 'examples_per_second': '4.9643', 'grad_norm': '6', 'counters/examples': 295616, 'counters/updates': 18476}
skipping logging after 295632 examples to avoid logging too frequently
skipping logging after 295648 examples to avoid logging too frequently
skipping logging after 295664 examples to avoid logging too frequently
train stats after 295680 examples: {'rewards_train/chosen': '0.43901', 'rewards_train/rejected': '-6.5822', 'rewards_train/margins': '6.8086', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24884', 'examples_per_second': '5.5492', 'grad_norm': '5.2812', 'counters/examples': 295680, 'counters/updates': 18480}
skipping logging after 295696 examples to avoid logging too frequently
skipping logging after 295712 examples to avoid logging too frequently
skipping logging after 295728 examples to avoid logging too frequently
train stats after 295744 examples: {'rewards_train/chosen': '-0.042904', 'rewards_train/rejected': '-6.7279', 'rewards_train/margins': '6.5312', 'rewards_train/KL_estimate': '0', 'loss/train': '0.24536', 'examples_per_second': '5.2547', 'grad_norm': '4.9688', 'counters/examples': 295744, 'counters/updates': 18484}
skipping logging after 295760 examples to avoid logging too frequently
skipping logging after 295776 examples to avoid logging too frequently
skipping logging after 295792 examples to avoid logging too frequently
train stats after 295808 examples: {'rewards_train/chosen': '0.62187', 'rewards_train/rejected': '-5.9112', 'rewards_train/margins': '6.4609', 'rewards_train/KL_estimate': '0', 'loss/train': '0.21802', 'examples_per_second': '5.4578', 'grad_norm': '4.0625', 'counters/examples': 295808, 'counters/updates': 18488}
skipping logging after 295824 examples to avoid logging too frequently
skipping logging after 295840 examples to avoid logging too frequently
skipping logging after 295856 examples to avoid logging too frequently
