[2024-05-03 05:33:05,296] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-03 05:33:05,883] torch.distributed.run: [WARNING] 
[2024-05-03 05:33:05,883] torch.distributed.run: [WARNING] *****************************************
[2024-05-03 05:33:05,883] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-05-03 05:33:05,883] torch.distributed.run: [WARNING] *****************************************
[2024-05-03 05:33:08,501] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-03 05:33:08,503] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-03 05:33:08,592] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.

[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[2024-05-03 05:33:08,618] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[2024-05-03 05:33:09,263] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-05-03 05:33:09,264] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-05-03 05:33:09,297] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-05-03 05:33:09,326] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-05-03 05:33:09,342] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-05-03 05:33:11,585] [INFO] [partition_parameters.py:345:__exit__] finished initializing model - num_params = 291, num_elems = 7.24B
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:02<00:04,  2.34s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:02<00:04,  2.35s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:02<00:04,  2.35s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:04<00:02,  2.05s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:04<00:02,  2.05s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:04<00:02,  2.06s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:05<00:10,  5.45s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  2.00s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  2.04s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  2.00s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  2.05s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  2.00s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  2.05s/it]
Loading checkpoint shards:  67%|██████▋   | 2/3 [00:09<00:04,  4.64s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:12<00:00,  3.93s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:12<00:00,  4.20s/it]
[2024-05-03 05:33:24,633] [INFO] [partition_parameters.py:345:__exit__] finished initializing model - num_params = 582, num_elems = 14.48B
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:03,  1.65s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:03,  1.66s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:03,  1.66s/it][2024-05-03 05:33:28,227] torch.distributed.elastic.agent.server.api: [WARNING] Received Signals.SIGINT death signal, shutting down workers
[2024-05-03 05:33:28,228] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 199354 closing signal SIGINT
[2024-05-03 05:33:28,228] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 199355 closing signal SIGINT
[2024-05-03 05:33:28,228] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 199356 closing signal SIGINT
[2024-05-03 05:33:28,228] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 199357 closing signal SIGINT
Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:07,  3.58s/it]
Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:07,  3.58s/it]
Traceback (most recent call last):
  File "/home/wxt/huatong/TRL_FT/train_code/dpo_train.py", line 116, in <module>
Traceback (most recent call last):
  File "/home/wxt/huatong/TRL_FT/train_code/dpo_train.py", line 116, in <module>
    model_ref = AutoModelForCausalLM.from_pretrained(model_config.model_name_or_path, **model_kwargs)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 563, in from_pretrained
    model_ref = AutoModelForCausalLM.from_pretrained(model_config.model_name_or_path, **model_kwargs)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 563, in from_pretrained
    return model_class.from_pretrained(    
return model_class.from_pretrained(  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/modeling_utils.py", line 3682, in from_pretrained

  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/modeling_utils.py", line 3682, in from_pretrained
    ) = cls._load_pretrained_model(
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4132, in _load_pretrained_model
    ) = cls._load_pretrained_model(
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4132, in _load_pretrained_model
    gc.collect()
KeyboardInterrupt
    gc.collect()
KeyboardInterrupt
Loading checkpoint shards:   0%|          | 0/3 [00:03<?, ?it/s]
Traceback (most recent call last):
  File "/home/wxt/huatong/TRL_FT/train_code/dpo_train.py", line 116, in <module>
    model_ref = AutoModelForCausalLM.from_pretrained(model_config.model_name_or_path, **model_kwargs)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 563, in from_pretrained
    return model_class.from_pretrained(
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/modeling_utils.py", line 3682, in from_pretrained
    ) = cls._load_pretrained_model(
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4128, in _load_pretrained_model
    error_msgs += _load_state_dict_into_model(model_to_load, state_dict, start_prefix)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/modeling_utils.py", line 703, in _load_state_dict_into_model
    load(model_to_load, state_dict, prefix=start_prefix)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/modeling_utils.py", line 701, in load
    load(child, state_dict, prefix + name + ".")
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/modeling_utils.py", line 701, in load
    load(child, state_dict, prefix + name + ".")
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/modeling_utils.py", line 701, in load
Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:07,  3.60s/it]
    load(child, state_dict, prefix + name + ".")
  [Previous line repeated 2 more times]
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/modeling_utils.py", line 695, in load
Traceback (most recent call last):
  File "/home/wxt/huatong/TRL_FT/train_code/dpo_train.py", line 116, in <module>
    module._load_from_state_dict(*args)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2040, in _load_from_state_dict
    model_ref = AutoModelForCausalLM.from_pretrained(model_config.model_name_or_path, **model_kwargs)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 563, in from_pretrained
    param.copy_(input_param)
    return model_class.from_pretrained(
KeyboardInterrupt  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/modeling_utils.py", line 3682, in from_pretrained

    ) = cls._load_pretrained_model(
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4132, in _load_pretrained_model
    gc.collect()
KeyboardInterrupt
[2024-05-03 05:33:29,438] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 199354 closing signal SIGTERM
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
Traceback (most recent call last):
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 727, in run
    result = self._invoke_run(role)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 868, in _invoke_run
    time.sleep(monitor_interval)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 62, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 199235 got signal: 2

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wxt/.conda/envs/rl/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py", line 46, in main
    args.func(args)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/accelerate/commands/launch.py", line 1060, in launch_command
    deepspeed_launcher(args)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/accelerate/commands/launch.py", line 764, in deepspeed_launcher
    distrib_run.run(args)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 259, in launch_agent
    result = agent.run()
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 123, in wrapper
    result = f(*args, **kwargs)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 734, in run
    self._shutdown(e.sigval)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py", line 311, in _shutdown
    self._pcontext.close(death_sig)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 318, in close
    self._close(death_sig=death_sig, timeout=timeout)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 706, in _close
    handler.proc.wait(time_to_wait)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/subprocess.py", line 1209, in wait
    return self._wait(timeout=timeout)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/subprocess.py", line 1953, in _wait
    time.sleep(delay)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 62, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 199235 got signal: 2
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Map:  37%|███▋      | 7329/19996 [00:32<00:52, 240.61 examples/s]Map:  37%|███▋      | 7357/19996 [00:32<00:50, 249.91 examples/s]Map:  37%|███▋      | 7393/19996 [00:32<00:52, 241.00 examples/s]Map:  37%|███▋      | 7422/19996 [00:32<00:51, 246.18 examples/s]Map:  37%|███▋      | 7450/19996 [00:32<00:57, 217.18 examples/s]Map:  37%|███▋      | 7476/19996 [00:32<00:57, 217.56 examples/s]Map:  38%|███▊      | 7502/19996 [00:32<00:55, 223.16 examples/s]Map:  38%|███▊      | 7528/19996 [00:33<00:53, 230.90 examples/s]Map:  38%|███▊      | 7558/19996 [00:33<00:50, 244.37 examples/s]Map:  38%|███▊      | 7585/19996 [00:33<00:49, 248.39 examples/s]Map:  38%|███▊      | 7618/19996 [00:33<00:53, 231.69 examples/s]Map:  38%|███▊      | 7644/19996 [00:33<00:53, 232.91 examples/s]Map:  38%|███▊      | 7669/19996 [00:33<00:52, 233.39 examples/s]Map:  38%|███▊      | 7694/19996 [00:33<00:52, 234.62 examples/s]Map:  39%|███▊      | 7724/19996 [00:33<00:56, 216.49 examples/s]Map:  39%|███▉      | 7761/19996 [00:34<00:54, 225.34 examples/s]Map:  39%|███▉      | 7789/19996 [00:34<00:51, 237.52 examples/s]Map:  39%|███▉      | 7817/19996 [00:34<00:49, 244.60 examples/s]Map:  39%|███▉      | 7850/19996 [00:34<00:52, 232.65 examples/s]Map:  39%|███▉      | 7876/19996 [00:34<00:51, 236.38 examples/s]Map:  40%|███▉      | 7904/19996 [00:34<00:49, 246.29 examples/s]Map:  40%|███▉      | 7935/19996 [00:34<00:52, 230.81 examples/s]Map:  40%|███▉      | 7966/19996 [00:34<00:55, 217.08 examples/s]Map:  40%|███▉      | 7992/19996 [00:35<00:53, 225.19 examples/s]Map:  40%|████      | 8022/19996 [00:35<01:30, 131.73 examples/s]Map:  40%|████      | 8042/19996 [00:35<01:24, 141.71 examples/s]Map:  40%|████      | 8072/19996 [00:35<01:18, 151.90 examples/s]Map:  40%|████      | 8098/19996 [00:35<01:09, 170.66 examples/s]Map:  41%|████      | 8122/19996 [00:36<01:04, 184.30 examples/s]Map:  41%|████      | 8144/19996 [00:36<01:02, 189.41 examples/s]Map:  41%|████      | 8175/19996 [00:36<01:01, 191.42 examples/s]Map:  41%|████      | 8204/19996 [00:36<01:02, 188.78 examples/s]Map:  41%|████      | 8235/19996 [00:36<01:01, 190.19 examples/s]Map:  41%|████▏     | 8256/19996 [00:36<01:00, 193.50 examples/s]Map:  41%|████▏     | 8284/19996 [00:36<01:06, 175.33 examples/s]Map:  42%|████▏     | 8308/19996 [00:36<01:02, 187.04 examples/s]Map:  42%|████▏     | 8333/19996 [00:37<00:58, 200.94 examples/s]Map:  42%|████▏     | 8360/19996 [00:37<00:53, 217.43 examples/s]Map:  42%|████▏     | 8391/19996 [00:37<00:55, 210.08 examples/s]Map:  42%|████▏     | 8423/19996 [00:37<00:55, 207.32 examples/s]Map:  42%|████▏     | 8446/19996 [00:37<00:54, 211.37 examples/s]Map:  42%|████▏     | 8474/19996 [00:37<00:58, 197.86 examples/s]Map:  43%|████▎     | 8503/19996 [00:37<01:01, 186.36 examples/s]Map:  43%|████▎     | 8528/19996 [00:38<00:57, 199.21 examples/s]Map:  43%|████▎     | 8550/19996 [00:38<00:57, 199.57 examples/s]Map:  43%|████▎     | 8573/19996 [00:38<00:56, 202.59 examples/s]Map:  43%|████▎     | 8595/19996 [00:38<00:57, 199.30 examples/s]Map:  43%|████▎     | 8617/19996 [00:38<00:55, 203.69 examples/s]Map:  43%|████▎     | 8642/19996 [00:38<00:53, 211.74 examples/s]Map:  43%|████▎     | 8668/19996 [00:38<00:51, 222.11 examples/s]Map:  44%|████▎     | 8701/19996 [00:38<00:53, 210.54 examples/s]Map:  44%|████▎     | 8728/19996 [00:38<00:51, 218.67 examples/s]Map:  44%|████▍     | 8751/19996 [00:39<00:51, 219.23 examples/s]Map:  44%|████▍     | 8777/19996 [00:39<00:56, 199.15 examples/s]Map:  44%|████▍     | 8798/19996 [00:39<00:56, 199.82 examples/s]Map:  44%|████▍     | 8827/19996 [00:39<00:50, 220.59 examples/s]Map:  44%|████▍     | 8853/19996 [00:39<00:49, 226.36 examples/s]Map:  44%|████▍     | 8884/19996 [00:39<00:45, 246.12 examples/s]Map:  45%|████▍     | 8921/19996 [00:39<00:45, 241.79 examples/s]Map:  45%|████▍     | 8958/19996 [00:39<00:46, 238.17 examples/s]Map:  45%|████▍     | 8992/19996 [00:40<00:48, 229.12 examples/s]Map:  45%|████▌     | 9018/19996 [00:40<01:24, 130.26 examples/s]Map:  45%|████▌     | 9037/19996 [00:40<01:19, 138.19 examples/s]Map:  45%|████▌     | 9059/19996 [00:40<01:11, 152.34 examples/s]Map:  45%|████▌     | 9086/19996 [00:40<01:02, 173.18 examples/s]Map:  46%|████▌     | 9109/19996 [00:41<00:59, 181.92 examples/s]Map:  46%|████▌     | 9136/19996 [00:41<01:01, 175.24 examples/s]Map:  46%|████▌     | 9166/19996 [00:41<01:00, 179.83 examples/s]Map:  46%|████▌     | 9191/19996 [00:41<00:56, 192.27 examples/s]Map:  46%|████▌     | 9214/19996 [00:41<00:54, 197.98 examples/s]Map:  46%|████▌     | 9235/19996 [00:41<00:54, 197.76 examples/s]Map:  46%|████▋     | 9259/19996 [00:41<00:52, 205.03 examples/s]Map:  46%|████▋     | 9285/19996 [00:41<00:55, 192.15 examples/s]Map:  47%|████▋     | 9309/19996 [00:42<00:53, 199.36 examples/s]Map:  47%|████▋     | 9334/19996 [00:42<00:50, 209.78 examples/s]Map:  47%|████▋     | 9362/19996 [00:42<00:48, 217.41 examples/s]Map:  47%|████▋     | 9400/19996 [00:42<00:46, 226.36 examples/s]Map:  47%|████▋     | 9423/19996 [00:42<00:46, 225.94 examples/s]Map:  47%|████▋     | 9447/19996 [00:42<00:46, 226.41 examples/s]Map:  47%|████▋     | 9470/19996 [00:42<00:46, 225.51 examples/s]Map:  48%|████▊     | 9505/19996 [00:42<00:47, 220.60 examples/s]Map:  48%|████▊     | 9537/19996 [00:43<00:48, 216.16 examples/s]Map:  48%|████▊     | 9562/19996 [00:43<00:48, 213.03 examples/s]Map:  48%|████▊     | 9589/19996 [00:43<00:46, 225.00 examples/s]Map:  48%|████▊     | 9620/19996 [00:43<00:49, 209.49 examples/s]Map:  48%|████▊     | 9651/19996 [00:43<00:50, 206.73 examples/s]Map:  48%|████▊     | 9679/19996 [00:43<00:46, 221.81 examples/s]Map:  49%|████▊     | 9704/19996 [00:43<00:45, 226.69 examples/s]Map:  49%|████▊     | 9735/19996 [00:43<00:49, 208.66 examples/s]Map:  49%|████▉     | 9764/19996 [00:44<00:45, 226.04 examples/s]Map:  49%|████▉     | 9794/19996 [00:44<00:47, 214.37 examples/s]Map:  49%|████▉     | 9817/19996 [00:44<00:47, 216.40 examples/s]Map:  49%|████▉     | 9852/19996 [00:44<00:46, 217.51 examples/s]Map:  49%|████▉     | 9875/19996 [00:44<00:45, 220.22 examples/s]Map:  50%|████▉     | 9902/19996 [00:44<00:44, 229.15 examples/s]Map:  50%|████▉     | 9927/19996 [00:44<00:43, 231.83 examples/s]Map:  50%|████▉     | 9960/19996 [00:44<00:45, 222.22 examples/s]Map:  50%|████▉     | 9992/19996 [00:45<00:40, 244.42 examples/s]Map:  50%|█████     | 10021/19996 [00:45<01:13, 136.53 examples/s]Map:  50%|█████     | 10046/19996 [00:45<01:10, 140.99 examples/s]Map:  50%|█████     | 10065/19996 [00:45<01:06, 148.35 examples/s]Map:  50%|█████     | 10088/19996 [00:45<01:00, 163.41 examples/s]Map:  51%|█████     | 10109/19996 [00:45<00:57, 172.86 examples/s]Map:  51%|█████     | 10142/19996 [00:46<00:53, 185.72 examples/s]Map:  51%|█████     | 10165/19996 [00:46<00:50, 192.86 examples/s]Map:  51%|█████     | 10186/19996 [00:46<00:50, 195.12 examples/s]Map:  51%|█████     | 10209/19996 [00:46<00:48, 202.46 examples/s]Map:  51%|█████     | 10234/19996 [00:46<00:46, 208.60 examples/s]Map:  51%|█████▏    | 10271/19996 [00:46<00:44, 218.80 examples/s]Map:  51%|█████▏    | 10294/19996 [00:46<00:44, 219.16 examples/s]Map:  52%|█████▏    | 10320/19996 [00:46<00:42, 229.08 examples/s]Map:  52%|█████▏    | 10351/19996 [00:47<00:46, 208.19 examples/s]Map:  52%|█████▏    | 10377/19996 [00:47<00:43, 220.23 examples/s]Map:  52%|█████▏    | 10404/19996 [00:47<00:41, 231.13 examples/s]Map:  52%|█████▏    | 10432/19996 [00:47<00:39, 241.56 examples/s]Map:  52%|█████▏    | 10461/19996 [00:47<00:37, 251.69 examples/s]Map:  53%|█████▎    | 10501/19996 [00:47<00:38, 247.21 examples/s]Map:  53%|█████▎    | 10531/19996 [00:47<00:36, 256.56 examples/s]Map:  53%|█████▎    | 10567/19996 [00:47<00:37, 249.44 examples/s]Map:  53%|█████▎    | 10601/19996 [00:48<00:39, 237.21 examples/s]Map:  53%|█████▎    | 10630/19996 [00:48<00:42, 222.12 examples/s]Map:  53%|█████▎    | 10654/19996 [00:48<00:42, 222.21 examples/s]Map:  53%|█████▎    | 10682/19996 [00:48<00:40, 232.70 examples/s]Map:  54%|█████▎    | 10714/19996 [00:48<00:42, 217.19 examples/s]Map:  54%|█████▎    | 10747/19996 [00:48<00:43, 211.06 examples/s]Map:  54%|█████▍    | 10772/19996 [00:48<00:42, 216.84 examples/s]Map:  54%|█████▍    | 10803/19996 [00:49<00:43, 212.28 examples/s]Map:  54%|█████▍    | 10829/19996 [00:49<00:41, 220.57 examples/s]Map:  54%|█████▍    | 10861/19996 [00:49<00:42, 216.30 examples/s]Map:  54%|█████▍    | 10885/19996 [00:49<00:41, 221.61 examples/s]Map:  55%|█████▍    | 10917/19996 [00:49<00:43, 210.06 examples/s]Map:  55%|█████▍    | 10942/19996 [00:49<00:44, 204.48 examples/s]Map:  55%|█████▍    | 10965/19996 [00:49<00:44, 203.23 examples/s]Map:  55%|█████▍    | 10991/19996 [00:49<00:43, 206.94 examples/s]Map:  55%|█████▌    | 11019/19996 [00:50<01:11, 125.04 examples/s]Map:  55%|█████▌    | 11040/19996 [00:50<01:05, 136.48 examples/s]Map:  55%|█████▌    | 11064/19996 [00:50<00:57, 155.03 examples/s]Map:  55%|█████▌    | 11093/19996 [00:50<00:49, 181.13 examples/s]Map:  56%|█████▌    | 11126/19996 [00:50<00:46, 189.35 examples/s]Map:  56%|█████▌    | 11153/19996 [00:50<00:43, 205.33 examples/s]Map:  56%|█████▌    | 11187/19996 [00:51<00:42, 206.36 examples/s]Map:  56%|█████▌    | 11222/19996 [00:51<00:41, 212.33 examples/s]Map:  56%|█████▌    | 11245/19996 [00:51<00:42, 208.21 examples/s]Map:  56%|█████▋    | 11270/19996 [00:51<00:40, 217.08 examples/s]Map:  57%|█████▋    | 11305/19996 [00:51<00:39, 220.03 examples/s]Map:  57%|█████▋    | 11340/19996 [00:51<00:39, 220.78 examples/s]Map:  57%|█████▋    | 11370/19996 [00:51<00:41, 210.02 examples/s]Map:  57%|█████▋    | 11395/19996 [00:52<00:39, 215.09 examples/s]Map:  57%|█████▋    | 11424/19996 [00:52<00:41, 206.20 examples/s]Map:  57%|█████▋    | 11449/19996 [00:52<00:39, 215.52 examples/s]Map:  57%|█████▋    | 11475/19996 [00:52<00:43, 197.89 examples/s]Map:  58%|█████▊    | 11498/19996 [00:52<00:41, 202.47 examples/s]Map:  58%|█████▊    | 11521/19996 [00:52<00:41, 204.13 examples/s]Map:  58%|█████▊    | 11543/19996 [00:52<00:40, 207.15 examples/s]Map:  58%|█████▊    | 11578/19996 [00:52<00:39, 210.72 examples/s]Map:  58%|█████▊    | 11604/19996 [00:53<00:38, 216.25 examples/s]Map:  58%|█████▊    | 11633/19996 [00:53<00:37, 223.34 examples/s]Map:  58%|█████▊    | 11662/19996 [00:53<00:36, 230.38 examples/s]Map:  58%|█████▊    | 11691/19996 [00:53<00:35, 237.16 examples/s]Map:  59%|█████▊    | 11725/19996 [00:53<00:36, 225.21 examples/s]Map:  59%|█████▉    | 11752/19996 [00:53<00:34, 235.64 examples/s]Map:  59%|█████▉    | 11777/19996 [00:53<00:36, 228.24 examples/s]Map:  59%|█████▉    | 11806/19996 [00:54<00:39, 207.69 examples/s]Map:  59%|█████▉    | 11833/19996 [00:54<00:37, 217.91 examples/s]Map:  59%|█████▉    | 11861/19996 [00:54<00:35, 230.59 examples/s]Map:  59%|█████▉    | 11885/19996 [00:54<00:34, 232.59 examples/s]Map:  60%|█████▉    | 11917/19996 [00:54<00:36, 220.57 examples/s]Map:  60%|█████▉    | 11946/19996 [00:54<00:38, 207.72 examples/s]Map:  60%|█████▉    | 11973/19996 [00:54<00:36, 219.94 examples/s]Map:  60%|██████    | 12000/19996 [00:55<00:59, 133.96 examples/s]Map:  60%|██████    | 12025/19996 [00:55<00:52, 151.87 examples/s]Map:  60%|██████    | 12049/19996 [00:55<00:47, 166.91 examples/s]Map:  60%|██████    | 12080/19996 [00:55<00:45, 173.99 examples/s]Map:  61%|██████    | 12102/19996 [00:55<00:43, 180.68 examples/s]Map:  61%|██████    | 12133/19996 [00:55<00:38, 206.89 examples/s]Map:  61%|██████    | 12157/19996 [00:55<00:37, 206.94 examples/s]Map:  61%|██████    | 12181/19996 [00:55<00:36, 212.69 examples/s]Map:  61%|██████    | 12214/19996 [00:56<00:36, 212.56 examples/s]Map:  61%|██████    | 12237/19996 [00:56<00:36, 211.84 examples/s]Map:  61%|██████▏   | 12267/19996 [00:56<00:38, 202.60 examples/s]Map:  61%|██████▏   | 12288/19996 [00:56<00:38, 201.95 examples/s]Map:  62%|██████▏   | 12309/19996 [00:56<00:37, 202.36 examples/s]Map:  62%|██████▏   | 12339/19996 [00:56<00:33, 226.26 examples/s]Map:  62%|██████▏   | 12373/19996 [00:56<00:34, 220.52 examples/s]Map:  62%|██████▏   | 12397/19996 [00:56<00:34, 220.11 examples/s]Map:  62%|██████▏   | 12426/19996 [00:57<00:36, 204.77 examples/s]Map:  62%|██████▏   | 12458/19996 [00:57<00:37, 199.20 examples/s]Map:  62%|██████▏   | 12481/19996 [00:57<00:37, 202.54 examples/s]Map:  63%|██████▎   | 12510/19996 [00:57<00:38, 193.24 examples/s]Map:  63%|██████▎   | 12532/19996 [00:57<00:38, 196.09 examples/s]Map:  63%|██████▎   | 12558/19996 [00:57<00:35, 208.99 examples/s]Map:  63%|██████▎   | 12588/19996 [00:57<00:37, 199.54 examples/s]Map:  63%|██████▎   | 12609/19996 [00:58<00:41, 176.17 examples/s]Map:  63%|██████▎   | 12635/19996 [00:58<00:37, 194.21 examples/s]Map:  63%|██████▎   | 12666/19996 [00:58<00:37, 197.32 examples/s]Map:  63%|██████▎   | 12688/19996 [00:58<00:36, 202.06 examples/s]Map:  64%|██████▎   | 12709/19996 [00:58<00:36, 200.85 examples/s]Map:  64%|██████▎   | 12735/19996 [00:58<00:34, 210.88 examples/s]Map:  64%|██████▍   | 12763/19996 [00:58<00:32, 219.58 examples/s]Map:  64%|██████▍   | 12786/19996 [00:58<00:32, 221.49 examples/s]Map:  64%|██████▍   | 12816/19996 [00:58<00:30, 238.46 examples/s]Map:  64%|██████▍   | 12850/19996 [00:59<00:30, 230.77 examples/s]Map:  64%|██████▍   | 12875/19996 [00:59<00:30, 234.02 examples/s]Map:  65%|██████▍   | 12908/19996 [00:59<00:31, 221.68 examples/s]Map:  65%|██████▍   | 12939/19996 [00:59<00:32, 214.94 examples/s]Map:  65%|██████▍   | 12961/19996 [00:59<00:32, 214.32 examples/s]Map:  65%|██████▍   | 12985/19996 [00:59<00:33, 207.51 examples/s]Map:  65%|██████▌   | 13007/19996 [01:00<01:01, 114.40 examples/s]Map:  65%|██████▌   | 13030/19996 [01:00<00:52, 131.57 examples/s]Map:  65%|██████▌   | 13054/19996 [01:00<00:46, 149.56 examples/s]Map:  65%|██████▌   | 13078/19996 [01:00<00:41, 167.23 examples/s]Map:  66%|██████▌   | 13099/19996 [01:00<00:39, 176.43 examples/s]Map:  66%|██████▌   | 13125/19996 [01:00<00:49, 138.16 examples/s]Map:  66%|██████▌   | 13145/19996 [01:01<00:45, 149.77 examples/s]Map:  66%|██████▌   | 13168/19996 [01:01<00:41, 166.46 examples/s]Map:  66%|██████▌   | 13192/19996 [01:01<00:38, 178.78 examples/s]Map:  66%|██████▌   | 13213/19996 [01:01<00:36, 185.82 examples/s]Map:  66%|██████▌   | 13238/19996 [01:01<00:33, 198.78 examples/s]Map:  66%|██████▋   | 13271/19996 [01:01<00:33, 203.67 examples/s]Map:  66%|██████▋   | 13295/19996 [01:01<00:32, 207.22 examples/s]Map:  67%|██████▋   | 13330/19996 [01:01<00:31, 209.74 examples/s]Map:  67%|██████▋   | 13354/19996 [01:01<00:31, 213.88 examples/s]Map:  67%|██████▋   | 13379/19996 [01:02<00:29, 222.12 examples/s]Map:  67%|██████▋   | 13413/19996 [01:02<00:29, 219.71 examples/s]Map:  67%|██████▋   | 13446/19996 [01:02<00:30, 217.37 examples/s]Map:  67%|██████▋   | 13468/19996 [01:02<00:30, 213.87 examples/s]Map:  67%|██████▋   | 13492/19996 [01:02<00:29, 218.75 examples/s]Map:  68%|██████▊   | 13526/19996 [01:02<00:30, 211.45 examples/s]Map:  68%|██████▊   | 13548/19996 [01:02<00:30, 210.54 examples/s]Map:  68%|██████▊   | 13572/19996 [01:02<00:29, 215.41 examples/s]Map:  68%|██████▊   | 13594/19996 [01:03<00:29, 214.39 examples/s]Map:  68%|██████▊   | 13618/19996 [01:03<00:29, 214.35 examples/s]Map:  68%|██████▊   | 13641/19996 [01:03<00:29, 215.31 examples/s]Map:  68%|██████▊   | 13671/19996 [01:03<00:27, 233.42 examples/s]Map:  69%|██████▊   | 13698/19996 [01:03<00:26, 241.68 examples/s]Map:  69%|██████▊   | 13728/19996 [01:03<00:28, 220.63 examples/s]Map:  69%|██████▉   | 13752/19996 [01:03<00:28, 220.35 examples/s]Map:  69%|██████▉   | 13783/19996 [01:03<00:25, 240.46 examples/s]Map:  69%|██████▉   | 13820/19996 [01:04<00:26, 237.49 examples/s]Map:  69%|██████▉   | 13849/19996 [01:04<00:25, 242.70 examples/s]Map:  69%|██████▉   | 13887/19996 [01:04<00:24, 245.14 examples/s]Map:  70%|██████▉   | 13912/19996 [01:04<00:25, 242.15 examples/s]Map:  70%|██████▉   | 13947/19996 [01:04<00:25, 235.49 examples/s]Map:  70%|██████▉   | 13979/19996 [01:04<00:26, 226.24 examples/s]Map:  70%|███████   | 14011/19996 [01:05<00:42, 140.48 examples/s]Map:  70%|███████   | 14040/19996 [01:05<00:39, 149.00 examples/s]Map:  70%|███████   | 14064/19996 [01:05<00:36, 164.00 examples/s]Map:  70%|███████   | 14087/19996 [01:05<00:33, 176.33 examples/s]Map:  71%|███████   | 14119/19996 [01:05<00:33, 177.84 examples/s]Map:  71%|███████   | 14143/19996 [01:05<00:31, 188.08 examples/s]Map:  71%|███████   | 14171/19996 [01:05<00:31, 183.52 examples/s]Map:  71%|███████   | 14197/19996 [01:06<00:29, 195.29 examples/s]Map:  71%|███████   | 14220/19996 [01:06<00:28, 200.56 examples/s]Map:  71%|███████   | 14242/19996 [01:06<00:28, 203.67 examples/s]Map:  71%|███████▏  | 14266/19996 [01:06<00:27, 208.60 examples/s]Map:  72%|███████▏  | 14298/19996 [01:06<00:27, 203.52 examples/s]Map:  72%|███████▏  | 14320/19996 [01:06<00:28, 201.42 examples/s]Map:  72%|███████▏  | 14346/19996 [01:06<00:26, 213.39 examples/s]Map:  72%|███████▏  | 14374/19996 [01:06<00:28, 199.27 examples/s]Map:  72%|███████▏  | 14398/19996 [01:07<00:27, 206.07 examples/s]Map:  72%|███████▏  | 14422/19996 [01:07<00:26, 207.63 examples/s]Map:  72%|███████▏  | 14454/19996 [01:07<00:27, 204.75 examples/s]Map:  72%|███████▏  | 14480/19996 [01:07<00:26, 211.49 examples/s]Map:  73%|███████▎  | 14502/19996 [01:07<00:25, 211.44 examples/s]Map:  73%|███████▎  | 14525/19996 [01:07<00:25, 213.53 examples/s]Map:  73%|███████▎  | 14548/19996 [01:07<00:25, 216.56 examples/s]Map:  73%|███████▎  | 14571/19996 [01:07<00:25, 215.62 examples/s]Map:  73%|███████▎  | 14603/19996 [01:08<00:25, 212.19 examples/s]Map:  73%|███████▎  | 14626/19996 [01:08<00:25, 213.81 examples/s]Map:  73%|███████▎  | 14654/19996 [01:08<00:23, 226.25 examples/s]Map:  73%|███████▎  | 14681/19996 [01:08<00:23, 225.59 examples/s]Map:  74%|███████▎  | 14708/19996 [01:08<00:22, 236.05 examples/s]Map:  74%|███████▎  | 14737/19996 [01:08<00:24, 218.02 examples/s]Map:  74%|███████▍  | 14763/19996 [01:08<00:23, 224.76 examples/s]Map:  74%|███████▍  | 14786/19996 [01:08<00:23, 221.80 examples/s]Map:  74%|███████▍  | 14818/19996 [01:08<00:21, 239.36 examples/s]Map:  74%|███████▍  | 14859/19996 [01:09<00:20, 248.13 examples/s]Map:  74%|███████▍  | 14885/19996 [01:09<00:20, 246.51 examples/s]Map:  75%|███████▍  | 14910/19996 [01:09<00:20, 245.33 examples/s]Map:  75%|███████▍  | 14939/19996 [01:09<00:19, 253.89 examples/s]Map:  75%|███████▍  | 14970/19996 [01:09<00:21, 229.31 examples/s]Map:  75%|███████▌  | 15000/19996 [01:09<00:34, 143.15 examples/s]Map:  75%|███████▌  | 15026/19996 [01:10<00:31, 160.31 examples/s]Map:  75%|███████▌  | 15054/19996 [01:10<00:29, 166.54 examples/s]Map:  75%|███████▌  | 15087/19996 [01:10<00:27, 177.82 examples/s]Map:  76%|███████▌  | 15112/19996 [01:10<00:25, 192.02 examples/s]Map:  76%|███████▌  | 15146/19996 [01:10<00:24, 199.52 examples/s]Map:  76%|███████▌  | 15176/19996 [01:10<00:24, 198.53 examples/s]Map:  76%|███████▌  | 15200/19996 [01:10<00:23, 204.74 examples/s]Map:  76%|███████▌  | 15224/19996 [01:11<00:22, 211.19 examples/s]Map:  76%|███████▋  | 15249/19996 [01:11<00:21, 220.56 examples/s]Map:  76%|███████▋  | 15280/19996 [01:11<00:22, 210.55 examples/s]Map:  77%|███████▋  | 15302/19996 [01:11<00:22, 211.35 examples/s]Map:  77%|███████▋  | 15327/19996 [01:11<00:21, 219.33 examples/s]Map:  77%|███████▋  | 15351/19996 [01:11<00:20, 222.12 examples/s]Map:  77%|███████▋  | 15378/19996 [01:11<00:19, 232.16 examples/s]Map:  77%|███████▋  | 15404/19996 [01:11<00:19, 232.21 examples/s]Map:  77%|███████▋  | 15429/19996 [01:11<00:19, 231.50 examples/s]Map:  77%|███████▋  | 15458/19996 [01:12<00:18, 243.83 examples/s]Map:  77%|███████▋  | 15485/19996 [01:12<00:18, 248.32 examples/s]Map:  78%|███████▊  | 15511/19996 [01:12<00:18, 246.84 examples/s]Map:  78%|███████▊  | 15542/19996 [01:12<00:19, 225.10 examples/s]Map:  78%|███████▊  | 15569/19996 [01:12<00:19, 230.79 examples/s]Map:  78%|███████▊  | 15596/19996 [01:12<00:19, 231.35 examples/s]Map:  78%|███████▊  | 15621/19996 [01:12<00:18, 232.96 examples/s]Map:  78%|███████▊  | 15650/19996 [01:12<00:20, 211.67 examples/s]Map:  78%|███████▊  | 15675/19996 [01:12<00:19, 219.90 examples/s]Map:  79%|███████▊  | 15701/19996 [01:13<00:18, 227.12 examples/s]Map:  79%|███████▊  | 15726/19996 [01:13<00:18, 232.60 examples/s]Map:  79%|███████▉  | 15758/19996 [01:13<00:19, 220.23 examples/s]Map:  79%|███████▉  | 15782/19996 [01:13<00:19, 216.38 examples/s]Map:  79%|███████▉  | 15810/19996 [01:13<00:18, 229.44 examples/s]Map:  79%|███████▉  | 15838/19996 [01:13<00:17, 239.92 examples/s]Map:  79%|███████▉  | 15871/19996 [01:13<00:15, 261.44 examples/s]Map:  80%|███████▉  | 15904/19996 [01:13<00:16, 243.46 examples/s]Map:  80%|███████▉  | 15931/19996 [01:14<00:16, 249.08 examples/s]Map:  80%|███████▉  | 15967/19996 [01:14<00:16, 239.68 examples/s]Map:  80%|████████  | 16000/19996 [01:14<00:27, 143.65 examples/s]Map:  80%|████████  | 16029/19996 [01:14<00:25, 153.14 examples/s]Map:  80%|████████  | 16055/19996 [01:14<00:23, 171.09 examples/s]Map:  80%|████████  | 16077/19996 [01:15<00:21, 178.91 examples/s]Map:  81%|████████  | 16106/19996 [01:15<00:21, 182.27 examples/s]Map:  81%|████████  | 16136/19996 [01:15<00:18, 206.68 examples/s]Map:  81%|████████  | 16163/19996 [01:15<00:19, 196.41 examples/s]Map:  81%|████████  | 16198/19996 [01:15<00:18, 202.45 examples/s]Map:  81%|████████  | 16220/19996 [01:15<00:18, 204.98 examples/s]Map:  81%|████████  | 16243/19996 [01:15<00:17, 210.68 examples/s]Map:  81%|████████▏ | 16266/19996 [01:15<00:17, 213.77 examples/s]Map:  82%|████████▏ | 16299/19996 [01:16<00:17, 210.65 examples/s]Map:  82%|████████▏ | 16333/19996 [01:16<00:17, 213.39 examples/s]Map:  82%|████████▏ | 16356/19996 [01:16<00:16, 217.03 examples/s]Map:  82%|████████▏ | 16387/19996 [01:16<00:17, 207.39 examples/s]Map:  82%|████████▏ | 16414/19996 [01:16<00:16, 219.50 examples/s]Map:  82%|████████▏ | 16445/19996 [01:16<00:17, 207.74 examples/s]Map:  82%|████████▏ | 16472/19996 [01:16<00:16, 218.62 examples/s]Map:  83%|████████▎ | 16510/19996 [01:17<00:15, 223.71 examples/s]Map:  83%|████████▎ | 16533/19996 [01:17<00:15, 222.78 examples/s]Map:  83%|████████▎ | 16558/19996 [01:17<00:15, 226.39 examples/s]Map:  83%|████████▎ | 16589/19996 [01:17<00:15, 214.26 examples/s]Map:  83%|████████▎ | 16611/19996 [01:17<00:15, 213.77 examples/s]Map:  83%|████████▎ | 16636/19996 [01:17<00:15, 216.11 examples/s]Map:  83%|████████▎ | 16667/19996 [01:17<00:14, 236.03 examples/s]Map:  84%|████████▎ | 16698/19996 [01:17<00:14, 221.43 examples/s]Map:  84%|████████▎ | 16723/19996 [01:17<00:14, 221.18 examples/s]Map:  84%|████████▍ | 16750/19996 [01:18<00:14, 219.01 examples/s]Map:  84%|████████▍ | 16775/19996 [01:18<00:14, 220.13 examples/s]Map:  84%|████████▍ | 16800/19996 [01:18<00:14, 222.29 examples/s]Map:  84%|████████▍ | 16831/19996 [01:18<00:13, 242.43 examples/s]Map:  84%|████████▍ | 16859/19996 [01:18<00:12, 250.75 examples/s]Map:  84%|████████▍ | 16885/19996 [01:18<00:12, 243.75 examples/s]Map:  85%|████████▍ | 16914/19996 [01:18<00:12, 242.10 examples/s]Map:  85%|████████▍ | 16942/19996 [01:18<00:12, 251.07 examples/s]Map:  85%|████████▍ | 16973/19996 [01:19<00:13, 227.14 examples/s]Map:  85%|████████▌ | 17000/19996 [01:19<00:21, 137.61 examples/s]Map:  85%|████████▌ | 17026/19996 [01:19<00:19, 155.81 examples/s]Map:  85%|████████▌ | 17047/19996 [01:19<00:17, 163.96 examples/s]Map:  85%|████████▌ | 17074/19996 [01:19<00:17, 166.08 examples/s]Map:  86%|████████▌ | 17101/19996 [01:19<00:15, 186.15 examples/s]Map:  86%|████████▌ | 17123/19996 [01:20<00:15, 186.86 examples/s]Map:  86%|████████▌ | 17151/19996 [01:20<00:13, 206.17 examples/s]Map:  86%|████████▌ | 17183/19996 [01:20<00:13, 205.08 examples/s]Map:  86%|████████▌ | 17208/19996 [01:20<00:13, 208.50 examples/s]Map:  86%|████████▌ | 17232/19996 [01:20<00:12, 215.38 examples/s]Map:  86%|████████▋ | 17257/19996 [01:20<00:12, 221.67 examples/s]Map:  86%|████████▋ | 17289/19996 [01:20<00:12, 215.55 examples/s][2024-05-03 06:07:30,304] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-03 06:07:33,456] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[2024-05-03 06:07:34,404] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[2024-05-03 06:07:34,717] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[2024-05-03 06:07:34,798] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[2024-05-03 06:07:35,003] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-05-03 06:07:35,003] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-05-03 06:07:35,053] [INFO] [comm.py:637:init_distributed] cdb=None
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[2024-05-03 06:07:35,419] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-05-03 06:07:35,604] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-05-03 06:07:37,080] [INFO] [partition_parameters.py:345:__exit__] finished initializing model - num_params = 291, num_elems = 7.24B
[2024-05-03 06:07:41,209] [INFO] [partition_parameters.py:345:__exit__] finished initializing model - num_params = 582, num_elems = 14.48B
DatasetDict({
    train_iteration_1: Dataset({
        features: ['prompt_id', 'prompt', 'chosen', 'rejected', 'all_generated_responses', 'all_rm_scores'],
        num_rows: 19766
    })
    test_iteration_1: Dataset({
        features: ['prompt_id', 'prompt', 'chosen', 'rejected', 'all_generated_responses', 'all_rm_scores'],
        num_rows: 994
    })
    train_iteration_2: Dataset({
        features: ['prompt_id', 'prompt', 'chosen', 'rejected', 'all_generated_responses', 'all_rm_scores'],
        num_rows: 19958
    })
    test_iteration_2: Dataset({
        features: ['prompt_id', 'prompt', 'chosen', 'rejected', 'all_generated_responses', 'all_rm_scores'],
        num_rows: 1000
    })
    train_iteration_3: Dataset({
        features: ['prompt_id', 'prompt', 'chosen', 'rejected', 'all_generated_responses', 'all_rm_scores'],
        num_rows: 19996
    })
    test_iteration_3: Dataset({
        features: ['prompt_id', 'prompt', 'chosen', 'rejected', 'all_generated_responses', 'all_rm_scores'],
        num_rows: 1000
    })
})
DatasetDict({
    train_iteration_1: Dataset({
        features: ['prompt_id', 'prompt', 'chosen', 'rejected', 'all_generated_responses', 'all_rm_scores'],
        num_rows: 19766
    })
    test_iteration_1: Dataset({
        features: ['prompt_id', 'prompt', 'chosen', 'rejected', 'all_generated_responses', 'all_rm_scores'],
        num_rows: 994
    })
    train_iteration_2: Dataset({
        features: ['prompt_id', 'prompt', 'chosen', 'rejected', 'all_generated_responses', 'all_rm_scores'],
        num_rows: 19958
    })
    test_iteration_2: Dataset({
        features: ['prompt_id', 'prompt', 'chosen', 'rejected', 'all_generated_responses', 'all_rm_scores'],
        num_rows: 1000
    })
    train_iteration_3: Dataset({
        features: ['prompt_id', 'prompt', 'chosen', 'rejected', 'all_generated_responses', 'all_rm_scores'],
        num_rows: 19996
    })
    test_iteration_3: Dataset({
        features: ['prompt_id', 'prompt', 'chosen', 'rejected', 'all_generated_responses', 'all_rm_scores'],
        num_rows: 1000
    })
})
DatasetDict({
    train_iteration_1: Dataset({
        features: ['prompt_id', 'prompt', 'chosen', 'rejected', 'all_generated_responses', 'all_rm_scores'],
        num_rows: 19766
    })
    test_iteration_1: Dataset({
        features: ['prompt_id', 'prompt', 'chosen', 'rejected', 'all_generated_responses', 'all_rm_scores'],
        num_rows: 994
    })
    train_iteration_2: Dataset({
        features: ['prompt_id', 'prompt', 'chosen', 'rejected', 'all_generated_responses', 'all_rm_scores'],
        num_rows: 19958
    })
    test_iteration_2: Dataset({
        features: ['prompt_id', 'prompt', 'chosen', 'rejected', 'all_generated_responses', 'all_rm_scores'],
        num_rows: 1000
    })
    train_iteration_3: Dataset({
        features: ['prompt_id', 'prompt', 'chosen', 'rejected', 'all_generated_responses', 'all_rm_scores'],
        num_rows: 19996
    })
    test_iteration_3: Dataset({
        features: ['prompt_id', 'prompt', 'chosen', 'rejected', 'all_generated_responses', 'all_rm_scores'],
        num_rows: 1000
    })
})
DatasetDict({
    train_iteration_1: Dataset({
        features: ['prompt_id', 'prompt', 'chosen', 'rejected', 'all_generated_responses', 'all_rm_scores'],
        num_rows: 19766
    })
    test_iteration_1: Dataset({
        features: ['prompt_id', 'prompt', 'chosen', 'rejected', 'all_generated_responses', 'all_rm_scores'],
        num_rows: 994
    })
    train_iteration_2: Dataset({
        features: ['prompt_id', 'prompt', 'chosen', 'rejected', 'all_generated_responses', 'all_rm_scores'],
        num_rows: 19958
    })
    test_iteration_2: Dataset({
        features: ['prompt_id', 'prompt', 'chosen', 'rejected', 'all_generated_responses', 'all_rm_scores'],
        num_rows: 1000
    })
    train_iteration_3: Dataset({
        features: ['prompt_id', 'prompt', 'chosen', 'rejected', 'all_generated_responses', 'all_rm_scores'],
        num_rows: 19996
    })
    test_iteration_3: Dataset({
        features: ['prompt_id', 'prompt', 'chosen', 'rejected', 'all_generated_responses', 'all_rm_scores'],
        num_rows: 1000
    })
})
[2024-05-03 06:09:46,657] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.2, git-hash=unknown, git-branch=unknown
[2024-05-03 06:09:46,667] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-05-03 06:09:46,668] [INFO] [logging.py:96:log_dist] [Rank 0] Creating ZeRO Offload
[2024-05-03 06:09:46,795] [INFO] [utils.py:779:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2024-05-03 06:09:46,796] [INFO] [utils.py:780:see_memory_usage] MA 8.24 GB         Max_MA 9.42 GB         CA 9.96 GB         Max_CA 10 GB 
[2024-05-03 06:09:46,796] [INFO] [utils.py:787:see_memory_usage] CPU Virtual Memory:  used = 17.75 GB, percent = 2.0%
Parameter Offload: Total persistent parameters: 266240 in 65 params
[2024-05-03 06:09:46,914] [INFO] [utils.py:779:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2024-05-03 06:09:46,914] [INFO] [utils.py:780:see_memory_usage] MA 8.24 GB         Max_MA 8.24 GB         CA 9.96 GB         Max_CA 10 GB 
[2024-05-03 06:09:46,915] [INFO] [utils.py:787:see_memory_usage] CPU Virtual Memory:  used = 17.78 GB, percent = 2.1%
[2024-05-03 06:09:46,916] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-05-03 06:09:46,916] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-05-03 06:09:46,916] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-05-03 06:09:46,916] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-05-03 06:09:46,916] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-05-03 06:09:46,916] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-05-03 06:09:46,916] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-05-03 06:09:46,916] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-05-03 06:09:46,916] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-05-03 06:09:46,916] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-05-03 06:09:46,916] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-05-03 06:09:46,916] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fa89431cb50>
[2024-05-03 06:09:46,916] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-05-03 06:09:46,917] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-05-03 06:09:46,918] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-05-03 06:09:46,918] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-05-03 06:09:46,918] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-05-03 06:09:46,918] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-05-03 06:09:46,918] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-05-03 06:09:46,918] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-05-03 06:09:46,918] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-05-03 06:09:46,918] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-05-03 06:09:46,918] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-05-03 06:09:46,918] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-05-03 06:09:46,918] [INFO] [config.py:1000:print]   train_batch_size ............. 16
[2024-05-03 06:09:46,918] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  4
[2024-05-03 06:09:46,918] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-05-03 06:09:46,918] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-05-03 06:09:46,918] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-05-03 06:09:46,918] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-05-03 06:09:46,918] [INFO] [config.py:1000:print]   world_size ................... 4
[2024-05-03 06:09:46,918] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  False
[2024-05-03 06:09:46,918] [INFO] [config.py:1000:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=True stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-05-03 06:09:46,918] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-05-03 06:09:46,918] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-05-03 06:09:46,918] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 3
[2024-05-03 06:09:46,918] [INFO] [config.py:986:print_user_config]   json = {
    "train_batch_size": 16, 
    "train_micro_batch_size_per_gpu": 4, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 3, 
        "offload_optimizer": {
            "device": "none", 
            "nvme_path": null
        }, 
        "offload_param": {
            "device": "none", 
            "nvme_path": null
        }, 
        "stage3_gather_16bit_weights_on_model_save": true
    }, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": true
    }, 
    "fp16": {
        "enabled": false
    }, 
    "zero_optimization.reduce_bucket_size": 1.677722e+07, 
    "zero_optimization.stage3_param_persistence_threshold": 4.096000e+04, 
    "zero_optimization.stage3_prefetch_bucket_size": 1.509949e+07
}
Parameter Offload: Total persistent parameters: 266240 in 65 params
{'loss': 0.6931, 'grad_norm': 317.0053506019013, 'learning_rate': 6.6666666666666675e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -538.1766357421875, 'logps/chosen': -536.8985595703125, 'logits/rejected': -2.4704391956329346, 'logits/chosen': -2.5065114498138428, 'epoch': 0.0}
[2024-05-03 06:11:32,515] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 1.6982, 'grad_norm': 1116.6930537395474, 'learning_rate': 6.666666666666667e-05, 'rewards/chosen': -16.8791446685791, 'rewards/rejected': -18.224760055541992, 'rewards/accuracies': 0.3888888955116272, 'rewards/margins': 1.3456132411956787, 'logps/rejected': -601.96240234375, 'logps/chosen': -577.103515625, 'logits/rejected': -2.553144931793213, 'logits/chosen': -2.5518949031829834, 'epoch': 0.01}
{'loss': 7.1385, 'grad_norm': 11944.044730796619, 'learning_rate': 0.00013333333333333334, 'rewards/chosen': -329.32342529296875, 'rewards/rejected': -331.4456481933594, 'rewards/accuracies': 0.2750000059604645, 'rewards/margins': 2.122215747833252, 'logps/rejected': -3812.784423828125, 'logps/chosen': -3777.91650390625, 'logits/rejected': -1.3357226848602295, 'logits/chosen': -1.3377416133880615, 'epoch': 0.02}
{'loss': 8.7857, 'grad_norm': 152.92818513820154, 'learning_rate': 0.0002, 'rewards/chosen': -372.38153076171875, 'rewards/rejected': -373.99737548828125, 'rewards/accuracies': 0.3499999940395355, 'rewards/margins': 1.615882158279419, 'logps/rejected': -4155.0263671875, 'logps/chosen': -4133.73046875, 'logits/rejected': -3.216965436935425, 'logits/chosen': -3.216878890991211, 'epoch': 0.02}
{'loss': 13.9169, 'grad_norm': 133.2596908191327, 'learning_rate': 0.0002666666666666667, 'rewards/chosen': -574.9593505859375, 'rewards/rejected': -578.8643798828125, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': 3.9050612449645996, 'logps/rejected': -6245.1396484375, 'logps/chosen': -6192.9912109375, 'logits/rejected': -2.615762710571289, 'logits/chosen': -2.6157355308532715, 'epoch': 0.03}
{'loss': 14.008, 'grad_norm': 167.6202970719131, 'learning_rate': 0.0003333333333333333, 'rewards/chosen': -469.8374938964844, 'rewards/rejected': -468.7686462402344, 'rewards/accuracies': 0.32499998807907104, 'rewards/margins': -1.0688183307647705, 'logps/rejected': -5121.458984375, 'logps/chosen': -5120.4189453125, 'logits/rejected': -3.6485626697540283, 'logits/chosen': -3.648550510406494, 'epoch': 0.04}
{'loss': 12.1279, 'grad_norm': 148.1848004183294, 'learning_rate': 0.0004, 'rewards/chosen': -464.5584411621094, 'rewards/rejected': -456.71826171875, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -7.8401288986206055, 'logps/rejected': -4946.615234375, 'logps/chosen': -5021.8310546875, 'logits/rejected': -3.386730670928955, 'logits/chosen': -3.3867831230163574, 'epoch': 0.05}
{'loss': 11.6834, 'grad_norm': 129.39895797356573, 'learning_rate': 0.00046666666666666666, 'rewards/chosen': -392.9407653808594, 'rewards/rejected': -404.7134094238281, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 11.772635459899902, 'logps/rejected': -4432.7216796875, 'logps/chosen': -4287.7578125, 'logits/rejected': -3.7909045219421387, 'logits/chosen': -3.7906508445739746, 'epoch': 0.06}
{'loss': 7.2123, 'grad_norm': 158.58117711708476, 'learning_rate': 0.0005333333333333334, 'rewards/chosen': -411.5702209472656, 'rewards/rejected': -412.7752990722656, 'rewards/accuracies': 0.3499999940395355, 'rewards/margins': 1.2050724029541016, 'logps/rejected': -4577.73291015625, 'logps/chosen': -4564.93896484375, 'logits/rejected': -2.4945342540740967, 'logits/chosen': -2.4948718547821045, 'epoch': 0.06}
{'loss': 11.5481, 'grad_norm': 226.9587209655194, 'learning_rate': 0.0006, 'rewards/chosen': -521.4357299804688, 'rewards/rejected': -513.0642700195312, 'rewards/accuracies': 0.5, 'rewards/margins': -8.3715181350708, 'logps/rejected': -5532.46533203125, 'logps/chosen': -5611.58984375, 'logits/rejected': -3.6503100395202637, 'logits/chosen': -3.6501853466033936, 'epoch': 0.07}
{'loss': 8.2341, 'grad_norm': 94.423835695599, 'learning_rate': 0.0006666666666666666, 'rewards/chosen': -484.01934814453125, 'rewards/rejected': -494.88226318359375, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 10.862958908081055, 'logps/rejected': -5395.44970703125, 'logps/chosen': -5280.0751953125, 'logits/rejected': -3.8719654083251953, 'logits/chosen': -3.8719258308410645, 'epoch': 0.08}
{'loss': 10.0463, 'grad_norm': 393.15308220102946, 'learning_rate': 0.0007333333333333333, 'rewards/chosen': -494.9698791503906, 'rewards/rejected': -502.73944091796875, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': 7.769578456878662, 'logps/rejected': -5511.1474609375, 'logps/chosen': -5430.29736328125, 'logits/rejected': -2.601747512817383, 'logits/chosen': -2.6017632484436035, 'epoch': 0.09}
{'loss': 13.5152, 'grad_norm': 100.09297591173147, 'learning_rate': 0.0008, 'rewards/chosen': -605.041259765625, 'rewards/rejected': -611.9716796875, 'rewards/accuracies': 0.32499998807907104, 'rewards/margins': 6.930470943450928, 'logps/rejected': -6572.7919921875, 'logps/chosen': -6495.87353515625, 'logits/rejected': -4.635520935058594, 'logits/chosen': -4.635728359222412, 'epoch': 0.1}
{'loss': 9.8746, 'grad_norm': 100.96072824829814, 'learning_rate': 0.0008666666666666667, 'rewards/chosen': -608.2572631835938, 'rewards/rejected': -604.2952270507812, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': -3.9620461463928223, 'logps/rejected': -6527.5888671875, 'logps/chosen': -6562.8330078125, 'logits/rejected': -3.0151162147521973, 'logits/chosen': -3.01509428024292, 'epoch': 0.1}
{'loss': 11.5401, 'grad_norm': 98.03271381923949, 'learning_rate': 0.0009333333333333333, 'rewards/chosen': -516.6548461914062, 'rewards/rejected': -521.4658813476562, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': 4.811007976531982, 'logps/rejected': -5629.5810546875, 'logps/chosen': -5574.8837890625, 'logits/rejected': -3.213689088821411, 'logits/chosen': -3.213554859161377, 'epoch': 0.11}
{'loss': 11.5001, 'grad_norm': 347.02249379888457, 'learning_rate': 0.001, 'rewards/chosen': -495.7162170410156, 'rewards/rejected': -489.55426025390625, 'rewards/accuracies': 0.375, 'rewards/margins': -6.162060260772705, 'logps/rejected': -5350.591796875, 'logps/chosen': -5396.0810546875, 'logits/rejected': -3.635890245437622, 'logits/chosen': -3.6361687183380127, 'epoch': 0.12}
{'loss': 14.9387, 'grad_norm': 236.56337631277088, 'learning_rate': 0.0009972222222222223, 'rewards/chosen': -552.512451171875, 'rewards/rejected': -560.8099365234375, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 8.297453880310059, 'logps/rejected': -6014.716796875, 'logps/chosen': -5932.1728515625, 'logits/rejected': -2.6683804988861084, 'logits/chosen': -2.6692421436309814, 'epoch': 0.13}
{'loss': 19.7611, 'grad_norm': 257.3474857922685, 'learning_rate': 0.0009944444444444445, 'rewards/chosen': -1123.0595703125, 'rewards/rejected': -1127.25439453125, 'rewards/accuracies': 0.3499999940395355, 'rewards/margins': 4.194831848144531, 'logps/rejected': -11736.6630859375, 'logps/chosen': -11695.0830078125, 'logits/rejected': -5.126761436462402, 'logits/chosen': -5.126490592956543, 'epoch': 0.14}
{'loss': 20.2984, 'grad_norm': 223.6365249747324, 'learning_rate': 0.0009916666666666667, 'rewards/chosen': -849.5173950195312, 'rewards/rejected': -849.9910888671875, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': 0.4736366271972656, 'logps/rejected': -8922.029296875, 'logps/chosen': -8907.513671875, 'logits/rejected': -3.9010021686553955, 'logits/chosen': -3.901644229888916, 'epoch': 0.14}
{'loss': 16.6184, 'grad_norm': 99.85350130281745, 'learning_rate': 0.000988888888888889, 'rewards/chosen': -765.7838134765625, 'rewards/rejected': -757.8084716796875, 'rewards/accuracies': 0.375, 'rewards/margins': -7.975337028503418, 'logps/rejected': -7994.20947265625, 'logps/chosen': -8061.4501953125, 'logits/rejected': -1.9296634197235107, 'logits/chosen': -1.929398536682129, 'epoch': 0.15}
{'loss': 10.533, 'grad_norm': 43.61178824419964, 'learning_rate': 0.0009861111111111112, 'rewards/chosen': -836.8150634765625, 'rewards/rejected': -842.3343505859375, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 5.5193352699279785, 'logps/rejected': -8861.3779296875, 'logps/chosen': -8798.3896484375, 'logits/rejected': -1.2261781692504883, 'logits/chosen': -1.2237026691436768, 'epoch': 0.16}
{'loss': 9.2903, 'grad_norm': 69.07399764329563, 'learning_rate': 0.0009833333333333332, 'rewards/chosen': -532.7193603515625, 'rewards/rejected': -541.6448974609375, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 8.925519943237305, 'logps/rejected': -5896.74609375, 'logps/chosen': -5792.009765625, 'logits/rejected': -1.5651663541793823, 'logits/chosen': -1.5653021335601807, 'epoch': 0.17}
{'loss': 15.6887, 'grad_norm': 76.82220639459598, 'learning_rate': 0.0009805555555555555, 'rewards/chosen': -464.6771545410156, 'rewards/rejected': -457.5574645996094, 'rewards/accuracies': 0.375, 'rewards/margins': -7.119654655456543, 'logps/rejected': -5095.00927734375, 'logps/chosen': -5153.32421875, 'logits/rejected': -1.1857469081878662, 'logits/chosen': -1.18570077419281, 'epoch': 0.18}
{'loss': 11.1497, 'grad_norm': 121.77283471942769, 'learning_rate': 0.0009777777777777777, 'rewards/chosen': -411.0917053222656, 'rewards/rejected': -421.7906188964844, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 10.698921203613281, 'logps/rejected': -4614.52099609375, 'logps/chosen': -4500.9697265625, 'logits/rejected': -1.251796007156372, 'logits/chosen': -1.2517354488372803, 'epoch': 0.18}
{'loss': 9.7924, 'grad_norm': 82.29843944927634, 'learning_rate': 0.000975, 'rewards/chosen': -440.1151428222656, 'rewards/rejected': -438.04840087890625, 'rewards/accuracies': 0.5, 'rewards/margins': -2.0666959285736084, 'logps/rejected': -4814.34228515625, 'logps/chosen': -4829.763671875, 'logits/rejected': -1.7756593227386475, 'logits/chosen': -1.7757542133331299, 'epoch': 0.19}
{'loss': 8.2257, 'grad_norm': 68.30373458484989, 'learning_rate': 0.0009722222222222222, 'rewards/chosen': -486.54815673828125, 'rewards/rejected': -488.2528381347656, 'rewards/accuracies': 0.375, 'rewards/margins': 1.7047523260116577, 'logps/rejected': -5287.060546875, 'logps/chosen': -5268.75634765625, 'logits/rejected': -1.0093424320220947, 'logits/chosen': -1.0092827081680298, 'epoch': 0.2}
{'loss': 13.4318, 'grad_norm': 72.42640276095226, 'learning_rate': 0.0009694444444444444, 'rewards/chosen': -406.2746887207031, 'rewards/rejected': -413.09490966796875, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': 6.820281982421875, 'logps/rejected': -4553.4482421875, 'logps/chosen': -4480.94580078125, 'logits/rejected': -1.1932058334350586, 'logits/chosen': -1.1937682628631592, 'epoch': 0.21}
{'loss': 10.2145, 'grad_norm': 83.83088742047367, 'learning_rate': 0.0009666666666666667, 'rewards/chosen': -445.8912658691406, 'rewards/rejected': -459.381591796875, 'rewards/accuracies': 0.5, 'rewards/margins': 13.490304946899414, 'logps/rejected': -4979.8583984375, 'logps/chosen': -4837.5791015625, 'logits/rejected': -0.6184136867523193, 'logits/chosen': -0.6182295083999634, 'epoch': 0.22}
{'loss': 7.0033, 'grad_norm': 58.4571371894565, 'learning_rate': 0.0009638888888888889, 'rewards/chosen': -445.24468994140625, 'rewards/rejected': -455.35101318359375, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': 10.106344223022461, 'logps/rejected': -4925.24267578125, 'logps/chosen': -4816.4658203125, 'logits/rejected': -1.1761173009872437, 'logits/chosen': -1.176386833190918, 'epoch': 0.22}
{'loss': 9.751, 'grad_norm': 45.63440959031233, 'learning_rate': 0.0009611111111111112, 'rewards/chosen': -476.40283203125, 'rewards/rejected': -483.2850646972656, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 6.88223934173584, 'logps/rejected': -5265.68701171875, 'logps/chosen': -5188.6298828125, 'logits/rejected': -1.2143744230270386, 'logits/chosen': -1.2144834995269775, 'epoch': 0.23}
{'loss': 9.5584, 'grad_norm': 78.70307616532965, 'learning_rate': 0.0009583333333333334, 'rewards/chosen': -430.5389709472656, 'rewards/rejected': -425.3472595214844, 'rewards/accuracies': 0.30000001192092896, 'rewards/margins': -5.191678047180176, 'logps/rejected': -4674.72314453125, 'logps/chosen': -4718.1640625, 'logits/rejected': -1.1817727088928223, 'logits/chosen': -1.1817175149917603, 'epoch': 0.24}
{'loss': 6.9143, 'grad_norm': 61.15627055232904, 'learning_rate': 0.0009555555555555556, 'rewards/chosen': -442.01995849609375, 'rewards/rejected': -450.9730529785156, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': 8.95302677154541, 'logps/rejected': -4950.701171875, 'logps/chosen': -4851.33056640625, 'logits/rejected': -0.6640117168426514, 'logits/chosen': -0.6640461683273315, 'epoch': 0.25}
{'loss': 9.7508, 'grad_norm': 94.71305392617604, 'learning_rate': 0.0009527777777777778, 'rewards/chosen': -372.99346923828125, 'rewards/rejected': -368.7510070800781, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': -4.242474555969238, 'logps/rejected': -4045.947265625, 'logps/chosen': -4087.93994140625, 'logits/rejected': -1.0353485345840454, 'logits/chosen': -1.0354077816009521, 'epoch': 0.26}
{'loss': 10.0043, 'grad_norm': 69.00427793941554, 'learning_rate': 0.00095, 'rewards/chosen': -478.30224609375, 'rewards/rejected': -485.3736877441406, 'rewards/accuracies': 0.625, 'rewards/margins': 7.0714111328125, 'logps/rejected': -5275.44482421875, 'logps/chosen': -5198.82275390625, 'logits/rejected': -1.0632660388946533, 'logits/chosen': -1.0634437799453735, 'epoch': 0.26}
{'loss': 12.5226, 'grad_norm': 66.20372197427136, 'learning_rate': 0.0009472222222222222, 'rewards/chosen': -464.0257873535156, 'rewards/rejected': -475.4443359375, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 11.418566703796387, 'logps/rejected': -5146.3662109375, 'logps/chosen': -5026.0693359375, 'logits/rejected': -2.0200047492980957, 'logits/chosen': -2.0200228691101074, 'epoch': 0.27}
{'loss': 8.0876, 'grad_norm': 1.5101390370490801, 'learning_rate': 0.0009444444444444445, 'rewards/chosen': -525.2359619140625, 'rewards/rejected': -531.4143676757812, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 6.178391933441162, 'logps/rejected': -5705.6044921875, 'logps/chosen': -5640.02978515625, 'logits/rejected': -1.7723356485366821, 'logits/chosen': -1.7722924947738647, 'epoch': 0.28}
{'loss': 11.8383, 'grad_norm': 156.46116806426832, 'learning_rate': 0.0009416666666666667, 'rewards/chosen': -459.5845642089844, 'rewards/rejected': -450.89312744140625, 'rewards/accuracies': 0.32499998807907104, 'rewards/margins': -8.691400527954102, 'logps/rejected': -4893.39697265625, 'logps/chosen': -4986.5166015625, 'logits/rejected': -1.6134411096572876, 'logits/chosen': -1.6135003566741943, 'epoch': 0.29}
{'loss': 11.2671, 'grad_norm': 73.29408286473661, 'learning_rate': 0.000938888888888889, 'rewards/chosen': -384.45904541015625, 'rewards/rejected': -381.11529541015625, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': -3.343749523162842, 'logps/rejected': -4224.6123046875, 'logps/chosen': -4266.22607421875, 'logits/rejected': -1.1620267629623413, 'logits/chosen': -1.1621220111846924, 'epoch': 0.3}
{'loss': 9.715, 'grad_norm': 84.41760858769362, 'learning_rate': 0.0009361111111111111, 'rewards/chosen': -364.8794250488281, 'rewards/rejected': -367.83673095703125, 'rewards/accuracies': 0.5, 'rewards/margins': 2.9572906494140625, 'logps/rejected': -4059.514892578125, 'logps/chosen': -4023.06689453125, 'logits/rejected': -1.1901235580444336, 'logits/chosen': -1.190388560295105, 'epoch': 0.3}
{'loss': 7.3261, 'grad_norm': 43.10097975251716, 'learning_rate': 0.0009333333333333333, 'rewards/chosen': -376.23980712890625, 'rewards/rejected': -380.4454040527344, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 4.20560884475708, 'logps/rejected': -4157.15966796875, 'logps/chosen': -4109.8525390625, 'logits/rejected': -1.0847028493881226, 'logits/chosen': -1.0848815441131592, 'epoch': 0.31}
{'loss': 8.632, 'grad_norm': 76.81969231048883, 'learning_rate': 0.0009305555555555556, 'rewards/chosen': -363.7080993652344, 'rewards/rejected': -376.8887634277344, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 13.180681228637695, 'logps/rejected': -4169.53759765625, 'logps/chosen': -4014.934326171875, 'logits/rejected': -1.0130798816680908, 'logits/chosen': -1.0131603479385376, 'epoch': 0.32}
{'loss': 7.386, 'grad_norm': 76.41025543831839, 'learning_rate': 0.0009277777777777778, 'rewards/chosen': -362.4552307128906, 'rewards/rejected': -372.60833740234375, 'rewards/accuracies': 0.5, 'rewards/margins': 10.153108596801758, 'logps/rejected': -4150.9541015625, 'logps/chosen': -4033.048095703125, 'logits/rejected': -1.3096871376037598, 'logits/chosen': -1.3096442222595215, 'epoch': 0.33}
{'loss': 7.6779, 'grad_norm': 40.40850696451371, 'learning_rate': 0.000925, 'rewards/chosen': -369.3738708496094, 'rewards/rejected': -395.46075439453125, 'rewards/accuracies': 0.75, 'rewards/margins': 26.086872100830078, 'logps/rejected': -4320.8837890625, 'logps/chosen': -4051.427001953125, 'logits/rejected': -1.2198946475982666, 'logits/chosen': -1.2199890613555908, 'epoch': 0.34}
{'loss': 7.6089, 'grad_norm': 116.88772372800173, 'learning_rate': 0.0009222222222222223, 'rewards/chosen': -384.86834716796875, 'rewards/rejected': -380.9039306640625, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -3.964411497116089, 'logps/rejected': -4218.14892578125, 'logps/chosen': -4257.41943359375, 'logits/rejected': -1.292339563369751, 'logits/chosen': -1.2926411628723145, 'epoch': 0.34}
{'loss': 7.2409, 'grad_norm': 43.12045147855882, 'learning_rate': 0.0009194444444444444, 'rewards/chosen': -364.3031311035156, 'rewards/rejected': -366.83282470703125, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': 2.5296454429626465, 'logps/rejected': -4138.00439453125, 'logps/chosen': -4111.296875, 'logits/rejected': -1.3517519235610962, 'logits/chosen': -1.3517720699310303, 'epoch': 0.35}
{'loss': 8.5019, 'grad_norm': 50.21693653535869, 'learning_rate': 0.0009166666666666666, 'rewards/chosen': -348.18609619140625, 'rewards/rejected': -348.31573486328125, 'rewards/accuracies': 0.5, 'rewards/margins': 0.12967605888843536, 'logps/rejected': -3864.17529296875, 'logps/chosen': -3860.92138671875, 'logits/rejected': -1.5108697414398193, 'logits/chosen': -1.5110042095184326, 'epoch': 0.36}
{'loss': 10.4916, 'grad_norm': 53.42799533143454, 'learning_rate': 0.0009138888888888889, 'rewards/chosen': -342.96783447265625, 'rewards/rejected': -338.86358642578125, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -4.104282379150391, 'logps/rejected': -3838.79052734375, 'logps/chosen': -3876.05078125, 'logits/rejected': -1.2342890501022339, 'logits/chosen': -1.2342369556427002, 'epoch': 0.37}
{'loss': 7.61, 'grad_norm': 78.24989479403476, 'learning_rate': 0.0009111111111111111, 'rewards/chosen': -327.2673034667969, 'rewards/rejected': -330.3697204589844, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': 3.1024086475372314, 'logps/rejected': -3739.451171875, 'logps/chosen': -3701.866455078125, 'logits/rejected': -1.2947719097137451, 'logits/chosen': -1.2947801351547241, 'epoch': 0.38}
{'loss': 8.8954, 'grad_norm': 42.904069033263205, 'learning_rate': 0.0009083333333333334, 'rewards/chosen': -333.77276611328125, 'rewards/rejected': -341.58709716796875, 'rewards/accuracies': 0.5, 'rewards/margins': 7.814385890960693, 'logps/rejected': -3868.27880859375, 'logps/chosen': -3786.92431640625, 'logits/rejected': -1.352864384651184, 'logits/chosen': -1.3529932498931885, 'epoch': 0.38}
{'loss': 8.7813, 'grad_norm': 34.25792585911644, 'learning_rate': 0.0009055555555555556, 'rewards/chosen': -338.0753479003906, 'rewards/rejected': -347.4718322753906, 'rewards/accuracies': 0.5, 'rewards/margins': 9.396517753601074, 'logps/rejected': -3914.1015625, 'logps/chosen': -3811.53076171875, 'logits/rejected': -1.5434174537658691, 'logits/chosen': -1.543310284614563, 'epoch': 0.39}
{'loss': 6.6891, 'grad_norm': 38.79929614197656, 'learning_rate': 0.0009027777777777778, 'rewards/chosen': -327.7699890136719, 'rewards/rejected': -327.15484619140625, 'rewards/accuracies': 0.375, 'rewards/margins': -0.6151618957519531, 'logps/rejected': -3700.03125, 'logps/chosen': -3705.409423828125, 'logits/rejected': -1.9309316873550415, 'logits/chosen': -1.9307349920272827, 'epoch': 0.4}
{'loss': 9.2771, 'grad_norm': 58.04790077981605, 'learning_rate': 0.0009000000000000001, 'rewards/chosen': -357.55218505859375, 'rewards/rejected': -356.0492248535156, 'rewards/accuracies': 0.32499998807907104, 'rewards/margins': -1.502986192703247, 'logps/rejected': -4000.82373046875, 'logps/chosen': -4018.6796875, 'logits/rejected': -1.7486671209335327, 'logits/chosen': -1.748668909072876, 'epoch': 0.41}
{'loss': 7.9143, 'grad_norm': 32.11453495900037, 'learning_rate': 0.0008972222222222223, 'rewards/chosen': -322.49505615234375, 'rewards/rejected': -327.166259765625, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': 4.671188831329346, 'logps/rejected': -3679.34033203125, 'logps/chosen': -3633.668701171875, 'logits/rejected': -1.9315649271011353, 'logits/chosen': -1.9316943883895874, 'epoch': 0.42}
{'loss': 4.5561, 'grad_norm': 40.41620931876069, 'learning_rate': 0.0008944444444444445, 'rewards/chosen': -341.87384033203125, 'rewards/rejected': -337.6656799316406, 'rewards/accuracies': 0.32499998807907104, 'rewards/margins': -4.208209991455078, 'logps/rejected': -3782.806640625, 'logps/chosen': -3827.06787109375, 'logits/rejected': -1.7043148279190063, 'logits/chosen': -1.704241394996643, 'epoch': 0.42}
{'loss': 8.5155, 'grad_norm': 50.06616085216413, 'learning_rate': 0.0008916666666666667, 'rewards/chosen': -328.2334899902344, 'rewards/rejected': -334.3682556152344, 'rewards/accuracies': 0.5, 'rewards/margins': 6.134780406951904, 'logps/rejected': -3735.633544921875, 'logps/chosen': -3669.393798828125, 'logits/rejected': -1.8276420831680298, 'logits/chosen': -1.8276491165161133, 'epoch': 0.43}
{'loss': 6.8754, 'grad_norm': 74.71084422805338, 'learning_rate': 0.0008888888888888888, 'rewards/chosen': -349.7035827636719, 'rewards/rejected': -352.1781005859375, 'rewards/accuracies': 0.30000001192092896, 'rewards/margins': 2.4745547771453857, 'logps/rejected': -3973.762451171875, 'logps/chosen': -3939.822998046875, 'logits/rejected': -1.832497239112854, 'logits/chosen': -1.8325307369232178, 'epoch': 0.44}
{'loss': 6.0295, 'grad_norm': 69.72523671870415, 'learning_rate': 0.0008861111111111111, 'rewards/chosen': -329.7685546875, 'rewards/rejected': -340.9719543457031, 'rewards/accuracies': 0.5, 'rewards/margins': 11.203368186950684, 'logps/rejected': -3800.202392578125, 'logps/chosen': -3678.60546875, 'logits/rejected': -2.0491888523101807, 'logits/chosen': -2.049295425415039, 'epoch': 0.45}
{'loss': 5.0416, 'grad_norm': 26.700429830339573, 'learning_rate': 0.0008833333333333333, 'rewards/chosen': -352.2430725097656, 'rewards/rejected': -349.75836181640625, 'rewards/accuracies': 0.2750000059604645, 'rewards/margins': -2.484727144241333, 'logps/rejected': -3939.198486328125, 'logps/chosen': -3966.604248046875, 'logits/rejected': -2.1152634620666504, 'logits/chosen': -2.1152539253234863, 'epoch': 0.46}
{'loss': 6.8804, 'grad_norm': 71.89473755045941, 'learning_rate': 0.0008805555555555555, 'rewards/chosen': -344.03045654296875, 'rewards/rejected': -344.5332946777344, 'rewards/accuracies': 0.375, 'rewards/margins': 0.5028522610664368, 'logps/rejected': -3818.94970703125, 'logps/chosen': -3810.20068359375, 'logits/rejected': -1.833082914352417, 'logits/chosen': -1.8331317901611328, 'epoch': 0.46}
{'loss': 6.6135, 'grad_norm': 23.68580219649024, 'learning_rate': 0.0008777777777777778, 'rewards/chosen': -333.0361022949219, 'rewards/rejected': -329.06744384765625, 'rewards/accuracies': 0.5, 'rewards/margins': -3.9686717987060547, 'logps/rejected': -3681.682861328125, 'logps/chosen': -3727.619140625, 'logits/rejected': -2.064265489578247, 'logits/chosen': -2.0643012523651123, 'epoch': 0.47}
{'loss': 8.2962, 'grad_norm': 59.19683784244992, 'learning_rate': 0.000875, 'rewards/chosen': -322.0965576171875, 'rewards/rejected': -319.9595642089844, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': -2.1369717121124268, 'logps/rejected': -3600.169189453125, 'logps/chosen': -3621.13037109375, 'logits/rejected': -2.164069652557373, 'logits/chosen': -2.1639537811279297, 'epoch': 0.48}
{'loss': 8.603, 'grad_norm': 29.573417672428864, 'learning_rate': 0.0008722222222222223, 'rewards/chosen': -297.29888916015625, 'rewards/rejected': -296.2834167480469, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': -1.0154447555541992, 'logps/rejected': -3359.653076171875, 'logps/chosen': -3367.114501953125, 'logits/rejected': -2.017768383026123, 'logits/chosen': -2.017702579498291, 'epoch': 0.49}
{'loss': 7.4513, 'grad_norm': 47.89777815358634, 'learning_rate': 0.0008694444444444445, 'rewards/chosen': -331.2872314453125, 'rewards/rejected': -332.71966552734375, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 1.4324886798858643, 'logps/rejected': -3737.78662109375, 'logps/chosen': -3722.265625, 'logits/rejected': -1.6582199335098267, 'logits/chosen': -1.658193826675415, 'epoch': 0.5}
{'loss': 11.0546, 'grad_norm': 51.92234814715474, 'learning_rate': 0.0008666666666666667, 'rewards/chosen': -305.366455078125, 'rewards/rejected': -305.8963317871094, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 0.529876708984375, 'logps/rejected': -3454.145751953125, 'logps/chosen': -3441.46630859375, 'logits/rejected': -1.8970108032226562, 'logits/chosen': -1.8969627618789673, 'epoch': 0.5}
{'loss': 4.1801, 'grad_norm': 60.82742713271649, 'learning_rate': 0.000863888888888889, 'rewards/chosen': -355.44024658203125, 'rewards/rejected': -360.89251708984375, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': 5.452272891998291, 'logps/rejected': -4013.35693359375, 'logps/chosen': -3941.311767578125, 'logits/rejected': -2.391106128692627, 'logits/chosen': -2.391254425048828, 'epoch': 0.51}
{'loss': 8.864, 'grad_norm': 42.94056561051473, 'learning_rate': 0.0008611111111111112, 'rewards/chosen': -322.73187255859375, 'rewards/rejected': -314.261962890625, 'rewards/accuracies': 0.3499999940395355, 'rewards/margins': -8.4699068069458, 'logps/rejected': -3674.11328125, 'logps/chosen': -3758.28662109375, 'logits/rejected': -2.4576268196105957, 'logits/chosen': -2.457559108734131, 'epoch': 0.52}
{'loss': 5.3808, 'grad_norm': 38.935858708901904, 'learning_rate': 0.0008583333333333333, 'rewards/chosen': -329.0027770996094, 'rewards/rejected': -332.3498229980469, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': 3.3470306396484375, 'logps/rejected': -3761.390625, 'logps/chosen': -3729.981201171875, 'logits/rejected': -2.195268154144287, 'logits/chosen': -2.1952834129333496, 'epoch': 0.53}
{'loss': 6.5494, 'grad_norm': 37.791361012256765, 'learning_rate': 0.0008555555555555556, 'rewards/chosen': -346.92633056640625, 'rewards/rejected': -344.40545654296875, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': -2.520862579345703, 'logps/rejected': -3853.482421875, 'logps/chosen': -3875.617919921875, 'logits/rejected': -2.050931930541992, 'logits/chosen': -2.0509302616119385, 'epoch': 0.54}
{'loss': 7.2155, 'grad_norm': 48.553841491459885, 'learning_rate': 0.0008527777777777777, 'rewards/chosen': -316.1145935058594, 'rewards/rejected': -325.02374267578125, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': 8.909111022949219, 'logps/rejected': -3713.2734375, 'logps/chosen': -3602.537109375, 'logits/rejected': -2.5526485443115234, 'logits/chosen': -2.5527679920196533, 'epoch': 0.54}
{'loss': 7.6494, 'grad_norm': 46.06006951643797, 'learning_rate': 0.00085, 'rewards/chosen': -338.8096618652344, 'rewards/rejected': -342.412841796875, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 3.6031692028045654, 'logps/rejected': -3863.737548828125, 'logps/chosen': -3824.4140625, 'logits/rejected': -2.401343822479248, 'logits/chosen': -2.401421070098877, 'epoch': 0.55}
{'loss': 7.4773, 'grad_norm': 44.08560704498094, 'learning_rate': 0.0008472222222222222, 'rewards/chosen': -311.4420471191406, 'rewards/rejected': -310.3807678222656, 'rewards/accuracies': 0.375, 'rewards/margins': -1.0612881183624268, 'logps/rejected': -3542.64599609375, 'logps/chosen': -3537.638671875, 'logits/rejected': -2.1365420818328857, 'logits/chosen': -2.136592388153076, 'epoch': 0.56}
{'loss': 6.5128, 'grad_norm': 59.10537104628089, 'learning_rate': 0.0008444444444444444, 'rewards/chosen': -295.00445556640625, 'rewards/rejected': -303.5791015625, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 8.5746431350708, 'logps/rejected': -3486.08154296875, 'logps/chosen': -3382.403564453125, 'logits/rejected': -2.39333438873291, 'logits/chosen': -2.393266201019287, 'epoch': 0.57}
{'loss': 5.6417, 'grad_norm': 49.472193215439745, 'learning_rate': 0.0008416666666666667, 'rewards/chosen': -320.44036865234375, 'rewards/rejected': -327.0708312988281, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 6.630456447601318, 'logps/rejected': -3673.31103515625, 'logps/chosen': -3589.276611328125, 'logits/rejected': -2.1683802604675293, 'logits/chosen': -2.168443202972412, 'epoch': 0.58}
{'loss': 5.9166, 'grad_norm': 18.23637514210601, 'learning_rate': 0.0008388888888888889, 'rewards/chosen': -316.2385559082031, 'rewards/rejected': -324.3672180175781, 'rewards/accuracies': 0.5, 'rewards/margins': 8.128650665283203, 'logps/rejected': -3671.79638671875, 'logps/chosen': -3584.403564453125, 'logits/rejected': -2.1427948474884033, 'logits/chosen': -2.142765522003174, 'epoch': 0.58}
{'loss': 8.2683, 'grad_norm': 93.88672505925034, 'learning_rate': 0.0008361111111111111, 'rewards/chosen': -316.8628234863281, 'rewards/rejected': -317.6790466308594, 'rewards/accuracies': 0.3499999940395355, 'rewards/margins': 0.8162670135498047, 'logps/rejected': -3629.25927734375, 'logps/chosen': -3608.5078125, 'logits/rejected': -2.1535935401916504, 'logits/chosen': -2.1534810066223145, 'epoch': 0.59}
{'loss': 5.721, 'grad_norm': 60.514418646589476, 'learning_rate': 0.0008333333333333334, 'rewards/chosen': -320.93267822265625, 'rewards/rejected': -320.14337158203125, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -0.7893131375312805, 'logps/rejected': -3641.82080078125, 'logps/chosen': -3645.305419921875, 'logits/rejected': -2.497079372406006, 'logits/chosen': -2.497354507446289, 'epoch': 0.6}
{'loss': 7.5327, 'grad_norm': 54.09311555044527, 'learning_rate': 0.0008305555555555556, 'rewards/chosen': -306.7482604980469, 'rewards/rejected': -316.33905029296875, 'rewards/accuracies': 0.3499999940395355, 'rewards/margins': 9.590757369995117, 'logps/rejected': -3587.83447265625, 'logps/chosen': -3487.87548828125, 'logits/rejected': -2.35680890083313, 'logits/chosen': -2.356886148452759, 'epoch': 0.61}
{'loss': 9.764, 'grad_norm': 45.095524649901726, 'learning_rate': 0.0008277777777777778, 'rewards/chosen': -309.28192138671875, 'rewards/rejected': -316.1644592285156, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': 6.8825225830078125, 'logps/rejected': -3580.54736328125, 'logps/chosen': -3508.126220703125, 'logits/rejected': -2.2548811435699463, 'logits/chosen': -2.254899501800537, 'epoch': 0.62}
{'loss': 8.1735, 'grad_norm': 44.11006256744914, 'learning_rate': 0.000825, 'rewards/chosen': -307.84478759765625, 'rewards/rejected': -299.6445007324219, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -8.20026969909668, 'logps/rejected': -3435.107421875, 'logps/chosen': -3524.837890625, 'logits/rejected': -2.676729917526245, 'logits/chosen': -2.6766014099121094, 'epoch': 0.62}
{'loss': 6.8563, 'grad_norm': 42.039703294110424, 'learning_rate': 0.0008222222222222222, 'rewards/chosen': -298.5113525390625, 'rewards/rejected': -299.39691162109375, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 0.8855360150337219, 'logps/rejected': -3371.25732421875, 'logps/chosen': -3367.39794921875, 'logits/rejected': -2.379070281982422, 'logits/chosen': -2.379072427749634, 'epoch': 0.63}
{'loss': 7.8923, 'grad_norm': 56.23319890673889, 'learning_rate': 0.0008194444444444445, 'rewards/chosen': -316.0845031738281, 'rewards/rejected': -313.18499755859375, 'rewards/accuracies': 0.3499999940395355, 'rewards/margins': -2.89949369430542, 'logps/rejected': -3583.98779296875, 'logps/chosen': -3600.561279296875, 'logits/rejected': -2.2265758514404297, 'logits/chosen': -2.2265264987945557, 'epoch': 0.64}
{'loss': 8.7607, 'grad_norm': 42.016021023790266, 'learning_rate': 0.0008166666666666667, 'rewards/chosen': -271.96881103515625, 'rewards/rejected': -272.4453125, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 0.4765390455722809, 'logps/rejected': -3159.40380859375, 'logps/chosen': -3149.689208984375, 'logits/rejected': -2.6019160747528076, 'logits/chosen': -2.6018176078796387, 'epoch': 0.65}
{'loss': 7.5049, 'grad_norm': 47.73072808746781, 'learning_rate': 0.000813888888888889, 'rewards/chosen': -300.5712890625, 'rewards/rejected': -309.7843017578125, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 9.213032722473145, 'logps/rejected': -3484.46630859375, 'logps/chosen': -3392.15380859375, 'logits/rejected': -2.4525694847106934, 'logits/chosen': -2.452500820159912, 'epoch': 0.66}
{'loss': 6.1529, 'grad_norm': 54.84498693855073, 'learning_rate': 0.0008111111111111111, 'rewards/chosen': -299.3385314941406, 'rewards/rejected': -300.32427978515625, 'rewards/accuracies': 0.3499999940395355, 'rewards/margins': 0.985704779624939, 'logps/rejected': -3450.887451171875, 'logps/chosen': -3431.492919921875, 'logits/rejected': -2.376563549041748, 'logits/chosen': -2.3765594959259033, 'epoch': 0.66}
{'loss': 5.6789, 'grad_norm': 33.700615723299634, 'learning_rate': 0.0008083333333333333, 'rewards/chosen': -303.9053649902344, 'rewards/rejected': -308.39520263671875, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 4.489806175231934, 'logps/rejected': -3515.792236328125, 'logps/chosen': -3462.868408203125, 'logits/rejected': -2.202446460723877, 'logits/chosen': -2.2023236751556396, 'epoch': 0.67}
{'loss': 6.3544, 'grad_norm': 41.24768834085838, 'learning_rate': 0.0008055555555555556, 'rewards/chosen': -303.93450927734375, 'rewards/rejected': -301.2029724121094, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -2.7315526008605957, 'logps/rejected': -3438.01513671875, 'logps/chosen': -3463.944091796875, 'logits/rejected': -2.234149932861328, 'logits/chosen': -2.234174966812134, 'epoch': 0.68}
{'loss': 7.745, 'grad_norm': 32.08834062151376, 'learning_rate': 0.0008027777777777778, 'rewards/chosen': -288.2304992675781, 'rewards/rejected': -288.88519287109375, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': 0.6546598672866821, 'logps/rejected': -3340.27294921875, 'logps/chosen': -3329.69140625, 'logits/rejected': -2.69742751121521, 'logits/chosen': -2.697376251220703, 'epoch': 0.69}
{'loss': 8.1445, 'grad_norm': 37.72930486967192, 'learning_rate': 0.0008, 'rewards/chosen': -298.4823303222656, 'rewards/rejected': -310.0189514160156, 'rewards/accuracies': 0.32499998807907104, 'rewards/margins': 11.536643028259277, 'logps/rejected': -3621.61669921875, 'logps/chosen': -3492.923095703125, 'logits/rejected': -2.452033519744873, 'logits/chosen': -2.452094554901123, 'epoch': 0.7}
{'loss': 7.6029, 'grad_norm': 33.91968965778789, 'learning_rate': 0.0007972222222222223, 'rewards/chosen': -295.74713134765625, 'rewards/rejected': -299.5851135253906, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': 3.8379459381103516, 'logps/rejected': -3446.700439453125, 'logps/chosen': -3406.86669921875, 'logits/rejected': -2.5341410636901855, 'logits/chosen': -2.534086227416992, 'epoch': 0.7}
{'loss': 8.7379, 'grad_norm': 45.96612268477998, 'learning_rate': 0.0007944444444444444, 'rewards/chosen': -287.78326416015625, 'rewards/rejected': -287.9908142089844, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': 0.20756301283836365, 'logps/rejected': -3314.89404296875, 'logps/chosen': -3312.693359375, 'logits/rejected': -2.4359729290008545, 'logits/chosen': -2.4359734058380127, 'epoch': 0.71}
{'loss': 6.5036, 'grad_norm': 58.96308621773921, 'learning_rate': 0.0007916666666666666, 'rewards/chosen': -292.8615417480469, 'rewards/rejected': -295.4847106933594, 'rewards/accuracies': 0.5, 'rewards/margins': 2.6231722831726074, 'logps/rejected': -3367.310546875, 'logps/chosen': -3331.0234375, 'logits/rejected': -2.375990867614746, 'logits/chosen': -2.376038074493408, 'epoch': 0.72}
{'loss': 9.4019, 'grad_norm': 45.790106974722704, 'learning_rate': 0.0007888888888888889, 'rewards/chosen': -307.7257385253906, 'rewards/rejected': -305.97198486328125, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -1.753732681274414, 'logps/rejected': -3528.89306640625, 'logps/chosen': -3548.69189453125, 'logits/rejected': -2.331756591796875, 'logits/chosen': -2.331739902496338, 'epoch': 0.73}
{'loss': 7.3838, 'grad_norm': 52.25826945728106, 'learning_rate': 0.0007861111111111111, 'rewards/chosen': -317.09271240234375, 'rewards/rejected': -315.129150390625, 'rewards/accuracies': 0.32499998807907104, 'rewards/margins': -1.9635670185089111, 'logps/rejected': -3629.081298828125, 'logps/chosen': -3651.75634765625, 'logits/rejected': -2.387521266937256, 'logits/chosen': -2.3874943256378174, 'epoch': 0.74}
{'loss': 5.7738, 'grad_norm': 39.1169278578033, 'learning_rate': 0.0007833333333333334, 'rewards/chosen': -304.1988830566406, 'rewards/rejected': -309.9664611816406, 'rewards/accuracies': 0.32499998807907104, 'rewards/margins': 5.767584323883057, 'logps/rejected': -3543.70703125, 'logps/chosen': -3479.67724609375, 'logits/rejected': -2.664808750152588, 'logits/chosen': -2.6648716926574707, 'epoch': 0.74}
{'loss': 4.8087, 'grad_norm': 43.471085041728415, 'learning_rate': 0.0007805555555555556, 'rewards/chosen': -311.9356994628906, 'rewards/rejected': -323.67840576171875, 'rewards/accuracies': 0.625, 'rewards/margins': 11.742716789245605, 'logps/rejected': -3651.91552734375, 'logps/chosen': -3528.95556640625, 'logits/rejected': -2.730782985687256, 'logits/chosen': -2.730858325958252, 'epoch': 0.75}
{'loss': 7.8841, 'grad_norm': 43.39210616041516, 'learning_rate': 0.0007777777777777778, 'rewards/chosen': -295.8046875, 'rewards/rejected': -294.1376647949219, 'rewards/accuracies': 0.30000001192092896, 'rewards/margins': -1.6670033931732178, 'logps/rejected': -3405.036376953125, 'logps/chosen': -3412.23828125, 'logits/rejected': -2.509300470352173, 'logits/chosen': -2.509276866912842, 'epoch': 0.76}
{'loss': 7.5204, 'grad_norm': 46.4299195256268, 'learning_rate': 0.0007750000000000001, 'rewards/chosen': -291.6146240234375, 'rewards/rejected': -291.20904541015625, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': -0.40555304288864136, 'logps/rejected': -3367.014892578125, 'logps/chosen': -3369.64453125, 'logits/rejected': -2.549530029296875, 'logits/chosen': -2.5496115684509277, 'epoch': 0.77}
{'loss': 5.1713, 'grad_norm': 33.520335712394896, 'learning_rate': 0.0007722222222222223, 'rewards/chosen': -319.87188720703125, 'rewards/rejected': -318.25408935546875, 'rewards/accuracies': 0.32499998807907104, 'rewards/margins': -1.617799162864685, 'logps/rejected': -3644.227294921875, 'logps/chosen': -3658.026123046875, 'logits/rejected': -2.4658737182617188, 'logits/chosen': -2.4656052589416504, 'epoch': 0.78}
{'loss': 5.6132, 'grad_norm': 30.591854425245007, 'learning_rate': 0.0007694444444444445, 'rewards/chosen': -278.5860900878906, 'rewards/rejected': -288.52093505859375, 'rewards/accuracies': 0.699999988079071, 'rewards/margins': 9.934859275817871, 'logps/rejected': -3246.00048828125, 'logps/chosen': -3146.743896484375, 'logits/rejected': -2.4592957496643066, 'logits/chosen': -2.459157943725586, 'epoch': 0.78}
{'loss': 5.0254, 'grad_norm': 55.82023752570267, 'learning_rate': 0.0007666666666666667, 'rewards/chosen': -311.1443176269531, 'rewards/rejected': -309.6790771484375, 'rewards/accuracies': 0.5, 'rewards/margins': -1.4652385711669922, 'logps/rejected': -3476.100341796875, 'logps/chosen': -3489.405517578125, 'logits/rejected': -2.316646099090576, 'logits/chosen': -2.316624879837036, 'epoch': 0.79}
{'loss': 4.6757, 'grad_norm': 60.90672485143894, 'learning_rate': 0.0007638888888888888, 'rewards/chosen': -295.61431884765625, 'rewards/rejected': -301.1777648925781, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': 5.5634260177612305, 'logps/rejected': -3471.25244140625, 'logps/chosen': -3411.14794921875, 'logits/rejected': -2.1347076892852783, 'logits/chosen': -2.1346874237060547, 'epoch': 0.8}
{'loss': 5.3977, 'grad_norm': 29.8751069712902, 'learning_rate': 0.0007611111111111111, 'rewards/chosen': -291.93975830078125, 'rewards/rejected': -296.83062744140625, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 4.890895366668701, 'logps/rejected': -3407.20068359375, 'logps/chosen': -3349.29931640625, 'logits/rejected': -2.3239269256591797, 'logits/chosen': -2.323812246322632, 'epoch': 0.81}
{'loss': 6.0577, 'grad_norm': 33.50359225085791, 'learning_rate': 0.0007583333333333333, 'rewards/chosen': -296.23590087890625, 'rewards/rejected': -303.489990234375, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': 7.254090309143066, 'logps/rejected': -3471.489013671875, 'logps/chosen': -3388.76025390625, 'logits/rejected': -2.452110767364502, 'logits/chosen': -2.4520668983459473, 'epoch': 0.82}
{'loss': 7.514, 'grad_norm': 43.76962786880891, 'learning_rate': 0.0007555555555555555, 'rewards/chosen': -296.8369445800781, 'rewards/rejected': -295.68609619140625, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -1.1508495807647705, 'logps/rejected': -3401.862548828125, 'logps/chosen': -3409.750732421875, 'logits/rejected': -2.494426965713501, 'logits/chosen': -2.4943795204162598, 'epoch': 0.82}
{'loss': 8.5077, 'grad_norm': 30.284804662764405, 'learning_rate': 0.0007527777777777778, 'rewards/chosen': -289.6574401855469, 'rewards/rejected': -286.2967224121094, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -3.3607559204101562, 'logps/rejected': -3294.207763671875, 'logps/chosen': -3326.43115234375, 'logits/rejected': -2.5206246376037598, 'logits/chosen': -2.520761251449585, 'epoch': 0.83}
{'loss': 5.255, 'grad_norm': 30.846944150758844, 'learning_rate': 0.00075, 'rewards/chosen': -308.32159423828125, 'rewards/rejected': -306.5067138671875, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -1.814903974533081, 'logps/rejected': -3489.622314453125, 'logps/chosen': -3505.547607421875, 'logits/rejected': -2.6020915508270264, 'logits/chosen': -2.60202956199646, 'epoch': 0.84}
{'loss': 7.0885, 'grad_norm': 39.17022608445121, 'learning_rate': 0.0007472222222222223, 'rewards/chosen': -300.1758117675781, 'rewards/rejected': -301.81707763671875, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': 1.6412261724472046, 'logps/rejected': -3448.12548828125, 'logps/chosen': -3427.64013671875, 'logits/rejected': -2.36283016204834, 'logits/chosen': -2.3626394271850586, 'epoch': 0.85}
{'loss': 6.8426, 'grad_norm': 52.77435627556075, 'learning_rate': 0.0007444444444444445, 'rewards/chosen': -288.6391296386719, 'rewards/rejected': -282.53466796875, 'rewards/accuracies': 0.375, 'rewards/margins': -6.1044816970825195, 'logps/rejected': -3259.054931640625, 'logps/chosen': -3324.08251953125, 'logits/rejected': -2.3563973903656006, 'logits/chosen': -2.3563742637634277, 'epoch': 0.86}
{'loss': 6.0393, 'grad_norm': 37.51761395317528, 'learning_rate': 0.0007416666666666667, 'rewards/chosen': -269.4462585449219, 'rewards/rejected': -279.3209533691406, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 9.874711990356445, 'logps/rejected': -3264.30810546875, 'logps/chosen': -3153.661865234375, 'logits/rejected': -2.478790760040283, 'logits/chosen': -2.4788405895233154, 'epoch': 0.86}
{'loss': 8.7505, 'grad_norm': 103.92728541316461, 'learning_rate': 0.000738888888888889, 'rewards/chosen': -296.8709411621094, 'rewards/rejected': -299.30078125, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 2.4298460483551025, 'logps/rejected': -3416.82080078125, 'logps/chosen': -3390.03369140625, 'logits/rejected': -2.253812074661255, 'logits/chosen': -2.2537693977355957, 'epoch': 0.87}
{'loss': 7.9787, 'grad_norm': 71.13224292518565, 'learning_rate': 0.0007361111111111112, 'rewards/chosen': -295.7581481933594, 'rewards/rejected': -285.53033447265625, 'rewards/accuracies': 0.3499999940395355, 'rewards/margins': -10.227853775024414, 'logps/rejected': -3223.158935546875, 'logps/chosen': -3332.760498046875, 'logits/rejected': -2.437094211578369, 'logits/chosen': -2.4370810985565186, 'epoch': 0.88}
{'loss': 5.9626, 'grad_norm': 41.99913474806316, 'learning_rate': 0.0007333333333333333, 'rewards/chosen': -291.06707763671875, 'rewards/rejected': -292.9280700683594, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': 1.8609647750854492, 'logps/rejected': -3350.26025390625, 'logps/chosen': -3332.22021484375, 'logits/rejected': -2.7187981605529785, 'logits/chosen': -2.7188613414764404, 'epoch': 0.89}
{'loss': 9.8822, 'grad_norm': 53.62448056193536, 'learning_rate': 0.0007305555555555556, 'rewards/chosen': -287.8757019042969, 'rewards/rejected': -284.9051513671875, 'rewards/accuracies': 0.3499999940395355, 'rewards/margins': -2.970594882965088, 'logps/rejected': -3233.24658203125, 'logps/chosen': -3260.109375, 'logits/rejected': -2.5957751274108887, 'logits/chosen': -2.595827579498291, 'epoch': 0.9}
{'loss': 3.6252, 'grad_norm': 39.03923101971171, 'learning_rate': 0.0007277777777777777, 'rewards/chosen': -270.52423095703125, 'rewards/rejected': -278.9750061035156, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': 8.450761795043945, 'logps/rejected': -3231.67431640625, 'logps/chosen': -3130.94873046875, 'logits/rejected': -2.405254602432251, 'logits/chosen': -2.405285596847534, 'epoch': 0.9}
{'loss': 6.8745, 'grad_norm': 41.645070546471636, 'learning_rate': 0.000725, 'rewards/chosen': -297.41522216796875, 'rewards/rejected': -301.7796325683594, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': 4.364398956298828, 'logps/rejected': -3406.474609375, 'logps/chosen': -3362.18359375, 'logits/rejected': -2.074540138244629, 'logits/chosen': -2.074582576751709, 'epoch': 0.91}
{'loss': 6.1452, 'grad_norm': 24.038056144623656, 'learning_rate': 0.0007222222222222222, 'rewards/chosen': -312.0406188964844, 'rewards/rejected': -320.8955383300781, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': 8.854907035827637, 'logps/rejected': -3662.947998046875, 'logps/chosen': -3557.7265625, 'logits/rejected': -2.031726360321045, 'logits/chosen': -2.0318541526794434, 'epoch': 0.92}
{'loss': 6.9521, 'grad_norm': 34.67872614514634, 'learning_rate': 0.0007194444444444444, 'rewards/chosen': -275.2929382324219, 'rewards/rejected': -279.8305969238281, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 4.537639141082764, 'logps/rejected': -3230.04150390625, 'logps/chosen': -3185.79833984375, 'logits/rejected': -2.5446536540985107, 'logits/chosen': -2.544628620147705, 'epoch': 0.93}
{'loss': 7.9155, 'grad_norm': 28.56498708988651, 'learning_rate': 0.0007166666666666667, 'rewards/chosen': -288.6748962402344, 'rewards/rejected': -291.9128723144531, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': 3.2379989624023438, 'logps/rejected': -3392.214111328125, 'logps/chosen': -3340.79052734375, 'logits/rejected': -2.637451648712158, 'logits/chosen': -2.6374034881591797, 'epoch': 0.94}
{'loss': 8.1747, 'grad_norm': 37.480217760971456, 'learning_rate': 0.0007138888888888889, 'rewards/chosen': -290.22906494140625, 'rewards/rejected': -292.5542297363281, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': 2.325148105621338, 'logps/rejected': -3348.637939453125, 'logps/chosen': -3326.15087890625, 'logits/rejected': -2.5637710094451904, 'logits/chosen': -2.563772678375244, 'epoch': 0.94}
{'loss': 7.2364, 'grad_norm': 41.55982268468992, 'learning_rate': 0.0007111111111111111, 'rewards/chosen': -264.7034912109375, 'rewards/rejected': -269.5876770019531, 'rewards/accuracies': 0.5, 'rewards/margins': 4.884166717529297, 'logps/rejected': -3148.58740234375, 'logps/chosen': -3089.691650390625, 'logits/rejected': -2.5484416484832764, 'logits/chosen': -2.548408031463623, 'epoch': 0.95}
{'loss': 4.4971, 'grad_norm': 34.92297061686209, 'learning_rate': 0.0007083333333333334, 'rewards/chosen': -287.49481201171875, 'rewards/rejected': -289.6849670410156, 'rewards/accuracies': 0.5, 'rewards/margins': 2.190159320831299, 'logps/rejected': -3311.93994140625, 'logps/chosen': -3282.520263671875, 'logits/rejected': -2.2063138484954834, 'logits/chosen': -2.206371784210205, 'epoch': 0.96}
{'loss': 7.8304, 'grad_norm': 35.469191219529584, 'learning_rate': 0.0007055555555555556, 'rewards/chosen': -296.11773681640625, 'rewards/rejected': -290.3728942871094, 'rewards/accuracies': 0.5, 'rewards/margins': -5.744847297668457, 'logps/rejected': -3323.338623046875, 'logps/chosen': -3388.05712890625, 'logits/rejected': -2.2617175579071045, 'logits/chosen': -2.2619595527648926, 'epoch': 0.97}
{'loss': 7.7448, 'grad_norm': 38.058063691724406, 'learning_rate': 0.0007027777777777778, 'rewards/chosen': -299.23004150390625, 'rewards/rejected': -296.46258544921875, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -2.767460346221924, 'logps/rejected': -3407.90673828125, 'logps/chosen': -3436.128173828125, 'logits/rejected': -2.4778025150299072, 'logits/chosen': -2.4780986309051514, 'epoch': 0.98}
{'loss': 6.2714, 'grad_norm': 39.64642170319012, 'learning_rate': 0.0007, 'rewards/chosen': -285.2649230957031, 'rewards/rejected': -284.34490966796875, 'rewards/accuracies': 0.32499998807907104, 'rewards/margins': -0.9200428128242493, 'logps/rejected': -3287.079345703125, 'logps/chosen': -3280.827392578125, 'logits/rejected': -2.292653799057007, 'logits/chosen': -2.2925589084625244, 'epoch': 0.98}
{'loss': 7.4121, 'grad_norm': 31.049112613683956, 'learning_rate': 0.0006972222222222222, 'rewards/chosen': -287.53515625, 'rewards/rejected': -285.49603271484375, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -2.0391507148742676, 'logps/rejected': -3242.4267578125, 'logps/chosen': -3260.7724609375, 'logits/rejected': -2.2554852962493896, 'logits/chosen': -2.255474090576172, 'epoch': 0.99}
{'loss': 7.3722, 'grad_norm': 27.923250681552652, 'learning_rate': 0.0006944444444444445, 'rewards/chosen': -275.9411315917969, 'rewards/rejected': -280.3992614746094, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 4.458133697509766, 'logps/rejected': -3245.951904296875, 'logps/chosen': -3211.466796875, 'logits/rejected': -2.426774740219116, 'logits/chosen': -2.426849603652954, 'epoch': 1.0}
{'loss': 5.833, 'grad_norm': 31.444040497489862, 'learning_rate': 0.0006916666666666667, 'rewards/chosen': -287.3064880371094, 'rewards/rejected': -293.0855407714844, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 5.779017448425293, 'logps/rejected': -3349.86181640625, 'logps/chosen': -3285.703857421875, 'logits/rejected': -2.325434684753418, 'logits/chosen': -2.325246572494507, 'epoch': 1.01}
{'loss': 4.6582, 'grad_norm': 17.11049772196512, 'learning_rate': 0.000688888888888889, 'rewards/chosen': -287.84918212890625, 'rewards/rejected': -293.9936828613281, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 6.144508361816406, 'logps/rejected': -3354.884765625, 'logps/chosen': -3288.25927734375, 'logits/rejected': -2.5075631141662598, 'logits/chosen': -2.5075674057006836, 'epoch': 1.02}
{'loss': 7.0776, 'grad_norm': 26.89034873281409, 'learning_rate': 0.0006861111111111111, 'rewards/chosen': -287.33660888671875, 'rewards/rejected': -298.7625732421875, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 11.425944328308105, 'logps/rejected': -3427.41552734375, 'logps/chosen': -3306.253173828125, 'logits/rejected': -2.8562655448913574, 'logits/chosen': -2.856403112411499, 'epoch': 1.02}
{'loss': 5.7496, 'grad_norm': 44.851709421923914, 'learning_rate': 0.0006833333333333333, 'rewards/chosen': -284.3992614746094, 'rewards/rejected': -288.44500732421875, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 4.0457353591918945, 'logps/rejected': -3323.837890625, 'logps/chosen': -3281.116455078125, 'logits/rejected': -2.8826661109924316, 'logits/chosen': -2.882996082305908, 'epoch': 1.03}
{'loss': 7.5236, 'grad_norm': 34.969318061869785, 'learning_rate': 0.0006805555555555556, 'rewards/chosen': -304.7342834472656, 'rewards/rejected': -306.4107971191406, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 1.6764519214630127, 'logps/rejected': -3531.516845703125, 'logps/chosen': -3519.850830078125, 'logits/rejected': -2.6967337131500244, 'logits/chosen': -2.6967711448669434, 'epoch': 1.04}
{'loss': 5.5283, 'grad_norm': 37.69936834507116, 'learning_rate': 0.0006777777777777778, 'rewards/chosen': -298.72198486328125, 'rewards/rejected': -307.4437255859375, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 8.721707344055176, 'logps/rejected': -3529.938720703125, 'logps/chosen': -3439.205810546875, 'logits/rejected': -3.0708346366882324, 'logits/chosen': -3.0708086490631104, 'epoch': 1.05}
{'loss': 4.7759, 'grad_norm': 34.18787964177403, 'learning_rate': 0.000675, 'rewards/chosen': -298.85406494140625, 'rewards/rejected': -302.92578125, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 4.071712493896484, 'logps/rejected': -3433.64208984375, 'logps/chosen': -3383.194091796875, 'logits/rejected': -3.130831241607666, 'logits/chosen': -3.1308701038360596, 'epoch': 1.06}
{'loss': 4.2559, 'grad_norm': 42.89044007362591, 'learning_rate': 0.0006722222222222223, 'rewards/chosen': -279.41998291015625, 'rewards/rejected': -289.9936218261719, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 10.573634147644043, 'logps/rejected': -3299.73779296875, 'logps/chosen': -3176.22021484375, 'logits/rejected': -2.9922537803649902, 'logits/chosen': -2.992567539215088, 'epoch': 1.06}
{'loss': 8.2674, 'grad_norm': 29.280228547802807, 'learning_rate': 0.0006694444444444444, 'rewards/chosen': -295.90777587890625, 'rewards/rejected': -299.8460693359375, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 3.9383087158203125, 'logps/rejected': -3403.75244140625, 'logps/chosen': -3357.81494140625, 'logits/rejected': -2.715100049972534, 'logits/chosen': -2.715035915374756, 'epoch': 1.07}
{'loss': 7.9067, 'grad_norm': 26.749834190282037, 'learning_rate': 0.0006666666666666666, 'rewards/chosen': -280.1112060546875, 'rewards/rejected': -282.6724548339844, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 2.561249256134033, 'logps/rejected': -3260.314453125, 'logps/chosen': -3212.79345703125, 'logits/rejected': -3.118974208831787, 'logits/chosen': -3.1189982891082764, 'epoch': 1.08}
{'loss': 4.2933, 'grad_norm': 38.38971859590947, 'learning_rate': 0.0006638888888888889, 'rewards/chosen': -297.44866943359375, 'rewards/rejected': -298.6553955078125, 'rewards/accuracies': 0.625, 'rewards/margins': 1.206681489944458, 'logps/rejected': -3415.529296875, 'logps/chosen': -3399.84423828125, 'logits/rejected': -3.088359832763672, 'logits/chosen': -3.0884087085723877, 'epoch': 1.09}
{'loss': 6.3924, 'grad_norm': 32.98482621445523, 'learning_rate': 0.0006611111111111111, 'rewards/chosen': -279.97601318359375, 'rewards/rejected': -284.5072326660156, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 4.531192779541016, 'logps/rejected': -3238.70458984375, 'logps/chosen': -3181.33984375, 'logits/rejected': -2.888820171356201, 'logits/chosen': -2.8889782428741455, 'epoch': 1.1}
{'loss': 4.4531, 'grad_norm': 39.28288598767699, 'learning_rate': 0.0006583333333333334, 'rewards/chosen': -313.13873291015625, 'rewards/rejected': -317.7015686035156, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 4.56284236907959, 'logps/rejected': -3609.12109375, 'logps/chosen': -3552.30126953125, 'logits/rejected': -2.738053560256958, 'logits/chosen': -2.7379918098449707, 'epoch': 1.1}
{'loss': 5.8355, 'grad_norm': 47.03103565875281, 'learning_rate': 0.0006555555555555556, 'rewards/chosen': -259.7618713378906, 'rewards/rejected': -267.3208923339844, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': 7.559049129486084, 'logps/rejected': -3102.15478515625, 'logps/chosen': -3013.624267578125, 'logits/rejected': -2.8613734245300293, 'logits/chosen': -2.8613147735595703, 'epoch': 1.11}
{'loss': 6.9279, 'grad_norm': 37.469247793058855, 'learning_rate': 0.0006527777777777778, 'rewards/chosen': -278.9559631347656, 'rewards/rejected': -288.434326171875, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': 9.47839069366455, 'logps/rejected': -3330.71533203125, 'logps/chosen': -3217.932373046875, 'logits/rejected': -2.894318103790283, 'logits/chosen': -2.8944833278656006, 'epoch': 1.12}
{'loss': 5.6576, 'grad_norm': 32.75873381878667, 'learning_rate': 0.0006500000000000001, 'rewards/chosen': -303.1657409667969, 'rewards/rejected': -316.7546081542969, 'rewards/accuracies': 0.6499999761581421, 'rewards/margins': 13.588801383972168, 'logps/rejected': -3558.93798828125, 'logps/chosen': -3414.197265625, 'logits/rejected': -2.9240972995758057, 'logits/chosen': -2.923884630203247, 'epoch': 1.13}
{'loss': 5.1282, 'grad_norm': 20.463702097367864, 'learning_rate': 0.0006472222222222223, 'rewards/chosen': -317.9054260253906, 'rewards/rejected': -318.9197692871094, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0143229961395264, 'logps/rejected': -3606.27392578125, 'logps/chosen': -3591.99609375, 'logits/rejected': -2.830477714538574, 'logits/chosen': -2.8305954933166504, 'epoch': 1.14}
{'loss': 5.9575, 'grad_norm': 44.77224975672518, 'learning_rate': 0.0006444444444444444, 'rewards/chosen': -291.87066650390625, 'rewards/rejected': -290.0748596191406, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -1.7958186864852905, 'logps/rejected': -3335.25146484375, 'logps/chosen': -3352.40087890625, 'logits/rejected': -2.8326683044433594, 'logits/chosen': -2.8325676918029785, 'epoch': 1.14}
{'loss': 4.7196, 'grad_norm': 32.19225833279976, 'learning_rate': 0.0006416666666666667, 'rewards/chosen': -273.94329833984375, 'rewards/rejected': -285.03509521484375, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 11.091797828674316, 'logps/rejected': -3249.66357421875, 'logps/chosen': -3117.241455078125, 'logits/rejected': -2.6167240142822266, 'logits/chosen': -2.6167778968811035, 'epoch': 1.15}
{'loss': 5.1164, 'grad_norm': 16.886273675497083, 'learning_rate': 0.0006388888888888888, 'rewards/chosen': -296.1595153808594, 'rewards/rejected': -300.6607971191406, 'rewards/accuracies': 0.625, 'rewards/margins': 4.501271724700928, 'logps/rejected': -3411.077392578125, 'logps/chosen': -3366.965576171875, 'logits/rejected': -2.6011366844177246, 'logits/chosen': -2.6009585857391357, 'epoch': 1.16}
{'loss': 7.7512, 'grad_norm': 59.323048690715375, 'learning_rate': 0.0006361111111111111, 'rewards/chosen': -282.891845703125, 'rewards/rejected': -287.9556579589844, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 5.063786029815674, 'logps/rejected': -3313.147216796875, 'logps/chosen': -3251.82958984375, 'logits/rejected': -2.929732084274292, 'logits/chosen': -2.929800271987915, 'epoch': 1.17}
{'loss': 6.2158, 'grad_norm': 13.032826316540671, 'learning_rate': 0.0006333333333333333, 'rewards/chosen': -294.16943359375, 'rewards/rejected': -291.78497314453125, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': -2.3844046592712402, 'logps/rejected': -3326.017578125, 'logps/chosen': -3358.885498046875, 'logits/rejected': -2.909421920776367, 'logits/chosen': -2.9092326164245605, 'epoch': 1.18}
{'loss': 6.5596, 'grad_norm': 58.99595451504332, 'learning_rate': 0.0006305555555555555, 'rewards/chosen': -293.6383056640625, 'rewards/rejected': -296.06927490234375, 'rewards/accuracies': 0.625, 'rewards/margins': 2.4309778213500977, 'logps/rejected': -3375.38134765625, 'logps/chosen': -3344.053466796875, 'logits/rejected': -2.793466329574585, 'logits/chosen': -2.793548345565796, 'epoch': 1.18}
{'loss': 4.5514, 'grad_norm': 19.140536602761138, 'learning_rate': 0.0006277777777777778, 'rewards/chosen': -288.83111572265625, 'rewards/rejected': -292.2671813964844, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': 3.4361026287078857, 'logps/rejected': -3354.672607421875, 'logps/chosen': -3321.106201171875, 'logits/rejected': -2.542600154876709, 'logits/chosen': -2.5429604053497314, 'epoch': 1.19}
{'loss': 6.4164, 'grad_norm': 23.93330839817176, 'learning_rate': 0.000625, 'rewards/chosen': -290.66900634765625, 'rewards/rejected': -287.34716796875, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': -3.321835994720459, 'logps/rejected': -3278.287109375, 'logps/chosen': -3308.87353515625, 'logits/rejected': -2.6236181259155273, 'logits/chosen': -2.6236860752105713, 'epoch': 1.2}
{'loss': 5.8368, 'grad_norm': 37.58554677603077, 'learning_rate': 0.0006222222222222223, 'rewards/chosen': -291.3800354003906, 'rewards/rejected': -296.10406494140625, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 4.7240214347839355, 'logps/rejected': -3372.21533203125, 'logps/chosen': -3320.21435546875, 'logits/rejected': -2.854613780975342, 'logits/chosen': -2.8542850017547607, 'epoch': 1.21}
{'loss': 6.8383, 'grad_norm': 34.44460587164659, 'learning_rate': 0.0006194444444444445, 'rewards/chosen': -293.47418212890625, 'rewards/rejected': -293.439453125, 'rewards/accuracies': 0.5, 'rewards/margins': -0.03473625332117081, 'logps/rejected': -3381.40966796875, 'logps/chosen': -3378.30615234375, 'logits/rejected': -2.9154534339904785, 'logits/chosen': -2.915522813796997, 'epoch': 1.22}
{'loss': 6.2636, 'grad_norm': 35.74969052899138, 'learning_rate': 0.0006166666666666667, 'rewards/chosen': -302.5542907714844, 'rewards/rejected': -298.85137939453125, 'rewards/accuracies': 0.5, 'rewards/margins': -3.7029521465301514, 'logps/rejected': -3402.968017578125, 'logps/chosen': -3448.76953125, 'logits/rejected': -3.0770678520202637, 'logits/chosen': -3.077099323272705, 'epoch': 1.22}
{'loss': 5.9338, 'grad_norm': 18.286707690295604, 'learning_rate': 0.000613888888888889, 'rewards/chosen': -283.8729553222656, 'rewards/rejected': -285.7838134765625, 'rewards/accuracies': 0.5, 'rewards/margins': 1.910875916481018, 'logps/rejected': -3230.03662109375, 'logps/chosen': -3204.89013671875, 'logits/rejected': -2.893536329269409, 'logits/chosen': -2.893491268157959, 'epoch': 1.23}
{'loss': 5.2556, 'grad_norm': 25.474755151380784, 'learning_rate': 0.0006111111111111112, 'rewards/chosen': -298.12017822265625, 'rewards/rejected': -299.66009521484375, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 1.5399692058563232, 'logps/rejected': -3470.686767578125, 'logps/chosen': -3449.49755859375, 'logits/rejected': -2.900698184967041, 'logits/chosen': -2.9008965492248535, 'epoch': 1.24}
{'loss': 5.8898, 'grad_norm': 45.77193437548451, 'learning_rate': 0.0006083333333333333, 'rewards/chosen': -288.836669921875, 'rewards/rejected': -295.79302978515625, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': 6.95632266998291, 'logps/rejected': -3397.296142578125, 'logps/chosen': -3322.1875, 'logits/rejected': -2.922475814819336, 'logits/chosen': -2.92229962348938, 'epoch': 1.25}
{'loss': 5.3545, 'grad_norm': 36.917982726478854, 'learning_rate': 0.0006055555555555556, 'rewards/chosen': -302.88861083984375, 'rewards/rejected': -303.7906188964844, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 0.902026355266571, 'logps/rejected': -3433.868408203125, 'logps/chosen': -3424.35107421875, 'logits/rejected': -2.954277753829956, 'logits/chosen': -2.9545276165008545, 'epoch': 1.26}
{'loss': 5.758, 'grad_norm': 19.584931136668533, 'learning_rate': 0.0006027777777777777, 'rewards/chosen': -289.50872802734375, 'rewards/rejected': -293.7457580566406, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 4.237052917480469, 'logps/rejected': -3339.885986328125, 'logps/chosen': -3296.08154296875, 'logits/rejected': -2.9107205867767334, 'logits/chosen': -2.9106202125549316, 'epoch': 1.26}
{'loss': 9.5309, 'grad_norm': 54.85770313347655, 'learning_rate': 0.0006, 'rewards/chosen': -281.23388671875, 'rewards/rejected': -277.0468444824219, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -4.187003135681152, 'logps/rejected': -3223.9609375, 'logps/chosen': -3255.73046875, 'logits/rejected': -2.8027920722961426, 'logits/chosen': -2.802722215652466, 'epoch': 1.27}
{'loss': 5.5658, 'grad_norm': 34.99448578113835, 'learning_rate': 0.0005972222222222222, 'rewards/chosen': -294.33746337890625, 'rewards/rejected': -285.5834655761719, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -8.753969192504883, 'logps/rejected': -3320.0546875, 'logps/chosen': -3421.145263671875, 'logits/rejected': -2.728980541229248, 'logits/chosen': -2.7288520336151123, 'epoch': 1.28}
{'loss': 5.3493, 'grad_norm': 30.632525114330992, 'learning_rate': 0.0005944444444444444, 'rewards/chosen': -297.12384033203125, 'rewards/rejected': -305.28509521484375, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 8.161297798156738, 'logps/rejected': -3474.461669921875, 'logps/chosen': -3380.849609375, 'logits/rejected': -2.633244276046753, 'logits/chosen': -2.6330604553222656, 'epoch': 1.29}
{'loss': 7.1613, 'grad_norm': 38.60792017007525, 'learning_rate': 0.0005916666666666667, 'rewards/chosen': -269.0761413574219, 'rewards/rejected': -271.68182373046875, 'rewards/accuracies': 0.6499999761581421, 'rewards/margins': 2.605687141418457, 'logps/rejected': -3123.38525390625, 'logps/chosen': -3096.438720703125, 'logits/rejected': -2.827176570892334, 'logits/chosen': -2.8272159099578857, 'epoch': 1.3}
{'loss': 6.8946, 'grad_norm': 36.67045841901368, 'learning_rate': 0.0005888888888888889, 'rewards/chosen': -298.2682800292969, 'rewards/rejected': -304.62628173828125, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': 6.357993125915527, 'logps/rejected': -3481.49853515625, 'logps/chosen': -3402.18701171875, 'logits/rejected': -3.027784824371338, 'logits/chosen': -3.02785062789917, 'epoch': 1.3}
{'loss': 6.638, 'grad_norm': 27.478169228820864, 'learning_rate': 0.0005861111111111111, 'rewards/chosen': -298.67169189453125, 'rewards/rejected': -300.11749267578125, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 1.4458049535751343, 'logps/rejected': -3442.907470703125, 'logps/chosen': -3421.924560546875, 'logits/rejected': -2.8478763103485107, 'logits/chosen': -2.8477745056152344, 'epoch': 1.31}
{'loss': 6.2862, 'grad_norm': 29.272035264213965, 'learning_rate': 0.0005833333333333334, 'rewards/chosen': -274.83038330078125, 'rewards/rejected': -276.29852294921875, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': 1.468136191368103, 'logps/rejected': -3180.35107421875, 'logps/chosen': -3148.222900390625, 'logits/rejected': -2.808795213699341, 'logits/chosen': -2.8085453510284424, 'epoch': 1.32}
{'loss': 4.4984, 'grad_norm': 23.184920505076335, 'learning_rate': 0.0005805555555555556, 'rewards/chosen': -305.20538330078125, 'rewards/rejected': -302.6974182128906, 'rewards/accuracies': 0.5, 'rewards/margins': -2.5080032348632812, 'logps/rejected': -3471.841064453125, 'logps/chosen': -3494.13720703125, 'logits/rejected': -2.755007266998291, 'logits/chosen': -2.7550222873687744, 'epoch': 1.33}
{'loss': 4.3212, 'grad_norm': 31.350081015633325, 'learning_rate': 0.0005777777777777778, 'rewards/chosen': -289.04925537109375, 'rewards/rejected': -294.4209899902344, 'rewards/accuracies': 0.3499999940395355, 'rewards/margins': 5.371776580810547, 'logps/rejected': -3360.62744140625, 'logps/chosen': -3296.94091796875, 'logits/rejected': -2.9919168949127197, 'logits/chosen': -2.9917690753936768, 'epoch': 1.34}
{'loss': 6.8035, 'grad_norm': 20.824314605329075, 'learning_rate': 0.000575, 'rewards/chosen': -283.29229736328125, 'rewards/rejected': -284.93963623046875, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': 1.6472997665405273, 'logps/rejected': -3298.30615234375, 'logps/chosen': -3270.882080078125, 'logits/rejected': -3.085164785385132, 'logits/chosen': -3.0851879119873047, 'epoch': 1.34}
{'loss': 4.8321, 'grad_norm': 43.46635331701438, 'learning_rate': 0.0005722222222222222, 'rewards/chosen': -285.71173095703125, 'rewards/rejected': -287.227783203125, 'rewards/accuracies': 0.5, 'rewards/margins': 1.5160179138183594, 'logps/rejected': -3262.725830078125, 'logps/chosen': -3246.170166015625, 'logits/rejected': -2.9909145832061768, 'logits/chosen': -2.9907302856445312, 'epoch': 1.35}
{'loss': 4.7651, 'grad_norm': 42.66546270799769, 'learning_rate': 0.0005694444444444445, 'rewards/chosen': -283.60687255859375, 'rewards/rejected': -297.70440673828125, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 14.097514152526855, 'logps/rejected': -3361.965576171875, 'logps/chosen': -3194.577392578125, 'logits/rejected': -2.811732769012451, 'logits/chosen': -2.811519145965576, 'epoch': 1.36}
{'loss': 4.7526, 'grad_norm': 31.565479061864014, 'learning_rate': 0.0005666666666666667, 'rewards/chosen': -293.57293701171875, 'rewards/rejected': -299.83868408203125, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 6.265720367431641, 'logps/rejected': -3449.78955078125, 'logps/chosen': -3364.833251953125, 'logits/rejected': -2.640392541885376, 'logits/chosen': -2.6404075622558594, 'epoch': 1.37}
{'loss': 5.4644, 'grad_norm': 24.812676969520954, 'learning_rate': 0.000563888888888889, 'rewards/chosen': -288.4385681152344, 'rewards/rejected': -292.53558349609375, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': 4.097029209136963, 'logps/rejected': -3381.643798828125, 'logps/chosen': -3329.255126953125, 'logits/rejected': -2.7211484909057617, 'logits/chosen': -2.7212843894958496, 'epoch': 1.38}
{'loss': 6.3929, 'grad_norm': 42.11265337997232, 'learning_rate': 0.0005611111111111111, 'rewards/chosen': -279.66510009765625, 'rewards/rejected': -287.27447509765625, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 7.609377861022949, 'logps/rejected': -3365.91796875, 'logps/chosen': -3287.547607421875, 'logits/rejected': -2.8976285457611084, 'logits/chosen': -2.8977982997894287, 'epoch': 1.38}
{'loss': 6.7593, 'grad_norm': 26.66474253054082, 'learning_rate': 0.0005583333333333333, 'rewards/chosen': -291.63934326171875, 'rewards/rejected': -292.02728271484375, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': 0.3879329562187195, 'logps/rejected': -3348.17626953125, 'logps/chosen': -3346.11962890625, 'logits/rejected': -2.8796496391296387, 'logits/chosen': -2.879676103591919, 'epoch': 1.39}
{'loss': 7.3545, 'grad_norm': 86.63642432392423, 'learning_rate': 0.0005555555555555556, 'rewards/chosen': -266.8619384765625, 'rewards/rejected': -275.90338134765625, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 9.041455268859863, 'logps/rejected': -3183.999267578125, 'logps/chosen': -3079.27197265625, 'logits/rejected': -2.9034502506256104, 'logits/chosen': -2.9033539295196533, 'epoch': 1.4}
{'loss': 6.0319, 'grad_norm': 17.714604552404897, 'learning_rate': 0.0005527777777777778, 'rewards/chosen': -295.29302978515625, 'rewards/rejected': -306.7335205078125, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 11.44047737121582, 'logps/rejected': -3462.74853515625, 'logps/chosen': -3344.059326171875, 'logits/rejected': -2.880380153656006, 'logits/chosen': -2.8804290294647217, 'epoch': 1.41}
{'loss': 4.7947, 'grad_norm': 12.860393760973022, 'learning_rate': 0.00055, 'rewards/chosen': -280.837890625, 'rewards/rejected': -288.84246826171875, 'rewards/accuracies': 0.675000011920929, 'rewards/margins': 8.004612922668457, 'logps/rejected': -3338.71533203125, 'logps/chosen': -3249.95947265625, 'logits/rejected': -2.6539700031280518, 'logits/chosen': -2.653939962387085, 'epoch': 1.42}
{'loss': 5.4457, 'grad_norm': 34.40947777123266, 'learning_rate': 0.0005472222222222223, 'rewards/chosen': -299.8970947265625, 'rewards/rejected': -298.572265625, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': -1.3248459100723267, 'logps/rejected': -3382.268798828125, 'logps/chosen': -3390.14599609375, 'logits/rejected': -2.6858766078948975, 'logits/chosen': -2.68565034866333, 'epoch': 1.42}
{'loss': 7.5438, 'grad_norm': 29.342380641702633, 'learning_rate': 0.0005444444444444444, 'rewards/chosen': -278.2164306640625, 'rewards/rejected': -277.630615234375, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': -0.5858398675918579, 'logps/rejected': -3236.876708984375, 'logps/chosen': -3242.38134765625, 'logits/rejected': -2.8535077571868896, 'logits/chosen': -2.853428363800049, 'epoch': 1.43}
{'loss': 7.9286, 'grad_norm': 45.29681702925306, 'learning_rate': 0.0005416666666666666, 'rewards/chosen': -286.0931701660156, 'rewards/rejected': -286.76312255859375, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': 0.6699374914169312, 'logps/rejected': -3402.203857421875, 'logps/chosen': -3391.016357421875, 'logits/rejected': -3.1169986724853516, 'logits/chosen': -3.117063522338867, 'epoch': 1.44}
{'loss': 7.1182, 'grad_norm': 55.05176935317811, 'learning_rate': 0.0005388888888888889, 'rewards/chosen': -304.52606201171875, 'rewards/rejected': -296.92950439453125, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': -7.5965895652771, 'logps/rejected': -3434.197265625, 'logps/chosen': -3503.71337890625, 'logits/rejected': -3.097069263458252, 'logits/chosen': -3.097045421600342, 'epoch': 1.45}
{'loss': 9.4246, 'grad_norm': 25.5974110346792, 'learning_rate': 0.0005361111111111111, 'rewards/chosen': -301.9410095214844, 'rewards/rejected': -296.80029296875, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -5.1407365798950195, 'logps/rejected': -3416.2890625, 'logps/chosen': -3469.177734375, 'logits/rejected': -3.0591700077056885, 'logits/chosen': -3.0588765144348145, 'epoch': 1.46}
{'loss': 7.2205, 'grad_norm': 44.13076736197042, 'learning_rate': 0.0005333333333333334, 'rewards/chosen': -289.40130615234375, 'rewards/rejected': -287.4475402832031, 'rewards/accuracies': 0.5, 'rewards/margins': -1.953796625137329, 'logps/rejected': -3243.03759765625, 'logps/chosen': -3262.32861328125, 'logits/rejected': -2.847355604171753, 'logits/chosen': -2.8474583625793457, 'epoch': 1.46}
{'loss': 6.16, 'grad_norm': 24.702086082947712, 'learning_rate': 0.0005305555555555556, 'rewards/chosen': -284.46282958984375, 'rewards/rejected': -292.75006103515625, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 8.287248611450195, 'logps/rejected': -3363.49853515625, 'logps/chosen': -3271.13037109375, 'logits/rejected': -2.7948756217956543, 'logits/chosen': -2.7951550483703613, 'epoch': 1.47}
{'loss': 8.0676, 'grad_norm': 31.1544366374161, 'learning_rate': 0.0005277777777777778, 'rewards/chosen': -281.7395324707031, 'rewards/rejected': -289.2516784667969, 'rewards/accuracies': 0.5, 'rewards/margins': 7.5121355056762695, 'logps/rejected': -3332.127685546875, 'logps/chosen': -3242.18505859375, 'logits/rejected': -2.788870096206665, 'logits/chosen': -2.788569927215576, 'epoch': 1.48}
{'loss': 6.4092, 'grad_norm': 16.988364962707905, 'learning_rate': 0.0005250000000000001, 'rewards/chosen': -275.1619567871094, 'rewards/rejected': -271.8421325683594, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': -3.3198254108428955, 'logps/rejected': -3123.88134765625, 'logps/chosen': -3150.254150390625, 'logits/rejected': -2.924513339996338, 'logits/chosen': -2.924617290496826, 'epoch': 1.49}
{'loss': 4.3046, 'grad_norm': 24.431920356820637, 'learning_rate': 0.0005222222222222223, 'rewards/chosen': -271.9736633300781, 'rewards/rejected': -276.88311767578125, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 4.909486293792725, 'logps/rejected': -3194.641357421875, 'logps/chosen': -3134.71728515625, 'logits/rejected': -3.017214298248291, 'logits/chosen': -3.0171680450439453, 'epoch': 1.5}
{'loss': 4.304, 'grad_norm': 22.393877193739232, 'learning_rate': 0.0005194444444444444, 'rewards/chosen': -293.5113220214844, 'rewards/rejected': -291.00994873046875, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': -2.501417398452759, 'logps/rejected': -3318.370361328125, 'logps/chosen': -3342.58544921875, 'logits/rejected': -3.034635305404663, 'logits/chosen': -3.034613847732544, 'epoch': 1.5}
{'loss': 3.2212, 'grad_norm': 40.16671902352473, 'learning_rate': 0.0005166666666666667, 'rewards/chosen': -280.80615234375, 'rewards/rejected': -284.1542663574219, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 3.348112106323242, 'logps/rejected': -3350.189453125, 'logps/chosen': -3304.879638671875, 'logits/rejected': -2.969477653503418, 'logits/chosen': -2.9691977500915527, 'epoch': 1.51}
{'loss': 5.4363, 'grad_norm': 47.04583308960076, 'learning_rate': 0.0005138888888888888, 'rewards/chosen': -286.9694519042969, 'rewards/rejected': -294.2218933105469, 'rewards/accuracies': 0.625, 'rewards/margins': 7.252455234527588, 'logps/rejected': -3330.67236328125, 'logps/chosen': -3253.22119140625, 'logits/rejected': -3.0105831623077393, 'logits/chosen': -3.0105371475219727, 'epoch': 1.52}
{'loss': 3.8447, 'grad_norm': 31.6536436672561, 'learning_rate': 0.0005111111111111111, 'rewards/chosen': -299.946044921875, 'rewards/rejected': -302.5623474121094, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': 2.6162989139556885, 'logps/rejected': -3525.260498046875, 'logps/chosen': -3500.311767578125, 'logits/rejected': -2.9368460178375244, 'logits/chosen': -2.9369256496429443, 'epoch': 1.53}
{'loss': 6.2571, 'grad_norm': 16.72578930787228, 'learning_rate': 0.0005083333333333333, 'rewards/chosen': -294.89837646484375, 'rewards/rejected': -297.36053466796875, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 2.4621634483337402, 'logps/rejected': -3378.885498046875, 'logps/chosen': -3349.180419921875, 'logits/rejected': -2.8826351165771484, 'logits/chosen': -2.8828744888305664, 'epoch': 1.54}
{'loss': 4.7425, 'grad_norm': 50.95847420889445, 'learning_rate': 0.0005055555555555555, 'rewards/chosen': -277.37176513671875, 'rewards/rejected': -287.13043212890625, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 9.75865364074707, 'logps/rejected': -3288.184326171875, 'logps/chosen': -3172.287841796875, 'logits/rejected': -3.0355310440063477, 'logits/chosen': -3.035573720932007, 'epoch': 1.54}
{'loss': 4.8055, 'grad_norm': 38.997745869432045, 'learning_rate': 0.0005027777777777778, 'rewards/chosen': -276.55548095703125, 'rewards/rejected': -289.34356689453125, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 12.788103103637695, 'logps/rejected': -3299.735595703125, 'logps/chosen': -3157.82080078125, 'logits/rejected': -3.100968837738037, 'logits/chosen': -3.1008667945861816, 'epoch': 1.55}
{'loss': 7.5943, 'grad_norm': 33.52334334996689, 'learning_rate': 0.0005, 'rewards/chosen': -286.65863037109375, 'rewards/rejected': -295.4580993652344, 'rewards/accuracies': 0.6499999761581421, 'rewards/margins': 8.799445152282715, 'logps/rejected': -3303.66845703125, 'logps/chosen': -3202.7763671875, 'logits/rejected': -2.958496570587158, 'logits/chosen': -2.9586477279663086, 'epoch': 1.56}
{'loss': 7.9499, 'grad_norm': 42.59380466924825, 'learning_rate': 0.0004972222222222222, 'rewards/chosen': -272.7516174316406, 'rewards/rejected': -266.5711975097656, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -6.180422782897949, 'logps/rejected': -3120.944091796875, 'logps/chosen': -3183.0966796875, 'logits/rejected': -2.793698787689209, 'logits/chosen': -2.7938058376312256, 'epoch': 1.57}
{'loss': 5.2855, 'grad_norm': 31.570732035870186, 'learning_rate': 0.0004944444444444445, 'rewards/chosen': -291.6387939453125, 'rewards/rejected': -292.98663330078125, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 1.34783136844635, 'logps/rejected': -3359.942138671875, 'logps/chosen': -3346.74560546875, 'logits/rejected': -2.8166465759277344, 'logits/chosen': -2.8165054321289062, 'epoch': 1.58}
{'loss': 4.9544, 'grad_norm': 28.89828684487753, 'learning_rate': 0.0004916666666666666, 'rewards/chosen': -271.5040588378906, 'rewards/rejected': -279.82891845703125, 'rewards/accuracies': 0.625, 'rewards/margins': 8.324851036071777, 'logps/rejected': -3239.098388671875, 'logps/chosen': -3139.51025390625, 'logits/rejected': -2.9183592796325684, 'logits/chosen': -2.918203115463257, 'epoch': 1.58}
{'loss': 6.2117, 'grad_norm': 36.644285110004944, 'learning_rate': 0.0004888888888888889, 'rewards/chosen': -281.5580139160156, 'rewards/rejected': -288.13043212890625, 'rewards/accuracies': 0.625, 'rewards/margins': 6.572405815124512, 'logps/rejected': -3281.193359375, 'logps/chosen': -3208.80419921875, 'logits/rejected': -2.946488618850708, 'logits/chosen': -2.946439504623413, 'epoch': 1.59}
{'loss': 6.6231, 'grad_norm': 25.796220859864817, 'learning_rate': 0.0004861111111111111, 'rewards/chosen': -272.189453125, 'rewards/rejected': -271.0296936035156, 'rewards/accuracies': 0.5, 'rewards/margins': -1.1597506999969482, 'logps/rejected': -3168.680908203125, 'logps/chosen': -3191.00537109375, 'logits/rejected': -2.8333256244659424, 'logits/chosen': -2.8333678245544434, 'epoch': 1.6}
{'loss': 5.8615, 'grad_norm': 36.37011970845791, 'learning_rate': 0.00048333333333333334, 'rewards/chosen': -278.38372802734375, 'rewards/rejected': -289.19573974609375, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 10.812031745910645, 'logps/rejected': -3310.496826171875, 'logps/chosen': -3195.8134765625, 'logits/rejected': -2.7410969734191895, 'logits/chosen': -2.7411608695983887, 'epoch': 1.61}
{'loss': 3.7938, 'grad_norm': 27.2232340290501, 'learning_rate': 0.0004805555555555556, 'rewards/chosen': -282.53851318359375, 'rewards/rejected': -284.7546081542969, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': 2.2161331176757812, 'logps/rejected': -3341.510498046875, 'logps/chosen': -3309.04443359375, 'logits/rejected': -2.901095390319824, 'logits/chosen': -2.900989532470703, 'epoch': 1.62}
{'loss': 5.7481, 'grad_norm': 46.7639887552298, 'learning_rate': 0.0004777777777777778, 'rewards/chosen': -282.41668701171875, 'rewards/rejected': -291.997802734375, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': 9.581121444702148, 'logps/rejected': -3341.756591796875, 'logps/chosen': -3237.945556640625, 'logits/rejected': -3.048029661178589, 'logits/chosen': -3.0481250286102295, 'epoch': 1.62}
{'loss': 5.4439, 'grad_norm': 27.187769468941433, 'learning_rate': 0.000475, 'rewards/chosen': -294.9397888183594, 'rewards/rejected': -295.1665954589844, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': 0.22683200240135193, 'logps/rejected': -3371.720703125, 'logps/chosen': -3372.11328125, 'logits/rejected': -2.9144415855407715, 'logits/chosen': -2.914639949798584, 'epoch': 1.63}
{'loss': 4.9376, 'grad_norm': 24.68861479040838, 'learning_rate': 0.00047222222222222224, 'rewards/chosen': -282.23089599609375, 'rewards/rejected': -283.5209045410156, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': 1.2900593280792236, 'logps/rejected': -3261.4189453125, 'logps/chosen': -3242.860107421875, 'logits/rejected': -2.67818021774292, 'logits/chosen': -2.678424596786499, 'epoch': 1.64}
{'loss': 4.668, 'grad_norm': 48.05225603125811, 'learning_rate': 0.0004694444444444445, 'rewards/chosen': -277.5015563964844, 'rewards/rejected': -288.08367919921875, 'rewards/accuracies': 0.6499999761581421, 'rewards/margins': 10.58211898803711, 'logps/rejected': -3278.92041015625, 'logps/chosen': -3166.63916015625, 'logits/rejected': -2.723454713821411, 'logits/chosen': -2.722978353500366, 'epoch': 1.65}
{'loss': 5.0886, 'grad_norm': 38.378033754750646, 'learning_rate': 0.00046666666666666666, 'rewards/chosen': -281.1181945800781, 'rewards/rejected': -287.7716369628906, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 6.653436183929443, 'logps/rejected': -3295.280029296875, 'logps/chosen': -3220.8515625, 'logits/rejected': -2.903352737426758, 'logits/chosen': -2.903445243835449, 'epoch': 1.66}
{'loss': 8.7885, 'grad_norm': 35.81677655103149, 'learning_rate': 0.0004638888888888889, 'rewards/chosen': -278.2877502441406, 'rewards/rejected': -278.68231201171875, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 0.3945499360561371, 'logps/rejected': -3183.168701171875, 'logps/chosen': -3162.78564453125, 'logits/rejected': -2.9904580116271973, 'logits/chosen': -2.99035382270813, 'epoch': 1.66}
{'loss': 5.1997, 'grad_norm': 37.75944984481702, 'learning_rate': 0.00046111111111111114, 'rewards/chosen': -281.62335205078125, 'rewards/rejected': -283.49609375, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 1.872754693031311, 'logps/rejected': -3264.35888671875, 'logps/chosen': -3237.26708984375, 'logits/rejected': -3.011233329772949, 'logits/chosen': -3.0113542079925537, 'epoch': 1.67}
{'loss': 5.201, 'grad_norm': 23.323891818873193, 'learning_rate': 0.0004583333333333333, 'rewards/chosen': -264.9914855957031, 'rewards/rejected': -272.14471435546875, 'rewards/accuracies': 0.5, 'rewards/margins': 7.153214454650879, 'logps/rejected': -3167.6533203125, 'logps/chosen': -3088.166259765625, 'logits/rejected': -2.898695468902588, 'logits/chosen': -2.8985304832458496, 'epoch': 1.68}
{'loss': 5.9161, 'grad_norm': 44.18208113811566, 'learning_rate': 0.00045555555555555556, 'rewards/chosen': -283.46466064453125, 'rewards/rejected': -282.70086669921875, 'rewards/accuracies': 0.5, 'rewards/margins': -0.7637988924980164, 'logps/rejected': -3296.06884765625, 'logps/chosen': -3306.448486328125, 'logits/rejected': -2.882575035095215, 'logits/chosen': -2.8829097747802734, 'epoch': 1.69}
{'loss': 5.0345, 'grad_norm': 36.34416803112391, 'learning_rate': 0.0004527777777777778, 'rewards/chosen': -277.12738037109375, 'rewards/rejected': -281.43963623046875, 'rewards/accuracies': 0.625, 'rewards/margins': 4.312211036682129, 'logps/rejected': -3242.117919921875, 'logps/chosen': -3198.861572265625, 'logits/rejected': -3.1335346698760986, 'logits/chosen': -3.1336112022399902, 'epoch': 1.7}
{'loss': 5.0354, 'grad_norm': 23.205446668751808, 'learning_rate': 0.00045000000000000004, 'rewards/chosen': -280.0069274902344, 'rewards/rejected': -283.3636779785156, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': 3.3567447662353516, 'logps/rejected': -3266.05712890625, 'logps/chosen': -3228.13330078125, 'logits/rejected': -3.162818431854248, 'logits/chosen': -3.162797451019287, 'epoch': 1.7}
{'loss': 4.5393, 'grad_norm': 14.823877070401597, 'learning_rate': 0.0004472222222222222, 'rewards/chosen': -287.44891357421875, 'rewards/rejected': -294.9716796875, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 7.5227837562561035, 'logps/rejected': -3353.520263671875, 'logps/chosen': -3266.733642578125, 'logits/rejected': -2.9863312244415283, 'logits/chosen': -2.986506700515747, 'epoch': 1.71}
{'loss': 6.404, 'grad_norm': 51.54842786919624, 'learning_rate': 0.0004444444444444444, 'rewards/chosen': -291.0635070800781, 'rewards/rejected': -293.06640625, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 2.0029029846191406, 'logps/rejected': -3305.36181640625, 'logps/chosen': -3283.295654296875, 'logits/rejected': -3.016068935394287, 'logits/chosen': -3.016278028488159, 'epoch': 1.72}
{'loss': 5.6011, 'grad_norm': 38.85359689263313, 'learning_rate': 0.00044166666666666665, 'rewards/chosen': -287.40093994140625, 'rewards/rejected': -297.80010986328125, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 10.399187088012695, 'logps/rejected': -3381.162841796875, 'logps/chosen': -3258.4453125, 'logits/rejected': -3.102186918258667, 'logits/chosen': -3.101959705352783, 'epoch': 1.73}
{'loss': 6.8243, 'grad_norm': 37.47614793874468, 'learning_rate': 0.0004388888888888889, 'rewards/chosen': -304.295166015625, 'rewards/rejected': -305.18389892578125, 'rewards/accuracies': 0.5, 'rewards/margins': 0.888719916343689, 'logps/rejected': -3436.897216796875, 'logps/chosen': -3428.123779296875, 'logits/rejected': -2.9527194499969482, 'logits/chosen': -2.952641248703003, 'epoch': 1.74}
{'loss': 5.8329, 'grad_norm': 40.639356220208825, 'learning_rate': 0.00043611111111111113, 'rewards/chosen': -275.5271301269531, 'rewards/rejected': -282.0777893066406, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 6.5506391525268555, 'logps/rejected': -3283.47119140625, 'logps/chosen': -3214.07861328125, 'logits/rejected': -2.8644816875457764, 'logits/chosen': -2.8646693229675293, 'epoch': 1.74}
{'loss': 5.1945, 'grad_norm': 32.147133799995274, 'learning_rate': 0.00043333333333333337, 'rewards/chosen': -292.9327392578125, 'rewards/rejected': -289.8647155761719, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -3.0680060386657715, 'logps/rejected': -3277.861328125, 'logps/chosen': -3304.783935546875, 'logits/rejected': -2.9609622955322266, 'logits/chosen': -2.960948944091797, 'epoch': 1.75}
{'loss': 5.6982, 'grad_norm': 47.24269229593362, 'learning_rate': 0.0004305555555555556, 'rewards/chosen': -288.23553466796875, 'rewards/rejected': -291.0365905761719, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': 2.801039218902588, 'logps/rejected': -3364.62646484375, 'logps/chosen': -3329.41552734375, 'logits/rejected': -2.894906520843506, 'logits/chosen': -2.8946051597595215, 'epoch': 1.76}
{'loss': 4.9353, 'grad_norm': 31.450415008691653, 'learning_rate': 0.0004277777777777778, 'rewards/chosen': -304.2497863769531, 'rewards/rejected': -303.8000793457031, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': -0.4497360289096832, 'logps/rejected': -3462.57763671875, 'logps/chosen': -3462.876953125, 'logits/rejected': -2.736644744873047, 'logits/chosen': -2.736943006515503, 'epoch': 1.77}
{'loss': 3.7791, 'grad_norm': 23.621615059000277, 'learning_rate': 0.000425, 'rewards/chosen': -317.7787170410156, 'rewards/rejected': -316.5619812011719, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': -1.2167155742645264, 'logps/rejected': -3582.22021484375, 'logps/chosen': -3587.09814453125, 'logits/rejected': -2.6180500984191895, 'logits/chosen': -2.618142604827881, 'epoch': 1.78}
{'loss': 3.8923, 'grad_norm': 21.036021842560686, 'learning_rate': 0.0004222222222222222, 'rewards/chosen': -278.48223876953125, 'rewards/rejected': -277.95843505859375, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': -0.523790180683136, 'logps/rejected': -3225.836181640625, 'logps/chosen': -3223.88720703125, 'logits/rejected': -2.687746047973633, 'logits/chosen': -2.687730550765991, 'epoch': 1.78}
{'loss': 6.9261, 'grad_norm': 43.80322030801796, 'learning_rate': 0.00041944444444444445, 'rewards/chosen': -304.72052001953125, 'rewards/rejected': -310.0635070800781, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 5.342982292175293, 'logps/rejected': -3547.173828125, 'logps/chosen': -3491.46240234375, 'logits/rejected': -2.8219733238220215, 'logits/chosen': -2.8222289085388184, 'epoch': 1.79}
{'loss': 4.7759, 'grad_norm': 33.9374549379721, 'learning_rate': 0.0004166666666666667, 'rewards/chosen': -270.97308349609375, 'rewards/rejected': -283.9407653808594, 'rewards/accuracies': 0.5, 'rewards/margins': 12.967721939086914, 'logps/rejected': -3240.551513671875, 'logps/chosen': -3104.141357421875, 'logits/rejected': -3.0690226554870605, 'logits/chosen': -3.0689339637756348, 'epoch': 1.8}
{'loss': 4.2576, 'grad_norm': 25.675970530386518, 'learning_rate': 0.0004138888888888889, 'rewards/chosen': -277.1490173339844, 'rewards/rejected': -275.18426513671875, 'rewards/accuracies': 0.3499999940395355, 'rewards/margins': -1.964776635169983, 'logps/rejected': -3227.354736328125, 'logps/chosen': -3244.11865234375, 'logits/rejected': -3.1479077339172363, 'logits/chosen': -3.1481237411499023, 'epoch': 1.81}
{'loss': 5.904, 'grad_norm': 36.560391850319746, 'learning_rate': 0.0004111111111111111, 'rewards/chosen': -293.19024658203125, 'rewards/rejected': -293.163818359375, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -0.026373673230409622, 'logps/rejected': -3381.106201171875, 'logps/chosen': -3374.539794921875, 'logits/rejected': -2.9515066146850586, 'logits/chosen': -2.9513635635375977, 'epoch': 1.82}
{'loss': 5.86, 'grad_norm': 53.37851704586936, 'learning_rate': 0.00040833333333333336, 'rewards/chosen': -296.73016357421875, 'rewards/rejected': -295.39801025390625, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': -1.3321564197540283, 'logps/rejected': -3396.688720703125, 'logps/chosen': -3405.2421875, 'logits/rejected': -2.8428804874420166, 'logits/chosen': -2.843201160430908, 'epoch': 1.82}
{'loss': 4.2301, 'grad_norm': 21.31260174163357, 'learning_rate': 0.00040555555555555554, 'rewards/chosen': -291.9777526855469, 'rewards/rejected': -294.0373229980469, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 2.059574604034424, 'logps/rejected': -3379.30078125, 'logps/chosen': -3348.163330078125, 'logits/rejected': -2.8457674980163574, 'logits/chosen': -2.845524311065674, 'epoch': 1.83}
{'loss': 4.7434, 'grad_norm': 27.212609938056477, 'learning_rate': 0.0004027777777777778, 'rewards/chosen': -288.2031555175781, 'rewards/rejected': -291.1399230957031, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 2.9367523193359375, 'logps/rejected': -3342.500732421875, 'logps/chosen': -3306.01171875, 'logits/rejected': -2.767805576324463, 'logits/chosen': -2.7679903507232666, 'epoch': 1.84}
{'loss': 7.0931, 'grad_norm': 19.89621902083038, 'learning_rate': 0.0004, 'rewards/chosen': -292.2090148925781, 'rewards/rejected': -297.9997863769531, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 5.79076623916626, 'logps/rejected': -3398.240966796875, 'logps/chosen': -3332.578125, 'logits/rejected': -2.808628559112549, 'logits/chosen': -2.808722972869873, 'epoch': 1.85}
{'loss': 5.1014, 'grad_norm': 32.82604451950389, 'learning_rate': 0.0003972222222222222, 'rewards/chosen': -286.88922119140625, 'rewards/rejected': -283.69488525390625, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -3.194336414337158, 'logps/rejected': -3217.076171875, 'logps/chosen': -3240.10986328125, 'logits/rejected': -2.9275975227355957, 'logits/chosen': -2.927821636199951, 'epoch': 1.86}
{'loss': 7.509, 'grad_norm': 43.333426658379246, 'learning_rate': 0.00039444444444444444, 'rewards/chosen': -298.41326904296875, 'rewards/rejected': -290.7085876464844, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -7.704676151275635, 'logps/rejected': -3270.21533203125, 'logps/chosen': -3340.637939453125, 'logits/rejected': -2.95491886138916, 'logits/chosen': -2.955186367034912, 'epoch': 1.86}
{'loss': 6.6426, 'grad_norm': 39.198706625947295, 'learning_rate': 0.0003916666666666667, 'rewards/chosen': -290.52777099609375, 'rewards/rejected': -290.2820129394531, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': -0.245747372508049, 'logps/rejected': -3329.85400390625, 'logps/chosen': -3324.517578125, 'logits/rejected': -2.9179513454437256, 'logits/chosen': -2.917740821838379, 'epoch': 1.87}
{'loss': 6.2169, 'grad_norm': 34.28643747522456, 'learning_rate': 0.0003888888888888889, 'rewards/chosen': -278.8430480957031, 'rewards/rejected': -284.3402404785156, 'rewards/accuracies': 0.625, 'rewards/margins': 5.497193336486816, 'logps/rejected': -3258.563720703125, 'logps/chosen': -3191.081298828125, 'logits/rejected': -2.994231939315796, 'logits/chosen': -2.99424147605896, 'epoch': 1.88}
{'loss': 7.5326, 'grad_norm': 16.700920332172043, 'learning_rate': 0.00038611111111111116, 'rewards/chosen': -270.1269226074219, 'rewards/rejected': -273.7471618652344, 'rewards/accuracies': 0.625, 'rewards/margins': 3.6202144622802734, 'logps/rejected': -3146.568115234375, 'logps/chosen': -3103.280029296875, 'logits/rejected': -2.9960851669311523, 'logits/chosen': -2.996264934539795, 'epoch': 1.89}
{'loss': 5.5492, 'grad_norm': 33.176744744311414, 'learning_rate': 0.00038333333333333334, 'rewards/chosen': -276.718505859375, 'rewards/rejected': -277.4488525390625, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': 0.7303463220596313, 'logps/rejected': -3267.534423828125, 'logps/chosen': -3263.29052734375, 'logits/rejected': -2.8604202270507812, 'logits/chosen': -2.860544443130493, 'epoch': 1.9}
{'loss': 5.5133, 'grad_norm': 14.232943178480228, 'learning_rate': 0.00038055555555555553, 'rewards/chosen': -267.52130126953125, 'rewards/rejected': -274.8741149902344, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 7.352855682373047, 'logps/rejected': -3206.480224609375, 'logps/chosen': -3132.178955078125, 'logits/rejected': -2.7480669021606445, 'logits/chosen': -2.748072385787964, 'epoch': 1.9}
{'loss': 5.2623, 'grad_norm': 40.563950014670624, 'learning_rate': 0.00037777777777777777, 'rewards/chosen': -281.94586181640625, 'rewards/rejected': -278.5514221191406, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -3.3944363594055176, 'logps/rejected': -3193.332275390625, 'logps/chosen': -3229.307373046875, 'logits/rejected': -2.7098402976989746, 'logits/chosen': -2.7098326683044434, 'epoch': 1.91}
{'loss': 4.5775, 'grad_norm': 27.54152759123145, 'learning_rate': 0.000375, 'rewards/chosen': -266.09967041015625, 'rewards/rejected': -272.2657775878906, 'rewards/accuracies': 0.32499998807907104, 'rewards/margins': 6.166110515594482, 'logps/rejected': -3225.94921875, 'logps/chosen': -3158.19677734375, 'logits/rejected': -2.656022787094116, 'logits/chosen': -2.6560111045837402, 'epoch': 1.92}
{'loss': 3.7707, 'grad_norm': 28.487051069296374, 'learning_rate': 0.00037222222222222225, 'rewards/chosen': -270.90386962890625, 'rewards/rejected': -276.91912841796875, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 6.015248775482178, 'logps/rejected': -3194.585205078125, 'logps/chosen': -3136.3359375, 'logits/rejected': -2.6446657180786133, 'logits/chosen': -2.6449928283691406, 'epoch': 1.93}
{'loss': 6.6308, 'grad_norm': 27.317940754748975, 'learning_rate': 0.0003694444444444445, 'rewards/chosen': -276.5520935058594, 'rewards/rejected': -275.8292236328125, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -0.7228622436523438, 'logps/rejected': -3201.30126953125, 'logps/chosen': -3194.325439453125, 'logits/rejected': -2.6581192016601562, 'logits/chosen': -2.6581690311431885, 'epoch': 1.94}
{'loss': 5.2589, 'grad_norm': 52.066391724056444, 'learning_rate': 0.00036666666666666667, 'rewards/chosen': -284.3789978027344, 'rewards/rejected': -281.5076904296875, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': -2.871391773223877, 'logps/rejected': -3210.83349609375, 'logps/chosen': -3241.328125, 'logits/rejected': -2.7252197265625, 'logits/chosen': -2.7251503467559814, 'epoch': 1.94}
{'loss': 4.103, 'grad_norm': 14.62354436526296, 'learning_rate': 0.00036388888888888886, 'rewards/chosen': -278.3900451660156, 'rewards/rejected': -285.8062438964844, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 7.41623592376709, 'logps/rejected': -3264.8203125, 'logps/chosen': -3176.55029296875, 'logits/rejected': -2.870771884918213, 'logits/chosen': -2.870577812194824, 'epoch': 1.95}
{'loss': 5.8005, 'grad_norm': 23.623623589898404, 'learning_rate': 0.0003611111111111111, 'rewards/chosen': -279.44232177734375, 'rewards/rejected': -279.13885498046875, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': -0.3035207688808441, 'logps/rejected': -3153.64794921875, 'logps/chosen': -3154.324951171875, 'logits/rejected': -2.9999287128448486, 'logits/chosen': -2.9995689392089844, 'epoch': 1.96}
{'loss': 5.1385, 'grad_norm': 21.35144790355192, 'learning_rate': 0.00035833333333333333, 'rewards/chosen': -264.3066711425781, 'rewards/rejected': -266.45367431640625, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': 2.147038698196411, 'logps/rejected': -3095.927490234375, 'logps/chosen': -3070.77490234375, 'logits/rejected': -3.027904510498047, 'logits/chosen': -3.0281498432159424, 'epoch': 1.97}
{'loss': 5.9395, 'grad_norm': 27.251079340789467, 'learning_rate': 0.00035555555555555557, 'rewards/chosen': -271.31268310546875, 'rewards/rejected': -275.19830322265625, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 3.8856422901153564, 'logps/rejected': -3129.3896484375, 'logps/chosen': -3072.06591796875, 'logits/rejected': -3.035247325897217, 'logits/chosen': -3.0352931022644043, 'epoch': 1.98}
{'loss': 2.9638, 'grad_norm': 15.797946476345144, 'learning_rate': 0.0003527777777777778, 'rewards/chosen': -277.418701171875, 'rewards/rejected': -286.4888000488281, 'rewards/accuracies': 0.625, 'rewards/margins': 9.070127487182617, 'logps/rejected': -3306.71728515625, 'logps/chosen': -3210.37841796875, 'logits/rejected': -3.0827794075012207, 'logits/chosen': -3.0830185413360596, 'epoch': 1.98}
{'loss': 5.5024, 'grad_norm': 27.258189223590577, 'learning_rate': 0.00035, 'rewards/chosen': -284.72479248046875, 'rewards/rejected': -286.38665771484375, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 1.6619144678115845, 'logps/rejected': -3292.528076171875, 'logps/chosen': -3277.94189453125, 'logits/rejected': -2.9478728771209717, 'logits/chosen': -2.948050022125244, 'epoch': 1.99}
{'loss': 5.9366, 'grad_norm': 18.32153602199697, 'learning_rate': 0.00034722222222222224, 'rewards/chosen': -267.5643615722656, 'rewards/rejected': -274.9107971191406, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 7.3464155197143555, 'logps/rejected': -3147.968505859375, 'logps/chosen': -3058.40673828125, 'logits/rejected': -2.7554726600646973, 'logits/chosen': -2.7553305625915527, 'epoch': 2.0}
{'loss': 5.6313, 'grad_norm': 24.464140385015504, 'learning_rate': 0.0003444444444444445, 'rewards/chosen': -262.72210693359375, 'rewards/rejected': -266.5943603515625, 'rewards/accuracies': 0.5, 'rewards/margins': 3.872222900390625, 'logps/rejected': -3088.15673828125, 'logps/chosen': -3047.08447265625, 'logits/rejected': -2.7580294609069824, 'logits/chosen': -2.758270025253296, 'epoch': 2.01}
{'loss': 3.7953, 'grad_norm': 27.250430667039776, 'learning_rate': 0.00034166666666666666, 'rewards/chosen': -264.3909606933594, 'rewards/rejected': -267.39202880859375, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 3.0010550022125244, 'logps/rejected': -3096.90380859375, 'logps/chosen': -3053.633056640625, 'logits/rejected': -2.864091396331787, 'logits/chosen': -2.863804340362549, 'epoch': 2.02}
{'loss': 3.6903, 'grad_norm': 17.268951508795496, 'learning_rate': 0.0003388888888888889, 'rewards/chosen': -270.5648498535156, 'rewards/rejected': -269.21923828125, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': -1.3456284999847412, 'logps/rejected': -3137.31787109375, 'logps/chosen': -3139.88037109375, 'logits/rejected': -3.013500690460205, 'logits/chosen': -3.0130977630615234, 'epoch': 2.02}
{'loss': 6.5784, 'grad_norm': 40.175755726629895, 'learning_rate': 0.00033611111111111114, 'rewards/chosen': -285.1872863769531, 'rewards/rejected': -286.78753662109375, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': 1.600262999534607, 'logps/rejected': -3306.163330078125, 'logps/chosen': -3293.30810546875, 'logits/rejected': -3.178377866744995, 'logits/chosen': -3.178508758544922, 'epoch': 2.03}
{'loss': 3.6758, 'grad_norm': 37.223988581361276, 'learning_rate': 0.0003333333333333333, 'rewards/chosen': -277.7889099121094, 'rewards/rejected': -282.0279541015625, 'rewards/accuracies': 0.675000011920929, 'rewards/margins': 4.239017009735107, 'logps/rejected': -3238.66552734375, 'logps/chosen': -3187.44091796875, 'logits/rejected': -3.164379835128784, 'logits/chosen': -3.164691925048828, 'epoch': 2.04}
{'loss': 6.131, 'grad_norm': 28.27093549564213, 'learning_rate': 0.00033055555555555556, 'rewards/chosen': -269.1595458984375, 'rewards/rejected': -264.5229187011719, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': -4.636605262756348, 'logps/rejected': -3037.779296875, 'logps/chosen': -3089.06982421875, 'logits/rejected': -3.1716036796569824, 'logits/chosen': -3.171600103378296, 'epoch': 2.05}
{'loss': 5.0715, 'grad_norm': 36.9995580830798, 'learning_rate': 0.0003277777777777778, 'rewards/chosen': -280.7745056152344, 'rewards/rejected': -283.2234802246094, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 2.4489693641662598, 'logps/rejected': -3241.474853515625, 'logps/chosen': -3218.24609375, 'logits/rejected': -3.243741512298584, 'logits/chosen': -3.244469165802002, 'epoch': 2.06}
{'loss': 2.9746, 'grad_norm': 25.3952396798319, 'learning_rate': 0.00032500000000000004, 'rewards/chosen': -264.4681091308594, 'rewards/rejected': -275.03948974609375, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 10.571393966674805, 'logps/rejected': -3159.42333984375, 'logps/chosen': -3030.30126953125, 'logits/rejected': -3.2275073528289795, 'logits/chosen': -3.228102922439575, 'epoch': 2.06}
{'loss': 6.8714, 'grad_norm': 12.924385194837352, 'learning_rate': 0.0003222222222222222, 'rewards/chosen': -291.73809814453125, 'rewards/rejected': -285.7394104003906, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -5.998718738555908, 'logps/rejected': -3256.955322265625, 'logps/chosen': -3315.56298828125, 'logits/rejected': -3.1826937198638916, 'logits/chosen': -3.1818947792053223, 'epoch': 2.07}
{'loss': 5.8165, 'grad_norm': 18.800152699164542, 'learning_rate': 0.0003194444444444444, 'rewards/chosen': -274.7576904296875, 'rewards/rejected': -278.85821533203125, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 4.1005449295043945, 'logps/rejected': -3215.344482421875, 'logps/chosen': -3173.308349609375, 'logits/rejected': -3.127511739730835, 'logits/chosen': -3.1278328895568848, 'epoch': 2.08}
{'loss': 6.5219, 'grad_norm': 25.688043743338284, 'learning_rate': 0.00031666666666666665, 'rewards/chosen': -284.4042053222656, 'rewards/rejected': -289.5066223144531, 'rewards/accuracies': 0.675000011920929, 'rewards/margins': 5.102390289306641, 'logps/rejected': -3251.9287109375, 'logps/chosen': -3194.210693359375, 'logits/rejected': -3.04899001121521, 'logits/chosen': -3.0494489669799805, 'epoch': 2.09}
{'loss': 3.0898, 'grad_norm': 14.288376308090056, 'learning_rate': 0.0003138888888888889, 'rewards/chosen': -291.16339111328125, 'rewards/rejected': -294.9082336425781, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 3.744797945022583, 'logps/rejected': -3329.236328125, 'logps/chosen': -3295.51171875, 'logits/rejected': -3.0705809593200684, 'logits/chosen': -3.0704009532928467, 'epoch': 2.1}
{'loss': 6.5358, 'grad_norm': 24.702152020616886, 'learning_rate': 0.0003111111111111111, 'rewards/chosen': -279.69818115234375, 'rewards/rejected': -282.2268371582031, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 2.528658390045166, 'logps/rejected': -3259.4453125, 'logps/chosen': -3219.4423828125, 'logits/rejected': -3.0759763717651367, 'logits/chosen': -3.075864791870117, 'epoch': 2.1}
{'loss': 7.139, 'grad_norm': 20.70581098167487, 'learning_rate': 0.00030833333333333337, 'rewards/chosen': -270.0679016113281, 'rewards/rejected': -274.5527038574219, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 4.484809875488281, 'logps/rejected': -3174.0185546875, 'logps/chosen': -3123.440673828125, 'logits/rejected': -3.1063625812530518, 'logits/chosen': -3.10597825050354, 'epoch': 2.11}
{'loss': 5.8514, 'grad_norm': 49.814043759757915, 'learning_rate': 0.0003055555555555556, 'rewards/chosen': -270.0766906738281, 'rewards/rejected': -281.0331726074219, 'rewards/accuracies': 0.6499999761581421, 'rewards/margins': 10.956487655639648, 'logps/rejected': -3226.69189453125, 'logps/chosen': -3112.91552734375, 'logits/rejected': -3.117490768432617, 'logits/chosen': -3.116978883743286, 'epoch': 2.12}
{'loss': 4.7466, 'grad_norm': 51.75507570136254, 'learning_rate': 0.0003027777777777778, 'rewards/chosen': -284.6208190917969, 'rewards/rejected': -291.4549865722656, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': 6.834145545959473, 'logps/rejected': -3353.676513671875, 'logps/chosen': -3272.7255859375, 'logits/rejected': -3.107322931289673, 'logits/chosen': -3.107603073120117, 'epoch': 2.13}
{'loss': 6.0123, 'grad_norm': 26.94821252351594, 'learning_rate': 0.0003, 'rewards/chosen': -289.3063049316406, 'rewards/rejected': -289.13128662109375, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': -0.17499256134033203, 'logps/rejected': -3315.79248046875, 'logps/chosen': -3308.24853515625, 'logits/rejected': -3.036329984664917, 'logits/chosen': -3.036193370819092, 'epoch': 2.14}
{'loss': 4.5248, 'grad_norm': 12.88171896501577, 'learning_rate': 0.0002972222222222222, 'rewards/chosen': -288.30426025390625, 'rewards/rejected': -287.79046630859375, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': -0.5138067007064819, 'logps/rejected': -3292.05712890625, 'logps/chosen': -3295.736328125, 'logits/rejected': -3.1158530712127686, 'logits/chosen': -3.115748643875122, 'epoch': 2.14}
{'loss': 4.0153, 'grad_norm': 17.630051695292256, 'learning_rate': 0.00029444444444444445, 'rewards/chosen': -287.5114440917969, 'rewards/rejected': -292.3207092285156, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 4.809264659881592, 'logps/rejected': -3357.32421875, 'logps/chosen': -3290.61474609375, 'logits/rejected': -3.2428226470947266, 'logits/chosen': -3.2431626319885254, 'epoch': 2.15}
{'loss': 5.3283, 'grad_norm': 34.34727761079513, 'learning_rate': 0.0002916666666666667, 'rewards/chosen': -279.1852111816406, 'rewards/rejected': -281.466064453125, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 2.280867099761963, 'logps/rejected': -3271.04248046875, 'logps/chosen': -3247.36865234375, 'logits/rejected': -3.28104829788208, 'logits/chosen': -3.2811355590820312, 'epoch': 2.16}
{'loss': 5.2506, 'grad_norm': 38.78889662298189, 'learning_rate': 0.0002888888888888889, 'rewards/chosen': -285.92083740234375, 'rewards/rejected': -294.3489074707031, 'rewards/accuracies': 0.3499999940395355, 'rewards/margins': 8.428046226501465, 'logps/rejected': -3369.35205078125, 'logps/chosen': -3269.53369140625, 'logits/rejected': -3.317969560623169, 'logits/chosen': -3.318117141723633, 'epoch': 2.17}
{'loss': 6.3094, 'grad_norm': 27.408692844095217, 'learning_rate': 0.0002861111111111111, 'rewards/chosen': -271.2865295410156, 'rewards/rejected': -273.77099609375, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 2.4844682216644287, 'logps/rejected': -3198.755859375, 'logps/chosen': -3174.29443359375, 'logits/rejected': -3.2613234519958496, 'logits/chosen': -3.2618491649627686, 'epoch': 2.18}
{'loss': 4.673, 'grad_norm': 25.21609075403004, 'learning_rate': 0.00028333333333333335, 'rewards/chosen': -265.3450927734375, 'rewards/rejected': -268.47381591796875, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 3.1286983489990234, 'logps/rejected': -3105.93115234375, 'logps/chosen': -3081.288330078125, 'logits/rejected': -3.1080751419067383, 'logits/chosen': -3.1080470085144043, 'epoch': 2.18}
{'loss': 3.2881, 'grad_norm': 18.348877890000328, 'learning_rate': 0.00028055555555555554, 'rewards/chosen': -265.1461486816406, 'rewards/rejected': -274.67230224609375, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 9.526177406311035, 'logps/rejected': -3203.216064453125, 'logps/chosen': -3106.309814453125, 'logits/rejected': -3.059792995452881, 'logits/chosen': -3.0597190856933594, 'epoch': 2.19}
{'loss': 4.5184, 'grad_norm': 25.49698779259907, 'learning_rate': 0.0002777777777777778, 'rewards/chosen': -262.986328125, 'rewards/rejected': -266.3207702636719, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 3.334428071975708, 'logps/rejected': -3069.52490234375, 'logps/chosen': -3027.89208984375, 'logits/rejected': -3.0310535430908203, 'logits/chosen': -3.031036138534546, 'epoch': 2.2}
{'loss': 5.2998, 'grad_norm': 31.120102428115658, 'learning_rate': 0.000275, 'rewards/chosen': -281.60418701171875, 'rewards/rejected': -292.645751953125, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 11.041574478149414, 'logps/rejected': -3336.469482421875, 'logps/chosen': -3223.83251953125, 'logits/rejected': -3.0374135971069336, 'logits/chosen': -3.0375475883483887, 'epoch': 2.21}
{'loss': 4.2961, 'grad_norm': 11.550279695816943, 'learning_rate': 0.0002722222222222222, 'rewards/chosen': -266.6541442871094, 'rewards/rejected': -273.6098937988281, 'rewards/accuracies': 0.5, 'rewards/margins': 6.955709934234619, 'logps/rejected': -3151.00830078125, 'logps/chosen': -3072.99853515625, 'logits/rejected': -3.0390841960906982, 'logits/chosen': -3.039151668548584, 'epoch': 2.22}
{'loss': 4.7169, 'grad_norm': 16.51341014316996, 'learning_rate': 0.00026944444444444444, 'rewards/chosen': -272.92645263671875, 'rewards/rejected': -278.71099853515625, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 5.784574508666992, 'logps/rejected': -3200.446533203125, 'logps/chosen': -3142.0693359375, 'logits/rejected': -3.0231146812438965, 'logits/chosen': -3.0235397815704346, 'epoch': 2.22}
{'loss': 4.6752, 'grad_norm': 30.41321620517754, 'learning_rate': 0.0002666666666666667, 'rewards/chosen': -276.4835510253906, 'rewards/rejected': -279.34820556640625, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 2.864682674407959, 'logps/rejected': -3171.377197265625, 'logps/chosen': -3149.481689453125, 'logits/rejected': -3.0169434547424316, 'logits/chosen': -3.0167858600616455, 'epoch': 2.23}
{'loss': 4.7923, 'grad_norm': 36.766423699713314, 'learning_rate': 0.0002638888888888889, 'rewards/chosen': -273.2281799316406, 'rewards/rejected': -282.92169189453125, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 9.693510055541992, 'logps/rejected': -3185.356689453125, 'logps/chosen': -3086.263671875, 'logits/rejected': -2.9952707290649414, 'logits/chosen': -2.995027542114258, 'epoch': 2.24}
{'loss': 4.2861, 'grad_norm': 29.697653755849366, 'learning_rate': 0.00026111111111111116, 'rewards/chosen': -274.43115234375, 'rewards/rejected': -280.54278564453125, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': 6.111684322357178, 'logps/rejected': -3244.537353515625, 'logps/chosen': -3171.64404296875, 'logits/rejected': -3.003467082977295, 'logits/chosen': -3.0031027793884277, 'epoch': 2.25}
{'loss': 3.7421, 'grad_norm': 17.676695669843603, 'learning_rate': 0.00025833333333333334, 'rewards/chosen': -287.81414794921875, 'rewards/rejected': -287.5149230957031, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': -0.29921644926071167, 'logps/rejected': -3320.010986328125, 'logps/chosen': -3323.61572265625, 'logits/rejected': -3.1103081703186035, 'logits/chosen': -3.1103241443634033, 'epoch': 2.26}
{'loss': 4.1368, 'grad_norm': 33.765213689424826, 'learning_rate': 0.00025555555555555553, 'rewards/chosen': -283.29632568359375, 'rewards/rejected': -289.0745544433594, 'rewards/accuracies': 0.625, 'rewards/margins': 5.778253078460693, 'logps/rejected': -3278.30029296875, 'logps/chosen': -3205.854736328125, 'logits/rejected': -3.145988941192627, 'logits/chosen': -3.1461901664733887, 'epoch': 2.26}
{'loss': 4.4716, 'grad_norm': 41.9787376667517, 'learning_rate': 0.00025277777777777777, 'rewards/chosen': -281.8357849121094, 'rewards/rejected': -283.86602783203125, 'rewards/accuracies': 0.375, 'rewards/margins': 2.0302340984344482, 'logps/rejected': -3292.435546875, 'logps/chosen': -3262.222412109375, 'logits/rejected': -3.1480441093444824, 'logits/chosen': -3.1479320526123047, 'epoch': 2.27}
{'loss': 5.4311, 'grad_norm': 31.566403478266928, 'learning_rate': 0.00025, 'rewards/chosen': -282.5955810546875, 'rewards/rejected': -282.91217041015625, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3165855407714844, 'logps/rejected': -3180.53515625, 'logps/chosen': -3172.64013671875, 'logits/rejected': -3.1073813438415527, 'logits/chosen': -3.1074795722961426, 'epoch': 2.28}
{'loss': 4.9137, 'grad_norm': 26.71820348626084, 'learning_rate': 0.00024722222222222224, 'rewards/chosen': -275.05401611328125, 'rewards/rejected': -275.96649169921875, 'rewards/accuracies': 0.5, 'rewards/margins': 0.9124670028686523, 'logps/rejected': -3141.438232421875, 'logps/chosen': -3131.906494140625, 'logits/rejected': -3.1165499687194824, 'logits/chosen': -3.116472005844116, 'epoch': 2.29}
{'loss': 6.4997, 'grad_norm': 22.324340094836963, 'learning_rate': 0.00024444444444444443, 'rewards/chosen': -285.3010559082031, 'rewards/rejected': -287.4521789550781, 'rewards/accuracies': 0.5, 'rewards/margins': 2.151097059249878, 'logps/rejected': -3336.903076171875, 'logps/chosen': -3304.848876953125, 'logits/rejected': -3.081918239593506, 'logits/chosen': -3.0817596912384033, 'epoch': 2.3}
{'loss': 5.959, 'grad_norm': 14.726740200099362, 'learning_rate': 0.00024166666666666667, 'rewards/chosen': -278.8331298828125, 'rewards/rejected': -282.0501708984375, 'rewards/accuracies': 0.625, 'rewards/margins': 3.2170467376708984, 'logps/rejected': -3234.285888671875, 'logps/chosen': -3200.09912109375, 'logits/rejected': -3.01853084564209, 'logits/chosen': -3.0187885761260986, 'epoch': 2.3}
{'loss': 3.9974, 'grad_norm': 33.31541334594282, 'learning_rate': 0.0002388888888888889, 'rewards/chosen': -278.316650390625, 'rewards/rejected': -278.478515625, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': 0.16186484694480896, 'logps/rejected': -3252.03173828125, 'logps/chosen': -3247.33154296875, 'logits/rejected': -3.101569175720215, 'logits/chosen': -3.1015634536743164, 'epoch': 2.31}
{'loss': 7.3854, 'grad_norm': 33.431165799516116, 'learning_rate': 0.00023611111111111112, 'rewards/chosen': -269.5132751464844, 'rewards/rejected': -267.09210205078125, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': -2.4211513996124268, 'logps/rejected': -3074.215087890625, 'logps/chosen': -3100.0185546875, 'logits/rejected': -3.191500425338745, 'logits/chosen': -3.191531181335449, 'epoch': 2.32}
{'loss': 4.2102, 'grad_norm': 22.5117117837504, 'learning_rate': 0.00023333333333333333, 'rewards/chosen': -263.7206115722656, 'rewards/rejected': -270.24053955078125, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 6.519930839538574, 'logps/rejected': -3137.88623046875, 'logps/chosen': -3065.74609375, 'logits/rejected': -3.167086362838745, 'logits/chosen': -3.166891574859619, 'epoch': 2.33}
{'loss': 4.1674, 'grad_norm': 15.412418324723838, 'learning_rate': 0.00023055555555555557, 'rewards/chosen': -258.451904296875, 'rewards/rejected': -267.555908203125, 'rewards/accuracies': 0.675000011920929, 'rewards/margins': 9.103987693786621, 'logps/rejected': -3206.53369140625, 'logps/chosen': -3104.135498046875, 'logits/rejected': -3.0789260864257812, 'logits/chosen': -3.078766345977783, 'epoch': 2.34}
{'loss': 6.4857, 'grad_norm': 18.388449688216237, 'learning_rate': 0.00022777777777777778, 'rewards/chosen': -269.2322692871094, 'rewards/rejected': -265.54376220703125, 'rewards/accuracies': 0.30000001192092896, 'rewards/margins': -3.6885056495666504, 'logps/rejected': -3155.7578125, 'logps/chosen': -3195.864501953125, 'logits/rejected': -3.0456275939941406, 'logits/chosen': -3.0453155040740967, 'epoch': 2.34}
{'loss': 5.4071, 'grad_norm': 51.209906934069764, 'learning_rate': 0.00022500000000000002, 'rewards/chosen': -269.97308349609375, 'rewards/rejected': -271.93780517578125, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 1.9647324085235596, 'logps/rejected': -3101.022705078125, 'logps/chosen': -3079.39111328125, 'logits/rejected': -3.0796542167663574, 'logits/chosen': -3.0795130729675293, 'epoch': 2.35}
{'loss': 3.3872, 'grad_norm': 38.49177788501119, 'learning_rate': 0.0002222222222222222, 'rewards/chosen': -287.40386962890625, 'rewards/rejected': -296.067626953125, 'rewards/accuracies': 0.625, 'rewards/margins': 8.663731575012207, 'logps/rejected': -3415.39306640625, 'logps/chosen': -3321.49951171875, 'logits/rejected': -3.098226547241211, 'logits/chosen': -3.098158836364746, 'epoch': 2.36}
{'loss': 3.023, 'grad_norm': 20.55609477208932, 'learning_rate': 0.00021944444444444444, 'rewards/chosen': -265.8069152832031, 'rewards/rejected': -271.3334045410156, 'rewards/accuracies': 0.625, 'rewards/margins': 5.5264739990234375, 'logps/rejected': -3080.59326171875, 'logps/chosen': -3028.64453125, 'logits/rejected': -3.086824893951416, 'logits/chosen': -3.086838722229004, 'epoch': 2.37}
{'loss': 7.3924, 'grad_norm': 43.066171724296304, 'learning_rate': 0.00021666666666666668, 'rewards/chosen': -282.5072937011719, 'rewards/rejected': -287.41845703125, 'rewards/accuracies': 0.625, 'rewards/margins': 4.911168575286865, 'logps/rejected': -3295.2890625, 'logps/chosen': -3234.45654296875, 'logits/rejected': -2.998417615890503, 'logits/chosen': -2.998486280441284, 'epoch': 2.38}
{'loss': 5.1456, 'grad_norm': 23.269934123871717, 'learning_rate': 0.0002138888888888889, 'rewards/chosen': -264.41571044921875, 'rewards/rejected': -267.18731689453125, 'rewards/accuracies': 0.675000011920929, 'rewards/margins': 2.7716012001037598, 'logps/rejected': -3053.09619140625, 'logps/chosen': -3032.474853515625, 'logits/rejected': -2.903080463409424, 'logits/chosen': -2.903233051300049, 'epoch': 2.38}
{'loss': 4.8336, 'grad_norm': 11.731870248009194, 'learning_rate': 0.0002111111111111111, 'rewards/chosen': -261.8716125488281, 'rewards/rejected': -263.89410400390625, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': 2.022448778152466, 'logps/rejected': -3100.052490234375, 'logps/chosen': -3067.78759765625, 'logits/rejected': -2.9461395740509033, 'logits/chosen': -2.9459874629974365, 'epoch': 2.39}
{'loss': 3.3647, 'grad_norm': 15.094940314931184, 'learning_rate': 0.00020833333333333335, 'rewards/chosen': -267.8012390136719, 'rewards/rejected': -273.3447570800781, 'rewards/accuracies': 0.625, 'rewards/margins': 5.543539047241211, 'logps/rejected': -3126.32763671875, 'logps/chosen': -3068.01318359375, 'logits/rejected': -3.0601720809936523, 'logits/chosen': -3.060037136077881, 'epoch': 2.4}
{'loss': 5.224, 'grad_norm': 28.33542985012076, 'learning_rate': 0.00020555555555555556, 'rewards/chosen': -255.220458984375, 'rewards/rejected': -258.0987243652344, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': 2.8783111572265625, 'logps/rejected': -3012.216796875, 'logps/chosen': -2978.66064453125, 'logits/rejected': -3.100759983062744, 'logits/chosen': -3.1007819175720215, 'epoch': 2.41}
{'loss': 3.7929, 'grad_norm': 24.9191627194146, 'learning_rate': 0.00020277777777777777, 'rewards/chosen': -275.2322998046875, 'rewards/rejected': -284.55328369140625, 'rewards/accuracies': 0.6499999761581421, 'rewards/margins': 9.320981979370117, 'logps/rejected': -3299.565673828125, 'logps/chosen': -3203.31689453125, 'logits/rejected': -3.091663122177124, 'logits/chosen': -3.0919928550720215, 'epoch': 2.42}
{'loss': 6.1529, 'grad_norm': 20.135198054651475, 'learning_rate': 0.0002, 'rewards/chosen': -265.56134033203125, 'rewards/rejected': -261.8948669433594, 'rewards/accuracies': 0.5, 'rewards/margins': -3.6664538383483887, 'logps/rejected': -3010.972412109375, 'logps/chosen': -3047.733154296875, 'logits/rejected': -3.1028552055358887, 'logits/chosen': -3.1028332710266113, 'epoch': 2.42}
{'loss': 2.5721, 'grad_norm': 22.070967860809287, 'learning_rate': 0.00019722222222222222, 'rewards/chosen': -274.3954772949219, 'rewards/rejected': -280.53643798828125, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 6.140940189361572, 'logps/rejected': -3281.169921875, 'logps/chosen': -3215.78759765625, 'logits/rejected': -3.148197889328003, 'logits/chosen': -3.148419141769409, 'epoch': 2.43}
{'loss': 5.0547, 'grad_norm': 18.77000827233595, 'learning_rate': 0.00019444444444444446, 'rewards/chosen': -268.6825866699219, 'rewards/rejected': -262.5932922363281, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -6.089323997497559, 'logps/rejected': -3075.738525390625, 'logps/chosen': -3137.92041015625, 'logits/rejected': -3.1654367446899414, 'logits/chosen': -3.165504217147827, 'epoch': 2.44}
{'loss': 4.8723, 'grad_norm': 28.7096264797374, 'learning_rate': 0.00019166666666666667, 'rewards/chosen': -289.82440185546875, 'rewards/rejected': -294.3706970214844, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 4.546301364898682, 'logps/rejected': -3386.571044921875, 'logps/chosen': -3342.309326171875, 'logits/rejected': -3.149129867553711, 'logits/chosen': -3.1493008136749268, 'epoch': 2.45}
{'loss': 5.7291, 'grad_norm': 36.54764392149384, 'learning_rate': 0.00018888888888888888, 'rewards/chosen': -272.7638244628906, 'rewards/rejected': -269.83953857421875, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -2.9242916107177734, 'logps/rejected': -3128.34423828125, 'logps/chosen': -3153.533935546875, 'logits/rejected': -3.1655690670013428, 'logits/chosen': -3.165421962738037, 'epoch': 2.46}
{'loss': 7.4624, 'grad_norm': 26.745226023233553, 'learning_rate': 0.00018611111111111112, 'rewards/chosen': -280.8795166015625, 'rewards/rejected': -281.3408508300781, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4613143801689148, 'logps/rejected': -3252.41064453125, 'logps/chosen': -3249.090576171875, 'logits/rejected': -3.206806182861328, 'logits/chosen': -3.206737995147705, 'epoch': 2.46}
{'loss': 7.0548, 'grad_norm': 11.094702831323776, 'learning_rate': 0.00018333333333333334, 'rewards/chosen': -266.9647521972656, 'rewards/rejected': -273.0311279296875, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': 6.066390037536621, 'logps/rejected': -3160.68359375, 'logps/chosen': -3094.443359375, 'logits/rejected': -3.196643352508545, 'logits/chosen': -3.196880340576172, 'epoch': 2.47}
{'loss': 8.0716, 'grad_norm': 21.44704182244024, 'learning_rate': 0.00018055555555555555, 'rewards/chosen': -275.70208740234375, 'rewards/rejected': -272.8291931152344, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': -2.8729348182678223, 'logps/rejected': -3147.08154296875, 'logps/chosen': -3189.67626953125, 'logits/rejected': -3.1533186435699463, 'logits/chosen': -3.1528983116149902, 'epoch': 2.48}
{'loss': 5.2084, 'grad_norm': 28.232281244900015, 'learning_rate': 0.00017777777777777779, 'rewards/chosen': -259.8647155761719, 'rewards/rejected': -259.1424865722656, 'rewards/accuracies': 0.375, 'rewards/margins': -0.7222501635551453, 'logps/rejected': -3099.364013671875, 'logps/chosen': -3107.612060546875, 'logits/rejected': -3.1735854148864746, 'logits/chosen': -3.173372745513916, 'epoch': 2.49}
{'loss': 3.8582, 'grad_norm': 30.719944002256405, 'learning_rate': 0.000175, 'rewards/chosen': -287.97430419921875, 'rewards/rejected': -287.83203125, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -0.14226531982421875, 'logps/rejected': -3318.516357421875, 'logps/chosen': -3315.487548828125, 'logits/rejected': -3.157508611679077, 'logits/chosen': -3.157557725906372, 'epoch': 2.5}
{'loss': 5.1918, 'grad_norm': 16.99298343527037, 'learning_rate': 0.00017222222222222224, 'rewards/chosen': -266.24615478515625, 'rewards/rejected': -264.5315856933594, 'rewards/accuracies': 0.5, 'rewards/margins': -1.7145683765411377, 'logps/rejected': -3079.47802734375, 'logps/chosen': -3092.44482421875, 'logits/rejected': -3.1173994541168213, 'logits/chosen': -3.1171059608459473, 'epoch': 2.5}
{'loss': 6.1418, 'grad_norm': 23.913580162882038, 'learning_rate': 0.00016944444444444445, 'rewards/chosen': -269.7708435058594, 'rewards/rejected': -276.72161865234375, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 6.95078182220459, 'logps/rejected': -3197.987060546875, 'logps/chosen': -3111.27001953125, 'logits/rejected': -3.064730167388916, 'logits/chosen': -3.0646164417266846, 'epoch': 2.51}
{'loss': 4.6296, 'grad_norm': 20.068912865629645, 'learning_rate': 0.00016666666666666666, 'rewards/chosen': -274.60333251953125, 'rewards/rejected': -275.0169372558594, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 0.4136062562465668, 'logps/rejected': -3207.73974609375, 'logps/chosen': -3198.75390625, 'logits/rejected': -3.074385166168213, 'logits/chosen': -3.0744309425354004, 'epoch': 2.52}
{'loss': 6.4358, 'grad_norm': 15.508119963650197, 'learning_rate': 0.0001638888888888889, 'rewards/chosen': -277.7096252441406, 'rewards/rejected': -281.72406005859375, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 4.0144453048706055, 'logps/rejected': -3252.10498046875, 'logps/chosen': -3199.04443359375, 'logits/rejected': -3.10241961479187, 'logits/chosen': -3.1024036407470703, 'epoch': 2.53}
{'loss': 1.9147, 'grad_norm': 6.25197599281276, 'learning_rate': 0.0001611111111111111, 'rewards/chosen': -272.1800231933594, 'rewards/rejected': -281.71453857421875, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 9.534528732299805, 'logps/rejected': -3219.16162109375, 'logps/chosen': -3110.67626953125, 'logits/rejected': -3.153050661087036, 'logits/chosen': -3.1533119678497314, 'epoch': 2.54}
{'loss': 5.0001, 'grad_norm': 20.96181391308291, 'learning_rate': 0.00015833333333333332, 'rewards/chosen': -275.78826904296875, 'rewards/rejected': -286.3382568359375, 'rewards/accuracies': 0.625, 'rewards/margins': 10.549955368041992, 'logps/rejected': -3263.92333984375, 'logps/chosen': -3150.31298828125, 'logits/rejected': -3.163243293762207, 'logits/chosen': -3.1632919311523438, 'epoch': 2.54}
{'loss': 7.3505, 'grad_norm': 19.407797223668922, 'learning_rate': 0.00015555555555555556, 'rewards/chosen': -275.6522216796875, 'rewards/rejected': -280.3103942871094, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 4.658137321472168, 'logps/rejected': -3202.52294921875, 'logps/chosen': -3155.33984375, 'logits/rejected': -3.124791383743286, 'logits/chosen': -3.1247894763946533, 'epoch': 2.55}
{'loss': 4.8388, 'grad_norm': 30.661628291751942, 'learning_rate': 0.0001527777777777778, 'rewards/chosen': -262.4237976074219, 'rewards/rejected': -273.0720520019531, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 10.648252487182617, 'logps/rejected': -3140.905029296875, 'logps/chosen': -3017.081787109375, 'logits/rejected': -3.058537006378174, 'logits/chosen': -3.058722972869873, 'epoch': 2.56}
{'loss': 4.985, 'grad_norm': 25.594678593367814, 'learning_rate': 0.00015, 'rewards/chosen': -275.65411376953125, 'rewards/rejected': -281.30877685546875, 'rewards/accuracies': 0.625, 'rewards/margins': 5.654642581939697, 'logps/rejected': -3243.980224609375, 'logps/chosen': -3196.190673828125, 'logits/rejected': -3.065746784210205, 'logits/chosen': -3.0654549598693848, 'epoch': 2.57}
{'loss': 5.9719, 'grad_norm': 32.17039128510327, 'learning_rate': 0.00014722222222222223, 'rewards/chosen': -275.57318115234375, 'rewards/rejected': -277.2786865234375, 'rewards/accuracies': 0.5, 'rewards/margins': 1.7054907083511353, 'logps/rejected': -3201.453857421875, 'logps/chosen': -3177.930419921875, 'logits/rejected': -3.1162209510803223, 'logits/chosen': -3.1163578033447266, 'epoch': 2.58}
{'loss': 3.5174, 'grad_norm': 26.385489719448252, 'learning_rate': 0.00014444444444444444, 'rewards/chosen': -265.0487060546875, 'rewards/rejected': -269.83477783203125, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 4.786111831665039, 'logps/rejected': -3174.06884765625, 'logps/chosen': -3114.751708984375, 'logits/rejected': -3.1407506465911865, 'logits/chosen': -3.1414153575897217, 'epoch': 2.58}
{'loss': 3.5678, 'grad_norm': 30.84875268191762, 'learning_rate': 0.00014166666666666668, 'rewards/chosen': -280.34075927734375, 'rewards/rejected': -284.13555908203125, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 3.794764280319214, 'logps/rejected': -3272.913330078125, 'logps/chosen': -3217.568359375, 'logits/rejected': -3.1163554191589355, 'logits/chosen': -3.116179943084717, 'epoch': 2.59}
{'loss': 3.4257, 'grad_norm': 22.291096136002185, 'learning_rate': 0.0001388888888888889, 'rewards/chosen': -278.740234375, 'rewards/rejected': -281.309814453125, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 2.569591522216797, 'logps/rejected': -3227.37890625, 'logps/chosen': -3190.43212890625, 'logits/rejected': -3.1457600593566895, 'logits/chosen': -3.145503520965576, 'epoch': 2.6}
{'loss': 3.6988, 'grad_norm': 18.011120532589025, 'learning_rate': 0.0001361111111111111, 'rewards/chosen': -263.7433166503906, 'rewards/rejected': -270.35736083984375, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 6.614025115966797, 'logps/rejected': -3140.01123046875, 'logps/chosen': -3068.740234375, 'logits/rejected': -3.208357572555542, 'logits/chosen': -3.2089219093322754, 'epoch': 2.61}
{'loss': 7.9099, 'grad_norm': 20.02265963207248, 'learning_rate': 0.00013333333333333334, 'rewards/chosen': -282.77642822265625, 'rewards/rejected': -281.90850830078125, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': -0.8679275512695312, 'logps/rejected': -3200.16748046875, 'logps/chosen': -3221.617919921875, 'logits/rejected': -3.2569777965545654, 'logits/chosen': -3.256455183029175, 'epoch': 2.62}
{'loss': 5.2612, 'grad_norm': 31.48517761990787, 'learning_rate': 0.00013055555555555558, 'rewards/chosen': -270.3973083496094, 'rewards/rejected': -271.9042663574219, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 1.5069496631622314, 'logps/rejected': -3193.15283203125, 'logps/chosen': -3175.330810546875, 'logits/rejected': -3.240058422088623, 'logits/chosen': -3.240156650543213, 'epoch': 2.62}
{'loss': 5.8022, 'grad_norm': 26.360502397058383, 'learning_rate': 0.00012777777777777776, 'rewards/chosen': -261.8916320800781, 'rewards/rejected': -259.44439697265625, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -2.4471917152404785, 'logps/rejected': -3010.148681640625, 'logps/chosen': -3029.382080078125, 'logits/rejected': -3.1634633541107178, 'logits/chosen': -3.163250207901001, 'epoch': 2.63}
{'loss': 4.4852, 'grad_norm': 18.437690682119356, 'learning_rate': 0.000125, 'rewards/chosen': -261.6444396972656, 'rewards/rejected': -273.49029541015625, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 11.845874786376953, 'logps/rejected': -3143.56982421875, 'logps/chosen': -3009.85986328125, 'logits/rejected': -3.107285499572754, 'logits/chosen': -3.1076200008392334, 'epoch': 2.64}
{'loss': 6.1579, 'grad_norm': 34.371490651962965, 'learning_rate': 0.00012222222222222221, 'rewards/chosen': -262.4375915527344, 'rewards/rejected': -273.781982421875, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 11.344367980957031, 'logps/rejected': -3174.190673828125, 'logps/chosen': -3049.987548828125, 'logits/rejected': -3.1079654693603516, 'logits/chosen': -3.107452869415283, 'epoch': 2.65}
{'loss': 4.8068, 'grad_norm': 22.321332650524393, 'learning_rate': 0.00011944444444444445, 'rewards/chosen': -283.3035888671875, 'rewards/rejected': -284.52325439453125, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': 1.2196567058563232, 'logps/rejected': -3291.00244140625, 'logps/chosen': -3271.380126953125, 'logits/rejected': -3.1095032691955566, 'logits/chosen': -3.10872220993042, 'epoch': 2.66}
{'loss': 4.5828, 'grad_norm': 24.90931150766185, 'learning_rate': 0.00011666666666666667, 'rewards/chosen': -273.75811767578125, 'rewards/rejected': -273.6934814453125, 'rewards/accuracies': 0.5, 'rewards/margins': -0.06466484069824219, 'logps/rejected': -3156.6982421875, 'logps/chosen': -3149.370849609375, 'logits/rejected': -3.114222764968872, 'logits/chosen': -3.1147372722625732, 'epoch': 2.66}
{'loss': 5.5882, 'grad_norm': 15.060317887099924, 'learning_rate': 0.00011388888888888889, 'rewards/chosen': -280.804931640625, 'rewards/rejected': -285.90301513671875, 'rewards/accuracies': 0.625, 'rewards/margins': 5.0980634689331055, 'logps/rejected': -3246.4990234375, 'logps/chosen': -3193.45166015625, 'logits/rejected': -3.1004509925842285, 'logits/chosen': -3.100766658782959, 'epoch': 2.67}
{'loss': 5.9697, 'grad_norm': 32.839429911121584, 'learning_rate': 0.0001111111111111111, 'rewards/chosen': -257.4336242675781, 'rewards/rejected': -262.63470458984375, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 5.201137542724609, 'logps/rejected': -3015.70751953125, 'logps/chosen': -2953.101806640625, 'logits/rejected': -3.0761218070983887, 'logits/chosen': -3.076486110687256, 'epoch': 2.68}
{'loss': 4.2972, 'grad_norm': 14.32441599158413, 'learning_rate': 0.00010833333333333334, 'rewards/chosen': -254.524169921875, 'rewards/rejected': -281.9324951171875, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 27.408300399780273, 'logps/rejected': -3243.507568359375, 'logps/chosen': -2944.963134765625, 'logits/rejected': -3.035433769226074, 'logits/chosen': -3.035395860671997, 'epoch': 2.69}
{'loss': 5.3487, 'grad_norm': 21.10688890431859, 'learning_rate': 0.00010555555555555555, 'rewards/chosen': -269.82781982421875, 'rewards/rejected': -264.51763916015625, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -5.310151100158691, 'logps/rejected': -3102.067626953125, 'logps/chosen': -3133.14892578125, 'logits/rejected': -3.0222232341766357, 'logits/chosen': -3.021585464477539, 'epoch': 2.7}
{'loss': 4.8308, 'grad_norm': 15.856120051087702, 'learning_rate': 0.00010277777777777778, 'rewards/chosen': -260.436767578125, 'rewards/rejected': -269.26092529296875, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': 8.82415771484375, 'logps/rejected': -3201.463623046875, 'logps/chosen': -3093.57470703125, 'logits/rejected': -3.0401527881622314, 'logits/chosen': -3.0402936935424805, 'epoch': 2.7}
{'loss': 4.227, 'grad_norm': 24.96732600019456, 'learning_rate': 0.0001, 'rewards/chosen': -280.77630615234375, 'rewards/rejected': -279.3577880859375, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': -1.4185177087783813, 'logps/rejected': -3197.825439453125, 'logps/chosen': -3211.870361328125, 'logits/rejected': -3.094367504119873, 'logits/chosen': -3.094738245010376, 'epoch': 2.71}
{'loss': 4.9593, 'grad_norm': 26.260312735804735, 'learning_rate': 9.722222222222223e-05, 'rewards/chosen': -262.28192138671875, 'rewards/rejected': -273.4908447265625, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 11.208935737609863, 'logps/rejected': -3184.06298828125, 'logps/chosen': -3063.63330078125, 'logits/rejected': -3.154231071472168, 'logits/chosen': -3.154629945755005, 'epoch': 2.72}
{'loss': 3.1947, 'grad_norm': 20.47402172370786, 'learning_rate': 9.444444444444444e-05, 'rewards/chosen': -287.45819091796875, 'rewards/rejected': -294.7369079589844, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 7.278750419616699, 'logps/rejected': -3336.37158203125, 'logps/chosen': -3259.858154296875, 'logits/rejected': -3.1690592765808105, 'logits/chosen': -3.1682915687561035, 'epoch': 2.73}
{'loss': 5.0219, 'grad_norm': 39.32591359850944, 'learning_rate': 9.166666666666667e-05, 'rewards/chosen': -271.31829833984375, 'rewards/rejected': -275.51983642578125, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 4.2015509605407715, 'logps/rejected': -3201.65185546875, 'logps/chosen': -3146.354248046875, 'logits/rejected': -3.1927971839904785, 'logits/chosen': -3.191340208053589, 'epoch': 2.74}
{'loss': 3.4599, 'grad_norm': 24.203851364691353, 'learning_rate': 8.888888888888889e-05, 'rewards/chosen': -286.43304443359375, 'rewards/rejected': -290.61981201171875, 'rewards/accuracies': 0.6499999761581421, 'rewards/margins': 4.186722278594971, 'logps/rejected': -3285.04736328125, 'logps/chosen': -3248.38720703125, 'logits/rejected': -3.2261078357696533, 'logits/chosen': -3.225773572921753, 'epoch': 2.74}
{'loss': 5.2053, 'grad_norm': 36.46736524747701, 'learning_rate': 8.611111111111112e-05, 'rewards/chosen': -272.0560607910156, 'rewards/rejected': -276.6008605957031, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 4.544814109802246, 'logps/rejected': -3139.375244140625, 'logps/chosen': -3081.249267578125, 'logits/rejected': -3.1807754039764404, 'logits/chosen': -3.1824917793273926, 'epoch': 2.75}
{'loss': 5.6806, 'grad_norm': 12.325122201081452, 'learning_rate': 8.333333333333333e-05, 'rewards/chosen': -262.6244201660156, 'rewards/rejected': -260.1797790527344, 'rewards/accuracies': 0.375, 'rewards/margins': -2.4446024894714355, 'logps/rejected': -3060.038330078125, 'logps/chosen': -3076.3037109375, 'logits/rejected': -3.0986685752868652, 'logits/chosen': -3.0979228019714355, 'epoch': 2.76}
{'loss': 4.4003, 'grad_norm': 17.23978919616113, 'learning_rate': 8.055555555555556e-05, 'rewards/chosen': -271.4351501464844, 'rewards/rejected': -271.3419494628906, 'rewards/accuracies': 0.625, 'rewards/margins': -0.0932079330086708, 'logps/rejected': -3116.698486328125, 'logps/chosen': -3110.282958984375, 'logits/rejected': -3.0334978103637695, 'logits/chosen': -3.032595157623291, 'epoch': 2.77}
{'loss': 4.6954, 'grad_norm': 25.04720094836761, 'learning_rate': 7.777777777777778e-05, 'rewards/chosen': -271.3436584472656, 'rewards/rejected': -273.3624267578125, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': 2.0187668800354004, 'logps/rejected': -3185.24267578125, 'logps/chosen': -3156.91259765625, 'logits/rejected': -3.0162668228149414, 'logits/chosen': -3.016465663909912, 'epoch': 2.78}
{'loss': 2.78, 'grad_norm': 19.294729770513722, 'learning_rate': 7.5e-05, 'rewards/chosen': -261.66845703125, 'rewards/rejected': -261.933349609375, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 0.26488035917282104, 'logps/rejected': -3057.15673828125, 'logps/chosen': -3041.035400390625, 'logits/rejected': -3.0101866722106934, 'logits/chosen': -3.0110700130462646, 'epoch': 2.78}
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
