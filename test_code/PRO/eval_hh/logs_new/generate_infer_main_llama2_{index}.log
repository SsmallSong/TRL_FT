4
4
4
4
/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
401 Client Error. (Request ID: Root=1-665ed631-3693b08c7deae86a6e41ad79)

Repository Not Found for url: https://huggingface.co/daryl149/llama-2-7b-hf/resolve/main/model.safetensors.index.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated.
User Access Token "mis" is expired
Traceback (most recent call last):
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 304, in hf_raise_for_status
    response.raise_for_status()
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/daryl149/llama-2-7b-hf/resolve/main/model.safetensors.index.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/utils/hub.py", line 629, in has_file
    hf_raise_for_status(r)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 352, in hf_raise_for_status
    raise RepositoryNotFoundError(message, response) from e
huggingface_hub.utils._errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-665ed631-3693b08c7deae86a6e41ad79)

Repository Not Found for url: https://huggingface.co/daryl149/llama-2-7b-hf/resolve/main/model.safetensors.index.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated.
User Access Token "mis" is expired

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wxt/huatong/TRL_FT/test_code/PRO/eval_hh/infer_and_eval_main_generate.py", line 50, in <module>
    model = AutoModelForCausalLM.from_pretrained(model_name_or_path,config=model_config).to(model_device)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 563, in from_pretrained
    return model_class.from_pretrained(
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/modeling_utils.py", line 3375, in from_pretrained
    if not has_file(pretrained_model_name_or_path, safe_weights_name, **has_file_kwargs):
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/utils/hub.py", line 640, in has_file
    raise EnvironmentError(f"{path_or_repo} is not a local folder or a valid repository name on 'https://hf.co'.")
OSError: daryl149/llama-2-7b-hf is not a local folder or a valid repository name on 'https://hf.co'.
401 Client Error. (Request ID: Root=1-665ed632-0227e06e0360fcd123bd79e7)

Repository Not Found for url: https://huggingface.co/daryl149/llama-2-7b-hf/resolve/main/model.safetensors.index.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated.
User Access Token "mis" is expired
Traceback (most recent call last):
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 304, in hf_raise_for_status
    response.raise_for_status()
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/daryl149/llama-2-7b-hf/resolve/main/model.safetensors.index.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/utils/hub.py", line 629, in has_file
    hf_raise_for_status(r)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 352, in hf_raise_for_status
    raise RepositoryNotFoundError(message, response) from e
huggingface_hub.utils._errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-665ed632-0227e06e0360fcd123bd79e7)

Repository Not Found for url: https://huggingface.co/daryl149/llama-2-7b-hf/resolve/main/model.safetensors.index.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated.
User Access Token "mis" is expired

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wxt/huatong/TRL_FT/test_code/PRO/eval_hh/infer_and_eval_main_generate.py", line 50, in <module>
    model = AutoModelForCausalLM.from_pretrained(model_name_or_path,config=model_config).to(model_device)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 563, in from_pretrained
    return model_class.from_pretrained(
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/modeling_utils.py", line 3375, in from_pretrained
    if not has_file(pretrained_model_name_or_path, safe_weights_name, **has_file_kwargs):
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/utils/hub.py", line 640, in has_file
    raise EnvironmentError(f"{path_or_repo} is not a local folder or a valid repository name on 'https://hf.co'.")
OSError: daryl149/llama-2-7b-hf is not a local folder or a valid repository name on 'https://hf.co'.
401 Client Error. (Request ID: Root=1-665ed632-04d99f2e2d48773812f106bf)

Repository Not Found for url: https://huggingface.co/daryl149/llama-2-7b-hf/resolve/main/model.safetensors.index.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated.
User Access Token "mis" is expired
Traceback (most recent call last):
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 304, in hf_raise_for_status
    response.raise_for_status()
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/daryl149/llama-2-7b-hf/resolve/main/model.safetensors.index.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/utils/hub.py", line 629, in has_file
    hf_raise_for_status(r)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 352, in hf_raise_for_status
    raise RepositoryNotFoundError(message, response) from e
huggingface_hub.utils._errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-665ed632-04d99f2e2d48773812f106bf)

Repository Not Found for url: https://huggingface.co/daryl149/llama-2-7b-hf/resolve/main/model.safetensors.index.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated.
User Access Token "mis" is expired

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wxt/huatong/TRL_FT/test_code/PRO/eval_hh/infer_and_eval_main_generate.py", line 50, in <module>
    model = AutoModelForCausalLM.from_pretrained(model_name_or_path,config=model_config).to(model_device)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 563, in from_pretrained
    return model_class.from_pretrained(
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/modeling_utils.py", line 3375, in from_pretrained
    if not has_file(pretrained_model_name_or_path, safe_weights_name, **has_file_kwargs):
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/utils/hub.py", line 640, in has_file
    raise EnvironmentError(f"{path_or_repo} is not a local folder or a valid repository name on 'https://hf.co'.")
OSError: daryl149/llama-2-7b-hf is not a local folder or a valid repository name on 'https://hf.co'.
401 Client Error. (Request ID: Root=1-665ed632-6e2aa287118f1f4b1724d4a4)

Repository Not Found for url: https://huggingface.co/daryl149/llama-2-7b-hf/resolve/main/model.safetensors.index.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated.
User Access Token "mis" is expired
Traceback (most recent call last):
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 304, in hf_raise_for_status
    response.raise_for_status()
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/daryl149/llama-2-7b-hf/resolve/main/model.safetensors.index.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/utils/hub.py", line 629, in has_file
    hf_raise_for_status(r)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 352, in hf_raise_for_status
    raise RepositoryNotFoundError(message, response) from e
huggingface_hub.utils._errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-665ed632-6e2aa287118f1f4b1724d4a4)

Repository Not Found for url: https://huggingface.co/daryl149/llama-2-7b-hf/resolve/main/model.safetensors.index.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated.
User Access Token "mis" is expired

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wxt/huatong/TRL_FT/test_code/PRO/eval_hh/infer_and_eval_main_generate.py", line 50, in <module>
    model = AutoModelForCausalLM.from_pretrained(model_name_or_path,config=model_config).to(model_device)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 563, in from_pretrained
    return model_class.from_pretrained(
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/modeling_utils.py", line 3375, in from_pretrained
    if not has_file(pretrained_model_name_or_path, safe_weights_name, **has_file_kwargs):
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/utils/hub.py", line 640, in has_file
    raise EnvironmentError(f"{path_or_repo} is not a local folder or a valid repository name on 'https://hf.co'.")
OSError: daryl149/llama-2-7b-hf is not a local folder or a valid repository name on 'https://hf.co'.
[2024-06-04 08:54:11,739] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 3312222) of binary: /home/wxt/.conda/envs/rl/bin/python
Traceback (most recent call last):
  File "/home/wxt/.conda/envs/rl/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py", line 46, in main
    args.func(args)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/accelerate/commands/launch.py", line 1066, in launch_command
    multi_gpu_launcher(args)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/accelerate/commands/launch.py", line 711, in multi_gpu_launcher
    distrib_run.run(args)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
infer_and_eval_main_generate.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-06-04_08:54:11
  host      : design-agent-09.internal.cloudapp.net
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 3312223)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-06-04_08:54:11
  host      : design-agent-09.internal.cloudapp.net
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 3312224)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2024-06-04_08:54:11
  host      : design-agent-09.internal.cloudapp.net
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 3312225)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-06-04_08:54:11
  host      : design-agent-09.internal.cloudapp.net
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3312222)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
