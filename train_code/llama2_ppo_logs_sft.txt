[2024-06-09 14:10:11,609] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-06-09 14:10:12,235] torch.distributed.run: [WARNING] 
[2024-06-09 14:10:12,235] torch.distributed.run: [WARNING] *****************************************
[2024-06-09 14:10:12,235] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-06-09 14:10:12,235] torch.distributed.run: [WARNING] *****************************************
hello, reward model
hello, reward model
hello, reward model
hello, reward model
[2024-06-09 14:10:15,503] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-06-09 14:10:15,519] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-06-09 14:10:15,532] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-06-09 14:10:15,569] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
++++++++++++++++++++
come on!
++++++++++++++++++++
[2024-06-09 14:10:16,115] [INFO] [comm.py:637:init_distributed] cdb=None
++++++++++++++++++++
come on!
++++++++++++++++++++
[2024-06-09 14:10:16,200] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-06-09 14:10:16,200] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
++++++++++++++++++++
come on!
++++++++++++++++++++
[2024-06-09 14:10:16,219] [INFO] [comm.py:637:init_distributed] cdb=None
++++++++++++++++++++
come on!
++++++++++++++++++++
[2024-06-09 14:10:16,235] [INFO] [comm.py:637:init_distributed] cdb=None
OpenAssistant/oasst-rm-2.1-pythia-1.4b-epoch-2.5
++++++++++++++++++++++++++++++
OpenAssistant/oasst-rm-2.1-pythia-1.4b-epoch-2.5
++++++++++++++++++++++++++++++
OpenAssistant/oasst-rm-2.1-pythia-1.4b-epoch-2.5
++++++++++++++++++++++++++++++
OpenAssistant/oasst-rm-2.1-pythia-1.4b-epoch-2.5
++++++++++++++++++++++++++++++
[2024-06-09 14:10:19,383] [INFO] [partition_parameters.py:345:__exit__] finished initializing model - num_params = 293, num_elems = 1.31B
[2024-06-09 14:10:22,473] [INFO] [partition_parameters.py:345:__exit__] finished initializing model - num_params = 586, num_elems = 2.62B
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Traceback (most recent call last):
  File "/home/wxt/huatong/TRL_FT/train_code/original_ppov2.py", line 83, in <module>
    output=value_model(**inputs)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/wxt/huatong/TRL_FT/train_code/model_training/models/reward_model.py", line 90, in forward
    outputs = self.gpt_neox(
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py", line 892, in forward
    inputs_embeds = self.embed_in(input_ids)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/functional.py", line 2237, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: 'weight' must be 2-D
Traceback (most recent call last):
  File "/home/wxt/huatong/TRL_FT/train_code/original_ppov2.py", line 83, in <module>
    output=value_model(**inputs)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/wxt/huatong/TRL_FT/train_code/model_training/models/reward_model.py", line 90, in forward
    outputs = self.gpt_neox(
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py", line 892, in forward
    inputs_embeds = self.embed_in(input_ids)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/functional.py", line 2237, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: 'weight' must be 2-D
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Traceback (most recent call last):
  File "/home/wxt/huatong/TRL_FT/train_code/original_ppov2.py", line 83, in <module>
    output=value_model(**inputs)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/wxt/huatong/TRL_FT/train_code/model_training/models/reward_model.py", line 90, in forward
    outputs = self.gpt_neox(
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py", line 892, in forward
    inputs_embeds = self.embed_in(input_ids)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/functional.py", line 2237, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: 'weight' must be 2-D
Traceback (most recent call last):
  File "/home/wxt/huatong/TRL_FT/train_code/original_ppov2.py", line 83, in <module>
    output=value_model(**inputs)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/wxt/huatong/TRL_FT/train_code/model_training/models/reward_model.py", line 90, in forward
    outputs = self.gpt_neox(
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py", line 892, in forward
    inputs_embeds = self.embed_in(input_ids)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/nn/functional.py", line 2237, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: 'weight' must be 2-D
[2024-06-09 14:10:27,259] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 921268) of binary: /home/wxt/.conda/envs/rl/bin/python
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
Traceback (most recent call last):
  File "/home/wxt/.conda/envs/rl/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py", line 46, in main
    args.func(args)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/accelerate/commands/launch.py", line 1060, in launch_command
    deepspeed_launcher(args)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/accelerate/commands/launch.py", line 764, in deepspeed_launcher
    distrib_run.run(args)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/home/wxt/huatong/TRL_FT/train_code/original_ppov2.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-06-09_14:10:27
  host      : design-agent-09.internal.cloudapp.net
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 921269)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-06-09_14:10:27
  host      : design-agent-09.internal.cloudapp.net
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 921270)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2024-06-09_14:10:27
  host      : design-agent-09.internal.cloudapp.net
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 921271)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-06-09_14:10:27
  host      : design-agent-09.internal.cloudapp.net
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 921268)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
