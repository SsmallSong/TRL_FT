[2024-06-25 04:31:32,700] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-06-25 04:31:33,330] torch.distributed.run: [WARNING] 
[2024-06-25 04:31:33,330] torch.distributed.run: [WARNING] *****************************************
[2024-06-25 04:31:33,330] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-06-25 04:31:33,330] torch.distributed.run: [WARNING] *****************************************
hello, reward model
okokokok
hello, reward model
okokokok
hello, reward model
okokokok
hello, reward model
okokokok
[2024-06-25 04:31:36,695] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-06-25 04:31:36,707] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-06-25 04:31:36,713] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-06-25 04:31:36,716] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[2024-06-25 04:31:37,280] [INFO] [comm.py:637:init_distributed] cdb=None
Traceback (most recent call last):
  File "/home/wxt/huatong/TRL_FT/train_code/original_ppov2.py", line 31, in <module>
    config, model_config = parser.parse_args_into_dataclasses()
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/hf_argparser.py", line 339, in parse_args_into_dataclasses
    obj = dtype(**inputs)
  File "<string>", line 158, in __init__
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/training_args.py", line 1641, in __post_init__
    and (self.device.type == "cpu" and not is_torch_greater_or_equal_than_2_3)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/training_args.py", line 2149, in device
    return self._setup_devices
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/utils/generic.py", line 59, in __get__
    cached = self.fget(obj)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/training_args.py", line 2081, in _setup_devices
    self.distributed_state = PartialState(
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/accelerate/state.py", line 280, in __init__
    self.set_device()
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/accelerate/state.py", line 790, in set_device
    torch.cuda.set_device(self.device)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/cuda/__init__.py", line 408, in set_device
    torch._C._cuda_setDevice(device)
RuntimeError: CUDA error: invalid device ordinal
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[2024-06-25 04:31:37,335] [INFO] [comm.py:637:init_distributed] cdb=None
Traceback (most recent call last):
  File "/home/wxt/huatong/TRL_FT/train_code/original_ppov2.py", line 31, in <module>
    config, model_config = parser.parse_args_into_dataclasses()
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/hf_argparser.py", line 339, in parse_args_into_dataclasses
    obj = dtype(**inputs)
  File "<string>", line 158, in __init__
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/training_args.py", line 1641, in __post_init__
    and (self.device.type == "cpu" and not is_torch_greater_or_equal_than_2_3)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/training_args.py", line 2149, in device
    return self._setup_devices
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/utils/generic.py", line 59, in __get__
    cached = self.fget(obj)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/training_args.py", line 2081, in _setup_devices
    self.distributed_state = PartialState(
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/accelerate/state.py", line 280, in __init__
    self.set_device()
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/accelerate/state.py", line 790, in set_device
    torch.cuda.set_device(self.device)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/cuda/__init__.py", line 408, in set_device
    torch._C._cuda_setDevice(device)
RuntimeError: CUDA error: invalid device ordinal
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[2024-06-25 04:31:37,355] [INFO] [comm.py:637:init_distributed] cdb=None
Traceback (most recent call last):
  File "/home/wxt/huatong/TRL_FT/train_code/original_ppov2.py", line 31, in <module>
    config, model_config = parser.parse_args_into_dataclasses()
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/hf_argparser.py", line 339, in parse_args_into_dataclasses
    obj = dtype(**inputs)
  File "<string>", line 158, in __init__
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/training_args.py", line 1641, in __post_init__
    and (self.device.type == "cpu" and not is_torch_greater_or_equal_than_2_3)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/training_args.py", line 2149, in device
    return self._setup_devices
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/utils/generic.py", line 59, in __get__
    cached = self.fget(obj)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/transformers/training_args.py", line 2081, in _setup_devices
    self.distributed_state = PartialState(
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/accelerate/state.py", line 280, in __init__
    self.set_device()
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/accelerate/state.py", line 790, in set_device
    torch.cuda.set_device(self.device)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/cuda/__init__.py", line 408, in set_device
    torch._C._cuda_setDevice(device)
RuntimeError: CUDA error: invalid device ordinal
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[2024-06-25 04:31:37,420] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-06-25 04:31:37,420] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-06-25 04:31:38,053] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1935654 closing signal SIGTERM
[2024-06-25 04:31:38,053] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1935655 closing signal SIGTERM
[2024-06-25 04:31:38,054] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1935657 closing signal SIGTERM
[2024-06-25 04:31:38,218] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 2 (pid: 1935656) of binary: /home/wxt/.conda/envs/rl/bin/python
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
Traceback (most recent call last):
  File "/home/wxt/.conda/envs/rl/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    args.func(args)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/accelerate/commands/launch.py", line 1082, in launch_command
    deepspeed_launcher(args)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/accelerate/commands/launch.py", line 786, in deepspeed_launcher
    distrib_run.run(args)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/home/wxt/huatong/TRL_FT/train_code/original_ppov2.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-06-25_04:31:38
  host      : design-agent-09.internal.cloudapp.net
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 1935656)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
