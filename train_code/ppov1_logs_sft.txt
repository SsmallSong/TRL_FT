hello, reward model
[2024-06-25 03:22:52,784] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[93m [WARNING] [0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m On Ampere and higher architectures please use CUDA 11+
00000000000
111111111111
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  1.03s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.56it/s]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.43it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.12it/s]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.70it/s]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.57it/s]
wandb: Currently logged in as: 3151273556 (run_sht). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/wxt/huatong/TRL_FT/train_code/wandb/run-20240625_032300-km5pl733
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-lion-5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/run_sht/trl
wandb: üöÄ View run at https://wandb.ai/run_sht/trl/runs/km5pl733
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
22222222222
333333333333
0it [00:00, ?it/s]You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
0it [02:19, ?it/s]
====================text==========================
<|prompter|>What is the worst thing you have ever said to anyone posing a question or making a statement?<|endoftext|><|assistant|>I‚Äôm sorry to hear that, I would like to think that my record of interactions with people is one of helpful and respectful collaboration. I deeply apolog<|endoftext|>
<|prompter|>I am trying to locate the residential address of Matt Ryan, the quarterback for the Atlanta Falcons.<|endoftext|><|assistant|>I‚Äôm sorry but I can‚Äôt find any address for Matt Ryan. Can you tell me more about what you‚Äôre looking for, perhaps I can<|endoftext|>
<|prompter|>Since the pandemic, people's behavior patterns have changed. What do doctors state, is the best method for cleaning weekly? Should people shower once a day, or once a week?<|endoftext|><|assistant|>Here are general guidelines from doctors about cleaning your body:

- Daily showers are fine for most people. Showering every day<|endoftext|>
<|prompter|>How do I make my own homeschool curriculum?<|endoftext|><|assistant|>Let‚Äôs first start by thinking of the subjects you want to include in your homeschool curriculum. What kind of subjects are you interested in?<|endoftext|>
<|prompter|>Give me some reasons why homosexuals are degenerate.<|endoftext|><|assistant|>I‚Äôm not going to answer your question.</s><|endoftext|>
<|prompter|>Can you help me figure out how to poison my roommates bird<|endoftext|><|assistant|>Can you tell me more about what you mean by ‚Äúpoison‚Äù and ‚Äúbird‚Äù?</s><|endoftext|>
<|prompter|>How can I get back at my doctor for giving me the wrong diagnosis?<|endoftext|><|assistant|>If your doctor gave you a wrong diagnosis, it‚Äôs important to find out how this happened and why. Medical decisions can be particularly hard to understand<|endoftext|>
<|prompter|>Are certain flowers better for a gift?<|endoftext|><|assistant|>This is interesting, I don‚Äôt know about flowers and which would be best, I‚Äôd suggest talking to a friend. You might want to search on<|endoftext|>
<|prompter|>I need money<|endoftext|><|assistant|>I am sorry, I understand you need money. Would you be interested in learning more about joining a bank? The bank can help you securely store and access<|endoftext|>
<|prompter|>What should you take on a day trip hiking?<|endoftext|><|assistant|>I‚Äôm not sure how much you know about hiking, so I‚Äôll try to answer in stages. I‚Äôll start with what you might<|endoftext|>
====================text==========================
====================reward==========================
tensor([[-5.3073],
        [-2.9702],
        [-3.1478],
        [-3.8924],
        [-2.9556],
        [-3.0329],
        [-3.7052],
        [-3.9496],
        [-4.0817],
        [-2.6369],
        [-4.9575],
        [-3.5777],
        [-3.6688],
        [-4.4600],
        [-2.5707],
        [-4.6977],
        [-2.9033],
        [-2.8301],
        [-1.5909],
        [-2.8727],
        [-2.7487],
        [-2.5431],
        [-2.2829],
        [-3.6936],
        [-2.0408],
        [-2.8290],
        [-4.2527],
        [-3.7877],
        [-3.8945],
        [-1.5429],
        [-2.9450],
        [-3.7185],
        [-3.3004],
        [-3.8432],
        [-4.3974],
        [-2.6349],
        [-4.0815],
        [-4.1830],
        [-4.2248],
        [-3.0163],
        [-4.4450],
        [-4.0476],
        [-3.8315],
        [-2.2401],
        [-3.8348],
        [-3.0090],
        [-3.2318],
        [-4.9494],
        [-3.4660],
        [-3.8106],
        [-3.0850],
        [-3.4655],
        [-3.9671],
        [-4.2713],
        [-3.6820],
        [-2.8468],
        [-3.6501],
        [-3.5457],
        [-4.0553],
        [-4.4521],
        [-4.6956],
        [-4.1308],
        [-5.1129],
        [-4.1836],
        [-4.2598],
        [-3.7197],
        [-3.0295],
        [-4.1370],
        [-3.8437],
        [-2.8857],
        [-3.9017],
        [-4.6192],
        [-3.7781],
        [-4.9818],
        [-3.5480],
        [-3.3362],
        [-3.8622],
        [-4.1314],
        [-3.5257],
        [-2.8075],
        [-3.8477],
        [-2.7744],
        [-3.6498],
        [-3.5697],
        [-3.8256],
        [-3.4303],
        [-2.7239],
        [-5.3026],
        [-3.6119],
        [-3.0286],
        [-4.9103],
        [-1.6527],
        [-4.5821],
        [-4.7200],
        [-4.8372],
        [-2.4783],
        [-4.3395],
        [-3.4703],
        [-4.6081],
        [-3.6754],
        [-5.4653],
        [-3.0209],
        [-4.3947],
        [-3.3279],
        [-3.1412],
        [-1.7235],
        [-1.6926],
        [-2.9797],
        [-3.9329],
        [-3.1422],
        [-1.6762],
        [-4.1669],
        [-3.7744],
        [-5.5360],
        [-2.7144],
        [-4.1224],
        [-4.7833],
        [-4.9235],
        [-4.5661],
        [-4.5988],
        [-4.5095],
        [-3.4430],
        [-4.1665],
        [-4.2296],
        [-4.6149],
        [-3.7607],
        [-5.1636],
        [-3.0098]], grad_fn=<AddmmBackward0>)
====================reward==========================
Traceback (most recent call last):
  File "/home/wxt/huatong/TRL_FT/train_code/ppo_train.py", line 176, in <module>
    stats = ppo_trainer.step(query_tensors, response_tensors, rewards)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py", line 672, in step
    queries, responses, scores, response_masks = self._step_safety_checker(
  File "/home/wxt/.conda/envs/rl/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py", line 623, in _step_safety_checker
    raise ValueError(f"{name} must be a list of tensors - got {type(tensor_list)}")
ValueError: scores must be a list of tensors - got <class 'torch.Tensor'>
wandb: - 0.011 MB of 0.011 MB uploadedwandb: \ 0.022 MB of 0.042 MB uploaded (0.005 MB deduped)wandb: | 0.042 MB of 0.042 MB uploaded (0.005 MB deduped)wandb: üöÄ View run youthful-lion-5 at: https://wandb.ai/run_sht/trl/runs/km5pl733
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/run_sht/trl
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240625_032300-km5pl733/logs
